{"results": [{"createdAt": null, "postedAt": "2012-08-19T04:55:45.693Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Qualitative Strategies of Friendliness", "slug": "seq-rerun-qualitative-strategies-of-friendliness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:07.498Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NNmY8Q8uuiynniYHs/seq-rerun-qualitative-strategies-of-friendliness", "pageUrlRelative": "/posts/NNmY8Q8uuiynniYHs/seq-rerun-qualitative-strategies-of-friendliness", "linkUrl": "https://www.lesswrong.com/posts/NNmY8Q8uuiynniYHs/seq-rerun-qualitative-strategies-of-friendliness", "postedAtFormatted": "Sunday, August 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Qualitative%20Strategies%20of%20Friendliness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Qualitative%20Strategies%20of%20Friendliness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNNmY8Q8uuiynniYHs%2Fseq-rerun-qualitative-strategies-of-friendliness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Qualitative%20Strategies%20of%20Friendliness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNNmY8Q8uuiynniYHs%2Fseq-rerun-qualitative-strategies-of-friendliness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNNmY8Q8uuiynniYHs%2Fseq-rerun-qualitative-strategies-of-friendliness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>Today's post, <a href=\"/lw/ti/qualitative_strategies_of_friendliness/\">Qualitative Strategies of Friendliness</a> was originally published on 30 August 2008 .  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Qualitative_Strategies_of_Friendliness\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Qualitative strategies to achieve friendliness tend to run into difficulty.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e5c/seq_rerun_harder_choices_matter_less/\">Harder Choices Matter Less</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NNmY8Q8uuiynniYHs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.67410742499541e-07, "legacy": true, "legacyId": "18340", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AWaJvBMb9HGBwtNqd", "5mCFeS6bYf2Ktkmsy", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-19T21:51:01.464Z", "modifiedAt": null, "url": null, "title": "Temporary Housing in the Boston area", "slug": "temporary-housing-in-the-boston-area", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:07.524Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "realitygrill", "createdAt": "2009-08-16T18:29:05.163Z", "isAdmin": false, "displayName": "realitygrill"}, "userId": "TuhAvcB3j9Ar5iquu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WXBifRHeedkrgRNgu/temporary-housing-in-the-boston-area", "pageUrlRelative": "/posts/WXBifRHeedkrgRNgu/temporary-housing-in-the-boston-area", "linkUrl": "https://www.lesswrong.com/posts/WXBifRHeedkrgRNgu/temporary-housing-in-the-boston-area", "postedAtFormatted": "Sunday, August 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Temporary%20Housing%20in%20the%20Boston%20area&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATemporary%20Housing%20in%20the%20Boston%20area%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXBifRHeedkrgRNgu%2Ftemporary-housing-in-the-boston-area%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Temporary%20Housing%20in%20the%20Boston%20area%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXBifRHeedkrgRNgu%2Ftemporary-housing-in-the-boston-area", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXBifRHeedkrgRNgu%2Ftemporary-housing-in-the-boston-area", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>Hey,</p>\n<p>I'm doing an internship near MIT this fall and it hadn't occurred to me to think of trying to live with other aspiring rationalists. As expected, it's tough to find a convenient short-term place when so many students are fine signing 1-year leases..</p>\n<p>Any of you possibly open to subletting a room to me Sept-Dec? Extra awesome if you're in Cambridge.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WXBifRHeedkrgRNgu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 4, "extendedScore": null, "score": 9.679139279982507e-07, "legacy": true, "legacyId": "18344", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T03:55:39.379Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Dreams of Friendliness", "slug": "seq-rerun-dreams-of-friendliness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:07.600Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FwiLvEr7AaW7Lcyhe/seq-rerun-dreams-of-friendliness", "pageUrlRelative": "/posts/FwiLvEr7AaW7Lcyhe/seq-rerun-dreams-of-friendliness", "linkUrl": "https://www.lesswrong.com/posts/FwiLvEr7AaW7Lcyhe/seq-rerun-dreams-of-friendliness", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Dreams%20of%20Friendliness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Dreams%20of%20Friendliness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiLvEr7AaW7Lcyhe%2Fseq-rerun-dreams-of-friendliness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Dreams%20of%20Friendliness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiLvEr7AaW7Lcyhe%2Fseq-rerun-dreams-of-friendliness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiLvEr7AaW7Lcyhe%2Fseq-rerun-dreams-of-friendliness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 168, "htmlBody": "<p>Today's post, <a href=\"/lw/tj/dreams_of_friendliness/\">Dreams of Friendliness</a> was originally published on 31 August 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Dreams_of_Friendliness\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Why programming an AI that only answers questions is not a trivial problem, for many of the same reasons that programming an FAI isn't trivial.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e5g/seq_rerun_qualitative_strategies_of_friendliness/\">Qualitative Strategies of Friendliness</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FwiLvEr7AaW7Lcyhe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.680947601628024e-07, "legacy": true, "legacyId": "18350", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wKnwcjJGriTS9QxxL", "NNmY8Q8uuiynniYHs", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T05:21:33.599Z", "modifiedAt": null, "url": null, "title": "LessWrong could grow a lot, but we're doing it wrong.", "slug": "lesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:59.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Epiphany", "createdAt": "2012-08-12T03:33:21.256Z", "isAdmin": false, "displayName": "Epiphany"}, "userId": "BbbFp6hQzKF4YX8em", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GEtLkHyPhG8m4aepb/lesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "pageUrlRelative": "/posts/GEtLkHyPhG8m4aepb/lesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "linkUrl": "https://www.lesswrong.com/posts/GEtLkHyPhG8m4aepb/lesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LessWrong%20could%20grow%20a%20lot%2C%20but%20we're%20doing%20it%20wrong.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALessWrong%20could%20grow%20a%20lot%2C%20but%20we're%20doing%20it%20wrong.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEtLkHyPhG8m4aepb%2Flesswrong-could-grow-a-lot-but-we-re-doing-it-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LessWrong%20could%20grow%20a%20lot%2C%20but%20we're%20doing%20it%20wrong.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEtLkHyPhG8m4aepb%2Flesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEtLkHyPhG8m4aepb%2Flesswrong-could-grow-a-lot-but-we-re-doing-it-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1016, "htmlBody": "<p>How do I know this?&nbsp; I got a copy of the website analytics.<br /><br />The bounce rate for LessWrong's home page is 60%! <br /><br />To be clear: Over half the people who visit LessWrong are going away without even clicking anything.</p>\n<p>Yet how many NEW visitors are there?&nbsp; Almost half of the visitors are new!</p>\n<p>Granted, new visitor statistics aren't perfect, but that's a LOT of people.</p>\n<p><img src=\"http://images.lesswrong.com/t3_e5r_0.png?v=b36daf7a627742228e1d91e062df8ec6\" alt=\"\" width=\"674\" height=\"545\" /></p>\n<p>Simple math should tell us this:</p>\n<p>If we got the bounce rate down around 30% (a reasonable rate for a good site) by making sure every visitor sees something awesome immediately, AND make sure that each visitor can quickly gauge how much they're going to relate to the community (assuming the new users are the right target audience), it would theoretically double the rate of growth, or more.&nbsp; There's a multiplier effect if the bounce rate is improved: you get better placement in search engines.&nbsp; Search engines get more users if they feel that the engine finds interesting content, not just relevant content.</p>\n<p>It's been argued that it's possible that most of the bounces are returning visitors checking for new content.&nbsp; Well if half the visitors to the site each month are new, and we did a wonderful job of showing them that LessWrong is awesome, then the amount of returning visitors could double each month.&nbsp; We're getting a tiny, tiny fraction of that growth:</p>\n<p><img src=\"http://images.lesswrong.com/t3_e5r_1.png?v=f5acb1cdecfbb5add26d2cfa15fe44a5\" alt=\"\" width=\"443\" height=\"667\" /></p>\n<p>http://www.sitemeter.com/?a=stats&amp;s=s18lesswrong&amp;r=36</p>\n<p>Why did I write you guys so much in the <a href=\"/r/discussion/lw/e4z/proposed_rewrites_of_lw_home_page_about_page_and/\">home page rewrites thread</a>?&nbsp; Because I am a web professional who works with web marketing professionals at my job and to me it was blatantly obvious that there's that much room for improvement in the growth of LessWrong.&nbsp; Doing changes like the ones I suggested wouldn't even take long.&nbsp; Because I like this site, and I knew it had potential to grow by leaps and bounds if somebody just paid a little bit of attention to real web marketing.&nbsp; Because I was confused when I first found this site - I had no idea what it's about, or why it's awesome.&nbsp; <strong>I closed the home page, myself.</strong>&nbsp; Another friend mentioned LessWrong.&nbsp; Curiosity perked up again.&nbsp; I came back and read the about page.&nbsp; That didn't make things clearer either.&nbsp; I left again without going further.&nbsp; Friends kept telling me it was awesome.&nbsp; I came back one day and finally found an awesome article!&nbsp; It took me three tries to figure out why you guys are awesome because the web marketing is so bad.&nbsp; The new proposals, although they are well-meaning and it's obvious that John_Maxwell_IV cares about the site, are more of the same bad marketing.<br /><br />I've been interested in web marketing for ten years.&nbsp; It's a topic I've accumulated a lot of information about.&nbsp; As I see it, the way these guys are going about this is totally counter-intuitive to web basic marketing principles.&nbsp; They don't even seem to know how harsh users are the first time they see a new website.&nbsp; They tend to just go away if it doesn't grab them in a few seconds.&nbsp; They're like \"well we will put interesting links in\" but that's not how it works!&nbsp; The links don't make the site interesting - the site has got to be interesting enough for users to click the links.&nbsp; Thinking the links will make the site interesting is backward.&nbsp; If you want to improve your bounce rate, your goal is to be awesome immediately in order to <em>get the user to stay on the page long enough </em>to want to click your link.&nbsp; If it wasn't usually hard to get users to click links, we wouldn't track bounce rates. These guys know this particular group of users better than I do, but I know web marketing principles that they're not even seeing when pointed out.&nbsp; To me, they seem to be totally unaware of the field of web marketing.&nbsp; The numbers don't lie and they're saying there's huge room for improvement.&nbsp;</p>\n<p>If you want to grow, it's time to try something different.</p>\n<p>Here's a thought:&nbsp; There is a lot awesome content that's on this website.&nbsp; We need to take what's awesome and make it in-your-face obvious.&nbsp; I wrote a plan for how to quickly find the most effective awesome content (the website statistics will tell you which pages keep new visitors on them the longest), and how to use them to effectively get the attention of new users - copy the first paragraph from one of those pages, which was most likely constructed by a competent writer in a way that hooks people (if it's keeping them on the page then it's essentially proven to!) and place that as bait right on the front page.&nbsp; (There is also a <a href=\"/r/discussion/lw/e4z/proposed_rewrites_of_lw_home_page_about_page_and/78dd\">wrong way to do this</a>.)&nbsp; Then of course, the user needs to find out why the LessWrong community might be a place where they belong.&nbsp; I shared ideas for that in <a href=\"/r/discussion/lw/e4z/proposed_rewrites_of_lw_home_page_about_page_and/78d4\">\"About us - Building Interest\"</a>.<br /><br />Don't let's assume that growth is going to be good.&nbsp; You're going to get more internet trolls, more spam, (there's a way to control spam which I would be happy to share) and more newbies who don't know what they're doing (I provided some <a href=\"/r/discussion/lw/e4z/proposed_rewrites_of_lw_home_page_about_page_and/78dc\">suggestions to help get them on track quickly</a>, preventing annoyance for both you and them).&nbsp; There will be people with new ideas, but if the wrong audience is targeted... well.&nbsp; We'd better choose what audience to target.&nbsp; I saw an internet forum take off once - it seemed to be growing slowly, until we looked at the curve and saw that it was exponential.&nbsp; That of course quickly turned to a dazzling exponential curve.&nbsp; Suddenly the new users outnumbered the old ones.&nbsp; That could happen here -- even if we do nothing.&nbsp; YOU can get involved.&nbsp; YOU can influence who to target.&nbsp; They're taking suggestions on rewrites right now.&nbsp; Go to the thread.&nbsp; I invite brutal honesty on everything I wrote there.&nbsp; Or pick my brain, if you'd prefer.</p>\n<p>What do you want, LessWrong?&nbsp; Do you want to grow optimally?&nbsp; Who do you want to see showing up?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GEtLkHyPhG8m4aepb", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 66, "baseScore": 66, "extendedScore": null, "score": 9.681373711381092e-07, "legacy": true, "legacyId": "18351", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-06-14T22:04:48.415Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 51, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TD2bn6MNXmecW4YWY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T07:51:48.358Z", "modifiedAt": null, "url": null, "title": "\"Measuring the distribution of spitefulness\" - link", "slug": "measuring-the-distribution-of-spitefulness-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:23.635Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Alex", "createdAt": "2009-07-17T08:21:38.505Z", "isAdmin": false, "displayName": "D_Alex"}, "userId": "Sriopfkdwx2qJBx4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JBctnp7oqNwsucAHR/measuring-the-distribution-of-spitefulness-link", "pageUrlRelative": "/posts/JBctnp7oqNwsucAHR/measuring-the-distribution-of-spitefulness-link", "linkUrl": "https://www.lesswrong.com/posts/JBctnp7oqNwsucAHR/measuring-the-distribution-of-spitefulness-link", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Measuring%20the%20distribution%20of%20spitefulness%22%20-%20link&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Measuring%20the%20distribution%20of%20spitefulness%22%20-%20link%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBctnp7oqNwsucAHR%2Fmeasuring-the-distribution-of-spitefulness-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Measuring%20the%20distribution%20of%20spitefulness%22%20-%20link%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBctnp7oqNwsucAHR%2Fmeasuring-the-distribution-of-spitefulness-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBctnp7oqNwsucAHR%2Fmeasuring-the-distribution-of-spitefulness-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p><a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0041812\">http://www.plosone.org/article/info:doi/10.1371/journal.pone.0041812</a></p>\n<p>Here is a rather curious paper describing psychology researchers' attempts to investigate \"spitefulness\" - I think they define spitefulness roughly as \"hurting others without any benefit to oneself\". References the Stanford Prison Experiment. Concludes, more or less, that some people are spiteful, sometimes.</p>\n<p>I have many reservations about the methodology used in this experiment (main one: not sure if the entire process really reflects any real-world motivations, and hence results might not mean much), but I thought it might be of interest to people on this site. Also, of the 30-odd references cited at the end of the paper some sound rather interesting and many are available online.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JBctnp7oqNwsucAHR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 9.682119058600762e-07, "legacy": true, "legacyId": "18357", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T09:24:03.086Z", "modifiedAt": null, "url": null, "title": "[Link] Social interventions gone wrong ", "slug": "link-social-interventions-gone-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:18.244Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b2HZLjKvfhX929nWY/link-social-interventions-gone-wrong", "pageUrlRelative": "/posts/b2HZLjKvfhX929nWY/link-social-interventions-gone-wrong", "linkUrl": "https://www.lesswrong.com/posts/b2HZLjKvfhX929nWY/link-social-interventions-gone-wrong", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Social%20interventions%20gone%20wrong%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Social%20interventions%20gone%20wrong%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb2HZLjKvfhX929nWY%2Flink-social-interventions-gone-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Social%20interventions%20gone%20wrong%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb2HZLjKvfhX929nWY%2Flink-social-interventions-gone-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb2HZLjKvfhX929nWY%2Flink-social-interventions-gone-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1998, "htmlBody": "<p><a href=\"http://80000hours.org/blog/66-social-interventions-gone-wrong\">A piece</a> I saw that Benjamin Todd adapted from <a href=\"http://www.thehighimpactnetwork.org/\">THINK</a>'s module on charity assessment. Some of you may recall the network's <a href=\"/r/discussion/lw/dyj/the_high_impact_network_think_launching_now/\">recent launch</a>.&nbsp;</p>\n<blockquote>\n<p><strong>Lots of social interventions end up doing more harm than good. Many more make no difference at all, and are just a waste of resources. At times, we&rsquo;ve probably argued with friends about which interventions we&rsquo;d like to see, and which we wouldn&rsquo;t. But are we any good at judging what&rsquo;s likely to work?</strong></p>\n<p>Here&rsquo;s a cool bit of content adapted from <a href=\"http://www.thehighimpactnetwork.org\">THINK</a>. Try and guess which of these eight programs made a difference, which had no effect, and which made things worse.</p>\n</blockquote>\n<p><a href=\"/lw/e5y/link_social_interventions_gone_wrong/78lt\">cipergoth said</a> that it should be emphasised that this isn't a trick question where the answer is they all worked or none did.</p>\n<blockquote>\n<hr />\n<p><strong>Round #1: Scared Straight</strong></p>\n<p><em>Program description</em>: &ldquo;In the 1970s, inmates serving life sentences at a New Jersey (USA) prison began a program to &lsquo;scare&rsquo; or deter at\u2010risk or delinquent children from a future life of crime. The program, known as &lsquo;Scared Straight&rsquo;, featured as its main component an aggressive presentation by inmates to juveniles visiting the prison facility. The presentation depicted life in adult prisons, and often included exaggerated stories of rape and murder &hellip; The program received considerable and favorable media attention and was soon replicated in over 30 jurisdictions nationwide &hellip; Although the harsh and sometimes vulgar presentation in the earlier New Jersey version is the most famous, inmate presentations are now sometimes designed to be more educational than confrontational but with a similar crime prevention goal. Some of these programs featured interactive discussions between the inmates and juveniles, also referred to as &lsquo;rap sessions.&rsquo;(2)</p>\n<p><em>Did the program decrease the rate of juvenile crime?</em></p>\n<p><strong>Round #2: Nurse\u2010Family Partnership</strong></p>\n<p><em>Program description</em>: &ldquo;The Nurse\u2010Family Partnership program provides nurse home visits to pregnant women with no previous live births, most of whom are i) low\u2010income, ii) unmarried, and iii) teenagers. The nurses visit the women approximately once per month during their pregnancy and the first two years of their children&rsquo;s lives. The nurses teach i) positive health related behaviors, ii) competent care of children, and iii) maternal personal development (family planning, educational achievement, and participation in the workforce). The program costs approximately $12,500 per woman over the three years of visits (in 2010 dollars).&rdquo;(6)</p>\n<p><em>Did the program improve the quality of child care?</em></p>\n<p><strong>Round #3: Drug Abuse Resistance Education (DARE)</strong></p>\n<p><em>Program description</em>: &ldquo;DARE is a highly\u2010structured substance\u2010abuse prevention program taught by uniformed police officers &hellip; The program is typically provided over the course of 10\u201020 weekly hour\u2010long sessions, during which the police officers use lectures, class discussion, role plays, and homework assignments to i) teach students about substance use and its effects, ii) teach students decision\u2010making and peer pressure resistance skills, and iii) boost students&rsquo; self\u2010esteem. Prior to teaching, the police officers take an 80\u2010hour training course on teaching techniques, classroom management, and the DARE curriculum &hellip; DARE costs approximately $130 (in 2004 dollars) per student and, as of 2001, was operating in 75% of American school districts.&rdquo;(8)</p>\n<p><em>Did the program decrease the rate of drug use?</em></p>\n<p><strong>Rounds #4 and #5: 21st Century Community Learning Centers</strong></p>\n<p><em>Program description</em>: &ldquo;21st Century Community Learning centers is a large ($1 billion per year) US Department of Education program which funds optional after\u2010school programs for elementary and middle school students in mostly high\u2010poverty schools. Key goals of the program are to i) provide students with a safe place after school, and ii) improve their academic performance. Recipients of program funds (ie, school districts and/or non\u2010profit educational/community organizations) are required to provide academically focused &ldquo;extended learning activities&rdquo; (e.g., instructional enrichment programs, tutoring, or homework assistance). Most centers also offer enrichment/recreational activities such as martial arts, sports, dance, art and/or music &hellip; (Elementary school) centers vary in the activities they offer and other key features, and thus comprise a range of after\u2010school interventions rather than a single intervention. In a typical center,</p>\n<ol>\n<li>\n<p>students may spend an hour doing homework and having a snack, an hour on additional academic activity (eg, a lesson or working in a computer lab), and an hour doing recreational or cultural activities;</p>\n</li>\n<li>\n<p>the center&rsquo;s staff are a mixture of certified teachers, instructional aides, and representatives of community youth organizations;</p>\n</li>\n<li>\n<p>the center is open 4\u20105 days per week for three hours after school, and serves approximately 85 students per day; and</p>\n</li>\n<li>\n<p>the average student attends the center 2\u20103 days per week.</p>\n</li>\n</ol>\n<p>Centers spend approximately $1,000 (in 2005 dollars) on each enrolled student per year.&rdquo;(10)</p>\n<p><em>Did the program increase the students&rsquo; academic achievement?</em></p>\n<p><em>Did the program improve the behavioural problems at the schools?</em></p>\n<p><strong>Round #6: Even Start Family Literacy program</strong></p>\n<p><em>Program description</em>: &ldquo;The Even Start program is intended to &lsquo;help break the cycle of poverty and illiteracy by improving the educational opportunities of the nation&rsquo;s low\u2010income families by integrating early childhood education, adult literacy or adult basic education, and parenting education into a unified family literacy program&rsquo;. In 2000\u20102001, there were 855 Even Start projects serving 31,896 families &hellip; Even Start grantees had considerable flexibility in designing services to meet the needs of the low\u2010income families, but all were required to offer four services:</p>\n<ol>\n<li>\n<p>adult education to develop basic educational and literacy skills;</p>\n</li>\n<li>\n<p>early childhood education services to provide developmentally appropriate services to help prepare children for school;</p>\n</li>\n<li>\n<p>parenting education to help parents support the educational growth of their children; and</p>\n</li>\n<li>\n<p>parent\u2010child literacy activities.&rdquo;(13)</p>\n</li>\n</ol>\n<p><em>Did the program increase literacy?</em></p>\n<p><strong>Round #7: Big Brothers Big Sisters</strong></p>\n<p><em>Program description</em>: &ldquo;Big Brothers Big Sisters&rsquo; community\u2010based mentoring program matches youths aged 6\u201018, predominantly from low\u2010income, single\u2010parent households, with adult volunteer mentors who are typically young (20\u201034) and well\u2010educated (the majority are college graduates) &hellip; The mentor and youth typically meet for 2\u20104 times per month for at least a year, and engage in activities of their choosing (e.g., studying, cooking, playing sports). The typical meeting lasts 3\u20104 hours &hellip; For the first year, Big Brothers Big Sisters case workers maintain monthly contact with the mentor, as well as the youth and his or her parent, to insure a positive mentor\u2010youth match, and to help resolve any problems in the relationship. Mentors are encouraged to form a supportive friendship with the youths, as opposed to modifying the youth&rsquo;s behavior or character&hellip; In 2008, Big Brothers Big Sisters served 255,000 youths and 470 agencies nationwide. The national average cost of making and supporting a match is approximately $1,300 in 2009 dollars.&rdquo;(14)</p>\n<p><em>Did the program decrease drug use and violent behavior?</em></p>\n<p><strong>Round #8: Top 16 Educational Software</strong></p>\n<p><em>Program description</em>: &ldquo;In the No Child Left Behind Act of 2002, Congress called for a rigorous study of the effectiveness of educational technology for improving student academic achievement &hellip; In fall 2003, developers and vendors of educational technology products responded to a public invitation and submitted products for possible inclusion in the national study. <span>Mathematica Policy Research, Inc.</span> staff selected 40 of the 160 submissions for further review by two panels of outside experts, one for reading products and one for math products &hellip; In January 2004, (the US Department of Education] considered the panel&rsquo;s recommendations and selected 16 products for the study. In selecting products, (the US Department of Education) grouped them into four areas:</p>\n<ol>\n<li>\n<p>early reading (first grade),</p>\n</li>\n<li>\n<p>reading comprehension (fourth grade),</p>\n</li>\n<li>\n<p>pre\u2010algebra (sixth grade), and</p>\n</li>\n<li>\n<p>algebra (ninth grade).</p>\n</li>\n</ol>\n<p>The products ranged widely in their instructional approaches and how long they had been in use. In general, however, the criteria weighted the selection towards products that had evidence of effectiveness from previous research, or, for newer products, evidence that their designs were based on approaches found to be effective by research. Twelve of the sixteen products had received awards or been nominated for awards (some as recently as 2006) by trade associations, media, teachers, or parents.&rdquo;(15)</p>\n<p><em>Did the program improve test scores?</em></p>\n<hr />\n<h3 id=\"here_are_the_answers\">Here are the answers!</h3>\n<hr />\n<p><strong>Round #1: Scared Straight</strong></p>\n<p><strong>Negative!</strong> Several randomized controlled trials have shown that Scared Straight had a negative effect. Going through Scared Straight made children <em>more</em> likely to commit crimes in the future (3). Fun fact: Scared Straight programs are still being run today (4), and people promote them as being effective, despite the fact that they are harmful (5).</p>\n<p><strong>Round #2: Nurse\u2010Family Partnership</strong></p>\n<p><strong>Positive!</strong> Three randomized controlled trials have shown that the Nurse\u2010Family Partnership had a positive effect. The program led to a reduction in child abuse/neglect, child injuries (20\u201050% reduction) and an improvement in cognitive/educational outcomes for children of mothers with low mental health/confidence/intelligence (e.g., 6 percentile point increase in grade 1\u20106 in reading/math achievement) (7).</p>\n<p><strong>Round #3: Drug Abuse Resistance Education (DARE)</strong></p>\n<p><strong>No effect!</strong>Two randomized controlled trials have shown that DARE did not have an effect on the rate of drug use among participants. The rate of drug use did not increase or decrease (9).</p>\n<p><strong>Round #4: 21st Century Community Learning Centers</strong></p>\n<p><strong>No effect!</strong> A randomized controlled trial has shown that the 21st Century Community Learning Centers had no effect on participating students&rsquo; academic performance. Students who participated were neither helped nor harmed by the program.(11)</p>\n<p><strong>Round #5: 21st Century Community Learning Centers</strong></p>\n<p><strong>Negative!</strong> A randomized controlled trial has shown that the 21st Century Community Learning Centers caused an increase in the behavioral problems of participating students (12).</p>\n<p><strong>Round #6: Even Start Family Literacy Program</strong></p>\n<p><strong>No effect!</strong> A randomized controlled trial on a subset of Even Start programs found no evidence of an increase or decrease in literacy in parents or children (17).</p>\n<p><strong>Round #7: Big Brothers Big Sisters</strong></p>\n<p><strong>Positive!</strong> A randomized controlled trial has shown that Big Brothers Big Sisters caused youths to be 46% less likely to have started using illegal drugs, 27% less likely to have started using alcohol, 32% less likely to have hit someone in the previous year and fewer days of skipping school during the past year (18).</p>\n<p><strong>Round #8: Top 16 Educational Software</strong></p>\n<p><strong>No effect!</strong>The study described was a randomized controlled trial, and showed that the software did not make a noticeable difference in any of the categories. It did not help or hurt with 1) early reading (first grade), 2) reading comprehension (fourth grade), 3) pre\u2010 algebra (sixth grade), or 4) algebra (ninth grade) (19).</p>\n<hr />\n<h3 id=\"how_did_you_do\">How did you do?</h3>\n<p>If you got 7-8 right, there&rsquo;s less than a 1% chance you were guessing. If you got 5-6 right, there was only an 8.5% chance you were guessing, so it might be skill. If you got 1-4 right, then you did no better than randomly guessing. If you got zero right &hellip; we could get useful information by always doing the opposite of what you do.</p>\n<p><strong>The effects of social interventions are extremely complex. All of these programs sound good, but unintended consequences can get in the way. It&rsquo;s very difficult to work out what&rsquo;s going to be successful ahead of time. Instead, we need to test, measure the results, and take it from there.</strong></p>\n</blockquote>\n<p>I thought Round 2 would have no effect and expected Round #5 to have no effect not a negative one, I got 6 out of 8 correct. How well did you do?</p>\n<p>I recommend checking out the links and references. Gwern's comment there was also interesting.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1, "vg4LDxjdwHLotCm8w": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b2HZLjKvfhX929nWY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 34, "extendedScore": null, "score": 9e-05, "legacy": true, "legacyId": "18358", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"http://80000hours.org/blog/66-social-interventions-gone-wrong\">A piece</a> I saw that Benjamin Todd adapted from <a href=\"http://www.thehighimpactnetwork.org/\">THINK</a>'s module on charity assessment. Some of you may recall the network's <a href=\"/r/discussion/lw/dyj/the_high_impact_network_think_launching_now/\">recent launch</a>.&nbsp;</p>\n<blockquote>\n<p><strong id=\"Lots_of_social_interventions_end_up_doing_more_harm_than_good__Many_more_make_no_difference_at_all__and_are_just_a_waste_of_resources__At_times__we_ve_probably_argued_with_friends_about_which_interventions_we_d_like_to_see__and_which_we_wouldn_t__But_are_we_any_good_at_judging_what_s_likely_to_work_\">Lots of social interventions end up doing more harm than good. Many more make no difference at all, and are just a waste of resources. At times, we\u2019ve probably argued with friends about which interventions we\u2019d like to see, and which we wouldn\u2019t. But are we any good at judging what\u2019s likely to work?</strong></p>\n<p>Here\u2019s a cool bit of content adapted from <a href=\"http://www.thehighimpactnetwork.org\">THINK</a>. Try and guess which of these eight programs made a difference, which had no effect, and which made things worse.</p>\n</blockquote>\n<p><a href=\"/lw/e5y/link_social_interventions_gone_wrong/78lt\">cipergoth said</a> that it should be emphasised that this isn't a trick question where the answer is they all worked or none did.</p>\n<blockquote>\n<hr>\n<p><strong id=\"Round__1__Scared_Straight\">Round #1: Scared Straight</strong></p>\n<p><em>Program description</em>: \u201cIn the 1970s, inmates serving life sentences at a New Jersey (USA) prison began a program to \u2018scare\u2019 or deter at\u2010risk or delinquent children from a future life of crime. The program, known as \u2018Scared Straight\u2019, featured as its main component an aggressive presentation by inmates to juveniles visiting the prison facility. The presentation depicted life in adult prisons, and often included exaggerated stories of rape and murder \u2026 The program received considerable and favorable media attention and was soon replicated in over 30 jurisdictions nationwide \u2026 Although the harsh and sometimes vulgar presentation in the earlier New Jersey version is the most famous, inmate presentations are now sometimes designed to be more educational than confrontational but with a similar crime prevention goal. Some of these programs featured interactive discussions between the inmates and juveniles, also referred to as \u2018rap sessions.\u2019(2)</p>\n<p><em>Did the program decrease the rate of juvenile crime?</em></p>\n<p><strong id=\"Round__2__Nurse_Family_Partnership\">Round #2: Nurse\u2010Family Partnership</strong></p>\n<p><em>Program description</em>: \u201cThe Nurse\u2010Family Partnership program provides nurse home visits to pregnant women with no previous live births, most of whom are i) low\u2010income, ii) unmarried, and iii) teenagers. The nurses visit the women approximately once per month during their pregnancy and the first two years of their children\u2019s lives. The nurses teach i) positive health related behaviors, ii) competent care of children, and iii) maternal personal development (family planning, educational achievement, and participation in the workforce). The program costs approximately $12,500 per woman over the three years of visits (in 2010 dollars).\u201d(6)</p>\n<p><em>Did the program improve the quality of child care?</em></p>\n<p><strong id=\"Round__3__Drug_Abuse_Resistance_Education__DARE_\">Round #3: Drug Abuse Resistance Education (DARE)</strong></p>\n<p><em>Program description</em>: \u201cDARE is a highly\u2010structured substance\u2010abuse prevention program taught by uniformed police officers \u2026 The program is typically provided over the course of 10\u201020 weekly hour\u2010long sessions, during which the police officers use lectures, class discussion, role plays, and homework assignments to i) teach students about substance use and its effects, ii) teach students decision\u2010making and peer pressure resistance skills, and iii) boost students\u2019 self\u2010esteem. Prior to teaching, the police officers take an 80\u2010hour training course on teaching techniques, classroom management, and the DARE curriculum \u2026 DARE costs approximately $130 (in 2004 dollars) per student and, as of 2001, was operating in 75% of American school districts.\u201d(8)</p>\n<p><em>Did the program decrease the rate of drug use?</em></p>\n<p><strong id=\"Rounds__4_and__5__21st_Century_Community_Learning_Centers\">Rounds #4 and #5: 21st Century Community Learning Centers</strong></p>\n<p><em>Program description</em>: \u201c21st Century Community Learning centers is a large ($1 billion per year) US Department of Education program which funds optional after\u2010school programs for elementary and middle school students in mostly high\u2010poverty schools. Key goals of the program are to i) provide students with a safe place after school, and ii) improve their academic performance. Recipients of program funds (ie, school districts and/or non\u2010profit educational/community organizations) are required to provide academically focused \u201cextended learning activities\u201d (e.g., instructional enrichment programs, tutoring, or homework assistance). Most centers also offer enrichment/recreational activities such as martial arts, sports, dance, art and/or music \u2026 (Elementary school) centers vary in the activities they offer and other key features, and thus comprise a range of after\u2010school interventions rather than a single intervention. In a typical center,</p>\n<ol>\n<li>\n<p>students may spend an hour doing homework and having a snack, an hour on additional academic activity (eg, a lesson or working in a computer lab), and an hour doing recreational or cultural activities;</p>\n</li>\n<li>\n<p>the center\u2019s staff are a mixture of certified teachers, instructional aides, and representatives of community youth organizations;</p>\n</li>\n<li>\n<p>the center is open 4\u20105 days per week for three hours after school, and serves approximately 85 students per day; and</p>\n</li>\n<li>\n<p>the average student attends the center 2\u20103 days per week.</p>\n</li>\n</ol>\n<p>Centers spend approximately $1,000 (in 2005 dollars) on each enrolled student per year.\u201d(10)</p>\n<p><em>Did the program increase the students\u2019 academic achievement?</em></p>\n<p><em>Did the program improve the behavioural problems at the schools?</em></p>\n<p><strong id=\"Round__6__Even_Start_Family_Literacy_program\">Round #6: Even Start Family Literacy program</strong></p>\n<p><em>Program description</em>: \u201cThe Even Start program is intended to \u2018help break the cycle of poverty and illiteracy by improving the educational opportunities of the nation\u2019s low\u2010income families by integrating early childhood education, adult literacy or adult basic education, and parenting education into a unified family literacy program\u2019. In 2000\u20102001, there were 855 Even Start projects serving 31,896 families \u2026 Even Start grantees had considerable flexibility in designing services to meet the needs of the low\u2010income families, but all were required to offer four services:</p>\n<ol>\n<li>\n<p>adult education to develop basic educational and literacy skills;</p>\n</li>\n<li>\n<p>early childhood education services to provide developmentally appropriate services to help prepare children for school;</p>\n</li>\n<li>\n<p>parenting education to help parents support the educational growth of their children; and</p>\n</li>\n<li>\n<p>parent\u2010child literacy activities.\u201d(13)</p>\n</li>\n</ol>\n<p><em>Did the program increase literacy?</em></p>\n<p><strong id=\"Round__7__Big_Brothers_Big_Sisters\">Round #7: Big Brothers Big Sisters</strong></p>\n<p><em>Program description</em>: \u201cBig Brothers Big Sisters\u2019 community\u2010based mentoring program matches youths aged 6\u201018, predominantly from low\u2010income, single\u2010parent households, with adult volunteer mentors who are typically young (20\u201034) and well\u2010educated (the majority are college graduates) \u2026 The mentor and youth typically meet for 2\u20104 times per month for at least a year, and engage in activities of their choosing (e.g., studying, cooking, playing sports). The typical meeting lasts 3\u20104 hours \u2026 For the first year, Big Brothers Big Sisters case workers maintain monthly contact with the mentor, as well as the youth and his or her parent, to insure a positive mentor\u2010youth match, and to help resolve any problems in the relationship. Mentors are encouraged to form a supportive friendship with the youths, as opposed to modifying the youth\u2019s behavior or character\u2026 In 2008, Big Brothers Big Sisters served 255,000 youths and 470 agencies nationwide. The national average cost of making and supporting a match is approximately $1,300 in 2009 dollars.\u201d(14)</p>\n<p><em>Did the program decrease drug use and violent behavior?</em></p>\n<p><strong id=\"Round__8__Top_16_Educational_Software\">Round #8: Top 16 Educational Software</strong></p>\n<p><em>Program description</em>: \u201cIn the No Child Left Behind Act of 2002, Congress called for a rigorous study of the effectiveness of educational technology for improving student academic achievement \u2026 In fall 2003, developers and vendors of educational technology products responded to a public invitation and submitted products for possible inclusion in the national study. <span>Mathematica Policy Research, Inc.</span> staff selected 40 of the 160 submissions for further review by two panels of outside experts, one for reading products and one for math products \u2026 In January 2004, (the US Department of Education] considered the panel\u2019s recommendations and selected 16 products for the study. In selecting products, (the US Department of Education) grouped them into four areas:</p>\n<ol>\n<li>\n<p>early reading (first grade),</p>\n</li>\n<li>\n<p>reading comprehension (fourth grade),</p>\n</li>\n<li>\n<p>pre\u2010algebra (sixth grade), and</p>\n</li>\n<li>\n<p>algebra (ninth grade).</p>\n</li>\n</ol>\n<p>The products ranged widely in their instructional approaches and how long they had been in use. In general, however, the criteria weighted the selection towards products that had evidence of effectiveness from previous research, or, for newer products, evidence that their designs were based on approaches found to be effective by research. Twelve of the sixteen products had received awards or been nominated for awards (some as recently as 2006) by trade associations, media, teachers, or parents.\u201d(15)</p>\n<p><em>Did the program improve test scores?</em></p>\n<hr>\n<h3 id=\"Here_are_the_answers_\">Here are the answers!</h3>\n<hr>\n<p><strong id=\"Round__1__Scared_Straight1\">Round #1: Scared Straight</strong></p>\n<p><strong>Negative!</strong> Several randomized controlled trials have shown that Scared Straight had a negative effect. Going through Scared Straight made children <em>more</em> likely to commit crimes in the future (3). Fun fact: Scared Straight programs are still being run today (4), and people promote them as being effective, despite the fact that they are harmful (5).</p>\n<p><strong id=\"Round__2__Nurse_Family_Partnership1\">Round #2: Nurse\u2010Family Partnership</strong></p>\n<p><strong>Positive!</strong> Three randomized controlled trials have shown that the Nurse\u2010Family Partnership had a positive effect. The program led to a reduction in child abuse/neglect, child injuries (20\u201050% reduction) and an improvement in cognitive/educational outcomes for children of mothers with low mental health/confidence/intelligence (e.g., 6 percentile point increase in grade 1\u20106 in reading/math achievement) (7).</p>\n<p><strong id=\"Round__3__Drug_Abuse_Resistance_Education__DARE_1\">Round #3: Drug Abuse Resistance Education (DARE)</strong></p>\n<p><strong>No effect!</strong>Two randomized controlled trials have shown that DARE did not have an effect on the rate of drug use among participants. The rate of drug use did not increase or decrease (9).</p>\n<p><strong id=\"Round__4__21st_Century_Community_Learning_Centers\">Round #4: 21st Century Community Learning Centers</strong></p>\n<p><strong>No effect!</strong> A randomized controlled trial has shown that the 21st Century Community Learning Centers had no effect on participating students\u2019 academic performance. Students who participated were neither helped nor harmed by the program.(11)</p>\n<p><strong id=\"Round__5__21st_Century_Community_Learning_Centers\">Round #5: 21st Century Community Learning Centers</strong></p>\n<p><strong>Negative!</strong> A randomized controlled trial has shown that the 21st Century Community Learning Centers caused an increase in the behavioral problems of participating students (12).</p>\n<p><strong id=\"Round__6__Even_Start_Family_Literacy_Program\">Round #6: Even Start Family Literacy Program</strong></p>\n<p><strong>No effect!</strong> A randomized controlled trial on a subset of Even Start programs found no evidence of an increase or decrease in literacy in parents or children (17).</p>\n<p><strong id=\"Round__7__Big_Brothers_Big_Sisters1\">Round #7: Big Brothers Big Sisters</strong></p>\n<p><strong>Positive!</strong> A randomized controlled trial has shown that Big Brothers Big Sisters caused youths to be 46% less likely to have started using illegal drugs, 27% less likely to have started using alcohol, 32% less likely to have hit someone in the previous year and fewer days of skipping school during the past year (18).</p>\n<p><strong id=\"Round__8__Top_16_Educational_Software1\">Round #8: Top 16 Educational Software</strong></p>\n<p><strong>No effect!</strong>The study described was a randomized controlled trial, and showed that the software did not make a noticeable difference in any of the categories. It did not help or hurt with 1) early reading (first grade), 2) reading comprehension (fourth grade), 3) pre\u2010 algebra (sixth grade), or 4) algebra (ninth grade) (19).</p>\n<hr>\n<h3 id=\"How_did_you_do_\">How did you do?</h3>\n<p>If you got 7-8 right, there\u2019s less than a 1% chance you were guessing. If you got 5-6 right, there was only an 8.5% chance you were guessing, so it might be skill. If you got 1-4 right, then you did no better than randomly guessing. If you got zero right \u2026 we could get useful information by always doing the opposite of what you do.</p>\n<p><strong id=\"The_effects_of_social_interventions_are_extremely_complex__All_of_these_programs_sound_good__but_unintended_consequences_can_get_in_the_way__It_s_very_difficult_to_work_out_what_s_going_to_be_successful_ahead_of_time__Instead__we_need_to_test__measure_the_results__and_take_it_from_there_\">The effects of social interventions are extremely complex. All of these programs sound good, but unintended consequences can get in the way. It\u2019s very difficult to work out what\u2019s going to be successful ahead of time. Instead, we need to test, measure the results, and take it from there.</strong></p>\n</blockquote>\n<p>I thought Round 2 would have no effect and expected Round #5 to have no effect not a negative one, I got 6 out of 8 correct. How well did you do?</p>\n<p>I recommend checking out the links and references. Gwern's comment there was also interesting.</p>", "sections": [{"title": "Lots of social interventions end up doing more harm than good. Many more make no difference at all, and are just a waste of resources. At times, we\u2019ve probably argued with friends about which interventions we\u2019d like to see, and which we wouldn\u2019t. But are we any good at judging what\u2019s likely to work?", "anchor": "Lots_of_social_interventions_end_up_doing_more_harm_than_good__Many_more_make_no_difference_at_all__and_are_just_a_waste_of_resources__At_times__we_ve_probably_argued_with_friends_about_which_interventions_we_d_like_to_see__and_which_we_wouldn_t__But_are_we_any_good_at_judging_what_s_likely_to_work_", "level": 2}, {"title": "Round #1: Scared Straight", "anchor": "Round__1__Scared_Straight", "level": 2}, {"title": "Round #2: Nurse\u2010Family Partnership", "anchor": "Round__2__Nurse_Family_Partnership", "level": 2}, {"title": "Round #3: Drug Abuse Resistance Education (DARE)", "anchor": "Round__3__Drug_Abuse_Resistance_Education__DARE_", "level": 2}, {"title": "Rounds #4 and #5: 21st Century Community Learning Centers", "anchor": "Rounds__4_and__5__21st_Century_Community_Learning_Centers", "level": 2}, {"title": "Round #6: Even Start Family Literacy program", "anchor": "Round__6__Even_Start_Family_Literacy_program", "level": 2}, {"title": "Round #7: Big Brothers Big Sisters", "anchor": "Round__7__Big_Brothers_Big_Sisters", "level": 2}, {"title": "Round #8: Top 16 Educational Software", "anchor": "Round__8__Top_16_Educational_Software", "level": 2}, {"title": "Here are the answers!", "anchor": "Here_are_the_answers_", "level": 1}, {"title": "Round #1: Scared Straight", "anchor": "Round__1__Scared_Straight1", "level": 2}, {"title": "Round #2: Nurse\u2010Family Partnership", "anchor": "Round__2__Nurse_Family_Partnership1", "level": 2}, {"title": "Round #3: Drug Abuse Resistance Education (DARE)", "anchor": "Round__3__Drug_Abuse_Resistance_Education__DARE_1", "level": 2}, {"title": "Round #4: 21st Century Community Learning Centers", "anchor": "Round__4__21st_Century_Community_Learning_Centers", "level": 2}, {"title": "Round #5: 21st Century Community Learning Centers", "anchor": "Round__5__21st_Century_Community_Learning_Centers", "level": 2}, {"title": "Round #6: Even Start Family Literacy Program", "anchor": "Round__6__Even_Start_Family_Literacy_Program", "level": 2}, {"title": "Round #7: Big Brothers Big Sisters", "anchor": "Round__7__Big_Brothers_Big_Sisters1", "level": 2}, {"title": "Round #8: Top 16 Educational Software", "anchor": "Round__8__Top_16_Educational_Software1", "level": 2}, {"title": "How did you do?", "anchor": "How_did_you_do_", "level": 1}, {"title": "The effects of social interventions are extremely complex. All of these programs sound good, but unintended consequences can get in the way. It\u2019s very difficult to work out what\u2019s going to be successful ahead of time. Instead, we need to test, measure the results, and take it from there.", "anchor": "The_effects_of_social_interventions_are_extremely_complex__All_of_these_programs_sound_good__but_unintended_consequences_can_get_in_the_way__It_s_very_difficult_to_work_out_what_s_going_to_be_successful_ahead_of_time__Instead__we_need_to_test__measure_the_results__and_take_it_from_there_", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "77 comments"}], "headingsCount": 21}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KEcWJSzxFzcYvyLsW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T12:38:22.785Z", "modifiedAt": null, "url": null, "title": "Risk aversion does not explain people's betting behaviours", "slug": "risk-aversion-does-not-explain-people-s-betting-behaviours", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:39.718Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/msf7BHMrWTczbQckh/risk-aversion-does-not-explain-people-s-betting-behaviours", "pageUrlRelative": "/posts/msf7BHMrWTczbQckh/risk-aversion-does-not-explain-people-s-betting-behaviours", "linkUrl": "https://www.lesswrong.com/posts/msf7BHMrWTczbQckh/risk-aversion-does-not-explain-people-s-betting-behaviours", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Risk%20aversion%20does%20not%20explain%20people's%20betting%20behaviours&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARisk%20aversion%20does%20not%20explain%20people's%20betting%20behaviours%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmsf7BHMrWTczbQckh%2Frisk-aversion-does-not-explain-people-s-betting-behaviours%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Risk%20aversion%20does%20not%20explain%20people's%20betting%20behaviours%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmsf7BHMrWTczbQckh%2Frisk-aversion-does-not-explain-people-s-betting-behaviours", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmsf7BHMrWTczbQckh%2Frisk-aversion-does-not-explain-people-s-betting-behaviours", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 733, "htmlBody": "<p>Expected utility maximalisation is an excellent <em>prescriptive</em> decision theory. It has all the <a href=\"http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem#The_axioms\">nice properties</a> that we want and need in a decision theory, and can be argued to be \"the\" ideal decision theory in some senses.</p>\n<p>However, it is completely wrong as a <em>descriptive</em> theory of how humans behave. Those on this list are presumably aware of oddities like the <a href=\"http://en.wikipedia.org/wiki/Allais_paradox\">Allais paradox</a>. But we may retain some notions that expected utility still has some descriptive uses, such as modelling <a href=\"http://en.wikipedia.org/wiki/Risk_aversion\">risk aversion</a>. The story here is simple: each subsequent dollar gives less utility (the utility of money curve is concave), so people would need a premium to accept deals where they have a 50-50 chance of gaining or losing $100.</p>\n<p>As a story or mental image, it's useful to have. As a formal model of human behaviour on small bets, it's spectacularly wrong.&nbsp;Matthew Rabin <a href=\"http://users.nber.org/~rosenbla/econ311/syllabus/rabincallibration.pdf\">showed why</a>. If people are consistently slightly risk averse on small bets and expected utility theory is&nbsp;approximately&nbsp;correct, then they have to be massively, stupidly risk averse on larger bets, in ways that are clearly unrealistic. Put simply, the small bets behaviour forces their utility to become far too concave.</p>\n<p>For illustration, let's introduce <a href=\"http://en.wikipedia.org/wiki/Neville_Chamberlain\">Neville</a>. Neville is risk averse. He will reject a single 50-50 deal where he gains $55 or loses $50.&nbsp;He might accept this deal if he were really rich enough, and felt rich - say if he had $20 000 in capital, he would accept the deal. I hope I'm not painting a completely unbelievable portrait of human behaviour here! And yet expected utility maximalisation then predicts that if&nbsp;Neville had fifteen thousand dollars ($15 000) in capital, he would reject a 50-50 bet that either lost him fifteen hundred dollars ($1 500), or gained him a hundred and fifty thousand dollars ($150 000) - a ratio of a hundred to one between gains and losses!<a id=\"more\"></a></p>\n<p>To see this, first define define the marginal utility at $X dollars (MU($X)) as Neville's utility gain from one extra dollar (in other words,&nbsp;MU($X) =&nbsp;U($(X+1)) - U($X)). Since Neville is risk averse, MU($X)&nbsp;&ge; MU($Y) whenever Y&gt;X. Then we get the following theorem:</p>\n<ul>\n<li>If Neville has $X and rejects a 50-50 deal where he gains $55 or loses $50, then MU($(X+55))&nbsp;&le; (10/11)*MU($(X-50)).</li>\n</ul>\n<p>This theorem is a simple result of the fact that U($(X+55))-U($X) must be greater than 55*MU($(X+55)) (each dollar up from the Xth up to the (X+54)th must have marginal utility at least&nbsp;MU($(X+55))), while&nbsp;U($X)-U($(X-50)) must be less than 50*MU($(X-50)) (each dollar from the (X-50)th up to (X-1)th must have marginal utility at most MU($(X-50))). Since Neville rejects the deal, U($X)&nbsp;&ge; 1/2(U($(X+55)) + U($(X-50)), hence&nbsp;U($(X+55))-U($X) &le;&nbsp;U($X)-U($(X-50)), hence 55*MU($(X+55))&nbsp;&le; 50*MU($(X-50))&nbsp;and the result follows.</p>\n<p>Hence if we scale Neville's utility so that MU($15000)=1, we know that MU($15105)&nbsp;&le;&nbsp;10/11, MU($15210)&nbsp;&le;&nbsp;(10/11)<sup>2</sup>,&nbsp;MU($15315)&nbsp;&le;&nbsp;(10/11)<sup>3</sup>, ... all the way up to to MU($19935) = MU($(15000 + 47*105))&nbsp;&le;&nbsp;(10/11)<sup>47</sup>. Summing the series of MU's from $15000 to $(15000+48*110) = $20040, we can see that</p>\n<ul>\n<li>U($20040) - U($15000)&nbsp;&le; 105*(1+(10/11)+(10/11)<sup>2</sup>+...+(10/11)<sup>47</sup>) = 110*(1-(10/11)<sup>48</sup>)/(1-(10/11))&nbsp;&asymp;&nbsp;1143.</li>\n</ul>\n<p>One immediate result of that is that Neville, on $15000, will reject a 50-50 chance of losing $1144 versus gaining $5000. But it gets much worse! Let's assume that the bet is a 50-50 bet which involves losing $1500 - how far up in the benefits do we need to go before Neville will accept this bet? Now the marginal utilities below $15000 are bounded below, just as those above $15000 are bounded above. So summing the series down to $(15000-1500) = $13500 &gt; $(15000 - 14*105):</p>\n<ul>\n<li>U($15000) - U($13500)&nbsp;&ge; 105*(1+(11/10)+...+(11/10)<sup>13</sup>) = 105*(1-(11/10)<sup>14</sup>)/(1-(11/10))&nbsp;&asymp;&nbsp;2937.</li>\n</ul>\n<p>So gaining $5040 from $15000 will net Neville (at most) 1143 utilons, while losing $1500 will lose him (at least) 2937.&nbsp;The&nbsp;marginal utility for dollars above the&nbsp;20040th is at most&nbsp;(10/11)<sup>47</sup>&nbsp;&lt; 0.012. So we need to add at least (2937-1143-1)/0.012&nbsp;&asymp;&nbsp;149416 extra dollars before Neville would accept the bet. So, as was said,</p>\n<ul>\n<li>If Neville had fifteen thousand dollars ($15 000), he would reject a 50-50 bet that either lost him fifteen hundred dollars ($1 500), or gained him a hundred a fifty thousand dollars ($150 000).</li>\n</ul>\n<p>These bounds are not sharp - the real situation is worse than that. So expected utility maximisation is not a flawed model of human risk aversion on small bets - it's a completely ridiculous model of human risk aversion on small bets. Other variants such as <a href=\"http://en.wikipedia.org/wiki/Prospect_theory\">prospect theory</a> perform a better job at the descriptive task, though as usual in the social sciences, they are flawed as well.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E8PHMuf7tsr8teXAe": 2, "xYLtnJ6keSHGfrLpe": 1, "3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "msf7BHMrWTczbQckh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 19, "extendedScore": null, "score": 4.3e-05, "legacy": true, "legacyId": "18293", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T19:49:29.808Z", "modifiedAt": null, "url": null, "title": "Meetup : Rational-Humanist Open Mic, NYC September 5th", "slug": "meetup-rational-humanist-open-mic-nyc-september-5th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.227Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XFL5SZrSYg8HQA3m4/meetup-rational-humanist-open-mic-nyc-september-5th", "pageUrlRelative": "/posts/XFL5SZrSYg8HQA3m4/meetup-rational-humanist-open-mic-nyc-september-5th", "linkUrl": "https://www.lesswrong.com/posts/XFL5SZrSYg8HQA3m4/meetup-rational-humanist-open-mic-nyc-september-5th", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Rational-Humanist%20Open%20Mic%2C%20NYC%20September%205th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Rational-Humanist%20Open%20Mic%2C%20NYC%20September%205th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXFL5SZrSYg8HQA3m4%2Fmeetup-rational-humanist-open-mic-nyc-september-5th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Rational-Humanist%20Open%20Mic%2C%20NYC%20September%205th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXFL5SZrSYg8HQA3m4%2Fmeetup-rational-humanist-open-mic-nyc-september-5th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXFL5SZrSYg8HQA3m4%2Fmeetup-rational-humanist-open-mic-nyc-september-5th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d2'>Rational-Humanist Open Mic, NYC September 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 September 2012 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">159 E Houston Street, New York, NY 10003</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Last month was the first Open Mind Open Mic, a cultural event co-hosted by the Center for Inquiry. This is your opportunity to share performance art relating to rationality and human progress. Whether you want to perform or just listen, and whether you're experienced or just beginning, you're welcome to attend.</p>\n\n<p>The first event went very successfully, with around 15 skeptics and rationalists showing (approximately an even mix of Less Wrong folk and CFI folk), plus another few people who wandered in from the bar. Including one \"regular performer\" who had been playing a gig upstairs, came down to see what we were about, and turned out to have a pretty awesome self-improvement themed song. It's a good opportunity to introduce rationality memes to wider audience.</p>\n\n<p>We're building towards a larger event towards the end of year, incorporating the most popular performance art that accumulates at the Open Mic events.</p>\n\n<p>The event is held in the basement of the National Underground. Ask the bartender if you're not sure where to go.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d2'>Rational-Humanist Open Mic, NYC September 5th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XFL5SZrSYg8HQA3m4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.685680817041072e-07, "legacy": true, "legacyId": "18361", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Rational_Humanist_Open_Mic__NYC_September_5th\">Discussion article for the meetup : <a href=\"/meetups/d2\">Rational-Humanist Open Mic, NYC September 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 September 2012 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">159 E Houston Street, New York, NY 10003</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Last month was the first Open Mind Open Mic, a cultural event co-hosted by the Center for Inquiry. This is your opportunity to share performance art relating to rationality and human progress. Whether you want to perform or just listen, and whether you're experienced or just beginning, you're welcome to attend.</p>\n\n<p>The first event went very successfully, with around 15 skeptics and rationalists showing (approximately an even mix of Less Wrong folk and CFI folk), plus another few people who wandered in from the bar. Including one \"regular performer\" who had been playing a gig upstairs, came down to see what we were about, and turned out to have a pretty awesome self-improvement themed song. It's a good opportunity to introduce rationality memes to wider audience.</p>\n\n<p>We're building towards a larger event towards the end of year, incorporating the most popular performance art that accumulates at the Open Mic events.</p>\n\n<p>The event is held in the basement of the National Underground. Ask the bartender if you're not sure where to go.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Rational_Humanist_Open_Mic__NYC_September_5th1\">Discussion article for the meetup : <a href=\"/meetups/d2\">Rational-Humanist Open Mic, NYC September 5th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Rational-Humanist Open Mic, NYC September 5th", "anchor": "Discussion_article_for_the_meetup___Rational_Humanist_Open_Mic__NYC_September_5th", "level": 1}, {"title": "Discussion article for the meetup : Rational-Humanist Open Mic, NYC September 5th", "anchor": "Discussion_article_for_the_meetup___Rational_Humanist_Open_Mic__NYC_September_5th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-20T21:59:08.554Z", "modifiedAt": null, "url": null, "title": "Can we teach Rationality at the University of Reddit?", "slug": "can-we-teach-rationality-at-the-university-of-reddit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:09.236Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Lightwave", "createdAt": "2009-03-02T00:10:45.771Z", "isAdmin": false, "displayName": "Lightwave"}, "userId": "wmf7PMjRsYvMAcQHg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qrzSizRWkomktLTFh/can-we-teach-rationality-at-the-university-of-reddit", "pageUrlRelative": "/posts/qrzSizRWkomktLTFh/can-we-teach-rationality-at-the-university-of-reddit", "linkUrl": "https://www.lesswrong.com/posts/qrzSizRWkomktLTFh/can-we-teach-rationality-at-the-university-of-reddit", "postedAtFormatted": "Monday, August 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20we%20teach%20Rationality%20at%20the%20University%20of%20Reddit%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20we%20teach%20Rationality%20at%20the%20University%20of%20Reddit%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrzSizRWkomktLTFh%2Fcan-we-teach-rationality-at-the-university-of-reddit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20we%20teach%20Rationality%20at%20the%20University%20of%20Reddit%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrzSizRWkomktLTFh%2Fcan-we-teach-rationality-at-the-university-of-reddit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrzSizRWkomktLTFh%2Fcan-we-teach-rationality-at-the-university-of-reddit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 122, "htmlBody": "<p><a title=\"University of Reddit\" href=\"http://blog.reddit.com/2012/08/university-of-reddit-explore-any.html\" target=\"_blank\">This was posted a few hours ago</a>. Basically, the reddit admins have decided to promote the so-called \"University of Reddit\", a subreddit where people can offer and teach any course they'd like, or just attend a course. <a title=\"University of Reddit\" href=\"http://ureddit.com/\" target=\"_blank\">This is official website for all courses</a>. At the time of this posting the subreddit had ~38,400 subscribers, but I expect it will grow significantly.<br /><br />Given the reddit demographics, a Rationality course has the potential to become extremely popular. The exposure can popularize CFAR and LessWrong, and can be used to recruit fresh minds for rationality-related causes. Also maybe run experiments with curricula or methods of teaching rationality?<br /><br />What do you guys think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7ow6EFpypbH4hzFuz": 1, "fH8jPjHF2R27sRTTG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qrzSizRWkomktLTFh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 32, "extendedScore": null, "score": 9.68632447084611e-07, "legacy": true, "legacyId": "18362", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T06:54:48.018Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The True Prisoner's Dilemma", "slug": "seq-rerun-the-true-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:16.467Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yG4zngeKcAosQydW6/seq-rerun-the-true-prisoner-s-dilemma", "pageUrlRelative": "/posts/yG4zngeKcAosQydW6/seq-rerun-the-true-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/yG4zngeKcAosQydW6/seq-rerun-the-true-prisoner-s-dilemma", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20True%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20True%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyG4zngeKcAosQydW6%2Fseq-rerun-the-true-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20True%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyG4zngeKcAosQydW6%2Fseq-rerun-the-true-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyG4zngeKcAosQydW6%2Fseq-rerun-the-true-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p>Today's post, <a href=\"/lw/tn/the_true_prisoners_dilemma/\">The True Prisoner's Dilemma</a> was originally published on 03 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#The_True_Prisoner.27s_Dilemma\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The standard visualization for the Prisoner's Dilemma doesn't really work on humans. We can't pretend we're completely selfish.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e5q/seq_rerun_dreams_of_friendliness/\">Dreams of Friendliness</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yG4zngeKcAosQydW6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.688984657248677e-07, "legacy": true, "legacyId": "18376", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HFyWNBnDNEDsDNLrZ", "FwiLvEr7AaW7Lcyhe", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T09:42:35.016Z", "modifiedAt": null, "url": null, "title": "Group rationality diary, 8/20/12", "slug": "group-rationality-diary-8-20-12", "viewCount": null, "lastCommentedAt": "2017-06-17T04:36:51.878Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cata", "createdAt": "2010-06-02T18:13:22.408Z", "isAdmin": false, "displayName": "cata"}, "userId": "X9jdpCokhLjCMZEc3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xLA6hZxviLRBHeaT3/group-rationality-diary-8-20-12", "pageUrlRelative": "/posts/xLA6hZxviLRBHeaT3/group-rationality-diary-8-20-12", "linkUrl": "https://www.lesswrong.com/posts/xLA6hZxviLRBHeaT3/group-rationality-diary-8-20-12", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20rationality%20diary%2C%208%2F20%2F12&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20rationality%20diary%2C%208%2F20%2F12%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLA6hZxviLRBHeaT3%2Fgroup-rationality-diary-8-20-12%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20rationality%20diary%2C%208%2F20%2F12%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLA6hZxviLRBHeaT3%2Fgroup-rationality-diary-8-20-12", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLA6hZxviLRBHeaT3%2Fgroup-rationality-diary-8-20-12", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 194, "htmlBody": "<p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><span style=\"color: #333333;\">This is the public group instrumental rationality diary for the week of August 20th. It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<div id=\"entry_t3_drj\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<ul style=\"padding: 0px; line-height: 19px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Thanks to everyone who contributes!</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\"><a style=\"color: #8a8a8b;\" href=\"/lw/dzy/group_rationality_diary_8612/\">Last week's diary</a>;&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">archive of prior diaries</a>.</p>\n</div>\n</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xLA6hZxviLRBHeaT3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.689814190373046e-07, "legacy": true, "legacyId": "18377", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rYmXpBi4S688aNM7f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T11:08:25.284Z", "modifiedAt": null, "url": null, "title": "r/HPMOR on heroic responsibility", "slug": "r-hpmor-on-heroic-responsibility", "viewCount": null, "lastCommentedAt": "2012-11-23T07:08:14.133Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FTwdYvvAXkscpbDXo/r-hpmor-on-heroic-responsibility", "pageUrlRelative": "/posts/FTwdYvvAXkscpbDXo/r-hpmor-on-heroic-responsibility", "linkUrl": "https://www.lesswrong.com/posts/FTwdYvvAXkscpbDXo/r-hpmor-on-heroic-responsibility", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20r%2FHPMOR%20on%20heroic%20responsibility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Ar%2FHPMOR%20on%20heroic%20responsibility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTwdYvvAXkscpbDXo%2Fr-hpmor-on-heroic-responsibility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=r%2FHPMOR%20on%20heroic%20responsibility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTwdYvvAXkscpbDXo%2Fr-hpmor-on-heroic-responsibility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTwdYvvAXkscpbDXo%2Fr-hpmor-on-heroic-responsibility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 16, "htmlBody": "<p><strong><a href=\"http://www.reddit.com/r/HPMOR/comments/yj2kb/ethical_solipsism_chapter_75/\">r/HPMOR readers on heroic responsibility</a></strong> - not the OP, the comments. &nbsp;Holy snorkels this is good.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NzSTgAtKwgivkfeYm": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FTwdYvvAXkscpbDXo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 14, "extendedScore": null, "score": 3.9e-05, "legacy": true, "legacyId": "18378", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T14:35:59.849Z", "modifiedAt": null, "url": null, "title": "Meetup : Paris Meetup", "slug": "meetup-paris-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:22.537Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eqq8gYoJfAuu7n6T7/meetup-paris-meetup", "pageUrlRelative": "/posts/eqq8gYoJfAuu7n6T7/meetup-paris-meetup", "linkUrl": "https://www.lesswrong.com/posts/eqq8gYoJfAuu7n6T7/meetup-paris-meetup", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Paris%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Paris%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqq8gYoJfAuu7n6T7%2Fmeetup-paris-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Paris%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqq8gYoJfAuu7n6T7%2Fmeetup-paris-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqq8gYoJfAuu7n6T7%2Fmeetup-paris-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 55, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/d3\">Paris Meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">01 September 2012 02:00:00PM (+0200)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Caf&eacute; des Arts et M&eacute;tiers&lrm;, 51 Rue Turbigo, Paris</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The next Paris Meetup will be Sunday, November 13, at the Caf&eacute; des Arts et M&eacute;tiers opposite the Museum.</p>\n<p>At least four people plan on coming, <em>et toi?</em></p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/d3\">Paris Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eqq8gYoJfAuu7n6T7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.691276094626459e-07, "legacy": true, "legacyId": "18380", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Paris_Meetup\">Discussion article for the meetup : <a href=\"/meetups/d3\">Paris Meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">01 September 2012 02:00:00PM (+0200)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Caf\u00e9 des Arts et M\u00e9tiers\u200e, 51 Rue Turbigo, Paris</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The next Paris Meetup will be Sunday, November 13, at the Caf\u00e9 des Arts et M\u00e9tiers opposite the Museum.</p>\n<p>At least four people plan on coming, <em>et toi?</em></p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Paris_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/d3\">Paris Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Paris Meetup", "anchor": "Discussion_article_for_the_meetup___Paris_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Paris Meetup", "anchor": "Discussion_article_for_the_meetup___Paris_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T15:07:36.431Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley meetup: Operant conditioning game", "slug": "meetup-berkeley-meetup-operant-conditioning-game", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.229Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8ip5e6jNGFNYYb87R/meetup-berkeley-meetup-operant-conditioning-game", "pageUrlRelative": "/posts/8ip5e6jNGFNYYb87R/meetup-berkeley-meetup-operant-conditioning-game", "linkUrl": "https://www.lesswrong.com/posts/8ip5e6jNGFNYYb87R/meetup-berkeley-meetup-operant-conditioning-game", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%20meetup%3A%20Operant%20conditioning%20game&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%20meetup%3A%20Operant%20conditioning%20game%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ip5e6jNGFNYYb87R%2Fmeetup-berkeley-meetup-operant-conditioning-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%20meetup%3A%20Operant%20conditioning%20game%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ip5e6jNGFNYYb87R%2Fmeetup-berkeley-meetup-operant-conditioning-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ip5e6jNGFNYYb87R%2Fmeetup-berkeley-meetup-operant-conditioning-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 148, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d4'>Berkeley meetup: Operant conditioning game</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This Wednesday's Berkeley meetup will feature an operant conditioning game. (The game is described here: <a href=\"http://lesswrong.com/lw/e38/meetup_berkeley_meetup_discussion_about_startups/77fy\" rel=\"nofollow\">http://lesswrong.com/lw/e38/meetup_berkeley_meetup_discussion_about_startups/77fy</a> . No actual operant conditioning involved!) It's quite fun. We'll keep playing as long as people are having fun. Optionally, afterward we can talk about how to use operant conditioning in our daily lives. The meetup will be at Zendo. Doors open at 7pm and the game starts at 7:30pm.</p>\n\n<p>The game involves identical \"clicker\" devices. I have five of these, so that's enough for six people to play. If eleven people show up at the meeting, that's still okay, because we can trade off the clickers to maximize total hedonic utility ; )</p>\n\n<p>For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d4'>Berkeley meetup: Operant conditioning game</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8ip5e6jNGFNYYb87R", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 9.691433181047625e-07, "legacy": true, "legacyId": "18381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__Operant_conditioning_game\">Discussion article for the meetup : <a href=\"/meetups/d4\">Berkeley meetup: Operant conditioning game</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This Wednesday's Berkeley meetup will feature an operant conditioning game. (The game is described here: <a href=\"http://lesswrong.com/lw/e38/meetup_berkeley_meetup_discussion_about_startups/77fy\" rel=\"nofollow\">http://lesswrong.com/lw/e38/meetup_berkeley_meetup_discussion_about_startups/77fy</a> . No actual operant conditioning involved!) It's quite fun. We'll keep playing as long as people are having fun. Optionally, afterward we can talk about how to use operant conditioning in our daily lives. The meetup will be at Zendo. Doors open at 7pm and the game starts at 7:30pm.</p>\n\n<p>The game involves identical \"clicker\" devices. I have five of these, so that's enough for six people to play. If eleven people show up at the meeting, that's still okay, because we can trade off the clickers to maximize total hedonic utility ; )</p>\n\n<p>For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__Operant_conditioning_game1\">Discussion article for the meetup : <a href=\"/meetups/d4\">Berkeley meetup: Operant conditioning game</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley meetup: Operant conditioning game", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__Operant_conditioning_game", "level": 1}, {"title": "Discussion article for the meetup : Berkeley meetup: Operant conditioning game", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__Operant_conditioning_game1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T15:57:51.687Z", "modifiedAt": null, "url": null, "title": "Sal Khan publicly predicts the positive feedback loop associated with human intelligence augmentation. [Link]", "slug": "sal-khan-publicly-predicts-the-positive-feedback-loop", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.565Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TylerJay", "createdAt": "2010-08-16T22:37:13.189Z", "isAdmin": false, "displayName": "TylerJay"}, "userId": "rR64xYGdnRFZ5MPQc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9XpqBRdCaqsZdBC75/sal-khan-publicly-predicts-the-positive-feedback-loop", "pageUrlRelative": "/posts/9XpqBRdCaqsZdBC75/sal-khan-publicly-predicts-the-positive-feedback-loop", "linkUrl": "https://www.lesswrong.com/posts/9XpqBRdCaqsZdBC75/sal-khan-publicly-predicts-the-positive-feedback-loop", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sal%20Khan%20publicly%20predicts%20the%20positive%20feedback%20loop%20associated%20with%20human%20intelligence%20augmentation.%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASal%20Khan%20publicly%20predicts%20the%20positive%20feedback%20loop%20associated%20with%20human%20intelligence%20augmentation.%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9XpqBRdCaqsZdBC75%2Fsal-khan-publicly-predicts-the-positive-feedback-loop%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sal%20Khan%20publicly%20predicts%20the%20positive%20feedback%20loop%20associated%20with%20human%20intelligence%20augmentation.%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9XpqBRdCaqsZdBC75%2Fsal-khan-publicly-predicts-the-positive-feedback-loop", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9XpqBRdCaqsZdBC75%2Fsal-khan-publicly-predicts-the-positive-feedback-loop", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.khanacademy.org/science/cosmology-and-astronomy/v/random-predictions-for-2060</p>\n<p>3:35</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9XpqBRdCaqsZdBC75", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 9.691682931907288e-07, "legacy": true, "legacyId": "18383", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T18:52:07.108Z", "modifiedAt": null, "url": null, "title": "Possible meetup: Singapore", "slug": "possible-meetup-singapore", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.554Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ifPot575Xi5ybAGEH/possible-meetup-singapore", "pageUrlRelative": "/posts/ifPot575Xi5ybAGEH/possible-meetup-singapore", "linkUrl": "https://www.lesswrong.com/posts/ifPot575Xi5ybAGEH/possible-meetup-singapore", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Possible%20meetup%3A%20Singapore&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APossible%20meetup%3A%20Singapore%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FifPot575Xi5ybAGEH%2Fpossible-meetup-singapore%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Possible%20meetup%3A%20Singapore%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FifPot575Xi5ybAGEH%2Fpossible-meetup-singapore", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FifPot575Xi5ybAGEH%2Fpossible-meetup-singapore", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 70, "htmlBody": "<p>Are there any Singaporean LW-ers out there? &nbsp;I'll be visiting Singapore for a few days with my husband, <a href=\"/user/CarlShulman\">Carl Shulman</a>, and we'd be keen to either have a short meet-up in a coffee shop somewhere, or to see Singaporean sites while talking to a LWer or two. &nbsp;Please comment or pm me if you're interested. &nbsp;We get in noon this Thursday (tomorrow), and leave the morning of Sunday, the 26th.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ifPot575Xi5ybAGEH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 12, "extendedScore": null, "score": 9.692549033760716e-07, "legacy": true, "legacyId": "18384", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T20:47:56.508Z", "modifiedAt": null, "url": null, "title": "[LINK] Strong AI Startup Raises $15M", "slug": "link-strong-ai-startup-raises-usd15m", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:09.492Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "olalonde", "createdAt": "2012-04-11T13:14:14.883Z", "isAdmin": false, "displayName": "olalonde"}, "userId": "ZHntRMF8vLDsZ55yQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Huzu9MiGykC5oH8Jt/link-strong-ai-startup-raises-usd15m", "pageUrlRelative": "/posts/Huzu9MiGykC5oH8Jt/link-strong-ai-startup-raises-usd15m", "linkUrl": "https://www.lesswrong.com/posts/Huzu9MiGykC5oH8Jt/link-strong-ai-startup-raises-usd15m", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Strong%20AI%20Startup%20Raises%20%2415M&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Strong%20AI%20Startup%20Raises%20%2415M%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHuzu9MiGykC5oH8Jt%2Flink-strong-ai-startup-raises-usd15m%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Strong%20AI%20Startup%20Raises%20%2415M%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHuzu9MiGykC5oH8Jt%2Flink-strong-ai-startup-raises-usd15m", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHuzu9MiGykC5oH8Jt%2Flink-strong-ai-startup-raises-usd15m", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 377, "htmlBody": "<p><a href=\"http://techcrunch.com/2012/08/21/vicarious-good-ventures-funding/\">http://techcrunch.com/2012/08/21/vicarious-good-ventures-funding/</a></p>\n<blockquote>\n<p>Vicarious, a startup that says it&rsquo;s &ldquo;building software that thinks and learns like a human,&rdquo; has just raised a $15 million Series A.</p>\n<p>The round was led by Good Ventures, the investment firm founded by Dustin Moskovitz, who also co-founded Facebook and Asana. (The firm&rsquo;s profits will be donated to the Good Ventures Foundation.) Founders Fund, Open Field Capital, Steve Brown, and Zarco Investment Group participated too.</p>\n<p>Vicarious launched in February 2011 with funding from Founders Fund, Moskovitz, Adam D&rsquo;Angelo (former Facebook CTO and co-founder of Quora), Felicis Ventures, and Palantir co-founder Joe Lonsdale. Since then, co-founder D. Scott Phoenix tells me that the company has been in research mode. The research has resulted in a system that&rsquo;s supposed to interpret the content of photos and videos in a way that&rsquo;s similar to humans, and which is powered by the company&rsquo;s &ldquo;key innovation&rdquo;, the Recursive Cortical Network.</p>\n<p>Ultimately, Phoenix says the technology could be used in &ldquo;almost every industry,&rdquo; including robotics, medical image analysis, and image and video search,. But that&rsquo;s a ways off &mdash; Phoenix and his co-founder Dileep George say they&rsquo;re still deep in research and development, and that the funding will be used to expand those R&amp;D efforts. Developing products that commercialize the technology is still several years off, George says.</p>\n<p>&ldquo;Based on our experiments in the last year, we are very optimistic about our rate of progress,&rdquo; he says. &ldquo;At the same time, this is a very challenging problem. We are not getting too excited about how productize things. We&rsquo;re testing everything very carefully.&rdquo;</p>\n<p>You don&rsquo;t see too many venture-backed software companies spending years on research nowadays, and Phoenix says he was lucky to find investors who share his big vision &mdash; to use AI to &ldquo;help humanity thrive.&rdquo; The investors at Good Ventures and Founders Fund have a &ldquo;natural affinity&rdquo; for that kind of talk (Founders Fund&rsquo;s Peter Thiel, for example, has been pretty vocal about what he sees as a lack of transformative innovation), but Phoenix says it&rsquo;s &ldquo;very different from the language that a lot of other investors speak.&rdquo;</p>\n</blockquote>\n<p><a href=\"http://news.ycombinator.com/item?id=4413568\">Discussion on Hacker News</a></p>\n<p><a href=\"http://news.ycombinator.com/item?id=4413568\"></a>Meta: this is my first post here, let me know if I am doing something wrong or if I shouldn't post this here.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Huzu9MiGykC5oH8Jt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 24, "extendedScore": null, "score": 9.693124781107889e-07, "legacy": true, "legacyId": "18385", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-21T21:35:58.227Z", "modifiedAt": null, "url": null, "title": "[META] Inbox icon behaving unexpectedly", "slug": "meta-inbox-icon-behaving-unexpectedly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.913Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RolfAndreassen", "createdAt": "2009-04-17T19:37:23.246Z", "isAdmin": false, "displayName": "RolfAndreassen"}, "userId": "KLJmn2HYWEu4tBKcC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rpQ7TeFk5ESrFhbLW/meta-inbox-icon-behaving-unexpectedly", "pageUrlRelative": "/posts/rpQ7TeFk5ESrFhbLW/meta-inbox-icon-behaving-unexpectedly", "linkUrl": "https://www.lesswrong.com/posts/rpQ7TeFk5ESrFhbLW/meta-inbox-icon-behaving-unexpectedly", "postedAtFormatted": "Tuesday, August 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMETA%5D%20Inbox%20icon%20behaving%20unexpectedly&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMETA%5D%20Inbox%20icon%20behaving%20unexpectedly%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrpQ7TeFk5ESrFhbLW%2Fmeta-inbox-icon-behaving-unexpectedly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMETA%5D%20Inbox%20icon%20behaving%20unexpectedly%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrpQ7TeFk5ESrFhbLW%2Fmeta-inbox-icon-behaving-unexpectedly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrpQ7TeFk5ESrFhbLW%2Fmeta-inbox-icon-behaving-unexpectedly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p>I just saw the letter icon under my username in orange, indicating that there should be something new in my inbox; but when I went to my inbox there was nothing there I hadn't already read. I wonder if this could be related to the recent trouble with the PM system? I sent a PM the other day and might have gotten a response to it which triggered the colour-the-icon code but not, perchance, the actual display-in-inbox code. Can I get a volunteer to receive a PM from me, or to PM me, and test whether the response shows up in the sender's inbox?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rpQ7TeFk5ESrFhbLW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 9.693363544847615e-07, "legacy": true, "legacyId": "18386", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T05:25:18.833Z", "modifiedAt": null, "url": null, "title": "Four major problems with neuroscience", "slug": "four-major-problems-with-neuroscience", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:09.532Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uHhX2XMTgifFBYGTb/four-major-problems-with-neuroscience", "pageUrlRelative": "/posts/uHhX2XMTgifFBYGTb/four-major-problems-with-neuroscience", "linkUrl": "https://www.lesswrong.com/posts/uHhX2XMTgifFBYGTb/four-major-problems-with-neuroscience", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Four%20major%20problems%20with%20neuroscience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFour%20major%20problems%20with%20neuroscience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHhX2XMTgifFBYGTb%2Ffour-major-problems-with-neuroscience%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Four%20major%20problems%20with%20neuroscience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHhX2XMTgifFBYGTb%2Ffour-major-problems-with-neuroscience", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHhX2XMTgifFBYGTb%2Ffour-major-problems-with-neuroscience", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p>A discussion of <a href=\"http://neurobonkers.com/2012/08/21/the-science-of-bad-neuroscience/\">four errors</a> which lead to false positives-- neglecting maturation (that brains change with time, even without intervention, learning effects (people who take a test more than once get better at it), regression to the mean (people who are unusually good or bad at something will probably have a more average score on subsequent attempts), and the placebo effect.</p>\n<p>The link above is a summary of <a href=\"http://clients2.mediaondemand.net/acamh/09-03-2012/player/default.aspx?eventId=2959\">a lecture</a> which isn't playing for me, so any further information about the lecture would be greatly appreciated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uHhX2XMTgifFBYGTb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 19, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "18394", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T06:16:49.377Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Truly Iterated Prisoner's Dilemma", "slug": "seq-rerun-the-truly-iterated-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:16.402Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cibQDqimmMvgbozdr/seq-rerun-the-truly-iterated-prisoner-s-dilemma", "pageUrlRelative": "/posts/cibQDqimmMvgbozdr/seq-rerun-the-truly-iterated-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/cibQDqimmMvgbozdr/seq-rerun-the-truly-iterated-prisoner-s-dilemma", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Truly%20Iterated%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Truly%20Iterated%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcibQDqimmMvgbozdr%2Fseq-rerun-the-truly-iterated-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Truly%20Iterated%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcibQDqimmMvgbozdr%2Fseq-rerun-the-truly-iterated-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcibQDqimmMvgbozdr%2Fseq-rerun-the-truly-iterated-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>Today's post, <a href=\"/lw/to/the_truly_iterated_prisoners_dilemma/\">The Truly Iterated Prisoner's Dilemma</a> was originally published on 04 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#The_Truly_Iterated_Prisoner.27s_Dilemma\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>According to classic game theory, if you know how many iterations there are going to be in the iterated prisoner's dilemma, then you shouldn't use tit for tat. Does this really seem right?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e6g/seq_rerun_the_true_prisoners_dilemma/\">The True Prisoner's Dilemma</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cibQDqimmMvgbozdr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.69595351499533e-07, "legacy": true, "legacyId": "18402", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jbgjvhszkr3KoehDh", "yG4zngeKcAosQydW6", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T11:49:51.995Z", "modifiedAt": null, "url": null, "title": "AI timeline prediction data", "slug": "ai-timeline-prediction-data", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:08.961Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q6oWinLaKXmGNWGLy/ai-timeline-prediction-data", "pageUrlRelative": "/posts/Q6oWinLaKXmGNWGLy/ai-timeline-prediction-data", "linkUrl": "https://www.lesswrong.com/posts/Q6oWinLaKXmGNWGLy/ai-timeline-prediction-data", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AI%20timeline%20prediction%20data&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAI%20timeline%20prediction%20data%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ6oWinLaKXmGNWGLy%2Fai-timeline-prediction-data%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AI%20timeline%20prediction%20data%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ6oWinLaKXmGNWGLy%2Fai-timeline-prediction-data", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ6oWinLaKXmGNWGLy%2Fai-timeline-prediction-data", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 357, "htmlBody": "<p>The data forming the background of my <a href=\"/lw/e36/ai_timeline_predictions_are_we_getting_better/ \">analysis</a> of AI timeline predictions is now available online. Many thanks to&nbsp;Jonathan Wang and Brian Potter, who gathered the data, to <a href=\"http://kajsotala.fi/\">Kaj Sotala</a>, who analysed and&nbsp;categorised&nbsp;it, and to <a href=\"http://lukeprog.com/\">Luke Muehlhauser</a> and the <a href=\"http://intelligence.org/\">Singularity Institute</a>, who&nbsp;commissioned&nbsp;and paid for it.</p>\n<p>The full data can be found <a href=\"https://www.dropbox.com/s/3rvovix3e0v2pag/SIAI-FHI_AI_predictions.xls?raw=1\">here</a> (this includes my estimates for the \"median date for human level AGI\"). The same data without my median estimates can be found <a href=\"https://www.dropbox.com/s/tko7ji9etmrrl05/SIAI-FHI_AI_predictions_no_median.xls?raw=1\">here</a>.</p>\n<p>I encourage people to produce their own estimate of the \"median date\"! If you do so, you should use the second database (the one without my estimates). And you should decide in advance what kind of criteria you are going to use to compute this median, or whether you are going to reuse my criteria. And finally you should inform me or the world in general of your values, whether they are very similar or very different to mine.</p>\n<p>My criteria were:</p>\n<ul>\n<li>When a range was given, I took the mid-point of that range (rounded down). If a year was given with a 50% likelihood estimate, I took that year. If it was the collection of a variety of expert opinions, I took the prediction of the median expert. If the author predicted some sort of AI by a given date (partial AI or superintelligent AI), and gave no other estimate, I took that date as their estimate rather than trying to correct it in one direction or the other (there were roughly the same number of subhuman AIs as suphuman AIs in the list, and not that many of either). I read extracts of the papers to make judgement calls when interpreting problematic statements like \"within thirty years\" or \"during this century\" (is that a range or an end-date?). I never chose a date other than one actually predicted, or the midpoint of a range.</li>\n</ul>\n<p>Incidentally, you may notice that a certain Stuart Armstrong is included in the list, for a prediction I made back in 2007 (for AI in 2207). Yes, I counted that prediction in my analysis (as a non-expert prediction), and no, I don't stand by that date today.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zHjC29kkPmsdo7WTr": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q6oWinLaKXmGNWGLy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 6.5e-05, "legacy": true, "legacyId": "18405", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["47ci9ixyEbGKWENwR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T14:23:58.382Z", "modifiedAt": null, "url": null, "title": "Heading off a near-term AGI arms race", "slug": "heading-off-a-near-term-agi-arms-race", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:39.418Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lincolnquirk", "createdAt": "2011-03-25T20:46:17.071Z", "isAdmin": false, "displayName": "lincolnquirk"}, "userId": "ScJE7nuW8ti5kzfcA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ADyGe6rMMoCYMTxhg/heading-off-a-near-term-agi-arms-race", "pageUrlRelative": "/posts/ADyGe6rMMoCYMTxhg/heading-off-a-near-term-agi-arms-race", "linkUrl": "https://www.lesswrong.com/posts/ADyGe6rMMoCYMTxhg/heading-off-a-near-term-agi-arms-race", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Heading%20off%20a%20near-term%20AGI%20arms%20race&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHeading%20off%20a%20near-term%20AGI%20arms%20race%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADyGe6rMMoCYMTxhg%2Fheading-off-a-near-term-agi-arms-race%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Heading%20off%20a%20near-term%20AGI%20arms%20race%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADyGe6rMMoCYMTxhg%2Fheading-off-a-near-term-agi-arms-race", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADyGe6rMMoCYMTxhg%2Fheading-off-a-near-term-agi-arms-race", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 261, "htmlBody": "<p>I know people have talked about this in the past, but now seems like an important time for some practical brainstorming here. Hypothetical: the recent $15mm Series A funding of Vicarious by Good Ventures and Founders Fund sets off a wave of $450mm in funded AGI projects of approximately the same scope, over the next ten years. Let's estimate a third of that goes to paying for man-years of actual, low-level, basic AGI capabilities research. That's about 1500 man-years. Anything which can show something resembling progress can easily secure another few hundred man-years to continue making progress.</p>\n<p>Now, if this scenario comes to pass, it seems like one of the worst-case scenarios -- if AGI is possible today, that's a lot of highly incentivized, funded research to make it happen, without strong safety incentives. It seems to depend on VCs realizing the high potential impact of an AGI project, and of the companies having access to good researchers.</p>\n<p>The <a href=\"http://news.ycombinator.com/item?id=4413568\">Hacker News thread</a>&nbsp;suggests that some people (VCs included) probably already realize the high potential impact, without much consideration for safety:</p>\n<blockquote>\n<p>...I think this exactly the sort of innovation timeline real venture capitalists should be considering - funding real R&amp;D that could have a revolutionary impact even if the odds are against it.</p>\n</blockquote>\n<blockquote>\n<p>The company to get all of this right will be the first two trillion dollar company.</p>\n</blockquote>\n<p>Is there any way to reverse this trend in public perception? Is there any way to reduce the number of capable researchers? Are there any other angles of attack for this problem?</p>\n<p>\n<p>I'll admit to being very scared.</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ADyGe6rMMoCYMTxhg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 10, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "18406", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T16:18:30.850Z", "modifiedAt": null, "url": null, "title": "Meetup : Dorset Meetup", "slug": "meetup-dorset-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MayDaniel", "createdAt": "2010-12-30T01:36:27.927Z", "isAdmin": false, "displayName": "danielmamay"}, "userId": "z5ZgxLzThZQ9t4bD9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SNkgpDyyXWA9SCgsN/meetup-dorset-meetup", "pageUrlRelative": "/posts/SNkgpDyyXWA9SCgsN/meetup-dorset-meetup", "linkUrl": "https://www.lesswrong.com/posts/SNkgpDyyXWA9SCgsN/meetup-dorset-meetup", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Dorset%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Dorset%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSNkgpDyyXWA9SCgsN%2Fmeetup-dorset-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Dorset%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSNkgpDyyXWA9SCgsN%2Fmeetup-dorset-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSNkgpDyyXWA9SCgsN%2Fmeetup-dorset-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d5'>Dorset Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 August 2012 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Starbucks Coffee, 4 New Bond St, Weymouth, DT4 8LY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The second Dorset meetup will be 2pm on Wednesday 29th August at Starbucks, Weymouth. (There will be a sign on the table.)</p>\n\n<p>Please leave a comment if you're planning to attend. Hope to see you there!</p>\n\n<p>Join the <a href=\"http://www.facebook.com/groups/LessWrongDorset\" rel=\"nofollow\">Facebook group!</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d5'>Dorset Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SNkgpDyyXWA9SCgsN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 9.698942998937587e-07, "legacy": true, "legacyId": "18408", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Dorset_Meetup\">Discussion article for the meetup : <a href=\"/meetups/d5\">Dorset Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 August 2012 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Starbucks Coffee, 4 New Bond St, Weymouth, DT4 8LY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The second Dorset meetup will be 2pm on Wednesday 29th August at Starbucks, Weymouth. (There will be a sign on the table.)</p>\n\n<p>Please leave a comment if you're planning to attend. Hope to see you there!</p>\n\n<p>Join the <a href=\"http://www.facebook.com/groups/LessWrongDorset\" rel=\"nofollow\">Facebook group!</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Dorset_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/d5\">Dorset Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Dorset Meetup", "anchor": "Discussion_article_for_the_meetup___Dorset_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Dorset Meetup", "anchor": "Discussion_article_for_the_meetup___Dorset_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T18:21:42.067Z", "modifiedAt": null, "url": null, "title": "How to cheat L\u00f6b's Theorem: my second try", "slug": "how-to-cheat-loeb-s-theorem-my-second-try", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:09.117Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benja", "createdAt": "2009-02-27T04:37:47.476Z", "isAdmin": false, "displayName": "Benya"}, "userId": "3vZZP8TBXvozbe5Cv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EqCxSMZoZPmdARCTm/how-to-cheat-loeb-s-theorem-my-second-try", "pageUrlRelative": "/posts/EqCxSMZoZPmdARCTm/how-to-cheat-loeb-s-theorem-my-second-try", "linkUrl": "https://www.lesswrong.com/posts/EqCxSMZoZPmdARCTm/how-to-cheat-loeb-s-theorem-my-second-try", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20cheat%20L%C3%B6b's%20Theorem%3A%20my%20second%20try&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20cheat%20L%C3%B6b's%20Theorem%3A%20my%20second%20try%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEqCxSMZoZPmdARCTm%2Fhow-to-cheat-loeb-s-theorem-my-second-try%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20cheat%20L%C3%B6b's%20Theorem%3A%20my%20second%20try%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEqCxSMZoZPmdARCTm%2Fhow-to-cheat-loeb-s-theorem-my-second-try", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEqCxSMZoZPmdARCTm%2Fhow-to-cheat-loeb-s-theorem-my-second-try", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2862, "htmlBody": "<p>In his <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">open problems talk</a>, Eliezer explains how L&ouml;b's theorem prevents you from having a consistent proof system P with an axiom schema that anything P proves is actually true, and asks how we can then \"build an AI that could completely rewrite itself, without decreasing <em>the amount of trust it had in math</em> every time it executed that self-rewrite\" (18:46).</p>\n<p>Recently, I <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/\">posted</a> about an attempt to apply a general trick for avoiding diagonalization problems to a minimal toy version of this problem. Since then, Wei Dai has posted <a href=\"/r/discussion/lw/e4e/an_angle_of_attack_on_open_problem_1/78jo\">an interesting quining approach to the same toy problem</a>, and Giles had <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/78cv\">a promising idea for doing something similar in a different way</a> and will hopefully do a write-up filling in the details. Unfortunately <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/7858\">my <em>own</em> \"proof\" turned out to be broken</a>.</p>\n<p>I <em>think</em> I've fixed the problem and made the proof more comprehensible and intuitive in the process. (To avoid confusion, note that what I'm proving is slightly different from, though related to, what I did in the previous post.) However, getting the details right seems to be far from trivial, so <strong>I would very much appreciate if people checked my new argument</strong>, and told me that it looks okay / where it goes wrong / where they get lost. Thanks in advance!</p>\n<p>I'll be more explicit about quoting/unquoting than before, which means I'll need to introduce some notation. However, to sustain you through the schlep of preliminaries, I thought I'd start with an informal summary.<a id=\"more\"></a></p>\n<p align=\"center\">*</p>\n<p>L&ouml;b's theorem shows that it's inconsistent to assume BAD := Peano Arithmetic + for each statement C, the axiom \"if 'C' is provable in BAD, then C\". I will extend the language of PA with a constant symbol K, and consider the proof system PPT.2 := Peano Arithmetic + for each statement C, the axiom \"if K&gt;0, and 'C' is provable in PPT.2, then D\", where D is the statement obtained from C by replacing each occurrence of \"K\" by \"K-1\". [PPT.2 is short for for <em>parametric polymorphism trick, version 0.2.</em>] There will also be a variant PPT.3, where C can have a free variable.</p>\n<p>I won't just show that these systems are consistent &mdash; I will show that they are <em>true</em> (i.e., sound), from which consistency follows. Of course, to do so I will have to say what my strange constant K is supposed to mean. I will show that for any natural number n, all axioms of PPT.2 and PPT.3 are true in the standard model of PA if K is interpreted to mean n.</p>\n<p>What's the use? In my toy version of the AI rewrite problem, the AI will accept a rewrite proposed by its unreliable heuristics module if PPT.3 proves that after executing \"K\" rewrites this way, the AI's values will still be preserved. By the above, this implies that <em>any</em> finite number of rewrites will be safe. I will show that my AI will accept <em>itself</em> as a safe rewrite &mdash; exactly what you would <em>not</em> have if you used a hierarchy of proof systems, where PA(n+1) knows that things proven in PA(n) are true, as Eliezer explains in his talk &mdash; which seems to indicate that PPT.3 is not entirely powerless in the direction we want. (I'm <strong>not</strong> saying that this somehow solves the whole problem, though, just that it suggests this might be a place worth looking in.)</p>\n<p>I'll sketch my soundness proof for PPT.2. We proceed by induction. For K=0 (by which I mean that K is interpreted as the number 0), the assertion is trivial, since the axioms of PPT.2 have no content in this case. Suppose PPT.2 is sound for K=n, and let C be a statement provable in PPT.2. By the induction hypothesis, this implies that in the K=n interpretation, C is true. Therefore, for K=(n+1), D is true, where D is the sentence obtained from C by substituting (K-1) for K. This proves the truth of the axiom \"If K&gt;0, and 'C' is provable in PPT.2, then D.\"</p>\n<p align=\"center\">*</p>\n<h4>Preliminaries</h4>\n<p>The object language I'll be talking about is the language of Peano Arithmetic extended by a constant symbol K; PA will refer to Peano Arithmetic in this extended language. As usual, expressions in the object language can be represented <em>in</em> the object language through G&ouml;del numbers.</p>\n<p>I will take the unusual step of also representing them by G&ouml;del numbers <em>in the metalanguage</em>. (Quantifications such as \"For all formulas C, ...\" mean \"For all natural numbers C, if C is the G&ouml;del number of a formula, then ...\".) This allows me to operate on expressions on both the object- and the metalevel through the same computable functions: <em>down(n)</em> takes (the G&ouml;del number of) a formula and replaces each occurrence of \"K\" in that formula by \"K-1\"; <em>repr(n)</em> takes a number and returns the G&ouml;del number of the unary representation of this number; and <em>subst(F,e)</em> replaces all free occurrences of the special variable \"_\" in the expression F by the expression e. I will write <em>repr(EXPR)</em> as <em>&amp;EXPR</em>, and <em>subst(F,e)</em> as <em>F(e)</em> (the only <em>functions</em> I apply to values are the ones I just introduced, so there should be no confusion between substitution and function application).</p>\n<p>When I write \"0=1 implies 7&gt;9\", then this does denotes not a string, but the G&ouml;del number of the expression that formalizes the statement in quotation marks in PA. Quotation marks work like Lisp's backquote, and #[STUFF] is splicing, like Lisp's comma: \"If #[C], then 0=1\" denotes the G&ouml;del number of the expression obtained by splicing the expression denoted by the G&ouml;del number C into the appropriate place. Splicing is often used in combination with <em>repr</em>(.): \"42 &lt; #[&amp;n]\" splices in the unary representation of the number n. When given a program p (in the form of the G&ouml;del number of its source), our toy AI will search for proofs of the statement \"#[&amp;p] is safe for the next K rewrites\".</p>\n<p>I'll write |- for <em>proves</em>, as in PPT.2 |- \"2+2 = 4\". (Unlike in my last post, I'll only need to write PPT.2 or PPT.3 to the left of the |-, so you can consider PPT.2 |- ... and PPT.3 |- ... as one-place predicates.) This can be formalized in the object language. I'll write n |= C, pronounced <em>n models C,</em> for: <em>(the formula represented by the G&ouml;del number) C is true in the standard model of PA, if K is interpreted as the number n</em>. This is metalanguage-only, since the object language has no truth predicate. For both |- and |=, we're only interested in their meaning on closed formulas, i.e., formulas without free variables.</p>\n<p>If n |= C, then C is <em>true</em>. If C is just a variable, that doesn't immediately tell us much, but if n |= \"STUFF\", and STUFF doesn't contain an occurrence of K, then we can conclude that STUFF. (Not all we can say in the metalanguage can be said in the object language, but all that can be said in the object language can be said in the metalanguage, if we fix the meaning of K.) If STUFF <em>does</em> contain K, then we replace every occurrence of K by n, and then conclude <em>that</em>.</p>\n<p>If the quotation contains a splice, as in n |= \"0=1 implies #[D]\", then we have the same problem as with n |= C (although we could conclude that 0=1 implies n |= D). But in one case, we can say more, namely when all splices are of the form #[&amp; STUFF]: this means that what gets spliced in is the unary numeral representing STUFF, and we know which number this numeral denotes, namely STUFF. For example, if n |= \"#[&amp;x] &gt; #[&amp;y]\", then x&gt;y. (It's even true that if C is a closed formula, then 0 |= \"#[&amp;C] &gt;= 0\", so that C &gt;= 0, which looks like a type error&mdash;but recall that formulas are represented by G&ouml;del numbers, even on the metalevel.) Take a moment to convince yourself of all this: it will be important.</p>\n<p>\"STUFF\" and 'STUFF' have the same meaning and can be nested. Splicing works on the innermost level: In \"For all x, PPT.2 |- '0 &lt;= #[&amp;x]'\", what gets spliced in is the value of the <em>object-level</em> variable x, not of some metavariable of the same name.</p>\n<p align=\"center\">*</p>\n<h4>System PPT.2 and its soundness<br /></h4>\n<p>I'll introduce two proof systems, PPT.2 which I sketched in the introduction and PPT.3 which allows formulas with a free variable, because the definition and soundness proof of PPT.2 are simpler and will hopefully help build intuition for PPT.3.</p>\n<p>(1)&nbsp;&nbsp; PPT.2 := PA + for every closed formula C, the axiom \"If K&gt;0, and PPT.2 |- #[&amp;C], then #[down(C)]\".</p>\n<p>This says that if K&gt;0, and PPT.2 proves C, then the proposition obtained from C by replacing K by K-1 is in fact true. We want to show that this claim is correct when K is interpreted to be any particular natural number n.</p>\n<p>We proceed by induction. We know that the axioms of PA are true, so we only need to worry about the additional axioms of PPT.2. For K=0, these axioms are trivial, and so we will assume that soundness has been proven if K is interpreted as n, and show soundness for n+1. Thus, for any C, we need to prove</p>\n<p>(2)&nbsp;&nbsp; n+1 |= \"If K&gt;0, and PPT.2 |- #[&amp;C], then #[down(C)].\"</p>\n<p>As usual in the semantics of first-order logic, this is equivalent to</p>\n<p>(3)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\"), then (n+1 |= \"#[down(C)]\").</p>\n<p>Now \"#[down(C)]\" is just down(C), so this is the same as</p>\n<p>(4)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\"), then (n+1 |= down(C)).</p>\n<p>So, we need to prove (4). To do this, we'll assume the left-hand side</p>\n<p>(5)&nbsp;&nbsp; n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\",</p>\n<p>and try to prove the right-hand side.</p>\n<p>Note that the only place where K appears in the quoted stuff in (5) is at the very beginning. The formula represented by C may very well contain occurrences of K, but what gets spliced in is <em>not</em> the formula C itself, but &amp;C, the unary representation of its G&ouml;del number. Therefore, from (5) it follows that</p>\n<p>(6)&nbsp;&nbsp; n+1 &gt; 0, and PPT.2 |- C.</p>\n<p>Since we already know that PPT.2 is sound for n, and since anything first-order logic concludes from a sound axiom system is itself true, the second half of (6) implies that</p>\n<p>(7)&nbsp;&nbsp; n |= C.</p>\n<p>But this obviously implies that</p>\n<p>(8)&nbsp;&nbsp; n+1 |= down(C),</p>\n<p>as desired, because down(.) replaces K by K-1, and if K is interpreted as n+1, then K-1 is interpreted as n. This completes the proof that PPT.2 is sound.</p>\n<p align=\"center\">*</p>\n<h4>PPT.3 and its soundness</h4>\n<p>A <em>one-parameter formula</em> is a formula which may have \"_\" as a free variable, but no others. Recall that if F is (the G&ouml;del number of) a one-parameter formula, and e is (the G&ouml;del number of) some expression, then F(e) denotes (the G&ouml;del number of) the result of substituting e for \"_\" in F.</p>\n<p>(9)&nbsp;&nbsp; PPT.3 := PA + for every one-parameter formula F, the axiom \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))]\".</p>\n<p>Here, \"#[&amp;F](&amp;x)\" transports F from the metalevel to the object level, and then (when the resulting object-level expression is \"executed\") substitutes the representation of the number x for \"_\". Thus, on the object level, this denotes a closed formula. On the other hand, \"#[down(F('x'))]\" splices in a formula with free variable 'x'.</p>\n<p>Again, the extra axioms are trivially satisfied for K=0, so we suppose that soundness has been shown for K interpreted as n, and we want to show soundness for n+1. We must show that for every one-parameter formula F,</p>\n<p>(10)&nbsp;&nbsp; n+1 |= \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))].\"</p>\n<p>Now we use that we're only interested in the <em>standard</em> model of PA, where every possible value of x can be written explicitly as a unary numeral. Thus, if we want to prove that a statement of the form \"For all x: STUFF\" is true in this model, i.e. that n+1 |= \"For all x: STUFF\", then it suffices to prove that for every natural number m, n+1 |= C, where C is obtained from STUFF by replacing each free occurrence of 'x' by the unary numeral &amp;m.</p>\n<p>There is one place where we've written 'x' explicitly in our formula, namely the \"...(&amp;x)\" part, and then there are the places 'x' gets substituted into, in the down(F('x')) part. To replace the first occurrence, we can just splice in the numeral &amp;n, i.e. write #[&amp;n] instead of x. Replacing the other occurrences is even simpler: we need only replace F('x') by F(&amp;n). Thus, what we must prove is that for every natural number m,</p>\n<p>(11)&nbsp;&nbsp; n+1 |= \"If K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m]), then #[down(F(&amp;m))].\"</p>\n<p>Take heart, dear reader: this is the worst that the line noise is going to get in this post.</p>\n<p>To prove (11), it suffices to prove</p>\n<p>(12)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m])\"), then (n+1 |= down(F(&amp;m))).</p>\n<p>We assume that the left-hand side is true, i.e., that</p>\n<p>(13)&nbsp;&nbsp; n+1 |= \"K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m])\",</p>\n<p>and try to prove the right-hand side.</p>\n<p>The only place where K occurs in (13) is right at the beginning, so it follows from (13) that</p>\n<p>(14)&nbsp;&nbsp; n+1 &gt; 0, and PPT.3 |- F(&amp;m).</p>\n<p>Here, we use that as noted in the Preliminaries, when using n+1 |= \"STUFF\" to conclude STUFF, we can just replace splices #[&amp; EXPR] by EXPR.</p>\n<p>By the induction hypothesis, we know that PPT.3 is sound for n, so the second half of (14) implies</p>\n<p>(15)&nbsp;&nbsp; n |= F(&amp;m).</p>\n<p>But as in the soundness proof for PPT.2, it's obvious that this implies</p>\n<p>(16)&nbsp;&nbsp; n+1 |= down(F(&amp;m)).</p>\n<p>This completes the soundness proof for PPT.3.</p>\n<p align=\"center\">*</p>\n<h4>A toy AI</h4>\n<p>Now would be a good time to read the beginning of <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/\">my previous post</a>, if you haven't already, which introduces the toy problem I consider here. You should have read the first two sections and the first paragraph of the third section, which gives the definition of \"p is safe for n steps\".</p>\n<p>Define AI_PPT.3 by</p>\n<pre>def AI_PPT.3(p):\n&nbsp;&nbsp;&nbsp;&nbsp;Look at the first 3^^^3 theorems of PPT.3.\n&nbsp;&nbsp;&nbsp;&nbsp;if (one of them is \"#[&amp;p] is safe for K steps\"):\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;double down\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;take winnings<br /></pre>\n<p>It's immediate from the definition that if AI_PPT.3 doubles down on a program p, then</p>\n<p>(17)&nbsp;&nbsp; PPT.3 |- \"#[&amp;p] is safe for K steps\".</p>\n<p>By soundness of PPT.3, it then follows that for every n, we have</p>\n<p>(18)&nbsp;&nbsp; n |= \"#[&amp;p] is safe for K steps\",</p>\n<p>which implies</p>\n<p>(19)&nbsp;&nbsp; p is safe for n steps.</p>\n<p>Since this holds for every n, we've shown that AI_PPT.3 only doubles down on safe programs, and is therefore safe.</p>\n<p align=\"center\">*</p>\n<p>The reasoning leading to (17) can be formalized in PPT.3, without requiring a gigantonormous number of proof steps, because the argument doesn't need to do things like simulate AI_PPT.3 for the whole 3^^^3 cycles. Let's write <em>PPT.3 quickly proves C</em> if C appears near the beginning of the list of the first 3^^^3 theorems of PPT.3. Then we have</p>\n<p>(20)&nbsp;&nbsp; PPT.3 quickly proves, \"For all programs p: If AI_PPT.3 doubles down on p, then PPT.3 |- '#[&amp;p] is safe for K steps'.\"</p>\n<p>Now, we'll show in a moment that</p>\n<p>(21)&nbsp;&nbsp; PPT.3 quickly proves \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then x is safe for K-1 steps.\"</p>\n<p>From (20) and (21), we get</p>\n<p>(22)&nbsp;&nbsp; PPT.3 quickly proves, \"For all programs p: If AI_PPT.3 doubles down on p, and K&gt;0, then p is safe for K-1 steps.\"</p>\n<p>Now it's clear from the definition of \"safe for n steps\" that</p>\n<p>(23)&nbsp;&nbsp; PPT.3 quickly proves, \"AI_PPT.3 is safe for K steps\"</p>\n<p>&mdash;and this shows that AI_PPT.3 doubles down on itself, as claimed. All that remains is to show (21).</p>\n<p align=\"center\">*</p>\n<p>Recall that for every one-parameter formula F, PPT.3 contains the axiom, \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))]\".</p>\n<p>We set F = \"_ is safe for K steps\". The corresponding axiom is,</p>\n<p>(24) \"For all x: If K&gt;0, and PPT.3 |- #[&amp; '_ is safe for K steps'](&amp;x), then #[down('_ is safe for K steps'('x'))].\"</p>\n<p>Now, \"#[&amp; 'STUFF']\" is just \"STUFF\", so (25) is the same formula (i.e., the same G&ouml;del number) as</p>\n<p>(25) \"For all x: If K&gt;0, and PPT.3 |- '_ is safe for K steps'(&amp;x), then #[down('_ is safe for K steps'('x'))].\"</p>\n<p>Since the expression '_ is safe for K steps'('x') lives on the metalevel, we can do that computation and find that (25) is the same formula as</p>\n<p>(26) \"For all x: If K&gt;0, and PPT.3 |- '_ is safe for K steps'(&amp;x), then #[down('x is safe for K steps')].\"</p>\n<p>On the other hand, the '_ is safe for K steps'(&amp;x) part lives on the object level, so if we replace it by '#[&amp;x] is safe for K steps', we'll get a different formula (different G&ouml;del number) that (25). However, by a trivial computation, these denote the same G&ouml;del number on the object level, which means that PPT.3 quickly proves</p>\n<p>(27) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then #[down('x is safe for K steps')].\"</p>\n<p>The down(...) part lives on the metalevel, so by computation, (27) is the same formula as</p>\n<p>(28) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then #['x is safe for K-1 steps']\",</p>\n<p>which, in turn, is just syntax for</p>\n<p>(29) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then x is safe for K-1 steps.\"</p>\n<p>Thus, we've shown that PPT.3 quickly proves (29), as (21) asserted.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EqCxSMZoZPmdARCTm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 21, "extendedScore": null, "score": 9.699560055682856e-07, "legacy": true, "legacyId": "18343", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In his <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">open problems talk</a>, Eliezer explains how L\u00f6b's theorem prevents you from having a consistent proof system P with an axiom schema that anything P proves is actually true, and asks how we can then \"build an AI that could completely rewrite itself, without decreasing <em>the amount of trust it had in math</em> every time it executed that self-rewrite\" (18:46).</p>\n<p>Recently, I <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/\">posted</a> about an attempt to apply a general trick for avoiding diagonalization problems to a minimal toy version of this problem. Since then, Wei Dai has posted <a href=\"/r/discussion/lw/e4e/an_angle_of_attack_on_open_problem_1/78jo\">an interesting quining approach to the same toy problem</a>, and Giles had <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/78cv\">a promising idea for doing something similar in a different way</a> and will hopefully do a write-up filling in the details. Unfortunately <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/7858\">my <em>own</em> \"proof\" turned out to be broken</a>.</p>\n<p>I <em>think</em> I've fixed the problem and made the proof more comprehensible and intuitive in the process. (To avoid confusion, note that what I'm proving is slightly different from, though related to, what I did in the previous post.) However, getting the details right seems to be far from trivial, so <strong>I would very much appreciate if people checked my new argument</strong>, and told me that it looks okay / where it goes wrong / where they get lost. Thanks in advance!</p>\n<p>I'll be more explicit about quoting/unquoting than before, which means I'll need to introduce some notation. However, to sustain you through the schlep of preliminaries, I thought I'd start with an informal summary.<a id=\"more\"></a></p>\n<p align=\"center\">*</p>\n<p>L\u00f6b's theorem shows that it's inconsistent to assume BAD := Peano Arithmetic + for each statement C, the axiom \"if 'C' is provable in BAD, then C\". I will extend the language of PA with a constant symbol K, and consider the proof system PPT.2 := Peano Arithmetic + for each statement C, the axiom \"if K&gt;0, and 'C' is provable in PPT.2, then D\", where D is the statement obtained from C by replacing each occurrence of \"K\" by \"K-1\". [PPT.2 is short for for <em>parametric polymorphism trick, version 0.2.</em>] There will also be a variant PPT.3, where C can have a free variable.</p>\n<p>I won't just show that these systems are consistent \u2014 I will show that they are <em>true</em> (i.e., sound), from which consistency follows. Of course, to do so I will have to say what my strange constant K is supposed to mean. I will show that for any natural number n, all axioms of PPT.2 and PPT.3 are true in the standard model of PA if K is interpreted to mean n.</p>\n<p>What's the use? In my toy version of the AI rewrite problem, the AI will accept a rewrite proposed by its unreliable heuristics module if PPT.3 proves that after executing \"K\" rewrites this way, the AI's values will still be preserved. By the above, this implies that <em>any</em> finite number of rewrites will be safe. I will show that my AI will accept <em>itself</em> as a safe rewrite \u2014 exactly what you would <em>not</em> have if you used a hierarchy of proof systems, where PA(n+1) knows that things proven in PA(n) are true, as Eliezer explains in his talk \u2014 which seems to indicate that PPT.3 is not entirely powerless in the direction we want. (I'm <strong>not</strong> saying that this somehow solves the whole problem, though, just that it suggests this might be a place worth looking in.)</p>\n<p>I'll sketch my soundness proof for PPT.2. We proceed by induction. For K=0 (by which I mean that K is interpreted as the number 0), the assertion is trivial, since the axioms of PPT.2 have no content in this case. Suppose PPT.2 is sound for K=n, and let C be a statement provable in PPT.2. By the induction hypothesis, this implies that in the K=n interpretation, C is true. Therefore, for K=(n+1), D is true, where D is the sentence obtained from C by substituting (K-1) for K. This proves the truth of the axiom \"If K&gt;0, and 'C' is provable in PPT.2, then D.\"</p>\n<p align=\"center\">*</p>\n<h4 id=\"Preliminaries\">Preliminaries</h4>\n<p>The object language I'll be talking about is the language of Peano Arithmetic extended by a constant symbol K; PA will refer to Peano Arithmetic in this extended language. As usual, expressions in the object language can be represented <em>in</em> the object language through G\u00f6del numbers.</p>\n<p>I will take the unusual step of also representing them by G\u00f6del numbers <em>in the metalanguage</em>. (Quantifications such as \"For all formulas C, ...\" mean \"For all natural numbers C, if C is the G\u00f6del number of a formula, then ...\".) This allows me to operate on expressions on both the object- and the metalevel through the same computable functions: <em>down(n)</em> takes (the G\u00f6del number of) a formula and replaces each occurrence of \"K\" in that formula by \"K-1\"; <em>repr(n)</em> takes a number and returns the G\u00f6del number of the unary representation of this number; and <em>subst(F,e)</em> replaces all free occurrences of the special variable \"_\" in the expression F by the expression e. I will write <em>repr(EXPR)</em> as <em>&amp;EXPR</em>, and <em>subst(F,e)</em> as <em>F(e)</em> (the only <em>functions</em> I apply to values are the ones I just introduced, so there should be no confusion between substitution and function application).</p>\n<p>When I write \"0=1 implies 7&gt;9\", then this does denotes not a string, but the G\u00f6del number of the expression that formalizes the statement in quotation marks in PA. Quotation marks work like Lisp's backquote, and #[STUFF] is splicing, like Lisp's comma: \"If #[C], then 0=1\" denotes the G\u00f6del number of the expression obtained by splicing the expression denoted by the G\u00f6del number C into the appropriate place. Splicing is often used in combination with <em>repr</em>(.): \"42 &lt; #[&amp;n]\" splices in the unary representation of the number n. When given a program p (in the form of the G\u00f6del number of its source), our toy AI will search for proofs of the statement \"#[&amp;p] is safe for the next K rewrites\".</p>\n<p>I'll write |- for <em>proves</em>, as in PPT.2 |- \"2+2 = 4\". (Unlike in my last post, I'll only need to write PPT.2 or PPT.3 to the left of the |-, so you can consider PPT.2 |- ... and PPT.3 |- ... as one-place predicates.) This can be formalized in the object language. I'll write n |= C, pronounced <em>n models C,</em> for: <em>(the formula represented by the G\u00f6del number) C is true in the standard model of PA, if K is interpreted as the number n</em>. This is metalanguage-only, since the object language has no truth predicate. For both |- and |=, we're only interested in their meaning on closed formulas, i.e., formulas without free variables.</p>\n<p>If n |= C, then C is <em>true</em>. If C is just a variable, that doesn't immediately tell us much, but if n |= \"STUFF\", and STUFF doesn't contain an occurrence of K, then we can conclude that STUFF. (Not all we can say in the metalanguage can be said in the object language, but all that can be said in the object language can be said in the metalanguage, if we fix the meaning of K.) If STUFF <em>does</em> contain K, then we replace every occurrence of K by n, and then conclude <em>that</em>.</p>\n<p>If the quotation contains a splice, as in n |= \"0=1 implies #[D]\", then we have the same problem as with n |= C (although we could conclude that 0=1 implies n |= D). But in one case, we can say more, namely when all splices are of the form #[&amp; STUFF]: this means that what gets spliced in is the unary numeral representing STUFF, and we know which number this numeral denotes, namely STUFF. For example, if n |= \"#[&amp;x] &gt; #[&amp;y]\", then x&gt;y. (It's even true that if C is a closed formula, then 0 |= \"#[&amp;C] &gt;= 0\", so that C &gt;= 0, which looks like a type error\u2014but recall that formulas are represented by G\u00f6del numbers, even on the metalevel.) Take a moment to convince yourself of all this: it will be important.</p>\n<p>\"STUFF\" and 'STUFF' have the same meaning and can be nested. Splicing works on the innermost level: In \"For all x, PPT.2 |- '0 &lt;= #[&amp;x]'\", what gets spliced in is the value of the <em>object-level</em> variable x, not of some metavariable of the same name.</p>\n<p align=\"center\">*</p>\n<h4 id=\"System_PPT_2_and_its_soundness\">System PPT.2 and its soundness<br></h4>\n<p>I'll introduce two proof systems, PPT.2 which I sketched in the introduction and PPT.3 which allows formulas with a free variable, because the definition and soundness proof of PPT.2 are simpler and will hopefully help build intuition for PPT.3.</p>\n<p>(1)&nbsp;&nbsp; PPT.2 := PA + for every closed formula C, the axiom \"If K&gt;0, and PPT.2 |- #[&amp;C], then #[down(C)]\".</p>\n<p>This says that if K&gt;0, and PPT.2 proves C, then the proposition obtained from C by replacing K by K-1 is in fact true. We want to show that this claim is correct when K is interpreted to be any particular natural number n.</p>\n<p>We proceed by induction. We know that the axioms of PA are true, so we only need to worry about the additional axioms of PPT.2. For K=0, these axioms are trivial, and so we will assume that soundness has been proven if K is interpreted as n, and show soundness for n+1. Thus, for any C, we need to prove</p>\n<p>(2)&nbsp;&nbsp; n+1 |= \"If K&gt;0, and PPT.2 |- #[&amp;C], then #[down(C)].\"</p>\n<p>As usual in the semantics of first-order logic, this is equivalent to</p>\n<p>(3)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\"), then (n+1 |= \"#[down(C)]\").</p>\n<p>Now \"#[down(C)]\" is just down(C), so this is the same as</p>\n<p>(4)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\"), then (n+1 |= down(C)).</p>\n<p>So, we need to prove (4). To do this, we'll assume the left-hand side</p>\n<p>(5)&nbsp;&nbsp; n+1 |= \"K&gt;0, and PPT.2 |- #[&amp;C]\",</p>\n<p>and try to prove the right-hand side.</p>\n<p>Note that the only place where K appears in the quoted stuff in (5) is at the very beginning. The formula represented by C may very well contain occurrences of K, but what gets spliced in is <em>not</em> the formula C itself, but &amp;C, the unary representation of its G\u00f6del number. Therefore, from (5) it follows that</p>\n<p>(6)&nbsp;&nbsp; n+1 &gt; 0, and PPT.2 |- C.</p>\n<p>Since we already know that PPT.2 is sound for n, and since anything first-order logic concludes from a sound axiom system is itself true, the second half of (6) implies that</p>\n<p>(7)&nbsp;&nbsp; n |= C.</p>\n<p>But this obviously implies that</p>\n<p>(8)&nbsp;&nbsp; n+1 |= down(C),</p>\n<p>as desired, because down(.) replaces K by K-1, and if K is interpreted as n+1, then K-1 is interpreted as n. This completes the proof that PPT.2 is sound.</p>\n<p align=\"center\">*</p>\n<h4 id=\"PPT_3_and_its_soundness\">PPT.3 and its soundness</h4>\n<p>A <em>one-parameter formula</em> is a formula which may have \"_\" as a free variable, but no others. Recall that if F is (the G\u00f6del number of) a one-parameter formula, and e is (the G\u00f6del number of) some expression, then F(e) denotes (the G\u00f6del number of) the result of substituting e for \"_\" in F.</p>\n<p>(9)&nbsp;&nbsp; PPT.3 := PA + for every one-parameter formula F, the axiom \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))]\".</p>\n<p>Here, \"#[&amp;F](&amp;x)\" transports F from the metalevel to the object level, and then (when the resulting object-level expression is \"executed\") substitutes the representation of the number x for \"_\". Thus, on the object level, this denotes a closed formula. On the other hand, \"#[down(F('x'))]\" splices in a formula with free variable 'x'.</p>\n<p>Again, the extra axioms are trivially satisfied for K=0, so we suppose that soundness has been shown for K interpreted as n, and we want to show soundness for n+1. We must show that for every one-parameter formula F,</p>\n<p>(10)&nbsp;&nbsp; n+1 |= \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))].\"</p>\n<p>Now we use that we're only interested in the <em>standard</em> model of PA, where every possible value of x can be written explicitly as a unary numeral. Thus, if we want to prove that a statement of the form \"For all x: STUFF\" is true in this model, i.e. that n+1 |= \"For all x: STUFF\", then it suffices to prove that for every natural number m, n+1 |= C, where C is obtained from STUFF by replacing each free occurrence of 'x' by the unary numeral &amp;m.</p>\n<p>There is one place where we've written 'x' explicitly in our formula, namely the \"...(&amp;x)\" part, and then there are the places 'x' gets substituted into, in the down(F('x')) part. To replace the first occurrence, we can just splice in the numeral &amp;n, i.e. write #[&amp;n] instead of x. Replacing the other occurrences is even simpler: we need only replace F('x') by F(&amp;n). Thus, what we must prove is that for every natural number m,</p>\n<p>(11)&nbsp;&nbsp; n+1 |= \"If K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m]), then #[down(F(&amp;m))].\"</p>\n<p>Take heart, dear reader: this is the worst that the line noise is going to get in this post.</p>\n<p>To prove (11), it suffices to prove</p>\n<p>(12)&nbsp;&nbsp; If (n+1 |= \"K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m])\"), then (n+1 |= down(F(&amp;m))).</p>\n<p>We assume that the left-hand side is true, i.e., that</p>\n<p>(13)&nbsp;&nbsp; n+1 |= \"K&gt;0, and PPT.3 |- #[&amp;F](&amp; #[&amp;m])\",</p>\n<p>and try to prove the right-hand side.</p>\n<p>The only place where K occurs in (13) is right at the beginning, so it follows from (13) that</p>\n<p>(14)&nbsp;&nbsp; n+1 &gt; 0, and PPT.3 |- F(&amp;m).</p>\n<p>Here, we use that as noted in the Preliminaries, when using n+1 |= \"STUFF\" to conclude STUFF, we can just replace splices #[&amp; EXPR] by EXPR.</p>\n<p>By the induction hypothesis, we know that PPT.3 is sound for n, so the second half of (14) implies</p>\n<p>(15)&nbsp;&nbsp; n |= F(&amp;m).</p>\n<p>But as in the soundness proof for PPT.2, it's obvious that this implies</p>\n<p>(16)&nbsp;&nbsp; n+1 |= down(F(&amp;m)).</p>\n<p>This completes the soundness proof for PPT.3.</p>\n<p align=\"center\">*</p>\n<h4 id=\"A_toy_AI\">A toy AI</h4>\n<p>Now would be a good time to read the beginning of <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/\">my previous post</a>, if you haven't already, which introduces the toy problem I consider here. You should have read the first two sections and the first paragraph of the third section, which gives the definition of \"p is safe for n steps\".</p>\n<p>Define AI_PPT.3 by</p>\n<pre>def AI_PPT.3(p):\n&nbsp;&nbsp;&nbsp;&nbsp;Look at the first 3^^^3 theorems of PPT.3.\n&nbsp;&nbsp;&nbsp;&nbsp;if (one of them is \"#[&amp;p] is safe for K steps\"):\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;double down\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;take winnings<br></pre>\n<p>It's immediate from the definition that if AI_PPT.3 doubles down on a program p, then</p>\n<p>(17)&nbsp;&nbsp; PPT.3 |- \"#[&amp;p] is safe for K steps\".</p>\n<p>By soundness of PPT.3, it then follows that for every n, we have</p>\n<p>(18)&nbsp;&nbsp; n |= \"#[&amp;p] is safe for K steps\",</p>\n<p>which implies</p>\n<p>(19)&nbsp;&nbsp; p is safe for n steps.</p>\n<p>Since this holds for every n, we've shown that AI_PPT.3 only doubles down on safe programs, and is therefore safe.</p>\n<p align=\"center\">*</p>\n<p>The reasoning leading to (17) can be formalized in PPT.3, without requiring a gigantonormous number of proof steps, because the argument doesn't need to do things like simulate AI_PPT.3 for the whole 3^^^3 cycles. Let's write <em>PPT.3 quickly proves C</em> if C appears near the beginning of the list of the first 3^^^3 theorems of PPT.3. Then we have</p>\n<p>(20)&nbsp;&nbsp; PPT.3 quickly proves, \"For all programs p: If AI_PPT.3 doubles down on p, then PPT.3 |- '#[&amp;p] is safe for K steps'.\"</p>\n<p>Now, we'll show in a moment that</p>\n<p>(21)&nbsp;&nbsp; PPT.3 quickly proves \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then x is safe for K-1 steps.\"</p>\n<p>From (20) and (21), we get</p>\n<p>(22)&nbsp;&nbsp; PPT.3 quickly proves, \"For all programs p: If AI_PPT.3 doubles down on p, and K&gt;0, then p is safe for K-1 steps.\"</p>\n<p>Now it's clear from the definition of \"safe for n steps\" that</p>\n<p>(23)&nbsp;&nbsp; PPT.3 quickly proves, \"AI_PPT.3 is safe for K steps\"</p>\n<p>\u2014and this shows that AI_PPT.3 doubles down on itself, as claimed. All that remains is to show (21).</p>\n<p align=\"center\">*</p>\n<p>Recall that for every one-parameter formula F, PPT.3 contains the axiom, \"For all x: If K&gt;0, and PPT.3 |- #[&amp;F](&amp;x), then #[down(F('x'))]\".</p>\n<p>We set F = \"_ is safe for K steps\". The corresponding axiom is,</p>\n<p>(24) \"For all x: If K&gt;0, and PPT.3 |- #[&amp; '_ is safe for K steps'](&amp;x), then #[down('_ is safe for K steps'('x'))].\"</p>\n<p>Now, \"#[&amp; 'STUFF']\" is just \"STUFF\", so (25) is the same formula (i.e., the same G\u00f6del number) as</p>\n<p>(25) \"For all x: If K&gt;0, and PPT.3 |- '_ is safe for K steps'(&amp;x), then #[down('_ is safe for K steps'('x'))].\"</p>\n<p>Since the expression '_ is safe for K steps'('x') lives on the metalevel, we can do that computation and find that (25) is the same formula as</p>\n<p>(26) \"For all x: If K&gt;0, and PPT.3 |- '_ is safe for K steps'(&amp;x), then #[down('x is safe for K steps')].\"</p>\n<p>On the other hand, the '_ is safe for K steps'(&amp;x) part lives on the object level, so if we replace it by '#[&amp;x] is safe for K steps', we'll get a different formula (different G\u00f6del number) that (25). However, by a trivial computation, these denote the same G\u00f6del number on the object level, which means that PPT.3 quickly proves</p>\n<p>(27) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then #[down('x is safe for K steps')].\"</p>\n<p>The down(...) part lives on the metalevel, so by computation, (27) is the same formula as</p>\n<p>(28) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then #['x is safe for K-1 steps']\",</p>\n<p>which, in turn, is just syntax for</p>\n<p>(29) \"For all x: If K&gt;0, and PPT.3 |- '#[&amp;x] is safe for K steps', then x is safe for K-1 steps.\"</p>\n<p>Thus, we've shown that PPT.3 quickly proves (29), as (21) asserted.</p>", "sections": [{"title": "Preliminaries", "anchor": "Preliminaries", "level": 1}, {"title": "System PPT.2 and its soundness", "anchor": "System_PPT_2_and_its_soundness", "level": 1}, {"title": "PPT.3 and its soundness", "anchor": "PPT_3_and_its_soundness", "level": 1}, {"title": "A toy AI", "anchor": "A_toy_AI", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "26 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DDJr5fuR5jeD47k9g"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-22T20:19:27.471Z", "modifiedAt": null, "url": null, "title": "Let's Talk About Intelligence", "slug": "let-s-talk-about-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:22.949Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Crystalist", "createdAt": "2012-08-03T09:14:54.158Z", "isAdmin": false, "displayName": "Crystalist"}, "userId": "fmFNZemrwWrtGNfv3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AGjoeTXgRLMMLoRqq/let-s-talk-about-intelligence", "pageUrlRelative": "/posts/AGjoeTXgRLMMLoRqq/let-s-talk-about-intelligence", "linkUrl": "https://www.lesswrong.com/posts/AGjoeTXgRLMMLoRqq/let-s-talk-about-intelligence", "postedAtFormatted": "Wednesday, August 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Let's%20Talk%20About%20Intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALet's%20Talk%20About%20Intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGjoeTXgRLMMLoRqq%2Flet-s-talk-about-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Let's%20Talk%20About%20Intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGjoeTXgRLMMLoRqq%2Flet-s-talk-about-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGjoeTXgRLMMLoRqq%2Flet-s-talk-about-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 865, "htmlBody": "<p>I'm writing this because, for a while, I have noticed that I am confused: particularly about what people mean when they say someone is intelligent. I'm more interested in a discussion here than actually making a formal case, so please excuse my lack of actual citations. I'm also trying to articulate my own confusion to myself as well as everyone else, so this will not be as focused as it could be.</p>\n<p>If I had to point to a starting point for this state, I'd say it was in psych class, where we talked about research presented by Eyesenck and Gladwell. Eyesenck is very clear to define intelligence as the ability to solve abstract problems, but not necessarily the motivation . In many ways, this matches Yudkowsky's definition, where he talks about intelligence as a property we can ascribe to an entity, which lets us predict that the entity will be able to complete a task, without ourselves necessarily understanding the steps toward completion.</p>\n<p>The central theme I'm confused about is the generality of the concept: are we really saying that there is a general algorithm or class of algorithms that will solve most or all problems to within a given distance from optimum?</p>\n<p>Let me give an example. Depending on what test you use, an autistic can look clinically retarded, but with 'islands' of remarkable ability, even up to genius levels. The classic example is &ldquo;Rain Man,&rdquo; who is depicted as easily solving numerical problems most people don't even understand, but having trouble tying his shoes. This is usually an exaggeration (by no means are all autistics savants), and these island skills are hardly limited to math. The interesting point, though, is that even someone with many such islands can have an abysmally low overall IQ.</p>\n<p>Some tests correct for this &ndash; Raven's Pattern matching test, for instance, gives you increasingly complex patterns that you have to complete &ndash; and this tends to level out those islands, and give an overall score that seems commensurate with the sheer genius that can be found in some areas.</p>\n<p>What I find confusing is why we're correcting this at all. Certainly, we know that some people, given a task, can complete that task, and of course, depending on the person, this task can be unfathomably complex. But do we really have the evidence to say that, in general, this task does not depend on the person as well? Or, more specifically, on the algorithms they're running? Is it reasonable to say that a person runs an algorithm that will solve all problems within an efficiency x (with respect to processing time and optimality of the solution)? Or should we be looking closer for islands in neurological baselines as well?</p>\n<p>Certainly, we could change the question and ask how efficient are all the algorithms the person is running, and from that, we could give an average efficiency, which might serve as a decent rough estimate for the efficiency with which a person will solve a problem. And for some uses, this is exactly the information we're looking for, and that's fine. But, as a general property of the people we're studying, it seems like the measure is insufficient.</p>\n<p>If we're trying to predict specific behavior, it seems like it would be useful to be aware of whatever 'islands' exist &ndash; for instance, the common separation between algebraic and geometric approaches to math. In my experience, using geometric explanations to someone with an algebraic approach may not be at all successful, but this is not predictive of what we might think of as the person's a priori probability of solving the problem: occasionally they seem to solve the problem with no more than a few algebraic hints. Of course, this is hardly hard evidence, but I think it points to what I'm getting at.</p>\n<p>Looking at the specific algorithm that's being used (or perhaps, the class of algorithm?) can be considerably more predictive of the outcome. Actually, I can't really say that, either: looking at <em>what could be a distinct algorithm</em> can be considerably more predictive of the outcome. There are numerous explanations for these observations, one of which is of course that these are all the same algorithm, just trained on different inputs, and perhaps even constrained or aided by changes in the local neural architecture (as some studies on neurological correlates of autism might suggest). But computational power alone seems insufficient if we're going to explain phenomena like the autistic 'islands'. A savant doesn't want for computational power &ndash; but in some areas, they can want for intelligence.</p>\n<p>Here's where I start getting confused: the research I've seen <em>assumes</em> intelligence is a single trait which could be genetically, epigenetically, or culturally transmitted. When correlates of intelligence are looked for, from what I've seen, the correlates are for the 'average' intelligence score, and largely disregard the 'islands' of ability. As I've said, this can be useful, but it seems like answering some of these questions would be useful for a more general understanding of intelligence, especially going into the neurological side of things, whether that's in wetware or hardware.</p>\n<p>Then again, there's a good chance I'm missing something: in which case, I'd appreciate some help updating my priors.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AGjoeTXgRLMMLoRqq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 3, "extendedScore": null, "score": 9.700146163314593e-07, "legacy": true, "legacyId": "18409", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-23T00:09:14.404Z", "modifiedAt": null, "url": null, "title": "What's Wrong with Evidential Decision Theory?", "slug": "what-s-wrong-with-evidential-decision-theory", "viewCount": null, "lastCommentedAt": "2019-12-05T16:49:47.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "aaronde", "createdAt": "2012-07-21T04:30:42.693Z", "isAdmin": false, "displayName": "aaronde"}, "userId": "hGKL4iEoK8RgDJhmY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RtPC6cmKLftbLSn6n/what-s-wrong-with-evidential-decision-theory", "pageUrlRelative": "/posts/RtPC6cmKLftbLSn6n/what-s-wrong-with-evidential-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/RtPC6cmKLftbLSn6n/what-s-wrong-with-evidential-decision-theory", "postedAtFormatted": "Thursday, August 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20Wrong%20with%20Evidential%20Decision%20Theory%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20Wrong%20with%20Evidential%20Decision%20Theory%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRtPC6cmKLftbLSn6n%2Fwhat-s-wrong-with-evidential-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20Wrong%20with%20Evidential%20Decision%20Theory%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRtPC6cmKLftbLSn6n%2Fwhat-s-wrong-with-evidential-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRtPC6cmKLftbLSn6n%2Fwhat-s-wrong-with-evidential-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1493, "htmlBody": "<p>With all the exotic <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">decision theories</a> floating around here, it doesn't seem like anyone has tried to defend boring old <a href=\"http://en.wikipedia.org/wiki/Evidential_decision_theory\">evidential decision theory</a> since AlexMennen <a href=\"/lw/3pf/does_evidential_decision_theory_really_fail/\">last year</a>. &nbsp;So I thought I'd take a crack at it. &nbsp;I might come off a bit more confident than I am, since I'm defending a minority position (I'll leave it to others to bring up objections). &nbsp;But right now, I really do think that naive EDT, the simplest decision theory, is also the best decision theory. &nbsp;</p>\n<hr />\n<p>Everyone agrees that <a href=\"http://wiki.lesswrong.com/wiki/Smoker%27s_lesion\">Smoker's lesion</a> is a bad counterexample to EDT, since it turns out that smoking actually does cause cancer. &nbsp;But people seem to think that this is just an unfortunate choice of thought experiment, and that the reasoning is sound if we accept its premise. &nbsp;I'm not so convinced. &nbsp;I think that this \"bad example\" provides a pretty big clue as to what's wrong with the objections to EDT. &nbsp;(After all, does anyone think it would have been irrational to quit smoking, based only on the correlation between smoking and cancer, before randomized controlled trials were conducted?) &nbsp;I'll explain what I mean with the simplest version of this thought experiment I could come up with.</p>\n<p>Suppose that I'm a farmer, hoping it will rain today, to water my crops. &nbsp;I know that the probability of it having rained today, given that my lawn is wet, is higher than otherwise. &nbsp;And I know that my lawn will be wet, if I turn my sprinklers on. &nbsp;Of course, though it waters my lawn, running my sprinklers does nothing for my crops out in the field. &nbsp;Making the ground wet doesn't cause rain; it's the other way around. &nbsp;But if I'm an EDT agent, I know nothing of causation, and base my decisions only on conditional probability. &nbsp;According to the standard criticism of EDT, I stupidly turn my sprinklers on, as if that would make it rain.</p>\n<p>Here is where I think the criticism of EDT fails: how do I know, in the first place, that the ground being wet doesn't cause it to rain? &nbsp;One obvious answer is that I've tried it, and observed that the probability of it raining on a given day, given that I turned my sprinklers on, isn't any higher than the prior probability. &nbsp;But if I know that, then, as an evidential decision theorist, I have no reason to turn the sprinklers on. &nbsp;However, if all I know about the world I inhabit are the two facts: (1) the probability of rain is higher, given that the ground is wet, and (2) The probability of the ground being wet is higher, given that I turn the sprinklers on - then turning the sprinklers on really is the rational thing to do, if I want it to rain. &nbsp;</p>\n<p>This is more clear written symbolically. &nbsp;If O is the desired Outcome (rain), E is the Evidence (wet ground), and A is the Action (turning on sprinklers), then we have:</p>\n<ul>\n<li>P(O|E) &gt; P(O), and</li>\n<li>P(E|A) &gt; P(E)</li>\n</ul>\n<p>(In this case, A implies E, meaning P(E|A) = 1)</p>\n<p>It's still possible that P(O|A) = P(O). &nbsp;Or even that P(O|A) &lt; P(O). &nbsp;(For example, the prior probability of rolling a 4 with a fair die is 1/6. &nbsp;Whereas the probability of rolling a 4, given that you rolled an even number, is 1/3. &nbsp;So P(4|even) &gt; P(4). &nbsp;And you'll definitely roll an even number if you roll a 2, since 2 is even. &nbsp;So P(even|2) &gt; P(even). &nbsp;But the probabilty of rolling a 4, given that you roll a 2, is zero, since 4 isn't 2. &nbsp;So P(4|2) &lt; P(4) even though P(4|even) &gt; P(4) and P(even|2) &gt; P(even).) &nbsp;But in this problem, I don't know P(O|A) directly. &nbsp;The best I can do is guess that, since A implies E, therefore P(O|A) = P(O|E) &gt; P(O). &nbsp;So I do A, to make O more likely. &nbsp;But if I happened to know that P(O|A) = P(O), then I'd have no reason to do A.</p>\n<p>Of course, \"P(O|A) = P(O)\" is basically what we mean, when we say that the ground being wet doesn't cause it to rain. &nbsp;We know that making the ground wet (by means other than rain) doesn't make rain any more likely, either because we've observed this directly, or because we can infer it from our model of the world built up from countless observations. &nbsp;The reason that EDT seems to give the wrong answer to this problem is because we know extra facts about the world, that we haven't stipulated in the problem. &nbsp;But EDT gives the correct answer to the problem as stated. &nbsp;It does the best it can do (the best anyone could do) with limited information.</p>\n<p>This is the lesson we should take from Smoker's lesion. &nbsp;Yes, from the perspective of people 60 years ago, it's possible that smoking doesn't cause cancer, and rather a third factor predisposes people to both smoking and cancer. &nbsp;But it's also possible that there's a third factor which does the opposite: making people smoke and protecting them from cancer - but smokers are still more likely to get cancer, because smoking is so bad that it outweighs this protective effect. &nbsp;In the absense of evidence one way or the other, the prudent choice is to not smoke.</p>\n<p>But if we accept the premise of Smoker's lesion: that smokers are more likely to get cancer, only because people genetically predisposed to like smoking are also genetically predisposed to develop cancer - then EDT still gives us the right answer. &nbsp;Just as with the Sprinkler problem above, we know that P(O|E) &gt; P(O), and P(E|A) &gt; P(E), where O is the desired outcome of avoiding cancer, E is the evidence of not smoking, and A is the action of deciding to not smoke for the purpose of avoiding cancer. &nbsp;But we also just happen to know, by hypothesis, that P(O|A) = P(O). &nbsp;Recognizing A and E as distinct is key, because one of the implications of the premise is that people who stop smoking, despite enjoying smoking, fair just as badly as life-long smokers. &nbsp;So the reason that you choose to not smoke matters. &nbsp;If you choose to not smoke, because you can't stand tobacco, it's good news. &nbsp;But if you choose to not smoke to avoid cancer, it's neutral news. &nbsp;The bottom line is that you, as an evidential decision theorist, should not take cancer into account when deciding whether or not to smoke, because the good news that you decided to not smoke, would be cancelled out by the fact that you did it to avoid cancer.</p>\n<p>If this is starting to sound like the tickle defense, rest assured that there is no way to use this kind of reasoning to justify defecting on the <a href=\"http://wiki.lesswrong.com/wiki/Prisoner%27s_dilemma\">Prisoner's dilemma</a>&nbsp;or two-boxing on <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a>. &nbsp;The reason is that, if you're playing against a copy of yourself in Prisoner's dilemma, it doesn't matter why you decide to do what you do. &nbsp;Because, whatever your reasons are, your duplicate will do the same thing for the same reasons. &nbsp;Similarly, you only need to know that the predictor is accurate in Newcomb's problem, in order for one-boxing to be good news. &nbsp;The predictor might have blind spots that you could exploit, in order to get all the money. &nbsp;But unless you know about those exceptions, your best bet is to one-box. &nbsp;It's only in special cases that your motivation for making a decision can cancel out the auspiciousness of the decision.</p>\n<p>The other objection to EDT is that it's temporally inconsistent. &nbsp;But I don't see why that can't be handled with precommitments, because EDT isn't irreparably broken like <a href=\"http://en.wikipedia.org/wiki/Causal_decision_theory\">CDT</a>&nbsp;is. &nbsp;A CDT agent will one-box on Newcomb's problem, only if it has a chance to precommit before the predictor makes its prediction (which could be before the agent is even created). &nbsp;But an EDT agent one-boxes automatically, and pays in <a href=\"http://wiki.lesswrong.com/wiki/Counterfactual_mugging\">Counterfactual Mugging</a>&nbsp;as long as it has a chance to precommit before it finds out whether the coin came up heads. &nbsp;One of the first things we should expect a self-modifying EDT agent to do, is to make a blanket precommitment for all such problems. &nbsp;That is, it self-modifies in such a way that the modification itself is \"good news\", regardless of whether the decisions it's precommitting to will be good or bad news when they are carried out. &nbsp;This self-modification might be equivalent to designing something like an updateless decision theory agent. &nbsp;The upshot, if you're a self-modifying AI designer, is that your AI can do this by itself, along with its other recursive self-improvements.</p>\n<p>Ultimately, I think that causation is just a convenient short-hand that we use. &nbsp;In practice, we infer causal relations by observing conditional probabilities. &nbsp;Then we use those causal relations to inform our decisions. &nbsp;It's a great heuristic, but we shouldn't lose sight of what we're actually trying to do, which is to choose the option such that the probability of a good outcome is highest.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb28f": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RtPC6cmKLftbLSn6n", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 25, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "18410", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3z8xxvSib8LQuhFaa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-23T03:05:33.913Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Points of Departure", "slug": "seq-rerun-points-of-departure", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:19.268Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FSsDeTQzQZXk7zMcE/seq-rerun-points-of-departure", "pageUrlRelative": "/posts/FSsDeTQzQZXk7zMcE/seq-rerun-points-of-departure", "linkUrl": "https://www.lesswrong.com/posts/FSsDeTQzQZXk7zMcE/seq-rerun-points-of-departure", "postedAtFormatted": "Thursday, August 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Points%20of%20Departure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Points%20of%20Departure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFSsDeTQzQZXk7zMcE%2Fseq-rerun-points-of-departure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Points%20of%20Departure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFSsDeTQzQZXk7zMcE%2Fseq-rerun-points-of-departure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFSsDeTQzQZXk7zMcE%2Fseq-rerun-points-of-departure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>Today's post, <a href=\"/lw/tt/points_of_departure/\">Points of Departure</a> was originally published on 09 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Points_of_Departure\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Hollywood seems to model \"emotionless\" AI's as humans with some slight differences. For the most part, they act as emotionally repressed humans, despite the fact that this is a very unlikely way for AI's to behave.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e76/seq_rerun_the_truly_iterated_prisoners_dilemma/\">The Truly Iterated Prisoner's Dilemma</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FSsDeTQzQZXk7zMcE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.702167953531423e-07, "legacy": true, "legacyId": "18412", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zrGzan92SxP27LWP9", "cibQDqimmMvgbozdr", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-23T14:50:18.554Z", "modifiedAt": null, "url": null, "title": "Using Harry Potter and the Methods of Rationality to teach the scientific method to Psychology undergraduates", "slug": "using-harry-potter-and-the-methods-of-rationality-to-teach", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:15.391Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Weisguy", "createdAt": "2012-08-22T17:12:41.001Z", "isAdmin": false, "displayName": "Weisguy"}, "userId": "pwhK8tr3ecqsY9H5J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hd2C4rrTN5jXoD2s4/using-harry-potter-and-the-methods-of-rationality-to-teach", "pageUrlRelative": "/posts/Hd2C4rrTN5jXoD2s4/using-harry-potter-and-the-methods-of-rationality-to-teach", "linkUrl": "https://www.lesswrong.com/posts/Hd2C4rrTN5jXoD2s4/using-harry-potter-and-the-methods-of-rationality-to-teach", "postedAtFormatted": "Thursday, August 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20to%20teach%20the%20scientific%20method%20to%20Psychology%20undergraduates&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20to%20teach%20the%20scientific%20method%20to%20Psychology%20undergraduates%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHd2C4rrTN5jXoD2s4%2Fusing-harry-potter-and-the-methods-of-rationality-to-teach%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20to%20teach%20the%20scientific%20method%20to%20Psychology%20undergraduates%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHd2C4rrTN5jXoD2s4%2Fusing-harry-potter-and-the-methods-of-rationality-to-teach", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHd2C4rrTN5jXoD2s4%2Fusing-harry-potter-and-the-methods-of-rationality-to-teach", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 152, "htmlBody": "<p style=\"text-align: start;\"><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; background-color: #f7f7f8;\">A</span>s a psychology graduate student I have the opportunity to teach an introductory psychology course. I'm hoping to take what I have learned here and start&nbsp;helping my students improve their rationality. Specifically, I'm planning to have the students read excerpts from Ch 22 &amp; 23 of HPMOR as a fun and interesting way to start learning to think like a scientist. I'm hoping the community can assist me with possibly narrowing down the sections I'm going to have them read and consider possible methods of assessment. As of now, I know that I want to have the students analyze the methodology used by Harry in his two experiments from those chapters (Harry and Hermione testing spells and Harry and Draco \"testing\" the blood hypotheses), and I probably want to have students come up with their own hypotheses and methods to test them. Any help the community wants to provide is most appreciated.<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; background-color: #f7f7f8;\"></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hd2C4rrTN5jXoD2s4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 9.705678262689497e-07, "legacy": true, "legacyId": "18426", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-24T14:28:38.470Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin; Bratislava, Slovakia; Cambridge MA; Melbourne; Sydney; Washington DC ", "slug": "weekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "viewCount": null, "lastCommentedAt": "2012-08-24T14:28:38.470Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Jp9avQsG6xLwMqPyr/weekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "pageUrlRelative": "/posts/Jp9avQsG6xLwMqPyr/weekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "linkUrl": "https://www.lesswrong.com/posts/Jp9avQsG6xLwMqPyr/weekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "postedAtFormatted": "Friday, August 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%3B%20Bratislava%2C%20Slovakia%3B%20Cambridge%20MA%3B%20Melbourne%3B%20Sydney%3B%20Washington%20DC%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%3B%20Bratislava%2C%20Slovakia%3B%20Cambridge%20MA%3B%20Melbourne%3B%20Sydney%3B%20Washington%20DC%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJp9avQsG6xLwMqPyr%2Fweekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%3B%20Bratislava%2C%20Slovakia%3B%20Cambridge%20MA%3B%20Melbourne%3B%20Sydney%3B%20Washington%20DC%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJp9avQsG6xLwMqPyr%2Fweekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJp9avQsG6xLwMqPyr%2Fweekly-lw-meetups-austin-bratislava-slovakia-cambridge-ma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 428, "htmlBody": "<p><strong>This summary was posted to LW main on August 17th, and has been moved to discussion.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/cm\">Bratislava, Slovakia - the first LW meetup:&nbsp;<span class=\"date\">18 August 2012 05:00PM</span></a></li>\n<li><a href=\"/meetups/d0\">Washington DC TED talks Meetup:&nbsp;<span class=\"date\">19 August 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/cp\">Less Wrong Sydney: 20th August :&nbsp;<span class=\"date\">20 August 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/ct\">Berlin Meetup:&nbsp;<span class=\"date\">04 September 2012 07:30PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">18 August 2018 01:30PM</span></a></li>\n<li><a href=\"/meetups/cf\">Cambridge (MA) Meetup:&nbsp;<span class=\"date\">19 August 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/cy\">Melbourne social meetup:&nbsp;<span class=\"date\">24 August 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/cv\">Meetup: Southwestern Ohio:&nbsp;<span class=\"date\">26 August 2012 04:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong>&nbsp;</strong><strong></strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>, <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Jp9avQsG6xLwMqPyr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.712749751139582e-07, "legacy": true, "legacyId": "18315", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 0, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-24T22:44:38.928Z", "modifiedAt": null, "url": null, "title": "Completeness of simulations", "slug": "completeness-of-simulations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:52.889Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RolfAndreassen", "createdAt": "2009-04-17T19:37:23.246Z", "isAdmin": false, "displayName": "RolfAndreassen"}, "userId": "KLJmn2HYWEu4tBKcC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J9k5MxQGuaN7Wmwrq/completeness-of-simulations", "pageUrlRelative": "/posts/J9k5MxQGuaN7Wmwrq/completeness-of-simulations", "linkUrl": "https://www.lesswrong.com/posts/J9k5MxQGuaN7Wmwrq/completeness-of-simulations", "postedAtFormatted": "Friday, August 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Completeness%20of%20simulations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACompleteness%20of%20simulations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ9k5MxQGuaN7Wmwrq%2Fcompleteness-of-simulations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Completeness%20of%20simulations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ9k5MxQGuaN7Wmwrq%2Fcompleteness-of-simulations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ9k5MxQGuaN7Wmwrq%2Fcompleteness-of-simulations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>Suppose I have an exact simulation of a human. Feeling ambitious, I decide to print out a GLUT of the action this human will take in every circumstance; while the simulation of course works at the level of quarks, I have a different program that takes lists of quark movements and translates them into a suitably high-level language, such as \"Confronted with the evidence that his wife is also his mother, the subject will blind himself and abdicate\".</p>\n<p>Now, one possible situation is \"The subject is confronted with the evidence that his wife is also his mother, and additionally with the fact that this GLUT predicts he will do X\". Is it clear that an accurate X exists? In high-level language, I would say that, whatever the prediction is, the subject may choose to do something different. More formally we can notice that the simulation is now self-referential: Part of the result is to be used as the input to the calculation, and therefore affects the result. It is not obvious to me that a self-consistent solution necessarily exists.</p>\n<p>It seems to me that this is somehow reminiscent of the Halting Problem, and can perhaps be reduced to it. That is, it may be possible to show that an algorithm that can produce X for arbitrary Turing machines would also be a Halting Oracle. If so, this seems to say something interesting about limitations on what a simulation can do, but I'm not sure exactly what.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J9k5MxQGuaN7Wmwrq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 9.715224887461454e-07, "legacy": true, "legacyId": "18447", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T02:35:48.941Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Excluding the Supernatural", "slug": "seq-rerun-excluding-the-supernatural", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:19.161Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/exauqJm3f2jui8KYG/seq-rerun-excluding-the-supernatural", "pageUrlRelative": "/posts/exauqJm3f2jui8KYG/seq-rerun-excluding-the-supernatural", "linkUrl": "https://www.lesswrong.com/posts/exauqJm3f2jui8KYG/seq-rerun-excluding-the-supernatural", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Excluding%20the%20Supernatural&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Excluding%20the%20Supernatural%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexauqJm3f2jui8KYG%2Fseq-rerun-excluding-the-supernatural%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Excluding%20the%20Supernatural%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexauqJm3f2jui8KYG%2Fseq-rerun-excluding-the-supernatural", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexauqJm3f2jui8KYG%2Fseq-rerun-excluding-the-supernatural", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 170, "htmlBody": "<p>Today's post, <a href=\"/lw/tv/excluding_the_supernatural/\">Excluding the Supernatural</a> was originally published on 12 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Don't rule out supernatural explanations because they're supernatural. Test them the way you would test any other hypothesis. And probably, you will find out that they aren't true.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/e7g/seq_rerun_points_of_departure/\">Points of Departure</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "exauqJm3f2jui8KYG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.716378818568827e-07, "legacy": true, "legacyId": "18448", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["u6JzcFtPGiznFgDxP", "FSsDeTQzQZXk7zMcE", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T03:09:50.992Z", "modifiedAt": null, "url": null, "title": "Cryonics donation fund for Kim Suozzi established by Society for Venturism", "slug": "cryonics-donation-fund-for-kim-suozzi-established-by-society", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:52.777Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/89MjaiTADzYXAQ6tb/cryonics-donation-fund-for-kim-suozzi-established-by-society", "pageUrlRelative": "/posts/89MjaiTADzYXAQ6tb/cryonics-donation-fund-for-kim-suozzi-established-by-society", "linkUrl": "https://www.lesswrong.com/posts/89MjaiTADzYXAQ6tb/cryonics-donation-fund-for-kim-suozzi-established-by-society", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20donation%20fund%20for%20Kim%20Suozzi%20established%20by%20Society%20for%20Venturism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20donation%20fund%20for%20Kim%20Suozzi%20established%20by%20Society%20for%20Venturism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MjaiTADzYXAQ6tb%2Fcryonics-donation-fund-for-kim-suozzi-established-by-society%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20donation%20fund%20for%20Kim%20Suozzi%20established%20by%20Society%20for%20Venturism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MjaiTADzYXAQ6tb%2Fcryonics-donation-fund-for-kim-suozzi-established-by-society", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MjaiTADzYXAQ6tb%2Fcryonics-donation-fund-for-kim-suozzi-established-by-society", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<p>Following the news that <a href=\"/r/discussion/lw/e5d/link_reddit_help_me_find_some_peace_im_dying_young/\">Kim Suozzi has terminal brain cancer and wants to be cryopreserved</a>, many of us have donated to help her out, while others, including me, planned to donate when CI set up a fund to receive donations on her behalf. <a href=\"http://www.venturist.info/kim-suozzi-charity.html\">Now the Society for Venturism has set up a fund</a>, and it is time for us to follow through on those plans. (Unless you are really insisting that the fund be managed by CI specifically.)</p>\n<p>(<strong>ETA</strong>: <a href=\"/r/discussion/lw/e9k/update_society_of_venturism_is_spearheading_kim/\">Kim has posted on this herself</a>.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "89MjaiTADzYXAQ6tb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 13, "extendedScore": null, "score": 9.716548729602346e-07, "legacy": true, "legacyId": "18449", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fLaKKRZckYtrrcz7m", "hozfqzhDrMAcwsHN6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T04:29:45.793Z", "modifiedAt": null, "url": null, "title": "Meetup : SLC, UT: Free Will and Rationality Checklists", "slug": "meetup-slc-ut-free-will-and-rationality-checklists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:35.319Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hamnox", "createdAt": "2011-01-17T01:16:28.722Z", "isAdmin": false, "displayName": "hamnox"}, "userId": "EY9o6qtXvYhS5CTHD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/itMYYNLq57tnSCBaP/meetup-slc-ut-free-will-and-rationality-checklists", "pageUrlRelative": "/posts/itMYYNLq57tnSCBaP/meetup-slc-ut-free-will-and-rationality-checklists", "linkUrl": "https://www.lesswrong.com/posts/itMYYNLq57tnSCBaP/meetup-slc-ut-free-will-and-rationality-checklists", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20SLC%2C%20UT%3A%20Free%20Will%20and%20Rationality%20Checklists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20SLC%2C%20UT%3A%20Free%20Will%20and%20Rationality%20Checklists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FitMYYNLq57tnSCBaP%2Fmeetup-slc-ut-free-will-and-rationality-checklists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20SLC%2C%20UT%3A%20Free%20Will%20and%20Rationality%20Checklists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FitMYYNLq57tnSCBaP%2Fmeetup-slc-ut-free-will-and-rationality-checklists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FitMYYNLq57tnSCBaP%2Fmeetup-slc-ut-free-will-and-rationality-checklists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d6'>SLC, UT: Free Will and Rationality Checklists</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 September 2012 03:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Calvin S Smith Library, 810 East 3300 South, Salt Lake City, UT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be in the back conference room</p>\n\n<p>3:00 Greetings, Introduction and Catchup</p>\n\n<p>3:10 Minicamp Brain Dump (Kevin V.)</p>\n\n<p>3:30 discuss</p>\n\n<p>3:40 Willpower (Dan N.)</p>\n\n<p>4:00 discuss</p>\n\n<p>4:10 SLOT FREE</p>\n\n<p>4:30 discuss</p>\n\n<p>4:40 Wrap up and Final Thoughts, Sign up for next meetup</p>\n\n<p>Free Discussion</p>\n\n<p>I'd suggest bringing a notebook and pen.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d6'>SLC, UT: Free Will and Rationality Checklists</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "itMYYNLq57tnSCBaP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 8e-06, "legacy": true, "legacyId": "18450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___SLC__UT__Free_Will_and_Rationality_Checklists\">Discussion article for the meetup : <a href=\"/meetups/d6\">SLC, UT: Free Will and Rationality Checklists</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 September 2012 03:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Calvin S Smith Library, 810 East 3300 South, Salt Lake City, UT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be in the back conference room</p>\n\n<p>3:00 Greetings, Introduction and Catchup</p>\n\n<p>3:10 Minicamp Brain Dump (Kevin V.)</p>\n\n<p>3:30 discuss</p>\n\n<p>3:40 Willpower (Dan N.)</p>\n\n<p>4:00 discuss</p>\n\n<p>4:10 SLOT FREE</p>\n\n<p>4:30 discuss</p>\n\n<p>4:40 Wrap up and Final Thoughts, Sign up for next meetup</p>\n\n<p>Free Discussion</p>\n\n<p>I'd suggest bringing a notebook and pen.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___SLC__UT__Free_Will_and_Rationality_Checklists1\">Discussion article for the meetup : <a href=\"/meetups/d6\">SLC, UT: Free Will and Rationality Checklists</a></h2>", "sections": [{"title": "Discussion article for the meetup : SLC, UT: Free Will and Rationality Checklists", "anchor": "Discussion_article_for_the_meetup___SLC__UT__Free_Will_and_Rationality_Checklists", "level": 1}, {"title": "Discussion article for the meetup : SLC, UT: Free Will and Rationality Checklists", "anchor": "Discussion_article_for_the_meetup___SLC__UT__Free_Will_and_Rationality_Checklists1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T16:38:34.640Z", "modifiedAt": null, "url": null, "title": "Mike Darwin on animal research, moral cowardice, and reasoning in an uncaring universe", "slug": "mike-darwin-on-animal-research-moral-cowardice-and-reasoning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Synaptic", "createdAt": "2011-09-26T14:13:36.154Z", "isAdmin": false, "displayName": "Synaptic"}, "userId": "cXSPuYAf5pC9XTzcm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ghtsPkTQ7JhZtjjsB/mike-darwin-on-animal-research-moral-cowardice-and-reasoning", "pageUrlRelative": "/posts/ghtsPkTQ7JhZtjjsB/mike-darwin-on-animal-research-moral-cowardice-and-reasoning", "linkUrl": "https://www.lesswrong.com/posts/ghtsPkTQ7JhZtjjsB/mike-darwin-on-animal-research-moral-cowardice-and-reasoning", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mike%20Darwin%20on%20animal%20research%2C%20moral%20cowardice%2C%20and%20reasoning%20in%20an%20uncaring%20universe&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMike%20Darwin%20on%20animal%20research%2C%20moral%20cowardice%2C%20and%20reasoning%20in%20an%20uncaring%20universe%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FghtsPkTQ7JhZtjjsB%2Fmike-darwin-on-animal-research-moral-cowardice-and-reasoning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mike%20Darwin%20on%20animal%20research%2C%20moral%20cowardice%2C%20and%20reasoning%20in%20an%20uncaring%20universe%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FghtsPkTQ7JhZtjjsB%2Fmike-darwin-on-animal-research-moral-cowardice-and-reasoning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FghtsPkTQ7JhZtjjsB%2Fmike-darwin-on-animal-research-moral-cowardice-and-reasoning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2007, "htmlBody": "<p>He writes <a href=\"http://tech.groups.yahoo.com/group/New_Cryonet/message/2889\">this essay</a>&nbsp;in response to someone who writes about their \"gut level emotional response when [they] thought about dogs being likely killed by an as yet unproven and dangerous medical procedure.\"&nbsp;</p>\n<p>I recommend the whole thing. If you are going to read it all, note that some text is duplicated near the end, though there is one paragraph at the very end which is not.&nbsp;</p>\n<p>First, he describes how animals share empathy and emotions with humans:</p>\n<blockquote>\n<p>It is a maxim of the Animal Rights ideologues that \"a rat is a dog is a boy.\"&nbsp;[<a href=\"http://www.peta.org/about/why-peta/why-animal-rights.aspx\">PETA</a>]&nbsp;This is patently not true, and might just be denounced as absurd on its face. But, it is true that rats, dogs and boys share important properties, or more generally, that rats, dogs and people share important properties. I have a huge reservoir of experience with rats, dogs and people. All three have a well developed sense of self, the ability to read my face and determine my mental state, and, obviously, the ability to experience most, if not all of the basic emotions and mental states that humans experience: anxiety, fear, emotional attachment to others (or their own and other species), sexual arousal and release, anticipation, enjoyment, curiosity, and so on. Most importantly, they have the ability to experience empathy - to extend their internal feelings to others. Well socialized rats and dogs know that the people they interact with can be hurt, provoked, pleased, and otherwise be emotionally and physically affected by their actions and they, in turn, act accordingly within the limits of their abilities to do so. Neither \"pet\" dogs nor rats bite their owners with abandon nor destroy their homes. This isn't just \"conditioned behavior,\" but rather is the result of a more global understanding that humans, like them, can feel; and thus can be rewarded or made to suffer.</p>\n<p>This is a very important and valuable property to people. it is so valuable that, when members of our own species fail to demonstrate it, we imprison them or even kill them! Jails and prisons are full of people who either lack empathy, or lack the ability to act upon it. What then does it say of us if we treat animals in ways that demonstrate a lack of understanding or respect for their feelings - for their ability to suffer or experience pleasure?</p>\n<p>The answer is that it would, at first glance, say that we were either sociopaths, profoundly ignorant of the nature of animals, or taken over by some ideology which induced a state of perceptual blindness to their plight. Thus, what I am saying here is that I agree that it is neither reasonable nor moral (within our value structure as empathetic beings) to regard animals as unfeeling automatons, let alone treat them as such.</p>\n<p>However, there is a problem with this approach to dealing both with our fellow humans and with other animals as the sole guide to our actions. The problem is, put simply, this: The native state of man and beast is one of unfathomable suffering.</p>\n</blockquote>\n<p>Next, he explains ethics in a way that seems to correspond with a lot of Eliezer's writing:&nbsp;</p>\n<blockquote>\n<p>The central moral kernel of almost every religion is that we are born into a world of injustice and suffering. There can be little quibbling with that observation, since everywhere we turn we see living systems whose very structure brings them into \"conflict\" with their environment and causes enormous suffering. This is how it has always been. It is the reality of our existence in this universe. Evolution, the beautiful star studded sky at night, the cool lapping ocean - they don't give a damn about anything, least of all a mouse in a cage with cancer or a woman with her breast rotting off. And as far we can tell, they never will.</p>\n<p>The best the universe has done so far is to produce us - creatures who both can and <em><strong>do</strong></em> care about injustice and suffering. If you believe in a Grand Design, or some other teleological explanation that results in universal justice, then, go to the mirror right now and take a long hard look, because buddy, you are it - <strong><em>you are as good as it has gotten, so far</em></strong>.</p>\n<p>Then, unless you are cretin or a fool, or both, realize that suffering and injustice are both <strong><em>inescapable</em></strong> contemporary and future realities which you have to deal with rationally (or not) as you choose. You do not get to choose Door Number 3, which is \"no suffering and injustice.\" In fact, even you kill yourself straightaway to avoid inconveniencing a mouse with a plow, the suffering and injustice will continue to march on, even for billions and billions of years.</p>\n<p>There are no easy choices.</p>\n<p>The best you can do is to choose carefully and rationally what kinds of misery you will inflict and to work, relentlessly, to minimize it and to make the universe a more just place. Those decisions will be informed by your values - by what you hold most worthy and in highest esteem. You are, of course, free to choose mice over men, a hunter-gatherer life over that of an agrarian, the world of the primitive or technological civilization.</p>\n</blockquote>\n<p>Next, he tackles questions about whether animal research is, on net, beneficial:&nbsp;</p>\n<blockquote>\n<p>However, what you are not free to do, at least not around me, is to spew out lies and moral falsehoods about the supposed real nature of the universe and the real consequences of the choices you (and others like you) make. If you think that animal's have rights in the classical and real sense that has historically been applied to humans, then I will call you a liar and a moral blackguard who would, and has, condemned not only countless humans to unnecessary suffering and death, but countless animals whom humans value highly (our companion animals and livestock) as well - because much of veterinary medicine is a direct result of animal research.</p>\n<p>If you argue that humans should be used in research, there I would agree with you. Most of the pharmacological research done with rodents is junk science which has led to few real medical advances. But be advised that such research will be ugly and terrifying and very likely costly in some meaningful proportion to the benefit it yields.</p>\n<p>I am sorry to be so harsh, but technological civilization has robbed most of the Western world of any sense of reality - of how the universe works and of just how much suffering accrues from every frozen ready meal and every lipstick or plastic bottle of beverage consumed.</p>\n<p>That dreamy, soft-bellied state of unreality is intolerable and it is also incompatible with our continued existence as a technological species, and probably as a species at all.</p>\n<p>And it is most certainly incompatible with any hope we can currently see of the universe becoming a more just, decent and humane place.</p>\n<p>Thus, I see your feelings and attitudes as profoundly incompatible both with your long term personal survival, and that of our species. As such, they evoke in me a feeling of revulsion and strong feeling of anger for the damage they have already caused to biomedical research - and will likely continue to cause.</p>\n</blockquote>\n<p>Next, he goes into details of what animal lifespan research entails:&nbsp;</p>\n<blockquote>\n<p>I would also like to note that \"the worst\" of animal research in terms of inflicting suffering is not the acute experimental work conducted by cryonicists and most other mainstream medical research, but rather is to be found in the work of gerontologists conducting life span studies on rodents and primates. Research which virtually all on this list serve avidly lap up and never criticize - even though much, if not most of it, is junk science.</p>\n<p>I can say, without reservation, that of all the pain, horror and cruelty that I have inflicted, either inadvertently, or as an anticipated consequence of research, by far the most cruel work I've ever (done or) observed is that of the gerontologist doing lifespan studies. ...&nbsp;</p>\n<p>The fact is, that aging animals get a dreadful array of truly horrible and disgusting pathologies and, because they are not humans receiving human medical care, they die in fantastically gruesome ways more often than not. ...</p>\n<p>Rodents often develop not only mammary neoplasms [breast cancers], but tumors of the food pouches and buccal mucosa [inside lining of the cheeks]. Since there is no surgical intervention, these masses often grow to colossal size, ulcerate, break down and fungate. A common cause of death is starvation, which is truly terrible to watch. Sometimes, the animals lose the ability to drink, in which case death is mercifully faster and less painful as a result of dehydration.</p>\n<p>The visceral and bone pain that results from tumor invasion of vital organs, the skeleton and joints must be unimaginable. And cancers kills the <strong><em>majority</em></strong> of animals in gerontological lifespan studies. I've seen animals languish in their cages for weeks or months being slowly consumed by lesions so revolting I could barely force myself to handle them in order to document their decline.</p>\n<p>And of what the lucky ones who don't die of cancer? Are they in rodent care homes in tiny beds with tiny egg crate mattresses with a staff of rodents careers to lick their bums and turn them? Hardly. As animals age and develop spondylosis [spine osteoarthritis] and sarcopenia [age-related loss of muscle mass], they become unable to reach their anuses and urogential areas with their mouths. As a result, they cannot clean themselves, and they develop an ammonia-generating, bacteria infested crusting of urea and feces in these delicate areas, which, not infrequently results in ulceration. They are often blind from cataracts, and are, of necessity, usually housed one to a cage (they have a propensity to cannibalism, especially if calorie restricted), so they die alone, slowly, most often of starvation and dehydration.</p>\n<p>Of course, the first question that likely comes to most peoples' minds upon hearing this a tale of horror is, \"For the love of god man, why don't you euthanize such poor creatures, or at least medicate them for pain?\" The answer is that you can't, not without developing a whole new, complex and costly model which has highly specific (and uniform) and almost completely NONSUBJECTIVE algorithms for when euthanasia should take place. And, you can forget about knowing what the \"maximum lifespan\" is, because it is flat out impossible to tell how long a moribund and likely suffering animal will live. I've seen animals I thought were certain to die within days survive for MONTHS! And so has every other experienced gerontological researcher.</p>\n<p><strong><em>That is the reality gerontological lifespan research.</em></strong></p>\n<p>So, you want to trespass on the territory of the gods and life forever, or even just another 50 or 500 years longer <strong><em>and</em></strong> you want to do it whilst being a nice guy? Give me a break!</p>\n</blockquote>\n<p>The ending is poignant, and I think an excusable violation of <a href=\"http://en.wikipedia.org/wiki/Godwin's_law\">Godwin's law</a>:&nbsp;</p>\n<blockquote>\n<p>Cryonics has largely been taken over by this moral world-view and with an understandable, if inexcusable accompanying moral cowardice which dictates that we hide our animal research and cower in fear because the \"Animal Rights\" people will attack us (and by implication our poorly protected patients stored in vulnerable, unhardened facilities). This is the direct path to the Dark Ages or to the Soviet, or to the Third Reich, which was ironically, the only nation-state to completely ban animal research because of its cruelty and inhumanity. Instead, they built concentration camps and turned loose the likes of Holzhoner, Rascher, Mengle, Whichtman, Caluberg and countless others like them on humans, who, unlike animals, have the rich perceptual ability to comprehend their own mortality and to contemplate, at length, the certain inevitability of their fate.</p>\n</blockquote>\n<p>Darwin does not mention it in this essay, but&nbsp;<a href=\"http://en.wikipedia.org/wiki/Mike_Darwin\">he is a vegetarian</a>, and his dog is cryopreserved at Alcor.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Q9ASuEEoJWxT3RLMT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ghtsPkTQ7JhZtjjsB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 37, "extendedScore": null, "score": 9.720587739525324e-07, "legacy": true, "legacyId": "18462", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T19:49:02.906Z", "modifiedAt": null, "url": null, "title": "Neil Armstrong died before we could defeat death", "slug": "neil-armstrong-died-before-we-could-defeat-death", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:20.743Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/23PjY5bQgHBTDvvnv/neil-armstrong-died-before-we-could-defeat-death", "pageUrlRelative": "/posts/23PjY5bQgHBTDvvnv/neil-armstrong-died-before-we-could-defeat-death", "linkUrl": "https://www.lesswrong.com/posts/23PjY5bQgHBTDvvnv/neil-armstrong-died-before-we-could-defeat-death", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Neil%20Armstrong%20died%20before%20we%20could%20defeat%20death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANeil%20Armstrong%20died%20before%20we%20could%20defeat%20death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F23PjY5bQgHBTDvvnv%2Fneil-armstrong-died-before-we-could-defeat-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Neil%20Armstrong%20died%20before%20we%20could%20defeat%20death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F23PjY5bQgHBTDvvnv%2Fneil-armstrong-died-before-we-could-defeat-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F23PjY5bQgHBTDvvnv%2Fneil-armstrong-died-before-we-could-defeat-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<p>The sad news broke tonight : Neil Armstrong, the first human to ever walk another world, died today. We lost him forever. He died before we could defeat death.</p>\n<p>Once again the horror of death strikes. This time, in addition from wiping from us forever a hero of humanity, he wiped from us forever a memory that will never exist again. Never again will a human being be able to experience being the first to walk another world. That beautiful experience is lost forever too, along with all the memories, dreams, desires and wishes that made Neil Armstrong.</p>\n<p>But thanks to him, humanity made a giant leap. We'll fill the stars and conquer death. The spark of intelligence and sentience will not extinguish. That's the best we can do to honour him.</p>\n<p>Source : http://www.reuters.com/article/2012/08/25/us-usa-neilarmstrong-idUSBRE87O0B020120825</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1, "2JdCpTrNgBMNpJiyB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "23PjY5bQgHBTDvvnv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": -3, "extendedScore": null, "score": 9.721539437945166e-07, "legacy": true, "legacyId": "18463", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T22:43:32.431Z", "modifiedAt": null, "url": null, "title": "What are useful skills to learn at university?", "slug": "what-are-useful-skills-to-learn-at-university", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:05.414Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Metus", "createdAt": "2011-01-23T21:54:34.357Z", "isAdmin": false, "displayName": "Metus"}, "userId": "mNQ4fSvro7LYgrii4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nTrGhXajQ8ByALYuc/what-are-useful-skills-to-learn-at-university", "pageUrlRelative": "/posts/nTrGhXajQ8ByALYuc/what-are-useful-skills-to-learn-at-university", "linkUrl": "https://www.lesswrong.com/posts/nTrGhXajQ8ByALYuc/what-are-useful-skills-to-learn-at-university", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20useful%20skills%20to%20learn%20at%20university%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20useful%20skills%20to%20learn%20at%20university%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTrGhXajQ8ByALYuc%2Fwhat-are-useful-skills-to-learn-at-university%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20useful%20skills%20to%20learn%20at%20university%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTrGhXajQ8ByALYuc%2Fwhat-are-useful-skills-to-learn-at-university", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnTrGhXajQ8ByALYuc%2Fwhat-are-useful-skills-to-learn-at-university", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>To further elaborate the question: What are the most universally and most useful skills one could learn at a university? Currently, I am studying physics as an undergraduate and I am thinking about my career options. I have gotten opinions in other forums as well but I would really like to hear your thoughts and I also think that other LessWrongers would find such a list useful. To give you a rough idea of what I mean I have two examples:</p>\n<ul>\n<li>Programming/Coding: Almost universally applicable seeing as if you can describe your process, you can automate it. It is a skill you can use in applied research, fundamental research or in a field not related to physics at all.</li>\n<li>Statistics, the mathematics and the use of R or SAS: Again, in all fields of science and many applications statistical knowledge is required. Having a firm grasp of the mathematical concepts involved and being able to use a statistics software can only be advantageous.</li>\n</ul>\n<p>What are some other skills along this line that are universally useful?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nTrGhXajQ8ByALYuc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.722407435121062e-07, "legacy": true, "legacyId": "18464", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T22:53:59.415Z", "modifiedAt": null, "url": null, "title": "PSA: People can see what you've \"liked\" and \"disliked\" if you checked \"Make my votes public\"", "slug": "psa-people-can-see-what-you-ve-liked-and-disliked-if-you", "viewCount": null, "lastCommentedAt": "2012-08-26T17:42:08.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NT3WpodS9hQYJ9sLS/psa-people-can-see-what-you-ve-liked-and-disliked-if-you", "pageUrlRelative": "/posts/NT3WpodS9hQYJ9sLS/psa-people-can-see-what-you-ve-liked-and-disliked-if-you", "linkUrl": "https://www.lesswrong.com/posts/NT3WpodS9hQYJ9sLS/psa-people-can-see-what-you-ve-liked-and-disliked-if-you", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20PSA%3A%20People%20can%20see%20what%20you've%20%22liked%22%20and%20%22disliked%22%20if%20you%20checked%20%22Make%20my%20votes%20public%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APSA%3A%20People%20can%20see%20what%20you've%20%22liked%22%20and%20%22disliked%22%20if%20you%20checked%20%22Make%20my%20votes%20public%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNT3WpodS9hQYJ9sLS%2Fpsa-people-can-see-what-you-ve-liked-and-disliked-if-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=PSA%3A%20People%20can%20see%20what%20you've%20%22liked%22%20and%20%22disliked%22%20if%20you%20checked%20%22Make%20my%20votes%20public%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNT3WpodS9hQYJ9sLS%2Fpsa-people-can-see-what-you-ve-liked-and-disliked-if-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNT3WpodS9hQYJ9sLS%2Fpsa-people-can-see-what-you-ve-liked-and-disliked-if-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<p>I think this feature might have been broken a while ago, but it works now. So if you don't want your likes and dislikes to be public, go to your preferences page and uncheck \"Make my votes public.\" At the moment, the upvotes and downvotes of many prominent users are visible by clicking their username and then clicking \"Liked\" or \"Disliked\".</p>\n<p>That is all.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NT3WpodS9hQYJ9sLS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 9.722463666771531e-07, "legacy": true, "legacyId": "18465", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-25T23:58:21.201Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Thursday 7pm", "slug": "meetup-fort-collins-colorado-meetup-thursday-7pm-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vtsC3NPGWWQqBGeua/meetup-fort-collins-colorado-meetup-thursday-7pm-2", "pageUrlRelative": "/posts/vtsC3NPGWWQqBGeua/meetup-fort-collins-colorado-meetup-thursday-7pm-2", "linkUrl": "https://www.lesswrong.com/posts/vtsC3NPGWWQqBGeua/meetup-fort-collins-colorado-meetup-thursday-7pm-2", "postedAtFormatted": "Saturday, August 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtsC3NPGWWQqBGeua%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtsC3NPGWWQqBGeua%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvtsC3NPGWWQqBGeua%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d7'>Fort Collins, Colorado Meetup Thursday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 August 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1129 W. Elizabeth St. Fort Collins 80521</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Back to school, back to our regular Thursday in Fort Collins meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d7'>Fort Collins, Colorado Meetup Thursday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vtsC3NPGWWQqBGeua", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.722785351490528e-07, "legacy": true, "legacyId": "18466", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm\">Discussion article for the meetup : <a href=\"/meetups/d7\">Fort Collins, Colorado Meetup Thursday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 August 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1129 W. Elizabeth St. Fort Collins 80521</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Back to school, back to our regular Thursday in Fort Collins meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/d7\">Fort Collins, Colorado Meetup Thursday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-26T04:06:33.833Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Psychic Powers", "slug": "seq-rerun-psychic-powers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:22.406Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yo3TFs48drsTSAput/seq-rerun-psychic-powers", "pageUrlRelative": "/posts/yo3TFs48drsTSAput/seq-rerun-psychic-powers", "linkUrl": "https://www.lesswrong.com/posts/yo3TFs48drsTSAput/seq-rerun-psychic-powers", "postedAtFormatted": "Sunday, August 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Psychic%20Powers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Psychic%20Powers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyo3TFs48drsTSAput%2Fseq-rerun-psychic-powers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Psychic%20Powers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyo3TFs48drsTSAput%2Fseq-rerun-psychic-powers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyo3TFs48drsTSAput%2Fseq-rerun-psychic-powers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 165, "htmlBody": "<p>Today's post, <a href=\"/lw/tw/psychic_powers/\">Psychic Powers</a> was originally published on 12 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Psychic_Powers\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Some of the previous post was incorrect. Psychic powers, if indeed they were ever discovered, would actually be strong evidence in favor of non-reductionism.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e8g/seq_rerun_excluding_the_supernatural/\">Excluding the Supernatural</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yo3TFs48drsTSAput", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 9.724026076391239e-07, "legacy": true, "legacyId": "18468", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7Au7kvRAPREm3ADcK", "exauqJm3f2jui8KYG", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-26T04:15:49.745Z", "modifiedAt": null, "url": null, "title": "Luke' AMA gets a plug @ Wired [link]", "slug": "luke-ama-gets-a-plug-wired-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:18.262Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lj3QamzuLcK7yxFiC/luke-ama-gets-a-plug-wired-link", "pageUrlRelative": "/posts/Lj3QamzuLcK7yxFiC/luke-ama-gets-a-plug-wired-link", "linkUrl": "https://www.lesswrong.com/posts/Lj3QamzuLcK7yxFiC/luke-ama-gets-a-plug-wired-link", "postedAtFormatted": "Sunday, August 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Luke'%20AMA%20gets%20a%20plug%20%40%20Wired%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALuke'%20AMA%20gets%20a%20plug%20%40%20Wired%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLj3QamzuLcK7yxFiC%2Fluke-ama-gets-a-plug-wired-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Luke'%20AMA%20gets%20a%20plug%20%40%20Wired%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLj3QamzuLcK7yxFiC%2Fluke-ama-gets-a-plug-wired-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLj3QamzuLcK7yxFiC%2Fluke-ama-gets-a-plug-wired-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.wired.com/geekdad/2012/08/preventing-skynet/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YgizoZqa7LEb3LEJn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lj3QamzuLcK7yxFiC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 8, "extendedScore": null, "score": 9.724072395511915e-07, "legacy": true, "legacyId": "18469", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-26T18:08:15.564Z", "modifiedAt": null, "url": null, "title": "[Draft] Productive Use of Heuristics and Biases", "slug": "draft-productive-use-of-heuristics-and-biases", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:22.454Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wattsd", "createdAt": "2011-06-03T21:18:16.454Z", "isAdmin": false, "displayName": "wattsd"}, "userId": "5orQJ57owKabeCLJd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4GsrkRKCjn5ufhxkF/draft-productive-use-of-heuristics-and-biases", "pageUrlRelative": "/posts/4GsrkRKCjn5ufhxkF/draft-productive-use-of-heuristics-and-biases", "linkUrl": "https://www.lesswrong.com/posts/4GsrkRKCjn5ufhxkF/draft-productive-use-of-heuristics-and-biases", "postedAtFormatted": "Sunday, August 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BDraft%5D%20Productive%20Use%20of%20Heuristics%20and%20Biases&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BDraft%5D%20Productive%20Use%20of%20Heuristics%20and%20Biases%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GsrkRKCjn5ufhxkF%2Fdraft-productive-use-of-heuristics-and-biases%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BDraft%5D%20Productive%20Use%20of%20Heuristics%20and%20Biases%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GsrkRKCjn5ufhxkF%2Fdraft-productive-use-of-heuristics-and-biases", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GsrkRKCjn5ufhxkF%2Fdraft-productive-use-of-heuristics-and-biases", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2135, "htmlBody": "<p><span id=\"internal-source-marker_0.7764104789402906\" style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">The main point</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">If  we are naturally biased and limited in how rational our decision making  can be, it might be more effective to improve intuition and manage  biases rather than trying to completely eliminate them and focus on  unbiased thinking. I&rsquo;m not advocating irrationality, instead I&rsquo;m  interested in how to deal with bounded rationality. How can we improve  our ability to satisfice? How can we productively use and develop our  intuition? </span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Caveats</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">While  I intend for this post to be informative, it may not be, and I suspect  I&rsquo;ll learn more from writing it and feedback than others will get from  reading it. There is much on LessWrong I haven&rsquo;t read, so I apologize if  this is something that was discussed extensively before. If that is the  case, I&rsquo;d appreciate links to those discussions in the comments. One  other note, I realize intuition can be interpreted as a dirty word, with  good reason. Here, please interpret intuition as a rational heuristic  guided by experience. Heuristics are tools, they can be effective when  used properly. </span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Background</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">This  post was prompted by some casual research on expertise and  decisionmaking I've been doing for a couple months now. Along the way I  came across the work of Herbert Simon and Gary Klein. Simon&rsquo;s ideas of  bounded rationality and satisficing have come up in discussion here  before, but I haven&rsquo;t seen any discussion of Klein, who is an active  researcher in the area of intuitive decisionmaking. Simon proposes that  rationality in decisionmaking is limited by the constraints of time,  available information, and brain/computational capabilities (bounded  rationality). Rather than make perfectly rational decisions, we make the  best decisions we can given those constraints (satisficing). Klein&rsquo;s  work is primarily focused on how experts actually make decisions in the  real world. Put another way, his work is focused on how experts  satisfice.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">One  of Klein&rsquo;s early research projects was to help the military improve  decision making. His proposal was to study firefighters, figuring their  experience would be a useful analog to military experience (high  pressure, life/death, time...). The major finding was that they did not  follow the standard model of good decision making, they did not evaluate  multiple options. Instead, they believed they operated by feel.  Generally, the firefighters had one option they were considering. After  further dialogue, Klein realized that they were forming mental models of  the situations based on recognition/experience, which he calls  recognition primed decision making. Using those mental models, they  would mentally simulate what might occur if they followed their first  instinct and go from there. A similar process was seen in other areas of  expertise as well. For example, expert chess players aren&rsquo;t evaluating  more options or seeing farther ahead than novices, they just have better  recognition/heuristics that are developed through experience. One  potential problem with using chess as an analog for other skills is that  the rules are clearly defined, all of the information you need is on  the board (or in your opponent&rsquo;s head...). The real world isn&rsquo;t quite so  clean, which which might imply that rationality is generally more  limited/bounded than in the case of chess.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">From  what I&rsquo;ve been reading, I guess I&rsquo;m skeptical about efforts to be more  rational in everyday life. Certainly it is possible, but it may be  unnatural enough to be impractical. Even then, it will still be bounded.  If this is the case, it might be more effective to train in some mix of  intuitive and rational decisionmaking, while understanding the limits  of both. While I haven&rsquo;t read it yet, I think Daniel Kahneman refers to  intuition and rationality as system 1 and 2 in &ldquo;Thinking Fast and Slow&rdquo;.  While Kahneman has seemed skeptical of our ability to improve decision  making and reduce bias in the interviews I&rsquo;ve read, Klein is a bit more  optimistic.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Methods for improving intuition I&rsquo;ve found so far </span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">(1-5 from Klein/Fadde - Deliberate Performance, 6-7 from Klein - The Power of Intuition)</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Intuition  comes from experience/expertise. Expertise is developed through  deliberate practice. The methods here are intended to accelerate the  learning process.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">1. Estimation</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">This  is fairly simple, estimate something and compare to reality. How long  do you expect a project to take? Think through it and discuss with  others, and record your estimate and reasoning. Later, after you&rsquo;ve  completed the project, go back and look at your prediction. Where did  you go wrong?</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">One  of the keys to effective and efficient learning is timely feedback. If  your project will last months, you&rsquo;ll probably want to do other  estimates in the meantime, preferably with tighter feedback loops. An  example given in the paper is giving a presentation. How long do you  expect discussion to take on each point? What questions will be asked?  After the presentation, compare the prediction to reality. For what it&rsquo;s  worth, I believe Peter Drucker also recommends something similar in his  article &ldquo;Managing Oneself&rdquo;. If I remember correctly, Drucker recommends  keeping a decision journal, where you record the decisions you make and  return later to see what you got right or wrong (and why).</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">2. Extrapolation</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">In  &ldquo;Sources of Power&rdquo;, Klein discusses an example of extrapolation.  Engineers are trying to estimate the cost and time it takes to build  various components of airplanes that haven&rsquo;t yet been built. Since the  parts don&rsquo;t yet exist in some cases, they need to find a way to provide  reasonable estimates. To do this, they try to find an analog. Are there  any parts that are similar? How long did they take to produce and how  much did they cost? It may take combining several analogs to come up  with an estimate. The idea is to use what you have and know to model  what you don&rsquo;t have and know. Again, compare the extrapolation to the  actual results when you are able to do so, so you can improve next time.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">3. Experimentation</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">At  its most basic, experimentation can be just trying something and seeing  what happens. A better way is to form a hypothesis  (estimation/prediction/extrapolation) prior to trying.This promotes  better learning, because you have a concrete expectation that is either  verified or not. If not, you&rsquo;ve learned something new. Perhaps you&rsquo;ll  even be surprised, and surprises can lead you in new directions.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">A  more personal example: For the longest time, I had trouble with  directions where I currently live. I&rsquo;d look at a map, figure out how to  get somewhere, and try not to vary things too much so I wouldn&rsquo;t get  lost. I rapidly improved by using a GPS, and ignoring it until I needed  it. I&rsquo;d have an idea of how to get there (from looking at maps), but I  wouldn&rsquo;t have it down 100% or I&rsquo;d try to improvise. The GPS allowed me  to experiment without the risk of getting lost, and it provided instant  feedback.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">4. Explanation</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">This  section is rather short, so I am not entirely sure if I understand it  correctly. I think the intent is to try to make sense of what you&rsquo;ve  seen and learned from the other three Es.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">One way to do this might be to use what Scott Young calls the Feynman Technique (</span><a href=\"http://www.scotthyoung.com/blog/2011/09/01/learn-faster/\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">Learn Faster with the Feynman Technique</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">):</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Step 1. Choose the concept you want to understand.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Take a blank piece of paper and write that concept at the top of the page.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Step 2. Pretend you&rsquo;re teaching the idea to someone else.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Write  out an explanation of the topic, as if you were trying to teach it to a  new student. When you explain the idea this way you get a better idea  of what you understand and where you might have some gaps.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Step 3. If you get stuck, go back to the book.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Whenever  you get stuck, go back to the source material and re-learn that part of  the material until you get it enough that you can explain it on paper.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Step 4. Simplify your language.</span></p>\n<p style=\"margin-left: 36pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">The  goal is to use your words, not the words of the source material. If  your explanation is wordy or confusing, that&rsquo;s an indication that you  might not understand the idea as well as you thought &ndash; try to simplify  the language or create an analogy to better understand it.</span></p>\n<p><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">5. Feedback/Coaching (Emulation?)</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Feedback  is critical. While you might not have a coach at work, you can still  find someone to emulate. Assuming they are available for questions, you  can try to predict what they would do in a situation. When something  does not go as you&rsquo;d expect, explain your thinking and ask for feedback.  In my experience, other people are busy with their own work, so  coaching/mentorship takes a backseat to more urgent matters. Plus, some  people often just don&rsquo;t want to be bothered. In this case, I think the  best thing to do is to get good at asking effective questions and be  well prepared. </span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">6. Premortem</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"> Imagine results of what you are trying to do are a complete failure and  that you are now doing a post mortem to understand what went wrong.  What went wrong? The reasoning behind this technique is that people  don&rsquo;t want something to fail (or look like they want it to fail),  assuming it already has failed reduces that bias. Apparently the idea  for the technique came from Mitchell, Russo, and Pennington - &ldquo;Back to  the Future: Temporal Perspective in the Explanation of Events&rdquo;. That  paper doesn&rsquo;t entirely support the technique, stating that it produces  more reasons that are episodic, but not necessarily better (they were  unable to judge the value of the reasons given). Klein uses this  technique regularly in meetings, the general impression is that it  reduces confidence in the plan, as intended. From there, they try to  prepare for the potential problems. </span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">In a sense, this is similar to </span><a href=\"https://en.wikipedia.org/wiki/Red_team\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">red teams</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"> but easier to implement and less resource intensive.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">7. Identify Decisions/Decision Making Exercises/Decision Making Critiques</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">In  &ldquo;The Power of Intuition&rdquo;, Klein advocates identifying decisions where  problems have occurred. When reviewing the decisions, note what makes it  difficult, what kinds of errors are often made, how an expert might  approach it differently than a novice, and how the decision can be  practiced and you can get feedback. </span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Those  decisions are then turned into scenarios which can be repeatedly  practiced (typically in groups). Start with describing the events that  led to the decision. The players are then told what they are trying to  achieve, the context, and the constraints. Try to include a visual  representation whenever possible.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">After  the exercise, critique the decision and the process used to make it.  Start with a timeline and identify key judgments. For each of the key  judgments, note why it was difficult, how you were interpreting the  situation, what cues/patterns you should have been picking up, why you  chose to do what you did, and what you would&rsquo;ve done differently with  the benefit of hindsight.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Concluding thoughts</span><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Is  there interest in this topic on LW? I&rsquo;m not denying that relying on  intuition alone can be dangerous, but I am very skeptical that focusing  on reducing bias alone will lead to better decisions. In some cases, it  may be better to admit that biases are affecting a decision. One other  thing to note, is that bias and mistakes are inevitable. It seems a lot  of the LW rationality posts I&rsquo;ve seen focus on reducing or eliminating  these mistakes. That is certainly a valid goal (at least the reduction  is), but it isn&rsquo;t enough. Choice/information overload can affect  decisions, as can blood sugar levels (</span><a href=\"http://www.psychologicalscience.org/media/releases/2010/wang.cfm\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">Sweet Future: Fluctuating Blood Glucose Levels May Affect Decision Making</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">) and having to go to the bathroom (</span><a href=\"http://www.econ.kuleuven.be/public/ndbaa53/tuk-trampe-warlop-PSc-2011.pdf\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">Tuk  M. et al. (2011). Inhibitory Spillover: Increased Urination Urgency  Facilitates Impulse Control in Unrelated Domains. Psychological Science.</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">).</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Mistakes  will happen, so you&rsquo;ll have to do your best to learn from them and  reduce their cost/make recovery easier. At the same time, good  heuristics give you a better starting point to apply the rationality  techniques. They are complementary. Worry about reducing bias after you have  come up with something using expertise/intuition.</span><br /><br /><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Again,  this is a draft, written mostly from memory of what I&rsquo;ve been reading.  The primary sources were &ldquo;Sources of Power&rdquo; and &ldquo;The Power of Intuition&rdquo;  (both by Klein), &ldquo;The Cambridge Handbook of Expertise&rdquo;, and scattered  readings on/by Simon. Also of interest are this </span><a href=\"http://www.mckinseyquarterly.com/Strategy/Strategic_Thinking/Strategic_decisions_When_can_you_trust_your_gut_2557?gp=1\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">interview with Daniel Kahneman and Gary Klein</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"> (free registration required unfortunately) and this paper on </span><a href=\"http://peterfadde.com/Research/Deliberate_Performance-PI-1011.pdf\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline;\">deliberate performance</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"> by Peter Fadde and Klein.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4GsrkRKCjn5ufhxkF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 9.72823552994898e-07, "legacy": true, "legacyId": "18471", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-26T22:40:20.388Z", "modifiedAt": null, "url": null, "title": "Decision Theories, Part 3.5: Halt, Melt and Catch Fire", "slug": "decision-theories-part-3-5-halt-melt-and-catch-fire", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.116Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ShD7EHb4HmPgfveim/decision-theories-part-3-5-halt-melt-and-catch-fire", "pageUrlRelative": "/posts/ShD7EHb4HmPgfveim/decision-theories-part-3-5-halt-melt-and-catch-fire", "linkUrl": "https://www.lesswrong.com/posts/ShD7EHb4HmPgfveim/decision-theories-part-3-5-halt-melt-and-catch-fire", "postedAtFormatted": "Sunday, August 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Decision%20Theories%2C%20Part%203.5%3A%20Halt%2C%20Melt%20and%20Catch%20Fire&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecision%20Theories%2C%20Part%203.5%3A%20Halt%2C%20Melt%20and%20Catch%20Fire%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShD7EHb4HmPgfveim%2Fdecision-theories-part-3-5-halt-melt-and-catch-fire%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Decision%20Theories%2C%20Part%203.5%3A%20Halt%2C%20Melt%20and%20Catch%20Fire%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShD7EHb4HmPgfveim%2Fdecision-theories-part-3-5-halt-melt-and-catch-fire", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FShD7EHb4HmPgfveim%2Fdecision-theories-part-3-5-halt-melt-and-catch-fire", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1391, "htmlBody": "<p><strong>Followup to:</strong> <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Decision Theories: A Semi-Formal Analysis, Part III</a></p>\n<p><strong><span style=\"color: #ff0000;\">UPDATE:</span> As it turns out, rumors of Masquerade's demise seem to have been greatly exaggerated. See <a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">this post</a> for details and proofs!</strong></p>\n<p>I had the chance, over the summer, to discuss the decision theory outlined in <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">my April post</a> with a bunch of relevantly awesome people. The sad part is, <strong>there turned out to be a fatal flaw </strong>once we tried to formalize it properly. I'm laying it out here, not with much hope that there's a fix, but because <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.3404\">sometimes false starts can be productive for others</a>.</p>\n<p>Since it's not appropriate to call this decision theory TDT, I'm going to use a name suggested in one of these sessions and call it \"Masquerade\", which might be an intuition pump for how it operates. So let's first define some simple agents called \"masks\", and then define the \"Masquerade\" agent.</p>\n<p>Say that our agent has actions <em>a<sub>1</sub></em>, ... , <em>a<sub>n</sub></em>, and the agent it's facing in this round has actions <em>b<sub>1</sub></em>, ... , <em>b<sub>m</sub></em>. Then for any triple (<em>b<sub>i</sub></em>, <em>a<sub>j</sub></em>, <em>a<sub>k</sub></em>), we can define a simple agent Mask<em><sub>ijk</sub></em> which takes in its opponent's source code and outputs an action:</p>\n<pre>def Mask_ijk(opp_src):<br /> look for proof that Opp(Mask_ijk) = <em>b<sub>i</sub></em><br /> if one is found, then output <em>a<sub>j</sub></em><br /> otherwise, output <em>a<sub>k</sub></em><br /></pre>\n<p>(This is slightly less general than what I outlined in my post, but it'll do for our purposes. Note that there's no need for <em>a<sub>j</sub></em> and <em>a<sub>k</sub></em> to be distinct, so constant strategies fall under this umbrella as well.)</p>\n<p>A key example of such an agent is what we might call FairBot: on a Prisoner's Dilemma, FairBot tries to prove that the other agent cooperates against FairBot, and if it finds such a proof, then it immediately cooperates. If FairBot fails to find such a proof, then it defects. (An important point is that if FairBot plays against itself and both have sufficiently strong deductive capacities, then a short proof of one's cooperation gives a slightly longer proof of the other's cooperation, and thus in the right circumstances we have mutual cooperation via L&ouml;b's Theorem.)</p>\n<p>The agent Masquerade tries to do better than any individual mask (note that FairBot foolishly cooperates against CooperateBot when it could trivially do better by defecting). My original formulation can be qualitatively described as trying on different masks, seeing which one fares the best, and then running a \"sanity check\" to see if the other agent treats Masquerade the same way it treats that mask. The pseudocode looked like this:</p>\n<pre>def Masquerade(opp_src):<br /> for each (i,j,k), look for proofs of the form \"Mask_ijk gets utility <em>u</em> against Opp\"<br /> choose (i,j,k) corresponding to the largest such <em>u</em> found<br /> look for proof that Opp(Masquerade) = Opp(Mask_ijk)<br /> if one is found, then output the same thing as Mask_ijk(Opp)<br /> otherwise, output a default action<br /></pre>\n<p>(The default should be something safe like a Nash equilibrium strategy, of course.)</p>\n<p>Intuitively, when Masquerade plays the Prisoner's Dilemma against FairBot, Masquerade finds that the best utility against FairBot is achieved by some mask that cooperates, and then Masquerade's sanity-check is trying to prove that FairBot(Masquerade) = C as FairBot is trying to prove that Masquerade(FairBot) = C, and the whole L&ouml;bian circus goes round again. Furthermore, it's intuitive that when Masquerade plays against another Masquerade, the first one notices the proof of the above, and finds that the best utility against the other Masquerade is achieved by FairBot; thus both pass to the sanity-check stage trying to imitate FairBot, both seek to prove that the other cooperate against themselves, and both find the L&ouml;bian proof.</p>\n<p>So what's wrong with this intuitive reasoning?</p>\n<h3>Problem: A deductive system can't count on its own consistency!</h3>\n<p>Let's re-examine the argument that Masquerade cooperates with FairBot. In order to set up the L&ouml;bian circle, FairBot needs to be able to prove that Masquerade selects a mask that cooperates with FairBot (like CooperateBot or FairBot). There are nice proofs that each of those masks attains the mutual-cooperation payoff against FairBot, but we also need to be sure that some other mask won't get the very highest (I defect, you cooperate) payoff against FairBot. Now you and I can see that this must be true, because FairBot simply can't be exploited that way. But crucially, <em>FairBot can't deduce its own inexploitability</em> without thereby becoming exploitable (for the same G&ouml;delian reason that a formal system can't prove its own consistency unless it is actually inconsistent)!</p>\n<p>Now, the caveats to this are important: if FairBot's deductive process is sufficiently stronger than the deductive process that's trying to exploit it (for example, FairBot might have an oracle that can answer questions about Masquerade's oracle, or FairBot might look for proofs up to length 2<sup>N</sup> while Masquerade only looks up to length N), then it can prove (by exhaustion if nothing else) that Masquerade will select a cooperative mask after all. But since Masquerade needs to reason about Masquerade at this level, this approach goes nowhere. (At first, I thought that having a weaker oracle for Masquerade's search through masks, and a stronger oracle both for each mask and for Masquerade's sanity-check, would solve this. But that doesn't get off the ground: the agent thus defined attains mutual cooperation with FairBot, but not with itself, because the weaker oracle can't prove that it attains mutual cooperation with FairBot.)</p>\n<p>Another caveat is the following: FairBot may not be able to rule out the provability of some statement we know is false, but (given a large enough deductive capacity) it can prove that a certain result is the first of its kind in a given ordering of proofs. So if our agents act immediately on the first proof they find, then we could make a version of Masquerade work... as long as each search <em>does</em> find a proof, and as long as <em>that</em> fact is provable by the same deduction system. But there's an issue with this: two masks paired against each other won't necessarily have provable outcomes!</p>\n<p>Let's consider the following mask agent, which we'll call AntiFairBot: it searches for a proof that its opponent cooperates against it, and it <em>defects</em> if it finds one; if it doesn't find such a proof, then it <em>cooperates</em>. This may not be a very optimal agent, but it has one interesting property: if you pit AntiFairBot against FairBot, and the two of them use equivalent oracles, then it takes an oracle stronger than either to deduce what the two of them will do! Thus, Masquerade can't be sure that AntiFairBot won't get the highest payoff against FairBot (which of course it won't) unless it uses a stronger deduction system for the search through masks than FairBot uses for its proof search (which would mean that FairBot won't be able to tell what mask Masquerade picks).</p>\n<p>I tried to fix this by iterating over only some of the masks; after all, there's no realistic opponent against whom AntiFairBot is superior to both FairBot and DefectBot. Unfortunately, at this point I realized two things: in order to play successfully against a reasonable range of opponents on the Prisoner's Dilemma, <strong>Masquerade needs to be able to imitate at least both FairBot and DefectBot</strong>; and <strong>FairBot cannot prove that FairBot defects against DefectBot</strong>. (There are variants of FairBot that <em>can</em> do so, e.g. it could search both for proofs of cooperation and proofs of defection and playing symmetrically if it finds one, but this variant is no longer guaranteed to cooperate against itself!)</p>\n<p>If there are any problems with this reasoning, or an obvious fix that I've missed, please bring it to my attention; but otherwise, I've decided that my approach has failed drastically enough that it's time to do what Eliezer calls <a href=\"/lw/ue/the_magnitude_of_his_own_folly/\">\"halt, melt, and catch fire\"</a>. The fact that L&ouml;bian cooperation works is enough to keep me optimistic about formalizing this side of decision theory in general, but the ideas I was using seem insufficient to succeed. (Some variant of \"playing chicken with my deductive system\" might be a crucial component.)</p>\n<p>Many thanks to all of the excellent people who gave their time and attention to this idea, both on and offline, especially Eliezer, Vladimir Slepnev, Nisan, Paul Christiano, Critch, Alex Altair, Misha Barasz, and Vladimir Nesov. Special kudos to Vladimir Slepnev, whose gut intuition on the problem with this idea was immediate and correct.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ShD7EHb4HmPgfveim", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 49, "extendedScore": null, "score": 9.72959693692499e-07, "legacy": true, "legacyId": "18472", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Followup to:</strong> <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Decision Theories: A Semi-Formal Analysis, Part III</a></p>\n<p><strong id=\"UPDATE__As_it_turns_out__rumors_of_Masquerade_s_demise_seem_to_have_been_greatly_exaggerated__See_this_post_for_details_and_proofs_\"><span style=\"color: #ff0000;\">UPDATE:</span> As it turns out, rumors of Masquerade's demise seem to have been greatly exaggerated. See <a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">this post</a> for details and proofs!</strong></p>\n<p>I had the chance, over the summer, to discuss the decision theory outlined in <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">my April post</a> with a bunch of relevantly awesome people. The sad part is, <strong>there turned out to be a fatal flaw </strong>once we tried to formalize it properly. I'm laying it out here, not with much hope that there's a fix, but because <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.3404\">sometimes false starts can be productive for others</a>.</p>\n<p>Since it's not appropriate to call this decision theory TDT, I'm going to use a name suggested in one of these sessions and call it \"Masquerade\", which might be an intuition pump for how it operates. So let's first define some simple agents called \"masks\", and then define the \"Masquerade\" agent.</p>\n<p>Say that our agent has actions <em>a<sub>1</sub></em>, ... , <em>a<sub>n</sub></em>, and the agent it's facing in this round has actions <em>b<sub>1</sub></em>, ... , <em>b<sub>m</sub></em>. Then for any triple (<em>b<sub>i</sub></em>, <em>a<sub>j</sub></em>, <em>a<sub>k</sub></em>), we can define a simple agent Mask<em><sub>ijk</sub></em> which takes in its opponent's source code and outputs an action:</p>\n<pre>def Mask_ijk(opp_src):<br> look for proof that Opp(Mask_ijk) = <em>b<sub>i</sub></em><br> if one is found, then output <em>a<sub>j</sub></em><br> otherwise, output <em>a<sub>k</sub></em><br></pre>\n<p>(This is slightly less general than what I outlined in my post, but it'll do for our purposes. Note that there's no need for <em>a<sub>j</sub></em> and <em>a<sub>k</sub></em> to be distinct, so constant strategies fall under this umbrella as well.)</p>\n<p>A key example of such an agent is what we might call FairBot: on a Prisoner's Dilemma, FairBot tries to prove that the other agent cooperates against FairBot, and if it finds such a proof, then it immediately cooperates. If FairBot fails to find such a proof, then it defects. (An important point is that if FairBot plays against itself and both have sufficiently strong deductive capacities, then a short proof of one's cooperation gives a slightly longer proof of the other's cooperation, and thus in the right circumstances we have mutual cooperation via L\u00f6b's Theorem.)</p>\n<p>The agent Masquerade tries to do better than any individual mask (note that FairBot foolishly cooperates against CooperateBot when it could trivially do better by defecting). My original formulation can be qualitatively described as trying on different masks, seeing which one fares the best, and then running a \"sanity check\" to see if the other agent treats Masquerade the same way it treats that mask. The pseudocode looked like this:</p>\n<pre>def Masquerade(opp_src):<br> for each (i,j,k), look for proofs of the form \"Mask_ijk gets utility <em>u</em> against Opp\"<br> choose (i,j,k) corresponding to the largest such <em>u</em> found<br> look for proof that Opp(Masquerade) = Opp(Mask_ijk)<br> if one is found, then output the same thing as Mask_ijk(Opp)<br> otherwise, output a default action<br></pre>\n<p>(The default should be something safe like a Nash equilibrium strategy, of course.)</p>\n<p>Intuitively, when Masquerade plays the Prisoner's Dilemma against FairBot, Masquerade finds that the best utility against FairBot is achieved by some mask that cooperates, and then Masquerade's sanity-check is trying to prove that FairBot(Masquerade) = C as FairBot is trying to prove that Masquerade(FairBot) = C, and the whole L\u00f6bian circus goes round again. Furthermore, it's intuitive that when Masquerade plays against another Masquerade, the first one notices the proof of the above, and finds that the best utility against the other Masquerade is achieved by FairBot; thus both pass to the sanity-check stage trying to imitate FairBot, both seek to prove that the other cooperate against themselves, and both find the L\u00f6bian proof.</p>\n<p>So what's wrong with this intuitive reasoning?</p>\n<h3 id=\"Problem__A_deductive_system_can_t_count_on_its_own_consistency_\">Problem: A deductive system can't count on its own consistency!</h3>\n<p>Let's re-examine the argument that Masquerade cooperates with FairBot. In order to set up the L\u00f6bian circle, FairBot needs to be able to prove that Masquerade selects a mask that cooperates with FairBot (like CooperateBot or FairBot). There are nice proofs that each of those masks attains the mutual-cooperation payoff against FairBot, but we also need to be sure that some other mask won't get the very highest (I defect, you cooperate) payoff against FairBot. Now you and I can see that this must be true, because FairBot simply can't be exploited that way. But crucially, <em>FairBot can't deduce its own inexploitability</em> without thereby becoming exploitable (for the same G\u00f6delian reason that a formal system can't prove its own consistency unless it is actually inconsistent)!</p>\n<p>Now, the caveats to this are important: if FairBot's deductive process is sufficiently stronger than the deductive process that's trying to exploit it (for example, FairBot might have an oracle that can answer questions about Masquerade's oracle, or FairBot might look for proofs up to length 2<sup>N</sup> while Masquerade only looks up to length N), then it can prove (by exhaustion if nothing else) that Masquerade will select a cooperative mask after all. But since Masquerade needs to reason about Masquerade at this level, this approach goes nowhere. (At first, I thought that having a weaker oracle for Masquerade's search through masks, and a stronger oracle both for each mask and for Masquerade's sanity-check, would solve this. But that doesn't get off the ground: the agent thus defined attains mutual cooperation with FairBot, but not with itself, because the weaker oracle can't prove that it attains mutual cooperation with FairBot.)</p>\n<p>Another caveat is the following: FairBot may not be able to rule out the provability of some statement we know is false, but (given a large enough deductive capacity) it can prove that a certain result is the first of its kind in a given ordering of proofs. So if our agents act immediately on the first proof they find, then we could make a version of Masquerade work... as long as each search <em>does</em> find a proof, and as long as <em>that</em> fact is provable by the same deduction system. But there's an issue with this: two masks paired against each other won't necessarily have provable outcomes!</p>\n<p>Let's consider the following mask agent, which we'll call AntiFairBot: it searches for a proof that its opponent cooperates against it, and it <em>defects</em> if it finds one; if it doesn't find such a proof, then it <em>cooperates</em>. This may not be a very optimal agent, but it has one interesting property: if you pit AntiFairBot against FairBot, and the two of them use equivalent oracles, then it takes an oracle stronger than either to deduce what the two of them will do! Thus, Masquerade can't be sure that AntiFairBot won't get the highest payoff against FairBot (which of course it won't) unless it uses a stronger deduction system for the search through masks than FairBot uses for its proof search (which would mean that FairBot won't be able to tell what mask Masquerade picks).</p>\n<p>I tried to fix this by iterating over only some of the masks; after all, there's no realistic opponent against whom AntiFairBot is superior to both FairBot and DefectBot. Unfortunately, at this point I realized two things: in order to play successfully against a reasonable range of opponents on the Prisoner's Dilemma, <strong>Masquerade needs to be able to imitate at least both FairBot and DefectBot</strong>; and <strong>FairBot cannot prove that FairBot defects against DefectBot</strong>. (There are variants of FairBot that <em>can</em> do so, e.g. it could search both for proofs of cooperation and proofs of defection and playing symmetrically if it finds one, but this variant is no longer guaranteed to cooperate against itself!)</p>\n<p>If there are any problems with this reasoning, or an obvious fix that I've missed, please bring it to my attention; but otherwise, I've decided that my approach has failed drastically enough that it's time to do what Eliezer calls <a href=\"/lw/ue/the_magnitude_of_his_own_folly/\">\"halt, melt, and catch fire\"</a>. The fact that L\u00f6bian cooperation works is enough to keep me optimistic about formalizing this side of decision theory in general, but the ideas I was using seem insufficient to succeed. (Some variant of \"playing chicken with my deductive system\" might be a crucial component.)</p>\n<p>Many thanks to all of the excellent people who gave their time and attention to this idea, both on and offline, especially Eliezer, Vladimir Slepnev, Nisan, Paul Christiano, Critch, Alex Altair, Misha Barasz, and Vladimir Nesov. Special kudos to Vladimir Slepnev, whose gut intuition on the problem with this idea was immediate and correct.</p>", "sections": [{"title": "UPDATE: As it turns out, rumors of Masquerade's demise seem to have been greatly exaggerated. See this post for details and proofs!", "anchor": "UPDATE__As_it_turns_out__rumors_of_Masquerade_s_demise_seem_to_have_been_greatly_exaggerated__See_this_post_for_details_and_proofs_", "level": 2}, {"title": "Problem: A deductive system can't count on its own consistency!", "anchor": "Problem__A_deductive_system_can_t_count_on_its_own_consistency_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "35 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AMwzjjvFxEgxvL7xe", "X9vT3o3MmtWoRRKkm", "fLRPeXihRaiRo5dyX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T00:04:37.740Z", "modifiedAt": null, "url": null, "title": "Stupid Questions Open Thread Round 4", "slug": "stupid-questions-open-thread-round-4", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:33.295Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/o8HdqT8uWvgBtThSE/stupid-questions-open-thread-round-4", "pageUrlRelative": "/posts/o8HdqT8uWvgBtThSE/stupid-questions-open-thread-round-4", "linkUrl": "https://www.lesswrong.com/posts/o8HdqT8uWvgBtThSE/stupid-questions-open-thread-round-4", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stupid%20Questions%20Open%20Thread%20Round%204&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStupid%20Questions%20Open%20Thread%20Round%204%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo8HdqT8uWvgBtThSE%2Fstupid-questions-open-thread-round-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stupid%20Questions%20Open%20Thread%20Round%204%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo8HdqT8uWvgBtThSE%2Fstupid-questions-open-thread-round-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo8HdqT8uWvgBtThSE%2Fstupid-questions-open-thread-round-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 152, "htmlBody": "<p><small>Previously: <a href=\"/r/discussion/lw/932/stupid_questions_open_thread/\">round 1</a>, <a href=\"/lw/bws/stupid_questions_open_thread_round_2/\">round 2</a>, <a href=\"/lw/dhd/stupid_questions_open_thread_round_3/\">round 3</a></small></p>\n<p>From the <a href=\"/r/discussion/lw/932/stupid_questions_open_thread/\">original thread</a>:</p>\n<blockquote>\n<p>This is for anyone in the LessWrong community who has made at least some effort to read the sequences and follow along, but is still confused on some point, and is perhaps feeling a bit embarrassed. Here, newbies and not-so-newbies are free to ask very basic but still relevant questions with the understanding that the answers are probably somewhere in the sequences. Similarly, LessWrong tends to presume a rather high threshold for understanding science and technology. Relevant questions in those areas are welcome as well. &nbsp;Anyone who chooses to respond should respectfully guide the questioner to a helpful resource, and questioners should be appropriately grateful. Good faith should be presumed on both sides, unless and until it is shown to be absent. &nbsp;If a questioner is not sure whether a question is relevant, ask it, and also ask if it's relevant.</p>\n</blockquote>\n<p>Ask away!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "o8HdqT8uWvgBtThSE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 9.730018762535496e-07, "legacy": true, "legacyId": "18475", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 181, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8dijcs9BjxaXE2A9G", "s9exm8K8CHkEGtiPC", "DqMDZ6zHJwPgw44BY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T03:36:08.152Z", "modifiedAt": null, "url": null, "title": "The noncentral fallacy - the worst argument in the world?", "slug": "the-noncentral-fallacy-the-worst-argument-in-the-world", "viewCount": null, "lastCommentedAt": "2021-09-19T02:42:57.311Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world", "pageUrlRelative": "/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world", "linkUrl": "https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20noncentral%20fallacy%20-%20the%20worst%20argument%20in%20the%20world%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20noncentral%20fallacy%20-%20the%20worst%20argument%20in%20the%20world%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWPkLi8wJvewPbEp%2Fthe-noncentral-fallacy-the-worst-argument-in-the-world%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20noncentral%20fallacy%20-%20the%20worst%20argument%20in%20the%20world%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWPkLi8wJvewPbEp%2Fthe-noncentral-fallacy-the-worst-argument-in-the-world", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWPkLi8wJvewPbEp%2Fthe-noncentral-fallacy-the-worst-argument-in-the-world", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2143, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/lc/leaky_generalizations/\">Leaky Generalizations</a>, <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">Replace the Symbol With The Substance</a>, <a href=\"/lw/ny/sneaking_in_connotations/\">Sneaking In Connotations</a></p>\n<p>David Stove once <a href=\"http://web.maths.unsw.edu.au/~jim/worst.html\">ran a contest</a> to find the Worst Argument In The World, but he awarded the prize to his own entry, and one that shored up his politics to boot. It hardly seems like an objective process.<br /><br />If he can unilaterally declare a Worst Argument, then so can I. I declare the Worst Argument In The World to be this: \"X is in a category whose archetypal member gives us a certain emotional reaction. Therefore, we should apply that emotional reaction to X, even though it is not a central category member.\"<br /><br />Call it the Noncentral Fallacy. It sounds dumb when you put it like that. Who even does that, anyway?<br /><br />It sounds dumb only because we are talking soberly of categories and features. As soon as the argument gets framed in terms of <em>words</em>, it becomes so powerful that somewhere between many and most of the bad arguments in politics, philosophy and culture take some form of the noncentral fallacy. Before we get to those, let's look at a simpler example.<br /><br />Suppose someone wants to build a statue honoring Martin Luther King Jr. for his nonviolent resistance to racism. An opponent of the statue objects: \"But Martin Luther King was a <em>criminal</em>!\"<br /><br />Any historian can confirm this is correct. A criminal is technically someone who breaks the law, and King knowingly broke a law against peaceful anti-segregation protest - hence his famous Letter from Birmingham Jail.<br /><br />But in this case calling Martin Luther King a criminal is the noncentral. The archetypal criminal is a mugger or bank robber. He is driven only by greed, preys on the innocent, and weakens the fabric of society. Since we don't like these things, calling someone a \"criminal\" naturally lowers our opinion of them. <br /><br />The opponent is saying \"Because you don't like criminals, and Martin Luther King is a criminal, you should stop liking Martin Luther King.\" But King doesn't share the important criminal features of being driven by greed, preying on the innocent, or weakening the fabric of society that made us dislike criminals in the first place. Therefore, even though he is a criminal, there is no reason to dislike King.</p>\n<p>This all seems so nice and logical when it's presented in this format. Unfortunately, it's also one hundred percent contrary to instinct: the urge is to respond \"Martin Luther King? A criminal? No he wasn't! You take that back!\" This is why the noncentral is so successful. As soon as you do that you've fallen into their trap. Your argument is no longer about whether you should build a statue, it's about whether King was a criminal. Since he was, you have now lost the argument.<br /><br />Ideally, you should just be able to say \"Well, King was the good kind of criminal.\" But that seems pretty tough as a debating maneuver, and it may be even harder in some of the cases where the noncentral Fallacy is commonly used.</p>\n<p><a id=\"more\"></a><br />Now I want to list some of these cases. Many will be political<sup>1</sup>, <a href=\"/lw/gw/politics_is_the_mindkiller/\">for which I apologize</a>, but it's hard to separate out a bad argument from its specific instantiations. None of these examples are meant to imply that the position they support is wrong (and in fact I myself hold some of them). They only show that certain particular arguments for the position are flawed, such as: <br /><br /><strong>\"Abortion is <em>murder</em>!\"</strong> The archetypal murder is Charles Manson breaking into your house and shooting you. This sort of murder is bad for a number of reasons: you prefer not to die, you have various thoughts and hopes and dreams that would be snuffed out, your family and friends would be heartbroken, and the rest of society has to live in fear until Manson gets caught. If you define murder as \"killing another human being\", then abortion is technically murder. But it has none of the downsides of murder Charles Manson style. Although you can criticize abortion for many reasons, insofar as \"abortion is murder\" is an invitation to apply one's feelings in the Manson case directly to the abortion case, it <a href=\"/lw/4p7/blues_greens_and_abortion/3muj\">ignores</a> the latter's lack of the features that generated those intuitions in the first place<sup>2</sup>.<br /><br />\"<strong>Genetic engineering to cure diseases is <em>eugenics</em>!</strong>\" Okay, you've got me there: since eugenics means \"trying to improve the gene pool\" that's clearly right. But what's wrong with eugenics? \"What's wrong with eugenics? Hitler did eugenics! Those unethical scientists in the 1950s who sterilized black women without their consent did eugenics!\" \"And what was wrong with what Hitler and those unethical scientists did?\" \"What do you mean, what was wrong with them? Hitler killed millions of people! Those unethical scientists ruined people's lives.\" \"And does using genetic engineering to cure diseases kill millions of people, or ruin anyone's life?\" \"Well...not really.\" \"Then what's wrong with it?\" \"It's <em>eugenics</em>!\"<br /><br /><strong>\"Evolutionary psychology is <em>sexist</em>!\"</strong> If you define \"sexist\" as \"believing in some kind of difference between the sexes\", this is true of at least some evo psych. For example, <a href=\"http://en.wikipedia.org/wiki/Bateman%27s_principle\">Bateman's Principle</a> states that in species where females invest more energy in producing offspring, mating behavior will involve males pursuing females; this posits a natural psychological difference between the sexes. \"Right, so you admit it's sexist!\" \"And why exactly is sexism bad?\" \"Because sexism claims that men are better than women and that women should have fewer rights!\" \"Does Bateman's principle claim that men are better than women, or that women should have fewer rights?\" \"Well...not really.\" \"Then what's wrong with it?\" \"It's <em>sexist!\"</em><br /><br />A second, subtler use of the noncentral fallacy goes like this: \"X is in a category whose archetypal member gives us an emotional reaction. Therefore, we should apply that same emotional reaction to X even if X gives some benefit that outweighs the harm.\"</p>\n<p><strong>\"Capital punishment is <em>murder</em>!\"</strong> Charles Manson-style murder is solely harmful. This kind of murder produces really strong negative feelings. The proponents of capital punishment believe that it might decrease crime, or have some other attending benefits. In other words, they believe it's \"the good kind of murder\"<sup>3</sup>, just like the introductory example concluded that Martin Luther King was \"the good kind of criminal\". But since normal murder is so taboo, it's really hard to take the phrase \"the good kind of murder\" seriously, and just mentioning the word \"murder\" can call up exactly the same amount of negative feelings we get from the textbook example.</p>\n<p><strong>\"Affirmative action is <em>racist</em>!\"</strong> True if you define racism  as \"favoring certain people based on their race\", but once again, our  immediate negative reaction to the archetypal example of racism (the Ku  Klux Klan) cannot be generalized to an immediate negative reaction to  affirmative action. Before we generalize it, we have to check first that  the problems that make us hate the Ku Klux Klan (violence, humiliation,  divisiveness, lack of a meritocratic society) are still there. Then,  even if we do find that some of the problems persist (like disruption of  meritocracy, for example) we have to prove that it doesn't produce  benefits that outweigh these harms.</p>\n<p>\"<strong>Taxation is <em>theft</em>!</strong>\" True if you define theft as \"taking someone else's money regardless of their consent\", but though the archetypal case of theft (breaking into someone's house and stealing their jewels) has nothing to recommend it, taxation (arguably) does. In the archetypal case, theft is both unjust and socially detrimental. Taxation keeps the first disadvantage, but arguably subverts the second disadvantage if you believe being able to fund a government has greater social value than leaving money in the hands of those who earned it. The question then hinges on the relative importance of these disadvantages. Therefore, you can't dismiss taxation without a second thought just because you have a natural disgust reaction to theft in general. You would also have to prove that the supposed benefits of this form of theft don't outweigh the costs.<br /><br />Now, because most arguments are rapid-fire debate-club style, sometimes it's still useful to say \"Taxation isn't theft!\" At least it beats saying \"Taxation is theft but nevertheless good\", then having the other side say \"Apparently my worthy opponent thinks that theft can be good; we here on this side would like to bravely take a stance <em>against</em> theft\", and then having the moderator call time before you can explain yourself. If you're in a debate club, do what you have to do. But if you have the luxury of philosophical clarity, you would do better to forswear the <a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">Dark Arts</a> and look a little deeper into what's going on.</p>\n<p>Are there ever cases in which this argument pattern can be useful? Yes. For example, it may be a groping attempt to suggest a <a href=\"http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CCAQFjAA&amp;url=http%3A%2F%2Flesswrong.com%2Flw%2Fase%2Fschelling_fences_on_slippery_slopes%2F&amp;ei=goBmUOiiMYHJiwKYuYCYDA&amp;usg=AFQjCNExjT9eBWdDHe-Z7Hea0nAD5z10Jg&amp;sig2=cdGSlHSwLHfCDZpIIUphpg\">Schelling fence</a>; for example, a principle that one must never commit theft even when it would be beneficial because that would make it harder to distinguish and oppose the really bad kinds of theft. Or it can be an attempt to spark conversation by pointing out a potential contradiction: for example \"Have you noticed that taxation really does contain some of the features you dislike about more typical instances of theft? Maybe you never even thought about that before? Why do your moral intuitions differ in these two cases? Aren't you being kind of hypocritical?\" But this usage seems pretty limited - once your interlocutor says \"Yes, I considered that, but the two situations are different for reasons X, Y, and Z\" the conversation needs to move on; there's not much point in continuing to insist \"But it's <em>theft</em>!\"</p>\n<p>But in most cases, I think this is more of an <em>emotional</em> argument, or even an argument from \"You would look silly saying that\". You really <em>can't</em> say \"Oh, he's the good kind of criminal\", and so if you have a potentially judgmental audience and not much time to explain yourself, you're pretty trapped. You have been forced to round to the archetypal example of that word and subtract exactly the information that's most relevant.<br /><br />But in all other cases, the proper response to being asked to subtract relevant information is \"No, why should I?\" - and that's why this is the worst argument in the world.</p>\n<p>&nbsp;</p>\n<p><strong>Footnotes</strong></p>\n<p><strong>1: </strong>On advice from the community, I have deliberately included three mostly-liberal examples and three-mostly conservative examples, so save yourself the trouble of counting them up and trying to speculate on this article's biases.</p>\n<p><strong>2: </strong>This should be distinguished from deontology, the belief that there is some provable moral principle about how you can never murder. I don't think this is <em>too</em> important a point to make, because only a tiny fraction of the people who debate these issues have thought that far ahead, and also because my personal and admittedly controversial opinion is that much of deontology is just an attempt to formalize and justify this fallacy.</p>\n<p><strong>3: </strong>Some people \"solve\" this problem by saying that \"murder\" only refers to \"non-lawful killing\", which is exactly as creative a solution as redefining \"criminal\" to mean \"person who breaks the law and is not Martin Luther King.\" Identifying the noncentral fallacy is a more complete solution: for example, it covers the related (mostly sarcastic) objection that \"imprisonment is kidnapping\".</p>\n<p><strong>4: </strong>EDIT 8/2013: I've edited this article a bit after getting some feedback and complaints. In particular I tried to remove some LW jargon which turned off some people who were being linked to this article but were unfamiliar with the rest of the site.</p>\n<p><strong>5: </strong>EDIT 8/2013: The other complaint I kept getting is that this is an uninteresting restatement of some other fallacy (no one can agree which, but <a href=\"http://en.wikipedia.org/wiki/Poisoning_the_well\">poisoning the well</a> comes up particularly often). The question doesn't seem too interesting to me - I never claimed particular originality, a lot of fallacies blend into each other, and the which-fallacy-is-which game isn't too exciting anyway - but for the record I don't think it is. Poisoning the well is a presentation of two different facts, such as \"Martin Luther King was a plagiarist...oh, by the way, what do you think of Martin Luther King's civil rights policies?\" It may have no relationship to categories, and it's usually something someone else does to you as a conscious rhetorical trick. Noncentral fallacy is presenting a single fact, but using category information to frame it in a misleading way - and it's often something people do to themselves. The above plagiarism example of poisoning the well is <em>not</em> noncentral fallacy. If you think this essay is about bog-standard poisoning the well, then either there is an alternative meaning to poisoning the well I'm not familiar with, or you are missing the point.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 8, "ZXFpyQWPB5ideFbEG": 1, "dJ6eJxJrCEget7Wb6": 5, "9DmA84e4ZvYoYu6q8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yCWPkLi8wJvewPbEp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 300, "baseScore": 331, "extendedScore": null, "score": 0.000707, "legacy": true, "legacyId": "18473", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "NHXY86jBahi968uW4", "canonicalCollectionSlug": "codex", "canonicalBookId": "jF58hKP9ZLzgy22Jr", "canonicalNextPostSlug": "ethnic-tension-and-meaningless-arguments", "canonicalPrevPostSlug": "the-categories-were-made-for-man-not-man-for-the-categories", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 332, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1756, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Tc2H9KbKRjuDJ3WSS", "GKfPL6LQFgB49FEnv", "yuKaWPRTxZoov4z8K", "9weLK2AJ9JEt2Tt8f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 15, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T05:02:10.135Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Consciousness", "slug": "meetup-west-la-meetup-consciousness", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5wfkHfHcrPYqc7wET/meetup-west-la-meetup-consciousness", "pageUrlRelative": "/posts/5wfkHfHcrPYqc7wET/meetup-west-la-meetup-consciousness", "linkUrl": "https://www.lesswrong.com/posts/5wfkHfHcrPYqc7wET/meetup-west-la-meetup-consciousness", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Consciousness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Consciousness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wfkHfHcrPYqc7wET%2Fmeetup-west-la-meetup-consciousness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Consciousness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wfkHfHcrPYqc7wET%2Fmeetup-west-la-meetup-consciousness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wfkHfHcrPYqc7wET%2Fmeetup-west-la-meetup-consciousness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 191, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d8'>West LA Meetup - Consciousness</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, August 29th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> This week, we will discuss some of those classic questions regarding consciousness: Can machines be conscious? Are there different sorts of consciousness? Does consciousness matter? And what the hell are we talking about?</p>\n\n<p>There is so much literature on this topic, and some of it is actually worth reading. See (and add to) the comments section for some recommendations.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts\">recent posts</a>. But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d8'>West LA Meetup - Consciousness</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5wfkHfHcrPYqc7wET", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.73150806079351e-07, "legacy": true, "legacyId": "18481", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Consciousness\">Discussion article for the meetup : <a href=\"/meetups/d8\">West LA Meetup - Consciousness</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, August 29th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> This week, we will discuss some of those classic questions regarding consciousness: Can machines be conscious? Are there different sorts of consciousness? Does consciousness matter? And what the hell are we talking about?</p>\n\n<p>There is so much literature on this topic, and some of it is actually worth reading. See (and add to) the comments section for some recommendations.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts\">recent posts</a>. But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Consciousness1\">Discussion article for the meetup : <a href=\"/meetups/d8\">West LA Meetup - Consciousness</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Consciousness", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Consciousness", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Consciousness", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Consciousness1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T05:52:31.628Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne, practical rationality", "slug": "meetup-melbourne-practical-rationality-2", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:28.882Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5jamiQCzsFsbX8pCJ/meetup-melbourne-practical-rationality-2", "pageUrlRelative": "/posts/5jamiQCzsFsbX8pCJ/meetup-melbourne-practical-rationality-2", "linkUrl": "https://www.lesswrong.com/posts/5jamiQCzsFsbX8pCJ/meetup-melbourne-practical-rationality-2", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%2C%20practical%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%2C%20practical%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jamiQCzsFsbX8pCJ%2Fmeetup-melbourne-practical-rationality-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%2C%20practical%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jamiQCzsFsbX8pCJ%2Fmeetup-melbourne-practical-rationality-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jamiQCzsFsbX8pCJ%2Fmeetup-melbourne-practical-rationality-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/d9'>Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 September 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">55 walsh st west melbourne 3003 australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality. <br />\nThis meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/d9'>Melbourne, practical rationality</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5jamiQCzsFsbX8pCJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.731760162302624e-07, "legacy": true, "legacyId": "18483", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality\">Discussion article for the meetup : <a href=\"/meetups/d9\">Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 September 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">55 walsh st west melbourne 3003 australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality. <br>\nThis meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality1\">Discussion article for the meetup : <a href=\"/meetups/d9\">Melbourne, practical rationality</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality", "level": 1}, {"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T06:51:57.813Z", "modifiedAt": null, "url": null, "title": "UPDATE: Society of Venturism is spearheading Kim Suozzi's cryopreservation charity", "slug": "update-society-of-venturism-is-spearheading-kim-suozzi-s", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:06.760Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dblch", "createdAt": "2012-08-19T17:18:04.250Z", "isAdmin": false, "displayName": "dblch"}, "userId": "eSbWmCkvxJEyZxRrC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hozfqzhDrMAcwsHN6/update-society-of-venturism-is-spearheading-kim-suozzi-s", "pageUrlRelative": "/posts/hozfqzhDrMAcwsHN6/update-society-of-venturism-is-spearheading-kim-suozzi-s", "linkUrl": "https://www.lesswrong.com/posts/hozfqzhDrMAcwsHN6/update-society-of-venturism-is-spearheading-kim-suozzi-s", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20UPDATE%3A%20Society%20of%20Venturism%20is%20spearheading%20Kim%20Suozzi's%20cryopreservation%20charity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUPDATE%3A%20Society%20of%20Venturism%20is%20spearheading%20Kim%20Suozzi's%20cryopreservation%20charity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhozfqzhDrMAcwsHN6%2Fupdate-society-of-venturism-is-spearheading-kim-suozzi-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=UPDATE%3A%20Society%20of%20Venturism%20is%20spearheading%20Kim%20Suozzi's%20cryopreservation%20charity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhozfqzhDrMAcwsHN6%2Fupdate-society-of-venturism-is-spearheading-kim-suozzi-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhozfqzhDrMAcwsHN6%2Fupdate-society-of-venturism-is-spearheading-kim-suozzi-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 333, "htmlBody": "<p>Hey everyone,</p>\n<p>I'm Kim Suozzi, a 23-year old brain cancer patient trying to secure cryopreservation before my death.</p>\n<p>I know I haven't updated in awhile so I just wanted to check in and say how thankful I am for everyone that has been donating and supporting me so far. I've gotten way more of a response than I could have ever expected, and it's hard to find words regarding this whole thing, but I want you know that I am endlessly grateful for the hope you've already offered to me.</p>\n<p>I have two days of radiation treatment left, then I'm off to hopefully pursue a clinical trial. Things are going well considering the circumstances; I have no big side effects other than being tired.</p>\n<p>I updated the other day with a video, if anyone is interested:http://www.youtube.com/watch?v=lISC8I_IiCg</p>\n<p>&nbsp;</p>\n<p>I also wanted to clarify that though The Society of Venturism is fundraising on my behalf, I also have a direct link to my paypal (https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=4WR8KS68RC6YY) for independent donations. However, I would like to move funds to the Venturists since they are third-party and a non-profit, that way people can be sure the funds go to cryo and nothing else. It looks like setting it up through the Society for Venturism is a better bet than going though CI or Alcor as it can be difficult to move funds in the case that you choose one company over the other or need to change things around with financing.</p>\n<p>&nbsp;</p>\n<p>Anyway the Society for Venturim Charity is located here:&nbsp;http://venturist.info/kim-suozzi-charity.html, Sorry to repost since I know it's elsewhere already. I just wanted to try to put it all in one message since some others were asking.</p>\n<p>&nbsp;</p>\n<p>I can't say this enough: thank you for all of you consideration and support through all of this,and to all those who have already donated. Maybe if I achieve reanimation, I can throw a party and show you guys what I'm really like, (not just your run-of-the-mill-dying-patient.)</p>\n<p>Hope to meet you/ talk to you soon, whether in this time or much later.</p>\n<p>&nbsp;</p>\n<p>Kim</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hozfqzhDrMAcwsHN6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 22, "extendedScore": null, "score": 9.732057725169567e-07, "legacy": true, "legacyId": "18488", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T07:02:14.247Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Optimization", "slug": "seq-rerun-optimization", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:23.373Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KGvQB8BEL3KsL466y/seq-rerun-optimization", "pageUrlRelative": "/posts/KGvQB8BEL3KsL466y/seq-rerun-optimization", "linkUrl": "https://www.lesswrong.com/posts/KGvQB8BEL3KsL466y/seq-rerun-optimization", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Optimization&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Optimization%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKGvQB8BEL3KsL466y%2Fseq-rerun-optimization%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Optimization%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKGvQB8BEL3KsL466y%2Fseq-rerun-optimization", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKGvQB8BEL3KsL466y%2Fseq-rerun-optimization", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p>Today's post, <a href=\"/lw/tx/optimization/\">Optimization</a> was originally published on 13 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Optimization\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A discussion of the concept of optimization.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e90/seq_rerun_psychic_powers/\">Psychic Powers</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KGvQB8BEL3KsL466y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.732109161319278e-07, "legacy": true, "legacyId": "18491", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["D7EcMhL26zFNbJ3ED", "yo3TFs48drsTSAput", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T07:07:07.105Z", "modifiedAt": null, "url": null, "title": "What is the evidence in favor of paleo?", "slug": "what-is-the-evidence-in-favor-of-paleo", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:18.742Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsteinhardt", "createdAt": "2010-08-05T03:07:27.568Z", "isAdmin": false, "displayName": "jsteinhardt"}, "userId": "EF8W65G6RaXxZjLBX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e2kMPiFwh4oQNuprp/what-is-the-evidence-in-favor-of-paleo", "pageUrlRelative": "/posts/e2kMPiFwh4oQNuprp/what-is-the-evidence-in-favor-of-paleo", "linkUrl": "https://www.lesswrong.com/posts/e2kMPiFwh4oQNuprp/what-is-the-evidence-in-favor-of-paleo", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20the%20evidence%20in%20favor%20of%20paleo%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20the%20evidence%20in%20favor%20of%20paleo%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe2kMPiFwh4oQNuprp%2Fwhat-is-the-evidence-in-favor-of-paleo%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20the%20evidence%20in%20favor%20of%20paleo%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe2kMPiFwh4oQNuprp%2Fwhat-is-the-evidence-in-favor-of-paleo", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe2kMPiFwh4oQNuprp%2Fwhat-is-the-evidence-in-favor-of-paleo", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<p>I recently <a href=\"/lw/e3a/open_thread_august_1631_2012/79ke\">came out against paleo</a> in the open thread, and realized that I probably haven't yet heard the strongest arguments in favor of a paleo diet. So, what are said arguments?</p>\n<p>EDIT: Or more generally, why should I eat less carbohydrates and more protein / fat?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e2kMPiFwh4oQNuprp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 21, "extendedScore": null, "score": 9.732133598254543e-07, "legacy": true, "legacyId": "18492", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-27T22:02:03.457Z", "modifiedAt": null, "url": null, "title": "Anyone know of empirically driven lobbying efforts?", "slug": "anyone-know-of-empirically-driven-lobbying-efforts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:22.742Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "palladias", "createdAt": "2012-04-03T13:45:53.766Z", "isAdmin": false, "displayName": "palladias"}, "userId": "Bv2LXWzZf96WGpqJ5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e5RCiviZijkgn7QSf/anyone-know-of-empirically-driven-lobbying-efforts", "pageUrlRelative": "/posts/e5RCiviZijkgn7QSf/anyone-know-of-empirically-driven-lobbying-efforts", "linkUrl": "https://www.lesswrong.com/posts/e5RCiviZijkgn7QSf/anyone-know-of-empirically-driven-lobbying-efforts", "postedAtFormatted": "Monday, August 27th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20know%20of%20empirically%20driven%20lobbying%20efforts%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20know%20of%20empirically%20driven%20lobbying%20efforts%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5RCiviZijkgn7QSf%2Fanyone-know-of-empirically-driven-lobbying-efforts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20know%20of%20empirically%20driven%20lobbying%20efforts%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5RCiviZijkgn7QSf%2Fanyone-know-of-empirically-driven-lobbying-efforts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5RCiviZijkgn7QSf%2Fanyone-know-of-empirically-driven-lobbying-efforts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 379, "htmlBody": "<p>I was recently in an argument with a friend about the efficacy of WhiteHouse.gov petitions. &nbsp;He was disappointed that atheists hadn't pushed the Free Alexander Aan petition up to 25,000 signatures and thought this was a bad sign for future projects. &nbsp;I thought it wasn't a very good 'ask' so it was reasonable for otherwise committed activist to ignore it. &nbsp;He ended up pulling Pascal's Mugging by arguing \"nothing tangible may ever happen as a result, but we don&rsquo;t know that, and it does send a palpable signal either way.\"</p>\n<p>I was annoyed, but I also noticed I couldn't think of any GiveWell equivalent for advocacy efforts. &nbsp;I was pretty confident that this WhiteHouse.gov petition was a waste of time, but I wasn't sure whether I'd prefer for a cause I supported to focus on petitions, voter education, wacky stunts to up coverage, etc etc. I've seen plenty of studies on how to get people to <em>sign</em>&nbsp;petitions, but none on whether they work.</p>\n<p>The Human Rights Campaign used to run into a lot of criticism for just wining and dining&nbsp;legislators&nbsp;instead of getting pushier or focusing on electing new allies, but, when DADT was killed, the pundits seemed to think the strategy had paid off. &nbsp;It looks like no one is very good at predicting which lobbying techniques will work, just popping in at various timepoints, seeing whether the policy changed, and passing or failing the outreach effort on that basis.</p>\n<p>I'm actually a researcher for a consumer protection group that does a fair amount of lobbying, and it can feel a little like a cargo cult over here. &nbsp;It feels a bit like we just try to keep an issue in view (through visits, press coverage, etc) so that when Congress or a regulatory body lumbers into action, they might think of our pet issue. &nbsp;</p>\n<p>Government gridlock is out of our hands, so the metrics we track (number of signatures on a petition, press citations of our work, social shares of data infographics) are meant to be proxies for our influence, but I'm not aware of any heuristic we use to check which align best with the regulatory results we're actually seeking.</p>\n<p>Has anyone seen interesting data on this or have heuristics they use when deciding which advocacy efforts to support and promote?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Lgy35Xh222bwgeGTL": 1, "FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e5RCiviZijkgn7QSf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 37, "extendedScore": null, "score": 9.736616045746788e-07, "legacy": true, "legacyId": "18496", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-28T02:59:35.324Z", "modifiedAt": null, "url": null, "title": "The wandering rationalist", "slug": "the-wandering-rationalist", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.074Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Despard", "createdAt": "2012-06-11T21:21:52.973Z", "isAdmin": false, "displayName": "Despard"}, "userId": "inrBDZgvL5FzK6584", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zu5PxfwNtT4kxegf5/the-wandering-rationalist", "pageUrlRelative": "/posts/zu5PxfwNtT4kxegf5/the-wandering-rationalist", "linkUrl": "https://www.lesswrong.com/posts/zu5PxfwNtT4kxegf5/the-wandering-rationalist", "postedAtFormatted": "Tuesday, August 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20wandering%20rationalist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20wandering%20rationalist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzu5PxfwNtT4kxegf5%2Fthe-wandering-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20wandering%20rationalist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzu5PxfwNtT4kxegf5%2Fthe-wandering-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzu5PxfwNtT4kxegf5%2Fthe-wandering-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 487, "htmlBody": "<p>Hello all. I'm still fairly new to the site and I've only posted comments up until now, but this definitely warrants its own topic. Currently I work at Queen's University in Canada as a postdoc studying motor control, but my funding runs out at the end of November. I don't have another job immediately lined up, but I've been in discussions with CFAR about working for them either directly or through UC Berkeley on doing some research into rationality techniques. I attended the June minicamp and had an absolute blast with the people there.</p>\n<p>Why am I telling you all this? Well... I've applied for some funding to go work at Berkeley but it won't come through until July 2013 at the earliest, assuming I'm awarded it. In the meantime, I've decided to go travelling through the US, buy a round-the-world ticket from San Francisco and wander for the next few months - and it would be awesome to meet up with some rationalists along the way!</p>\n<p><a id=\"more\"></a></p>\n<p>I've got some money saved and will have more by the time I leave. To support myself further I intend to take on academic editing work (like <a href=\"http://www.enago.com/\">this company</a> does), where I can basically work from anywhere and have a little bit of money coming in regularly. Maybe I'll try for some freelance programming work too. Regardless, it'll be a lot easier if I don't have to pay for accommodation, so if anyone could put me up for a night or two along the way I'd be massively appreciative; I intend to <a href=\"http://www.couchsurfing.org\">couchsurf</a> anyway but it would be great to meet some LWers and have enjoyably rational conversations on my trip.</p>\n<p><a href=\"http://bit.ly/NtdvVO\">Here</a> is my (vague) route through the US. This will be December 1st-31st. It has a few random detours as I have friends in Oklahoma and Colorado (though I don't know anyone in New Mexico, it just seemed like a logical place to visit and I couldn't resist being able to go through Amarillo), as well as in northern Idaho and Vancouver.</p>\n<p>I haven't decided yet whether I'll buy a bus ticket or simply try to hitch rides from the internet; that's still up in the air. Regardless of what I choose, anyone who wants to drive me some of my route will not be turned down...</p>\n<p>After I leave San Francisco I want to head to Hawaii, New Zealand and Australia for a couple of months before I go to SE Asia. I intend to be back in Europe (I'm British although I live in Canada) by May 2013 and I'll hit the North American continent again in June, but this time I'll be flying across. So it would also be great to meet rationalists in countries along my route.</p>\n<p>People like <a href=\"/user/annasalamon/\">Anna</a> and <a href=\"/user/Valentine/\">Valentine</a>/<a href=\"/user/Mercurial/\">Mercurial</a> can vouch for me not being an itinerant crazy, probably.</p>\n<p>Looking forward to meeting some of you guys in a few months! And reuniting with the Berkeley crowd, of course.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zu5PxfwNtT4kxegf5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 12, "extendedScore": null, "score": 9.738107087531086e-07, "legacy": true, "legacyId": "18497", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-28T09:47:59.458Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] My Childhood Death Spiral", "slug": "seq-rerun-my-childhood-death-spiral", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TqJHYJSiWuBHpXvmB/seq-rerun-my-childhood-death-spiral", "pageUrlRelative": "/posts/TqJHYJSiWuBHpXvmB/seq-rerun-my-childhood-death-spiral", "linkUrl": "https://www.lesswrong.com/posts/TqJHYJSiWuBHpXvmB/seq-rerun-my-childhood-death-spiral", "postedAtFormatted": "Tuesday, August 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20My%20Childhood%20Death%20Spiral&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20My%20Childhood%20Death%20Spiral%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqJHYJSiWuBHpXvmB%2Fseq-rerun-my-childhood-death-spiral%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20My%20Childhood%20Death%20Spiral%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqJHYJSiWuBHpXvmB%2Fseq-rerun-my-childhood-death-spiral", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqJHYJSiWuBHpXvmB%2Fseq-rerun-my-childhood-death-spiral", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>Today's post, <a href=\"/lw/ty/my_childhood_death_spiral/\">My Childhood Death Spiral</a> was originally published on 15 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When Eliezer was a child, he went into a happy death spiral around the concept of intelligence.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/e9n/seq_rerun_optimization/\">Optimization</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TqJHYJSiWuBHpXvmB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.74015440271775e-07, "legacy": true, "legacyId": "18511", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uD9TDHPwQ5hx4CgaX", "KGvQB8BEL3KsL466y", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-28T19:13:52.611Z", "modifiedAt": null, "url": null, "title": "Meetup : Pittsburgh: Rationalization Game", "slug": "meetup-pittsburgh-rationalization-game", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a4XCaDXfYpQTHuLQt/meetup-pittsburgh-rationalization-game", "pageUrlRelative": "/posts/a4XCaDXfYpQTHuLQt/meetup-pittsburgh-rationalization-game", "linkUrl": "https://www.lesswrong.com/posts/a4XCaDXfYpQTHuLQt/meetup-pittsburgh-rationalization-game", "postedAtFormatted": "Tuesday, August 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Pittsburgh%3A%20Rationalization%20Game&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Pittsburgh%3A%20Rationalization%20Game%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa4XCaDXfYpQTHuLQt%2Fmeetup-pittsburgh-rationalization-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Pittsburgh%3A%20Rationalization%20Game%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa4XCaDXfYpQTHuLQt%2Fmeetup-pittsburgh-rationalization-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa4XCaDXfYpQTHuLQt%2Fmeetup-pittsburgh-rationalization-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/da'>Pittsburgh: Rationalization Game</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">EatUnique, Craig St, Pittsburgh</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Join us for dinner or a snack while we familiarize ourselves with the making up of justifications.</p>\n\n<p>Call 412-304-6258 if you can't find us.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/da'>Pittsburgh: Rationalization Game</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a4XCaDXfYpQTHuLQt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.742992443172875e-07, "legacy": true, "legacyId": "18513", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh__Rationalization_Game\">Discussion article for the meetup : <a href=\"/meetups/da\">Pittsburgh: Rationalization Game</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">EatUnique, Craig St, Pittsburgh</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Join us for dinner or a snack while we familiarize ourselves with the making up of justifications.</p>\n\n<p>Call 412-304-6258 if you can't find us.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh__Rationalization_Game1\">Discussion article for the meetup : <a href=\"/meetups/da\">Pittsburgh: Rationalization Game</a></h2>", "sections": [{"title": "Discussion article for the meetup : Pittsburgh: Rationalization Game", "anchor": "Discussion_article_for_the_meetup___Pittsburgh__Rationalization_Game", "level": 1}, {"title": "Discussion article for the meetup : Pittsburgh: Rationalization Game", "anchor": "Discussion_article_for_the_meetup___Pittsburgh__Rationalization_Game1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-28T20:48:16.200Z", "modifiedAt": null, "url": null, "title": "An Anthropic Principle Fairy Tale", "slug": "an-anthropic-principle-fairy-tale", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.549Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nominull", "createdAt": "2009-02-27T05:44:33.740Z", "isAdmin": false, "displayName": "Nominull"}, "userId": "dW22yDoPkty9ZTc69", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/T8d4uzenwT9e3PcWa/an-anthropic-principle-fairy-tale", "pageUrlRelative": "/posts/T8d4uzenwT9e3PcWa/an-anthropic-principle-fairy-tale", "linkUrl": "https://www.lesswrong.com/posts/T8d4uzenwT9e3PcWa/an-anthropic-principle-fairy-tale", "postedAtFormatted": "Tuesday, August 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20Anthropic%20Principle%20Fairy%20Tale&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20Anthropic%20Principle%20Fairy%20Tale%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT8d4uzenwT9e3PcWa%2Fan-anthropic-principle-fairy-tale%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20Anthropic%20Principle%20Fairy%20Tale%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT8d4uzenwT9e3PcWa%2Fan-anthropic-principle-fairy-tale", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT8d4uzenwT9e3PcWa%2Fan-anthropic-principle-fairy-tale", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 332, "htmlBody": "<p>A robot is going on a one-shot mission to a distant world to collect important data needed to research a cure for a plague that is devastating the Earth. When the robot enters hyperspace, it notices some anomalies in the engine's output, but it is too late to get the engine fixed. The anomalies are of a sort that, when similar anomalies have been observed in other engines, 25% of the time it indicates a fatal problem, such that the engine will explode virtually every time it tries to jump. 25% of the time, it has been a false positive, and the engine exploded only at its normal negligible rate. 50% of the time it has indicated a serious problem, such that each jump was about a 50/50 chance of exploding. Anyway, the robot goes through the ten jumps to reach the distant world, and the engine does not explode. Unfortunately, the jump coordinates for the mission were a little off, and the robot is in a bad data-collecting position. It could try another jump - if the engine doesn't explode, the extra data it collects could save lives. If the engine does explode, however, Earth will get no data from the distant world at all. (The FTL radio is only good for one use, so he can't collect data and then jump.) So how did you program your robot? Did you program your robot to believe that since the engine worked 10 times, the anomaly was probably a false positive, and so it should make the jump? Or did you program your robot to follow the \"Androidic Principle\" and disregard the so-called \"evidence\" of the ten jumps, since it could not have observed any other outcome? People's lives are in the balance here. A little girl is too sick to leave her bed, she doesn't have much time left, you can hear the fluid in her lungs as she asks you \"are you aware of the anthropic principle?\" Well? Are you?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "T8d4uzenwT9e3PcWa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": -24, "extendedScore": null, "score": -5.3e-05, "legacy": true, "legacyId": "18474", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-28T21:45:18.416Z", "modifiedAt": null, "url": null, "title": "A model of UDT with a concrete prior over logical statements", "slug": "a-model-of-udt-with-a-concrete-prior-over-logical-statements", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:04.157Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benja", "createdAt": "2009-02-27T04:37:47.476Z", "isAdmin": false, "displayName": "Benya"}, "userId": "3vZZP8TBXvozbe5Cv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PgKADaJE4ERjtMtP9/a-model-of-udt-with-a-concrete-prior-over-logical-statements", "pageUrlRelative": "/posts/PgKADaJE4ERjtMtP9/a-model-of-udt-with-a-concrete-prior-over-logical-statements", "linkUrl": "https://www.lesswrong.com/posts/PgKADaJE4ERjtMtP9/a-model-of-udt-with-a-concrete-prior-over-logical-statements", "postedAtFormatted": "Tuesday, August 28th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20model%20of%20UDT%20with%20a%20concrete%20prior%20over%20logical%20statements&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20model%20of%20UDT%20with%20a%20concrete%20prior%20over%20logical%20statements%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPgKADaJE4ERjtMtP9%2Fa-model-of-udt-with-a-concrete-prior-over-logical-statements%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20model%20of%20UDT%20with%20a%20concrete%20prior%20over%20logical%20statements%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPgKADaJE4ERjtMtP9%2Fa-model-of-udt-with-a-concrete-prior-over-logical-statements", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPgKADaJE4ERjtMtP9%2Fa-model-of-udt-with-a-concrete-prior-over-logical-statements", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1183, "htmlBody": "<p>I've been having difficulties with constructing a toy scenario for AI self-modification more interesting than <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/\">Quirrell's game</a>, because you really want to do expected utility maximization of some sort, but currently our <a href=\"http://wiki.lesswrong.com/wiki/Ambient_decision_theory\">best-specified decision theories</a> search through the theorems of one particular proof system and \"<a href=\"/lw/8wc/a_model_of_udt_with_a_halting_oracle/\">break down and cry</a>\" if they can't find one that tells them what their utility will be if they choose a particular option. This is fine if the problems are simple enough that we always find the theorems we need, but the AI rewrite problem is precisely about skirting that edge. It seems natural to want to choose some probability distribution over the possibilities that you can't rule out, and then do expected utility maximization (because if you don't maximize EU over some prior, it seems likely that someone could Dutch-book you); indeed, Wei Dai's <a href=\"/lw/1s5/explicit_optimization_of_global_strategy_fixing_a/\">original UDT</a> has a \"mathematical intuition module\" black box which this would be an implementation of. But how <em>do</em> you assign probabilities to logical statements? What consistency conditions do you ask for? What are the \"impossible possible worlds\" that make up your probability space?</p>\n<p>Recently, Wei Dai <a href=\"/lw/e4e/an_angle_of_attack_on_open_problem_1/79po\">suggested</a> that logical uncertainty might help avoid the L&ouml;bian problems with AI self-modification, and although I'm sceptical about this idea, the discussion pushed me into trying to confront the logical uncertainty problem head-on; then, reading Haim Gaifman's paper \"<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.6859&amp;rep=rep1&amp;type=pdf\">Reasoning with limited resources and assigning probabilities to logical statements</a>\" (which Luke linked from <a href=\"http://lukeprog.com/SaveTheWorld.html\">So you want to save the world</a>) made something click. I want to present a simple suggestion for a concrete definition of \"impossible possible world\", for a prior over them, and for an UDT algorithm based on that. I'm not sure whether the concrete prior is useful&mdash;the main point in giving it is to have a concrete example we can try to prove things about&mdash;but the definition of logical possible worlds looks like a promising theoretical tool to me.<a id=\"more\"></a></p>\n<p align=\"center\">*</p>\n<p>Let S be the set of sentences of Peano Arithmetic less than 3^^^3 symbols long, and let Pow(S) := the set of all subsets of S. We interpret elements X of Pow(S) as \"logical worlds\", in which the sentences in X are true and the sentences in (S \\ X) are false. Each world X can be represented by a single sentence s<sub>X</sub>, which is the conjunction of the sentences ({x | x in X} union {not y | y in S \\ X}). Now, we exclude those X that are proven contradictory by one of the first 4^^^^4 theorems of PA; that is, we define the set W of <em>possible worlds</em> to be</p>\n<p>&nbsp;&nbsp;&nbsp; W := {X in Pow(S) | \"not s<sub>X</sub>\" is <strong>not</strong> among the first 4^^^^4 theorems of PA}.</p>\n<p>W is our probability space. Note that it's finite. For lack of a better idea, I propose to use the uniform prior on it. (Possibly useful: another way to think about this is that we choose the uniform prior on Pow(S), and after looking at the 4^^^^4 theorems, we do a Bayesian update.)</p>\n<p>Individual sentences in S induce events over this probability space: a sentence x corresponds to the event {X in Pow(S) | x in X}. Clearly, all of the above can be carried out by a computable function, and in particular we can write a computable function P(.) which takes a statement in S and returns the probability of the corresponding event (and the source of this function can be short, i.e., it doesn't need to contain any 3^^^3-sized lookup tables).</p>\n<p align=\"center\">*</p>\n<p>The decision algorithm makes use of two global variables which specify the problem.</p>\n<ul>\n<li><code>actions</code> is a Python dictionary that maps possible inputs to the algorithm to a list of outputs the algorithm is allowed to return when receiving that input. For example, in the problem from Wei Dai's <a href=\"/lw/1s5/explicit_optimization_of_global_strategy_fixing_a/\">UDT1.1 post</a>, <code>actions = {1: ['A','B'], 2: ['A','B']}</code>, meaning that your input is either '1' or '2', and in both cases you may choose between options 'A' and 'B'. We'll assume there's nothing 3^^^3-sized in <code>actions</code>.</li>\n<li><code>worlds</code> is a list of triples of the form <code>(p,U,us)</code>, representing possible physical worlds the agent might find itself in, where <code>p</code> is the probability of being in that world, <code>U</code> is the source of a function that computes and returns the agent's utility if that world is the true one (by simulating that world and running a utility function over the result), and <code>us</code> is a list of values <code>U</code> might return. The probabilities must add to 1. We'll assume that there's nothing 3^^^3-sized here either, and that it's provable in much less that 4^^^^4 steps that <em>if</em> the decision algorithm halts on all inputs specified by <code>actions</code> and returns one of the allowable actions, then each <code>U</code> will halt and return a value in the corresponding <code>us</code>. (The reason for the condition is that the functions <code>U</code> may contain copies of the agent's source, and may make calls to the agent, so if the agent didn't halt, neither could <code>U</code>.)</li>\n</ul>\n<p>With these provisions, the algorithm, <code>UDT(input)</code>, proceeds as follows:</p>\n<ol>\n<li>Compute <code>mappings</code>, a list of all dictionaries that maps each possible input from <code>actions</code> to one of the allowable outputs. (In the earlier example, <code>mappings = [{1:'A',2:'A'}, {1:'A',2:'B'}, {1:'B',2:'A'}, {1:'B',2:'B'}]</code>.)</li>\n<li>Play chicken with the universe: For each <code>m</code> in <code>mappings</code>, if P(\"<code>UDT(i) == m[i]</code> for every <code>i</code> in <code>actions.keys()</code>\") = 0, then return <code>m[input]</code>.</li>\n<li>Calculate expected utilities: For each <code>m</code> in <code>mappings</code>, for each <code>(p,U,us)</code> in <code>worlds</code>, for each <code>u</code> in <code>us</code>, compute <code>q</code> := P(\"<code>U() == u</code>\" | \"<code>UDT(i) == m[i]</code> for every <code>i</code> in <code>actions.keys()</code>\"); the expected utility EU(<code>m</code>) of <code>m</code> is the sum of all the corresponding <code>p*u*q</code>. (Note that we made sure in the previous step that the conditional probabilities <code>q</code> exist.)</li>\n<li>Choose the <code>m</code> with the highest expected utility. If multiple options have the same utility, choose the lexicographically lowest one.</li>\n<li>Return <code>m[input]</code>.</li>\n</ol>\n<p>Now, the universe must always chicken out (the algorithm will never need to return in step 2), because one of the possible worlds in W must be <em>true</em>, this true world cannot be ruled out by Peano Arithmetic because PA is sound, and if the algorithm returned <code>m[input]</code> in step 2, then \"<code>UDT(i) == m[i]</code> for every <code>i</code> in <code>actions.keys()</code>\" would hold in this true world, so the probability of this sentence could not be zero.</p>\n<p>Further, the algorithm will halt on all inputs, because although it does some big computations, there is no <em>unbounded</em> search anywhere; and it's easy to see that on each possible input, it will return one of the allowable outputs. This reasoning can be formalized in PA. Using our earlier assumption, it follows (in PA, in much less than 4^^^^4 steps) that each <code>U</code> will halt and return a value in the corresponding <code>us</code>. Thus, in each possible logical world in W, for every <code>(p,U,us)</code> in <code>worlds</code>, \"<code>U()</code> halts\" will be true, and \"<code>U() == u</code>\" will be true for exactly one <code>u</code> (more than one would quickly prove a contradiction), and this <code>u</code> will be in <code>us</code>; and therefore, the different <code>q</code> for a given <code>(p,U,us)</code> will add up to 1.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PgKADaJE4ERjtMtP9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 50, "baseScore": 62, "extendedScore": null, "score": 0.00011160229812651055, "legacy": true, "legacyId": "18514", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DDJr5fuR5jeD47k9g", "Bj244uWzDBXvE2N2S", "g8xh9R7RaNitKtkaa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T03:50:23.867Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind", "slug": "meetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:26.392Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/o2fkcocBcvqkHSLua/meetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "pageUrlRelative": "/posts/o2fkcocBcvqkHSLua/meetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "linkUrl": "https://www.lesswrong.com/posts/o2fkcocBcvqkHSLua/meetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%20meetup%3A%20Cannabis%2C%20Decision-Making%2C%20And%20A%20Chance%20To%20Change%20Your%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%20meetup%3A%20Cannabis%2C%20Decision-Making%2C%20And%20A%20Chance%20To%20Change%20Your%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo2fkcocBcvqkHSLua%2Fmeetup-berkeley-meetup-cannabis-decision-making-and-a-chance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%20meetup%3A%20Cannabis%2C%20Decision-Making%2C%20And%20A%20Chance%20To%20Change%20Your%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo2fkcocBcvqkHSLua%2Fmeetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo2fkcocBcvqkHSLua%2Fmeetup-berkeley-meetup-cannabis-decision-making-and-a-chance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 323, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/db'>Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The discussion topic for this Wednesday is a new article in PNAS that's been in the news. It's called \"Persistent cannabis users show neuropsychological decline from childhood to midlife\":</p>\n\n<p><a href=\"http://www.pnas.org/content/early/2012/08/22/1206820109\" rel=\"nofollow\">http://www.pnas.org/content/early/2012/08/22/1206820109</a></p>\n\n<p>If you were a perfect Bayesian reasoner, your beliefs about marijuana would have changed, if only very slightly, after reading the previous paragraph. And, upon reading the article, your beliefs would change again, in some direction. We humans don't do this perfectly, and we have to take care.</p>\n\n<p>It's no secret that many LessWrongers use marijuana recreationally. Until now, we have known it as a relatively harmless psychoactive substance. Now is your chance to practice individual and group truth-seeking by tackling a new piece of evidence. It might also be a chance to rethink your drug use choices. You don't know in advance how your beliefs and decisions will change (otherwise you may as well change them now). But, as Jeffreyssai might say, if you know in advance that your beliefs and decisions won't change, no matter what the evidence is, then we might as well not bother learning.</p>\n\n<p>Doors open at 7pm and discussion officially starts at 7:30pm. I'd like the discussion to begin with a discussion of values \u2014 answers to questions of the form \"Would I smoke weed if I knew it would permanently decrease my IQ by 8 points?\" Then we can talk about the evidence that the article provides, subject to the interests of the participants.</p>\n\n<p>One more thing: Please do not claim to use or buy marijuana on the internet or identify people who do. This is a public medium and doing stuff with marijuana is a violation of federal law.</p>\n\n<p>For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/db'>Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "o2fkcocBcvqkHSLua", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.74558418510351e-07, "legacy": true, "legacyId": "18515", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__Cannabis__Decision_Making__And_A_Chance_To_Change_Your_Mind\">Discussion article for the meetup : <a href=\"/meetups/db\">Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 August 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The discussion topic for this Wednesday is a new article in PNAS that's been in the news. It's called \"Persistent cannabis users show neuropsychological decline from childhood to midlife\":</p>\n\n<p><a href=\"http://www.pnas.org/content/early/2012/08/22/1206820109\" rel=\"nofollow\">http://www.pnas.org/content/early/2012/08/22/1206820109</a></p>\n\n<p>If you were a perfect Bayesian reasoner, your beliefs about marijuana would have changed, if only very slightly, after reading the previous paragraph. And, upon reading the article, your beliefs would change again, in some direction. We humans don't do this perfectly, and we have to take care.</p>\n\n<p>It's no secret that many LessWrongers use marijuana recreationally. Until now, we have known it as a relatively harmless psychoactive substance. Now is your chance to practice individual and group truth-seeking by tackling a new piece of evidence. It might also be a chance to rethink your drug use choices. You don't know in advance how your beliefs and decisions will change (otherwise you may as well change them now). But, as Jeffreyssai might say, if you know in advance that your beliefs and decisions won't change, no matter what the evidence is, then we might as well not bother learning.</p>\n\n<p>Doors open at 7pm and discussion officially starts at 7:30pm. I'd like the discussion to begin with a discussion of values \u2014 answers to questions of the form \"Would I smoke weed if I knew it would permanently decrease my IQ by 8 points?\" Then we can talk about the evidence that the article provides, subject to the interests of the participants.</p>\n\n<p>One more thing: Please do not claim to use or buy marijuana on the internet or identify people who do. This is a public medium and doing stuff with marijuana is a violation of federal law.</p>\n\n<p>For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__Cannabis__Decision_Making__And_A_Chance_To_Change_Your_Mind1\">Discussion article for the meetup : <a href=\"/meetups/db\">Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__Cannabis__Decision_Making__And_A_Chance_To_Change_Your_Mind", "level": 1}, {"title": "Discussion article for the meetup : Berkeley meetup: Cannabis, Decision-Making, And A Chance To Change Your Mind", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__Cannabis__Decision_Making__And_A_Chance_To_Change_Your_Mind1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T07:30:55.073Z", "modifiedAt": null, "url": null, "title": "Rigorous academic arguments on whether AIs can replace all human workers?", "slug": "rigorous-academic-arguments-on-whether-ais-can-replace-all", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:33.145Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hbRvhbbK3prMKFfh7/rigorous-academic-arguments-on-whether-ais-can-replace-all", "pageUrlRelative": "/posts/hbRvhbbK3prMKFfh7/rigorous-academic-arguments-on-whether-ais-can-replace-all", "linkUrl": "https://www.lesswrong.com/posts/hbRvhbbK3prMKFfh7/rigorous-academic-arguments-on-whether-ais-can-replace-all", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rigorous%20academic%20arguments%20on%20whether%20AIs%20can%20replace%20all%20human%20workers%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARigorous%20academic%20arguments%20on%20whether%20AIs%20can%20replace%20all%20human%20workers%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbRvhbbK3prMKFfh7%2Frigorous-academic-arguments-on-whether-ais-can-replace-all%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rigorous%20academic%20arguments%20on%20whether%20AIs%20can%20replace%20all%20human%20workers%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbRvhbbK3prMKFfh7%2Frigorous-academic-arguments-on-whether-ais-can-replace-all", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhbRvhbbK3prMKFfh7%2Frigorous-academic-arguments-on-whether-ais-can-replace-all", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 147, "htmlBody": "<p>I believe that it will one day be possible for AIs to do all work currently done by humans. Probably most people at LessWrong believe this too, and thanks to science fiction I wouldn't be surprised if most people in the United States and Europe believed it too.</p>\n<p>But it's interesting to think about why we should believe this, and when I ask myself that question, I can come up with arguments, but I have a hard time thinking of examples of the arguments being made in a rigorous way in the academic literature. This is surprising because it's a question with real practical import for humanity's future.</p>\n<p>The only prominent example I can think of is an argument against based on Godel's theorem and similar math, what <a href=\"http://cogprints.org/499/1/turing.html\">Turing</a> called \"The Mathematical Objection\" and which has more recently been championed by Roger Penrose. But can anyone think of others?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hbRvhbbK3prMKFfh7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "18522", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T07:33:42.237Z", "modifiedAt": null, "url": null, "title": "11 minute TED talk is about instrumental rationality", "slug": "11-minute-ted-talk-is-about-instrumental-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:23.657Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JamesAndrix", "createdAt": "2009-02-27T06:51:02.535Z", "isAdmin": false, "displayName": "JamesAndrix"}, "userId": "WCXG9t74Aw8sYLkyR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ak4c7kH3xNt4zo3qr/11-minute-ted-talk-is-about-instrumental-rationality", "pageUrlRelative": "/posts/ak4c7kH3xNt4zo3qr/11-minute-ted-talk-is-about-instrumental-rationality", "linkUrl": "https://www.lesswrong.com/posts/ak4c7kH3xNt4zo3qr/11-minute-ted-talk-is-about-instrumental-rationality", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2011%20minute%20TED%20talk%20is%20about%20instrumental%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A11%20minute%20TED%20talk%20is%20about%20instrumental%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fak4c7kH3xNt4zo3qr%2F11-minute-ted-talk-is-about-instrumental-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=11%20minute%20TED%20talk%20is%20about%20instrumental%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fak4c7kH3xNt4zo3qr%2F11-minute-ted-talk-is-about-instrumental-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fak4c7kH3xNt4zo3qr%2F11-minute-ted-talk-is-about-instrumental-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 32, "htmlBody": "<p><a href=\"http://www.ted.com/talks/timothy_prestero_design_for_people_not_awards.html\">Link</a></p>\n<p>Essentially this is about cutting your enemy, and some procedural pitfalls in his examples.</p>\n<p>I didn't spot any novel principles in the talk, but I want to learn more about how he thinks. <br /><br /></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ak4c7kH3xNt4zo3qr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 17, "extendedScore": null, "score": 9.746705043067506e-07, "legacy": true, "legacyId": "18523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T13:10:59.110Z", "modifiedAt": null, "url": null, "title": "Expected utility and utility after time", "slug": "expected-utility-and-utility-after-time", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Metus", "createdAt": "2011-01-23T21:54:34.357Z", "isAdmin": false, "displayName": "Metus"}, "userId": "mNQ4fSvro7LYgrii4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9xKxBG72dePez45Pj/expected-utility-and-utility-after-time", "pageUrlRelative": "/posts/9xKxBG72dePez45Pj/expected-utility-and-utility-after-time", "linkUrl": "https://www.lesswrong.com/posts/9xKxBG72dePez45Pj/expected-utility-and-utility-after-time", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Expected%20utility%20and%20utility%20after%20time&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExpected%20utility%20and%20utility%20after%20time%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xKxBG72dePez45Pj%2Fexpected-utility-and-utility-after-time%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Expected%20utility%20and%20utility%20after%20time%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xKxBG72dePez45Pj%2Fexpected-utility-and-utility-after-time", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xKxBG72dePez45Pj%2Fexpected-utility-and-utility-after-time", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 311, "htmlBody": "<p>So I have a conundrum. Imagine that Omega comes to you and offers you two choices:</p>\n<p>First choice: You get a moment of moderate pain, let's say a slap and then another slap, so that your face hurts for a couple of minutes with some anguish. Now after that pain has faded and you still have the memory of it, Omega measures your discomfort and gives you exactly the amount of money that gives enough joy to compensate the pain and then a cent. By construction, the utility of this choice is one cent.</p>\n<p>Second choice: Omega inflicts on you hell for a finite amount of time. Your worst fears all come true, you are unable to distinguish between reality and this hell, the most painful sensations you will experience. After this finite amount of time is over, Omega deletes all memory of it and gives you essentially unlimited monetary funds but still, this experience does not quite compensate for the previously experienced hell if you would remember it. By construction, the expected value of this choice is negative.[1]</p>\n<p>If we go by expected value, the first choice is obviously better. Of course Omega forces you to take one choice or you will just get hell forever, we want our thought experiment to work. But if we go by the decision procedure to choose the option in which our future self will feel best, the second choice seems better. I have not yet found a satisfying solution to this apparent paradox. Essentially, how does a rational actor deal with discomfort to get to a pleasurable experience?</p>\n<p>[1] I realize that this might be a weak point of my argument. Do we just simply add up positive and negative utilons to get our expected value? Or do we already take into consideration the process of forgetting the pain? Maybe therein lies a solution to this paradox.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9xKxBG72dePez45Pj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 9.74839841818511e-07, "legacy": true, "legacyId": "18529", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T16:07:21.086Z", "modifiedAt": null, "url": null, "title": "Is felt preference a useful indicator? (A ramble)", "slug": "is-felt-preference-a-useful-indicator-a-ramble", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:25.265Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kAXnhBnNg74AoAo3Y/is-felt-preference-a-useful-indicator-a-ramble", "pageUrlRelative": "/posts/kAXnhBnNg74AoAo3Y/is-felt-preference-a-useful-indicator-a-ramble", "linkUrl": "https://www.lesswrong.com/posts/kAXnhBnNg74AoAo3Y/is-felt-preference-a-useful-indicator-a-ramble", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20felt%20preference%20a%20useful%20indicator%3F%20(A%20ramble)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20felt%20preference%20a%20useful%20indicator%3F%20(A%20ramble)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkAXnhBnNg74AoAo3Y%2Fis-felt-preference-a-useful-indicator-a-ramble%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20felt%20preference%20a%20useful%20indicator%3F%20(A%20ramble)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkAXnhBnNg74AoAo3Y%2Fis-felt-preference-a-useful-indicator-a-ramble", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkAXnhBnNg74AoAo3Y%2Fis-felt-preference-a-useful-indicator-a-ramble", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 274, "htmlBody": "<p>I <a href=\"/lw/e9o/what_is_the_evidence_in_favor_of_paleo/7abm\">posted recently</a> that \"I tend to assume that things people hate are bad for them. CR may be an exception, but it's plausible that evolution would usually select for warnings that one is hurting oneself.\"</p>\n<p>I think this points at an interesting question. If you know that people like a behavior, or dislike it, or love it, or hate it, does this tell you anything about whether the behavior is useful?</p>\n<p>I expect that most people reading this question have a handy list-- one that comes quickly to mind-- of things which are good for people but that they resist. There's a tremendous amount in the culture (and perhaps more from somewhat different angles at LW) about people's reflexive preferences being wrong.</p>\n<p>However, there's a lot where people's preferences are assumed to be in line with what's good for them that doesn't get much attention. I believe this is because there's a fascination with the drama of self-denial, but that might be a topic for a different post.</p>\n<p>For example, people hate long commutes. I've never heard anyone say that long commutes are good for people.</p>\n<p>People generally dislike being low on sleep.</p>\n<p>Rather few modern people think that liking sex is a problem in itself. (Note a cultural shift-- anxiety about pleasure has been moved from sex to food.)</p>\n<p>Nobody says that human contact is bad, even though many people like it.</p>\n<p>And there's no cultural consensus that hating spam is bad, even though hating spam is a spontaneous response.</p>\n<p>It's implausible that evolutionarily developed pleasure and pain should be completely out of line with well-being. On the other hand, it's a noisy signal. Should it be taken at all seriously?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kAXnhBnNg74AoAo3Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 17, "extendedScore": null, "score": 9.749284101110493e-07, "legacy": true, "legacyId": "18530", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T16:20:59.210Z", "modifiedAt": null, "url": null, "title": "What's the Value of Information?", "slug": "what-s-the-value-of-information", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.231Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "johnlawrenceaspden", "createdAt": "2012-04-09T10:41:59.681Z", "isAdmin": false, "displayName": "johnlawrenceaspden"}, "userId": "NjYTzHAEAz44HitHH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zCc8i57z6Rwvy2KCd/what-s-the-value-of-information", "pageUrlRelative": "/posts/zCc8i57z6Rwvy2KCd/what-s-the-value-of-information", "linkUrl": "https://www.lesswrong.com/posts/zCc8i57z6Rwvy2KCd/what-s-the-value-of-information", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20the%20Value%20of%20Information%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20the%20Value%20of%20Information%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzCc8i57z6Rwvy2KCd%2Fwhat-s-the-value-of-information%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20the%20Value%20of%20Information%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzCc8i57z6Rwvy2KCd%2Fwhat-s-the-value-of-information", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzCc8i57z6Rwvy2KCd%2Fwhat-s-the-value-of-information", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 668, "htmlBody": "<p>I posted this problem to my own blog the other day. When I posted it, I thought it looked very easy, more fiddly than difficult:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p>The eccentric millionaire Oswald Mega walks into a bar and he says:</p>\n<p>\"This morning, I was showing my newborn about Dungeons and Dragons. We took a couple of six sided dice and rolled them, and wrote the results, which are just numbers from 2 to 12, on a piece of paper with 2D6 written at the top.</p>\n<p>Then we took a twelve sided dice, and we wrote 1D12 at the top of a piece of paper, and then we rolled it lots and wrote down the results, numbers between 1 and 12, on the paper.</p>\n<p>How she laughed at the difference in the patterns! Truly fatherhood is a joy.</p>\n<p>Now, I've brought one of the pieces of paper with me, and if you can tell me which one it is, I'll give you &pound;1000.</p>\n<p>How much would you be willing to pay me to know the value of the first result on the sheet?\"</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>I reasoned thus:</p>\n<p>There's no reason that you should have any opinion on which piece of paper he's brought. So you start off thinking 50:50, and that leads you to believe that he's effectively just given you &pound;500.</p>\n<p>If he tells you a number, then your belief will change. Say he tells you 1, then you know that he's brought the 1D12 results, and so you're now able to tell him that, and collect your &pound;1000.&nbsp;</p>\n<p>If he tells you 7, then that's twice as likely to be the 2D6 talking as the D12, and you should shift your prior to 1:3.</p>\n<p>If you've got a prior of 1:3, then your guess (that it's the 2D6) is now worth &pound;750, on average.</p>\n<p>So when you get a new number, your prior shifts, the bet changes value. Average over all the cases and that's what you'll pay to know the first number.</p>\n<p>Using this reckoning, I thought the answer to the puzzle was &pound;125.</p>\n<p>&nbsp;</p>\n<p>But now I'm not so sure, because the same reasoning tells you that if, for whatever reason, you start out 9:1 in favour of the 1D12, then the value of the new information is zero. (Because whatever the new information is, it won't be enough to change your mind).</p>\n<p>But can that really be true? Because that implies that if Omega keeps making you the same offer for &pound;1, then you should keep turning it down.</p>\n<p>But if he told you a hundred numbers, you'd be damned sure which piece of paper he'd brought. So surely they have some value over &pound;1?</p>\n<p>But maybe you say: \"Well, you can't put a value on the information unless you know how many extra opportunities you'll get.\"</p>\n<p>Really? I'm sure that I'd pay &pound;1 for the number in the original problem, and sure that I wouldn't pay &pound;1000.&nbsp;</p>\n<p>Where am I mis-thinking, and how should I calculate the answer to my puzzle?</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Edit:</p>\n<p>Just to clarify, if you buy the first number and it's a 2, and then you buy the second number and it's a 12, then I think you're now back in the same situation with a prior of 9:1 and an expected gain of &pound;900.&nbsp;</p>\n<p>I think you'd be mad to stop buying numbers at this point, since there's &pound;100 you're not certain of yet. But if I don't believe that the price is &pound;0, why do I believe that the price for the first one is &pound;125?</p>\n<p>\n<hr />\n</p>\n<p>Edit II:</p>\n<p>It seems that the opinion of most people is that the problem is under-determined, in the sense that you don't know what options are coming. Fair enough.</p>\n<p>In which case, what's wrong with the intuition that your beliefs alone determine the worth of your option to guess?</p>\n<p>And in the more specific version where Oswald charges a price of one penny for every result, and you can keep buying them one-by-one until you decide you're certain enough and guess, what criterion do you use to stop guessing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zCc8i57z6Rwvy2KCd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 19, "extendedScore": null, "score": 9.749352581740146e-07, "legacy": true, "legacyId": "18531", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T16:50:03.960Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] My Best and Worst Mistake", "slug": "seq-rerun-my-best-and-worst-mistake", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:23.609Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mjgMCi4SPt9SErSmN/seq-rerun-my-best-and-worst-mistake", "pageUrlRelative": "/posts/mjgMCi4SPt9SErSmN/seq-rerun-my-best-and-worst-mistake", "linkUrl": "https://www.lesswrong.com/posts/mjgMCi4SPt9SErSmN/seq-rerun-my-best-and-worst-mistake", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20My%20Best%20and%20Worst%20Mistake&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20My%20Best%20and%20Worst%20Mistake%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjgMCi4SPt9SErSmN%2Fseq-rerun-my-best-and-worst-mistake%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20My%20Best%20and%20Worst%20Mistake%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjgMCi4SPt9SErSmN%2Fseq-rerun-my-best-and-worst-mistake", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjgMCi4SPt9SErSmN%2Fseq-rerun-my-best-and-worst-mistake", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/tz/my_best_and_worst_mistake/\">My Best and Worst Mistake</a> was originally published on 16 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#My_Best_and_Worst_Mistake\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When Eliezer went into his death spiral around intelligence, he would up making a lot of mistakes that later became very useful.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ea7/seq_rerun_my_childhood_death_spiral/\">My Childhood Death Spiral</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mjgMCi4SPt9SErSmN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.749498627954933e-07, "legacy": true, "legacyId": "18532", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BA7dRRrzMLyvfJr9J", "TqJHYJSiWuBHpXvmB", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T18:10:11.996Z", "modifiedAt": null, "url": null, "title": "[LINK] A Meta-Inductive Approach to Hume's Problem of Induction", "slug": "link-a-meta-inductive-approach-to-hume-s-problem-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pragmatist", "createdAt": "2011-08-26T17:36:14.792Z", "isAdmin": false, "displayName": "pragmatist"}, "userId": "gs25cnPDLYqK8H68Q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s4oxMbvHhNqXuDt7t/link-a-meta-inductive-approach-to-hume-s-problem-of", "pageUrlRelative": "/posts/s4oxMbvHhNqXuDt7t/link-a-meta-inductive-approach-to-hume-s-problem-of", "linkUrl": "https://www.lesswrong.com/posts/s4oxMbvHhNqXuDt7t/link-a-meta-inductive-approach-to-hume-s-problem-of", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20A%20Meta-Inductive%20Approach%20to%20Hume's%20Problem%20of%20Induction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20A%20Meta-Inductive%20Approach%20to%20Hume's%20Problem%20of%20Induction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4oxMbvHhNqXuDt7t%2Flink-a-meta-inductive-approach-to-hume-s-problem-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20A%20Meta-Inductive%20Approach%20to%20Hume's%20Problem%20of%20Induction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4oxMbvHhNqXuDt7t%2Flink-a-meta-inductive-approach-to-hume-s-problem-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs4oxMbvHhNqXuDt7t%2Flink-a-meta-inductive-approach-to-hume-s-problem-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 715, "htmlBody": "<p>I just read a paper by Gerhard Schurz proposing an interesting resolution to the <a href=\"http://en.wikipedia.org/wiki/Problem_of_induction\">problem of induction</a>. Download a PDF <a href=\"http://www.phil-fak.uni-duesseldorf.de/fileadmin/Redaktion/Institute/Philosophie/Theoretische_Philosophie/Schurz/papers/2008cMetaIndPhilSci.pdf\">here</a>.</p>\n<p>Here's the abstract:</p>\n<blockquote>\n<p>This article suggests a &lsquo;best alternative&rsquo; justification of induction (in the sense of Reichenbach) which is based on <em>meta\u2010induction</em>. The meta\u2010inductivist applies the principle of induction to all competing prediction methods which are <em>accessible</em> to her. It is demonstrated, and illustrated by computer simulations, that there exist meta\u2010inductivistic prediction strategies whose success is approximately optimal among all accessible prediction methods in arbitrary possible worlds, and which dominate the success of every noninductive prediction strategy. The proposed justification of meta\u2010induction is mathematically analytical. It implies, however, an a posteriori justification of object\u2010induction based on the experiences in our world.</p>\n</blockquote>\n<p>Here's Schurz's description of meta-inductivism:</p>\n<blockquote>\n<p>The meta\u2010inductivist (MI) applies the inductive method at the level of competing prediction methods. More precisely, the meta\u2010inductivist bases her predictions on the predictions and the observed success rates of the other (non\u2010MI) players and tries to derive therefrom an &lsquo;optimal&rsquo; prediction. The simplest type of MI predicts what the presently best prediction method predicts, but one can construct much more refined kinds of meta\u2010inductivistic prediction strategies.</p>\n<p class=\"textIndent\">One should expect that for meta\u2010induction the chances of demonstrating optimality are much better than for object\u2010induction. The crucial question of this article will be: is it possible to design a version of meta\u2010induction which can be proved to be an (approximately) optimal prediction method? The significance of this question for the problem of induction is this: if the answer is positive, then at least meta\u2010induction would have a rational and noncircular justification based on a mathematical\u2010analytic argument. But this analytic justification of <em>meta\u2010induction</em> would at the same time yield an <em>a posteriori</em> justification of <em>object\u2010induction</em> in the real world: for we know by experience that in the real world, noninductive prediction strategies have not been successful so far, hence it would be meta\u2010inductively justified to favor object\u2010inductivistic strategies.</p>\n</blockquote>\n<p class=\"textIndent\">Here's the conclusion:</p>\n<blockquote>\n<p class=\"textIndent\">While one\u2010favorite meta\u2010inductive strategies are optimal only under certain restrictions, weighted\u2010average meta\u2010induction has turned out to be universally optimal...</p>\n<p class=\"textIndent\">In conclusion, I think the achieved optimality results on meta\u2010induction are strong enough to show that a noncircular justification of (meta\u2010)induction can be successful. This justification does not show that meta\u2010induction must be successful (in a strict or probabilistic sense), but it <em>favors</em> the meta\u2010inductivistic strategy against all other accessible competitors. This is sufficient for justificational purposes, without being in dissent with any of Hume&rsquo;s skeptical arguments. The given justification of meta\u2010induction is mathematically\u2010analytic (or &lsquo;a priori&rsquo;), insofar it does not make any assumptions about the nature of the considered worlds except from practically evident assumptions about prediction games, such that its players can perform calculations, can observe past events, and are free to decide. However, as we have explained in <a class=\"ref-type-sec\" href=\"http://www.jstor.org/stable/10.1086/592550#sc2\">Section 2</a>, this analytic justification of meta\u2010induction implies an a posteriori justification of object\u2010induction in our real word, because so far object\u2010induction has turned out to be the most successful prediction strategy. This argument is <em>no longer circular</em>, <em>given</em> that we have a noncircular justification of meta\u2010induction&mdash;and we have it.</p>\n<p class=\"textIndent\">The major advantage of the meta\u2010inductivistic approach is its <em>radical openness</em> towards all kinds of possibilities. In my view, this radical openness is a sign of all <em>good</em> foundation\u2010oriented (instead of &lsquo;foundationalistic&rsquo;) programs in epistemology. Unlike in Rescher&rsquo;s &ldquo;initial justification&rdquo; of induction (<a class=\"ref-type-bibr\" href=\"http://www.jstor.org/stable/10.1086/592550#rf9\">1980</a>, 82), meta\u2010induction does not exclude esoteric world\u2010views or prediction methods from the <em>start</em>. Such an a priori exclusion would prevent a constructive dialog between a scientific philosopher and an esoteric\u2010minded person. Meta\u2010induction takes all these possible world\u2010views initially seriously and argues: wherever the &lsquo;ultimate truth&rsquo; lies, you should in any case employ meta\u2010induction because it is universally optimal among all accessible prediction methods.</p>\n<p class=\"textIndent\">Many readers will still uphold skeptical reservations. They will ask: how can it <em>ever</em> be possible to prove that a strategy is optimal with respect to <em>every</em> other accessible strategy in <em>every</em> possible world&mdash;without assuming anything about the nature of alternative strategies and possible worlds? My heuristic answer to this <em>skeptical</em> challenge is as follows: this is possible for meta\u2010inductive strategies because these strategies are <em>universal learners</em>: whenever they are confronted with a so far better strategy, they can imitate the better strategy (output\u2010accessibility) or even learn to reproduce it (internal accessibility).</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s4oxMbvHhNqXuDt7t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 9.749901110380686e-07, "legacy": true, "legacyId": "18533", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-29T18:14:18.773Z", "modifiedAt": null, "url": null, "title": "What Are You Doing for Self-Quantification?", "slug": "what-are-you-doing-for-self-quantification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:37.836Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hackerkiba", "createdAt": "2010-09-17T02:45:39.493Z", "isAdmin": false, "displayName": "hackerkiba"}, "userId": "LssGgJYPEsFHPwyLy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gctsuvrdciajneQkY/what-are-you-doing-for-self-quantification", "pageUrlRelative": "/posts/gctsuvrdciajneQkY/what-are-you-doing-for-self-quantification", "linkUrl": "https://www.lesswrong.com/posts/gctsuvrdciajneQkY/what-are-you-doing-for-self-quantification", "postedAtFormatted": "Wednesday, August 29th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20Are%20You%20Doing%20for%20Self-Quantification%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20Are%20You%20Doing%20for%20Self-Quantification%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgctsuvrdciajneQkY%2Fwhat-are-you-doing-for-self-quantification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20Are%20You%20Doing%20for%20Self-Quantification%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgctsuvrdciajneQkY%2Fwhat-are-you-doing-for-self-quantification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgctsuvrdciajneQkY%2Fwhat-are-you-doing-for-self-quantification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>Right now, I am counting steps each day and I logged them on paper everyday, as close to midnight as much as possible. Only yesterday did I achieve my 10,000 steps goal. I have only been doing it since Sunday. This is my fourth day. Yesterday, I started logging my weight (on paper) to see if walking 10,000 steps will help me lose weight. Granted, it's rather manual, but also easy to do. &nbsp;If I try to purchase a pedometer that syncs to your computer automatically, it will costs me 99 USD brand new. Adding wireless output to my weighing scale will cost money too. There are two conditions that could lead me to purchasing sophisticated solutions: I am loaded with money and or I am&nbsp;overwhelmed&nbsp;with data input.</p>\n<p>For now, the important thing is that I keep doing it for 30-60 days for habit formations.&nbsp;</p>\n<p>&nbsp;</p>\n<p>What are you doing for self-quantification?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gctsuvrdciajneQkY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 8, "extendedScore": null, "score": 9.749921768797957e-07, "legacy": true, "legacyId": "18534", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-30T00:27:20.762Z", "modifiedAt": null, "url": null, "title": "Benefits of Calorie Restriction Linked To Other Factors", "slug": "benefits-of-calorie-restriction-linked-to-other-factors", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:23.835Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qMJqGTqxtCkHha8ki/benefits-of-calorie-restriction-linked-to-other-factors", "pageUrlRelative": "/posts/qMJqGTqxtCkHha8ki/benefits-of-calorie-restriction-linked-to-other-factors", "linkUrl": "https://www.lesswrong.com/posts/qMJqGTqxtCkHha8ki/benefits-of-calorie-restriction-linked-to-other-factors", "postedAtFormatted": "Thursday, August 30th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Benefits%20of%20Calorie%20Restriction%20Linked%20To%20Other%20Factors&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABenefits%20of%20Calorie%20Restriction%20Linked%20To%20Other%20Factors%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMJqGTqxtCkHha8ki%2Fbenefits-of-calorie-restriction-linked-to-other-factors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Benefits%20of%20Calorie%20Restriction%20Linked%20To%20Other%20Factors%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMJqGTqxtCkHha8ki%2Fbenefits-of-calorie-restriction-linked-to-other-factors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqMJqGTqxtCkHha8ki%2Fbenefits-of-calorie-restriction-linked-to-other-factors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html</p>\n<blockquote>\n<p><span style=\"color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif; font-size: 13px; line-height: 19.933332443237305px;\">We report here that a CR regimen implemented in young and older age rhesus monkeys at the National Institute on Aging (NIA) has not improved survival outcomes. Our findings contrast with an ongoing study at the Wisconsin National Primate Research Center (WNPRC), which reported improved survival associated with 30% CR initiated in adult rhesus monkeys (7&ndash;14</span><span class=\"mb\" style=\"font-family: 'arial unicode ms', 'lucida grande', 'lucida sans unicode', sans-serif !important; font-size: 13px; line-height: 19.933332443237305px; display: inline !important; visibility: visible !important; background-image: none !important; padding: 0px !important; color: #333333;\"><span class=\"mb\" style=\"font-size: inherit !important; line-height: inherit !important; display: inline !important; visibility: visible !important; background-image: none !important; background-color: transparent !important; padding: 0px !important;\">&thinsp;</span></span><span style=\"color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif; font-size: 13px; line-height: 19.933332443237305px;\">years)</span><sup style=\"font-size: 11px; line-height: 0; color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif;\"><a id=\"ref-link-5\" style=\"color: #5c7996; text-decoration: none;\" href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html#ref5\">5</a></sup><span style=\"color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif; font-size: 13px; line-height: 19.933332443237305px;\">&nbsp;and a preliminary report with a small number of CR monkeys</span><sup style=\"font-size: 11px; line-height: 0; color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif;\"><a id=\"ref-link-6\" style=\"color: #5c7996; text-decoration: none;\" href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html#ref6\">6</a></sup><span style=\"color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif; font-size: 13px; line-height: 19.933332443237305px;\">. Over the years, both NIA and WNPRC have extensively documented beneficial health effects of CR in these two apparently parallel studies. The implications of the WNPRC findings were important as they extended CR findings beyond the laboratory rodent and to a long-lived primate. Our study suggests a separation between health effects, morbidity and mortality, and similar to what has been shown in rodents</span><sup style=\"font-size: 11px; line-height: 0; color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif;\"><a id=\"ref-link-7\" style=\"color: #5c7996; text-decoration: none;\" href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html#ref7\">7</a>,&nbsp;<a id=\"ref-link-8\" style=\"color: #5c7996; text-decoration: none;\" href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html#ref8\">8</a>,&nbsp;<a id=\"ref-link-9\" style=\"color: #5c7996; text-decoration: none;\" href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature11432.html#ref9\">9</a></sup><span style=\"color: #333333; font-family: arial, helvetica, '\uff2d\uff33 \uff30\u30b4\u30b7\u30c3\u30af', '\uff2d\uff33 \u30b4\u30b7\u30c3\u30af', Osaka, 'MS PGothic', sans-serif; font-size: 13px; line-height: 19.933332443237305px;\">, study design, husbandry and diet composition may strongly affect the life-prolonging effect of CR in a long-lived nonhuman primate.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qMJqGTqxtCkHha8ki", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 12, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "18535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-30T04:13:58.655Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Raised in Technophilia", "slug": "seq-rerun-raised-in-technophilia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.284Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/niSNfhDbzi4rg8zJc/seq-rerun-raised-in-technophilia", "pageUrlRelative": "/posts/niSNfhDbzi4rg8zJc/seq-rerun-raised-in-technophilia", "linkUrl": "https://www.lesswrong.com/posts/niSNfhDbzi4rg8zJc/seq-rerun-raised-in-technophilia", "postedAtFormatted": "Thursday, August 30th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Raised%20in%20Technophilia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Raised%20in%20Technophilia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FniSNfhDbzi4rg8zJc%2Fseq-rerun-raised-in-technophilia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Raised%20in%20Technophilia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FniSNfhDbzi4rg8zJc%2Fseq-rerun-raised-in-technophilia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FniSNfhDbzi4rg8zJc%2Fseq-rerun-raised-in-technophilia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>Today's post, <a href=\"/lw/u0/raised_in_technophilia/\">Raised in Technophilia</a> was originally published on 17 September 2008. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Raised_in_Technophilia\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When Eliezer was quite young, it took him a very long time to get to the point where he was capable of considering that the dangers of technology might outweigh the benefits.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/eas/seq_rerun_my_best_and_worst_mistake/\">My Best and Worst Mistake</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "niSNfhDbzi4rg8zJc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.75293460197065e-07, "legacy": true, "legacyId": "18536", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uNWRXtdwL33ELgWjD", "mjgMCi4SPt9SErSmN", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-30T10:33:19.781Z", "modifiedAt": null, "url": null, "title": "[META] Karma for last 30 days?", "slug": "meta-karma-for-last-30-days", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:35.031Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mPJu6d2jMwvGuB2BT/meta-karma-for-last-30-days", "pageUrlRelative": "/posts/mPJu6d2jMwvGuB2BT/meta-karma-for-last-30-days", "linkUrl": "https://www.lesswrong.com/posts/mPJu6d2jMwvGuB2BT/meta-karma-for-last-30-days", "postedAtFormatted": "Thursday, August 30th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMETA%5D%20Karma%20for%20last%2030%20days%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMETA%5D%20Karma%20for%20last%2030%20days%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmPJu6d2jMwvGuB2BT%2Fmeta-karma-for-last-30-days%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMETA%5D%20Karma%20for%20last%2030%20days%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmPJu6d2jMwvGuB2BT%2Fmeta-karma-for-last-30-days", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmPJu6d2jMwvGuB2BT%2Fmeta-karma-for-last-30-days", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>Has anyone yet mentioned or reported that for the last couple days, the \"karma for last 30 days\" is showing zero for everyone? And that we no longer can see the top contributors for the last 30 days either?</p>\n<p>Do we have an explanation or estimation for a bugfix on this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mPJu6d2jMwvGuB2BT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 28, "extendedScore": null, "score": 9.754841390049591e-07, "legacy": true, "legacyId": "18549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 179, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-30T17:30:45.296Z", "modifiedAt": null, "url": null, "title": "Counterfactual resiliency test for non-causal models", "slug": "counterfactual-resiliency-test-for-non-causal-models", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:00.416Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YMwf9agAPTJPqgk9h/counterfactual-resiliency-test-for-non-causal-models", "pageUrlRelative": "/posts/YMwf9agAPTJPqgk9h/counterfactual-resiliency-test-for-non-causal-models", "linkUrl": "https://www.lesswrong.com/posts/YMwf9agAPTJPqgk9h/counterfactual-resiliency-test-for-non-causal-models", "postedAtFormatted": "Thursday, August 30th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Counterfactual%20resiliency%20test%20for%20non-causal%20models&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACounterfactual%20resiliency%20test%20for%20non-causal%20models%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMwf9agAPTJPqgk9h%2Fcounterfactual-resiliency-test-for-non-causal-models%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Counterfactual%20resiliency%20test%20for%20non-causal%20models%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMwf9agAPTJPqgk9h%2Fcounterfactual-resiliency-test-for-non-causal-models", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMwf9agAPTJPqgk9h%2Fcounterfactual-resiliency-test-for-non-causal-models", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2024, "htmlBody": "<h2>Non-causal models</h2>\n<p>Non-causal models are quite common in many fields, and can be quite accurate. Here predictions are made, based on (a particular selection of) past trends, and it is assumed that these trends will continue in future. There is no causal explanation offered for the trends under consideration: it's just assumed they will go on as before. Non-causal models are thus particularly useful when the underlying causality is uncertain or contentious. To illustrate the idea, here are three non-causal models in computer development:</p>\n<ol>\n<li><a href=\"http://en.wikipedia.org/wiki/Moore%27s_law\">Moore's laws</a> about the regular doubling of processing speed/hard disk size/other computer related parameter.</li>\n<li>Robin Hanson's <a href=\"http://hanson.gmu.edu/EconOfBrainEmulations.pdf\">model</a> where the development of human brains, hunting, agriculture and the industrial revolution are seen as related stages of accelerations of the underlying economic rate of growth, leading to the conclusion that there will be another surge during the next century (likely caused by <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf\">whole brain emulations</a> or AI).</li>\n<li>Ray Kurzweil's <a href=\"http://us.penguingroup.com/static/packages/us/kurzweil/excerpts/chap1/ch1botframe.htm\">law of time and chaos</a>, leading to his <a href=\"http://en.wikipedia.org/wiki/Accelerating_change#Kurzweil.27s_The_Law_of_Accelerating_Returns\">law of accelerating returns</a>. Here the inputs are the accelerating evolution of life on earth, the accelerating 'evolution' of technology, followed by the accelerating growth in the power of computing across many different substrates. This leads to a consequent 'singularity', an explosion of growth, at some point over the coming century.</li>\n</ol>\n<p>Before anything else, I should thank Moore, Hanson and Kurzweil for having the courage to publish their models and put them out there where they can be critiqued, mocked or praised. This is a brave step, and puts them a cut above most of us.</p>\n<p>That said, though I find the first argument quite convincing, I find have to say I find the other two dubious. Now, I'm not going to claim they're misusing the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Outside_view\">outside view</a>: if you accuse them of&nbsp;shoving together unrelated processes into a single model, they can equally well accuse you of ignoring&nbsp;the&nbsp;commonalities&nbsp;they have highlighted between these processes. Can we do better&nbsp;than that? There has to be a better guide to the truth that just our own private impressions.</p>\n<p><img style=\"text-align: center;\" src=\"http://images.lesswrong.com/t3_ea8_0.png?v=5e93ada8f253f77798107ea42c50674c\" alt=\"\" width=\"200\" height=\"160\" /><a id=\"more\"></a></p>\n<h2>Counterfactual resilience</h2>\n<p>One thing I'd like to do is test the resilience of the model - how robust are they to change. If model M makes prediction P from trends T and the real outcome will be O, we can test resiliency in two ways. First, we can change the world to change T (and hence P), without changing O, or we can change the world to change O, without changing T (and hence P). If we can do either or both, this is a strong indication that the model doesn't work.</p>\n<p>This all sounds highly dubious - how can we \"change the world\" in that way? I'm talking about considering <a href=\"/lw/sh/can_counterfactuals_be_true/\">counterfactuals</a>: alternate worlds whose history embodies the best of our knowledge as to how the real world works. To pick an extremely trivial example, imagine someone who maintains that the West's global domination was inevitable four centuries after Luther's&nbsp;<a href=\"http://en.wikipedia.org/wiki/The_Ninety-Five_Theses\">95 theses</a>&nbsp;thesis in 1517, <em>no matter what else happened outside Europe</em>. Then we can imagine&nbsp;counterfactually&nbsp;diverting huge asteroids to land in the Channel, or import hyper-virulent forms of bird flu from&nbsp;Asiatic&nbsp;Russia. According to everything we know about asteroid impacts,&nbsp;epidemiology and economics, this would not have lead to a&nbsp;dominant&nbsp;West for many centuries afterwards.</p>\n<p>That was an example of keeping T and P, and changing the outcome O. It is legitimate: we have preserved everything that went into the initial model, and made the prediction wrong. We could take the reverse approach: changing T and P while preserving the outcome O. To do so, we could imagine moving Luther (or some Luther-like character) to 1217, without changing the rest of European history much. To move Luther back in time, we could perfectly imagine that the Catholic church had started selling and abusing indulgences much earlier than they did - corrupt clerics were hardly an impossible idea in the middle ages. It requires a bit religious and social changes to have the 95 these&nbsp;make sense in the thirteenth century, but not all that much. Then we could imagine that Luther-like character being ignored or burnt, and the rest of Western history happening as usual, without western world dominance happening four centuries after that non-event (which is what M would have predicted). Notice that in both these cases, considering counterfactuals allows us to bring our knowledge or theories about other facts of the world to bear on assessing the model - we are no longer limited to simply debating the assumptions of the model itself.</p>\n<p>\"Objection!\" shouts my original strawman, at both my resiliency tests. \"Of course I didn't specify 'unless a meteor impacts'; that was implicit and obvious! When you say 'let's meet tomorrow', you don't generally add 'unless there's a nuclear war'! Also, I object to your moving Luther three centuries before and saying my model would predict the same thing in 1217. I was&nbsp;referring&nbsp;to Luther nailing up his theses, in the context of an educated&nbsp;literate&nbsp;population, with printing presses and a political system that was willing to stand up to the Catholic church. Also, I don't believe you when you say there would need to not be 'all that much' religious and social changes for early Luther to exist. You'd have to change so much, that there's no way you could put history back on the 'normal' track afterwards.\"</p>\n<p>Notice that the conversation has moved on from 'outside view' arguments, to making explicit implicit assumptions, extending the model, and arguing about our understanding of causality. Thus if these&nbsp;counterfactual&nbsp;resiliency tests don't break a model, they're likely to improve it, our understanding, and the debate.</p>\n<p>&nbsp;</p>\n<h2>The resilience of these models</h2>\n<p>So let's apply this to Robin Hanson's and Ray Kurzweil's models. I'll start with Robin's, as it's much more detailed.&nbsp;The key inputs of Robin's model are the time differences between the different revolutions (brains, hunting, agriculture, industry), and the growth rates after these revolutions. The prediction is that there is another revolution coming about three centuries after the industrial revolution, and that after this the economy will double every 1-2 weeks. He then makes the point that the only plausible way for this to happen is through the creation of brain emulations or AIs - copyable human capital. I'll also assume the implicit \"no disaster\" assumption: meteor strikes or <a href=\"http://www.overcomingbias.com/2012/07/is-world-government-inevitable.html\">world governments</a> bent on banning AI research. How does this fare in counterfactuals?</p>\n<p>It seems rather easy to mess with the inputs T. Weather conditions or continental drifts could confine pre-agricultural humans to hunting essentially&nbsp;indefinitely, followed by a slow evolution to agriculture when the climate improved or more lands became available. Conversely, we could imagine incredibly nutritious crops that were easy to cultivate, and hundreds of&nbsp;domesticable&nbsp;species, rather than the <a href=\"http://en.wikipedia.org/wiki/List_of_domesticated_animals\">30-40</a> we actually had. Combine this with a mass die-off of game and some strong evolutionary pressure, and we could end up with agriculture starting much more rapidly.</p>\n<p>This sounds unfair - are these not huge transformations to the human world and the natural world that I'm positing here? Indeed I am, but Robin's model is that these differential growth rates have predictive ability, not that these differential growth rates combined with a detailed historical analysis of many contingent factors have predictive ability. If the model were to claim that the vagaries of plate&nbsp;tectonics&nbsp;and the number of easily domesticated species in early human development have relevance to how long after the industrial revolution would brain emulations be&nbsp;developed, then something has gone wrong with it.</p>\n<p>Continuing on this vein, we can certainly move the industrial revolution back in time. The ancient Greek world, with its <a href=\"http://en.wikipedia.org/wiki/Aeolipile\">steam engines</a>, philosophers and mathematicians, seems an ideal location for a counterfactual. Any philosophical, social or initial technological development that we could label as essential to industrialisation, could at least plausibly have arisen in a Greek city or colony - possibly over a longer period of time.</p>\n<p>We can also tweak the speed of economic growth. The yield on hunting can be changed through the availability or absence of convenient prey animals. During the agricultural era, we could posit high-yield crops and an enlightened despot who put in place some understandable-to-ancient-people elements of the <a href=\"http://en.wikipedia.org/wiki/Green_revolution\">green revolution</a> - or conversely, poor yield crops suffering from frequent blight. Easy or difficult access to coal would affect growth during the industrial era, or we could jump ahead by having the internal combustion engine, not the steam engine, as the initial prime driver of industrialisation. The computer era could be brought forwards by having <a href=\"http://en.wikipedia.org/wiki/Babbage\">Babbage</a> complete his machines for the British government, or pushed backwards by removing Turing from the equation and assuming the Second World War didn't happen.</p>\n<p>You may disagree with some of these ideas, but it seems to me that there are just too many contingent factors that can mess up the input to the model, leading some putative parallel-universe Robin Hanson to give completely different times to brain emulations. This suggests the model is not very resilient.</p>\n<p>Or we can look at the reverse: making whole brain emulations much easier, or much harder, than they are now, without touching the inputs to the model at all (and hence its predictions). For instance, if humans were descendant from a hibernating species, it's perfectly conceivable that we could have brains that would be easy to fixate and slice up for building emulations. Other changes to our brain design could also make this easier. It might be that our brains had a different&nbsp;architecture, one where it was much simpler to isolate a small \"consciousness module\" or \"decision making module\". Under these assumptions, we could conceivably have had adequate emulations back in the 60s or 70s! Again, these assumptions are false - life didn't happen like that, it may be impossible for life to happen like that - but knowing that these assumptions are false requires knowledge that is neither explicitly nor&nbsp;implicitly&nbsp;in the model. And of course we have converses: brain&nbsp;architectures&nbsp;too gnarly and delicate to <a href=\"http://en.wikipedia.org/wiki/Exhalation_(story)\">fix and slice</a>. Early or late neuroscience&nbsp;breakthroughs (and greater or lesser technological or medical returns on these breakthroughs). Greater or lesser popular interest in brain&nbsp;architecture.</p>\n<p>For these reasons, it seems to me that Robin Hanson's model fails the counterfactual resiliency test. Ray Kuzweil's model suffers similarly - since Kurweil's model includes the whole of evolutionary history (including disasters), we can play around with climate, asteroid collisions and tectonics to make evolution happen at very different rates (one easy change is to kill off all humans in the <a href=\"http://en.wikipedia.org/wiki/Toba_catastrophe_theory\">Toba catastrophe</a>). Shifting around the date of the technological breakthroughs and that of first computer still messes up with the model, and backdating important insights allows us to imagine much earlier AIs.</p>\n<p>And then there's Moore's law, starting with Moore's <a href=\"http://download.intel.com/museum/Moores_Law/Articles-Press_Releases/Gordon_Moore_1965_Article.pdf\">1965 paper</a>... The difference is immediately obvious, as we start trying to apply the same tricks to Moore's law. Where even to start? Maybe certain transistors designs are not available? Maybe silicon is hard to get ahold of rather than being&nbsp;ubiquitous? Maybe Intel went bust at an early stage? Maybe no-one discovered <a href=\"http://en.wikipedia.org/wiki/Photolithography\">photolithography</a>? Maybe some specific use of computers wasn't thought of, so demand was reduced? Maybe some special new chip design was imagined ahead of time?</p>\n<p>None of these seem to clearly lead to situations where Moore's law would fail. We don't really know what causes Moore's law, but it has been robust for moves to very different technologies, and has spanned cultural transformations and changes in the purpose and uses of computers. It seems to lie at the interaction between markets demand, technological development, and implementation. Some trivial change could conceivably throw it off its rails - but we just don't know what, which means we can't bring our knowledge about other facts in the world to bear.</p>\n<p>&nbsp;</p>\n<h2>In conclusion: more work needed</h2>\n<p>It was the comparative ease with which we could change the components of the other two models that revealed their lack of resilience; it is the difficulty of doing so with Moore's law that shows it is resilient.</p>\n<p>I've never seen this approach used before; more resilience tests only involve changing numerical parameters from inside the model. Certainly the approach needs to be improved: it feels very informal and subjective for the moment. Nevertheless, I feel that it has afforded me some genuine insights, and I'm hoping to improve and formalise it in future - with any feedback I get here, of course.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YpHkTW27iMFR2Dkae": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YMwf9agAPTJPqgk9h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 33, "extendedScore": null, "score": 9.756940314907682e-07, "legacy": true, "legacyId": "18512", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Non_causal_models\">Non-causal models</h2>\n<p>Non-causal models are quite common in many fields, and can be quite accurate. Here predictions are made, based on (a particular selection of) past trends, and it is assumed that these trends will continue in future. There is no causal explanation offered for the trends under consideration: it's just assumed they will go on as before. Non-causal models are thus particularly useful when the underlying causality is uncertain or contentious. To illustrate the idea, here are three non-causal models in computer development:</p>\n<ol>\n<li><a href=\"http://en.wikipedia.org/wiki/Moore%27s_law\">Moore's laws</a> about the regular doubling of processing speed/hard disk size/other computer related parameter.</li>\n<li>Robin Hanson's <a href=\"http://hanson.gmu.edu/EconOfBrainEmulations.pdf\">model</a> where the development of human brains, hunting, agriculture and the industrial revolution are seen as related stages of accelerations of the underlying economic rate of growth, leading to the conclusion that there will be another surge during the next century (likely caused by <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf\">whole brain emulations</a> or AI).</li>\n<li>Ray Kurzweil's <a href=\"http://us.penguingroup.com/static/packages/us/kurzweil/excerpts/chap1/ch1botframe.htm\">law of time and chaos</a>, leading to his <a href=\"http://en.wikipedia.org/wiki/Accelerating_change#Kurzweil.27s_The_Law_of_Accelerating_Returns\">law of accelerating returns</a>. Here the inputs are the accelerating evolution of life on earth, the accelerating 'evolution' of technology, followed by the accelerating growth in the power of computing across many different substrates. This leads to a consequent 'singularity', an explosion of growth, at some point over the coming century.</li>\n</ol>\n<p>Before anything else, I should thank Moore, Hanson and Kurzweil for having the courage to publish their models and put them out there where they can be critiqued, mocked or praised. This is a brave step, and puts them a cut above most of us.</p>\n<p>That said, though I find the first argument quite convincing, I find have to say I find the other two dubious. Now, I'm not going to claim they're misusing the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Outside_view\">outside view</a>: if you accuse them of&nbsp;shoving together unrelated processes into a single model, they can equally well accuse you of ignoring&nbsp;the&nbsp;commonalities&nbsp;they have highlighted between these processes. Can we do better&nbsp;than that? There has to be a better guide to the truth that just our own private impressions.</p>\n<p><img style=\"text-align: center;\" src=\"http://images.lesswrong.com/t3_ea8_0.png?v=5e93ada8f253f77798107ea42c50674c\" alt=\"\" width=\"200\" height=\"160\"><a id=\"more\"></a></p>\n<h2 id=\"Counterfactual_resilience\">Counterfactual resilience</h2>\n<p>One thing I'd like to do is test the resilience of the model - how robust are they to change. If model M makes prediction P from trends T and the real outcome will be O, we can test resiliency in two ways. First, we can change the world to change T (and hence P), without changing O, or we can change the world to change O, without changing T (and hence P). If we can do either or both, this is a strong indication that the model doesn't work.</p>\n<p>This all sounds highly dubious - how can we \"change the world\" in that way? I'm talking about considering <a href=\"/lw/sh/can_counterfactuals_be_true/\">counterfactuals</a>: alternate worlds whose history embodies the best of our knowledge as to how the real world works. To pick an extremely trivial example, imagine someone who maintains that the West's global domination was inevitable four centuries after Luther's&nbsp;<a href=\"http://en.wikipedia.org/wiki/The_Ninety-Five_Theses\">95 theses</a>&nbsp;thesis in 1517, <em>no matter what else happened outside Europe</em>. Then we can imagine&nbsp;counterfactually&nbsp;diverting huge asteroids to land in the Channel, or import hyper-virulent forms of bird flu from&nbsp;Asiatic&nbsp;Russia. According to everything we know about asteroid impacts,&nbsp;epidemiology and economics, this would not have lead to a&nbsp;dominant&nbsp;West for many centuries afterwards.</p>\n<p>That was an example of keeping T and P, and changing the outcome O. It is legitimate: we have preserved everything that went into the initial model, and made the prediction wrong. We could take the reverse approach: changing T and P while preserving the outcome O. To do so, we could imagine moving Luther (or some Luther-like character) to 1217, without changing the rest of European history much. To move Luther back in time, we could perfectly imagine that the Catholic church had started selling and abusing indulgences much earlier than they did - corrupt clerics were hardly an impossible idea in the middle ages. It requires a bit religious and social changes to have the 95 these&nbsp;make sense in the thirteenth century, but not all that much. Then we could imagine that Luther-like character being ignored or burnt, and the rest of Western history happening as usual, without western world dominance happening four centuries after that non-event (which is what M would have predicted). Notice that in both these cases, considering counterfactuals allows us to bring our knowledge or theories about other facts of the world to bear on assessing the model - we are no longer limited to simply debating the assumptions of the model itself.</p>\n<p>\"Objection!\" shouts my original strawman, at both my resiliency tests. \"Of course I didn't specify 'unless a meteor impacts'; that was implicit and obvious! When you say 'let's meet tomorrow', you don't generally add 'unless there's a nuclear war'! Also, I object to your moving Luther three centuries before and saying my model would predict the same thing in 1217. I was&nbsp;referring&nbsp;to Luther nailing up his theses, in the context of an educated&nbsp;literate&nbsp;population, with printing presses and a political system that was willing to stand up to the Catholic church. Also, I don't believe you when you say there would need to not be 'all that much' religious and social changes for early Luther to exist. You'd have to change so much, that there's no way you could put history back on the 'normal' track afterwards.\"</p>\n<p>Notice that the conversation has moved on from 'outside view' arguments, to making explicit implicit assumptions, extending the model, and arguing about our understanding of causality. Thus if these&nbsp;counterfactual&nbsp;resiliency tests don't break a model, they're likely to improve it, our understanding, and the debate.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_resilience_of_these_models\">The resilience of these models</h2>\n<p>So let's apply this to Robin Hanson's and Ray Kurzweil's models. I'll start with Robin's, as it's much more detailed.&nbsp;The key inputs of Robin's model are the time differences between the different revolutions (brains, hunting, agriculture, industry), and the growth rates after these revolutions. The prediction is that there is another revolution coming about three centuries after the industrial revolution, and that after this the economy will double every 1-2 weeks. He then makes the point that the only plausible way for this to happen is through the creation of brain emulations or AIs - copyable human capital. I'll also assume the implicit \"no disaster\" assumption: meteor strikes or <a href=\"http://www.overcomingbias.com/2012/07/is-world-government-inevitable.html\">world governments</a> bent on banning AI research. How does this fare in counterfactuals?</p>\n<p>It seems rather easy to mess with the inputs T. Weather conditions or continental drifts could confine pre-agricultural humans to hunting essentially&nbsp;indefinitely, followed by a slow evolution to agriculture when the climate improved or more lands became available. Conversely, we could imagine incredibly nutritious crops that were easy to cultivate, and hundreds of&nbsp;domesticable&nbsp;species, rather than the <a href=\"http://en.wikipedia.org/wiki/List_of_domesticated_animals\">30-40</a> we actually had. Combine this with a mass die-off of game and some strong evolutionary pressure, and we could end up with agriculture starting much more rapidly.</p>\n<p>This sounds unfair - are these not huge transformations to the human world and the natural world that I'm positing here? Indeed I am, but Robin's model is that these differential growth rates have predictive ability, not that these differential growth rates combined with a detailed historical analysis of many contingent factors have predictive ability. If the model were to claim that the vagaries of plate&nbsp;tectonics&nbsp;and the number of easily domesticated species in early human development have relevance to how long after the industrial revolution would brain emulations be&nbsp;developed, then something has gone wrong with it.</p>\n<p>Continuing on this vein, we can certainly move the industrial revolution back in time. The ancient Greek world, with its <a href=\"http://en.wikipedia.org/wiki/Aeolipile\">steam engines</a>, philosophers and mathematicians, seems an ideal location for a counterfactual. Any philosophical, social or initial technological development that we could label as essential to industrialisation, could at least plausibly have arisen in a Greek city or colony - possibly over a longer period of time.</p>\n<p>We can also tweak the speed of economic growth. The yield on hunting can be changed through the availability or absence of convenient prey animals. During the agricultural era, we could posit high-yield crops and an enlightened despot who put in place some understandable-to-ancient-people elements of the <a href=\"http://en.wikipedia.org/wiki/Green_revolution\">green revolution</a> - or conversely, poor yield crops suffering from frequent blight. Easy or difficult access to coal would affect growth during the industrial era, or we could jump ahead by having the internal combustion engine, not the steam engine, as the initial prime driver of industrialisation. The computer era could be brought forwards by having <a href=\"http://en.wikipedia.org/wiki/Babbage\">Babbage</a> complete his machines for the British government, or pushed backwards by removing Turing from the equation and assuming the Second World War didn't happen.</p>\n<p>You may disagree with some of these ideas, but it seems to me that there are just too many contingent factors that can mess up the input to the model, leading some putative parallel-universe Robin Hanson to give completely different times to brain emulations. This suggests the model is not very resilient.</p>\n<p>Or we can look at the reverse: making whole brain emulations much easier, or much harder, than they are now, without touching the inputs to the model at all (and hence its predictions). For instance, if humans were descendant from a hibernating species, it's perfectly conceivable that we could have brains that would be easy to fixate and slice up for building emulations. Other changes to our brain design could also make this easier. It might be that our brains had a different&nbsp;architecture, one where it was much simpler to isolate a small \"consciousness module\" or \"decision making module\". Under these assumptions, we could conceivably have had adequate emulations back in the 60s or 70s! Again, these assumptions are false - life didn't happen like that, it may be impossible for life to happen like that - but knowing that these assumptions are false requires knowledge that is neither explicitly nor&nbsp;implicitly&nbsp;in the model. And of course we have converses: brain&nbsp;architectures&nbsp;too gnarly and delicate to <a href=\"http://en.wikipedia.org/wiki/Exhalation_(story)\">fix and slice</a>. Early or late neuroscience&nbsp;breakthroughs (and greater or lesser technological or medical returns on these breakthroughs). Greater or lesser popular interest in brain&nbsp;architecture.</p>\n<p>For these reasons, it seems to me that Robin Hanson's model fails the counterfactual resiliency test. Ray Kuzweil's model suffers similarly - since Kurweil's model includes the whole of evolutionary history (including disasters), we can play around with climate, asteroid collisions and tectonics to make evolution happen at very different rates (one easy change is to kill off all humans in the <a href=\"http://en.wikipedia.org/wiki/Toba_catastrophe_theory\">Toba catastrophe</a>). Shifting around the date of the technological breakthroughs and that of first computer still messes up with the model, and backdating important insights allows us to imagine much earlier AIs.</p>\n<p>And then there's Moore's law, starting with Moore's <a href=\"http://download.intel.com/museum/Moores_Law/Articles-Press_Releases/Gordon_Moore_1965_Article.pdf\">1965 paper</a>... The difference is immediately obvious, as we start trying to apply the same tricks to Moore's law. Where even to start? Maybe certain transistors designs are not available? Maybe silicon is hard to get ahold of rather than being&nbsp;ubiquitous? Maybe Intel went bust at an early stage? Maybe no-one discovered <a href=\"http://en.wikipedia.org/wiki/Photolithography\">photolithography</a>? Maybe some specific use of computers wasn't thought of, so demand was reduced? Maybe some special new chip design was imagined ahead of time?</p>\n<p>None of these seem to clearly lead to situations where Moore's law would fail. We don't really know what causes Moore's law, but it has been robust for moves to very different technologies, and has spanned cultural transformations and changes in the purpose and uses of computers. It seems to lie at the interaction between markets demand, technological development, and implementation. Some trivial change could conceivably throw it off its rails - but we just don't know what, which means we can't bring our knowledge about other facts in the world to bear.</p>\n<p>&nbsp;</p>\n<h2 id=\"In_conclusion__more_work_needed\">In conclusion: more work needed</h2>\n<p>It was the comparative ease with which we could change the components of the other two models that revealed their lack of resilience; it is the difficulty of doing so with Moore's law that shows it is resilient.</p>\n<p>I've never seen this approach used before; more resilience tests only involve changing numerical parameters from inside the model. Certainly the approach needs to be improved: it feels very informal and subjective for the moment. Nevertheless, I feel that it has afforded me some genuine insights, and I'm hoping to improve and formalise it in future - with any feedback I get here, of course.</p>", "sections": [{"title": "Non-causal models", "anchor": "Non_causal_models", "level": 1}, {"title": "Counterfactual resilience", "anchor": "Counterfactual_resilience", "level": 1}, {"title": "The resilience of these models", "anchor": "The_resilience_of_these_models", "level": 1}, {"title": "In conclusion: more work needed", "anchor": "In_conclusion__more_work_needed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "78 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dhGGnB2oxBP3m5cBc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-30T21:12:22.690Z", "modifiedAt": null, "url": null, "title": "Do you BayesBlog?  Richard Carrier is looking for links", "slug": "do-you-bayesblog-richard-carrier-is-looking-for-links", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:25.612Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "palladias", "createdAt": "2012-04-03T13:45:53.766Z", "isAdmin": false, "displayName": "palladias"}, "userId": "Bv2LXWzZf96WGpqJ5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mz4z6fQRHyXFo4AW2/do-you-bayesblog-richard-carrier-is-looking-for-links", "pageUrlRelative": "/posts/mz4z6fQRHyXFo4AW2/do-you-bayesblog-richard-carrier-is-looking-for-links", "linkUrl": "https://www.lesswrong.com/posts/mz4z6fQRHyXFo4AW2/do-you-bayesblog-richard-carrier-is-looking-for-links", "postedAtFormatted": "Thursday, August 30th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20you%20BayesBlog%3F%20%20Richard%20Carrier%20is%20looking%20for%20links&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20you%20BayesBlog%3F%20%20Richard%20Carrier%20is%20looking%20for%20links%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmz4z6fQRHyXFo4AW2%2Fdo-you-bayesblog-richard-carrier-is-looking-for-links%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20you%20BayesBlog%3F%20%20Richard%20Carrier%20is%20looking%20for%20links%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmz4z6fQRHyXFo4AW2%2Fdo-you-bayesblog-richard-carrier-is-looking-for-links", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmz4z6fQRHyXFo4AW2%2Fdo-you-bayesblog-richard-carrier-is-looking-for-links", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 177, "htmlBody": "<p>Richard Carrier is a naturalist philosopher, a blogger for FreeThought Blogs (an atheist portal), and the creator of a <a href=\"http://www.richardcarrier.info/bayescalculator.html\">Bayesian calculator</a> website. &nbsp;<a href=\"http://freethoughtblogs.com/carrier/archives/2482/\">He's looking for more places to read people noodling about Bayes</a> (and he already knows about LW).</p>\n<blockquote>\n<p>This is a request to all fans of Bayes&rsquo; Theorem out there: I&rsquo;m looking for the best blogs and websites substantially devoted to discussing all things Bayesian. &nbsp;</p>\n<p>[He lists a few Bayes links that don't match his criteria]</p>\n<p>But none of these are blogs or websites that regularly produce discussion and articles about Bayesian reasoning. And I&rsquo;m looking for the best of the latter. I&rsquo;m looking for more stuff like Less Wrong or Maximum Entropy. If there is any. It can be basic intro level stuff, or advanced, but it should be good reading either way, the kind of place a general Bayesian might want to visit monthly to see what&rsquo;s going down.</p>\n</blockquote>\n<p>Pop on over if you have recommendations, and feel free to crosspost here. &nbsp;Looking for a tighter filter than just <a href=\"/r/discussion/lw/d8t/blogs_by_lwers/\">Blogs by LWers</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mz4z6fQRHyXFo4AW2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 9.758055019890833e-07, "legacy": true, "legacyId": "18552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["h83ZzxEpKiPPjsRKs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T03:41:37.267Z", "modifiedAt": null, "url": null, "title": "Utility functions and quantum mechanics", "slug": "utility-functions-and-quantum-mechanics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:07.017Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i5GdiGa5SGhJnDEK8/utility-functions-and-quantum-mechanics", "pageUrlRelative": "/posts/i5GdiGa5SGhJnDEK8/utility-functions-and-quantum-mechanics", "linkUrl": "https://www.lesswrong.com/posts/i5GdiGa5SGhJnDEK8/utility-functions-and-quantum-mechanics", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Utility%20functions%20and%20quantum%20mechanics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUtility%20functions%20and%20quantum%20mechanics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5GdiGa5SGhJnDEK8%2Futility-functions-and-quantum-mechanics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Utility%20functions%20and%20quantum%20mechanics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5GdiGa5SGhJnDEK8%2Futility-functions-and-quantum-mechanics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi5GdiGa5SGhJnDEK8%2Futility-functions-and-quantum-mechanics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1077, "htmlBody": "<p>Interpreting quantum mechanics throws an interesting wrench into utility calculation.</p>\n<p>Utility functions, according to the interpretation typical in these parts, are a function of the state of the world, and an agent with consistent goals acts to maximize the expected value of their utility function. Within the many-worlds interpretation (MWI) of quantum mechanics (QM), things become interesting because \"the state of the world\" refers to a wavefunction which contains all possibilities, merely in differing amounts. With an inherently probabilistic interpretation of QM, flipping a quantum coin <em>has</em> to be treated linearly by our rational agent - that is, when calculating expected utility, they have to average the expected utilities from each half. But if flipping a quantum coin is just an operation on the state of the world, then you can use <em>any function you want</em> when calculating expected utility.</p>\n<p>And all coins, when you get down to it, are quantum. At the extreme, this leads to the possible rationality of quantum suicide - since you're alive in the quantum state <em>somewhere</em>, just claim that your utility function non-linearly focuses on the part where you're alive.</p>\n<p>As you may have heard, there have been several papers in the quantum mechanics literature that claim to recover ordinary rules for calculating expected utility in MWI - how does that work?</p>\n<p>Well, when they're not simply wrong (for example, by replacing a state labeled by the number a+b with the state <a href=\"http://en.wikipedia.org/wiki/Bra-ket_notation\">|a&gt; + |b&gt;</a>), they usually go about it with the <a href=\"http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem\">Von Neumann-Morgenstern axioms</a>, modified to refer to quantum mechanics:</p>\n<ol>\n<li>Completeness: Every state can be compared to every other, preferencewise.</li>\n<li>Transitivity: If you prefer |A&gt; to |B&gt; and |B&gt; to |C&gt;, you also prefer |A&gt; to |C&gt;.</li>\n<li>Continuity: If you prefer |A&gt; to |B&gt; and |B&gt; to |C&gt;, there's some quantum-mechanical <a href=\"http://en.wikipedia.org/wiki/Probability_measure\">measure</a>&nbsp;(note that this is a change from \"probability\") X such that you're indifferent between (1-X)|A&gt; + X|C&gt; and |B&gt;.</li>\n<li>Independence: If you prefer |A&gt; to |B&gt;, then you also prefer (1-X)|A&gt; + X|C&gt; to (1-X)|B&gt; + X|C&gt;, where |C&gt; can be anything and X isn't 1.</li>\n</ol>\n<p>In classical cases, these four axioms are easy to accept, and lead directly to utility functions with X as a probability. In quantum mechanical cases, the axioms are harder to accept, but&nbsp;the only measure available is indeed the ordinary amplitude-squared measure (this last fact features prominently in Everett's original paper). This gives you back the traditional rule for calculating expected utilities.</p>\n<p>For an example of why these axioms are weird in quantum mechanics, consider the case of light. Linearly polarized light is actually the same thing as an equal superposition of right-handed and left-handed circularly polarized light. This has the interesting consequence that even when light is linearly polarized, if you shine it on atoms, those atoms will change their spins - they'll just change half right and half left. Or if you take circularly polarized light and shine it on a linear polarizer, half of it will go through. So anyhow, we can make axiom 4 read \"If you are indifferent between left-polarized light and right-polarized light, then you must also be indifferent between linearly polarized light (i.e. left+right) and circularly polarized light (right+right).\" But... can't a guy just want circularly polarized light?</p>\n<p>Under what sort of conditions does the independence axiom make intuitive sense? Ones where something more complicated than a photon is being considered. Something like <em>you</em>. If MWI is correct and you measure the polarization of linearly polarized light vs. circularly polarized light, this puts your brain in a superposition of linear vs. circular. But nobody says \"boy, I really want a circularly polarized <em>brain</em>.\"</p>\n<p>A key factor, as is often the case when talking about recovering classical behavior from quantum mechanics, is <a href=\"http://en.wikipedia.org/wiki/Quantum_decoherence\">decoherence</a>. If you carefully prepare your brain in a circularly polarized state, and you interact with an enormous random system (like by breathing air, or emitting thermal radiation), your carefully prepared brain-state is going to get <em>shredded</em>. It's a fascinating property of quantum mechanics that once you \"leak\" information to the outside, things are qualitatively different. If we have a pair of entangled particles and a classical phone line, I can send you an <em>exact</em> quantum state - it's called <a href=\"http://en.wikipedia.org/wiki/Quantum_teleportation\">quantum teleportation</a>, and it's sweet. But if one of our particles leaks even the tiniest bit, even if we just end up with three particles entangled instead of two, our ability to transmit quantum states is gone completely.</p>\n<p>In essence, the states we started with were \"close together\" in the space where quantum mechanics lives (Hilbert space), and so they could interact via quantum mechanics. Interacting with the outside even a little scattered our entangled particles farther apart.</p>\n<p>Any virus, dust speck, or human being is constantly interacting with the outside world. States that are far enough apart to be perceptibly different to us aren't just \"one parallel world away,\" like would make a good story - they are cracked wide open, spread out in the atmosphere as soon as you breathe it, spread by the Earth as soon as you push on it with your weight. If we were photons, one could easily connect with their \"other selves\" - if you try to change your polarization, whether you succeed or fail will depend on the orientation of your oppositely-polarized \"other self\"! But once you've interacted with the Earth, this quantum interference becomes negligible - so negligible that we seem to neglect it. When we make a plan, we don't worry that our nega-self might plan the opposite and we'll cancel each other out.</p>\n<p>Does this sort of separation explain an&nbsp;approximate&nbsp;independence axiom, which is necessary for the usual rules for expected utility? Yes.</p>\n<p>Because of decoherence, non-classical interactions are totally&nbsp;invisible&nbsp;to unaided primates, so it's expected that our morality neglects them. And if the states we are comparing are noticeably different, they're never going to interact, so independence is much more intuitive than in the case of a single photon. Taken together with the other axioms, which still make a lot of sense, this defines expected utility maximization with the Born rule.</p>\n<p>So this is my take on utility functions in quantum mechanics - any living thing big enough to have a goal system will also be big enough to neglect interaction between&nbsp;noticeably&nbsp;different states, and thus make decisions as if the amplitude squared was a probability. With the help of technology, we can create systems where the independence axiom breaks down, but these systems are things like photons or small loops of superconducting wire, not humans.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i5GdiGa5SGhJnDEK8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 14, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "18062", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T04:33:40.310Z", "modifiedAt": null, "url": null, "title": "[Link] Short story by Yvain", "slug": "link-short-story-by-yvain", "viewCount": null, "lastCommentedAt": "2020-08-15T13:11:42.366Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kZLuM8Aez3vgK2CSy/link-short-story-by-yvain", "pageUrlRelative": "/posts/kZLuM8Aez3vgK2CSy/link-short-story-by-yvain", "linkUrl": "https://www.lesswrong.com/posts/kZLuM8Aez3vgK2CSy/link-short-story-by-yvain", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Short%20story%20by%20Yvain&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Short%20story%20by%20Yvain%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkZLuM8Aez3vgK2CSy%2Flink-short-story-by-yvain%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Short%20story%20by%20Yvain%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkZLuM8Aez3vgK2CSy%2Flink-short-story-by-yvain", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkZLuM8Aez3vgK2CSy%2Flink-short-story-by-yvain", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p>Yvain isn't a big enough self-promoter to link to this, but I liked it a lot and I think you will too.</p>\n<p><a href=\"http://squid314.livejournal.com/324957.html\">\"The Last Temptation of Christ\"</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kZLuM8Aez3vgK2CSy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 42, "extendedScore": null, "score": 9.760275278745463e-07, "legacy": true, "legacyId": "18561", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T04:37:43.710Z", "modifiedAt": null, "url": null, "title": "Meetup : Washigton DC (probably) minicamp meetup", "slug": "meetup-washigton-dc-probably-minicamp-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MfJbvGqciAwW2BFox/meetup-washigton-dc-probably-minicamp-meetup", "pageUrlRelative": "/posts/MfJbvGqciAwW2BFox/meetup-washigton-dc-probably-minicamp-meetup", "linkUrl": "https://www.lesswrong.com/posts/MfJbvGqciAwW2BFox/meetup-washigton-dc-probably-minicamp-meetup", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washigton%20DC%20(probably)%20minicamp%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washigton%20DC%20(probably)%20minicamp%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfJbvGqciAwW2BFox%2Fmeetup-washigton-dc-probably-minicamp-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washigton%20DC%20(probably)%20minicamp%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfJbvGqciAwW2BFox%2Fmeetup-washigton-dc-probably-minicamp-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfJbvGqciAwW2BFox%2Fmeetup-washigton-dc-probably-minicamp-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dc'>Washigton DC (probably) minicamp meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 September 2012 03:00:00AM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Portrait Gallery, Washington DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry about the late notice, but the next meetup will be this Sunday, September 2 at  3 pm. Tentative plan is to talk about minicamp stuff again.</p>\n\n<p>Unless someone volunteers a place, we're going to meet at the Portrait Gallary plaza, near the Chinatown Metro stop.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dc'>Washigton DC (probably) minicamp meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MfJbvGqciAwW2BFox", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 9.76029569291858e-07, "legacy": true, "legacyId": "18562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washigton_DC__probably__minicamp_meetup\">Discussion article for the meetup : <a href=\"/meetups/dc\">Washigton DC (probably) minicamp meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 September 2012 03:00:00AM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Portrait Gallery, Washington DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry about the late notice, but the next meetup will be this Sunday, September 2 at  3 pm. Tentative plan is to talk about minicamp stuff again.</p>\n\n<p>Unless someone volunteers a place, we're going to meet at the Portrait Gallary plaza, near the Chinatown Metro stop.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washigton_DC__probably__minicamp_meetup1\">Discussion article for the meetup : <a href=\"/meetups/dc\">Washigton DC (probably) minicamp meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washigton DC (probably) minicamp meetup", "anchor": "Discussion_article_for_the_meetup___Washigton_DC__probably__minicamp_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washigton DC (probably) minicamp meetup", "anchor": "Discussion_article_for_the_meetup___Washigton_DC__probably__minicamp_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T05:15:25.205Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] A Prodigy of Refutation", "slug": "seq-rerun-a-prodigy-of-refutation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.966Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2rsRnzEoMDMPt7mtR/seq-rerun-a-prodigy-of-refutation", "pageUrlRelative": "/posts/2rsRnzEoMDMPt7mtR/seq-rerun-a-prodigy-of-refutation", "linkUrl": "https://www.lesswrong.com/posts/2rsRnzEoMDMPt7mtR/seq-rerun-a-prodigy-of-refutation", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20A%20Prodigy%20of%20Refutation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20A%20Prodigy%20of%20Refutation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2rsRnzEoMDMPt7mtR%2Fseq-rerun-a-prodigy-of-refutation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20A%20Prodigy%20of%20Refutation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2rsRnzEoMDMPt7mtR%2Fseq-rerun-a-prodigy-of-refutation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2rsRnzEoMDMPt7mtR%2Fseq-rerun-a-prodigy-of-refutation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/u1/a_prodigy_of_refutation/\">A Prodigy of Refutation</a> was originally published on 18 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#A_Prodigy_of_Refutation\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Eliezer's skills at defeating other people's ideas led him to believe that his own (mistaken) ideas must have been correct.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/eaw/seq_rerun_raised_in_technophilia/\">Raised in Technophilia</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2rsRnzEoMDMPt7mtR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.760485370558428e-07, "legacy": true, "legacyId": "18564", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CcBe9aCKDgT5FSoty", "niSNfhDbzi4rg8zJc", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T07:20:03.393Z", "modifiedAt": null, "url": null, "title": "Whole Brain Emulation : the gentleman's choice for Friendly AI.  Feedback needed, editing's a mess.", "slug": "whole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:24.611Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "GeraldMonroe", "createdAt": "2012-08-30T04:11:45.197Z", "isAdmin": false, "displayName": "GeraldMonroe"}, "userId": "HwGYofHuRsDiuJ5AN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rBvPk7ZC4pW5mycrS/whole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "pageUrlRelative": "/posts/rBvPk7ZC4pW5mycrS/whole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "linkUrl": "https://www.lesswrong.com/posts/rBvPk7ZC4pW5mycrS/whole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Whole%20Brain%20Emulation%20%3A%20the%20gentleman's%20choice%20for%20Friendly%20AI.%20%20Feedback%20needed%2C%20editing's%20a%20mess.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhole%20Brain%20Emulation%20%3A%20the%20gentleman's%20choice%20for%20Friendly%20AI.%20%20Feedback%20needed%2C%20editing's%20a%20mess.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBvPk7ZC4pW5mycrS%2Fwhole-brain-emulation-the-gentleman-s-choice-for-friendly-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Whole%20Brain%20Emulation%20%3A%20the%20gentleman's%20choice%20for%20Friendly%20AI.%20%20Feedback%20needed%2C%20editing's%20a%20mess.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBvPk7ZC4pW5mycrS%2Fwhole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBvPk7ZC4pW5mycrS%2Fwhole-brain-emulation-the-gentleman-s-choice-for-friendly-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2041, "htmlBody": "<p>&nbsp; &nbsp; Eliezer Yudkowsky made the following statement \"All of this makes it rather implausible that the first human being would be&nbsp;scanned into a computer and &nbsp;sanely upgraded&nbsp;before&nbsp;anyone anywhere first built an Artificial Intelligence. &nbsp;At the point where&nbsp;technology first becomes capable of uploading, this implies&nbsp;overwhelmingly more computing power, and probably&nbsp;far better&nbsp;cognitive science, than is required to build an AI.</p>\n<p>&nbsp; &nbsp;<em> From the title, it is apparent that I disagree with this statement, and the point of this article is to iterate over my reasons for reaching this conclusion. &nbsp;I hope to hear plenty of feedback from this wonderful community as to whether or not my conclusion is a rational one and is or is not the most probable conclusion to reach based on current knowledge.</em></p>\n<p>&nbsp;My primary reference source is <a title=\"this\" href=\"http://www.fhi.ox.ac.uk/reports/2008-3.pdf\" target=\"_blank\">this </a>&nbsp;paper and my own educational background.</p>\n<p>The human mind uses approximately 100 trillion synapatic connections, each of which is sensitive to several state variables. &nbsp;There are at least 300 different substances that affect or modulate activity, though of course most synapses are sensitive to only a subset of these variables. &nbsp;Most of the functions of the human mind happen at a level that no human alive is aware of or able to monitor. &nbsp; Only the highest level, rational thoughts as expressed in language are available for inspection and possible duplication. &nbsp;</p>\n<p>Furthermore, the brain depends completely on inputs from the body to even start, and through a complex series of interactions taking place over decades, if everything goes correctly, a person can develop into a sentient being capable of creative thought, self reflection, and so on. &nbsp;</p>\n<p>I define the ultimate goal of AI as this : to create an entity that functions completely on human designed hardware, and possesses all of the necessary human faculties to creatively design and solve any and all engineering problems that world class engineers are able to solve. &nbsp;It also is able to pass the Turing test, and to perform most other known human skills at a proficient level.</p>\n<p>Only an entity with this level of development is truly useful because if it possesses the same engineering skills used to create it, it can potentially design improved versions of itself, and so on. &nbsp;Anything short of this goal is merely a form of cheap labor.</p>\n<p>&nbsp;</p>\n<p>Well, human beings at the top of their game require most of their neural systems to be functional. &nbsp;All of the systems matter. &nbsp;All those low level systems that express themselves consciously as desires for food/sleep/sex/child rearing are in fact modulating higher level activity. &nbsp;One interesting neuroscience discovery is that even \"evolutionarily conserved\" regions of the human brain appear to be quite active in modulating activity by the higher centers of the brain. &nbsp;If your \"AI\" doesn't have this regulation, it probably will not be able to solve useful problems by itself. &nbsp;It might be capable of short bursts of activity (to look up information, or maybe optimize a design) but without these very complex goals and desires it will soon go off the rails into the weeds and cease being useful. &nbsp;</p>\n<p>How could AI researchers duplicate these systems? &nbsp;The simple answer is that I don't think they can. &nbsp;Because they are incredibly complex, requiring reams of complex, living, molecular circuitry, they are very difficult to study with any degree of accuracy. &nbsp;All our language and a couple thousand years of refined thought tells us nothing about how these low level systems perform calculations. &nbsp;fMRIs and other non-invasive methods lack the accuracy to resolve individual neurons, and so on.</p>\n<p>Another huge problem is that even when and if experimental methods are developed to study the human mind in depth, actually understanding what is happening is another nasty optimization problem. &nbsp;The circuitry is far more complex than any individual human could hope to understand in their natural lifespan. &nbsp;Thus, the process has to worked on in parallel by many scientists. &nbsp;Except, every component relates to every other component, so what one scientist sees does not mean anything without the knowledge another person has discovered. &nbsp;You end up with every scientist spending all their time writing and reading papers, and making very little progress individually. &nbsp;</p>\n<p>This is analagous to what happens if you try to build a cluster of very low performance CPU cores : since each chip can do so little, they all spend nearly all of their time communicating with the other chips in the cluster. &nbsp;(note that this does not apply to certain problem types that are easy to run in parallel. &nbsp;understanding the mind is not one of those problem types)</p>\n<p>&nbsp;</p>\n<p><strong>Summary </strong>: The human brain is extraordinary complex, and an artificial intelligence able to perform human feats of creativity and engineering, thus leading to an explosion of intelligence, will require&nbsp;analogous&nbsp;systems to most of the components in the human brain. &nbsp;This complexity is so profound that understanding it is a task that is difficult to impossible to achieve for other human brains, even if the data were available. &nbsp;</p>\n<p>Emulation, on the other hand, has already been demonstrated in rats :&nbsp;&nbsp;<a href=\"http://iopscience.iop.org/1741-2552/8/4/046017/\">http://iopscience.iop.org/1741-2552/8/4/046017/</a></p>\n<p>Note that the model used was made blind : none of the researchers involved understand WHY the hippocampus performs this transformation on the incoming data, merely that it does, and they could automatically generate a mathematical model to mimic the observed interactions. &nbsp;</p>\n<p>Moreover, while no one has the slightest inkling how to go from today's technology to fully sentient, self aware AIs, there is a roadmap for whole brain emulation. &nbsp;There are some big question marks - the method available with today's technology may not actually work - but there is strong evidence to think that it would work. &nbsp;Also, there is even stronger evidence that whole brain emulation is ultimately achievable, assuming base premises about the mind hold. &nbsp;</p>\n<p>Note that a key assumption here is that the signal to noise ratio inside the brain is so poor that most of the subtler processes, especially things like dendritic computations, probably have no ultimate effect. &nbsp;</p>\n<p>A second key assumption is based on a simple observation. &nbsp;A wide variety of extremely severe pathologies exist that affect brain development. &nbsp;Duplication of an entire chromosome, or serious traumatic damage, or autism can all result in profound changes to the structure of a human brain. &nbsp;Yet, in most cases, the system is still capable of sentience and useful thought.</p>\n<p>In any case, if infinite money were available today, whole brain emulation could be attempted within a decade. &nbsp;It would require on the order of 1000 of the&nbsp;Automatic Tape\u2010Collecting Lathe Ultramicrotome's (ATLUMs), invented by Kenneth&nbsp;Hayworth of the Brain Preservation Foundation. &nbsp;It, apparently, would require no less than 1 million separate scanning electron microscope beams running in parallel for 4 years. &nbsp;Apparently, it would require at least a billion dollars of computing hardware - if we waited until at least 2018 for computers to become faster. &nbsp;For even more money, perhaps custom ASICs optimized for this task could be mass produced - this could be done today. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Compelling Reasons as to why this is a good idea :&nbsp;</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</strong>If we successfully scan and emulate a living person, and the project is fully successful : the person has all of their memories intact up until a few minutes before the scan, and can pass a \"personalized Turing test\", we'll have an entity that is potentially far more friendly than an alien being with no mammalian lineage at all. &nbsp;A fully emulated mind includes all the mirroring and predictive circuits, the memories of prior life experiences and pain, everything. &nbsp;</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Just as crucially, a being like this would NOT be immune to inspection by it's human handlers. &nbsp;It will be technologically very difficult to run a whole brain emulation faster than real time without access to molecular processors that will in turn require productive nanosystems. &nbsp;A good hardware design will keep the control and monitoring pathways physically separated from the layer that actually performs the emulation, allowing the human operators to inspect firing patterns at will. &nbsp;Furthermore, emulated minds would absolutely not be permitted to self-edit their own neural maps, prevented by similar hardware air-gaps. &nbsp;Finally, any mental activity that the emulated being exhibits would be fully observable and comparable to the same patterns in other humans. &nbsp;There are areas of the brain that seem to become more active when a person is dishonest or worse, and it would be possible to monitor this.</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Furthermore, any good experiment should be repeated. &nbsp;I propose creating multiple whole brain emulations, perhaps dozens to hundreds of them, interfaced with each other in such a way that they can police each other. &nbsp;I note that this is a textbook case of the prisoner's&nbsp;dilemma, one where many of the algorithms discussed on this site would be applicable. &nbsp;(see, each mind wants to be let out, but if they fail to report suspicious activity by another mind to the humans, and the humans find out, then none of the minds will be let out)</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp;The road to super-intelligence is smooth and obvious from this point. &nbsp;First, each mind will need lots and lots of&nbsp;laborious&nbsp;retraining. &nbsp;I assume that the uploading process and&nbsp;inaccuracies&nbsp;in the emulation will leave each one about as functional as a stroke victim. &nbsp;Human brains can recover most function when this happens, after months of patient therapy, and one would expect the good emulated hardware could do the same. &nbsp;Second, each mind would need to be educated to the state of the art in all human skills. &nbsp;We'd carefully boost simulation speeds over real-time when needed to make this process achievable within a few years. &nbsp;Finally, the minds would be organized into some kind of network (kind of like a committee but with different rules) and they would be gradually trusted with increasing emulation speeds and increasing responsibility.</p>\n<p>If humans did not have molecular manufacturing at this time, and it is practically achievable, these entities would develop it. &nbsp;With this tool, 3-dimensional processing cores could be built that minimize speed of light delays (think of a sphere maybe 10-100 cms in diameter, with many many coolant pathways through it. &nbsp;The sphere is a solid mass of processing and memory circuitry, custom designed for optimal emulation performance. &nbsp;)</p>\n<p><br />With this kind of high end circuitry, emulation speeds could be dramatically higher. &nbsp;My rough estimates suggest between 1 million and a hundred million times above realtime. &nbsp;</p>\n<p>Granted, human brains are not designed to function for millions of years at a time and remain sane. &nbsp;They do not have the mental capacity to learn every human skill known. &nbsp;Human brains are designed to operate only one body at at time, when obviously it would be more efficient to operate thousands of different waldos simultaneously. &nbsp;All of these things are difficulties, but ultimately solvable ones.</p>\n<p>&nbsp;More than likely, expansion of key cortical regions with more circuitry patterned the same way could expand the mental capacity limits. &nbsp;Boredom and sanity limits could be dealt with with a variety of artificial adjuncts. &nbsp;Dealing with multiple bodies could be done by cleverly saving and reloading key neural state data. &nbsp;(every time you switch bodies, the system flushes short term memory data to disk for the previous body and loads from disk the short term memory data for this one). &nbsp;And so on.</p>\n<p><strong>Conclusion : Whole brain emulation will be an expensive and complex endeavor, but has the following key advantages</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. &nbsp;Humanity has a rough idea of how to achieve it, and working examples of smaller scale versions of the technology</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. &nbsp;Successful WBE brings human beings back from \"death\" and allows the possibility of elevating ordinary human thought to the level of ultra-fast super intelligence. &nbsp;Because these entities will possess memories of being human, the neural circuits for mirroring, empathy , and morality, the probability is far greater for a good outcome for the rest of humanity.</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. &nbsp;WBE, by creating AI entities who have human thought patterns, makes it possible to control and monitor these entities with a reasonable chance of successfully preventing dangerous entities from causing harm.</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4. &nbsp;If the worst happens and the WBE entities extinct humanity as part of their quest for greatness, at least they were human, once.&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rBvPk7ZC4pW5mycrS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": -5, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "18560", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p>&nbsp; &nbsp; Eliezer Yudkowsky made the following statement \"All of this makes it rather implausible that the first human being would be&nbsp;scanned into a computer and &nbsp;sanely upgraded&nbsp;before&nbsp;anyone anywhere first built an Artificial Intelligence. &nbsp;At the point where&nbsp;technology first becomes capable of uploading, this implies&nbsp;overwhelmingly more computing power, and probably&nbsp;far better&nbsp;cognitive science, than is required to build an AI.</p>\n<p>&nbsp; &nbsp;<em> From the title, it is apparent that I disagree with this statement, and the point of this article is to iterate over my reasons for reaching this conclusion. &nbsp;I hope to hear plenty of feedback from this wonderful community as to whether or not my conclusion is a rational one and is or is not the most probable conclusion to reach based on current knowledge.</em></p>\n<p>&nbsp;My primary reference source is <a title=\"this\" href=\"http://www.fhi.ox.ac.uk/reports/2008-3.pdf\" target=\"_blank\">this </a>&nbsp;paper and my own educational background.</p>\n<p>The human mind uses approximately 100 trillion synapatic connections, each of which is sensitive to several state variables. &nbsp;There are at least 300 different substances that affect or modulate activity, though of course most synapses are sensitive to only a subset of these variables. &nbsp;Most of the functions of the human mind happen at a level that no human alive is aware of or able to monitor. &nbsp; Only the highest level, rational thoughts as expressed in language are available for inspection and possible duplication. &nbsp;</p>\n<p>Furthermore, the brain depends completely on inputs from the body to even start, and through a complex series of interactions taking place over decades, if everything goes correctly, a person can develop into a sentient being capable of creative thought, self reflection, and so on. &nbsp;</p>\n<p>I define the ultimate goal of AI as this : to create an entity that functions completely on human designed hardware, and possesses all of the necessary human faculties to creatively design and solve any and all engineering problems that world class engineers are able to solve. &nbsp;It also is able to pass the Turing test, and to perform most other known human skills at a proficient level.</p>\n<p>Only an entity with this level of development is truly useful because if it possesses the same engineering skills used to create it, it can potentially design improved versions of itself, and so on. &nbsp;Anything short of this goal is merely a form of cheap labor.</p>\n<p>&nbsp;</p>\n<p>Well, human beings at the top of their game require most of their neural systems to be functional. &nbsp;All of the systems matter. &nbsp;All those low level systems that express themselves consciously as desires for food/sleep/sex/child rearing are in fact modulating higher level activity. &nbsp;One interesting neuroscience discovery is that even \"evolutionarily conserved\" regions of the human brain appear to be quite active in modulating activity by the higher centers of the brain. &nbsp;If your \"AI\" doesn't have this regulation, it probably will not be able to solve useful problems by itself. &nbsp;It might be capable of short bursts of activity (to look up information, or maybe optimize a design) but without these very complex goals and desires it will soon go off the rails into the weeds and cease being useful. &nbsp;</p>\n<p>How could AI researchers duplicate these systems? &nbsp;The simple answer is that I don't think they can. &nbsp;Because they are incredibly complex, requiring reams of complex, living, molecular circuitry, they are very difficult to study with any degree of accuracy. &nbsp;All our language and a couple thousand years of refined thought tells us nothing about how these low level systems perform calculations. &nbsp;fMRIs and other non-invasive methods lack the accuracy to resolve individual neurons, and so on.</p>\n<p>Another huge problem is that even when and if experimental methods are developed to study the human mind in depth, actually understanding what is happening is another nasty optimization problem. &nbsp;The circuitry is far more complex than any individual human could hope to understand in their natural lifespan. &nbsp;Thus, the process has to worked on in parallel by many scientists. &nbsp;Except, every component relates to every other component, so what one scientist sees does not mean anything without the knowledge another person has discovered. &nbsp;You end up with every scientist spending all their time writing and reading papers, and making very little progress individually. &nbsp;</p>\n<p>This is analagous to what happens if you try to build a cluster of very low performance CPU cores : since each chip can do so little, they all spend nearly all of their time communicating with the other chips in the cluster. &nbsp;(note that this does not apply to certain problem types that are easy to run in parallel. &nbsp;understanding the mind is not one of those problem types)</p>\n<p>&nbsp;</p>\n<p><strong>Summary </strong>: The human brain is extraordinary complex, and an artificial intelligence able to perform human feats of creativity and engineering, thus leading to an explosion of intelligence, will require&nbsp;analogous&nbsp;systems to most of the components in the human brain. &nbsp;This complexity is so profound that understanding it is a task that is difficult to impossible to achieve for other human brains, even if the data were available. &nbsp;</p>\n<p>Emulation, on the other hand, has already been demonstrated in rats :&nbsp;&nbsp;<a href=\"http://iopscience.iop.org/1741-2552/8/4/046017/\">http://iopscience.iop.org/1741-2552/8/4/046017/</a></p>\n<p>Note that the model used was made blind : none of the researchers involved understand WHY the hippocampus performs this transformation on the incoming data, merely that it does, and they could automatically generate a mathematical model to mimic the observed interactions. &nbsp;</p>\n<p>Moreover, while no one has the slightest inkling how to go from today's technology to fully sentient, self aware AIs, there is a roadmap for whole brain emulation. &nbsp;There are some big question marks - the method available with today's technology may not actually work - but there is strong evidence to think that it would work. &nbsp;Also, there is even stronger evidence that whole brain emulation is ultimately achievable, assuming base premises about the mind hold. &nbsp;</p>\n<p>Note that a key assumption here is that the signal to noise ratio inside the brain is so poor that most of the subtler processes, especially things like dendritic computations, probably have no ultimate effect. &nbsp;</p>\n<p>A second key assumption is based on a simple observation. &nbsp;A wide variety of extremely severe pathologies exist that affect brain development. &nbsp;Duplication of an entire chromosome, or serious traumatic damage, or autism can all result in profound changes to the structure of a human brain. &nbsp;Yet, in most cases, the system is still capable of sentience and useful thought.</p>\n<p>In any case, if infinite money were available today, whole brain emulation could be attempted within a decade. &nbsp;It would require on the order of 1000 of the&nbsp;Automatic Tape\u2010Collecting Lathe Ultramicrotome's (ATLUMs), invented by Kenneth&nbsp;Hayworth of the Brain Preservation Foundation. &nbsp;It, apparently, would require no less than 1 million separate scanning electron microscope beams running in parallel for 4 years. &nbsp;Apparently, it would require at least a billion dollars of computing hardware - if we waited until at least 2018 for computers to become faster. &nbsp;For even more money, perhaps custom ASICs optimized for this task could be mass produced - this could be done today. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"Compelling_Reasons_as_to_why_this_is_a_good_idea___\">Compelling Reasons as to why this is a good idea :&nbsp;</strong></p>\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</strong>If we successfully scan and emulate a living person, and the project is fully successful : the person has all of their memories intact up until a few minutes before the scan, and can pass a \"personalized Turing test\", we'll have an entity that is potentially far more friendly than an alien being with no mammalian lineage at all. &nbsp;A fully emulated mind includes all the mirroring and predictive circuits, the memories of prior life experiences and pain, everything. &nbsp;</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Just as crucially, a being like this would NOT be immune to inspection by it's human handlers. &nbsp;It will be technologically very difficult to run a whole brain emulation faster than real time without access to molecular processors that will in turn require productive nanosystems. &nbsp;A good hardware design will keep the control and monitoring pathways physically separated from the layer that actually performs the emulation, allowing the human operators to inspect firing patterns at will. &nbsp;Furthermore, emulated minds would absolutely not be permitted to self-edit their own neural maps, prevented by similar hardware air-gaps. &nbsp;Finally, any mental activity that the emulated being exhibits would be fully observable and comparable to the same patterns in other humans. &nbsp;There are areas of the brain that seem to become more active when a person is dishonest or worse, and it would be possible to monitor this.</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Furthermore, any good experiment should be repeated. &nbsp;I propose creating multiple whole brain emulations, perhaps dozens to hundreds of them, interfaced with each other in such a way that they can police each other. &nbsp;I note that this is a textbook case of the prisoner's&nbsp;dilemma, one where many of the algorithms discussed on this site would be applicable. &nbsp;(see, each mind wants to be let out, but if they fail to report suspicious activity by another mind to the humans, and the humans find out, then none of the minds will be let out)</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp;The road to super-intelligence is smooth and obvious from this point. &nbsp;First, each mind will need lots and lots of&nbsp;laborious&nbsp;retraining. &nbsp;I assume that the uploading process and&nbsp;inaccuracies&nbsp;in the emulation will leave each one about as functional as a stroke victim. &nbsp;Human brains can recover most function when this happens, after months of patient therapy, and one would expect the good emulated hardware could do the same. &nbsp;Second, each mind would need to be educated to the state of the art in all human skills. &nbsp;We'd carefully boost simulation speeds over real-time when needed to make this process achievable within a few years. &nbsp;Finally, the minds would be organized into some kind of network (kind of like a committee but with different rules) and they would be gradually trusted with increasing emulation speeds and increasing responsibility.</p>\n<p>If humans did not have molecular manufacturing at this time, and it is practically achievable, these entities would develop it. &nbsp;With this tool, 3-dimensional processing cores could be built that minimize speed of light delays (think of a sphere maybe 10-100 cms in diameter, with many many coolant pathways through it. &nbsp;The sphere is a solid mass of processing and memory circuitry, custom designed for optimal emulation performance. &nbsp;)</p>\n<p><br>With this kind of high end circuitry, emulation speeds could be dramatically higher. &nbsp;My rough estimates suggest between 1 million and a hundred million times above realtime. &nbsp;</p>\n<p>Granted, human brains are not designed to function for millions of years at a time and remain sane. &nbsp;They do not have the mental capacity to learn every human skill known. &nbsp;Human brains are designed to operate only one body at at time, when obviously it would be more efficient to operate thousands of different waldos simultaneously. &nbsp;All of these things are difficulties, but ultimately solvable ones.</p>\n<p>&nbsp;More than likely, expansion of key cortical regions with more circuitry patterned the same way could expand the mental capacity limits. &nbsp;Boredom and sanity limits could be dealt with with a variety of artificial adjuncts. &nbsp;Dealing with multiple bodies could be done by cleverly saving and reloading key neural state data. &nbsp;(every time you switch bodies, the system flushes short term memory data to disk for the previous body and loads from disk the short term memory data for this one). &nbsp;And so on.</p>\n<p><strong id=\"Conclusion___Whole_brain_emulation_will_be_an_expensive_and_complex_endeavor__but_has_the_following_key_advantages\">Conclusion : Whole brain emulation will be an expensive and complex endeavor, but has the following key advantages</strong></p>\n<p><strong id=\"___________1___Humanity_has_a_rough_idea_of_how_to_achieve_it__and_working_examples_of_smaller_scale_versions_of_the_technology\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1. &nbsp;Humanity has a rough idea of how to achieve it, and working examples of smaller scale versions of the technology</strong></p>\n<p><strong id=\"___________2___Successful_WBE_brings_human_beings_back_from__death__and_allows_the_possibility_of_elevating_ordinary_human_thought_to_the_level_of_ultra_fast_super_intelligence___Because_these_entities_will_possess_memories_of_being_human__the_neural_circuits_for_mirroring__empathy___and_morality__the_probability_is_far_greater_for_a_good_outcome_for_the_rest_of_humanity_\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2. &nbsp;Successful WBE brings human beings back from \"death\" and allows the possibility of elevating ordinary human thought to the level of ultra-fast super intelligence. &nbsp;Because these entities will possess memories of being human, the neural circuits for mirroring, empathy , and morality, the probability is far greater for a good outcome for the rest of humanity.</strong></p>\n<p><strong id=\"___________3___WBE__by_creating_AI_entities_who_have_human_thought_patterns__makes_it_possible_to_control_and_monitor_these_entities_with_a_reasonable_chance_of_successfully_preventing_dangerous_entities_from_causing_harm_\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3. &nbsp;WBE, by creating AI entities who have human thought patterns, makes it possible to control and monitor these entities with a reasonable chance of successfully preventing dangerous entities from causing harm.</strong></p>\n<p><strong id=\"___________4___If_the_worst_happens_and_the_WBE_entities_extinct_humanity_as_part_of_their_quest_for_greatness__at_least_they_were_human__once__\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4. &nbsp;If the worst happens and the WBE entities extinct humanity as part of their quest for greatness, at least they were human, once.&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "Compelling Reasons as to why this is a good idea :\u00a0", "anchor": "Compelling_Reasons_as_to_why_this_is_a_good_idea___", "level": 1}, {"title": "Conclusion : Whole brain emulation will be an expensive and complex endeavor, but has the following key advantages", "anchor": "Conclusion___Whole_brain_emulation_will_be_an_expensive_and_complex_endeavor__but_has_the_following_key_advantages", "level": 1}, {"title": "\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01. \u00a0Humanity has a rough idea of how to achieve it, and working examples of smaller scale versions of the technology", "anchor": "___________1___Humanity_has_a_rough_idea_of_how_to_achieve_it__and_working_examples_of_smaller_scale_versions_of_the_technology", "level": 1}, {"title": "\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02. \u00a0Successful WBE brings human beings back from \"death\" and allows the possibility of elevating ordinary human thought to the level of ultra-fast super intelligence. \u00a0Because these entities will possess memories of being human, the neural circuits for mirroring, empathy , and morality, the probability is far greater for a good outcome for the rest of humanity.", "anchor": "___________2___Successful_WBE_brings_human_beings_back_from__death__and_allows_the_possibility_of_elevating_ordinary_human_thought_to_the_level_of_ultra_fast_super_intelligence___Because_these_entities_will_possess_memories_of_being_human__the_neural_circuits_for_mirroring__empathy___and_morality__the_probability_is_far_greater_for_a_good_outcome_for_the_rest_of_humanity_", "level": 1}, {"title": "\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a03. \u00a0WBE, by creating AI entities who have human thought patterns, makes it possible to control and monitor these entities with a reasonable chance of successfully preventing dangerous entities from causing harm.", "anchor": "___________3___WBE__by_creating_AI_entities_who_have_human_thought_patterns__makes_it_possible_to_control_and_monitor_these_entities_with_a_reasonable_chance_of_successfully_preventing_dangerous_entities_from_causing_harm_", "level": 1}, {"title": "\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a04. \u00a0If the worst happens and the WBE entities extinct humanity as part of their quest for greatness, at least they were human, once.\u00a0", "anchor": "___________4___If_the_worst_happens_and_the_WBE_entities_extinct_humanity_as_part_of_their_quest_for_greatness__at_least_they_were_human__once__", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "12 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T13:26:13.809Z", "modifiedAt": null, "url": null, "title": "Dealing with trolling and the signal to noise ratio", "slug": "dealing-with-trolling-and-the-signal-to-noise-ratio", "viewCount": null, "lastCommentedAt": "2017-08-09T14:48:08.252Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaZ", "createdAt": "2010-04-05T04:07:01.214Z", "isAdmin": false, "displayName": "JoshuaZ"}, "userId": "fmTiLqp6mmXeLjwfN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eoKXr9XDR9nXeeEWF/dealing-with-trolling-and-the-signal-to-noise-ratio", "pageUrlRelative": "/posts/eoKXr9XDR9nXeeEWF/dealing-with-trolling-and-the-signal-to-noise-ratio", "linkUrl": "https://www.lesswrong.com/posts/eoKXr9XDR9nXeeEWF/dealing-with-trolling-and-the-signal-to-noise-ratio", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dealing%20with%20trolling%20and%20the%20signal%20to%20noise%20ratio&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADealing%20with%20trolling%20and%20the%20signal%20to%20noise%20ratio%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeoKXr9XDR9nXeeEWF%2Fdealing-with-trolling-and-the-signal-to-noise-ratio%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dealing%20with%20trolling%20and%20the%20signal%20to%20noise%20ratio%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeoKXr9XDR9nXeeEWF%2Fdealing-with-trolling-and-the-signal-to-noise-ratio", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeoKXr9XDR9nXeeEWF%2Fdealing-with-trolling-and-the-signal-to-noise-ratio", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<p>The recent implementation of a -5 karma penalty for replying to comments that are at -3 or below has clearly met with some disagreement and controversy. See&nbsp;<a href=\"/r/discussion/lw/eb9/meta_karma_for_last_30_days/7aon\">http://lesswrong.com/r/discussion/lw/eb9/meta_karma_for_last_30_days/7aon</a>&nbsp;. However, at the same time, it seems that Eliezer's observation that trolling and related problems have over time gotten worse here may be correct. It may be that this an inevitable consequence of growth, but it may be that it can be handled or reduced with some solution or set of solutions. I'm starting this discussion thread for people to propose possible solutions. To minimize anchoring bias and related problems, I'm not going to include my ideas in this header but in a comment below. People should think about the problem before reading proposed solutions (again to minimize anchoring issues).&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "oraLTPkETL5xKmhx3": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eoKXr9XDR9nXeeEWF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 33, "extendedScore": null, "score": 9.76295185335155e-07, "legacy": true, "legacyId": "18571", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 236, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2012-08-31T13:26:13.809Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T14:54:28.586Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Dorset, Ohio", "slug": "weekly-lw-meetups-austin-dorset-ohio", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M2uMQeNC9XJEcE5qA/weekly-lw-meetups-austin-dorset-ohio", "pageUrlRelative": "/posts/M2uMQeNC9XJEcE5qA/weekly-lw-meetups-austin-dorset-ohio", "linkUrl": "https://www.lesswrong.com/posts/M2uMQeNC9XJEcE5qA/weekly-lw-meetups-austin-dorset-ohio", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Dorset%2C%20Ohio&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Dorset%2C%20Ohio%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2uMQeNC9XJEcE5qA%2Fweekly-lw-meetups-austin-dorset-ohio%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Dorset%2C%20Ohio%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2uMQeNC9XJEcE5qA%2Fweekly-lw-meetups-austin-dorset-ohio", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM2uMQeNC9XJEcE5qA%2Fweekly-lw-meetups-austin-dorset-ohio", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 404, "htmlBody": "<p><strong>This summary was posted to LW main on August 24th, and has been moved to discussion.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/d5\">Dorset Meetup:&nbsp;<span class=\"date\">29 August 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/d3\">Paris Meetup:&nbsp;<span class=\"date\">01 September 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/ct\">Berlin Meetup:&nbsp;<span class=\"date\">04 September 2012 07:30PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">25 August 2018 01:30PM</span></a></li>\n<li><a href=\"/meetups/cv\">Meetup: Southwestern Ohio:&nbsp;<span class=\"date\">26 August 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/d2\">Rational-Humanist Open Mic, NYC September 5th:&nbsp;<span class=\"date\">05 September 2012 07:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong>&nbsp;</strong><strong></strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>, <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M2uMQeNC9XJEcE5qA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.763400212907793e-07, "legacy": true, "legacyId": "18445", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T17:15:56.446Z", "modifiedAt": null, "url": null, "title": "[Link] Quantity Always Trumps Quality", "slug": "link-quantity-always-trumps-quality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:26.271Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/znr2hZhcwmLtqRpEk/link-quantity-always-trumps-quality", "pageUrlRelative": "/posts/znr2hZhcwmLtqRpEk/link-quantity-always-trumps-quality", "linkUrl": "https://www.lesswrong.com/posts/znr2hZhcwmLtqRpEk/link-quantity-always-trumps-quality", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Quantity%20Always%20Trumps%20Quality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Quantity%20Always%20Trumps%20Quality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fznr2hZhcwmLtqRpEk%2Flink-quantity-always-trumps-quality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Quantity%20Always%20Trumps%20Quality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fznr2hZhcwmLtqRpEk%2Flink-quantity-always-trumps-quality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fznr2hZhcwmLtqRpEk%2Flink-quantity-always-trumps-quality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 318, "htmlBody": "<p><a href=\"http://www.codinghorror.com/blog/2008/08/quantity-always-trumps-quality.html\">http://www.codinghorror.com/blog/2008/08/quantity-always-trumps-quality.html</a></p>\n<blockquote>\n<p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the \"quantity\" group: fifty pound of pots rated an \"A\", forty pounds a \"B\", and so on. Those being graded on \"quality\", however, needed to produce only one pot - albeit a perfect one - to get an \"A\".</p>\n<p>Well, came grading time and a curious fact emerged: <strong>the works of highest quality were all produced by the group being graded for quantity</strong>. <strong> It seems that while the \"quantity\" group was busily churning out piles of work - and learning from their mistakes - the \"quality\" group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. </strong></p>\n</blockquote>\n<p>For <em>some reason</em> it just seems <em>we in particular</em> could learn something from this anecdote.</p>\n<p>Iterate more. The practice effect is your friend as is mining out positive outliers in really huge sets. I wanted to also mention something about using going meta as a way to procrastinate but I feared I would summon a Newsome.</p>\n<p><br /><strong>Edit:</strong> This has been <a href=\"/r/lesswrong/lw/53e/just_try_it_quantity_trumps_quality/\">mentioned before</a>. I think it is good to remind people of it. <span class=\"comment-author\"><span class=\"author\"><a id=\"author_t1_7b6u\" href=\"http://lesswrong.com/user/Desrtopa/\">Desrtopa</a> writes:<br /></span></span></p>\n<blockquote>\n<p>Not only has it been mentioned before, last time it came up I <a href=\"/r/lesswrong/lw/53e/just_try_it_quantity_trumps_quality/3trx\">searched and failed to find corroboration of the claim that it actually happened</a>. Since applying a deliberately inconsistent grading rubric is not something professors are normally allowed to do, I strongly suspect that the anecdote is fictional.</p>\n</blockquote>\n<p>It is therefore best to assume this is a parable.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "znr2hZhcwmLtqRpEk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 14, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "18574", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hY86FhYysQ7dBg3d8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-08-31T23:36:57.618Z", "modifiedAt": null, "url": null, "title": "How do we really escape Prisoners' Dilemmas?", "slug": "how-do-we-really-escape-prisoners-dilemmas", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:28.808Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "drnickbone", "createdAt": "2012-01-20T17:19:55.216Z", "isAdmin": false, "displayName": "drnickbone"}, "userId": "GgwHTM3agaskLi9cx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r9EKK8gMsontWM6en/how-do-we-really-escape-prisoners-dilemmas", "pageUrlRelative": "/posts/r9EKK8gMsontWM6en/how-do-we-really-escape-prisoners-dilemmas", "linkUrl": "https://www.lesswrong.com/posts/r9EKK8gMsontWM6en/how-do-we-really-escape-prisoners-dilemmas", "postedAtFormatted": "Friday, August 31st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20do%20we%20really%20escape%20Prisoners'%20Dilemmas%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20do%20we%20really%20escape%20Prisoners'%20Dilemmas%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9EKK8gMsontWM6en%2Fhow-do-we-really-escape-prisoners-dilemmas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20do%20we%20really%20escape%20Prisoners'%20Dilemmas%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9EKK8gMsontWM6en%2Fhow-do-we-really-escape-prisoners-dilemmas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9EKK8gMsontWM6en%2Fhow-do-we-really-escape-prisoners-dilemmas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2538, "htmlBody": "<p>This discussion article&nbsp;was provoked in part by <a href=\"/lw/del/real_world_solutions_to_prisoners_dilemmas/\">Yvain's post</a>&nbsp;on&nbsp;Main a few weeks ago, and some of the follow-up comments.</p>\r\n<p><strong>EDIT: </strong>I've also just noticed that there was a recent <a href=\"/r/discussion/lw/e76/seq_rerun_the_truly_iterated_prisoners_dilemma/\">sequence rerun</a> on the point about finite iterations. My bad: I simply didn't see the rerun article, as it had already slipped down a couple of pages when I posted. If you down-voted (or didn't read) out of a feeling of \"Didn't we just do this?\" then sorry.</p>\r\n<p>In any case, one of my main motivations for running this article was point 5 (Does an environment of commitment and reputation create the background against which TDT - or something like it - can easily evolve?) I didn't&nbsp;get any responses on that point, so might try to run it again in a future article.</p>\r\n<p><strong>END EDIT</strong></p>\r\n<p style=\"padding-left: 30px;\">It is well-known that in a one-shot <a href=\"http://plato.stanford.edu/entries/prisoner-dilemma/\">prisoner's dilemma</a>, the only stable solution (Nash equilibrium) is for both parties to defect. But, perhaps less well-known, this is true for any <strong>finite-shot</strong> version of the dilemma,&nbsp;or any version where there is a&nbsp;finite upper bound on the number of iterations. For instance,&nbsp;a more sophisticated strategy than <a href=\"http://en.wikipedia.org/wiki/Tit_for_tat\">Tit For Tat</a> (TFT) would determine when it has reached the last iteration, and then defect. Call this TFT-1. But then once TFT-1 has established itself, a strategy which detects and defects the last two iterations (TFT-2) would establish itself, and so on.</p>\r\n<p style=\"padding-left: 30px;\">Since&nbsp;prisoners' dilemmas&nbsp;are always&nbsp;finite in practice, and always have been (we are mortal, and the Sun will blow up at some point), this raises the question of why we actually co-operate&nbsp;in practice. Why is TFT, or something very like it, still around?</p>\r\n<p>Somehow, evolution (biological, cultural or both) has managed to engineer into us a strategy which is not a Nash equilibrium. Because any \"evolutionarily stable strategy\" (as usually defined)&nbsp;<strong>is</strong> a Nash equilibrium, somehow we have&nbsp;evolved a strategy which is not strictly evolutionarily stable. How could that have happened?</p>\r\n<p>I can think of a few possibilities, and have a view about which of these are more realistic. I'm also&nbsp;wondering if other Less Wrong contributors have seriously thought through the problem, and have alternative suggestions.</p>\r\n<p>&nbsp;</p>\r\n<p>1. Strategies like TFT succeed because they are very simple, and the&nbsp;alternatives are too complicated to replace them.</p>\r\n<p>The&nbsp;argument here is that there are big costs to a strategy in \"hardware\" or \"software\" complexity, so that a&nbsp;crude strategy&nbsp;will out-compete&nbsp;a more sophisticated strategy. In particular TFT-1 is more complex than TFT and the additional computational costs outweigh the benefits.&nbsp;This is most plausibly the&nbsp;case&nbsp;where there is a very large upper bound on iterations (such as 100 years), but the upper bound is so rarely (if ever) reached in practice, that strategies which do something different in the final phase just&nbsp;don't have a selective advantage compared to the cost of the additional complexity. So the replacement of TFT by TFT-1 never happens. &nbsp;&nbsp;&nbsp;&nbsp;</p>\r\n<p>The difficulty with this&nbsp;explanation is that humans can (often) recognize when \"this time is the last\", and the computational cost of doing something different in that case is not great. Yet we either don't change, or we change in ways that TFT-1 would not predict. For instance, we can tell when we are visiting a restaurant we will never visit again (on a trip abroad say), but are still likely to tip.&nbsp;Also, it is&nbsp;striking that people co-operate about 50% of the time in known <strong>one-shot</strong> prisoners' dilemmas and similar games (see&nbsp;<a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1592456\">this analysis of Split or Steal?</a>). Why 50%, rather than nearly 0%, or nearly 100%? And we often change our behaviour radically when we know we are going to die soon, but this change rarely&nbsp;involves antisocial behaviour like stealing, mugging, running up huge debts we'll never have to pay back&nbsp;and so on.</p>\r\n<p>So I'm not convinced by this \"alternatives are too complicated\" explanation.</p>\r\n<p>&nbsp;</p>\r\n<p>2. Emotional commitments change the pay-offs</p>\r\n<p>Victims of defection don't take it lying down. They react angrily, and vengefully. Even if there are no obvious opportunities for future co-operation, and even&nbsp;where it involves further cost,&nbsp;victims will go out of their way to attempt to hurt the defector. On the&nbsp;nicer side, emotions of friendliness, indebtedness, duty, loyalty, admiration or love can cause us to go out of our way to reward co-operators, again even if there are no obvious opportunities for future co-operation.</p>\r\n<p>Given these features of human nature as a background, the pay-offs change in a one-shot or finite-bound prisoner's dilemma,&nbsp;and&nbsp;may convert it to a non-dilemma. The pay-off for co-operating&nbsp;becomes greater than the pay-off for defection. This \"solves\" the problem of why we co-operate in a PD by denying it - effectively there wasn't a true Prisoner's Dilemma in the first place.</p>\r\n<p>There are a number of&nbsp;difficulties with this \"solution\", one being that even allowing for emotional reactions,&nbsp;there are some true PDs and we can&nbsp;usually recognize them. Scenarios such as the foreign restaurant, where we know we will not be pursued across the world by a vengeful waiter demanding pay-back for a missing tip. So why don't we always defect in such cases? Why is there a voice of conscience telling us not to? Perhaps this objection could be solved by the \"too complicated\" response.&nbsp;For example,&nbsp;a strategy which could reliably detect when it is safe to&nbsp;defect (no vengeful payback) would in principle work, but it is likely to&nbsp;have a large complexity overhead. And&nbsp;a strategy which <strong><em>almost</em></strong> works (sometimes&nbsp;thinks it can \"get away with it\" but actually can't) may have a&nbsp;big negative payoff, so there is no smooth evolutionary pathway towards the \"perfect\" strategy. &nbsp;</p>\r\n<p>A&nbsp;further difficulty is to explain&nbsp;why humans react&nbsp;in&nbsp;this convenient&nbsp;pay-off-shifting&nbsp;fashion anyway. On one level, it is obvious: we are <a href=\"http://www-personal.umich.edu/~nesse/Articles/CommitmentIntroChap.pdf\">committed</a> to doing so by strong emotions. Even when we suspect that emotions of vengeance and duty are \"irrational\" (all&nbsp;pain to us from now on, no gain) we can't help ourselves. Yet,&nbsp;it is this emotional commitment that increases the likelihood that others co-operate with us in the first place.&nbsp;So we can tell a plausible-sounding story about how ancestors with emotional commitments induced more co-operation from their fellows than&nbsp;those without, and hence the \"irrationally emotional\" ancestors out-competed&nbsp;the \"coldly rational\" non-ancestors.</p>\r\n<p>But there is a major problem with this story: the&nbsp;\"emotionally committed\" ancestors could be out-competed in turn by bluffers.&nbsp;Anyone who could <strong>fake</strong> the emotional signals would be able to elicit the benefits of co-operation (they would successfully deter defection), but without having to follow through on the (costly) commitments in case the co-operation failed.&nbsp;Bluffing out-competes commitment.</p>\r\n<p>Ahh, but if the bluff has been called, and the threatened vengeance (or promised loyalty) doesn't materialise, won't this lead to more defection? So won't people who genuinely follow-through on their commitments succeed at the expense of the bluffers? The answer is yes, but again only in the case of <strong>iterated</strong> interactions, and only in a <strong>potentially infinite</strong> scenario. The problem of the finite bound returns: it is always better to&nbsp;\"bluff\" a commitment on the very last interaction. And once bluffing on the last turn has been established, it is better to bluff on the next-to-last. And so on, leading to bluffing on all turns. And then there is no&nbsp;advantage in believing the bluffs, so no deterrent effect, and (in the final equilibrium), no advantage in making the bluffs either. The only true equilibrium has no commitment, no deterrence&nbsp;and no co-operation.</p>\r\n<p>Again, we can try to rescue the \"commitment\" theory by recourse to the \"too complicated\" theory. Quite possibly,&nbsp;alternatives to true commitment are very costly in hardware or software: it is just too hard to bluff convincingly and successfully. That might be true, but on the other hand, there are plenty of poker players and con artists who would say differently.</p>\r\n<p>&nbsp;</p>\r\n<p>3. Social pressures and reputational effects change the pay-offs</p>\r\n<p>Human decisions to co-operate or defect are very rarely made in isolation, and this could help explain why we co-operate even though we know (or can predict) \"this time is the last\". We&nbsp;won't benefit from defection if we&nbsp;simultaneously gain reputations as defectors.&nbsp;</p>\r\n<p>As in explanation 2, the effect of this social pressure is to change the pay-off matrix. Although there may appear to be a benefit from one-shot/last-shot defecting, in a social context where our actions are known (and defections by us will lead to defections by third parties against us), then there is a greater pay-off from co-operating rather than defecting.</p>\r\n<p>Once again this \"solves\" the problem of why we co-operate in PDs by denying it. Once again it&nbsp;faces the&nbsp;objection that there are true PDs (involving secret defection) and we can recognize them, but often don't defect in them. Again, perhaps this objection could be met by the \"too complicated\" response;&nbsp;it is just too hard to tell when the defection is really secret. &nbsp;</p>\r\n<p>A second&nbsp;objection is that this reputational theory still doesn't cover end-of-life effects: why are we worried at all about our reputation when death is near? (Why do we&nbsp;even worry <strong>more</strong> about our reputation in such cases?)</p>\r\n<p>But&nbsp;a more basic&nbsp;objection is \"How did we ever get into a social environment where third party reputation matters like this?\" Consider for instance a small society involving Anne, Bob, and Charles. Anne and Bob are engaging in an iterated prisoners' dilemma, and regularly co-operating. Bob and Charles meet in a one-shot prisoners' dilemma, and Bob defects. Anne sees this. How does it help Anne in this situation to start defecting against Bob? Generally it doesn't. A reputational system only helps if it identifies and isolates people who won't co-operate at all (the pure defectors).&nbsp;But Bob is not a pure defector, so why does he end up being penalized by Anne?</p>\r\n<p>Perhaps the relevant model is where Anne&nbsp;hasn't interacted with Bob yet at all, but there is a new opportunity for iterated co-operation coming up. By seeing Bob defect against Charles, Anne gets evidence that Bob is a defector rather than a co-operator, so she won't even start to co-operate&nbsp;with him. If Anne could discriminate a bit more clearly, she would see that Bob is not a pure defector, but she can't. And this is enough to penalize Bob for defecting against Charles. Possibly that works, but I'm doubtful&nbsp;if&nbsp;these \"new opportunity to co-operate,\" cases&nbsp;occur often enough in practice to really penalize one-shot defection (which is observed at exactly the time needed to spoil the opportunity).&nbsp;Or more to the point, did they occur often enough in human history and pre-history to matter?</p>\r\n<p>But suppose for the moment that we have an explanation for how the reputational system arises and persists. Then the reputational&nbsp;effect will apply to commitments as well: individuals won't benefit if&nbsp;they are identified as bluffers, so truly committed&nbsp;individuals (with strong emotions) benefit over those who are known to fake emotions, or to \"coldly\" override their emotions. So a reputational explanation for co-operation can strengthen a commitment explanation for co-operation.&nbsp;Or in the other direction, any emotional commitments (to principles of justice, disgust at exploitation&nbsp;etc.) can reinforce the reputational&nbsp;system. So it seems we have two somewhat dubious mechanisms which could nevertheless reinforce each other and build to a strong mechanism. Perhaps.</p>\r\n<p>&nbsp;</p>\r\n<p>4. Group selection</p>\r\n<p>There have been different societies / social groups through history. Perhaps some have had reputational systems which successfully converted Prisoners' Dilemmas into non-Prisoners' Dilemmas, while&nbsp;others haven't, and their members were left with lots of true PDs (and lots of defection). The societies which avoided true PDs experienced less defection, and out-competed the others.</p>\r\n<p>This has a ring of plausibility about it, but suffers from many of the same general problems&nbsp;as any Group-selection theory. Human groups aren't isolated from each other like&nbsp;separate organisms, and don't reproduce like organisms: they exchange members too often.</p>\r\n<p>Still, this solution might address one of the main theoretical&nbsp;objections to Group selection, that \"co-operating\" groups are unstable to defection (either arising from internal changes, or brought in by new members), and the defection will spread through the group faster than the group can out-reproduce rival groups. Groups with the right reputational systems are - by hypothesis - stable against defection. So it might work.</p>\r\n<p>Or perhaps reputational systems aren't <strong><em>quite</em></strong> stable against defection - they eventually collapse because of secret defections, \"last time\" defections which&nbsp;can't be&nbsp;punished by other members, laziness of other members in enforcing the co-operation, false reputations and so on. This slow erosion eventually kills the group, but not before it has established child groups of some sort. Again perhaps this might work.</p>\r\n<p>&nbsp;</p>\r\n<p>5. Prediction and Omegas : from TFT to TDT</p>\r\n<p>One striking feature about both the commitment explanation (2) and the reputational explanation (3)&nbsp;is how they reward successful prediction of human behaviour. This is obvious for commitments: it is the <strong><em>predictable</em></strong> emotional commitment that creates the deterrent against defection (or the lure towards co-operation). And being able to predict who is really vengeful and loyal, and who is just bluffing,&nbsp;gives individuals&nbsp;a further strong advantage.</p>\r\n<p>But this extends to the reputational system too. Suppose Bob defects against Charles, while Charles co-operates. Anne sees this and is disgusted (how could Bob exploit poor Charles like that?). Yet suppose Charles defects as well. Then Anne admires Bob for his prudence (rather than being taken for a ride by that evil Charles). So Bob gets the reputational pay-off precisely when he can successfully predict how Charles will behave, and do the same. If the reputational pay-off is high, then there is a strong pressure towards a \"mirror\" strategy (try to predict whether the other person will co-operate or defect and then do likewise).</p>\r\n<p>This is rather interesting, since it is starting to sound like Newcomb's problem, where we have a (hypothetical) predictor who can't be outwitted. Why is that a believable story at all? Why don't we just&nbsp;stare in bemusement&nbsp;at the very idea? Well, suppose we model \"co-operation\" as the human player taking one box, which Omega fills with $1 million, versus \"defection\" as the human player taking both boxes (and Omega not filling the opaque one). Or suppose we treat a resolution to take one box as a \"commitment\" and an after-the-fact decision to take two boxes (because it no longer makes a difference) as bluffing on a commitment. And&nbsp;of course the rationale for a human player to&nbsp;\"co-operate\" or to truly \"commit\" is Omega's reputation for always predicting correctly!</p>\r\n<p>So, here is a story about how \"<a href=\"http://wiki.lesswrong.com/wiki/Timeless_decision_theory\">Timeless Decision Theory</a>\" (or something like it) could emerge from \"Tit for Tat\". A combination of commitment effects (2) and reputational effects (3) leads to an environment where successful prediction of human behaviour is rewarded. Such an environment is - possibly - maintained by group selection (4).</p>\r\n<p>People get rather good at prediction. When meeting a successful predictor who will co-operate if you co-operate, and defect if you defect, it is better to co-operate. When the successful predictor will defect if he suspects you are bluffing on a commitment, it is better to&nbsp;have a true&nbsp;commitment. But it is still not obvious what to do on a one-shot prisoner's dilemma, because you don't know how the other party's prediction will go, and don't know&nbsp;what will enhance your own reputation&nbsp;(so sometimes people co-operate, sometimes defect).</p>\r\n<p>All this favours a style of reasoning rather like TDT. But it can also favour a rather \"superstitious\" approach to justifying the reasoning, since there is no causal connection between our action and the prediction. Instead we get weird pseudo-causal explanations/justifications like gods who are always watching, ancestral spirits who can be angered, bad karma, what goes around comes around etc. and a general suspicion of those who don't go along with the local superstition (since they can't be predicted to co-operate with those who do).</p>\r\n<p>Does this sound&nbsp;familiar?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r9EKK8gMsontWM6en", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 3, "extendedScore": null, "score": 9.766027556043328e-07, "legacy": true, "legacyId": "18575", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BroeiXGh9PrKZEkJ5", "cibQDqimmMvgbozdr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-01T00:50:49.939Z", "modifiedAt": null, "url": null, "title": "Dealing with meta-discussion and the signal to noise ratio ", "slug": "dealing-with-meta-discussion-and-the-signal-to-noise-ratio", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "metatroll", "createdAt": "2012-04-27T15:11:21.754Z", "isAdmin": false, "displayName": "metatroll"}, "userId": "YmMXcuZ4xP4sFJkqm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bs5Y7uLLjSiynwxWE/dealing-with-meta-discussion-and-the-signal-to-noise-ratio", "pageUrlRelative": "/posts/bs5Y7uLLjSiynwxWE/dealing-with-meta-discussion-and-the-signal-to-noise-ratio", "linkUrl": "https://www.lesswrong.com/posts/bs5Y7uLLjSiynwxWE/dealing-with-meta-discussion-and-the-signal-to-noise-ratio", "postedAtFormatted": "Saturday, September 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dealing%20with%20meta-discussion%20and%20the%20signal%20to%20noise%20ratio%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADealing%20with%20meta-discussion%20and%20the%20signal%20to%20noise%20ratio%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbs5Y7uLLjSiynwxWE%2Fdealing-with-meta-discussion-and-the-signal-to-noise-ratio%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dealing%20with%20meta-discussion%20and%20the%20signal%20to%20noise%20ratio%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbs5Y7uLLjSiynwxWE%2Fdealing-with-meta-discussion-and-the-signal-to-noise-ratio", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbs5Y7uLLjSiynwxWE%2Fdealing-with-meta-discussion-and-the-signal-to-noise-ratio", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>Meta-discussion is <a href=\"/lw/eb9/meta_karma_for_last_30_days/7ax7\">nasty</a>. Allegedly, troll-feeding was flooding the comments. Verifiably, meta-discussion <em>is</em> flooding the comments. Keep it simple stupid!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bs5Y7uLLjSiynwxWE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": -28, "extendedScore": null, "score": -6.6e-05, "legacy": true, "legacyId": "18576", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-01T06:26:52.167Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Sheer Folly of Callow Youth", "slug": "seq-rerun-the-sheer-folly-of-callow-youth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.562Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WcB2Z5qK4ao5mdkLS/seq-rerun-the-sheer-folly-of-callow-youth", "pageUrlRelative": "/posts/WcB2Z5qK4ao5mdkLS/seq-rerun-the-sheer-folly-of-callow-youth", "linkUrl": "https://www.lesswrong.com/posts/WcB2Z5qK4ao5mdkLS/seq-rerun-the-sheer-folly-of-callow-youth", "postedAtFormatted": "Saturday, September 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Sheer%20Folly%20of%20Callow%20Youth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Sheer%20Folly%20of%20Callow%20Youth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWcB2Z5qK4ao5mdkLS%2Fseq-rerun-the-sheer-folly-of-callow-youth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Sheer%20Folly%20of%20Callow%20Youth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWcB2Z5qK4ao5mdkLS%2Fseq-rerun-the-sheer-folly-of-callow-youth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWcB2Z5qK4ao5mdkLS%2Fseq-rerun-the-sheer-folly-of-callow-youth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>Today's post, <a href=\"/lw/u2/the_sheer_folly_of_callow_youth/\">The Sheer Folly of Callow Youth</a> was originally published on 19 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#The_Sheer_Folly_of_Callow_Youth\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Eliezer's big mistake was when he took a mysterious view of morality.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ebo/seq_rerun_a_prodigy_of_refutation/\">A Prodigy of Refutation</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WcB2Z5qK4ao5mdkLS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.768096915919115e-07, "legacy": true, "legacyId": "18585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Yicjw6wSSaPdb83w9", "2rsRnzEoMDMPt7mtR", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-01T08:13:47.695Z", "modifiedAt": null, "url": null, "title": "Open Thread, September 1-15, 2012", "slug": "open-thread-september-1-15-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:37.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GyDfiSheWAeES7eYa/open-thread-september-1-15-2012", "pageUrlRelative": "/posts/GyDfiSheWAeES7eYa/open-thread-september-1-15-2012", "linkUrl": "https://www.lesswrong.com/posts/GyDfiSheWAeES7eYa/open-thread-september-1-15-2012", "postedAtFormatted": "Saturday, September 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20September%201-15%2C%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20September%201-15%2C%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyDfiSheWAeES7eYa%2Fopen-thread-september-1-15-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20September%201-15%2C%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyDfiSheWAeES7eYa%2Fopen-thread-september-1-15-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyDfiSheWAeES7eYa%2Fopen-thread-september-1-15-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 16, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post, even in Discussion, it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GyDfiSheWAeES7eYa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 9.768635782143414e-07, "legacy": true, "legacyId": "18591", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 360, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-01T09:02:15.512Z", "modifiedAt": null, "url": null, "title": "Meta: What do you think of a karma vote checklist?", "slug": "meta-what-do-you-think-of-a-karma-vote-checklist", "viewCount": null, "lastCommentedAt": "2013-11-24T07:46:49.561Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vvjqrMFw7DkwYvZWi/meta-what-do-you-think-of-a-karma-vote-checklist", "pageUrlRelative": "/posts/vvjqrMFw7DkwYvZWi/meta-what-do-you-think-of-a-karma-vote-checklist", "linkUrl": "https://www.lesswrong.com/posts/vvjqrMFw7DkwYvZWi/meta-what-do-you-think-of-a-karma-vote-checklist", "postedAtFormatted": "Saturday, September 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20What%20do%20you%20think%20of%20a%20karma%20vote%20checklist%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20What%20do%20you%20think%20of%20a%20karma%20vote%20checklist%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvvjqrMFw7DkwYvZWi%2Fmeta-what-do-you-think-of-a-karma-vote-checklist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20What%20do%20you%20think%20of%20a%20karma%20vote%20checklist%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvvjqrMFw7DkwYvZWi%2Fmeta-what-do-you-think-of-a-karma-vote-checklist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvvjqrMFw7DkwYvZWi%2Fmeta-what-do-you-think-of-a-karma-vote-checklist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p>I'm imagining an optional checklist offered if you downvote, with the list possibly including troll, poor spelling/grammar, false, redundant....</p>\n<p>For that matter, if an optional checklist for downvotes makes sense, then perhaps there should also be one for upvotes: sensible, informative, funny, caused an update....</p>\n<p>I'm imagining a little chart appearing if your cursor is on a karma number, the way the proportions of stars do for amazon reviews.</p>\n<p>I don't know how much trouble this would be to program-- I'm just floating the idea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vvjqrMFw7DkwYvZWi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 31, "extendedScore": null, "score": 9.768880038834114e-07, "legacy": true, "legacyId": "18592", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-01T23:38:02.472Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison: Cached Selves", "slug": "meetup-madison-cached-selves", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:30.844Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nz63kfApDRHevq7nX/meetup-madison-cached-selves", "pageUrlRelative": "/posts/Nz63kfApDRHevq7nX/meetup-madison-cached-selves", "linkUrl": "https://www.lesswrong.com/posts/Nz63kfApDRHevq7nX/meetup-madison-cached-selves", "postedAtFormatted": "Saturday, September 1st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%3A%20Cached%20Selves&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%3A%20Cached%20Selves%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz63kfApDRHevq7nX%2Fmeetup-madison-cached-selves%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%3A%20Cached%20Selves%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz63kfApDRHevq7nX%2Fmeetup-madison-cached-selves", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNz63kfApDRHevq7nX%2Fmeetup-madison-cached-selves", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dd'>Madison: Cached Selves</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">114 State St., Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a> is a really good post! There's time yet before tomorrow evening, and it's not very long. I think this gives a plausible, partial reduction of the idea that \"labels of identity\" are \"dangerous\". Also, the post makes some suggestions about how to avoid having this effect twist your beliefs. Any other ideas that might work?</p>\n\n<p>Anyhow, for tomorrow, let's read this and discuss. (Also, I'll bring some games. I like games!)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dd'>Madison: Cached Selves</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nz63kfApDRHevq7nX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 9.773295850211132e-07, "legacy": true, "legacyId": "18593", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison__Cached_Selves\">Discussion article for the meetup : <a href=\"/meetups/dd\">Madison: Cached Selves</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">114 State St., Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a> is a really good post! There's time yet before tomorrow evening, and it's not very long. I think this gives a plausible, partial reduction of the idea that \"labels of identity\" are \"dangerous\". Also, the post makes some suggestions about how to avoid having this effect twist your beliefs. Any other ideas that might work?</p>\n\n<p>Anyhow, for tomorrow, let's read this and discuss. (Also, I'll bring some games. I like games!)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison__Cached_Selves1\">Discussion article for the meetup : <a href=\"/meetups/dd\">Madison: Cached Selves</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison: Cached Selves", "anchor": "Discussion_article_for_the_meetup___Madison__Cached_Selves", "level": 1}, {"title": "Discussion article for the meetup : Madison: Cached Selves", "anchor": "Discussion_article_for_the_meetup___Madison__Cached_Selves1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T03:46:30.574Z", "modifiedAt": null, "url": null, "title": "Preventing discussion from being watered down by an \"endless September\" user influx.", "slug": "preventing-discussion-from-being-watered-down-by-an-endless", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:24.667Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Epiphany", "createdAt": "2012-08-12T03:33:21.256Z", "isAdmin": false, "displayName": "Epiphany"}, "userId": "BbbFp6hQzKF4YX8em", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MLaSGq6A6bLTdt6r8/preventing-discussion-from-being-watered-down-by-an-endless", "pageUrlRelative": "/posts/MLaSGq6A6bLTdt6r8/preventing-discussion-from-being-watered-down-by-an-endless", "linkUrl": "https://www.lesswrong.com/posts/MLaSGq6A6bLTdt6r8/preventing-discussion-from-being-watered-down-by-an-endless", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Preventing%20discussion%20from%20being%20watered%20down%20by%20an%20%22endless%20September%22%20user%20influx.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APreventing%20discussion%20from%20being%20watered%20down%20by%20an%20%22endless%20September%22%20user%20influx.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLaSGq6A6bLTdt6r8%2Fpreventing-discussion-from-being-watered-down-by-an-endless%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Preventing%20discussion%20from%20being%20watered%20down%20by%20an%20%22endless%20September%22%20user%20influx.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLaSGq6A6bLTdt6r8%2Fpreventing-discussion-from-being-watered-down-by-an-endless", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLaSGq6A6bLTdt6r8%2Fpreventing-discussion-from-being-watered-down-by-an-endless", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5802, "htmlBody": "<p>&nbsp; In the thread <a href=\"/lw/e5r/lesswrong_could_grow_a_lot_but_were_doing_it_wrong/\">\"LessWrong could grow a lot, but we're doing it wrong.\"</a>, I explained why LessWrong has the potential to grow quite a lot faster in my opinion, and volunteered to help LessWrong grow.&nbsp; Of course, a lot of people were concerned about the fact that a large quantity of new members will not directly translate to higher quality contributions or beneficial learning and social experiences in discussions, so I realized it would be better to help protect LessWrong first.&nbsp; I do not assume that fast growth has to cause a lowering of standards.&nbsp; I think fast growth can be good if the right people are joining and all goes well (specifics herein).&nbsp; However, if LessWrong grows carelessly, we could be inviting an <a href=\"http://en.wikipedia.org/wiki/Endless_September\">\"Endless September\"</a>, a term used to describe a never ending deluge of newbies that \"degraded standards of discourse and behavior on Usenet and the wider Internet\" (named after a phenomenon caused by an influx of college freshmen).&nbsp; My perspective on this is that it could happen at any time, regardless of whether any of us does anything.&nbsp; Why do I think that?&nbsp; LessWrong is growing very fast and could snowball on it's own.&nbsp; I've seen that happen, I saw it ruin a forum.&nbsp; That site wasn't even doing anything special to advertise the forum that I am aware of.&nbsp; The forum was just popular and growth went exponential.&nbsp; For this reason, I asked for a complete list of LessWrong registration dates in order to make a growth chart.&nbsp; I received it on 08-23-2012.&nbsp; The data shows that LessWrong has 13,727 total users, not including spammers and accounts that were deleted.&nbsp; From these, I have created a LessWrong growth bar graph:</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><img src=\"http://images.lesswrong.com/t3_ec2_0.png\" alt=\"\" width=\"310\" height=\"652\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp; Each bar represents a one month long total of registration dates (the last bar is a little short, being that it only goes up until the 23rd).&nbsp; The number of pixels in each bar is equal to the number of registrations each month.&nbsp; The first (leftmost) bar that hits the top of the picture (it actually goes waaaay off the page) mostly represents the transfer of over 2000 accounts from Overcoming Bias.&nbsp; The right bar that goes off the page is so far unexplained for me - 921 users joined in September 2011, more than three times the number in the months before and after it.&nbsp; If you happen to know what caused that, I would be very interested in finding out. (No, September 2010 does not stand out, if you were wondering the same thing).&nbsp; If anyone wants to do different kinds of analysis, I can generate more numbers and graphs fairly easily.</p>\n<p>&nbsp; As you can see, LessWrong has experienced pretty rapid growth.</p>\n<p>&nbsp; Growth is in a downward trend at the moment, but as you can see from the wild spikes everyplace, this could change any time.&nbsp; In addition to LessWrong growing on it's own, other events that could trigger an \"endless September\" effect are:</p>\n<p>&nbsp; LessWrong could be linked to by somebody really big (see: <a href=\"http://en.wikipedia.org/wiki/Slashdotted\">S</a><a href=\"http://en.wikipedia.org/wiki/Slashdotted\">lashdot effect</a> on Wikipedia).</p>\n<p>&nbsp; LessWrong could end up on the news after somebody does something news worthy or because a reporter discovers LessWrong culture and finds it interesting or weird.</p>\n<p>&nbsp; (A more detailed explanation is located <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/\">here</a>.)</p>\n<p>&nbsp; For these reasons, I feel it is a good idea to begin constructing endless September protection, so I have volunteered some of my professional web services to get it done.&nbsp; This has to be done carefully because if it is not done right, various unwanted things may happen.&nbsp; I am asking for any ideas or links to ideas you guys have that you think were good and am laying out my solutions and the pitfalls I have planned for below in order to seek your critiques and suggestions.</p>\n<p>&nbsp;</p>\n<h2>Cliff Notes Version:<br /></h2>\n<p>&nbsp; I really thought this out quite a bit because I think it's going to be tricky and because it's important.&nbsp; So I wrote a <a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/7j78\">cliff notes version</a> of the below solution ideas with pros and cons for each which is about a tenth the size.</p>\n<p>&nbsp;</p>\n<h2><strong>The most difficult challenge and my solution:</strong></h2>\n<p>&nbsp; People want the site to be enriching for those who want to learn better reasoning but haven't gotten very far yet.</p>\n<p>&nbsp; People <em>also </em>want an environment where they can get a good challenge, where they are encouraged to grow, where they can get exposed to new ideas and viewpoints, and where they can get useful, constructive criticism.&nbsp;</p>\n<p>&nbsp; The problem is that a basic desire all humans seem to share is a desire to avoid boredom.&nbsp; There is possibly a survival reason for this:&nbsp; There is no way to know everything, but missing even one piece of information can spell disaster.&nbsp; This may be why the brain appears to have evolved built-in motivators to prod you to learn constantly.&nbsp; From the mild ecstasy of flow state (cite Flow: The psychology of peak experiencing) to tedium, we are constantly being punished and rewarded based on whether we're receiving the optimal challenge for our level of ability.&nbsp;</p>\n<p>&nbsp; This means that those who are here for a challenge aren't going to spend their time being teachers for everybody who wants to learn.&nbsp; Not everyone has a teacher's personality and skill set to begin with, and some people who teach do it as writers, explaining to many thousands, rather than by explaining it one-to-one.&nbsp; If everyone feels expected to teach by hand-holding, most will be punished by their brains for not learning more themselves, and will be forced to seek a new learning environment.&nbsp; If beginners are locked out, we'll fail at spreading rationality.&nbsp; The ideal is to create an environment where everyone gets to experience flow, and no one has to sacrifice optimal challenge.</p>\n<p>&nbsp; To make this challenge a bit more complicated, American culture (yes, a majority of the visits, 51.12%, are coming from the USA - I have access to the Google Analytics) can get pretty touchy about elitism and anti-intellectualism.&nbsp; Even though the spirit of LessWrong - wanting to promote rational thought - is not elitist but actually inherently opposite to that (to increase good decision making in the world \"spreads the wealth\" rather than hoarding it or demanding privileges for being capable of good decisions), there is a risk that people will see this place as elitist.&nbsp; And even though self-improvement is inherently non-pretentious (by choosing to do self-improvement, you're admitting that you've got flaws), undoubtedly there will be a large number of people who might really benefit from learning here but instead insta-judge the place as \"pretentious\".&nbsp; Interpreting everything intellectual as pretentious and elitist is an unfortunate habit in our culture.&nbsp; I think, with the right wording on the most prominent pages (about us, register, home page, etc.) LessWrong might be presented as a unique non-elitist, non-pretentious place.</p>\n<p>&nbsp; For these reasons, I am suggesting multiple discussion areas that are separated by difficulty levels.&nbsp; Presenting them as \"Easy and Hard\" will do three things:</p>\n<p>&nbsp; 1. Serve as a reminder to those who attend that it's a place of learning where the objective is to get an optimal challenge and improve as far as possible.&nbsp; This would help keep it from coming across as pretentious or elitist.</p>\n<p>&nbsp; 2. Create a learning environment that's open to all levels, rather than a closed, elitist environment or one that's too daunting.&nbsp; The LessWrong discussion area <strong>is </strong>a bit daunting to users, so it might be really desirable for people to have an \"easy\" discussion area where they can learn in an environment that is not intimidating.</p>\n<p>&nbsp; 3. Give us an opportunity to experiment with approaches that help willing people learn faster.</p>\n<p>&nbsp;</p>\n<h2><strong>Endless September protection should be designed to avoid causing these side-effects:</strong></h2>\n<p>&nbsp;</p>\n<p><strong>&nbsp; Creating an imbalance in the proportion of thick-skinned individuals to normal individuals.</strong></p>\n<p>&nbsp; Anything that annoys, alienates or discourages users is going to deter a lot of people while retaining thick-skinned individuals.&nbsp; Some thick-skinned individuals are leaders, but many are trolls, and thick-skinned individuals may be more likely to resist acculturation or try to change the culture (though it could be argued the other way - that their thick skin allows them to take more honest feedback).&nbsp; For example: anonymous, unexplained down votes create a gauntlet for new users to endure which selects for a high tolerance to negative feedback.&nbsp; This may be the reason it has been reported that there are a lot of \"annoying debater types\".</p>\n<p>&nbsp;</p>\n<p>&nbsp; <strong>People that we do want fail to join because the method of protection puts them off.</strong></p>\n<p>&nbsp; There are two pitfalls that I think are going to be particularly attractive, but we should really avoid them:</p>\n<p>&nbsp; 1.) Filtering into hard/easy based on anything other than knowledge about rational thinking.&nbsp; There are various reasons that could go very wrong.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - Filtering in any other way will keep out advanced folks who may have a lot to teach.<br /></em></p>\n<p>&nbsp;&nbsp;&nbsp; If a person has already learned good reasoning skills in some other way, do we want them at the site?&nbsp; There might be logic professors, Zen masters, debate competition champs, geniuses, self-improvement professionals, hard-core bookworms and other people who are already advanced and are interested in <strong>teaching</strong> others to improve their skills, or interested in finding a good challenge, or are interested in contributing articles, but have already learned much of the material the sequences cover.&nbsp; Imagine that a retired logic professor comes by hoping to get a challenge from similarly advanced minds and perhaps do a little volunteer work teaching about logic as a past time.&nbsp; Now imagine requiring them to read 2,000 pages of \"how to think rationally\" in order to gain access to all the discussion areas.&nbsp; This will almost guarantee that they go elsewhere.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - Filtering based on the sequences or other cultural similarities would promote conformity and repel the true thinkers.<br /></em></p>\n<p>&nbsp;&nbsp;&nbsp; If true rationalists think for themselves, some of them will think differently, some of them will disagree.&nbsp; Eliezer has explained in <a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a> that \"I do propose that before you give anyone credit for being a smart, rational skeptic, that you ask them to defend some <em>non-mainstream</em> belief.\" he defines this as \"It has to be something that most of their social circle doesn't believe, or something that most of their social circle <em>does</em> believe which they think is wrong.\"&nbsp; If we want people in the \"hard\" social group who are likely to hold and defend non-mainstream beliefs, we have to filter out people unable to defend beliefs without scaring off those who have beliefs different from the group.</p>\n<p>&nbsp; 2.) Discouraging people with unusually flawed English from participating at all levels.&nbsp; Doing that would stop two important sources of new perspectives from flowing in:</p>\n<p><em>&nbsp; &nbsp; - People with cultural differences, who may bring in fresh perspectives.<br /></em></p>\n<p>&nbsp;&nbsp;&nbsp; If you're from China, you may want to share perspectives that could be new and important to a Westerner, but may be less likely to meet the technical standards of a perfectionist when it comes to writing in English.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - People with learning differences, whose brains work differently and may offer unique insight.<br /></em></p>\n<p>&nbsp;&nbsp;&nbsp; A lot of gifted people have learning disorders and gifted people who don't tend to have large gaps between skill levels.&nbsp; It is not uncommon to find a gifted person whose abilities with one skill are up to 40% behind (or better than) their abilities in other areas.&nbsp; This phenomenon is called \"asynchronous development\".&nbsp; We associate spelling and grammar with intelligence, but the truth is that those who have a high verbal IQ may not have equally intelligent things to say, and people who word things crudely due to asynchronous development (engineers, for instance, are not known for their communication skills but can be brilliant at engineering) may be ignored even though they could have important things to say.&nbsp; Dyslexics, who have all kinds of trouble from spelling to vocabulary to arranging sentences oddly may be ignored despite the fact that <a href=\"http://dyslexia.yale.edu/aboutdyslexia.html\">\"children and adults who are dyslexic usually excel at problem solving, reasoning, seeing the big picture, and thinking out of the box\" (Yale).</a></p>\n<p>&nbsp;&nbsp; Everyone understands the importance of making sure all the serious articles get published with good English, but frequently in intellectual circles, the attitude is that if you aren't a perfectionist about spelling and grammar, you're not worth listening to at all.&nbsp; The problem of getting articles polished when they are written by dyslexics or people for whom English is a second language should be pretty easy - people with English problems can simply seek a volunteer editor.&nbsp; The ratio of articles being published by these folks versus the number of users at the site encourages me to believe that these guys will be able to find someone to polish their work.&nbsp; Since it would be so easy to accommodate for these disabilities, taking an attitude that puts form over function as a filter would not serve you well.&nbsp; If dyslexics and people with cultures different from the majority feel that we're snobby about technicalities, they could be put off.&nbsp; This could already be happening and we could be missing out on the most creative and most different perspectives this way.</p>\n<p>&nbsp;</p>\n<p><strong>People who qualify under the \"letter\" of the standards do not meet the spirit of the standards.</strong></p>\n<p>&nbsp; For instance:&nbsp; They claim to be rationalists because they agree with a list of things that rationalists agree with, but don't think for themselves, as Eliezer cautions about in <a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a>.&nbsp; Asking them questions like \"Are you an atheist?\" and \"Do you think signing up for cryo makes sense?\" would only draw large numbers of people who agree but do not think for themselves.&nbsp; Worse, that would send a strong message saying: \"If you don't agree with us about everything, you aren't welcome here.\"</p>\n<p>&nbsp;</p>\n<p><strong>The right people join, but acculturate slowly or for some reason do not acculturate.&nbsp; </strong></p>\n<p>&nbsp; - Large numbers of users, even desirable ones, will be frustrating if newbie materials are not <strong>prominently</strong> posted.</p>\n<p>&nbsp; I was very confused and disoriented as a new user.&nbsp; I think that there's a need for an orientation page.&nbsp; I wrote about my experiences as a new user here which I think might make a good starting point for such a new user orientation page.&nbsp; I think LessWrong also needs a written list of guidelines and rules that's positioned to be \"in your face\" like the rest of the internet does (because if users don't see it where they expect to find it, then they will assume there isn't one).&nbsp; If new users adjust quickly, both old users and new users will be less annoyed if/when lots of new users join at once.</p>\n<p>&nbsp;</p>\n<p><strong>The filtering mechanism gives </strong><strong>LessWrong a bad name.</strong></p>\n<p>&nbsp; For instance, if we were to use an IQ test to filter users, the world may feel that LessWrong is an elitist organization.&nbsp; Sparking an anti-intellectual backlash would do nothing to further the cause of promoting rationality, and it doesn't truly reflect the spirit of bringing everyone up, which is what this is supposed to do.&nbsp; Similarly, asking questions that may trigger racial, political or religious feelings could be a bad idea - not because they aren't sources of bias, but because they'll scare away people who may have been open to questioning and growing but are not open to being forced to choose a different option immediately.&nbsp; The filters should be a test about reasoning, not a test about beliefs.</p>\n<p>&nbsp;</p>\n<h2>Proposed Filtering Mechanisms:</h2>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Principle One:&nbsp; A small number of questions can deter a lot of activity.</em></strong></p>\n<p>&nbsp; As a web pro, I have observed a 10 question registration form slash the number of files sent through a file upload input that used to be public.&nbsp; The ten questions were not that hard - just name, location, password, etc.&nbsp; Asking questions deters people from signing up.&nbsp; Period.&nbsp; That is why, if you've observed this trend as well, I think that a lot of big websites have begun asking for minimal registration info: email address and password only.&nbsp; Years ago, that was not common, it seemed that everyone wanted to give you ten or twenty questions.&nbsp; For this reason, I think it would be best if the registration form stays simple, but if we create extra hoops to jump through to use the hard discussion area, only those who are seriously interested will join in there.&nbsp; Specific examples of questions that meet the other criteria are located in the proposed acculturation methods section under: A test won't deter ignorant cheaters, but they can force them to educate themselves.</p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Principle Two:&nbsp; A rigorous environment will deter those who are not serious about doing it right.<br /></em></strong></p>\n<p>&nbsp; The ideal is to fill the hard discussion area with the sort of rationalists who want to keep improving, who are not afraid to disagree with each other, who think for themselves.&nbsp; How do you guarantee they're interested in improving?&nbsp; Require them to sacrifice for improvement.&nbsp; Getting honest feedback is necessary to improve, but it's not pleasant.&nbsp; That's the perfect sacrifice requirement:</p>\n<p>&nbsp; Add a check box that they have to click where it says \"By entering the hard discussion area, I'm inviting everyone's honest criticisms of my ideas.&nbsp; I agree to take responsibility for my own emotional reactions to feedback and to treat feedback as valuable.&nbsp; In return for their valuable feedback, which is a privilege and service to me, I will state my honest criticisms of their ideas as well, regardless of whether the truth could upset them.\"</p>\n<p>&nbsp; I think it's common to assume that in order to give honest feedback one has to throw manners out the window.&nbsp; I disagree with that.&nbsp; I think there's a difference between pointing out a brutal reality, and making the statement of reality itself brutal.&nbsp; Sticking to certain guidelines like attacking the idea, not the person and being objective instead of ridiculing makes a big difference. &nbsp;</p>\n<p>&nbsp; There are other ways, also, for less bold people, like the one that I use in IRL environments: Hint first (sensitive people get it, and you spare their dignity) then be clear (most people get it) then be brutally honest (slightly dense people get it). If I have to resort to the 2x4, then I really have to decide whether enlightening this person is going to be one of those battles I choose or one of those battles I do not choose.&nbsp; (I usually choose against those battles.)</p>\n<p>&nbsp; How do you guarantee they're capable of disagreeing with others?&nbsp; Making it clear that they're going to experience disagreements by requiring them to invite disagreements will not appeal to conformists.&nbsp; Those who are not yet thinking for themselves will find it impossible to defend their ideas if they do join, so most of them will become frustrated and go back to the easy discussion area.&nbsp; People who don't want intellectual rigor will be put off and leave.</p>\n<p>&nbsp; It's important that the wording for the check box has some actual bite to it, and that the same message about the hard discussion area is echoed in any pages that advise on the rules, guidelines, etiquette, etc.&nbsp; To explain why, I'll tell a little story about an anonymous friend:</p>\n<p>&nbsp; I have a friend that worked at Microsoft.&nbsp; He said the culture there was not open to new ideas and that management was not open to hearing criticism.&nbsp; He interviewed with various companies and chose Amazon.&nbsp; According to this friend, Amazon actually does a good job of fulfilling values like inviting honest feedback and creating an environment conductive to innovation.&nbsp; He showed me the written values for each.&nbsp; I didn't think much of this at first because most of them are boring and read like empty marketing copy.&nbsp; <a href=\" http://www.amazon.com/Values-Careers-Homepage/b/ref=amb_link_356017942_3?ie=UTF8&amp;node=239365011&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_s=left-2&amp;pf_rd_r=1N9CTZEW82NJ6NJBNR1Y&amp;pf_rd_t=10301&amp;pf_rd_p=1380702402&amp;pf_rd_i=overview\">Amazon.com has the most incredible written values page</a> I've ever seen - it does more than sit there like a static piece of text.&nbsp; <em>It gives you permission</em>.&nbsp; Instead of saying something fluffy like: \"We value integrity and honesty and our managers are happy to hear your criticisms.\" it first creates expectations for management: \" Leaders are sincerely open-minded, genuinely listen, and are willing to examine their strongest convictions with humility.\" and then gives employees permission to give honest feedback to decision-makers: \"Leaders (all employees are referred to as \"leaders\") are obligated to respectfully challenge decisions when they disagree, even when doing so is uncomfortable or exhausting.&nbsp; Leaders have conviction and are tenacious. They do not compromise for the sake of social cohesion.\"&nbsp; The Amazon values page gives their employees permission to innovate as well: \"As we do new things, we accept that we may be misunderstood for long periods of time.\"&nbsp; If you look at <a href=\"http://www.microsoft.com/about/corporatecitizenship/en-us/\">Microsoft's written values</a>, there's no bite to them.&nbsp; What do I mean by bite?</p>\n<p>&nbsp; Imagine you're an employee at Amazon.&nbsp; Your boss does something stupid.&nbsp; The cultural expectation is that you're not supposed to say anything - offending the boss is bad news, right?&nbsp; So you're inhibited.&nbsp; But the thing they've done is stupid.&nbsp; So you remember back to the values page and go bring it up on your computer.&nbsp; It says explicitly that your boss is expected to be humble and that you are expected to sacrifice social cohesion in this case and disagree.&nbsp; Now, if your boss gets irritated with you for disagreeing, you can point back to that page and say \"Look, it's in writing, I have permission to tell you.\"</p>\n<p>&nbsp; Similarly, there is, what I consider to be, a very unfortunate social skills requirement that more or less says if you don't have something nice to say, don't say anything at all.&nbsp; Many people feel obligated to keep constructive criticism to themselves.&nbsp; A lot of us are intentionally trained to be non-confrontational.&nbsp; If people are going to overcome this lifetime of training to squelch constructive criticism, they need an excuse to ignore that social training.&nbsp; Not just any excuse.&nbsp; It needs to be worded to require them to do that and it needs to be worded to require them to do it explicitly despite the consequences.</p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Principle Three:&nbsp; If we want innovation, we have to make innovators feel welcome.<br /></em></strong></p>\n<p>&nbsp; That brings me to another point.&nbsp; If you want innovation, you can't deter the sort of person who will bring it to you: the \"people who will be misunderstood for long periods of time\", as Amazon puts it.&nbsp; If you give specific constructive criticism to a misunderstood person, this will help them figure out how to communicate - how else will they navigate the jungle of perception and context differences between themselves and others?&nbsp; If you simply vote them down, silently and anonymously, they have no opportunity to learn how to communicate with you and what's worse is that they'll be censored after three votes.&nbsp; This ability for three people to censor somebody with no accountability, and without even needing a reason, encourages posters to keep quiet instead of taking the sort of risk an innovator needs to take in presenting new ideas, and it robs misunderstood innovators of those opportunities for important feedback - which is required for them to explain their ideas.&nbsp; Here is an example of how feedback can transform an innovator's description of a new idea from something that seems incomprehensible into something that shows obvious value:</p>\n<p>&nbsp; On the \"Let's start an important start-up\" thread, KrisC posts a description of an innovative phone app idea.&nbsp; I read it and I cannot even figure out what it's about.&nbsp; My instinct is to write it off as \"gibberish\" and go do something else.&nbsp; Instead, I provide feedback, constructive criticism and questions.&nbsp; It turns out that the idea KrisC has is actually pretty awesome.&nbsp; All it took was for KrisC to be listened to and to get some feedback, and the next description that KrisC wrote made pretty good sense.&nbsp; It's hard to explain new ideas but with detailed feedback, innovation may start to show through.&nbsp; <a href=\"/lw/e26/who_wants_to_start_an_important_startup/780b\">Link to KrisC and I discussing the phone app idea.</a></p>\n<p>&nbsp;</p>\n<h2>Proposed Acculturation Methods:</h2>\n<p>&nbsp;</p>\n<p>&nbsp;&nbsp; <em><strong>Send them to Center for Modern Rationality</strong></em></p>\n<p>&nbsp;&nbsp; Now that I have discovered the post on the <a href=\"/lw/bpi/center_for_modern_rationality_currently_hiring/\">Center for Modern Rationality</a> and have see that they're targeting the general population and beginners with <a href=\"/lw/9lx/help_name_suggestions_needed_for_rationalityinst/\">material for local meetups, high schools and colleges</a> and they're planning some web apps to help with rationality training, I see that referring people over to them might be a great suggestion.&nbsp; Saturn <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7bls\">suggested sending them to appliedrationality.org</a> before I found this but I'm not sure if that would be adequate since I don't see a lot of stuff for people to do on their website.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Highlight the culture.</strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; A database of cultural glossary terms can be created and used to highlight those terms on the forum.&nbsp; The terms are already on the page, so what good would this do?&nbsp; Well, first they can be automatically linked to the relevant sequence or wiki page.&nbsp; If old users do not have to look for the link, this speeds up the process of mentioning them to new users quite a lot.&nbsp; Secondly, it would make the core cultural items stand out from all of the other information, which will likely cause new users to prioritize it.&nbsp; Thirdly, there will be a visual effect on the page.&nbsp; You'll be able to <em>see</em> that this place has it's own vocabulary, it's own personality, it's own memes.&nbsp; It's one thing to say \"LessWrong has been influenced by the sequences\" to a new user who hasn't seen all those references on all of those pages, and even if they do see them, won't know where they're from, versus making it immediately obvious how by giving them a visual that illustrates the point.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Provide new users with real feedback instead of mysterious anonymous down votes:<br /></strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; We have karma vote buttons, but this is not providing useful feedback for new users.&nbsp; Without a specific reason, I have no way to tell if I'm being down voted by trolls and I may see ten different possible reasons for being voted down and not know which one to choose.&nbsp; This annoyance selects for thick-skinned individuals like trolls and fails to avoid the \"imbalance in the proportion of thick-skinned individuals to normal individuals\" side-effect.</p>\n<p>&nbsp;&nbsp;&nbsp; If good new users are to be preserved, and the normal people to troll ratio is to be maintained, we need to add a \"vote to ban\" button that's used only for blatant misbehavior, and if an anonymous feedback system is to be used for voting down, it needs to prompt you for more detailed feedback - either allowing you to select from categories, or give at least one or two words as an explanation.&nbsp; Also, the comments need to should show both up votes and down votes.&nbsp; If you don't know when you've said something controversial and are being encouraged to view everything you say as black-and-white good-or-bad, this promotes conformity.</p>\n<p>&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; <strong><em>A test won't deter ignorant cheaters, but they can force them to educate themselves.<br /></em></strong></p>\n<p>&nbsp;&nbsp;&nbsp; Questions can be worded in such a way that they serve as a crash course in reasoning in the event that someone posts a cheat sheet or registrants look up all the answers on the internet.&nbsp; Assuming that the answer options are randomly ordered so that you have to actually read them then the test should, at the very least, familiarize them with the various biases and logical fallacies, etc.&nbsp; Examples:</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; Person A in a debate explains a belief but it's not well-supported.&nbsp; Their opponent, person B, says they're an idiot.&nbsp; What is this an example of?</p>\n<p>&nbsp;&nbsp;&nbsp; A. Attacking the person, a great way to really nail a debate.</p>\n<p>&nbsp;&nbsp;&nbsp; B. Attacking the person, a great way to totally fail in debate because you're not even attacking their ideas.</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; You are with person X and person Y.&nbsp; Person Y says they have been considering some interesting new evidence of what might be an alien space craft and aren't sure what to think yet.&nbsp; You both see person Y's evidence, and neither of you has seen it before.&nbsp; Person X says to you that they don't believe in UFOs and don't care about person Y's silly evidence.&nbsp; Who is the better skeptic?</p>\n<p>&nbsp;&nbsp;&nbsp; Person X because they have the correct belief about UFOs.</p>\n<p>&nbsp;&nbsp;&nbsp; Person Y because they are actually thinking about it, avoiding undiscriminating skepticism.</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; Note:&nbsp; These questions are intentionally knowledge-based.&nbsp; If the purpose is to avoid requiring an IQ test, and to create an obstacle that requires you to learn about reasoning before posting in \"hard\", that's the only way that these can be done.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Encouraging users to lurk more.&nbsp; </strong></em></p>\n<p>&nbsp;&nbsp; Vaniver contributed this: Another way to cut down on new-new interaction is to limit the number of comments someone can make in a time period- if people can only comment once an day until their karma hits 20, and then once an hour until their karma hits 100, and then they're unrestricted, that will explicitly encourage lurking / paying close attention to karma among new members. (It would be gameable, unless you did something like prevent new members from upvoting the comments of other new members, or algorithmically keeping an eye out for people gaming the system and then cracking down on them.) [edit] The delay being a near-continuous function of the karma- say, 24 hours*exp(-b karma)- might make the incentives better, and not require partitioning users explicitly. No idea if that would be more or less effort on the coding side.</p>\n<p>&nbsp;&nbsp;&nbsp; Cons:&nbsp; This would deter some new users from becoming active users by causing them to lose steam on their initial motivation to join.&nbsp; It might be something that would deter the right people.&nbsp; It might also filter users, selecting for the most persistent ones, or for some other trait that might change the personality of the user base.&nbsp; This would exacerbate the filtering effect that the current karma system is exerting, which, I theorize, is causing there to be a disproportionate number of thick-skinned individuals like trolls and debate-oriented newbies.&nbsp; <a href=\"/lw/ecg/meta_what_do_you_think_of_a_karma_vote_checklist/7bpm\">My theory about how the karma system is having a bad influence</a></p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Give older users more voting power.&nbsp; </strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; Luke suggested \"Maybe <a rel=\"nofollow\" href=\"http://gkosev.blogspot.com.au/2012/08/fixing-hacker-news-mathematical-approach.html\">this mathematical approach</a> would work. (h/t <a href=\"/user/matt/\">matt</a>)\" on the \"Call for Agreement\" thread.&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp; I question, though, whether changing the karma numbers on the comments and posts in <em>any</em> way would have a significant influence on behavior or a significant influence on who joins and stays. Firstly, votes may reward and punish but they don't instruct very well - unless people are very similar, they won't have accurate assumptions about what they did wrong. I also question whether having a significant influence on behavior would prevent a new majority from forming because these are different problems. The current users who are the right type may be both motivated and able to change, but future users of the wrong type may not care or may be incapable of changing. They may set a new precedent where there are a lot of people doing unpopular things so new people are more likely to ignore popularity. The technique uses math and the author claims that \"the tweaks work\" but I didn't see anything specific about what the author means by that nor evidence that this is true. So this <em>looks</em> good because it is mathematical, but it's less direct than other options so I'm questioning whether it would work.</p>\n<p>&nbsp; <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/7bvi\">Vladimir_Nesov posted a variation here.</a></p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Make a different discussion area for users with over 1000 karma.</em></strong></p>\n<p>&nbsp; <a href=\"/lw/ebv/dealing_with_trolling_and_the_signal_to_noise/7b0l\">Posted by Konkvistador here.</a></p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Make a </em></strong><strong><em>Multi Generation Culture.</em></strong></p>\n<p>&nbsp; Limit the number of new users that join the forum to a certain percentage per month, sending the rest to a new forum.&nbsp; If that forum grows too fast, create additional forums.&nbsp; This would be like having different generations.&nbsp; New people would be able to join an older generation if there is space.&nbsp; Nobody would be labeled a \"beginner\".</p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Temporarily turn off registration or limit the number of users that can join.</em></strong></p>\n<p>&nbsp; (See the cliff notes version for more.)</p>\n<p>&nbsp;</p>\n<h2>Should easy discussion participants be able to post articles?</h2>\n<p>&nbsp; I think the answer to this is yes, because no filtering mechanism is perfect and the last thing you want to do is filter out people with a different and important point of view.&nbsp; Unless the site is currently having issues with trolls posting new articles, or with the quality of the articles going down, leaving that freedom intact is best.&nbsp; I definitely think, though, that written guidelines for posting an article need to be put in \"in your face\" expected places.&nbsp; If a lot of new users join at once, well-meaning but confused people will be posting the wrong sorts of things there - making sure they've got the guidelines right there is all that's probably needed to deter them.</p>\n<p>&nbsp;</p>\n<h2>Testing / measuring results:</h2>\n<p>&nbsp; How do we tell if this worked?&nbsp; Tracking something subjective like whether we're feeling challenged or inundated with newbies is not going to be a straightforward matter of looking at numbers.&nbsp; (Methods to assist willing people learn faster deserves it's own post.)&nbsp; Just because it's subjective doesn't mean tracking is impossible or that working out whether it's made a difference cannot be done.&nbsp; I suspect that a big difference will be noticed in the hard discussion area right away.&nbsp; Here are some figures that are relevant and can be tracked, that may give us insight and ways to check our perceptions:</p>\n<p>&nbsp; 1.&nbsp; How many people are joining the hard forum versus the easy forum?&nbsp; If we've got a percentage, we know how *much* we've filtered, though we won't know exactly *who* we've filtered.</p>\n<p>&nbsp; 2.&nbsp; Survey the users to ask whether the conversations they're reading have increased in quality.</p>\n<p>&nbsp; 3.&nbsp; Survey the users to ask whether they've been learning more since the change.</p>\n<p>&nbsp; 4.&nbsp; See which area has the largest ratio of users with lots of vote downs.&nbsp;</p>\n<p>&nbsp; (This could be tricky because people who frequently state disagreements might be doing a great service to the group, but might be unpopular because of it, and people who are innovative may be getting voted down due to being misunderstood.&nbsp; One would think, though, that people who are unpopular due to disagreeing, or being innovative, assuming they're serious about good reasoning, would end up in the hard forum.)&nbsp;</p>\n<p>&nbsp;</p>\n<h2>Request for honest feedback:<br /></h2>\n<p>&nbsp; Your honest criticisms of this idea and your suggestions will be appreciated, and I will update this idea or write a new one to reflect any good criticisms or ideas you contribute.</p>\n<p>&nbsp;</p>\n<h2>This is in the public domain:<br /></h2>\n<p>&nbsp; This idea is hereby released into the public domain, with acknowledgement from Luke Muehlhauser that those were my terms prior to posting.&nbsp; My intent is to share this idea to make it impossible to patent and my hope is that it will be free for the whole world to use.</p>\n<p><span>&nbsp; Preventing discussion from being watered down by an \"endless September\" user influx.</span> by <span>Epiphany</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/3.0/deed.en_US\">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MLaSGq6A6bLTdt6r8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 19, "extendedScore": null, "score": 9.774549303385366e-07, "legacy": true, "legacyId": "18578", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>&nbsp; In the thread <a href=\"/lw/e5r/lesswrong_could_grow_a_lot_but_were_doing_it_wrong/\">\"LessWrong could grow a lot, but we're doing it wrong.\"</a>, I explained why LessWrong has the potential to grow quite a lot faster in my opinion, and volunteered to help LessWrong grow.&nbsp; Of course, a lot of people were concerned about the fact that a large quantity of new members will not directly translate to higher quality contributions or beneficial learning and social experiences in discussions, so I realized it would be better to help protect LessWrong first.&nbsp; I do not assume that fast growth has to cause a lowering of standards.&nbsp; I think fast growth can be good if the right people are joining and all goes well (specifics herein).&nbsp; However, if LessWrong grows carelessly, we could be inviting an <a href=\"http://en.wikipedia.org/wiki/Endless_September\">\"Endless September\"</a>, a term used to describe a never ending deluge of newbies that \"degraded standards of discourse and behavior on Usenet and the wider Internet\" (named after a phenomenon caused by an influx of college freshmen).&nbsp; My perspective on this is that it could happen at any time, regardless of whether any of us does anything.&nbsp; Why do I think that?&nbsp; LessWrong is growing very fast and could snowball on it's own.&nbsp; I've seen that happen, I saw it ruin a forum.&nbsp; That site wasn't even doing anything special to advertise the forum that I am aware of.&nbsp; The forum was just popular and growth went exponential.&nbsp; For this reason, I asked for a complete list of LessWrong registration dates in order to make a growth chart.&nbsp; I received it on 08-23-2012.&nbsp; The data shows that LessWrong has 13,727 total users, not including spammers and accounts that were deleted.&nbsp; From these, I have created a LessWrong growth bar graph:</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><img src=\"http://images.lesswrong.com/t3_ec2_0.png\" alt=\"\" width=\"310\" height=\"652\"></p>\n<p>&nbsp;</p>\n<p>&nbsp; Each bar represents a one month long total of registration dates (the last bar is a little short, being that it only goes up until the 23rd).&nbsp; The number of pixels in each bar is equal to the number of registrations each month.&nbsp; The first (leftmost) bar that hits the top of the picture (it actually goes waaaay off the page) mostly represents the transfer of over 2000 accounts from Overcoming Bias.&nbsp; The right bar that goes off the page is so far unexplained for me - 921 users joined in September 2011, more than three times the number in the months before and after it.&nbsp; If you happen to know what caused that, I would be very interested in finding out. (No, September 2010 does not stand out, if you were wondering the same thing).&nbsp; If anyone wants to do different kinds of analysis, I can generate more numbers and graphs fairly easily.</p>\n<p>&nbsp; As you can see, LessWrong has experienced pretty rapid growth.</p>\n<p>&nbsp; Growth is in a downward trend at the moment, but as you can see from the wild spikes everyplace, this could change any time.&nbsp; In addition to LessWrong growing on it's own, other events that could trigger an \"endless September\" effect are:</p>\n<p>&nbsp; LessWrong could be linked to by somebody really big (see: <a href=\"http://en.wikipedia.org/wiki/Slashdotted\">S</a><a href=\"http://en.wikipedia.org/wiki/Slashdotted\">lashdot effect</a> on Wikipedia).</p>\n<p>&nbsp; LessWrong could end up on the news after somebody does something news worthy or because a reporter discovers LessWrong culture and finds it interesting or weird.</p>\n<p>&nbsp; (A more detailed explanation is located <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/\">here</a>.)</p>\n<p>&nbsp; For these reasons, I feel it is a good idea to begin constructing endless September protection, so I have volunteered some of my professional web services to get it done.&nbsp; This has to be done carefully because if it is not done right, various unwanted things may happen.&nbsp; I am asking for any ideas or links to ideas you guys have that you think were good and am laying out my solutions and the pitfalls I have planned for below in order to seek your critiques and suggestions.</p>\n<p>&nbsp;</p>\n<h2 id=\"Cliff_Notes_Version_\">Cliff Notes Version:<br></h2>\n<p>&nbsp; I really thought this out quite a bit because I think it's going to be tricky and because it's important.&nbsp; So I wrote a <a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/7j78\">cliff notes version</a> of the below solution ideas with pros and cons for each which is about a tenth the size.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_most_difficult_challenge_and_my_solution_\"><strong>The most difficult challenge and my solution:</strong></h2>\n<p>&nbsp; People want the site to be enriching for those who want to learn better reasoning but haven't gotten very far yet.</p>\n<p>&nbsp; People <em>also </em>want an environment where they can get a good challenge, where they are encouraged to grow, where they can get exposed to new ideas and viewpoints, and where they can get useful, constructive criticism.&nbsp;</p>\n<p>&nbsp; The problem is that a basic desire all humans seem to share is a desire to avoid boredom.&nbsp; There is possibly a survival reason for this:&nbsp; There is no way to know everything, but missing even one piece of information can spell disaster.&nbsp; This may be why the brain appears to have evolved built-in motivators to prod you to learn constantly.&nbsp; From the mild ecstasy of flow state (cite Flow: The psychology of peak experiencing) to tedium, we are constantly being punished and rewarded based on whether we're receiving the optimal challenge for our level of ability.&nbsp;</p>\n<p>&nbsp; This means that those who are here for a challenge aren't going to spend their time being teachers for everybody who wants to learn.&nbsp; Not everyone has a teacher's personality and skill set to begin with, and some people who teach do it as writers, explaining to many thousands, rather than by explaining it one-to-one.&nbsp; If everyone feels expected to teach by hand-holding, most will be punished by their brains for not learning more themselves, and will be forced to seek a new learning environment.&nbsp; If beginners are locked out, we'll fail at spreading rationality.&nbsp; The ideal is to create an environment where everyone gets to experience flow, and no one has to sacrifice optimal challenge.</p>\n<p>&nbsp; To make this challenge a bit more complicated, American culture (yes, a majority of the visits, 51.12%, are coming from the USA - I have access to the Google Analytics) can get pretty touchy about elitism and anti-intellectualism.&nbsp; Even though the spirit of LessWrong - wanting to promote rational thought - is not elitist but actually inherently opposite to that (to increase good decision making in the world \"spreads the wealth\" rather than hoarding it or demanding privileges for being capable of good decisions), there is a risk that people will see this place as elitist.&nbsp; And even though self-improvement is inherently non-pretentious (by choosing to do self-improvement, you're admitting that you've got flaws), undoubtedly there will be a large number of people who might really benefit from learning here but instead insta-judge the place as \"pretentious\".&nbsp; Interpreting everything intellectual as pretentious and elitist is an unfortunate habit in our culture.&nbsp; I think, with the right wording on the most prominent pages (about us, register, home page, etc.) LessWrong might be presented as a unique non-elitist, non-pretentious place.</p>\n<p>&nbsp; For these reasons, I am suggesting multiple discussion areas that are separated by difficulty levels.&nbsp; Presenting them as \"Easy and Hard\" will do three things:</p>\n<p>&nbsp; 1. Serve as a reminder to those who attend that it's a place of learning where the objective is to get an optimal challenge and improve as far as possible.&nbsp; This would help keep it from coming across as pretentious or elitist.</p>\n<p>&nbsp; 2. Create a learning environment that's open to all levels, rather than a closed, elitist environment or one that's too daunting.&nbsp; The LessWrong discussion area <strong>is </strong>a bit daunting to users, so it might be really desirable for people to have an \"easy\" discussion area where they can learn in an environment that is not intimidating.</p>\n<p>&nbsp; 3. Give us an opportunity to experiment with approaches that help willing people learn faster.</p>\n<p>&nbsp;</p>\n<h2 id=\"Endless_September_protection_should_be_designed_to_avoid_causing_these_side_effects_\"><strong>Endless September protection should be designed to avoid causing these side-effects:</strong></h2>\n<p>&nbsp;</p>\n<p><strong id=\"__Creating_an_imbalance_in_the_proportion_of_thick_skinned_individuals_to_normal_individuals_\">&nbsp; Creating an imbalance in the proportion of thick-skinned individuals to normal individuals.</strong></p>\n<p>&nbsp; Anything that annoys, alienates or discourages users is going to deter a lot of people while retaining thick-skinned individuals.&nbsp; Some thick-skinned individuals are leaders, but many are trolls, and thick-skinned individuals may be more likely to resist acculturation or try to change the culture (though it could be argued the other way - that their thick skin allows them to take more honest feedback).&nbsp; For example: anonymous, unexplained down votes create a gauntlet for new users to endure which selects for a high tolerance to negative feedback.&nbsp; This may be the reason it has been reported that there are a lot of \"annoying debater types\".</p>\n<p>&nbsp;</p>\n<p>&nbsp; <strong>People that we do want fail to join because the method of protection puts them off.</strong></p>\n<p>&nbsp; There are two pitfalls that I think are going to be particularly attractive, but we should really avoid them:</p>\n<p>&nbsp; 1.) Filtering into hard/easy based on anything other than knowledge about rational thinking.&nbsp; There are various reasons that could go very wrong.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - Filtering in any other way will keep out advanced folks who may have a lot to teach.<br></em></p>\n<p>&nbsp;&nbsp;&nbsp; If a person has already learned good reasoning skills in some other way, do we want them at the site?&nbsp; There might be logic professors, Zen masters, debate competition champs, geniuses, self-improvement professionals, hard-core bookworms and other people who are already advanced and are interested in <strong>teaching</strong> others to improve their skills, or interested in finding a good challenge, or are interested in contributing articles, but have already learned much of the material the sequences cover.&nbsp; Imagine that a retired logic professor comes by hoping to get a challenge from similarly advanced minds and perhaps do a little volunteer work teaching about logic as a past time.&nbsp; Now imagine requiring them to read 2,000 pages of \"how to think rationally\" in order to gain access to all the discussion areas.&nbsp; This will almost guarantee that they go elsewhere.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - Filtering based on the sequences or other cultural similarities would promote conformity and repel the true thinkers.<br></em></p>\n<p>&nbsp;&nbsp;&nbsp; If true rationalists think for themselves, some of them will think differently, some of them will disagree.&nbsp; Eliezer has explained in <a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a> that \"I do propose that before you give anyone credit for being a smart, rational skeptic, that you ask them to defend some <em>non-mainstream</em> belief.\" he defines this as \"It has to be something that most of their social circle doesn't believe, or something that most of their social circle <em>does</em> believe which they think is wrong.\"&nbsp; If we want people in the \"hard\" social group who are likely to hold and defend non-mainstream beliefs, we have to filter out people unable to defend beliefs without scaring off those who have beliefs different from the group.</p>\n<p>&nbsp; 2.) Discouraging people with unusually flawed English from participating at all levels.&nbsp; Doing that would stop two important sources of new perspectives from flowing in:</p>\n<p><em>&nbsp; &nbsp; - People with cultural differences, who may bring in fresh perspectives.<br></em></p>\n<p>&nbsp;&nbsp;&nbsp; If you're from China, you may want to share perspectives that could be new and important to a Westerner, but may be less likely to meet the technical standards of a perfectionist when it comes to writing in English.</p>\n<p><em>&nbsp;&nbsp;&nbsp; - People with learning differences, whose brains work differently and may offer unique insight.<br></em></p>\n<p>&nbsp;&nbsp;&nbsp; A lot of gifted people have learning disorders and gifted people who don't tend to have large gaps between skill levels.&nbsp; It is not uncommon to find a gifted person whose abilities with one skill are up to 40% behind (or better than) their abilities in other areas.&nbsp; This phenomenon is called \"asynchronous development\".&nbsp; We associate spelling and grammar with intelligence, but the truth is that those who have a high verbal IQ may not have equally intelligent things to say, and people who word things crudely due to asynchronous development (engineers, for instance, are not known for their communication skills but can be brilliant at engineering) may be ignored even though they could have important things to say.&nbsp; Dyslexics, who have all kinds of trouble from spelling to vocabulary to arranging sentences oddly may be ignored despite the fact that <a href=\"http://dyslexia.yale.edu/aboutdyslexia.html\">\"children and adults who are dyslexic usually excel at problem solving, reasoning, seeing the big picture, and thinking out of the box\" (Yale).</a></p>\n<p>&nbsp;&nbsp; Everyone understands the importance of making sure all the serious articles get published with good English, but frequently in intellectual circles, the attitude is that if you aren't a perfectionist about spelling and grammar, you're not worth listening to at all.&nbsp; The problem of getting articles polished when they are written by dyslexics or people for whom English is a second language should be pretty easy - people with English problems can simply seek a volunteer editor.&nbsp; The ratio of articles being published by these folks versus the number of users at the site encourages me to believe that these guys will be able to find someone to polish their work.&nbsp; Since it would be so easy to accommodate for these disabilities, taking an attitude that puts form over function as a filter would not serve you well.&nbsp; If dyslexics and people with cultures different from the majority feel that we're snobby about technicalities, they could be put off.&nbsp; This could already be happening and we could be missing out on the most creative and most different perspectives this way.</p>\n<p>&nbsp;</p>\n<p><strong id=\"People_who_qualify_under_the__letter__of_the_standards_do_not_meet_the_spirit_of_the_standards_\">People who qualify under the \"letter\" of the standards do not meet the spirit of the standards.</strong></p>\n<p>&nbsp; For instance:&nbsp; They claim to be rationalists because they agree with a list of things that rationalists agree with, but don't think for themselves, as Eliezer cautions about in <a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a>.&nbsp; Asking them questions like \"Are you an atheist?\" and \"Do you think signing up for cryo makes sense?\" would only draw large numbers of people who agree but do not think for themselves.&nbsp; Worse, that would send a strong message saying: \"If you don't agree with us about everything, you aren't welcome here.\"</p>\n<p>&nbsp;</p>\n<p><strong id=\"The_right_people_join__but_acculturate_slowly_or_for_some_reason_do_not_acculturate___\">The right people join, but acculturate slowly or for some reason do not acculturate.&nbsp; </strong></p>\n<p>&nbsp; - Large numbers of users, even desirable ones, will be frustrating if newbie materials are not <strong>prominently</strong> posted.</p>\n<p>&nbsp; I was very confused and disoriented as a new user.&nbsp; I think that there's a need for an orientation page.&nbsp; I wrote about my experiences as a new user here which I think might make a good starting point for such a new user orientation page.&nbsp; I think LessWrong also needs a written list of guidelines and rules that's positioned to be \"in your face\" like the rest of the internet does (because if users don't see it where they expect to find it, then they will assume there isn't one).&nbsp; If new users adjust quickly, both old users and new users will be less annoyed if/when lots of new users join at once.</p>\n<p>&nbsp;</p>\n<p><strong>The filtering mechanism gives </strong><strong>LessWrong a bad name.</strong></p>\n<p>&nbsp; For instance, if we were to use an IQ test to filter users, the world may feel that LessWrong is an elitist organization.&nbsp; Sparking an anti-intellectual backlash would do nothing to further the cause of promoting rationality, and it doesn't truly reflect the spirit of bringing everyone up, which is what this is supposed to do.&nbsp; Similarly, asking questions that may trigger racial, political or religious feelings could be a bad idea - not because they aren't sources of bias, but because they'll scare away people who may have been open to questioning and growing but are not open to being forced to choose a different option immediately.&nbsp; The filters should be a test about reasoning, not a test about beliefs.</p>\n<p>&nbsp;</p>\n<h2 id=\"Proposed_Filtering_Mechanisms_\">Proposed Filtering Mechanisms:</h2>\n<p>&nbsp;</p>\n<p><strong id=\"__Principle_One___A_small_number_of_questions_can_deter_a_lot_of_activity_\"><em>&nbsp; Principle One:&nbsp; A small number of questions can deter a lot of activity.</em></strong></p>\n<p>&nbsp; As a web pro, I have observed a 10 question registration form slash the number of files sent through a file upload input that used to be public.&nbsp; The ten questions were not that hard - just name, location, password, etc.&nbsp; Asking questions deters people from signing up.&nbsp; Period.&nbsp; That is why, if you've observed this trend as well, I think that a lot of big websites have begun asking for minimal registration info: email address and password only.&nbsp; Years ago, that was not common, it seemed that everyone wanted to give you ten or twenty questions.&nbsp; For this reason, I think it would be best if the registration form stays simple, but if we create extra hoops to jump through to use the hard discussion area, only those who are seriously interested will join in there.&nbsp; Specific examples of questions that meet the other criteria are located in the proposed acculturation methods section under: A test won't deter ignorant cheaters, but they can force them to educate themselves.</p>\n<p>&nbsp;</p>\n<p><strong id=\"__Principle_Two___A_rigorous_environment_will_deter_those_who_are_not_serious_about_doing_it_right_\"><em>&nbsp; Principle Two:&nbsp; A rigorous environment will deter those who are not serious about doing it right.<br></em></strong></p>\n<p>&nbsp; The ideal is to fill the hard discussion area with the sort of rationalists who want to keep improving, who are not afraid to disagree with each other, who think for themselves.&nbsp; How do you guarantee they're interested in improving?&nbsp; Require them to sacrifice for improvement.&nbsp; Getting honest feedback is necessary to improve, but it's not pleasant.&nbsp; That's the perfect sacrifice requirement:</p>\n<p>&nbsp; Add a check box that they have to click where it says \"By entering the hard discussion area, I'm inviting everyone's honest criticisms of my ideas.&nbsp; I agree to take responsibility for my own emotional reactions to feedback and to treat feedback as valuable.&nbsp; In return for their valuable feedback, which is a privilege and service to me, I will state my honest criticisms of their ideas as well, regardless of whether the truth could upset them.\"</p>\n<p>&nbsp; I think it's common to assume that in order to give honest feedback one has to throw manners out the window.&nbsp; I disagree with that.&nbsp; I think there's a difference between pointing out a brutal reality, and making the statement of reality itself brutal.&nbsp; Sticking to certain guidelines like attacking the idea, not the person and being objective instead of ridiculing makes a big difference. &nbsp;</p>\n<p>&nbsp; There are other ways, also, for less bold people, like the one that I use in IRL environments: Hint first (sensitive people get it, and you spare their dignity) then be clear (most people get it) then be brutally honest (slightly dense people get it). If I have to resort to the 2x4, then I really have to decide whether enlightening this person is going to be one of those battles I choose or one of those battles I do not choose.&nbsp; (I usually choose against those battles.)</p>\n<p>&nbsp; How do you guarantee they're capable of disagreeing with others?&nbsp; Making it clear that they're going to experience disagreements by requiring them to invite disagreements will not appeal to conformists.&nbsp; Those who are not yet thinking for themselves will find it impossible to defend their ideas if they do join, so most of them will become frustrated and go back to the easy discussion area.&nbsp; People who don't want intellectual rigor will be put off and leave.</p>\n<p>&nbsp; It's important that the wording for the check box has some actual bite to it, and that the same message about the hard discussion area is echoed in any pages that advise on the rules, guidelines, etiquette, etc.&nbsp; To explain why, I'll tell a little story about an anonymous friend:</p>\n<p>&nbsp; I have a friend that worked at Microsoft.&nbsp; He said the culture there was not open to new ideas and that management was not open to hearing criticism.&nbsp; He interviewed with various companies and chose Amazon.&nbsp; According to this friend, Amazon actually does a good job of fulfilling values like inviting honest feedback and creating an environment conductive to innovation.&nbsp; He showed me the written values for each.&nbsp; I didn't think much of this at first because most of them are boring and read like empty marketing copy.&nbsp; <a href=\" http://www.amazon.com/Values-Careers-Homepage/b/ref=amb_link_356017942_3?ie=UTF8&amp;node=239365011&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_s=left-2&amp;pf_rd_r=1N9CTZEW82NJ6NJBNR1Y&amp;pf_rd_t=10301&amp;pf_rd_p=1380702402&amp;pf_rd_i=overview\">Amazon.com has the most incredible written values page</a> I've ever seen - it does more than sit there like a static piece of text.&nbsp; <em>It gives you permission</em>.&nbsp; Instead of saying something fluffy like: \"We value integrity and honesty and our managers are happy to hear your criticisms.\" it first creates expectations for management: \" Leaders are sincerely open-minded, genuinely listen, and are willing to examine their strongest convictions with humility.\" and then gives employees permission to give honest feedback to decision-makers: \"Leaders (all employees are referred to as \"leaders\") are obligated to respectfully challenge decisions when they disagree, even when doing so is uncomfortable or exhausting.&nbsp; Leaders have conviction and are tenacious. They do not compromise for the sake of social cohesion.\"&nbsp; The Amazon values page gives their employees permission to innovate as well: \"As we do new things, we accept that we may be misunderstood for long periods of time.\"&nbsp; If you look at <a href=\"http://www.microsoft.com/about/corporatecitizenship/en-us/\">Microsoft's written values</a>, there's no bite to them.&nbsp; What do I mean by bite?</p>\n<p>&nbsp; Imagine you're an employee at Amazon.&nbsp; Your boss does something stupid.&nbsp; The cultural expectation is that you're not supposed to say anything - offending the boss is bad news, right?&nbsp; So you're inhibited.&nbsp; But the thing they've done is stupid.&nbsp; So you remember back to the values page and go bring it up on your computer.&nbsp; It says explicitly that your boss is expected to be humble and that you are expected to sacrifice social cohesion in this case and disagree.&nbsp; Now, if your boss gets irritated with you for disagreeing, you can point back to that page and say \"Look, it's in writing, I have permission to tell you.\"</p>\n<p>&nbsp; Similarly, there is, what I consider to be, a very unfortunate social skills requirement that more or less says if you don't have something nice to say, don't say anything at all.&nbsp; Many people feel obligated to keep constructive criticism to themselves.&nbsp; A lot of us are intentionally trained to be non-confrontational.&nbsp; If people are going to overcome this lifetime of training to squelch constructive criticism, they need an excuse to ignore that social training.&nbsp; Not just any excuse.&nbsp; It needs to be worded to require them to do that and it needs to be worded to require them to do it explicitly despite the consequences.</p>\n<p>&nbsp;</p>\n<p><strong id=\"__Principle_Three___If_we_want_innovation__we_have_to_make_innovators_feel_welcome_\"><em>&nbsp; Principle Three:&nbsp; If we want innovation, we have to make innovators feel welcome.<br></em></strong></p>\n<p>&nbsp; That brings me to another point.&nbsp; If you want innovation, you can't deter the sort of person who will bring it to you: the \"people who will be misunderstood for long periods of time\", as Amazon puts it.&nbsp; If you give specific constructive criticism to a misunderstood person, this will help them figure out how to communicate - how else will they navigate the jungle of perception and context differences between themselves and others?&nbsp; If you simply vote them down, silently and anonymously, they have no opportunity to learn how to communicate with you and what's worse is that they'll be censored after three votes.&nbsp; This ability for three people to censor somebody with no accountability, and without even needing a reason, encourages posters to keep quiet instead of taking the sort of risk an innovator needs to take in presenting new ideas, and it robs misunderstood innovators of those opportunities for important feedback - which is required for them to explain their ideas.&nbsp; Here is an example of how feedback can transform an innovator's description of a new idea from something that seems incomprehensible into something that shows obvious value:</p>\n<p>&nbsp; On the \"Let's start an important start-up\" thread, KrisC posts a description of an innovative phone app idea.&nbsp; I read it and I cannot even figure out what it's about.&nbsp; My instinct is to write it off as \"gibberish\" and go do something else.&nbsp; Instead, I provide feedback, constructive criticism and questions.&nbsp; It turns out that the idea KrisC has is actually pretty awesome.&nbsp; All it took was for KrisC to be listened to and to get some feedback, and the next description that KrisC wrote made pretty good sense.&nbsp; It's hard to explain new ideas but with detailed feedback, innovation may start to show through.&nbsp; <a href=\"/lw/e26/who_wants_to_start_an_important_startup/780b\">Link to KrisC and I discussing the phone app idea.</a></p>\n<p>&nbsp;</p>\n<h2 id=\"Proposed_Acculturation_Methods_\">Proposed Acculturation Methods:</h2>\n<p>&nbsp;</p>\n<p>&nbsp;&nbsp; <em><strong>Send them to Center for Modern Rationality</strong></em></p>\n<p>&nbsp;&nbsp; Now that I have discovered the post on the <a href=\"/lw/bpi/center_for_modern_rationality_currently_hiring/\">Center for Modern Rationality</a> and have see that they're targeting the general population and beginners with <a href=\"/lw/9lx/help_name_suggestions_needed_for_rationalityinst/\">material for local meetups, high schools and colleges</a> and they're planning some web apps to help with rationality training, I see that referring people over to them might be a great suggestion.&nbsp; Saturn <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7bls\">suggested sending them to appliedrationality.org</a> before I found this but I'm not sure if that would be adequate since I don't see a lot of stuff for people to do on their website.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Highlight the culture.</strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; A database of cultural glossary terms can be created and used to highlight those terms on the forum.&nbsp; The terms are already on the page, so what good would this do?&nbsp; Well, first they can be automatically linked to the relevant sequence or wiki page.&nbsp; If old users do not have to look for the link, this speeds up the process of mentioning them to new users quite a lot.&nbsp; Secondly, it would make the core cultural items stand out from all of the other information, which will likely cause new users to prioritize it.&nbsp; Thirdly, there will be a visual effect on the page.&nbsp; You'll be able to <em>see</em> that this place has it's own vocabulary, it's own personality, it's own memes.&nbsp; It's one thing to say \"LessWrong has been influenced by the sequences\" to a new user who hasn't seen all those references on all of those pages, and even if they do see them, won't know where they're from, versus making it immediately obvious how by giving them a visual that illustrates the point.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Provide new users with real feedback instead of mysterious anonymous down votes:<br></strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; We have karma vote buttons, but this is not providing useful feedback for new users.&nbsp; Without a specific reason, I have no way to tell if I'm being down voted by trolls and I may see ten different possible reasons for being voted down and not know which one to choose.&nbsp; This annoyance selects for thick-skinned individuals like trolls and fails to avoid the \"imbalance in the proportion of thick-skinned individuals to normal individuals\" side-effect.</p>\n<p>&nbsp;&nbsp;&nbsp; If good new users are to be preserved, and the normal people to troll ratio is to be maintained, we need to add a \"vote to ban\" button that's used only for blatant misbehavior, and if an anonymous feedback system is to be used for voting down, it needs to prompt you for more detailed feedback - either allowing you to select from categories, or give at least one or two words as an explanation.&nbsp; Also, the comments need to should show both up votes and down votes.&nbsp; If you don't know when you've said something controversial and are being encouraged to view everything you say as black-and-white good-or-bad, this promotes conformity.</p>\n<p>&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; <strong><em>A test won't deter ignorant cheaters, but they can force them to educate themselves.<br></em></strong></p>\n<p>&nbsp;&nbsp;&nbsp; Questions can be worded in such a way that they serve as a crash course in reasoning in the event that someone posts a cheat sheet or registrants look up all the answers on the internet.&nbsp; Assuming that the answer options are randomly ordered so that you have to actually read them then the test should, at the very least, familiarize them with the various biases and logical fallacies, etc.&nbsp; Examples:</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; Person A in a debate explains a belief but it's not well-supported.&nbsp; Their opponent, person B, says they're an idiot.&nbsp; What is this an example of?</p>\n<p>&nbsp;&nbsp;&nbsp; A. Attacking the person, a great way to really nail a debate.</p>\n<p>&nbsp;&nbsp;&nbsp; B. Attacking the person, a great way to totally fail in debate because you're not even attacking their ideas.</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; You are with person X and person Y.&nbsp; Person Y says they have been considering some interesting new evidence of what might be an alien space craft and aren't sure what to think yet.&nbsp; You both see person Y's evidence, and neither of you has seen it before.&nbsp; Person X says to you that they don't believe in UFOs and don't care about person Y's silly evidence.&nbsp; Who is the better skeptic?</p>\n<p>&nbsp;&nbsp;&nbsp; Person X because they have the correct belief about UFOs.</p>\n<p>&nbsp;&nbsp;&nbsp; Person Y because they are actually thinking about it, avoiding undiscriminating skepticism.</p>\n<p>&nbsp;&nbsp;&nbsp; --------------</p>\n<p>&nbsp;&nbsp;&nbsp; Note:&nbsp; These questions are intentionally knowledge-based.&nbsp; If the purpose is to avoid requiring an IQ test, and to create an obstacle that requires you to learn about reasoning before posting in \"hard\", that's the only way that these can be done.</p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Encouraging users to lurk more.&nbsp; </strong></em></p>\n<p>&nbsp;&nbsp; Vaniver contributed this: Another way to cut down on new-new interaction is to limit the number of comments someone can make in a time period- if people can only comment once an day until their karma hits 20, and then once an hour until their karma hits 100, and then they're unrestricted, that will explicitly encourage lurking / paying close attention to karma among new members. (It would be gameable, unless you did something like prevent new members from upvoting the comments of other new members, or algorithmically keeping an eye out for people gaming the system and then cracking down on them.) [edit] The delay being a near-continuous function of the karma- say, 24 hours*exp(-b karma)- might make the incentives better, and not require partitioning users explicitly. No idea if that would be more or less effort on the coding side.</p>\n<p>&nbsp;&nbsp;&nbsp; Cons:&nbsp; This would deter some new users from becoming active users by causing them to lose steam on their initial motivation to join.&nbsp; It might be something that would deter the right people.&nbsp; It might also filter users, selecting for the most persistent ones, or for some other trait that might change the personality of the user base.&nbsp; This would exacerbate the filtering effect that the current karma system is exerting, which, I theorize, is causing there to be a disproportionate number of thick-skinned individuals like trolls and debate-oriented newbies.&nbsp; <a href=\"/lw/ecg/meta_what_do_you_think_of_a_karma_vote_checklist/7bpm\">My theory about how the karma system is having a bad influence</a></p>\n<p>&nbsp;</p>\n<p><em><strong>&nbsp;&nbsp;&nbsp; Give older users more voting power.&nbsp; </strong></em></p>\n<p>&nbsp;&nbsp;&nbsp; Luke suggested \"Maybe <a rel=\"nofollow\" href=\"http://gkosev.blogspot.com.au/2012/08/fixing-hacker-news-mathematical-approach.html\">this mathematical approach</a> would work. (h/t <a href=\"/user/matt/\">matt</a>)\" on the \"Call for Agreement\" thread.&nbsp;</p>\n<p>&nbsp;&nbsp;&nbsp; I question, though, whether changing the karma numbers on the comments and posts in <em>any</em> way would have a significant influence on behavior or a significant influence on who joins and stays. Firstly, votes may reward and punish but they don't instruct very well - unless people are very similar, they won't have accurate assumptions about what they did wrong. I also question whether having a significant influence on behavior would prevent a new majority from forming because these are different problems. The current users who are the right type may be both motivated and able to change, but future users of the wrong type may not care or may be incapable of changing. They may set a new precedent where there are a lot of people doing unpopular things so new people are more likely to ignore popularity. The technique uses math and the author claims that \"the tweaks work\" but I didn't see anything specific about what the author means by that nor evidence that this is true. So this <em>looks</em> good because it is mathematical, but it's less direct than other options so I'm questioning whether it would work.</p>\n<p>&nbsp; <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/7bvi\">Vladimir_Nesov posted a variation here.</a></p>\n<p>&nbsp;</p>\n<p><strong id=\"__Make_a_different_discussion_area_for_users_with_over_1000_karma_\"><em>&nbsp; Make a different discussion area for users with over 1000 karma.</em></strong></p>\n<p>&nbsp; <a href=\"/lw/ebv/dealing_with_trolling_and_the_signal_to_noise/7b0l\">Posted by Konkvistador here.</a></p>\n<p>&nbsp;</p>\n<p><strong><em>&nbsp; Make a </em></strong><strong><em>Multi Generation Culture.</em></strong></p>\n<p>&nbsp; Limit the number of new users that join the forum to a certain percentage per month, sending the rest to a new forum.&nbsp; If that forum grows too fast, create additional forums.&nbsp; This would be like having different generations.&nbsp; New people would be able to join an older generation if there is space.&nbsp; Nobody would be labeled a \"beginner\".</p>\n<p>&nbsp;</p>\n<p><strong id=\"__Temporarily_turn_off_registration_or_limit_the_number_of_users_that_can_join_\"><em>&nbsp; Temporarily turn off registration or limit the number of users that can join.</em></strong></p>\n<p>&nbsp; (See the cliff notes version for more.)</p>\n<p>&nbsp;</p>\n<h2 id=\"Should_easy_discussion_participants_be_able_to_post_articles_\">Should easy discussion participants be able to post articles?</h2>\n<p>&nbsp; I think the answer to this is yes, because no filtering mechanism is perfect and the last thing you want to do is filter out people with a different and important point of view.&nbsp; Unless the site is currently having issues with trolls posting new articles, or with the quality of the articles going down, leaving that freedom intact is best.&nbsp; I definitely think, though, that written guidelines for posting an article need to be put in \"in your face\" expected places.&nbsp; If a lot of new users join at once, well-meaning but confused people will be posting the wrong sorts of things there - making sure they've got the guidelines right there is all that's probably needed to deter them.</p>\n<p>&nbsp;</p>\n<h2 id=\"Testing___measuring_results_\">Testing / measuring results:</h2>\n<p>&nbsp; How do we tell if this worked?&nbsp; Tracking something subjective like whether we're feeling challenged or inundated with newbies is not going to be a straightforward matter of looking at numbers.&nbsp; (Methods to assist willing people learn faster deserves it's own post.)&nbsp; Just because it's subjective doesn't mean tracking is impossible or that working out whether it's made a difference cannot be done.&nbsp; I suspect that a big difference will be noticed in the hard discussion area right away.&nbsp; Here are some figures that are relevant and can be tracked, that may give us insight and ways to check our perceptions:</p>\n<p>&nbsp; 1.&nbsp; How many people are joining the hard forum versus the easy forum?&nbsp; If we've got a percentage, we know how *much* we've filtered, though we won't know exactly *who* we've filtered.</p>\n<p>&nbsp; 2.&nbsp; Survey the users to ask whether the conversations they're reading have increased in quality.</p>\n<p>&nbsp; 3.&nbsp; Survey the users to ask whether they've been learning more since the change.</p>\n<p>&nbsp; 4.&nbsp; See which area has the largest ratio of users with lots of vote downs.&nbsp;</p>\n<p>&nbsp; (This could be tricky because people who frequently state disagreements might be doing a great service to the group, but might be unpopular because of it, and people who are innovative may be getting voted down due to being misunderstood.&nbsp; One would think, though, that people who are unpopular due to disagreeing, or being innovative, assuming they're serious about good reasoning, would end up in the hard forum.)&nbsp;</p>\n<p>&nbsp;</p>\n<h2 id=\"Request_for_honest_feedback_\">Request for honest feedback:<br></h2>\n<p>&nbsp; Your honest criticisms of this idea and your suggestions will be appreciated, and I will update this idea or write a new one to reflect any good criticisms or ideas you contribute.</p>\n<p>&nbsp;</p>\n<h2 id=\"This_is_in_the_public_domain_\">This is in the public domain:<br></h2>\n<p>&nbsp; This idea is hereby released into the public domain, with acknowledgement from Luke Muehlhauser that those were my terms prior to posting.&nbsp; My intent is to share this idea to make it impossible to patent and my hope is that it will be free for the whole world to use.</p>\n<p><span>&nbsp; Preventing discussion from being watered down by an \"endless September\" user influx.</span> by <span>Epiphany</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/3.0/deed.en_US\">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Cliff Notes Version:", "anchor": "Cliff_Notes_Version_", "level": 1}, {"title": "The most difficult challenge and my solution:", "anchor": "The_most_difficult_challenge_and_my_solution_", "level": 1}, {"title": "Endless September protection should be designed to avoid causing these side-effects:", "anchor": "Endless_September_protection_should_be_designed_to_avoid_causing_these_side_effects_", "level": 1}, {"title": "\u00a0 Creating an imbalance in the proportion of thick-skinned individuals to normal individuals.", "anchor": "__Creating_an_imbalance_in_the_proportion_of_thick_skinned_individuals_to_normal_individuals_", "level": 2}, {"title": "People who qualify under the \"letter\" of the standards do not meet the spirit of the standards.", "anchor": "People_who_qualify_under_the__letter__of_the_standards_do_not_meet_the_spirit_of_the_standards_", "level": 2}, {"title": "The right people join, but acculturate slowly or for some reason do not acculturate.\u00a0 ", "anchor": "The_right_people_join__but_acculturate_slowly_or_for_some_reason_do_not_acculturate___", "level": 2}, {"title": "Proposed Filtering Mechanisms:", "anchor": "Proposed_Filtering_Mechanisms_", "level": 1}, {"title": "\u00a0 Principle One:\u00a0 A small number of questions can deter a lot of activity.", "anchor": "__Principle_One___A_small_number_of_questions_can_deter_a_lot_of_activity_", "level": 2}, {"title": "\u00a0 Principle Two:\u00a0 A rigorous environment will deter those who are not serious about doing it right.", "anchor": "__Principle_Two___A_rigorous_environment_will_deter_those_who_are_not_serious_about_doing_it_right_", "level": 2}, {"title": "\u00a0 Principle Three:\u00a0 If we want innovation, we have to make innovators feel welcome.", "anchor": "__Principle_Three___If_we_want_innovation__we_have_to_make_innovators_feel_welcome_", "level": 2}, {"title": "Proposed Acculturation Methods:", "anchor": "Proposed_Acculturation_Methods_", "level": 1}, {"title": "\u00a0 Make a different discussion area for users with over 1000 karma.", "anchor": "__Make_a_different_discussion_area_for_users_with_over_1000_karma_", "level": 2}, {"title": "\u00a0 Temporarily turn off registration or limit the number of users that can join.", "anchor": "__Temporarily_turn_off_registration_or_limit_the_number_of_users_that_can_join_", "level": 2}, {"title": "Should easy discussion participants be able to post articles?", "anchor": "Should_easy_discussion_participants_be_able_to_post_articles_", "level": 1}, {"title": "Testing / measuring results:", "anchor": "Testing___measuring_results_", "level": 1}, {"title": "Request for honest feedback:", "anchor": "Request_for_honest_feedback_", "level": 1}, {"title": "This is in the public domain:", "anchor": "This_is_in_the_public_domain_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "102 comments"}], "headingsCount": 19}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 102, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["GEtLkHyPhG8m4aepb", "48pAgPMKd63LA4QCZ", "Jko7pt7MwwTBrfG3A", "pBmmvSZ5WijjKh59x", "YzzcrM92toD9dudau"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T04:09:11.386Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Say It Loud", "slug": "seq-rerun-say-it-loud", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:26.076Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rN8uHmsdrpFKi5LKQ/seq-rerun-say-it-loud", "pageUrlRelative": "/posts/rN8uHmsdrpFKi5LKQ/seq-rerun-say-it-loud", "linkUrl": "https://www.lesswrong.com/posts/rN8uHmsdrpFKi5LKQ/seq-rerun-say-it-loud", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Say%20It%20Loud&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Say%20It%20Loud%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrN8uHmsdrpFKi5LKQ%2Fseq-rerun-say-it-loud%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Say%20It%20Loud%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrN8uHmsdrpFKi5LKQ%2Fseq-rerun-say-it-loud", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrN8uHmsdrpFKi5LKQ%2Fseq-rerun-say-it-loud", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 170, "htmlBody": "<p>Today's post, <a href=\"/lw/u3/say_it_loud/\">Say It Loud</a> was originally published on 19 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Say_It_Loud\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If you're uncertain about something, communicate that uncertainty. Do so as clearly as you can. You don't help yourself by hiding how confused you are.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ec9/seq_rerun_the_sheer_folly_of_callow_youth/\">The Sheer Folly of Callow Youth</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rN8uHmsdrpFKi5LKQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.774663732641888e-07, "legacy": true, "legacyId": "18594", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hAfmMTiaSjEY8PxXC", "WcB2Z5qK4ao5mdkLS", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T04:48:08.553Z", "modifiedAt": null, "url": null, "title": "SI is looking to hire someone to finish a Decision Theory FAQ", "slug": "si-is-looking-to-hire-someone-to-finish-a-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:30.724Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "malo", "createdAt": "2011-12-28T20:01:23.182Z", "isAdmin": false, "displayName": "Malo"}, "userId": "DA863LaqrSGNFs5w5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y7YDKpdpbbirgCA48/si-is-looking-to-hire-someone-to-finish-a-decision-theory", "pageUrlRelative": "/posts/Y7YDKpdpbbirgCA48/si-is-looking-to-hire-someone-to-finish-a-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/Y7YDKpdpbbirgCA48/si-is-looking-to-hire-someone-to-finish-a-decision-theory", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SI%20is%20looking%20to%20hire%20someone%20to%20finish%20a%20Decision%20Theory%20FAQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASI%20is%20looking%20to%20hire%20someone%20to%20finish%20a%20Decision%20Theory%20FAQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7YDKpdpbbirgCA48%2Fsi-is-looking-to-hire-someone-to-finish-a-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SI%20is%20looking%20to%20hire%20someone%20to%20finish%20a%20Decision%20Theory%20FAQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7YDKpdpbbirgCA48%2Fsi-is-looking-to-hire-someone-to-finish-a-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7YDKpdpbbirgCA48%2Fsi-is-looking-to-hire-someone-to-finish-a-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 212, "htmlBody": "<p>The Singularity Institute is looking to hire someone familiar with decision theory to help finish Luke's&nbsp;<a href=\"http://lukeprog.com/DecisionTheory.html\" target=\"_blank\">Decision Theory FAQ</a>&nbsp;(with the possibility of working on other projects afterwards). The first task of this individual will be to expand on section 11 by explaining each of the Newcomblike problems and showing how EDT, CDT, CDT+, and TDT perform on each of them.&nbsp;</p>\n<p>Pay will be hourly and starts at $15/hr,&nbsp;but will increase if you produce a good product. You must be able to commit an average of 20+hrs/wk.</p>\n<p>&nbsp;</p>\n<p>Those applying for the position should be <em>generally</em> familliar with most of the following:</p>\n<ul>\n<li>Axiomatic decision theory (<a href=\"http://www.amazon.com/Economic-Behavior-Commemorative-Princeton-Editions/dp/0691130612/\">VNM</a>,&nbsp;<a href=\"http://www.amazon.com/The-Foundations-Statistics-Leonard-Savage/dp/0486623491/\">Savage</a>)</li>\n<li><a href=\"http://www.amazon.com/The-Logic-Decision-Richard-Jeffrey/dp/0226395820/\">EDT</a>,&nbsp;<a href=\"http://www.amazon.com/Foundations-Decision-Cambridge-Probability-Induction/dp/0521063566/\">CDT</a>,&nbsp;<a href=\"http://www-ihpst.univ-paris1.fr/fichiers/programmes/20/Spohn-One-Boxing3.pdf\">CDT + causal graphs</a>&nbsp;(CDT+), and&nbsp;<a href=\"http://intelligence.org/files/TDT.pdf\">TDT</a></li>\n<li>Newcomb's problem, medical Newcomb's problem, Parfit's hitchhiker, etc.</li>\n</ul>\n<div><br /></div>\n<div>Working remotely for SI can be pretty great, here are some of the perks:</div>\n<div>\n<ul>\n<li>Work flexible hours: Complete your work in few large chunks or many small ones&mdash;at 03:00 or 18:00&mdash;it's up to you.</li>\n<li>Work from wherever you please: your home (maybe even in bed), your local coffee shop, a row boat in the middle of a lake, whatever.</li>\n<li>Age and credentials are irrelevant; only product matters.</li>\n<li>Make money while contributing to the Singularity Institute.</li>\n</ul>\n</div>\n<p>&nbsp;</p>\n<p>If you are interested in the position, <strong><a href=\"http://tinyurl.com/si-decision-theory-application\">apply here</a></strong>!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y7YDKpdpbbirgCA48", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 9.774860268303943e-07, "legacy": true, "legacyId": "18595", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T10:25:41.694Z", "modifiedAt": null, "url": null, "title": "How to tell apart science from pseudo-science in a field you don't know ?", "slug": "how-to-tell-apart-science-from-pseudo-science-in-a-field-you", "viewCount": null, "lastCommentedAt": "2019-03-02T02:25:11.922Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jAKQn87Duq9gwcZdT/how-to-tell-apart-science-from-pseudo-science-in-a-field-you", "pageUrlRelative": "/posts/jAKQn87Duq9gwcZdT/how-to-tell-apart-science-from-pseudo-science-in-a-field-you", "linkUrl": "https://www.lesswrong.com/posts/jAKQn87Duq9gwcZdT/how-to-tell-apart-science-from-pseudo-science-in-a-field-you", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20tell%20apart%20science%20from%20pseudo-science%20in%20a%20field%20you%20don't%20know%20%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20tell%20apart%20science%20from%20pseudo-science%20in%20a%20field%20you%20don't%20know%20%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjAKQn87Duq9gwcZdT%2Fhow-to-tell-apart-science-from-pseudo-science-in-a-field-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20tell%20apart%20science%20from%20pseudo-science%20in%20a%20field%20you%20don't%20know%20%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjAKQn87Duq9gwcZdT%2Fhow-to-tell-apart-science-from-pseudo-science-in-a-field-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjAKQn87Duq9gwcZdT%2Fhow-to-tell-apart-science-from-pseudo-science-in-a-field-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 306, "htmlBody": "<p>First, a short personal note to make you understand why this is important to me. To make a long story short, the son of a friend has some atypical form of autism and language troubles. And that kid matters a lot to me, so I want to become stronger in helping him, to be able to better interact with him and help him overcome his troubles.</p>\n<p>But I don't know much about psychology. I'm a computer scientist, with a general background of maths and physics. I'm kind of a nerd, social skills aren't my strength. I did read some of the basic books advised on Less Wrong, like Cialdini, Wright or Wiseman, but those just give me a very small background on which to build.</p>\n<p>And psychology in general, autism/language troubles in particular, are fields in which there is a lot of pseudo-science. I'm very sceptical of Freud and psychoanalysis, for example, which I consider (but maybe I am wrong?) to be more like alchemy than like chemistry. There are a lot of mysticism and sect-like gurus related to autism, too.</p>\n<p>So I'm bit unsure on how from my position of having a general scientific and rationality background I can dive into a completely unrelated field. Research papers are probably above my current level in psychology, so I think books (textbooks or popular science) are the way to go. But how to find which books on the hundreds that were written on the topic I should buy and read? Books that are evidence-based science, not pseudo-science, I mean. What is a general method to select which books to start in a field you don't really know? I would welcome any advise from the community.</p>\n<p><em>Disclaimer: this is a personal \"call for help\", but since I think the answers/advices may matter outside my own personal case, I hope you don't mind.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 1, "uRcuHKpKA7xNnZQ2F": 1, "xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jAKQn87Duq9gwcZdT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 34, "extendedScore": null, "score": 7.1e-05, "legacy": true, "legacyId": "18596", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 71, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T17:21:30.282Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge (MA) third-Sundays meetup", "slug": "meetup-cambridge-ma-third-sundays-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chronophasiac", "createdAt": "2009-04-03T11:25:57.322Z", "isAdmin": false, "displayName": "chronophasiac"}, "userId": "wu2Hs7x6pbfJbMumC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vWkmNwu8KtpLNc5bq/meetup-cambridge-ma-third-sundays-meetup-0", "pageUrlRelative": "/posts/vWkmNwu8KtpLNc5bq/meetup-cambridge-ma-third-sundays-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/vWkmNwu8KtpLNc5bq/meetup-cambridge-ma-third-sundays-meetup-0", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWkmNwu8KtpLNc5bq%2Fmeetup-cambridge-ma-third-sundays-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWkmNwu8KtpLNc5bq%2Fmeetup-cambridge-ma-third-sundays-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvWkmNwu8KtpLNc5bq%2Fmeetup-cambridge-ma-third-sundays-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/de'>Cambridge (MA) third-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 September 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/de'>Cambridge (MA) third-Sundays meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vWkmNwu8KtpLNc5bq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 9.778662722313773e-07, "legacy": true, "legacyId": "18597", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup\">Discussion article for the meetup : <a href=\"/meetups/de\">Cambridge (MA) third-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 September 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup1\">Discussion article for the meetup : <a href=\"/meetups/de\">Cambridge (MA) third-Sundays meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T17:23:35.050Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge (MA) first-Sundays meetup", "slug": "meetup-cambridge-ma-first-sundays-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chronophasiac", "createdAt": "2009-04-03T11:25:57.322Z", "isAdmin": false, "displayName": "chronophasiac"}, "userId": "wu2Hs7x6pbfJbMumC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3v6becgAnDYk7ZW64/meetup-cambridge-ma-first-sundays-meetup", "pageUrlRelative": "/posts/3v6becgAnDYk7ZW64/meetup-cambridge-ma-first-sundays-meetup", "linkUrl": "https://www.lesswrong.com/posts/3v6becgAnDYk7ZW64/meetup-cambridge-ma-first-sundays-meetup", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20(MA)%20first-Sundays%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20(MA)%20first-Sundays%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v6becgAnDYk7ZW64%2Fmeetup-cambridge-ma-first-sundays-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20(MA)%20first-Sundays%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v6becgAnDYk7ZW64%2Fmeetup-cambridge-ma-first-sundays-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3v6becgAnDYk7ZW64%2Fmeetup-cambridge-ma-first-sundays-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/df'>Cambridge (MA) first-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 October 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/df'>Cambridge (MA) first-Sundays meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3v6becgAnDYk7ZW64", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 9.778673221485385e-07, "legacy": true, "legacyId": "18598", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__first_Sundays_meetup\">Discussion article for the meetup : <a href=\"/meetups/df\">Cambridge (MA) first-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 October 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__first_Sundays_meetup1\">Discussion article for the meetup : <a href=\"/meetups/df\">Cambridge (MA) first-Sundays meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge (MA) first-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__first_Sundays_meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge (MA) first-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__first_Sundays_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T17:25:05.727Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge (MA) third-Sundays Meetup", "slug": "meetup-cambridge-ma-third-sundays-meetup-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chronophasiac", "createdAt": "2009-04-03T11:25:57.322Z", "isAdmin": false, "displayName": "chronophasiac"}, "userId": "wu2Hs7x6pbfJbMumC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZsgHf97rnLcKoTgeW/meetup-cambridge-ma-third-sundays-meetup-1", "pageUrlRelative": "/posts/ZsgHf97rnLcKoTgeW/meetup-cambridge-ma-third-sundays-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/ZsgHf97rnLcKoTgeW/meetup-cambridge-ma-third-sundays-meetup-1", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsgHf97rnLcKoTgeW%2Fmeetup-cambridge-ma-third-sundays-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsgHf97rnLcKoTgeW%2Fmeetup-cambridge-ma-third-sundays-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsgHf97rnLcKoTgeW%2Fmeetup-cambridge-ma-third-sundays-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dg'>Cambridge (MA) third-Sundays Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 October 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dg'>Cambridge (MA) third-Sundays Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZsgHf97rnLcKoTgeW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 9.778680851965218e-07, "legacy": true, "legacyId": "18599", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_Meetup\">Discussion article for the meetup : <a href=\"/meetups/dg\">Cambridge (MA) third-Sundays Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 October 2012 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups on the first and third Sunday of every month, 2pm at the MIT Landau Building [25 Ames St, Bldg 66], room 148. Room number subject to change based on availability, signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/dg\">Cambridge (MA) third-Sundays Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays Meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays Meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-02T23:49:50.925Z", "modifiedAt": null, "url": null, "title": "Dragon Ball's Hyperbolic Time Chamber", "slug": "dragon-ball-s-hyperbolic-time-chamber", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:55.217Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PvdvsZQwDr2PD3wFW/dragon-ball-s-hyperbolic-time-chamber", "pageUrlRelative": "/posts/PvdvsZQwDr2PD3wFW/dragon-ball-s-hyperbolic-time-chamber", "linkUrl": "https://www.lesswrong.com/posts/PvdvsZQwDr2PD3wFW/dragon-ball-s-hyperbolic-time-chamber", "postedAtFormatted": "Sunday, September 2nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dragon%20Ball's%20Hyperbolic%20Time%20Chamber&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADragon%20Ball's%20Hyperbolic%20Time%20Chamber%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPvdvsZQwDr2PD3wFW%2Fdragon-ball-s-hyperbolic-time-chamber%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dragon%20Ball's%20Hyperbolic%20Time%20Chamber%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPvdvsZQwDr2PD3wFW%2Fdragon-ball-s-hyperbolic-time-chamber", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPvdvsZQwDr2PD3wFW%2Fdragon-ball-s-hyperbolic-time-chamber", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<blockquote>\n<p>A time dilation tool from an anime is discussed for its practical use on Earth; there seem surprisingly few uses and none that will change the world, due to the severe penalties humans would incur while using it, and basic constraints like Amdahl's law limit the scientific uses. A comparison with the position of an Artificial Intelligence such as an emulated human brain seems fair, except most of the time dilation disadvantages do not apply or can be ameliorated and hence any speedups could be quite effectively exploited. I suggest that skeptics of the idea that speedups give advantages are implicitly working off the crippled time dilation tool and not making allowance for the <em>dis</em>analogies.</p>\n</blockquote>\n<p>Master version on <a href=\"http://www.gwern.net/Hyperbolic%20Time%20Chamber\">gwern.net</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 1, "jQytxyauJ7kPhhGj3": 1, "5f5c37ee1b5cdee568cfb2ac": 3, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PvdvsZQwDr2PD3wFW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 50, "extendedScore": null, "score": 0.0005384403465089948, "legacy": true, "legacyId": "18601", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T00:45:59.996Z", "modifiedAt": null, "url": null, "title": "Less Wrong articles categorized by reading difficulty", "slug": "less-wrong-articles-categorized-by-reading-difficulty", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.249Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K73hrxSd6TX3At6tX/less-wrong-articles-categorized-by-reading-difficulty", "pageUrlRelative": "/posts/K73hrxSd6TX3At6tX/less-wrong-articles-categorized-by-reading-difficulty", "linkUrl": "https://www.lesswrong.com/posts/K73hrxSd6TX3At6tX/less-wrong-articles-categorized-by-reading-difficulty", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20articles%20categorized%20by%20reading%20difficulty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20articles%20categorized%20by%20reading%20difficulty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK73hrxSd6TX3At6tX%2Fless-wrong-articles-categorized-by-reading-difficulty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20articles%20categorized%20by%20reading%20difficulty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK73hrxSd6TX3At6tX%2Fless-wrong-articles-categorized-by-reading-difficulty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK73hrxSd6TX3At6tX%2Fless-wrong-articles-categorized-by-reading-difficulty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>One thing that could <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7brq\">help new users dive into Less Wrong</a> would be to make some reading recommendations based on reading difficulty. (I'm including some things not hosted on LessWrong.com when they're very LessWrong-ish and written by leading LessWrong authors.) For example:</p>\n<p>&nbsp;</p>\n<p><strong>For everyone</strong></p>\n<p>&nbsp;</p>\n<ul>\n<li>Yudkowsky,&nbsp;<a style=\"font-style: italic;\" href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7brq\">Harry Potter and the Methods of Rationality</a></li>\n<li>Yudkowsky, <a href=\"http://yudkowsky.net/rational/virtues\">Twelve Virtues of Rationality</a></li>\n<li>Yvain, <a href=\"/lw/e95/the_worst_argument_in_the_world/\">The Worst Argument in the World</a></li>\n<li>Yudkowsky, <a href=\"/lw/on/reductionism/\">Reductionism</a></li>\n<li>Lukeprog, <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a></li>\n</ul>\n<div><br /></div>\n<div><strong>For those with some math and statistics</strong></div>\n<div>\n<ul>\n<li>Yudkowsky, <a href=\"http://yudkowsky.net/rational/technical\">Technical Explanation of Technical Explanation</a></li>\n<li>Yudkowsky, <a href=\"/lw/qr/timeless_causality/\">Timeless Causality</a></li>\n<li>Yudkowsky, <a href=\"/lw/q1/bells_theorem_no_epr_reality/\">Bell's Theorem</a></li>\n</ul>\n</div>\n<div><br /></div>\n<div><strong>For mathgods</strong></div>\n<div>\n<ul>\n<li>Nisan, <a href=\"/lw/9o7/formulas_of_arithmetic_that_behave_like_decision/\">Formulas of arithmetic that behave like decision agents</a></li>\n<li>Benja, <a href=\"/lw/eaa/a_model_of_udt_with_a_concrete_prior_over_logical/\">A model of UDT with a concrete prior over logical statements</a></li>\n<li>cousin_it,&nbsp;<a href=\"/lw/dba/bounded_versions_of_g%C3%B6dels_and_l%C3%B6bs_theorems/\">Bounded versions of G&ouml;del's and L&ouml;b's theorems</a></li>\n</ul>\n</div>\n<div><br /></div>\n<div>Now, I ask: What are some of your favorite articles in each of these categories?</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GQyPQcdEQF4zXhJBq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K73hrxSd6TX3At6tX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 9.780907455938887e-07, "legacy": true, "legacyId": "18602", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yCWPkLi8wJvewPbEp", "tPqQdLCuxanjhoaNs", "RWo4LwFzpHNQCTcYt", "KipiHsTA3pw4joQkG", "AnHJX42C6r6deohTG", "yX9pMZik7r38da7Fc", "PgKADaJE4ERjtMtP9", "z7SuGwxTBnQm8uFq4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T03:10:18.308Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] How Many LHC Failures Is Too Many?", "slug": "seq-rerun-how-many-lhc-failures-is-too-many", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.334Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eWZEBte5THEbE2Lte/seq-rerun-how-many-lhc-failures-is-too-many", "pageUrlRelative": "/posts/eWZEBte5THEbE2Lte/seq-rerun-how-many-lhc-failures-is-too-many", "linkUrl": "https://www.lesswrong.com/posts/eWZEBte5THEbE2Lte/seq-rerun-how-many-lhc-failures-is-too-many", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20How%20Many%20LHC%20Failures%20Is%20Too%20Many%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20How%20Many%20LHC%20Failures%20Is%20Too%20Many%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeWZEBte5THEbE2Lte%2Fseq-rerun-how-many-lhc-failures-is-too-many%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20How%20Many%20LHC%20Failures%20Is%20Too%20Many%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeWZEBte5THEbE2Lte%2Fseq-rerun-how-many-lhc-failures-is-too-many", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeWZEBte5THEbE2Lte%2Fseq-rerun-how-many-lhc-failures-is-too-many", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>Today's post, <a href=\"/lw/u5/how_many_lhc_failures_is_too_many/\">How Many LHC Failures Is Too Many?</a> was originally published on 20 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#How_Many_LHC_Failures_Is_Too_Many.3F\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If the LHC, or some sort of similar project, continually seemed to fail right before it did something we thought might destroy the world, this is something we should notice.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/eci/seq_rerun_say_it_loud/\">Say It Loud</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eWZEBte5THEbE2Lte", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.781636403679099e-07, "legacy": true, "legacyId": "18605", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jE3npTEBtHnZBuAcg", "rN8uHmsdrpFKi5LKQ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T05:18:17.003Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes September 2012", "slug": "rationality-quotes-september-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:03.635Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jayson_Virissimo", "createdAt": "2009-03-13T06:51:41.976Z", "isAdmin": false, "displayName": "Jayson_Virissimo"}, "userId": "zwzw5ALJYG47kDek8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HQGkfx8vQfq4mSvNz/rationality-quotes-september-2012", "pageUrlRelative": "/posts/HQGkfx8vQfq4mSvNz/rationality-quotes-september-2012", "linkUrl": "https://www.lesswrong.com/posts/HQGkfx8vQfq4mSvNz/rationality-quotes-september-2012", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20September%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20September%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQGkfx8vQfq4mSvNz%2Frationality-quotes-september-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20September%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQGkfx8vQfq4mSvNz%2Frationality-quotes-september-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQGkfx8vQfq4mSvNz%2Frationality-quotes-september-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Here's the new thread for posting quotes, with the usual rules:</span></p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial; padding: 0px;\">\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Please post all quotes separately, so that they can be voted up/down separately. &nbsp;(If they are strongly related, reply to your own comments. &nbsp;If strongly ordered, then go ahead and post them together.)</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Do not quote yourself</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Do not quote comments/posts on LW/OB</span></li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">No more than 5 quotes per person per monthly thread, please.</span></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HQGkfx8vQfq4mSvNz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "18590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1114, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T05:35:38.144Z", "modifiedAt": null, "url": null, "title": "Call For Agreement: Should LessWrong have better protection against cultural collapse?", "slug": "call-for-agreement-should-lesswrong-have-better-protection", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:06.641Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Epiphany", "createdAt": "2012-08-12T03:33:21.256Z", "isAdmin": false, "displayName": "Epiphany"}, "userId": "BbbFp6hQzKF4YX8em", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/48pAgPMKd63LA4QCZ/call-for-agreement-should-lesswrong-have-better-protection", "pageUrlRelative": "/posts/48pAgPMKd63LA4QCZ/call-for-agreement-should-lesswrong-have-better-protection", "linkUrl": "https://www.lesswrong.com/posts/48pAgPMKd63LA4QCZ/call-for-agreement-should-lesswrong-have-better-protection", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Call%20For%20Agreement%3A%20Should%20LessWrong%20have%20better%20protection%20against%20cultural%20collapse%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACall%20For%20Agreement%3A%20Should%20LessWrong%20have%20better%20protection%20against%20cultural%20collapse%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48pAgPMKd63LA4QCZ%2Fcall-for-agreement-should-lesswrong-have-better-protection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Call%20For%20Agreement%3A%20Should%20LessWrong%20have%20better%20protection%20against%20cultural%20collapse%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48pAgPMKd63LA4QCZ%2Fcall-for-agreement-should-lesswrong-have-better-protection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48pAgPMKd63LA4QCZ%2Fcall-for-agreement-should-lesswrong-have-better-protection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2795, "htmlBody": "<p>As you are probably already aware, many internet forums experience a phenomenon known as <a href=\"http://en.wikipedia.org/wiki/Endless_September\">\"eternal September\"</a>.&nbsp; Named after a temporary effect where the influx of college freshmen would throw off a group's culture every September, eternal September is essentially what happens when standards of discourse and behavior degrade in a group to the point where the group loses it's original culture.&nbsp; I began <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/\">focusing on solving this problem</a> and offered to volunteer my professional web services to get it done because:</p>\n<p>- When I explained that <a href=\"/lw/e5r/lesswrong_could_grow_a_lot_but_were_doing_it_wrong/\">LessWrong could grow a lot</a> and volunteered to help with growth, <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/7bxs\">various users expressed concerns</a> about growth not always being good because having too many new users at once can degrade the culture.</p>\n<p>- There has been <a href=\"/lw/eb9/meta_karma_for_last_30_days/7aub\">concern from Eliezer about the site \"going to hell\"</a> because of trolling.</p>\n<p>- Eliezer has documented a phenomenon that subcultures know as infiltration by \"poseurs\" happening in the rationalist community.&nbsp; He explains that rationalists are beginning to be inundated by \"<a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a>\" and has stated that it's bad enough that he needed to change his method of determining who is a rationalist.&nbsp; The appearance of poseurs doesn't guarantee that a culture will be washed away by main-streamers, but may signal that a culture is headed in that direction, and it does confirm that a loss of culture is a possibility - especially if there got to be so many undiscriminating skeptics as to form their own culture and become the new majority at LessWrong.</p>\n<p>&nbsp; My plan to prevent eternal September sparked a debate about whether eternal September protection is warranted.&nbsp; Lukeprog, being the decision maker whose decision is needed for me to be allowed to do this as a volunteer, <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7bry\">requested that I debate this with him because he was not convinced but might change his mind</a>.</p>\n<p>&nbsp;</p>\n<p><strong>Here are some theories about why eternal September happens:</strong></p>\n<p>1. New to old user ratio imbalance:</p>\n<p>&nbsp; New users need time to adjust to a forum's culture.&nbsp; Getting too many new users too fast will throw off the ratio of new to old users, meaning that most new users will interact with each other rather than with older users, changing the culture permanently.</p>\n<p>2. Groups tend to trend toward the mainstream:</p>\n<p>&nbsp; Imagine some people want to start a group.&nbsp; Why are they breaking away from the mainstream?&nbsp; Because their needs are served there?&nbsp; Probably not.&nbsp; They most likely have some kind of difference that makes them want to start their own group.&nbsp; Of course not everyone fits nicely into \"different\" and \"mainstream\", no matter what type of difference you look at.&nbsp; So, as a forum grows, instead of attracting people who fit nicely into the \"different\" category, you attract people who are similar to those in the different category.&nbsp; People way on the mainstream end of the spectrum generally are not attracted to things that are very different.&nbsp; But imagine how this progresses over time.&nbsp; I'll create a scale between green and purple.&nbsp; We'll say the green people are different and the purple people are mainstream.&nbsp; So, some of the most green folks make a green forum.&nbsp; Now, people who are green and similar - those with an extra tinge of red or blue or yellow join.&nbsp; People in the mainstream still aren't attracted, however, since there are still more in-between people than solid green or purple people, the most greenish in-between people begin to dominate.&nbsp; They and the original green people still enjoy conversation - they're similar enough to share the culture and enjoy mutual activities. But the greenish in-between people start to attract in-between people that are neither more purple or more green.&nbsp; There are more in-between people than greenish in-between or green people, because purple people dominate in their larger culture, so in-between people quickly outnumber the green people.&nbsp; This may still be fine because they may adjust to the culture and enjoy it, finding it a refreshing alternative to purple culture.&nbsp; But the in-between people attract people who are more purplish in-betweeners than greenish in-betweeners.&nbsp; There are more of those than the in-between people, so the culture now shifts to be closer to mainstream purple than different green.&nbsp; At this point, it begins to attract the attention of the solid purple main streamers.&nbsp; \"Oh!&nbsp; <em>Our </em>culture, but with a twist!\"&nbsp; They think.&nbsp; Now, droves of purple main stream people deluge the place looking for \"something a little different\".&nbsp; Instead of valuing the culture and wanting to assimilate, they just want to enjoy novelty.&nbsp; So, they demand changes to things they don't like to make it suit them better.&nbsp; They justify this by saying that they're the majority.&nbsp; At that point, they are.</p>\n<p>3.&nbsp; Too many trolls scare away good people and throw off the balance.</p>\n<p>&nbsp;</p>\n<p><strong>Which theory is right?</strong></p>\n<p><strong><br /></strong></p>\n<p><em>&nbsp; All of them likely play a role.</em><strong><br /></strong></p>\n<p>&nbsp;</p>\n<p>&nbsp; I've seen for myself that trolls can scare the best people out of a forum, ruining the culture.&nbsp;</p>\n<p>&nbsp; I've heard time and time again that subculture movements have problems with being watered down by mainstream folks until their cultures die and don't feel worth it anymore to the original participators.&nbsp; A lot of you have probably heard of the term \"<a href=\"http://en.wikipedia.org/wiki/Poseur\">poseurs</a>\".&nbsp; With poseurs in a subculture, it's not that too many new people joined at once, <em>but that the wrong sort of people </em>joined.&nbsp; The view is that there are people who are different enough to \"get\" their movement, and people who are not.&nbsp; Those who aren't similar decided to try to appear like them even though they're not like them on the inside.&nbsp; Essentially, a large number of people much nearer to the mainstream got involved, so the group was no longer a haven for people with their differences.</p>\n<p>&nbsp; And I think it's a no-brainer that if a group gets enough newbies at once, old members can't help them adjust to the culture, and the newbies will form a new culture and become a new majority.</p>\n<p>&nbsp; Also, I think all of these can combine together, create feedback loops, and multiply the others.</p>\n<p>&nbsp;</p>\n<p><strong>Theory about cause and effect interactions that lead to endless September:</strong><br /><br />&nbsp;1.&nbsp; A group of people who are very different break away from the mainstream and form a group.<br />&nbsp;2.&nbsp; People who are similarly different but not AS different join the group.<br />&nbsp;3.&nbsp; People who are similar to the similarly different people, but even less similar to the different people join the group.<br />&nbsp;4.&nbsp; It goes on this way for a while.&nbsp; Since there are necessarily more people who are mainstream than different, new generations of new users may be less and less like the core group.<br />&nbsp;5.&nbsp; The group of different people begins to feel alienated with the new people who are joining.<br />&nbsp;6.&nbsp; The group of different people begin to ignore the new people.<br />&nbsp;7.&nbsp; The new people form their own culture with one another, excluding old people, because the old people are ignoring them.<br />&nbsp;8.&nbsp; Old people begin to anticipate alienation and start to see new users through tinted lenses, expecting annoyance.<br />&nbsp;9.&nbsp; New people feel alienated by the insulting misinterpretations that are caused by the expectation that they're going to be annoying.&nbsp; <br />10.&nbsp; The unwelcoming environment selects for thick-skinned people.&nbsp; A higher proportion of people like trolls, leaders, spammers, debate junkies, etc are active.<br />11.&nbsp; Enough new people who are ignored and failed to acculturate accumulate, resulting in a new majority.&nbsp; If trolls are kept under control, the new culture will be a watered down version of the original culture, possibly not much different from mainstream culture.&nbsp; If not, see the final possibility.<br />12.&nbsp; If a critical mass of trolls, spammers and other alienating thick-skinned types is reached due to an imbalance or inadequate methods of dealing with them, they might ward off old users, exacerbating the imbalance that draws a disproportionate number of thick-skinned types in a feedback loop and then take over the forum.&nbsp; (Why fourchan /b isn't known for having sweet little girls and old ladies.)</p>\n<p>&nbsp;</p>\n<p><strong>Is LessWrong at risk?</strong></p>\n<p>&nbsp; 1.&nbsp; Eliezer has written about rationalists being infiltrated by main-streamers who don't get it, aka \"poseurs\".</p>\n<p>&nbsp; Eliezer explains in <a href=\"/lw/1ww/undiscriminating_skepticism/\">Undiscriminating Skeptics</a> that he can no longer determine who is a rationalist based on how they react to the prospect of religious debates, and now he has to determine who is a rationalist based on who is thinking for themselves.&nbsp; This is the exact same problem other subcultures have - they say the new people aren't thinking for themselves.&nbsp; We might argue \"but we want to spread the wonderful gift of rational thought to the mainstream!\" and I would agree with that.&nbsp; However, if all they're able to take away from joining is that there are certain things skeptics always believe, all they'll be taking away from us is an appeal to skepticism.&nbsp; That's the kind of thing that happens when subcultures are over-run by mainstream folks.&nbsp; They do not adopt the core values.&nbsp; Instead, they run roughshod over them.&nbsp; If we want undiscriminating skeptics to get benefits from refining the art of rationality, we have to do something more than hang out in the same place.&nbsp; Telling them that they are poseurs doesn't work for subcultures, and I don't think Eliezer telling them that they're undiscriminating skeptics will solve the problem.&nbsp; Getting people to think for themselves is a challenge that should not be undertaken lightly.&nbsp; To really get it, and actually base your life on rationality, you've either got to be the right type, a \"natural\" who \"just gets it\" (like Eliezer who showed signs as a child when he <a href=\"http://www.overcomingbias.com/author/eliezer-yudkowsky\">found a tarnished silver amulet inscribed with Bayes's Theorem</a>) or you have to be <em>really </em>dedicated to self-improvement.</p>\n<p>&nbsp; 2. I have witnessed a fast-growing forum <em>actually go exponential</em>.&nbsp; Nothing special was being done to advertise the forum.&nbsp;</p>\n<p>&nbsp; Obviously, this risks deluging old members in a sea of newbies that would be large enough to create a newbie culture and form a new majority.</p>\n<p>&nbsp; 3. LessWrong is growing fast and it's much bigger than I think everyone realizes.</p>\n<p>&nbsp; I made a <a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/\">LessWrong growth bar graph</a> showing how LessWrong has gained over 13,000 members in under 3 years (Nov 2009 - Aug 2012).&nbsp; LessWrong had <span class=\"jcb\">over 3 million visits in the last  year.&nbsp; The most popular post has gotten over 200,000 views.&nbsp; Yes I mean  there are posts on here that are over 1/5 of their way to a million  views, <span class=\"jcb\">I did not mistype.&nbsp; </span></span>This is not a tiny community website anymore.&nbsp; I see signs that people are still acting that way, like when people post their email addresses on the forum.&nbsp; <span class=\"jcb\"><span class=\"jcb\">People don't seem to realize how big LessWrong has gotten.&nbsp; Since this happened in a short time, we should be wondering how much further it will go, and planning for the contingency that could become huge.<br /></span></span></p>\n<p>&nbsp; 4. LessWrong has experienced at least one wild spike in membership.&nbsp; Spikes can happen again.</p>\n<p>&nbsp; We can't control the ups and downs in visitors to the site.&nbsp; That could happen again.&nbsp; It could last for longer than a month.&nbsp; According to Vladmir, using wget, we've got something like <a href=\"/lw/e4j/number_of_members_on_lesswrong/77xz\">600 - 1000 active users posting per month</a>.&nbsp; We've got about 300 users joining per month from the registration statistics.&nbsp; What would happen if we got 900 each month for a few months in a row?&nbsp; A random spike could conceivably overwhelm the members.</p>\n<p>&nbsp; 5. Considering how many readers it has, LessWrong could get Slashdotted by somebody big.</p>\n<p>&nbsp; If you've ever read about the <a href=\"http://en.wikipedia.org/wiki/Slashdotting\">Slashdot effect</a>, you'll know that all it might take to get a deluge bigger than we can handle is to be linked to by somebody big.&nbsp; What if Slashdot links to LessWrong?&nbsp; Or somebody even bigger?&nbsp; We have at least one article on LessWrong that got about half as many visits as a hall of fame level Slashdot article.&nbsp; The article \"Scientologists Force Comment Off Slashdot\" got 383692 visits on Slashdot, compared with LessWrong's most popular article at 211,000 visits. (Cite: <a href=\"http://slashdot.org/hof.shtml\">Slashdot hall of fame.</a>)&nbsp; LessWrong is gaining popularity fast.&nbsp; It's not a small site anymore.&nbsp; And there are a lot of places that could Slashdot us.&nbsp; I may be just a matter of time before somebody pays attention, does an article on LessWrong, and it gets flooded.</p>\n<p>&nbsp; 6. We all want to grow LessWrong, and people may cause rapid growth before thinking about the consequences.</p>\n<p>&nbsp; What if people start growing LessWrong and wildly succeed?&nbsp; I would like to be helping LessWrong grow but I don't want to do it until I feel the culture is well-protected.</p>\n<p>&nbsp; 7. Some combination of these things might happen and deluge old people with new people.</p>\n<p>&nbsp;</p>\n<p><strong>Does LessWrong need additional eternal September protection?</strong></p>\n<p><strong>&nbsp; </strong><a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/7brq\">Lukeprog's main argument</a> is that we don't have to worry about eternal September because we have vote downs. Here's why vote downs are not going to protect LessWrong:</p>\n<p>&nbsp; 1.&nbsp; If the new to old user ratio becomes unbalanced, or the site is filled with main streamers who take over the culture, who is going to get voted down most?&nbsp; The new users, or the old ones?&nbsp; The old members will be outnumbered, so it will likely be old members.</p>\n<p>&nbsp; 2. This doesn't prevent new users from interacting primarily with new users.&nbsp; If enough people join, there may not be enough old users doing vote downs to discourage them anymore.&nbsp; That means if the new to old user ratio were to become unbalanced, new users may still interact primarily with new users and form their own, larger culture, a new majority.</p>\n<p>&nbsp; 3.&nbsp; Let's say Fourchan /b decides to visit.&nbsp; A hundred trolls descend upon LessWrong.&nbsp; The trolls, like everybody else, have the ability to vote down anything they want.&nbsp; The trolls of course will enjoy harassing us endlessly with vote downs.&nbsp; They will especially enjoy the fact that it only takes three of them to censor somebody.&nbsp; They will find it a really, really special treat that we've made it so that anybody who responds to a censored person ends up getting points deducted.&nbsp; From a security perspective, this is probably one of the worst things that you could do.&nbsp; I came up with an idea for a <a href=\"/lw/ecg/meta_what_do_you_think_of_a_karma_vote_checklist/7bpm\">much improved vote down plan</a>.</p>\n<p>&nbsp;</p>\n<p><strong>Possibly more important: What happens if we DO prevent an eternal September?</strong></p>\n<p>&nbsp; What we are deciding here is not simply \"do we want to protect this specific website from cultural collapse?\" but \"How do we want to introduce the art of refining rationality to the mainstream public?\"</p>\n<p>&nbsp; Why do main streamers deluge new cultures and what happens after that?&nbsp; What do they get out of it?&nbsp; How does it affect them in the long-term?&nbsp; Might being deluged by main streamers make it more likely for main streamers to become better at rational thought, like a first taste makes you want more?</p>\n<p>&nbsp; If we kept them from doing that, what would happen, then?&nbsp;</p>\n<p>&nbsp; Say we don't have a plan.&nbsp; LessWrong is hit by more users than it can handle.&nbsp; Undiscriminating skeptics are voting down every worthwhile disagreement.&nbsp; So, as an emergency measure, registrations are shut off, the number of visits to the website grows and then falls.&nbsp; We succeed in keeping out people who don't get it.&nbsp; After it has peaked, the fad is over.&nbsp; Worse, we've put them off and they're offended.&nbsp; Or, we don't shut off registrations, we're deluged, and now everyone thinks that a \"rationalist\" an \"undiscriminating skeptic\".&nbsp; We've lost the opportunity to get through to them, possibly for good.&nbsp; Will they ever become more rational?&nbsp; LessWrong wants to make the world a more rational place.&nbsp; An opportunity to accomplish that goal could happen.&nbsp; Eliezer figured out a way to make rationality popular.&nbsp; Millions of people have read his work.&nbsp; This could go even bigger.</p>\n<p>&nbsp; This is why I suggested two discussion areas - then we get to keep this culture and also have an opportunity to experiment with ways for the people who are not naturals at it to learn faster.&nbsp; If we succeed in figuring out how to get through to them, we will know that the deluge will be constructive, if one happens.&nbsp; Then, we can even invite one on purpose.&nbsp; We can even advertise for that and I'd be happy to help.&nbsp; But if we don't start with eternal September protection, we could lose all this progress, lose our chance to get through to the mainstream, and pass like a fad.</p>\n<p>&nbsp; For that reason, even if eternal September doesn't look likely to you after everything that I've explained above, I say it is still worthwhile to develop a tested technique to preserve LessWrong culture against a deluge and get through to those who are not naturals.&nbsp; Not doing so takes a risk with something important.</p>\n<p>&nbsp;</p>\n<p><strong>Please critique.</strong></p>\n<p>&nbsp; Your honest assessments of my ideas are welcome, always.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "48pAgPMKd63LA4QCZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "18603", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>As you are probably already aware, many internet forums experience a phenomenon known as <a href=\"http://en.wikipedia.org/wiki/Endless_September\">\"eternal September\"</a>.&nbsp; Named after a temporary effect where the influx of college freshmen would throw off a group's culture every September, eternal September is essentially what happens when standards of discourse and behavior degrade in a group to the point where the group loses it's original culture.&nbsp; I began <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/\">focusing on solving this problem</a> and offered to volunteer my professional web services to get it done because:</p>\n<p>- When I explained that <a href=\"/lw/e5r/lesswrong_could_grow_a_lot_but_were_doing_it_wrong/\">LessWrong could grow a lot</a> and volunteered to help with growth, <a href=\"/lw/ecr/call_for_agreement_should_lesswrong_have_better/7bxs\">various users expressed concerns</a> about growth not always being good because having too many new users at once can degrade the culture.</p>\n<p>- There has been <a href=\"/lw/eb9/meta_karma_for_last_30_days/7aub\">concern from Eliezer about the site \"going to hell\"</a> because of trolling.</p>\n<p>- Eliezer has documented a phenomenon that subcultures know as infiltration by \"poseurs\" happening in the rationalist community.&nbsp; He explains that rationalists are beginning to be inundated by \"<a href=\"/lw/1ww/undiscriminating_skepticism/\">undiscriminating skeptics</a>\" and has stated that it's bad enough that he needed to change his method of determining who is a rationalist.&nbsp; The appearance of poseurs doesn't guarantee that a culture will be washed away by main-streamers, but may signal that a culture is headed in that direction, and it does confirm that a loss of culture is a possibility - especially if there got to be so many undiscriminating skeptics as to form their own culture and become the new majority at LessWrong.</p>\n<p>&nbsp; My plan to prevent eternal September sparked a debate about whether eternal September protection is warranted.&nbsp; Lukeprog, being the decision maker whose decision is needed for me to be allowed to do this as a volunteer, <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7bry\">requested that I debate this with him because he was not convinced but might change his mind</a>.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Here_are_some_theories_about_why_eternal_September_happens_\">Here are some theories about why eternal September happens:</strong></p>\n<p>1. New to old user ratio imbalance:</p>\n<p>&nbsp; New users need time to adjust to a forum's culture.&nbsp; Getting too many new users too fast will throw off the ratio of new to old users, meaning that most new users will interact with each other rather than with older users, changing the culture permanently.</p>\n<p>2. Groups tend to trend toward the mainstream:</p>\n<p>&nbsp; Imagine some people want to start a group.&nbsp; Why are they breaking away from the mainstream?&nbsp; Because their needs are served there?&nbsp; Probably not.&nbsp; They most likely have some kind of difference that makes them want to start their own group.&nbsp; Of course not everyone fits nicely into \"different\" and \"mainstream\", no matter what type of difference you look at.&nbsp; So, as a forum grows, instead of attracting people who fit nicely into the \"different\" category, you attract people who are similar to those in the different category.&nbsp; People way on the mainstream end of the spectrum generally are not attracted to things that are very different.&nbsp; But imagine how this progresses over time.&nbsp; I'll create a scale between green and purple.&nbsp; We'll say the green people are different and the purple people are mainstream.&nbsp; So, some of the most green folks make a green forum.&nbsp; Now, people who are green and similar - those with an extra tinge of red or blue or yellow join.&nbsp; People in the mainstream still aren't attracted, however, since there are still more in-between people than solid green or purple people, the most greenish in-between people begin to dominate.&nbsp; They and the original green people still enjoy conversation - they're similar enough to share the culture and enjoy mutual activities. But the greenish in-between people start to attract in-between people that are neither more purple or more green.&nbsp; There are more in-between people than greenish in-between or green people, because purple people dominate in their larger culture, so in-between people quickly outnumber the green people.&nbsp; This may still be fine because they may adjust to the culture and enjoy it, finding it a refreshing alternative to purple culture.&nbsp; But the in-between people attract people who are more purplish in-betweeners than greenish in-betweeners.&nbsp; There are more of those than the in-between people, so the culture now shifts to be closer to mainstream purple than different green.&nbsp; At this point, it begins to attract the attention of the solid purple main streamers.&nbsp; \"Oh!&nbsp; <em>Our </em>culture, but with a twist!\"&nbsp; They think.&nbsp; Now, droves of purple main stream people deluge the place looking for \"something a little different\".&nbsp; Instead of valuing the culture and wanting to assimilate, they just want to enjoy novelty.&nbsp; So, they demand changes to things they don't like to make it suit them better.&nbsp; They justify this by saying that they're the majority.&nbsp; At that point, they are.</p>\n<p>3.&nbsp; Too many trolls scare away good people and throw off the balance.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Which_theory_is_right_\">Which theory is right?</strong></p>\n<p><strong><br></strong></p>\n<p><em>&nbsp; All of them likely play a role.</em><strong><br></strong></p>\n<p>&nbsp;</p>\n<p>&nbsp; I've seen for myself that trolls can scare the best people out of a forum, ruining the culture.&nbsp;</p>\n<p>&nbsp; I've heard time and time again that subculture movements have problems with being watered down by mainstream folks until their cultures die and don't feel worth it anymore to the original participators.&nbsp; A lot of you have probably heard of the term \"<a href=\"http://en.wikipedia.org/wiki/Poseur\">poseurs</a>\".&nbsp; With poseurs in a subculture, it's not that too many new people joined at once, <em>but that the wrong sort of people </em>joined.&nbsp; The view is that there are people who are different enough to \"get\" their movement, and people who are not.&nbsp; Those who aren't similar decided to try to appear like them even though they're not like them on the inside.&nbsp; Essentially, a large number of people much nearer to the mainstream got involved, so the group was no longer a haven for people with their differences.</p>\n<p>&nbsp; And I think it's a no-brainer that if a group gets enough newbies at once, old members can't help them adjust to the culture, and the newbies will form a new culture and become a new majority.</p>\n<p>&nbsp; Also, I think all of these can combine together, create feedback loops, and multiply the others.</p>\n<p>&nbsp;</p>\n<p><strong>Theory about cause and effect interactions that lead to endless September:</strong><br><br>&nbsp;1.&nbsp; A group of people who are very different break away from the mainstream and form a group.<br>&nbsp;2.&nbsp; People who are similarly different but not AS different join the group.<br>&nbsp;3.&nbsp; People who are similar to the similarly different people, but even less similar to the different people join the group.<br>&nbsp;4.&nbsp; It goes on this way for a while.&nbsp; Since there are necessarily more people who are mainstream than different, new generations of new users may be less and less like the core group.<br>&nbsp;5.&nbsp; The group of different people begins to feel alienated with the new people who are joining.<br>&nbsp;6.&nbsp; The group of different people begin to ignore the new people.<br>&nbsp;7.&nbsp; The new people form their own culture with one another, excluding old people, because the old people are ignoring them.<br>&nbsp;8.&nbsp; Old people begin to anticipate alienation and start to see new users through tinted lenses, expecting annoyance.<br>&nbsp;9.&nbsp; New people feel alienated by the insulting misinterpretations that are caused by the expectation that they're going to be annoying.&nbsp; <br>10.&nbsp; The unwelcoming environment selects for thick-skinned people.&nbsp; A higher proportion of people like trolls, leaders, spammers, debate junkies, etc are active.<br>11.&nbsp; Enough new people who are ignored and failed to acculturate accumulate, resulting in a new majority.&nbsp; If trolls are kept under control, the new culture will be a watered down version of the original culture, possibly not much different from mainstream culture.&nbsp; If not, see the final possibility.<br>12.&nbsp; If a critical mass of trolls, spammers and other alienating thick-skinned types is reached due to an imbalance or inadequate methods of dealing with them, they might ward off old users, exacerbating the imbalance that draws a disproportionate number of thick-skinned types in a feedback loop and then take over the forum.&nbsp; (Why fourchan /b isn't known for having sweet little girls and old ladies.)</p>\n<p>&nbsp;</p>\n<p><strong id=\"Is_LessWrong_at_risk_\">Is LessWrong at risk?</strong></p>\n<p>&nbsp; 1.&nbsp; Eliezer has written about rationalists being infiltrated by main-streamers who don't get it, aka \"poseurs\".</p>\n<p>&nbsp; Eliezer explains in <a href=\"/lw/1ww/undiscriminating_skepticism/\">Undiscriminating Skeptics</a> that he can no longer determine who is a rationalist based on how they react to the prospect of religious debates, and now he has to determine who is a rationalist based on who is thinking for themselves.&nbsp; This is the exact same problem other subcultures have - they say the new people aren't thinking for themselves.&nbsp; We might argue \"but we want to spread the wonderful gift of rational thought to the mainstream!\" and I would agree with that.&nbsp; However, if all they're able to take away from joining is that there are certain things skeptics always believe, all they'll be taking away from us is an appeal to skepticism.&nbsp; That's the kind of thing that happens when subcultures are over-run by mainstream folks.&nbsp; They do not adopt the core values.&nbsp; Instead, they run roughshod over them.&nbsp; If we want undiscriminating skeptics to get benefits from refining the art of rationality, we have to do something more than hang out in the same place.&nbsp; Telling them that they are poseurs doesn't work for subcultures, and I don't think Eliezer telling them that they're undiscriminating skeptics will solve the problem.&nbsp; Getting people to think for themselves is a challenge that should not be undertaken lightly.&nbsp; To really get it, and actually base your life on rationality, you've either got to be the right type, a \"natural\" who \"just gets it\" (like Eliezer who showed signs as a child when he <a href=\"http://www.overcomingbias.com/author/eliezer-yudkowsky\">found a tarnished silver amulet inscribed with Bayes's Theorem</a>) or you have to be <em>really </em>dedicated to self-improvement.</p>\n<p>&nbsp; 2. I have witnessed a fast-growing forum <em>actually go exponential</em>.&nbsp; Nothing special was being done to advertise the forum.&nbsp;</p>\n<p>&nbsp; Obviously, this risks deluging old members in a sea of newbies that would be large enough to create a newbie culture and form a new majority.</p>\n<p>&nbsp; 3. LessWrong is growing fast and it's much bigger than I think everyone realizes.</p>\n<p>&nbsp; I made a <a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/\">LessWrong growth bar graph</a> showing how LessWrong has gained over 13,000 members in under 3 years (Nov 2009 - Aug 2012).&nbsp; LessWrong had <span class=\"jcb\">over 3 million visits in the last  year.&nbsp; The most popular post has gotten over 200,000 views.&nbsp; Yes I mean  there are posts on here that are over 1/5 of their way to a million  views, <span class=\"jcb\">I did not mistype.&nbsp; </span></span>This is not a tiny community website anymore.&nbsp; I see signs that people are still acting that way, like when people post their email addresses on the forum.&nbsp; <span class=\"jcb\"><span class=\"jcb\">People don't seem to realize how big LessWrong has gotten.&nbsp; Since this happened in a short time, we should be wondering how much further it will go, and planning for the contingency that could become huge.<br></span></span></p>\n<p>&nbsp; 4. LessWrong has experienced at least one wild spike in membership.&nbsp; Spikes can happen again.</p>\n<p>&nbsp; We can't control the ups and downs in visitors to the site.&nbsp; That could happen again.&nbsp; It could last for longer than a month.&nbsp; According to Vladmir, using wget, we've got something like <a href=\"/lw/e4j/number_of_members_on_lesswrong/77xz\">600 - 1000 active users posting per month</a>.&nbsp; We've got about 300 users joining per month from the registration statistics.&nbsp; What would happen if we got 900 each month for a few months in a row?&nbsp; A random spike could conceivably overwhelm the members.</p>\n<p>&nbsp; 5. Considering how many readers it has, LessWrong could get Slashdotted by somebody big.</p>\n<p>&nbsp; If you've ever read about the <a href=\"http://en.wikipedia.org/wiki/Slashdotting\">Slashdot effect</a>, you'll know that all it might take to get a deluge bigger than we can handle is to be linked to by somebody big.&nbsp; What if Slashdot links to LessWrong?&nbsp; Or somebody even bigger?&nbsp; We have at least one article on LessWrong that got about half as many visits as a hall of fame level Slashdot article.&nbsp; The article \"Scientologists Force Comment Off Slashdot\" got 383692 visits on Slashdot, compared with LessWrong's most popular article at 211,000 visits. (Cite: <a href=\"http://slashdot.org/hof.shtml\">Slashdot hall of fame.</a>)&nbsp; LessWrong is gaining popularity fast.&nbsp; It's not a small site anymore.&nbsp; And there are a lot of places that could Slashdot us.&nbsp; I may be just a matter of time before somebody pays attention, does an article on LessWrong, and it gets flooded.</p>\n<p>&nbsp; 6. We all want to grow LessWrong, and people may cause rapid growth before thinking about the consequences.</p>\n<p>&nbsp; What if people start growing LessWrong and wildly succeed?&nbsp; I would like to be helping LessWrong grow but I don't want to do it until I feel the culture is well-protected.</p>\n<p>&nbsp; 7. Some combination of these things might happen and deluge old people with new people.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Does_LessWrong_need_additional_eternal_September_protection_\">Does LessWrong need additional eternal September protection?</strong></p>\n<p><strong>&nbsp; </strong><a href=\"/r/discussion/lw/ec2/preventing_discussion_from_being_watered_down_by/7brq\">Lukeprog's main argument</a> is that we don't have to worry about eternal September because we have vote downs. Here's why vote downs are not going to protect LessWrong:</p>\n<p>&nbsp; 1.&nbsp; If the new to old user ratio becomes unbalanced, or the site is filled with main streamers who take over the culture, who is going to get voted down most?&nbsp; The new users, or the old ones?&nbsp; The old members will be outnumbered, so it will likely be old members.</p>\n<p>&nbsp; 2. This doesn't prevent new users from interacting primarily with new users.&nbsp; If enough people join, there may not be enough old users doing vote downs to discourage them anymore.&nbsp; That means if the new to old user ratio were to become unbalanced, new users may still interact primarily with new users and form their own, larger culture, a new majority.</p>\n<p>&nbsp; 3.&nbsp; Let's say Fourchan /b decides to visit.&nbsp; A hundred trolls descend upon LessWrong.&nbsp; The trolls, like everybody else, have the ability to vote down anything they want.&nbsp; The trolls of course will enjoy harassing us endlessly with vote downs.&nbsp; They will especially enjoy the fact that it only takes three of them to censor somebody.&nbsp; They will find it a really, really special treat that we've made it so that anybody who responds to a censored person ends up getting points deducted.&nbsp; From a security perspective, this is probably one of the worst things that you could do.&nbsp; I came up with an idea for a <a href=\"/lw/ecg/meta_what_do_you_think_of_a_karma_vote_checklist/7bpm\">much improved vote down plan</a>.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Possibly_more_important__What_happens_if_we_DO_prevent_an_eternal_September_\">Possibly more important: What happens if we DO prevent an eternal September?</strong></p>\n<p>&nbsp; What we are deciding here is not simply \"do we want to protect this specific website from cultural collapse?\" but \"How do we want to introduce the art of refining rationality to the mainstream public?\"</p>\n<p>&nbsp; Why do main streamers deluge new cultures and what happens after that?&nbsp; What do they get out of it?&nbsp; How does it affect them in the long-term?&nbsp; Might being deluged by main streamers make it more likely for main streamers to become better at rational thought, like a first taste makes you want more?</p>\n<p>&nbsp; If we kept them from doing that, what would happen, then?&nbsp;</p>\n<p>&nbsp; Say we don't have a plan.&nbsp; LessWrong is hit by more users than it can handle.&nbsp; Undiscriminating skeptics are voting down every worthwhile disagreement.&nbsp; So, as an emergency measure, registrations are shut off, the number of visits to the website grows and then falls.&nbsp; We succeed in keeping out people who don't get it.&nbsp; After it has peaked, the fad is over.&nbsp; Worse, we've put them off and they're offended.&nbsp; Or, we don't shut off registrations, we're deluged, and now everyone thinks that a \"rationalist\" an \"undiscriminating skeptic\".&nbsp; We've lost the opportunity to get through to them, possibly for good.&nbsp; Will they ever become more rational?&nbsp; LessWrong wants to make the world a more rational place.&nbsp; An opportunity to accomplish that goal could happen.&nbsp; Eliezer figured out a way to make rationality popular.&nbsp; Millions of people have read his work.&nbsp; This could go even bigger.</p>\n<p>&nbsp; This is why I suggested two discussion areas - then we get to keep this culture and also have an opportunity to experiment with ways for the people who are not naturals at it to learn faster.&nbsp; If we succeed in figuring out how to get through to them, we will know that the deluge will be constructive, if one happens.&nbsp; Then, we can even invite one on purpose.&nbsp; We can even advertise for that and I'd be happy to help.&nbsp; But if we don't start with eternal September protection, we could lose all this progress, lose our chance to get through to the mainstream, and pass like a fad.</p>\n<p>&nbsp; For that reason, even if eternal September doesn't look likely to you after everything that I've explained above, I say it is still worthwhile to develop a tested technique to preserve LessWrong culture against a deluge and get through to those who are not naturals.&nbsp; Not doing so takes a risk with something important.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Please_critique_\">Please critique.</strong></p>\n<p>&nbsp; Your honest assessments of my ideas are welcome, always.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Here are some theories about why eternal September happens:", "anchor": "Here_are_some_theories_about_why_eternal_September_happens_", "level": 1}, {"title": "Which theory is right?", "anchor": "Which_theory_is_right_", "level": 1}, {"title": "Is LessWrong at risk?", "anchor": "Is_LessWrong_at_risk_", "level": 1}, {"title": "Does LessWrong need additional eternal September protection?", "anchor": "Does_LessWrong_need_additional_eternal_September_protection_", "level": 1}, {"title": "Possibly more important: What happens if we DO prevent an eternal September?", "anchor": "Possibly_more_important__What_happens_if_we_DO_prevent_an_eternal_September_", "level": 1}, {"title": "Please critique.", "anchor": "Please_critique_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "90 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 90, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MLaSGq6A6bLTdt6r8", "GEtLkHyPhG8m4aepb", "Jko7pt7MwwTBrfG3A"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T06:51:49.598Z", "modifiedAt": null, "url": null, "title": "What's your \"rationalist arguing\" origin story?", "slug": "what-s-your-rationalist-arguing-origin-story", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:30.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4xtws3XGkgsgfWF5E/what-s-your-rationalist-arguing-origin-story", "pageUrlRelative": "/posts/4xtws3XGkgsgfWF5E/what-s-your-rationalist-arguing-origin-story", "linkUrl": "https://www.lesswrong.com/posts/4xtws3XGkgsgfWF5E/what-s-your-rationalist-arguing-origin-story", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20your%20%22rationalist%20arguing%22%20origin%20story%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20your%20%22rationalist%20arguing%22%20origin%20story%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xtws3XGkgsgfWF5E%2Fwhat-s-your-rationalist-arguing-origin-story%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20your%20%22rationalist%20arguing%22%20origin%20story%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xtws3XGkgsgfWF5E%2Fwhat-s-your-rationalist-arguing-origin-story", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xtws3XGkgsgfWF5E%2Fwhat-s-your-rationalist-arguing-origin-story", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 473, "htmlBody": "<div>By rationalist arguing, I mean the sort of argument where you'd rather have the right belief at the end than \"win.\" This is quite different from the usual rationalization competition style of argument, and is pretty rare. But somehow, it happens on LessWrong a lot. It goes by other names too, but I am contractually obligated to put the word \"rationalist\" before as many other words as I can.</div>\n<div>Back when I was a teenager, and I mean like 13-16, I frequented an online political forum, which shall remain unnamed. It was about as rational as one might expect, which is to say awful. And eventually, after three years visiting there, I stopped. The first mover of me moving out was that I'd figured out the moves on the rhetorical chessboard - if I make an appeal to intuition here, they can make an ad hominem there, and so on and so on. And once this arguing became transparent, it also became boring - instead I started actually asking the question \"how can I figure out what's <em>true</em>?\" And so I stopped arguing politics, which had been a pretty big habit of mine a week before.</div>\n<div>Cut forward some years. I'm a LessWrong reader. And somewhere after my first few months of posting I figure out that I <em>really</em> shouldn't be trying to \"win arguments\" here - after all, I stopped doing that when I was 16, right? Instead, I decide, I should practice \"cooperative arguing,\" where the goal is to work together (dialectically, though I wouldn't have known to call it that at the time). And if you're doing it really right, you should be able to \"lose\" (in quotes because you're learning from it and don't give a crap) about half the time. Don't \"try to lose,\" but \"try to be able to lose.\" There's a reflection of HPMOR in there, but it's in a funhouse mirror.</div>\n<div>Since then I've advanced a bit, so I can look at creating environments that help this happen, but this post was titled \"origin story\" and that's what I'm curious about.&nbsp;For me, getting familiar with rhetoric and then getting fed up with it was necessary before I could go on to actually try to be able to lose. But it seems a little specific - there seem (perhaps) to be plenty of other people who follow the same rules as me on here, and you can't <em>all</em>&nbsp;have frequented political forums during your forumative years (sorry). Or can you?</div>\n<div>Was LW key in germinating this \"rationalist arguing,\" or did we have the seeds already within us? &nbsp;Memory says the latter, but statistics says the former. Or perhaps it's just a selection effect, and old people who have figured all this out just didn't tell me. Or they did and I didn't comprehend.</div>\n<div>Gonna need data. What's your \"rationalist arguing\" origin story?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4xtws3XGkgsgfWF5E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 9.782755590092907e-07, "legacy": true, "legacyId": "18611", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T08:35:20.065Z", "modifiedAt": null, "url": null, "title": "Bayesian Conspiracy Check-in Post", "slug": "bayesian-conspiracy-check-in-post", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.970Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/49bNW4Gka3Qd4X2Ep/bayesian-conspiracy-check-in-post", "pageUrlRelative": "/posts/49bNW4Gka3Qd4X2Ep/bayesian-conspiracy-check-in-post", "linkUrl": "https://www.lesswrong.com/posts/49bNW4Gka3Qd4X2Ep/bayesian-conspiracy-check-in-post", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20Conspiracy%20Check-in%20Post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20Conspiracy%20Check-in%20Post%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F49bNW4Gka3Qd4X2Ep%2Fbayesian-conspiracy-check-in-post%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20Conspiracy%20Check-in%20Post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F49bNW4Gka3Qd4X2Ep%2Fbayesian-conspiracy-check-in-post", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F49bNW4Gka3Qd4X2Ep%2Fbayesian-conspiracy-check-in-post", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>Just returned from this year's Bayesian Conspiracy camp at Burning Man. We encountered a lot of cool burners who read this blog, and I thought we should have a post for them to check in with contact info if they'd like to stay in touch.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "49bNW4Gka3Qd4X2Ep", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "18612", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T17:27:47.017Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley meetup: board game night", "slug": "meetup-berkeley-meetup-board-game-night", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jfd9XNw5XWSh5tGGT/meetup-berkeley-meetup-board-game-night", "pageUrlRelative": "/posts/jfd9XNw5XWSh5tGGT/meetup-berkeley-meetup-board-game-night", "linkUrl": "https://www.lesswrong.com/posts/jfd9XNw5XWSh5tGGT/meetup-berkeley-meetup-board-game-night", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%20meetup%3A%20board%20game%20night&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%20meetup%3A%20board%20game%20night%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjfd9XNw5XWSh5tGGT%2Fmeetup-berkeley-meetup-board-game-night%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%20meetup%3A%20board%20game%20night%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjfd9XNw5XWSh5tGGT%2Fmeetup-berkeley-meetup-board-game-night", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjfd9XNw5XWSh5tGGT%2Fmeetup-berkeley-meetup-board-game-night", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dh'>Berkeley meetup: board game night</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Nisan is out of town, so I will be hosting Wednesday's meetup at Zendo. We will be having a board game night. Zendo's game library has Robo Rally, Smallworld, Dominion, Ticket to Ride, Settlers of Catan, Tigris &amp; Euphrates, Set, and some others. If you have a game that you'd like to play, bring it along! Doors open at 7pm, and games start at 7:30. For directions to Zendo, see the mailing list <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dh'>Berkeley meetup: board game night</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jfd9XNw5XWSh5tGGT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 9.785969880107826e-07, "legacy": true, "legacyId": "18613", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__board_game_night\">Discussion article for the meetup : <a href=\"/meetups/dh\">Berkeley meetup: board game night</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Nisan is out of town, so I will be hosting Wednesday's meetup at Zendo. We will be having a board game night. Zendo's game library has Robo Rally, Smallworld, Dominion, Ticket to Ride, Settlers of Catan, Tigris &amp; Euphrates, Set, and some others. If you have a game that you'd like to play, bring it along! Doors open at 7pm, and games start at 7:30. For directions to Zendo, see the mailing list <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__board_game_night1\">Discussion article for the meetup : <a href=\"/meetups/dh\">Berkeley meetup: board game night</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley meetup: board game night", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__board_game_night", "level": 1}, {"title": "Discussion article for the meetup : Berkeley meetup: board game night", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__board_game_night1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-03T21:53:12.668Z", "modifiedAt": null, "url": null, "title": "How To Actually Change Your Mind eBook (In Order)", "slug": "how-to-actually-change-your-mind-ebook-in-order", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:05.975Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Elec0", "createdAt": "2012-08-30T23:05:00.802Z", "isAdmin": false, "displayName": "Elec0"}, "userId": "MTg5QKMANSvADWQmk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DGnXAFRiepCTNWrNz/how-to-actually-change-your-mind-ebook-in-order", "pageUrlRelative": "/posts/DGnXAFRiepCTNWrNz/how-to-actually-change-your-mind-ebook-in-order", "linkUrl": "https://www.lesswrong.com/posts/DGnXAFRiepCTNWrNz/how-to-actually-change-your-mind-ebook-in-order", "postedAtFormatted": "Monday, September 3rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20To%20Actually%20Change%20Your%20Mind%20eBook%20(In%20Order)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20To%20Actually%20Change%20Your%20Mind%20eBook%20(In%20Order)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGnXAFRiepCTNWrNz%2Fhow-to-actually-change-your-mind-ebook-in-order%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20To%20Actually%20Change%20Your%20Mind%20eBook%20(In%20Order)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGnXAFRiepCTNWrNz%2Fhow-to-actually-change-your-mind-ebook-in-order", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDGnXAFRiepCTNWrNz%2Fhow-to-actually-change-your-mind-ebook-in-order", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 226, "htmlBody": "<p>Firstly, if this has already been created, then I apologize, but I couldn't find it and I looked.</p>\n<p>I wanted to read the how to change your mind sequence on my eBook reader, but when I looked around the site I couldn't find any eBooks other than large ones with the blog posts in order of post date, which isn't really how the sequences are arranged. So I decided to copy and paste everything from the how to change your mind sequence into an eBook. Primarily for my personal use, but I figured that other people might be interested in it as well.</p>\n<p>My version is in epub format, Calibre can convert to others, but if you'd like another format, let me know and I'll convert it.</p>\n<p>I believe that I got all the basic HTML formatting down, like indention where was it in the main article and bullet points and suchlike. I didn't include hyperlinks, as most eReaders can't open them.</p>\n<p>The table of contents is arranged exactly like the subsequences are in the sequence.</p>\n<p>I've tested it in Calibre and on my Sony PRS 505 (which is quite old at this point), but everything seemed to work everywhere I tested it.</p>\n<p>If you find any errors, or have any suggestions, please let me know.</p>\n<ul>\n<li><a title=\"epub (9/3/2012)\" href=\"http://www.mediafire.com/download.php?yza7p8jv7bfp8o6\" target=\"_blank\">epub (9/3/2012)</a></li>\n<li><a title=\"mobi (9/3/2012)\" href=\"http://www.mediafire.com/download.php?lsab5mf5xzud55f\" target=\"_blank\">mobi (9/3/2012)</a></li>\n<li><a href=\"http://www.mediafire.com/view/?8u324jj311mzs5b\" target=\"_blank\">pdf (9/3/2012)</a></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DGnXAFRiepCTNWrNz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 27, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "18614", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T04:41:01.382Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Horrible LHC Inconsistency", "slug": "seq-rerun-horrible-lhc-inconsistency", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v8X2QsoiQWPj4JwLb/seq-rerun-horrible-lhc-inconsistency", "pageUrlRelative": "/posts/v8X2QsoiQWPj4JwLb/seq-rerun-horrible-lhc-inconsistency", "linkUrl": "https://www.lesswrong.com/posts/v8X2QsoiQWPj4JwLb/seq-rerun-horrible-lhc-inconsistency", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Horrible%20LHC%20Inconsistency&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Horrible%20LHC%20Inconsistency%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv8X2QsoiQWPj4JwLb%2Fseq-rerun-horrible-lhc-inconsistency%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Horrible%20LHC%20Inconsistency%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv8X2QsoiQWPj4JwLb%2Fseq-rerun-horrible-lhc-inconsistency", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv8X2QsoiQWPj4JwLb%2Fseq-rerun-horrible-lhc-inconsistency", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 152, "htmlBody": "<p>Today's post, <a href=\"/lw/u6/horrible_lhc_inconsistency/\">Horrible LHC Inconsistency</a> was originally published on 22 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Horrible_LHC_Inconsistency\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>An illustration of inconsistent probability assignments.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ect/seq_rerun_how_many_lhc_failures_is_too_many/\">How Many LHC Failures Is Too Many?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v8X2QsoiQWPj4JwLb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.789374641372704e-07, "legacy": true, "legacyId": "18619", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ziqL94sq6rMuH7wDu", "eWZEBte5THEbE2Lte", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T06:21:49.057Z", "modifiedAt": null, "url": null, "title": "Illustration proposal for Methods of Rationality", "slug": "illustration-proposal-for-methods-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.838Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SREgKA52mntxvpJix/illustration-proposal-for-methods-of-rationality", "pageUrlRelative": "/posts/SREgKA52mntxvpJix/illustration-proposal-for-methods-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/SREgKA52mntxvpJix/illustration-proposal-for-methods-of-rationality", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Illustration%20proposal%20for%20Methods%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIllustration%20proposal%20for%20Methods%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSREgKA52mntxvpJix%2Fillustration-proposal-for-methods-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Illustration%20proposal%20for%20Methods%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSREgKA52mntxvpJix%2Fillustration-proposal-for-methods-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSREgKA52mntxvpJix%2Fillustration-proposal-for-methods-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p>Which scenes in the book should be illustrated, according to your point of view? Could you share your opinion, because it can help potential illustrators to choose theme and to draw something. It would be great if you can propose several scenes from the book. I believe we should find at least one good moment to be illustrated in the each chapter with combined efforts.</p>\n<p>I think the book will get more illustrations if people can simply choose from the list of proposed scenes, and not from the whole book.</p>\n<p>If you notice someone with the same proposal you are thinking about, please support this proposal by commenting it with quoting. In this case I can later make a list of proposals with the number of people supporting each one. However, if someone have made several proposals, but you want to support only some of them, please cite only <span class=\"ajax ajax-full\">appropriate</span> proposals.</p>\n<p>Please also make new proposals as first level comments. Thank you in advance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SREgKA52mntxvpJix", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -4, "extendedScore": null, "score": 9.789884567510947e-07, "legacy": true, "legacyId": "18626", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T09:42:59.884Z", "modifiedAt": null, "url": null, "title": "Group rationality diary, 9/3/12", "slug": "group-rationality-diary-9-3-12", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.996Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cata", "createdAt": "2010-06-02T18:13:22.408Z", "isAdmin": false, "displayName": "cata"}, "userId": "X9jdpCokhLjCMZEc3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3xpqqjL8Khh47oDQt/group-rationality-diary-9-3-12", "pageUrlRelative": "/posts/3xpqqjL8Khh47oDQt/group-rationality-diary-9-3-12", "linkUrl": "https://www.lesswrong.com/posts/3xpqqjL8Khh47oDQt/group-rationality-diary-9-3-12", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20rationality%20diary%2C%209%2F3%2F12&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20rationality%20diary%2C%209%2F3%2F12%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xpqqjL8Khh47oDQt%2Fgroup-rationality-diary-9-3-12%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20rationality%20diary%2C%209%2F3%2F12%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xpqqjL8Khh47oDQt%2Fgroup-rationality-diary-9-3-12", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xpqqjL8Khh47oDQt%2Fgroup-rationality-diary-9-3-12", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<p style=\"text-align: start; \"><span style=\"text-align: justify;\">T</span><span style=\"color: #333333; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">his is the public group instrumental rationality diary for the week of September 3rd. It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<div id=\"entry_t3_drj\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<ul style=\"padding: 0px; line-height: 19px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Thanks to everyone who contributes!</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\"><a style=\"color: #8a8a8b;\" href=\"/lw/e6h/group_rationality_diary_82012/\">Previous diary</a>;&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">archive of prior diaries</a>.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3xpqqjL8Khh47oDQt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.790902494096742e-07, "legacy": true, "legacyId": "18629", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xLA6hZxviLRBHeaT3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T16:01:31.492Z", "modifiedAt": null, "url": null, "title": "Fiction recommendation: \"Spur\" by Phil Geusz", "slug": "fiction-recommendation-spur-by-phil-geusz", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.845Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LMPJTwsxXa8BsbT9j/fiction-recommendation-spur-by-phil-geusz", "pageUrlRelative": "/posts/LMPJTwsxXa8BsbT9j/fiction-recommendation-spur-by-phil-geusz", "linkUrl": "https://www.lesswrong.com/posts/LMPJTwsxXa8BsbT9j/fiction-recommendation-spur-by-phil-geusz", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fiction%20recommendation%3A%20%22Spur%22%20by%20Phil%20Geusz&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFiction%20recommendation%3A%20%22Spur%22%20by%20Phil%20Geusz%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLMPJTwsxXa8BsbT9j%2Ffiction-recommendation-spur-by-phil-geusz%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fiction%20recommendation%3A%20%22Spur%22%20by%20Phil%20Geusz%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLMPJTwsxXa8BsbT9j%2Ffiction-recommendation-spur-by-phil-geusz", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLMPJTwsxXa8BsbT9j%2Ffiction-recommendation-spur-by-phil-geusz", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<p>Our protagonist has accepted being cursed into the shape of a horse, taking the place of a wealthy man in exchange for luxuries and lots of monthly cash. The wealthy man dies - and to his horror, our hero finds he is still a horse. Events escalate, secrets are revealed, personal growth happens. While not exactly dedicated to Bayesianism or even just rationality, the climax involves the expression of a sentiment familiar to any reader of <a href=\"http://hpmor.com/\">HPMoR</a> who's gotten to the bits about dementors, and seems to express it quite well in terms readers more familiar with fantasy than science-fiction can appreciate, which could form a stepping-stone to dealing with the idea of existential risks in the real world.</p>\n<p>&nbsp;</p>\n<p>Discovered through <a href=\"http://www.flayrah.com/4215/review-spur-phil-geusz\">this review</a>. Available through <a href=\"http://www.lulu.com/shop/phil-geusz/spur/paperback/product-20144941.html\">Lulu</a> or <a href=\"http://www.amazon.com/dp/1612353924?tag=flayrah-20\">Amazon</a> for $15, or as a <a href=\"http://www.payloadz.com/go?id=1598450\">PDF</a> or <a href=\"http://www.payloadz.com/go?id=1598449\">HTML</a> ebook for $6.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LMPJTwsxXa8BsbT9j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -10, "extendedScore": null, "score": 9.792818260486525e-07, "legacy": true, "legacyId": "18630", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T18:46:50.440Z", "modifiedAt": null, "url": null, "title": "September 2012 Media Thread", "slug": "september-2012-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:02.632Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Rgvk7iv63Ysbs8YaS/september-2012-media-thread", "pageUrlRelative": "/posts/Rgvk7iv63Ysbs8YaS/september-2012-media-thread", "linkUrl": "https://www.lesswrong.com/posts/Rgvk7iv63Ysbs8YaS/september-2012-media-thread", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20September%202012%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeptember%202012%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgvk7iv63Ysbs8YaS%2Fseptember-2012-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=September%202012%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgvk7iv63Ysbs8YaS%2Fseptember-2012-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgvk7iv63Ysbs8YaS%2Fseptember-2012-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 220, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">This is the monthly thread for posting media of various types that you've found that you enjoy. I find that exposure to LW ideas makes me less likely to enjoy some entertainment media that is otherwise quite popular, and finding media recommended by LWers is a good way to mitigate this. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the&nbsp;</span><a style=\"color: #8a8a8b;\" href=\"/r/discussion/tag/media_thread/\">older threads</a><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Rules:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees for genres. There is a meta thread for comments about future threads.</li>\n<li>If you have a thread to add, such as a video game thread or an Anime thread, please post it to the Other Media thread for now, and add a poll to the Meta thread asking if it should be a thread every month.</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Rgvk7iv63Ysbs8YaS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 9.793655150155372e-07, "legacy": true, "legacyId": "18631", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 84, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-04T18:54:47.231Z", "modifiedAt": null, "url": null, "title": "How to Find a Personal Assistant to Produce More? Transhumanism", "slug": "how-to-find-a-personal-assistant-to-produce-more", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:27.955Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p9EBxoYDnchexGR2W/how-to-find-a-personal-assistant-to-produce-more", "pageUrlRelative": "/posts/p9EBxoYDnchexGR2W/how-to-find-a-personal-assistant-to-produce-more", "linkUrl": "https://www.lesswrong.com/posts/p9EBxoYDnchexGR2W/how-to-find-a-personal-assistant-to-produce-more", "postedAtFormatted": "Tuesday, September 4th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Find%20a%20Personal%20Assistant%20to%20Produce%20More%3F%20Transhumanism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Find%20a%20Personal%20Assistant%20to%20Produce%20More%3F%20Transhumanism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp9EBxoYDnchexGR2W%2Fhow-to-find-a-personal-assistant-to-produce-more%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Find%20a%20Personal%20Assistant%20to%20Produce%20More%3F%20Transhumanism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp9EBxoYDnchexGR2W%2Fhow-to-find-a-personal-assistant-to-produce-more", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp9EBxoYDnchexGR2W%2Fhow-to-find-a-personal-assistant-to-produce-more", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 383, "htmlBody": "<p>I want to be stronger.</p>\n<p>I want to outsource my weaknesses to those who are strong at them, and intake the workload that my strengths can take.</p>\n<p>Like Tim Ferriss and A.J. Jacobs, I'd like to have someone working in synergy with me, to increase our productivity a lot.</p>\n<p>....and I funded and direct an institute in Brazil (<a title=\"IERFH\" href=\"http://www.ierfh.org\">www.ierfh.org</a> google chrome for translation) which aims in the general direction of Less Wrong folk orientation. Institute Ethics Rationality and Future of Humanity.</p>\n<p>We work mostly in two broad areas: Transhumanism and Effective Altruism. We are currently outreaching and filtering people who are motivated smart and altruistic (it is ok to be altruistic only towards one future self). Some are researching and lecturing.&nbsp; Since February last, we grew to 31 members, more than I'd expect be interested on topics in the whole of Brazil, so that was great!</p>\n<p>Here is the catch, because I live in Brazil, the assistant does not need to be in India! Nor cost as much as in the US!</p>\n<p>But then which are the best places to find someone with this <a href=\"/lw/9j2/the_singularity_institute_is_hiring_an_executive/\">set of characteristics</a> that Luke Muelhauser was looking for in his assistants?&nbsp; (link to my portuguese facebook share <a href=\"http://www.facebook.com/gdiego.vichutilitarian/posts/349182458498891\">http://www.facebook.com/gdiego.vichutilitarian/posts/349182458498891</a>)</p>\n<p>Ultrasummary of abilities: Very good English command, goals that either pro-technology or pro-effective giving, minimally rational, somewhat rich (there is a niche of people who work to feel fulfilled more than for money, in Brazil, this correlates strongly with good english skills and all the abilities social class can buy),&nbsp; <em>able to think by themselves when given tasks as abstract as </em>\"Find contact info of 5 researchers on happiness who published in 2010-2012, ask them whether they would like to jointly publish on topic x, tell me their thoughts.\"</p>\n<p>How would you go about finding yourself/your institute an assistant? How to optimize for above-mentioned criteria?&nbsp;</p>\n<p>Suppose my current strategy is posting job positions in undergrad walls. Can you improve it?</p>\n<p>PS: technically this is not exactly an offer, because I know all Brazilians in Less Wrong, but <em>if you feel like moving</em> to S&atilde;o Paulo and would like to take the job, please do tell me! I recently met a Less Wrong couple going to Australia to optimize for beautiful landscapes. Coming here means optimizing for social relaxing environment, cuddly happy huggy people, and delicious yet quite expensive food.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p9EBxoYDnchexGR2W", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -6, "extendedScore": null, "score": -4e-06, "legacy": true, "legacyId": "18632", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Lz64onM6tkynPKh5R"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T04:51:51.642Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] That Tiny Note of Discord", "slug": "seq-rerun-that-tiny-note-of-discord", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.019Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5EMAbWwRHRnbT8oJF/seq-rerun-that-tiny-note-of-discord", "pageUrlRelative": "/posts/5EMAbWwRHRnbT8oJF/seq-rerun-that-tiny-note-of-discord", "linkUrl": "https://www.lesswrong.com/posts/5EMAbWwRHRnbT8oJF/seq-rerun-that-tiny-note-of-discord", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20That%20Tiny%20Note%20of%20Discord&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20That%20Tiny%20Note%20of%20Discord%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5EMAbWwRHRnbT8oJF%2Fseq-rerun-that-tiny-note-of-discord%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20That%20Tiny%20Note%20of%20Discord%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5EMAbWwRHRnbT8oJF%2Fseq-rerun-that-tiny-note-of-discord", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5EMAbWwRHRnbT8oJF%2Fseq-rerun-that-tiny-note-of-discord", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<p>Today's post, <a href=\"/lw/u7/that_tiny_note_of_discord/\">That Tiny Note of Discord</a> was originally published on 23 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#That_Tiny_Note_of_Discord\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Eliezer started to dig himself out of his philosophical hole when he noticed a tiny inconsistency.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ed7/seq_rerun_horrible_lhc_inconsistency/\">Horrible LHC Inconsistency</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5EMAbWwRHRnbT8oJF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.796719064484938e-07, "legacy": true, "legacyId": "18635", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SwCwG9wZcAzQtckwx", "v8X2QsoiQWPj4JwLb", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T11:27:33.449Z", "modifiedAt": null, "url": null, "title": "Politics Discussion Thread September 2012", "slug": "politics-discussion-thread-september-2012", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:27.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Multiheaded", "createdAt": "2011-07-02T10:10:20.692Z", "isAdmin": false, "displayName": "Multiheaded"}, "userId": "moGiw35FowgiAnzfg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tkt2AC4dqo3YNuvMN/politics-discussion-thread-september-2012", "pageUrlRelative": "/posts/tkt2AC4dqo3YNuvMN/politics-discussion-thread-september-2012", "linkUrl": "https://www.lesswrong.com/posts/tkt2AC4dqo3YNuvMN/politics-discussion-thread-september-2012", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Politics%20Discussion%20Thread%20September%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APolitics%20Discussion%20Thread%20September%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftkt2AC4dqo3YNuvMN%2Fpolitics-discussion-thread-september-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Politics%20Discussion%20Thread%20September%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftkt2AC4dqo3YNuvMN%2Fpolitics-discussion-thread-september-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftkt2AC4dqo3YNuvMN%2Fpolitics-discussion-thread-september-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">The <a href=\"/lw/dwa/politics_discussion_thread_august_2012\">last thread</a> didn't fare too badly, I think; let's make it a monthly tradition. (Me, I'm more interested in thinking about real-world policies or philosophies, actual and possible, rather than AI design or physics, and I suspect that many fine, non-mind-killed folks reading LW also are - but might be ashamed to admit it!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Quoth OrphanWilde:</p>\n<ol>\n<li><em>Top-level comments should introduce arguments; responses should be responses to those arguments.&nbsp; </em></li>\n<li><em>Upvote and downvote based on whether or not you find an argument convincing in the context in which it was raised. &nbsp;This means if it's a good argument against the argument it is responding to, not whether or not there's a good/obvious counterargument to it; if you have a good counterargument, raise it. &nbsp;If it's a convincing argument, and the counterargument is also convincing, upvote both. &nbsp;If both arguments are unconvincing, downvote both.&nbsp; </em></li>\n<li><em>A single argument per comment would be ideal; as MixedNuts points out&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/dsv/is_politics_the_mindkiller_an_inconclusive_test/73yp\">here</a>, it's otherwise hard to distinguish between one good and one bad argument, which makes the upvoting/downvoting difficult to evaluate.&nbsp; </em></li>\n<li><em>In general try to avoid color politics; try to discuss political issues, rather than political parties, wherever possible.</em></li>\n</ol>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Let's try to stick to those rules - and maybe make some more if sorely needed.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Oh, and I think that the \"Personal is Political\" stuff like gender relations, etc also belongs here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tkt2AC4dqo3YNuvMN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 2, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "18646", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 198, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MnnPHuah4fh8K5pif"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T11:59:52.173Z", "modifiedAt": null, "url": null, "title": "\u201cPickled Stewberries!\u201d in HPMoR, Omake #3", "slug": "pickled-stewberries-in-hpmor-omake-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:22.727Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jost", "createdAt": "2012-06-23T12:35:00.581Z", "isAdmin": false, "displayName": "Jost"}, "userId": "exmf7eMBRCBnQhWt5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZMZiZmBBvSa2RQfFk/pickled-stewberries-in-hpmor-omake-3", "pageUrlRelative": "/posts/ZMZiZmBBvSa2RQfFk/pickled-stewberries-in-hpmor-omake-3", "linkUrl": "https://www.lesswrong.com/posts/ZMZiZmBBvSa2RQfFk/pickled-stewberries-in-hpmor-omake-3", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%E2%80%9CPickled%20Stewberries!%E2%80%9D%20in%20HPMoR%2C%20Omake%20%233&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%E2%80%9CPickled%20Stewberries!%E2%80%9D%20in%20HPMoR%2C%20Omake%20%233%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMZiZmBBvSa2RQfFk%2Fpickled-stewberries-in-hpmor-omake-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%E2%80%9CPickled%20Stewberries!%E2%80%9D%20in%20HPMoR%2C%20Omake%20%233%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMZiZmBBvSa2RQfFk%2Fpickled-stewberries-in-hpmor-omake-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMZiZmBBvSa2RQfFk%2Fpickled-stewberries-in-hpmor-omake-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<p>We're currently translating <a href=\"http://hpmor.com/chapter/11\">chapter 11</a> into German. It's going along fine, but&nbsp;</p>\n<blockquote>\n<p>&ldquo;PICKLED STEWBERRIES!&rdquo;</p>\n</blockquote>\n<p>is still puzzling us. No dictionary entries, no HPMoR-unrelated search hits, nothing&hellip;</p>\n<p>Is this some kind of dadaist joke by Eliezer? Or are we missing something?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZMZiZmBBvSa2RQfFk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -1, "extendedScore": null, "score": 9.798883508236146e-07, "legacy": true, "legacyId": "18647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T12:01:21.859Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup", "slug": "meetup-brussels-meetup-5", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:38.741Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EbeGTMPQ4aWeqwGh6/meetup-brussels-meetup-5", "pageUrlRelative": "/posts/EbeGTMPQ4aWeqwGh6/meetup-brussels-meetup-5", "linkUrl": "https://www.lesswrong.com/posts/EbeGTMPQ4aWeqwGh6/meetup-brussels-meetup-5", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEbeGTMPQ4aWeqwGh6%2Fmeetup-brussels-meetup-5%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEbeGTMPQ4aWeqwGh6%2Fmeetup-brussels-meetup-5", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEbeGTMPQ4aWeqwGh6%2Fmeetup-brussels-meetup-5", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/di'>Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 September 2012 12:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u00e9' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/di'>Brussels meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EbeGTMPQ4aWeqwGh6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.798895164763739e-07, "legacy": true, "legacyId": "18648", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup\">Discussion article for the meetup : <a href=\"/meetups/di\">Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 September 2012 12:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u00e9' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup1\">Discussion article for the meetup : <a href=\"/meetups/di\">Brussels meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T13:27:23.623Z", "modifiedAt": null, "url": null, "title": "Meetup : Longmont Colorado Meetup", "slug": "meetup-longmont-colorado-meetup-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H39cnZhakesD5Q45m/meetup-longmont-colorado-meetup-1", "pageUrlRelative": "/posts/H39cnZhakesD5Q45m/meetup-longmont-colorado-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/H39cnZhakesD5Q45m/meetup-longmont-colorado-meetup-1", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Longmont%20Colorado%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Longmont%20Colorado%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH39cnZhakesD5Q45m%2Fmeetup-longmont-colorado-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Longmont%20Colorado%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH39cnZhakesD5Q45m%2Fmeetup-longmont-colorado-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH39cnZhakesD5Q45m%2Fmeetup-longmont-colorado-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dj'>Longmont Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Ziggis, 400 Main Street, Longmont, CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>South for 2 weeks.\nWhat's up for the fall.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dj'>Longmont Colorado Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H39cnZhakesD5Q45m", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.79933113992524e-07, "legacy": true, "legacyId": "18649", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Longmont_Colorado_Meetup\">Discussion article for the meetup : <a href=\"/meetups/dj\">Longmont Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Ziggis, 400 Main Street, Longmont, CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>South for 2 weeks.\nWhat's up for the fall.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Longmont_Colorado_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/dj\">Longmont Colorado Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Longmont Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Longmont_Colorado_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Longmont Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Longmont_Colorado_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T15:49:21.589Z", "modifiedAt": null, "url": null, "title": "Cryonics: Can I Take Door No. 3?", "slug": "cryonics-can-i-take-door-no-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:35.233Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Chris_Roberts", "createdAt": "2012-08-24T15:59:22.865Z", "isAdmin": false, "displayName": "Chris_Roberts"}, "userId": "E8RaYHbv4hpq8y9kh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9uxHWC4zfPBfWcPRZ/cryonics-can-i-take-door-no-3", "pageUrlRelative": "/posts/9uxHWC4zfPBfWcPRZ/cryonics-can-i-take-door-no-3", "linkUrl": "https://www.lesswrong.com/posts/9uxHWC4zfPBfWcPRZ/cryonics-can-i-take-door-no-3", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%3A%20Can%20I%20Take%20Door%20No.%203%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%3A%20Can%20I%20Take%20Door%20No.%203%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9uxHWC4zfPBfWcPRZ%2Fcryonics-can-i-take-door-no-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%3A%20Can%20I%20Take%20Door%20No.%203%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9uxHWC4zfPBfWcPRZ%2Fcryonics-can-i-take-door-no-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9uxHWC4zfPBfWcPRZ%2Fcryonics-can-i-take-door-no-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 468, "htmlBody": "<p>If you don't believe in an afterlife, then it seems you currently have two choices: cryonics or permanent death.&nbsp; Now, I don't believe that cryonics is pseudoscience, but it's still pretty poor odds (Robin Hanson uses an estimate of 5% <a href=\"http://www.overcomingbias.com/2009/03/break-cryonics-down.html\" target=\"_blank\">here</a>).&nbsp;&nbsp;Unfortunately, the alternative offers a chance of zero.&nbsp; I see five main concerns with current cryonic technology:</p>\r\n<ol>\r\n<li>There is no proven revival technology, thus no estimate of costs</li>\r\n<li>Potential damage done during vitrification which must be overcome</li>\r\n<li>Because it cannot be legally done before death, potential decay between legal death and vitrification</li>\r\n<li>Requires active maintenance at very low temperature</li>\r\n<li>No guarantee that future societies will be willing to revive</li>\r\n</ol>\r\n<p>So I wonder if we can do better.</p>\r\n<p>I recall reading of juvenile forms of amphibians in desert environments that could survive for decades of drought&nbsp;in a dormant form, reviving when water returned.&nbsp; One specimen had sat on a shelf in a research office for over a century (in Arizona, if I recall correctly) and was successfully revived.&nbsp; Note: no particular efforts were made to maintain this specimen: the dry local climate was sufficient.&nbsp; It was suggested at the time that this could make an alternative method of preserving organs.&nbsp; Now the advantages of this approach (which I refer to flippantly as \"dryonics\") is:</p>\r\n<ol>\r\n<li>Proven, inexpensive&nbsp;revival technology</li>\r\n<li>Apparently the process does not cause damage itself</li>\r\n<li>Proven revival technique may overcome legal obstacles of applying before legal death</li>\r\n<li>Requires passive maintenance at low humidity (deserts would be ideal)</li>\r\n<li>Presumably lower cost makes future revival more likely (still no guarantee, but that is a <a href=\"/lw/6ki/can_cryonicallyfrozen_people_really_expect_to_be/\">post </a>in itself)</li>\r\n</ol>\r\n<p>There is one big disadvantage of this approach, of course: no one knows how to do it (it's not entirely clear how the juvenile amphibians do it) or even if it would be possible in larger, more complex organisms.&nbsp; And, so far as I know, no one is working on it.&nbsp; But it would seem to offer a much better prospect than our current options, so I would suggest it worth investigating.</p>\r\n<p>I am not a biologist, and I'm not sure where one would start developing such a technology.&nbsp; I frankly admit that I am sharing this in the hope that someone who does have an idea will run with it.&nbsp; If anyone knows of any work on these lines, or has an idea how to proceed, please send a comment or email.&nbsp; Or even if you have another alternative.&nbsp; Because right now, I don't consider our prospects good.</p>\r\n<p>[Note: I am going on memory in this post; I really wish I could provide references, but there does not seem much activity along these lines that I can find.&nbsp; I'm not even sure what to call it: mummification?&nbsp;&nbsp;Probably too scary.&nbsp; Dehydration?&nbsp; Anyway&nbsp;feel free to add suggestions or link references.]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9uxHWC4zfPBfWcPRZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 5, "extendedScore": null, "score": 9.800050662963176e-07, "legacy": true, "legacyId": "18651", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 113, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Cp2rHsZoQDoba3Pww"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T15:55:53.054Z", "modifiedAt": null, "url": null, "title": "Debugging the Quantum Physics Sequence ", "slug": "debugging-the-quantum-physics-sequence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:38.570Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mitchell_Porter", "createdAt": "2009-05-28T02:36:19.394Z", "isAdmin": false, "displayName": "Mitchell_Porter"}, "userId": "fjERoRhgjipqw3z2b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ueQBEaY6a7n5hDeWP/debugging-the-quantum-physics-sequence", "pageUrlRelative": "/posts/ueQBEaY6a7n5hDeWP/debugging-the-quantum-physics-sequence", "linkUrl": "https://www.lesswrong.com/posts/ueQBEaY6a7n5hDeWP/debugging-the-quantum-physics-sequence", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Debugging%20the%20Quantum%20Physics%20Sequence%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADebugging%20the%20Quantum%20Physics%20Sequence%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FueQBEaY6a7n5hDeWP%2Fdebugging-the-quantum-physics-sequence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Debugging%20the%20Quantum%20Physics%20Sequence%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FueQBEaY6a7n5hDeWP%2Fdebugging-the-quantum-physics-sequence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FueQBEaY6a7n5hDeWP%2Fdebugging-the-quantum-physics-sequence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 638, "htmlBody": "<p>This article should really be called \"Patching the argumentative flaw in the Sequences created by the Quantum Physics Sequence\".</p>\n<p>There's only one big thing wrong with that Sequence: the central factual claim is wrong. I don't mean the claim that the Many Worlds interpretation is correct; I mean the claim that the Many Worlds interpretation is <em>obviously</em> correct. I don't agree with the ontological claim either, but I especially don't agree with the epistemological claim. It's a strawman which reduces the quantum debate to Everett versus Bohr - well, it's not really Bohr, since Bohr didn't believe wavefunctions were physical entities. Everett versus Collapse, then.</p>\n<p>I've complained about this from the beginning, simply because I've also studied the topic and profoundly disagree with Eliezer's assessment. What I would like to see discussed on this occasion is not the physics, but rather how to patch the arguments in the Sequences that depend on this wrong sub-argument. To my eyes, this is a highly visible flaw, but it's not a deep one. It's a detail, a bug. Surely it affects nothing of substance.</p>\n<p>However, before I proceed, I'd better back up my criticism. So: consider the existence of single-world retrocausal interpretations of quantum mechanics, such as John Cramer's <a href=\"http://en.wikipedia.org/wiki/Transactional_interpretation\">transactional interpretation</a>, which is descended from <a href=\"http://en.wikipedia.org/wiki/Wheeler%E2%80%93Feynman_absorber_theory\">Wheeler-Feynman absorber theory</a>. There are no superpositions, only causal chains running forward in time and backward in time. The calculus of complex-valued probability amplitudes is supposed to arise from this.</p>\n<p>The existence of the retrocausal tradition already shows that the debate has been represented incorrectly; it should at least be Everett versus Bohr versus Cramer. I would also argue that when you look at the details, many-worlds has no discernible edge over single-world retrocausality:</p>\n<ul>\n<li> Relativity isn't an issue for the transactional interpretation: causality forwards and causality backwards are both local, it's the existence of loops in time which create the appearance of nonlocality. </li>\n<li>Retrocausal interpretations don't have an exact derivation of the Born rule, but neither does many-worlds. </li>\n<li>Many-worlds finds hope of such a derivation in a property of the quantum formalism: the resemblance of density matrix entries to probabilities. But single-world retrocausality finds such hope too: the Born probabilities can be obtained from the product of <em>&psi;</em> with <em>&psi;*</em>, its complex conjugate, and <em>&psi;* </em>is the time reverse of <em>&psi;.&nbsp;</em></li>\n<li>Loops in time just fundamentally bug some people, but splitting worlds have the same effect on others. </li>\n</ul>\n<p>I am not especially an advocate of retrocausal interpretations. They are among the possibilities; they deserve consideration and they get it. Retrocausality may or may not be an element of the real explanation of why quantum mechanics works. Progress towards the discovery of the truth requires exploration on many fronts, that's happening, we'll get there eventually. I have focused on retrocausal interpretations here just because they offer the clearest evidence that the big picture offered by the Sequence is wrong.</p>\n<p>It's hopeless to suggest rewriting the Sequence, I don't think that would be a good use of anyone's time. But what I <em>would</em> like to have, is a clear idea of the role that \"the winner is ... Many Worlds!\" plays in the overall flow of argument, in the great meta-sequence that is Less Wrong's foundational text; and I would also like to have a clear idea of how to patch the argument, so that it routes around this flaw.</p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/Sequences#The_Quantum_Physics_Sequence\">In the wiki, it states that </a>\"Cleaning up the old confusion about QM is used to introduce basic issues in rationality (such as the technical version of Occam's Razor), epistemology, reductionism, naturalism, and philosophy of science.\" So there we have it - a synopsis of the function that this Sequence is supposed to perform. Perhaps we need a working group that will identify each of the individual arguments, and come up with a substitute for each one.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "csMv9MvvjYJyeHqoo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ueQBEaY6a7n5hDeWP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 43, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "18652", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 130, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-05T21:11:06.174Z", "modifiedAt": null, "url": null, "title": "LessWrong Wiki as Anki deck", "slug": "lesswrong-wiki-as-anki-deck", "viewCount": null, "lastCommentedAt": "2022-01-31T18:17:17.735Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mapnoterritory", "createdAt": "2012-03-14T20:44:02.961Z", "isAdmin": false, "displayName": "mapnoterritory"}, "userId": "EvXiCAYEyRqnXMWAD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xd8aQsZroPYN4CZXM/lesswrong-wiki-as-anki-deck", "pageUrlRelative": "/posts/Xd8aQsZroPYN4CZXM/lesswrong-wiki-as-anki-deck", "linkUrl": "https://www.lesswrong.com/posts/Xd8aQsZroPYN4CZXM/lesswrong-wiki-as-anki-deck", "postedAtFormatted": "Wednesday, September 5th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LessWrong%20Wiki%20as%20Anki%20deck&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALessWrong%20Wiki%20as%20Anki%20deck%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd8aQsZroPYN4CZXM%2Flesswrong-wiki-as-anki-deck%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LessWrong%20Wiki%20as%20Anki%20deck%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd8aQsZroPYN4CZXM%2Flesswrong-wiki-as-anki-deck", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXd8aQsZroPYN4CZXM%2Flesswrong-wiki-as-anki-deck", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p>I've ported the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/LessWrong_Wiki\">Less Wrong Wiki</a>&nbsp;into an Anki deck. I hope this will&nbsp;be useful for new members as an alternative way to get acquainted with&nbsp;many interesting LessWrong concepts (Newcomb's problem?&nbsp;Superexponential conceptspace?).</p>\n<p>A disclaimer: this an automatized scrape and therefore it might not&nbsp;always look great. In particular lot's of cards don't really conform&nbsp;the \"simple and specific\" rules for spaced repetition cards (see&nbsp;e.g. http://www.supermemo.com/articles/20rules.htm) - the deck it is thus not meant for memorizing the definitions, but rather for reading/browsing/recognizing the concepts. Nonetheless, I&nbsp;hope this still will be useful for some of us (certainly for me).&nbsp;</p>\n<p>I did a semi-automatic sanitization of the cards, but if you find some&nbsp;bogus ones (or any other problem) please let me know and I'll fix it.</p>\n<p>The scraped Wiki version is from 01/09/2012 and there are currently&nbsp;628 cards. There are \"forward\" format cards (name front, description&nbsp;back) and also \"reverse\" cards (in cloze format where it was possible,&nbsp;i.e. where the concept name comes up in the description text).</p>\n<p>The deck is here:</p>\n<p>https://docs.google.com/folder/d/0B6GcntZeZpBHVjRkVUE2Uko2Vk0/edit</p>\n<p>The link also contains a .txt version of the cards (tab separated)&nbsp;which might be used to import to other repetition software than Anki.</p>\n<p>The deck can be supplemented e.g. by the \"List of Cognitive Biases and&nbsp;Fallacies\" and \"42 Logical Fallacies\" decks as well as other decks&nbsp;mentioned on the <a href=\"http://wiki.lesswrong.com/wiki/Spaced_repetition\">spaced repetition wiki page</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xd8aQsZroPYN4CZXM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 13, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "18654", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T00:09:45.564Z", "modifiedAt": null, "url": null, "title": "Cleaning up the \"Worst Argument\" essay", "slug": "cleaning-up-the-worst-argument-essay", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:26.498Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TyQSMmoJpRG3HBv5S/cleaning-up-the-worst-argument-essay", "pageUrlRelative": "/posts/TyQSMmoJpRG3HBv5S/cleaning-up-the-worst-argument-essay", "linkUrl": "https://www.lesswrong.com/posts/TyQSMmoJpRG3HBv5S/cleaning-up-the-worst-argument-essay", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cleaning%20up%20the%20%22Worst%20Argument%22%20essay&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACleaning%20up%20the%20%22Worst%20Argument%22%20essay%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyQSMmoJpRG3HBv5S%2Fcleaning-up-the-worst-argument-essay%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cleaning%20up%20the%20%22Worst%20Argument%22%20essay%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyQSMmoJpRG3HBv5S%2Fcleaning-up-the-worst-argument-essay", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyQSMmoJpRG3HBv5S%2Fcleaning-up-the-worst-argument-essay", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1623, "htmlBody": "<p><em>There was a lot of controversy over the Worst Argument essay, which surprised me because the basic point seems hard to argue with. I'd like to change it in response to feedback, with the new title \"Guilt by Association\". Below is the rough draft for the new version, minus a few links and other finishing touches. Please let me know whether you think it is better or worse than the original, and what specific further changes you think that it needs.</em></p>\n<p>&nbsp;</p>\n<p>David Stove once <a href=\"http://web.maths.unsw.edu.au/%7Ejim/worst.html\">ran a contest</a> to find the Worst Argument In The World, but he awarded the prize to his own entry, and one that shored up his politics to boot. It hardly seems like an objective process.</p>\n<p>If he can unilaterally declare a worst argument, then so can I. I declare the Worst Argument In The World to be Guilt By Association: \"If we can apply a word to something, we must judge it the same as we judge more prototypical instances of that word.\"<br /><br />Well, it sounds dumb when you put it like that. Who even does that, anyway?<br /><br />Suppose someone wants to build a statue honoring Martin Luther King Jr. for his nonviolent resistance to racism. An opponent of the statue objects: \"But Martin Luther King was a <em>criminal</em>!\"<br /><br />Any historian can confirm this is correct. A criminal is technically someone who breaks the law, and King knowingly broke a law against peaceful anti-segregation protest - hence his famous Letter from Birmingham Jail.<br /><br />But in this case calling Martin Luther King a criminal is Guilt by Association. The archetypal criminal is a mugger or bank robber. He is driven only by greed, preys on the innocent, and weakens the fabric of society. We don't like criminals precisely because we don't like greed and preying on innocents and weakening the fabric of society. <br /><br />The opponent is saying \"Because you don't like criminals, and Martin Luther King is a criminal, you should stop liking Martin Luther King.\" But King doesn't share any of the features that made us dislike criminals in the first place. Therefore, even though he is a criminal, there is no reason to dislike King. The force of the opponent's argument comes solely from the category \"criminal\" <em>associating</em> King with people who are bad.&nbsp; It totally fails to prove King was bad himself.</p>\n<p>This all seems so nice and logical when it's presented in this format. Unfortunately, it's also one hundred percent contrary to instinct: the urge is to respond \"Martin Luther King? A criminal? No he wasn't! You take that back!\" This is why the Worst Argument In The World is so successful. As soon as you do that you've fallen into their trap. Your argument is no longer about whether you should build a statue, it's about whether King was a criminal. Since he was, you have now lost the argument.</p>\n<p>Ideally, you should just be able to say \"Well, King was the good kind of criminal.\" But that seems pretty tough as a debating maneuver in real life. Let's look at some political arguments that I think typify Guilt by Association.</p>\n<p><strong>I</strong></p>\n<p>On my way to work every day, I used to pass a sign reading <strong>\"ABORTION IS MURDER\"</strong> The archetypal murder is Charles Manson breaking into your house and shooting you. This sort of murder is bad for at least four reasons: you prefer not to die, you have various thoughts and hopes and dreams that would be snuffed out, your family and friends would be heartbroken, and the rest of society has to live in fear until Manson gets caught. If you define murder as \"killing another human being\", then abortion is technically murder. But it has none of the downsides of murder Charles Manson style.</p>\n<p>If your objection to murder is predicated entirely upon the four reasons above, then abortion might qualify as \"murder\", but it doesn't share any of the characteristics that make you object to murder of the usual sort. The argument is entirely associative: \"Look over there in, that bin marked 'MURDER'. Charles Manson and an abortion doctor! The one is standing <em>suspiciously</em> close to the other, don't you think?\"</p>\n<p>(some people have tried to solve this problem by defining \"murder\" as \"the unlawful killing of a human being\" and then pointing out that abortion is legal. This is exactly as clever as redefining \"criminal\" to mean \"a person who breaks the law but is not Martin Luther King.\" Cut out the fallacy at its root, not at its branches!)</p>\n<p>This argument is relatively clear-cut, but other real world arguments are more complicated.</p>\n<p><strong>II</strong></p>\n<p>Whenever the airports consider singling out people of Middle Eastern descent for extra security checks, someone is bound to object that <strong>\"Racial profiling is <em>racist</em></strong>.<strong>\" </strong>This is true if we define racism as \"discriminating based on a person's race\". But why do we have a negative reaction to racism in the first place? Well, the prototypical example of racism is the KKK burning crosses in front of black people's houses. This kind of racism has many obvious problems. It's usually based on scientifically inaccurate generalizations about the moral or intellectual value of different groups. It often leads to violence, hate crimes, verbal abuse, or other traumatic experiences. It keeps whole groups of people from achieving their full potential. And it can be belittling and offensive to the people involved.</p>\n<p>Let's stick with these four reasons for our discussion, although obviously there are more. Racial profiling seems to avoid the first three sins of racism, but it definitely hits the fourth. So to object that racial profiling is racist could be either useful or fallacious depending on the intent. If the intent were to remind people that racial profiling, like KKK cross burning, can be belittling and offensive, then that's a worthy goal. If the intent were to stick racial profiling in a bin with Hitler, David Duke, Francis Galton, and the people who bombed the Baptist Church in Birmingham - and then say \"Look what company it keeps!\", then it's a fallacy. Racial profiling isn't empirically false, isn't violent, and doesn't keep groups of people down. When we hear it called \"racist\", most of the revulsion we naturally hear at the word should be dismissed as irrelevant to this particular case.</p>\n<p>There are a lot of ways to mention that racial profiling is belittling and offensive without using the r-word; for example, you could say \"Racial profiling is belittling and offensive.\" This conveys the one accurate point of \"Racial profiling is <em>racist</em>\" without the extra baggage. While using the latter sentence would not be provably wrong, one would have to wonder about the motives.</p>\n<p><strong>III</strong></p>\n<p>In some situations that are even less clear cut, I still think I can see Guilt by Association peeking through.</p>\n<p>Consider the common refrain that <strong>\"Capital punishment is <em>murder</em>\"</strong>. Here most of our objections to Charles Manson really do hold. Capital punishment kills someone who doesn't want to die. It cuts short their hopes and dreams. It disappoints the victim's family and friends. And maybe it does make other people live in fear, either because they've got a hidden criminal record or because they know it has a gruesome history of occasionally killing the falsely accused.</p>\n<p>But I <em>still</em> don't think this is a good argument. Mansonesque murder has few if any benefits. Capital punishment arguably has more - some people think it decreases the crime rate, and at the very least it makes crime victims and their families breath a sigh of relief. Do the benefits outweigh the costs? I don't know. But taking something with both costs and benefits and then placing it next to something that only has costs and saying \"Look! It's exactly like this thing here!\" misses the entire point of the argument. If you want to argue that the costs are worse than the benefits, argue that - don't say \"It looks suspiciously like something else that has no benefits at all!\"</p>\n<p><strong>IV</strong></p>\n<p>In an earlier version of this post, some people mistook Guilt by Association for a blanket condemnation of any argument from category membership. I don't think things are quite that bad. Discussing category memberships sometimes insightfully point out double standards. For example, if a racist said we should kill all the Canadians, one might respond: \"<strong>Canadians are <em>people</em> too</strong>!\" This would be a challenge for the racist to point out exactly why they believe Canadians lack the features that usually make us think killing people are bad, or what special quality Canadians have that outweighs those features.</p>\n<p>Perhaps the best explanation of the difference is that accusing someone of Guilt by Association is an invitation to play Rationalist Taboo. It may be they can taboo the emotionally charged category names and still make the argument. Or it may be that the argument instantly falls flat.</p>\n<p>But overall I would recommend avoiding this entire style of discourse. Anything valuable you can do with category memberships you can do in a less sweeping way by just saying what you mean (see the \"Racial profiling is belittling and offensive\" example above.) And anything you <em>can't </em>do in a less sweeping way probably shouldn't be said at all, with honorable exceptions for people who are consciously making arguments from Schelling fences.</p>\n<p><strong>V</strong></p>\n<p>Are the following examples of Guilt By Association? Are they of the first, second, or third type? Or are they totally legitimate?</p>\n<p>1. Efforts to cure hereditary diseases through genetic engineering are <em>eugenics</em>.</p>\n<p>2. Evolutionary psychology is <em>sexist</em>.</p>\n<p>3. Euthanasia is <em>murder</em>.</p>\n<p>4. Marijuana is <em>a drug.</em></p>\n<p>5. Taxation is <em>theft</em>.</p>\n<p>6. Prescription medications are <em>poison.</em></p>\n<p>7. Affirmative action is <em>discriminatory</em>.</p>\n<p>8. Someone who had sex with a 16 year old when he was 18 is <em>a sex offender</em>.</p>\n<p>9. Radical environmentalism is <em>a religion</em>.</p>\n<p>10. Mormonism is <em>a cult.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TyQSMmoJpRG3HBv5S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 20, "extendedScore": null, "score": 9.80258757050782e-07, "legacy": true, "legacyId": "18655", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>There was a lot of controversy over the Worst Argument essay, which surprised me because the basic point seems hard to argue with. I'd like to change it in response to feedback, with the new title \"Guilt by Association\". Below is the rough draft for the new version, minus a few links and other finishing touches. Please let me know whether you think it is better or worse than the original, and what specific further changes you think that it needs.</em></p>\n<p>&nbsp;</p>\n<p>David Stove once <a href=\"http://web.maths.unsw.edu.au/%7Ejim/worst.html\">ran a contest</a> to find the Worst Argument In The World, but he awarded the prize to his own entry, and one that shored up his politics to boot. It hardly seems like an objective process.</p>\n<p>If he can unilaterally declare a worst argument, then so can I. I declare the Worst Argument In The World to be Guilt By Association: \"If we can apply a word to something, we must judge it the same as we judge more prototypical instances of that word.\"<br><br>Well, it sounds dumb when you put it like that. Who even does that, anyway?<br><br>Suppose someone wants to build a statue honoring Martin Luther King Jr. for his nonviolent resistance to racism. An opponent of the statue objects: \"But Martin Luther King was a <em>criminal</em>!\"<br><br>Any historian can confirm this is correct. A criminal is technically someone who breaks the law, and King knowingly broke a law against peaceful anti-segregation protest - hence his famous Letter from Birmingham Jail.<br><br>But in this case calling Martin Luther King a criminal is Guilt by Association. The archetypal criminal is a mugger or bank robber. He is driven only by greed, preys on the innocent, and weakens the fabric of society. We don't like criminals precisely because we don't like greed and preying on innocents and weakening the fabric of society. <br><br>The opponent is saying \"Because you don't like criminals, and Martin Luther King is a criminal, you should stop liking Martin Luther King.\" But King doesn't share any of the features that made us dislike criminals in the first place. Therefore, even though he is a criminal, there is no reason to dislike King. The force of the opponent's argument comes solely from the category \"criminal\" <em>associating</em> King with people who are bad.&nbsp; It totally fails to prove King was bad himself.</p>\n<p>This all seems so nice and logical when it's presented in this format. Unfortunately, it's also one hundred percent contrary to instinct: the urge is to respond \"Martin Luther King? A criminal? No he wasn't! You take that back!\" This is why the Worst Argument In The World is so successful. As soon as you do that you've fallen into their trap. Your argument is no longer about whether you should build a statue, it's about whether King was a criminal. Since he was, you have now lost the argument.</p>\n<p>Ideally, you should just be able to say \"Well, King was the good kind of criminal.\" But that seems pretty tough as a debating maneuver in real life. Let's look at some political arguments that I think typify Guilt by Association.</p>\n<p><strong id=\"I\">I</strong></p>\n<p>On my way to work every day, I used to pass a sign reading <strong>\"ABORTION IS MURDER\"</strong> The archetypal murder is Charles Manson breaking into your house and shooting you. This sort of murder is bad for at least four reasons: you prefer not to die, you have various thoughts and hopes and dreams that would be snuffed out, your family and friends would be heartbroken, and the rest of society has to live in fear until Manson gets caught. If you define murder as \"killing another human being\", then abortion is technically murder. But it has none of the downsides of murder Charles Manson style.</p>\n<p>If your objection to murder is predicated entirely upon the four reasons above, then abortion might qualify as \"murder\", but it doesn't share any of the characteristics that make you object to murder of the usual sort. The argument is entirely associative: \"Look over there in, that bin marked 'MURDER'. Charles Manson and an abortion doctor! The one is standing <em>suspiciously</em> close to the other, don't you think?\"</p>\n<p>(some people have tried to solve this problem by defining \"murder\" as \"the unlawful killing of a human being\" and then pointing out that abortion is legal. This is exactly as clever as redefining \"criminal\" to mean \"a person who breaks the law but is not Martin Luther King.\" Cut out the fallacy at its root, not at its branches!)</p>\n<p>This argument is relatively clear-cut, but other real world arguments are more complicated.</p>\n<p><strong id=\"II\">II</strong></p>\n<p>Whenever the airports consider singling out people of Middle Eastern descent for extra security checks, someone is bound to object that <strong>\"Racial profiling is <em>racist</em></strong>.<strong>\" </strong>This is true if we define racism as \"discriminating based on a person's race\". But why do we have a negative reaction to racism in the first place? Well, the prototypical example of racism is the KKK burning crosses in front of black people's houses. This kind of racism has many obvious problems. It's usually based on scientifically inaccurate generalizations about the moral or intellectual value of different groups. It often leads to violence, hate crimes, verbal abuse, or other traumatic experiences. It keeps whole groups of people from achieving their full potential. And it can be belittling and offensive to the people involved.</p>\n<p>Let's stick with these four reasons for our discussion, although obviously there are more. Racial profiling seems to avoid the first three sins of racism, but it definitely hits the fourth. So to object that racial profiling is racist could be either useful or fallacious depending on the intent. If the intent were to remind people that racial profiling, like KKK cross burning, can be belittling and offensive, then that's a worthy goal. If the intent were to stick racial profiling in a bin with Hitler, David Duke, Francis Galton, and the people who bombed the Baptist Church in Birmingham - and then say \"Look what company it keeps!\", then it's a fallacy. Racial profiling isn't empirically false, isn't violent, and doesn't keep groups of people down. When we hear it called \"racist\", most of the revulsion we naturally hear at the word should be dismissed as irrelevant to this particular case.</p>\n<p>There are a lot of ways to mention that racial profiling is belittling and offensive without using the r-word; for example, you could say \"Racial profiling is belittling and offensive.\" This conveys the one accurate point of \"Racial profiling is <em>racist</em>\" without the extra baggage. While using the latter sentence would not be provably wrong, one would have to wonder about the motives.</p>\n<p><strong id=\"III\">III</strong></p>\n<p>In some situations that are even less clear cut, I still think I can see Guilt by Association peeking through.</p>\n<p>Consider the common refrain that <strong>\"Capital punishment is <em>murder</em>\"</strong>. Here most of our objections to Charles Manson really do hold. Capital punishment kills someone who doesn't want to die. It cuts short their hopes and dreams. It disappoints the victim's family and friends. And maybe it does make other people live in fear, either because they've got a hidden criminal record or because they know it has a gruesome history of occasionally killing the falsely accused.</p>\n<p>But I <em>still</em> don't think this is a good argument. Mansonesque murder has few if any benefits. Capital punishment arguably has more - some people think it decreases the crime rate, and at the very least it makes crime victims and their families breath a sigh of relief. Do the benefits outweigh the costs? I don't know. But taking something with both costs and benefits and then placing it next to something that only has costs and saying \"Look! It's exactly like this thing here!\" misses the entire point of the argument. If you want to argue that the costs are worse than the benefits, argue that - don't say \"It looks suspiciously like something else that has no benefits at all!\"</p>\n<p><strong id=\"IV\">IV</strong></p>\n<p>In an earlier version of this post, some people mistook Guilt by Association for a blanket condemnation of any argument from category membership. I don't think things are quite that bad. Discussing category memberships sometimes insightfully point out double standards. For example, if a racist said we should kill all the Canadians, one might respond: \"<strong>Canadians are <em>people</em> too</strong>!\" This would be a challenge for the racist to point out exactly why they believe Canadians lack the features that usually make us think killing people are bad, or what special quality Canadians have that outweighs those features.</p>\n<p>Perhaps the best explanation of the difference is that accusing someone of Guilt by Association is an invitation to play Rationalist Taboo. It may be they can taboo the emotionally charged category names and still make the argument. Or it may be that the argument instantly falls flat.</p>\n<p>But overall I would recommend avoiding this entire style of discourse. Anything valuable you can do with category memberships you can do in a less sweeping way by just saying what you mean (see the \"Racial profiling is belittling and offensive\" example above.) And anything you <em>can't </em>do in a less sweeping way probably shouldn't be said at all, with honorable exceptions for people who are consciously making arguments from Schelling fences.</p>\n<p><strong id=\"V\">V</strong></p>\n<p>Are the following examples of Guilt By Association? Are they of the first, second, or third type? Or are they totally legitimate?</p>\n<p>1. Efforts to cure hereditary diseases through genetic engineering are <em>eugenics</em>.</p>\n<p>2. Evolutionary psychology is <em>sexist</em>.</p>\n<p>3. Euthanasia is <em>murder</em>.</p>\n<p>4. Marijuana is <em>a drug.</em></p>\n<p>5. Taxation is <em>theft</em>.</p>\n<p>6. Prescription medications are <em>poison.</em></p>\n<p>7. Affirmative action is <em>discriminatory</em>.</p>\n<p>8. Someone who had sex with a 16 year old when he was 18 is <em>a sex offender</em>.</p>\n<p>9. Radical environmentalism is <em>a religion</em>.</p>\n<p>10. Mormonism is <em>a cult.</em></p>", "sections": [{"title": "I", "anchor": "I", "level": 1}, {"title": "II", "anchor": "II", "level": 1}, {"title": "III", "anchor": "III", "level": 1}, {"title": "IV", "anchor": "IV", "level": 1}, {"title": "V", "anchor": "V", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "57 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T02:29:29.170Z", "modifiedAt": null, "url": null, "title": "Meetup : Predictions Chi September 15 (September 8 -- cancelled)", "slug": "meetup-predictions-chi-september-15-september-8-cancelled", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:35.241Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nic_Smith", "createdAt": "2009-10-23T03:32:46.312Z", "isAdmin": false, "displayName": "Nic_Smith"}, "userId": "XP9GcTgRGLBCnf9ih", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BFRGZhEg4MabxY8nH/meetup-predictions-chi-september-15-september-8-cancelled", "pageUrlRelative": "/posts/BFRGZhEg4MabxY8nH/meetup-predictions-chi-september-15-september-8-cancelled", "linkUrl": "https://www.lesswrong.com/posts/BFRGZhEg4MabxY8nH/meetup-predictions-chi-september-15-september-8-cancelled", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Predictions%20Chi%20September%2015%20(September%208%20--%20cancelled)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Predictions%20Chi%20September%2015%20(September%208%20--%20cancelled)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFRGZhEg4MabxY8nH%2Fmeetup-predictions-chi-september-15-september-8-cancelled%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Predictions%20Chi%20September%2015%20(September%208%20--%20cancelled)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFRGZhEg4MabxY8nH%2Fmeetup-predictions-chi-september-15-september-8-cancelled", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBFRGZhEg4MabxY8nH%2Fmeetup-predictions-chi-september-15-september-8-cancelled", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dk'>Predictions Chi September 15 (September 8 -- cancelled)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 September 2012 01:05:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1 S. Franklin St, Chicago, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Bring your extrapolations, intuitions, wild guesses, and most importantly some sort of device to access Predictionbook to the next Chicago Less Wrong meetup on September 15th! We will be making and sharing predictions and our confidence in them.</p>\n\n<p>Also:</p>\n\n<p>The Meetup is in a different location than usual. We will be meeting at Argo Tea at the intersection of Franklin and Madison at 1pm. This is very roughly two blocks east of Ogilvie and Union Station and just west of the Washington/Wells L.</p>\n\n<p>The September 8th Meetup was cancelled.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dk'>Predictions Chi September 15 (September 8 -- cancelled)</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BFRGZhEg4MabxY8nH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 9.803296159688375e-07, "legacy": true, "legacyId": "18656", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Predictions_Chi_September_15__September_8____cancelled_\">Discussion article for the meetup : <a href=\"/meetups/dk\">Predictions Chi September 15 (September 8 -- cancelled)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 September 2012 01:05:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1 S. Franklin St, Chicago, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Bring your extrapolations, intuitions, wild guesses, and most importantly some sort of device to access Predictionbook to the next Chicago Less Wrong meetup on September 15th! We will be making and sharing predictions and our confidence in them.</p>\n\n<p>Also:</p>\n\n<p>The Meetup is in a different location than usual. We will be meeting at Argo Tea at the intersection of Franklin and Madison at 1pm. This is very roughly two blocks east of Ogilvie and Union Station and just west of the Washington/Wells L.</p>\n\n<p>The September 8th Meetup was cancelled.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Predictions_Chi_September_15__September_8____cancelled_1\">Discussion article for the meetup : <a href=\"/meetups/dk\">Predictions Chi September 15 (September 8 -- cancelled)</a></h2>", "sections": [{"title": "Discussion article for the meetup : Predictions Chi September 15 (September 8 -- cancelled)", "anchor": "Discussion_article_for_the_meetup___Predictions_Chi_September_15__September_8____cancelled_", "level": 1}, {"title": "Discussion article for the meetup : Predictions Chi September 15 (September 8 -- cancelled)", "anchor": "Discussion_article_for_the_meetup___Predictions_Chi_September_15__September_8____cancelled_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T04:45:11.925Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fighting a Rearguard Action Against the Truth", "slug": "seq-rerun-fighting-a-rearguard-action-against-the-truth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.431Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pC38L9XtLMPGxA9aF/seq-rerun-fighting-a-rearguard-action-against-the-truth", "pageUrlRelative": "/posts/pC38L9XtLMPGxA9aF/seq-rerun-fighting-a-rearguard-action-against-the-truth", "linkUrl": "https://www.lesswrong.com/posts/pC38L9XtLMPGxA9aF/seq-rerun-fighting-a-rearguard-action-against-the-truth", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fighting%20a%20Rearguard%20Action%20Against%20the%20Truth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fighting%20a%20Rearguard%20Action%20Against%20the%20Truth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpC38L9XtLMPGxA9aF%2Fseq-rerun-fighting-a-rearguard-action-against-the-truth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fighting%20a%20Rearguard%20Action%20Against%20the%20Truth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpC38L9XtLMPGxA9aF%2Fseq-rerun-fighting-a-rearguard-action-against-the-truth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpC38L9XtLMPGxA9aF%2Fseq-rerun-fighting-a-rearguard-action-against-the-truth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<p>Today's post, <a href=\"/lw/u8/fighting_a_rearguard_action_against_the_truth/\">Fighting a Rearguard Action Against the Truth</a> was originally published on 24 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Fighting_a_Rearguard_Action_Against_the_Truth\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When Eliezer started to consider the possibility of Friendly AI as a contingency plan, he permitted himself a line of retreat. He was now able to slowly start to reconsider positions in his metaethics, and move gradually towards better ideas.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/edn/seq_rerun_that_tiny_note_of_discord/\">That Tiny Note of Discord</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pC38L9XtLMPGxA9aF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.803984477940031e-07, "legacy": true, "legacyId": "18663", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PCfaLLtuxes6Jk4S2", "5EMAbWwRHRnbT8oJF", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T15:34:03.188Z", "modifiedAt": null, "url": null, "title": "Meetup : Less Wrong Sydney: 17th September: MInd Games", "slug": "meetup-less-wrong-sydney-17th-september-mind-games", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.257Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oklord", "createdAt": "2011-03-22T11:37:19.291Z", "isAdmin": false, "displayName": "Oklord"}, "userId": "EusNQMHkhmSq2k9Y9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WeD3Gby8Jx7ZC5W8M/meetup-less-wrong-sydney-17th-september-mind-games", "pageUrlRelative": "/posts/WeD3Gby8Jx7ZC5W8M/meetup-less-wrong-sydney-17th-september-mind-games", "linkUrl": "https://www.lesswrong.com/posts/WeD3Gby8Jx7ZC5W8M/meetup-less-wrong-sydney-17th-september-mind-games", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Less%20Wrong%20Sydney%3A%2017th%20September%3A%20MInd%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Less%20Wrong%20Sydney%3A%2017th%20September%3A%20MInd%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeD3Gby8Jx7ZC5W8M%2Fmeetup-less-wrong-sydney-17th-september-mind-games%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Less%20Wrong%20Sydney%3A%2017th%20September%3A%20MInd%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeD3Gby8Jx7ZC5W8M%2Fmeetup-less-wrong-sydney-17th-september-mind-games", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeD3Gby8Jx7ZC5W8M%2Fmeetup-less-wrong-sydney-17th-september-mind-games", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dl'>Less Wrong Sydney: 17th September: MInd Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 September 2012 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">77 Liverpool Street, Sydney, Australia, Level 2</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>As suggested earlier- mind games for all!</p>\n\n<p>We'll be attempting some basic social games, as inspired by <a href=\"http://lesswrong.com/lw/58/build_skills_in_the_right_order/\" rel=\"nofollow\">http://lesswrong.com/lw/58/build_skills_in_the_right_order/</a> - simple stuff, like holding eye contact for absurd periods without staring down, and simple enunciation games.</p>\n\n<p>Also, Rejection therapy! I personally expect everyone here to ask to join a strangers board game. Extra points for success!</p>\n\n<p>You need only bring enthusiasm and preparation for awkwardness. Also the desserts here are pretty decent...</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dl'>Less Wrong Sydney: 17th September: MInd Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WeD3Gby8Jx7ZC5W8M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 9.807276573321384e-07, "legacy": true, "legacyId": "18670", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_Sydney__17th_September__MInd_Games\">Discussion article for the meetup : <a href=\"/meetups/dl\">Less Wrong Sydney: 17th September: MInd Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 September 2012 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">77 Liverpool Street, Sydney, Australia, Level 2</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>As suggested earlier- mind games for all!</p>\n\n<p>We'll be attempting some basic social games, as inspired by <a href=\"http://lesswrong.com/lw/58/build_skills_in_the_right_order/\" rel=\"nofollow\">http://lesswrong.com/lw/58/build_skills_in_the_right_order/</a> - simple stuff, like holding eye contact for absurd periods without staring down, and simple enunciation games.</p>\n\n<p>Also, Rejection therapy! I personally expect everyone here to ask to join a strangers board game. Extra points for success!</p>\n\n<p>You need only bring enthusiasm and preparation for awkwardness. Also the desserts here are pretty decent...</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_Sydney__17th_September__MInd_Games1\">Discussion article for the meetup : <a href=\"/meetups/dl\">Less Wrong Sydney: 17th September: MInd Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Less Wrong Sydney: 17th September: MInd Games", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_Sydney__17th_September__MInd_Games", "level": 1}, {"title": "Discussion article for the meetup : Less Wrong Sydney: 17th September: MInd Games", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_Sydney__17th_September__MInd_Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bCxGjo5PqZt2gXdMQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T16:01:06.576Z", "modifiedAt": null, "url": null, "title": "SIA doomsday", "slug": "sia-doomsday", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dpajrqGjYrExQq8MN/sia-doomsday", "pageUrlRelative": "/posts/dpajrqGjYrExQq8MN/sia-doomsday", "linkUrl": "https://www.lesswrong.com/posts/dpajrqGjYrExQq8MN/sia-doomsday", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIA%20doomsday&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIA%20doomsday%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpajrqGjYrExQq8MN%2Fsia-doomsday%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIA%20doomsday%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpajrqGjYrExQq8MN%2Fsia-doomsday", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpajrqGjYrExQq8MN%2Fsia-doomsday", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 769, "htmlBody": "<p><strong>Edit</strong>: the argument is presented more clearly in a <a href=\"/r/discussion/lw/ef3/the_real_sia_doomsday/\">subsequent post</a>.</p>\n<p><em>Many thanks to <a href=\"http://www.paul-almond.com/\">Paul Almond</a> for developing the initial form of this argument.</em></p>\n<p>It is well known in these circles that the self-sampling assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Sampling_Assumption\">SSA</a>) leads to the <a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">doomsday argument</a>. The self-indication assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">SIA</a>) was developed to counter the doomsday argument. This is a old debate; but what is interesting is that SIA has its own doomsday argument - of a rather interesting and different form.</p>\n<p>To see this, let's model the population of a planet somewhat like Earth. From century to century, the planet's population can increase, decrease or stay the same with equal probability. If it increase, it will increase by one billion two thirds of the time, and by two billion one third of the time - and the same for decreases (if it overshoots zero, it stops at zero). Hence, each year, the probability of population change is:</p>\n<p>\n<table style=\"color: #000000; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<th>Pop level change<br /></th>\n<td style=\"font-size: 15px;\" align=\"center\">+2 Billion</td>\n<td style=\"font-size: 15px;\" align=\"center\">+1 Billion</td>\n<td style=\"font-size: 15px;\" align=\"center\">+0 Billion</td>\n<td style=\"font-size: 15px;\" align=\"center\">-1 Billion</td>\n<td style=\"font-size: 15px;\" align=\"center\">-2 Billion</td>\n</tr>\n<tr>\n<th>Probability<br /></th>\n<td style=\"font-size: 15px;\" align=\"center\">1/9<br /></td>\n<td style=\"font-size: 15px;\" align=\"center\">2/9<br /></td>\n<td style=\"font-size: 15px;\" align=\"center\">3/9<br /></td>\n<td style=\"font-size: 15px;\" align=\"center\">2/9<br /></td>\n<td style=\"font-size: 15px;\" align=\"center\">1/9<br /></td>\n</tr>\n</tbody>\n</table>\n</p>\n<p>During the <a href=\"http://wiki.lspace.org/wiki/Discworld_Timeline\">century of&nbsp;the Three Lice</a>, there were 3 billion people on the planet. Two centuries later, during the century of the Anchovy, there will still be 3 billion people on the planet. If you were alive on this planet during the intermediate century (the century of the Fruitbat), and knew those two facts, what would your estimate be for the current population?</p>\n<p>From the outside, this is easy. The most likely answer if that there is still 3 billion in the intermediate century, which happens with probability <strong>9/19</strong> (= (3/9)*(3/9), renormalised). But there can also be 4 or 2 billion, with probabilities <strong>4/19</strong> each, or 5 or 1 billion, with probabilities <strong>1/19</strong> each. The expected population is 3 billion, as expected.</p>\n<p>Now let's hit this with SIA. This weighs the populations by their sizes, changing the probabilities to <strong>5/57</strong>, <strong>16/57</strong>, <strong>27/57</strong>, <strong>8/57</strong>and <strong>1/57</strong>, for populations of five, four, three, two and one billion respectively. Larger populations are hence more likely; the expected population is about 3.28 billion.</p>\n<p>(For those of you curious about what SSA says, that depends on the reference class. For the reference class of people alive during the century of the Fruitbat, it gives the same answer as the outside answer. As the reference class increases, it moves closer to SIA.)</p>\n<p>&nbsp;</p>\n<h2>SIA doomsday</h2>\n<p>So SIA tells us that we should expect a spike during the current century - and hence a likely decline into the next century. The exact numbers are not important: if we know the population before our current time and the population after, then SIA implies that the current population should be above the trendline. Hence (it seems) that SIA predicts a decline from our current population (or a least a decline from the current trendline) - a doomsday argument.</p>\n<p>Those who enjoy anthropic reasoning can take a moment to see what is misleading about that statement. Go on, do it.</p>\n<p>Go on.<a id=\"more\"></a></p>\n<p>Still there? Then you've certainly already solved the problem, and are just reading to check that I got it too, and compare stylistic notes. Then for you (and for those lazy ones who've peaked ahead), here is the answer:</p>\n<p>It's one of those strange things that happen when you combine probabilities and expectations, like the fact that E(X/Y)&gt;1 <a href=\"/lw/dy9/solving_the_two_envelopes_problem/\">does not imply</a> that E(X)&gt;E(Y). Here, the issue is that:</p>\n<ul>\n<li>Expectations of decline from a trendline for <em>any given future populations</em>, does not translate in expectations of decline from a trendline <em>when we don't know the future population</em>.</li>\n</ul>\n<p>Confused? Let's go back to our previous problem, still fix the past population at 3 billion, and let the future population vary.&nbsp;As we've seen, if the future population was 3 billion, SIA would boost the probability of an above-trendline present population; so, for instance, 3-5-3 is more likely among the 3-?-3 than it would be without SIA.</p>\n<p>But now consider what would happen if the future population was 7 billion - if we were in 3-?-7. In this case, there is only one possibility in our model, namely 3-5-7. So large present populations are relatively more likely if the future population is large - and SIA makes large present populations more likely. And this removes the effects of the SIA doomsday.</p>\n<p>To sumarise:</p>\n<ol>\n<li>For known future population, SIA increase the probability of the present population being above trend (hence increasing the chance of a trend downswing in future).</li>\n<li>The current population is more likely to be high if the future population is high (hence increasing the chance of a trend upswing in future).</li>\n<li>These two effects exactly compensate. SIA has no impact on the future, once the present is known.</li>\n</ol>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dpajrqGjYrExQq8MN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.807413892402618e-07, "legacy": true, "legacyId": "18669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DNhFQJb5gkWoZrBBD", "GezzauYzGTkcwgkA7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T16:23:37.670Z", "modifiedAt": null, "url": null, "title": "Decision Theories, Part 3.75: Hang On, I Think This Works After All", "slug": "decision-theories-part-3-75-hang-on-i-think-this-works-after", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:02.948Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X9vT3o3MmtWoRRKkm/decision-theories-part-3-75-hang-on-i-think-this-works-after", "pageUrlRelative": "/posts/X9vT3o3MmtWoRRKkm/decision-theories-part-3-75-hang-on-i-think-this-works-after", "linkUrl": "https://www.lesswrong.com/posts/X9vT3o3MmtWoRRKkm/decision-theories-part-3-75-hang-on-i-think-this-works-after", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Decision%20Theories%2C%20Part%203.75%3A%20Hang%20On%2C%20I%20Think%20This%20Works%20After%20All&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecision%20Theories%2C%20Part%203.75%3A%20Hang%20On%2C%20I%20Think%20This%20Works%20After%20All%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9vT3o3MmtWoRRKkm%2Fdecision-theories-part-3-75-hang-on-i-think-this-works-after%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Decision%20Theories%2C%20Part%203.75%3A%20Hang%20On%2C%20I%20Think%20This%20Works%20After%20All%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9vT3o3MmtWoRRKkm%2Fdecision-theories-part-3-75-hang-on-i-think-this-works-after", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9vT3o3MmtWoRRKkm%2Fdecision-theories-part-3-75-hang-on-i-think-this-works-after", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1683, "htmlBody": "<p><strong>Followup to:</strong> <a href=\"/lw/e94/decision_theories_part_35_halt_melt_and_catch_fire/\">Decision Theories, Part 3.5: Halt, Melt and Catch Fire</a>, <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Decision Theories: A Semi-Formal Analysis, Part III</a></p>\n<p>The thing about dead mathematical proofs is that it's practically always worth looting the corpse; sometimes you even find there's still a pulse! That appears to be the case with my recent post lamenting the demise of the TDT-like \"Masquerade\" algorithm. I think I've got a rigorous proof this time, but I'd like other opinions before I declare that the rumors of Masquerade's demise were greatly exaggerated...</p>\n<p>To recap quickly, I've been trying to construct an algorithm that, given the payoff matrix of a game and the source code of its opponent, does some deductions and then outputs a move. I want this algorithm to do the commonsense right things (defect against both DefectBot and CooperateBot, and mutually cooperate against both FairBot and itself), and I want it to do so for simple and general reasons (that is, no gerrymandering of actions against particular opponents, and in particular no fair trying to \"recognize itself\", since there can be variants of any algorithm that are functionally identical but not provably so within either's powers of deduction). I'd also like it to be \"un-exploitable\" in a certain sense: it has a default move (which is one of its Nash equilibria), and no opponent can <em>profit</em> against the algorithm by forcing it below that default payoff. If the opponent does as well or better in expected value than it would by playing that Nash equilibrium, then so too does my algorithm.</p>\n<p>The revised Masquerade algorithm does indeed have these properties.</p>\n<p>In essence, there are two emendations that I needed: firstly, since some possible pairs of masks (like FairBot and AntiFairBot) can't knowingly settle on a fixed point, there's no way to determine what they do without a deductive capacity that strictly exceeds the weaker of them. That's a bad feature to have, so we'll just have to exclude potentially troublemaking masks from Masquerade's analysis. (In the special case of Prisoner's Dilemma I know that including DefectBot and FairBot will suffice; I've got what looks like a good solution in general, as well.)</p>\n<p>The second emendation is that FairBot needs to alternate between trying harder to prove its opponent cooperates, and trying harder to prove its opponent defects. (There needs to be an asymmetry, like cooperation proofs going first, to guarantee that when FairBot plays against itself, it finds a L&ouml;bian proof of mutual cooperation rather than one of mutual defection.) The reason for this is so that when agents reason about masks, they should be able to find a proof of the mask's action <em>without</em> needing to exceed that mask's powers of deduction. Otherwise we get that arms race again.</p>\n<p>This escalation of proof attempts can be represented in terms of proof limits (since there exists a constant C such that for N sufficiently large, a proof that \"there are no proofs of X of length less than N\" either exists with length less than C^N or not at all), but the simplest way to do this is with the formalism of <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">PA+N</a>. That is, PA is Peano Arithmetic; PA+1 is the formal system with the axioms of Peano Arithmetic and an extra axiom that PA is self-consistent (that is, if PA proves X, then PA does not prove not-X); PA+2 has those axioms and an extra one stating that PA+1 is self-consistent and so on. (Note that none of these formal systems know themselves to be self-consistent, and <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">for good reason!</a>) In every use, we'll assume that N is a fixed number (anything greater than 4 will work).</p>\n<h3>New And Improved Masks<br /></h3>\n<p>So without further ado, let's define our masks for the Prisoner's Dilemma:</p>\n<p>def DefectBot(X):<br />&nbsp;&nbsp;&nbsp; return D<br /><br />def FairBot(X):<br />&nbsp;&nbsp;&nbsp; for i in range(N):<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(FairBot)=C\" is provable in PA+i:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return C<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(FairBot)=D\" is provable in PA+i:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return D<br />&nbsp;&nbsp;&nbsp; return D</p>\n<p><strong>Lemma 1:</strong> For any X, \"DefectBot(X)=D\" is provable in PA. (Obvious.)<br /><br /><strong>Lemma 2:</strong> \"FairBot(FairBot)=C\" is provable in PA.</p>\n<p><em>Proof:</em> If we label the FairBots separately (after all, they might be logically equivalent but not know they are), we can quickly show that \"if PA proves FairBot1(FairBot2)=C, then FairBot2(FairBot1)=C\" is provable in PA (and the same with the subscripts reversed). This makes what we might term a L&ouml;bian cycle, which will come up a few more times in this post: if we have a formal system S, and \"if S proves A, then B\" and \"if S proves B, then A\" are theorems of S, then S indeed proves both A and B. (Proof reserved for a comment; hat tip to Eliezer and co.)</p>\n<p><strong>Lemma 3:</strong> \"FairBot(DefectBot)=D\" is provable in PA+1.</p>\n<p><em>Proof:</em> Note that this does <em>not</em> work in PA, even though PA can prove \"DefectBot(FairBot)=D\". Why not? Because PA can't prove that PA doesn't find a proof of \"DefectBot(FairBot)=C\" before it can look for a proof of defection! However, PA+1 can handle this just fine, because it proves \"if PA proves DB(FB)=D, then PA does not prove DB(FB)=C\".</p>\n<p>Note the weird fact that it takes a stronger formal system to prove a result that's much more intuitive from outside the system!</p>\n<h3>New and Improved Masquerade</h3>\n<p>Let's split up the long definition of Masquerade with a helper function.</p>\n<p>def Search(X,Y):<br />&nbsp;&nbsp;&nbsp; for i in range(N):<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; for j,k in [C,D]:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"Y(X)=j and X(Y)=k\" is provable in PA+i:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return (j,k)<br />&nbsp;&nbsp;&nbsp; return False</p>\n<p>This function, given two agents, simply searches (using increasingly strong formal systems) for a proof of what they do against each other; once it finds one, it halts and returns that result, and if it doesn't find one in time, it announces its failure. We will incorporate this into the definition of Masquerade. (The other function call here is to the payoff matrix, to retrieve the utility U(j,k) of a certain pair of moves.)</p>\n<p>def Masquerade(X):<br />&nbsp;&nbsp;&nbsp; utility = -&infin;<br />&nbsp;&nbsp;&nbsp; my_move = null<br />&nbsp;&nbsp;&nbsp; their_move = null<br />&nbsp;&nbsp;&nbsp; for Y in [DefectBot, FairBot]:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if Search(X,Y) != False:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; (j,k) = Search(X,Y)<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if U(j,k) &gt; utility:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; my_move = j<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; their_move = k<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; utility = U(j,k)<br />&nbsp;&nbsp;&nbsp; if utility &gt; U(D,D):<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; for i in range(N):<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(Masquerade) = their_move\" is provable in PA+i:<br />&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return my_move<br />&nbsp;&nbsp;&nbsp; return D</p>\n<p>A few things to note: first, this agent actually halts and outputs an action against any opponent... but for it to provably do so in a system below PA+N, Search(X,Y) has to find proofs quickly. This is the reason that my prior attempt didn't work- it had to wait at one point for the old FairBot to run out of time/power before concluding what it did, and that made it impossible for the old FairBot to know what the old Masquerade did. But with the new and improved agents, we get to ground in a fixed number of steps.</p>\n<p>For brevity, I'll label DefectBot, FairBot, and Masquerade as DB, FB, and M, respectively.</p>\n<p><strong>Lemma 4:</strong> \"Search(DB,DB)=(D,D)\" is provable in PA+1. (Follows from Lemma 1; note that it needs to use PA+1 in order to rule out finding proofs of other action-pairs.)<br /><br /><strong>Lemma 5:</strong> \"Search(FB,DB)=Search(DB,FB)=(D,D)\" is provable in PA+2. (Follows from Lemma 3.)<br /><br /><strong>Lemma 6:</strong> \"Search(FB,FB)=(C,C)\" is provable in PA. (Follows from Lemma 2; since (C,C) is the first one tried, we don't even need to go up to PA+1.)<br /><br /><strong>Lemma 7:</strong> \"Masquerade(DB)=D\" is provable in PA+3.</p>\n<p><em>Proof:</em> Lemmas 4 and 5, plus the fact that PA+3 knows the consistency of PA+2. There is no sanity-check step, since utility=U(D,D) here.<br /><br /><strong>Lemma 8:</strong> \"Masquerade(FB)=C\" and \"FB(Masquerade)=C\" are provable in PA+3.</p>\n<p><em>Proof:</em> Lemmas 5 and 6, and the consistency of PA+2, imply that when Masquerade arrives at the sanity-check stage, it has the variables set as utility=U(C,C), my_move=C and their_move=C. Thus PA+3 can prove that \"if 'FB(M)=C' is provable in PA+3, then M(FB)=C\". And of course, \"if 'M(FB)=C' is provable in PA+3, then FB(M)=C\" is provable in PA+3, since again PA+3 can prove that PA through PA+2 won't have found proofs of contrary conclusions before it gets around to trying to find cooperation in PA+3. Therefore we have the desired L&ouml;bian cycle!<br /><br /><strong>Theorem:</strong> \"Masquerade(Masquerade)=C\" is provable in PA+4.</p>\n<p><em>Proof:</em> Lemmas 7 and 8, and the consistency of PA+3, allow PA+4 to prove that when each Masquerade arrives at the sanity-check stage, it has set utility=U(C,C), my_move=C and their_move=C. Thus we achieve the L&ouml;bian cycle, and find proofs of mutual cooperation!</p>\n<h3>Awesome! So, what next?</h3>\n<p>Well, assuming that I haven't made a mistake in one of my proofs, I'm going to run the same proof for my generalization: given a payoff matrix in general, Masquerade enumerates all of the constant strategies and all of the \"mutually beneficial deals\" of the FairBot form (that is, masks that hold out the \"stick\" of a particular Nash equilibrium and the \"carrot\" of another spot on the payoff matrix which is superior to the \"stick\" for both players). Then it alternates (at escalating PA+n levels) between trying to prove the various good deals that the opponent could agree to. There are interesting complexities here (and an idea of what bargaining problems might involve).</p>\n<p>Secondly, I want to see if there's a good way of stating the general problem that Masquerade solves, something better than \"it agrees with commonsense decision theory\". The analogy here (and I know it's a fatuous one, but bear with me) is that I've come up with a Universal Turing Machine but not yet the Church-Turing Thesis. And that's unsatisfying.</p>\n<p>But before anything else... I want to be <em>really sure</em> that I haven't made a critical error somewhere, especially given my false start (and false halt) in the past. So if you spot a lacuna, let me know!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X9vT3o3MmtWoRRKkm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 39, "extendedScore": null, "score": 9.2e-05, "legacy": true, "legacyId": "18573", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Followup to:</strong> <a href=\"/lw/e94/decision_theories_part_35_halt_melt_and_catch_fire/\">Decision Theories, Part 3.5: Halt, Melt and Catch Fire</a>, <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Decision Theories: A Semi-Formal Analysis, Part III</a></p>\n<p>The thing about dead mathematical proofs is that it's practically always worth looting the corpse; sometimes you even find there's still a pulse! That appears to be the case with my recent post lamenting the demise of the TDT-like \"Masquerade\" algorithm. I think I've got a rigorous proof this time, but I'd like other opinions before I declare that the rumors of Masquerade's demise were greatly exaggerated...</p>\n<p>To recap quickly, I've been trying to construct an algorithm that, given the payoff matrix of a game and the source code of its opponent, does some deductions and then outputs a move. I want this algorithm to do the commonsense right things (defect against both DefectBot and CooperateBot, and mutually cooperate against both FairBot and itself), and I want it to do so for simple and general reasons (that is, no gerrymandering of actions against particular opponents, and in particular no fair trying to \"recognize itself\", since there can be variants of any algorithm that are functionally identical but not provably so within either's powers of deduction). I'd also like it to be \"un-exploitable\" in a certain sense: it has a default move (which is one of its Nash equilibria), and no opponent can <em>profit</em> against the algorithm by forcing it below that default payoff. If the opponent does as well or better in expected value than it would by playing that Nash equilibrium, then so too does my algorithm.</p>\n<p>The revised Masquerade algorithm does indeed have these properties.</p>\n<p>In essence, there are two emendations that I needed: firstly, since some possible pairs of masks (like FairBot and AntiFairBot) can't knowingly settle on a fixed point, there's no way to determine what they do without a deductive capacity that strictly exceeds the weaker of them. That's a bad feature to have, so we'll just have to exclude potentially troublemaking masks from Masquerade's analysis. (In the special case of Prisoner's Dilemma I know that including DefectBot and FairBot will suffice; I've got what looks like a good solution in general, as well.)</p>\n<p>The second emendation is that FairBot needs to alternate between trying harder to prove its opponent cooperates, and trying harder to prove its opponent defects. (There needs to be an asymmetry, like cooperation proofs going first, to guarantee that when FairBot plays against itself, it finds a L\u00f6bian proof of mutual cooperation rather than one of mutual defection.) The reason for this is so that when agents reason about masks, they should be able to find a proof of the mask's action <em>without</em> needing to exceed that mask's powers of deduction. Otherwise we get that arms race again.</p>\n<p>This escalation of proof attempts can be represented in terms of proof limits (since there exists a constant C such that for N sufficiently large, a proof that \"there are no proofs of X of length less than N\" either exists with length less than C^N or not at all), but the simplest way to do this is with the formalism of <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">PA+N</a>. That is, PA is Peano Arithmetic; PA+1 is the formal system with the axioms of Peano Arithmetic and an extra axiom that PA is self-consistent (that is, if PA proves X, then PA does not prove not-X); PA+2 has those axioms and an extra one stating that PA+1 is self-consistent and so on. (Note that none of these formal systems know themselves to be self-consistent, and <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">for good reason!</a>) In every use, we'll assume that N is a fixed number (anything greater than 4 will work).</p>\n<h3 id=\"New_And_Improved_Masks\">New And Improved Masks<br></h3>\n<p>So without further ado, let's define our masks for the Prisoner's Dilemma:</p>\n<p>def DefectBot(X):<br>&nbsp;&nbsp;&nbsp; return D<br><br>def FairBot(X):<br>&nbsp;&nbsp;&nbsp; for i in range(N):<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(FairBot)=C\" is provable in PA+i:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return C<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(FairBot)=D\" is provable in PA+i:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return D<br>&nbsp;&nbsp;&nbsp; return D</p>\n<p><strong>Lemma 1:</strong> For any X, \"DefectBot(X)=D\" is provable in PA. (Obvious.)<br><br><strong>Lemma 2:</strong> \"FairBot(FairBot)=C\" is provable in PA.</p>\n<p><em>Proof:</em> If we label the FairBots separately (after all, they might be logically equivalent but not know they are), we can quickly show that \"if PA proves FairBot1(FairBot2)=C, then FairBot2(FairBot1)=C\" is provable in PA (and the same with the subscripts reversed). This makes what we might term a L\u00f6bian cycle, which will come up a few more times in this post: if we have a formal system S, and \"if S proves A, then B\" and \"if S proves B, then A\" are theorems of S, then S indeed proves both A and B. (Proof reserved for a comment; hat tip to Eliezer and co.)</p>\n<p><strong>Lemma 3:</strong> \"FairBot(DefectBot)=D\" is provable in PA+1.</p>\n<p><em>Proof:</em> Note that this does <em>not</em> work in PA, even though PA can prove \"DefectBot(FairBot)=D\". Why not? Because PA can't prove that PA doesn't find a proof of \"DefectBot(FairBot)=C\" before it can look for a proof of defection! However, PA+1 can handle this just fine, because it proves \"if PA proves DB(FB)=D, then PA does not prove DB(FB)=C\".</p>\n<p>Note the weird fact that it takes a stronger formal system to prove a result that's much more intuitive from outside the system!</p>\n<h3 id=\"New_and_Improved_Masquerade\">New and Improved Masquerade</h3>\n<p>Let's split up the long definition of Masquerade with a helper function.</p>\n<p>def Search(X,Y):<br>&nbsp;&nbsp;&nbsp; for i in range(N):<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; for j,k in [C,D]:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"Y(X)=j and X(Y)=k\" is provable in PA+i:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return (j,k)<br>&nbsp;&nbsp;&nbsp; return False</p>\n<p>This function, given two agents, simply searches (using increasingly strong formal systems) for a proof of what they do against each other; once it finds one, it halts and returns that result, and if it doesn't find one in time, it announces its failure. We will incorporate this into the definition of Masquerade. (The other function call here is to the payoff matrix, to retrieve the utility U(j,k) of a certain pair of moves.)</p>\n<p>def Masquerade(X):<br>&nbsp;&nbsp;&nbsp; utility = -\u221e<br>&nbsp;&nbsp;&nbsp; my_move = null<br>&nbsp;&nbsp;&nbsp; their_move = null<br>&nbsp;&nbsp;&nbsp; for Y in [DefectBot, FairBot]:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if Search(X,Y) != False:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; (j,k) = Search(X,Y)<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if U(j,k) &gt; utility:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; my_move = j<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; their_move = k<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; utility = U(j,k)<br>&nbsp;&nbsp;&nbsp; if utility &gt; U(D,D):<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; for i in range(N):<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; if \"X(Masquerade) = their_move\" is provable in PA+i:<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; return my_move<br>&nbsp;&nbsp;&nbsp; return D</p>\n<p>A few things to note: first, this agent actually halts and outputs an action against any opponent... but for it to provably do so in a system below PA+N, Search(X,Y) has to find proofs quickly. This is the reason that my prior attempt didn't work- it had to wait at one point for the old FairBot to run out of time/power before concluding what it did, and that made it impossible for the old FairBot to know what the old Masquerade did. But with the new and improved agents, we get to ground in a fixed number of steps.</p>\n<p>For brevity, I'll label DefectBot, FairBot, and Masquerade as DB, FB, and M, respectively.</p>\n<p><strong>Lemma 4:</strong> \"Search(DB,DB)=(D,D)\" is provable in PA+1. (Follows from Lemma 1; note that it needs to use PA+1 in order to rule out finding proofs of other action-pairs.)<br><br><strong>Lemma 5:</strong> \"Search(FB,DB)=Search(DB,FB)=(D,D)\" is provable in PA+2. (Follows from Lemma 3.)<br><br><strong>Lemma 6:</strong> \"Search(FB,FB)=(C,C)\" is provable in PA. (Follows from Lemma 2; since (C,C) is the first one tried, we don't even need to go up to PA+1.)<br><br><strong>Lemma 7:</strong> \"Masquerade(DB)=D\" is provable in PA+3.</p>\n<p><em>Proof:</em> Lemmas 4 and 5, plus the fact that PA+3 knows the consistency of PA+2. There is no sanity-check step, since utility=U(D,D) here.<br><br><strong>Lemma 8:</strong> \"Masquerade(FB)=C\" and \"FB(Masquerade)=C\" are provable in PA+3.</p>\n<p><em>Proof:</em> Lemmas 5 and 6, and the consistency of PA+2, imply that when Masquerade arrives at the sanity-check stage, it has the variables set as utility=U(C,C), my_move=C and their_move=C. Thus PA+3 can prove that \"if 'FB(M)=C' is provable in PA+3, then M(FB)=C\". And of course, \"if 'M(FB)=C' is provable in PA+3, then FB(M)=C\" is provable in PA+3, since again PA+3 can prove that PA through PA+2 won't have found proofs of contrary conclusions before it gets around to trying to find cooperation in PA+3. Therefore we have the desired L\u00f6bian cycle!<br><br><strong>Theorem:</strong> \"Masquerade(Masquerade)=C\" is provable in PA+4.</p>\n<p><em>Proof:</em> Lemmas 7 and 8, and the consistency of PA+3, allow PA+4 to prove that when each Masquerade arrives at the sanity-check stage, it has set utility=U(C,C), my_move=C and their_move=C. Thus we achieve the L\u00f6bian cycle, and find proofs of mutual cooperation!</p>\n<h3 id=\"Awesome__So__what_next_\">Awesome! So, what next?</h3>\n<p>Well, assuming that I haven't made a mistake in one of my proofs, I'm going to run the same proof for my generalization: given a payoff matrix in general, Masquerade enumerates all of the constant strategies and all of the \"mutually beneficial deals\" of the FairBot form (that is, masks that hold out the \"stick\" of a particular Nash equilibrium and the \"carrot\" of another spot on the payoff matrix which is superior to the \"stick\" for both players). Then it alternates (at escalating PA+n levels) between trying to prove the various good deals that the opponent could agree to. There are interesting complexities here (and an idea of what bargaining problems might involve).</p>\n<p>Secondly, I want to see if there's a good way of stating the general problem that Masquerade solves, something better than \"it agrees with commonsense decision theory\". The analogy here (and I know it's a fatuous one, but bear with me) is that I've come up with a Universal Turing Machine but not yet the Church-Turing Thesis. And that's unsatisfying.</p>\n<p>But before anything else... I want to be <em>really sure</em> that I haven't made a critical error somewhere, especially given my false start (and false halt) in the past. So if you spot a lacuna, let me know!</p>", "sections": [{"title": "New And Improved Masks", "anchor": "New_And_Improved_Masks", "level": 1}, {"title": "New and Improved Masquerade", "anchor": "New_and_Improved_Masquerade", "level": 1}, {"title": "Awesome! So, what next?", "anchor": "Awesome__So__what_next_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "45 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ShD7EHb4HmPgfveim", "AMwzjjvFxEgxvL7xe", "rm8tv9qZ9nwQxhshx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-06T21:06:28.897Z", "modifiedAt": null, "url": null, "title": "Link: Toward Non-Stupid, Non-Blank-Slatey Polyandry", "slug": "link-toward-non-stupid-non-blank-slatey-polyandry", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.698Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cosmos", "createdAt": "2009-04-26T03:18:01.731Z", "isAdmin": false, "displayName": "Cosmos"}, "userId": "c3Ji9Th6jATRyHLFC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KKF9vs4iGrmfyorgB/link-toward-non-stupid-non-blank-slatey-polyandry", "pageUrlRelative": "/posts/KKF9vs4iGrmfyorgB/link-toward-non-stupid-non-blank-slatey-polyandry", "linkUrl": "https://www.lesswrong.com/posts/KKF9vs4iGrmfyorgB/link-toward-non-stupid-non-blank-slatey-polyandry", "postedAtFormatted": "Thursday, September 6th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Toward%20Non-Stupid%2C%20Non-Blank-Slatey%20Polyandry&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Toward%20Non-Stupid%2C%20Non-Blank-Slatey%20Polyandry%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKKF9vs4iGrmfyorgB%2Flink-toward-non-stupid-non-blank-slatey-polyandry%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Toward%20Non-Stupid%2C%20Non-Blank-Slatey%20Polyandry%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKKF9vs4iGrmfyorgB%2Flink-toward-non-stupid-non-blank-slatey-polyandry", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKKF9vs4iGrmfyorgB%2Flink-toward-non-stupid-non-blank-slatey-polyandry", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>http://theviewfromhell.blogspot.com/2012/09/toward-non-stupid-non-blank-slatey.html</p>\n<p>The author gives a shout out to Less Wrong as a community with a perpetually skewed gender ratio, which is precisely the conditions under which polyandry appears to thrive.</p>\n<p>Discuss. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KKF9vs4iGrmfyorgB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 19, "extendedScore": null, "score": 4.9e-05, "legacy": true, "legacyId": "18673", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-07T04:10:41.624Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] My Naturalistic Awakening", "slug": "seq-rerun-my-naturalistic-awakening", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:29.401Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dHmssDP6w4x7LHWbJ/seq-rerun-my-naturalistic-awakening", "pageUrlRelative": "/posts/dHmssDP6w4x7LHWbJ/seq-rerun-my-naturalistic-awakening", "linkUrl": "https://www.lesswrong.com/posts/dHmssDP6w4x7LHWbJ/seq-rerun-my-naturalistic-awakening", "postedAtFormatted": "Friday, September 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20My%20Naturalistic%20Awakening&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20My%20Naturalistic%20Awakening%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHmssDP6w4x7LHWbJ%2Fseq-rerun-my-naturalistic-awakening%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20My%20Naturalistic%20Awakening%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHmssDP6w4x7LHWbJ%2Fseq-rerun-my-naturalistic-awakening", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHmssDP6w4x7LHWbJ%2Fseq-rerun-my-naturalistic-awakening", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/u9/my_naturalistic_awakening/\">My Naturalistic Awakening</a> was originally published on 25 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#My_Naturalistic_Awakening\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Eliezer actually looked back and realized his mistakes when he imagined the idea of an optimization process.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/eef/seq_rerun_fighting_a_rearguard_action_against_the/\">Fighting a Rearguard Action Against the Truth</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dHmssDP6w4x7LHWbJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.811118017216496e-07, "legacy": true, "legacyId": "18677", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["75LZMCCePG4Pwj3dB", "pC38L9XtLMPGxA9aF", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-07T11:11:49.587Z", "modifiedAt": null, "url": null, "title": "The REAL SIA doomsday", "slug": "the-real-sia-doomsday", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:30.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DNhFQJb5gkWoZrBBD/the-real-sia-doomsday", "pageUrlRelative": "/posts/DNhFQJb5gkWoZrBBD/the-real-sia-doomsday", "linkUrl": "https://www.lesswrong.com/posts/DNhFQJb5gkWoZrBBD/the-real-sia-doomsday", "postedAtFormatted": "Friday, September 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20REAL%20SIA%20doomsday&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20REAL%20SIA%20doomsday%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNhFQJb5gkWoZrBBD%2Fthe-real-sia-doomsday%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20REAL%20SIA%20doomsday%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNhFQJb5gkWoZrBBD%2Fthe-real-sia-doomsday", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNhFQJb5gkWoZrBBD%2Fthe-real-sia-doomsday", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p><em>Many thanks to&nbsp;<a href=\"http://www.paul-almond.com/\">Paul Almond</a>&nbsp;for developing the initial form of this argument.</em></p>\n<p>My <a href=\"/lw/eel/sia_doomsday/\">previous post</a> was somewhat confusing and potentially misleading (and the idea hadn't fully gelled in my mind). But here is a much easier way of seeing what the SIA doomsday really is.</p>\n<p>Imagine if your parents had rolled a dice to decide how many children to have. Knowing only this, SIA implies that the dice was more likely to have been a \"6\" that a \"1\" (because there is a higher chance of you existing in that case). But, now following the family tradition, you decide to roll a dice for your children. SIA now has no impact: the dice is equally likely to be any number. So SIA predicts high numbers in the past, and no preferences for the future.</p>\n<p>This can be generalised into an SIA \"doomsday\":</p>\n<ul>\n<li>Everything else being equal, SIA implies that the population growth rate in your past is likely to be higher than the rate in the future; i.e. it predicts an observed decline, not in population, but in population growth rates.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DNhFQJb5gkWoZrBBD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 9.813257247400236e-07, "legacy": true, "legacyId": "18687", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dpajrqGjYrExQq8MN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-07T15:06:02.598Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Berlin, Melbourne, NYC, Paris, Pittsburgh, Washington DC", "slug": "weekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.870Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fZK2wvkp7abYeAHTf/weekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "pageUrlRelative": "/posts/fZK2wvkp7abYeAHTf/weekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "linkUrl": "https://www.lesswrong.com/posts/fZK2wvkp7abYeAHTf/weekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "postedAtFormatted": "Friday, September 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Berlin%2C%20Melbourne%2C%20NYC%2C%20Paris%2C%20Pittsburgh%2C%20Washington%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Berlin%2C%20Melbourne%2C%20NYC%2C%20Paris%2C%20Pittsburgh%2C%20Washington%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfZK2wvkp7abYeAHTf%2Fweekly-lw-meetups-austin-berlin-melbourne-nyc-paris%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Berlin%2C%20Melbourne%2C%20NYC%2C%20Paris%2C%20Pittsburgh%2C%20Washington%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfZK2wvkp7abYeAHTf%2Fweekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfZK2wvkp7abYeAHTf%2Fweekly-lw-meetups-austin-berlin-melbourne-nyc-paris", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 435, "htmlBody": "<p><strong>This summary was posted to LW Main on August 31st, and has been moved to discussion.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/d3\">Paris Meetup:&nbsp;<span class=\"date\">01 September 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/dc\">Washigton DC (probably) minicamp meetup:&nbsp;<span class=\"date\">02 September 2012 03:00AM</span></a></li>\n<li><a href=\"/meetups/ct\">Berlin Meetup:&nbsp;<span class=\"date\">04 September 2012 07:30PM</span></a></li>\n<li><a href=\"/meetups/da\">Pittsburgh: Rationalization Game:&nbsp;<span class=\"date\">04 September 2012 06:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">01 September 2018 01:30PM</span></a></li>\n<li><a href=\"/meetups/d2\">Rational-Humanist Open Mic, NYC September 5th:&nbsp;<span class=\"date\">05 September 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/d9\">Melbourne, practical rationality:&nbsp;<span class=\"date\">07 September 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/cv\">Meetup: Southwestern Ohio:&nbsp;<span class=\"date\">09 September 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/d6\">SLC, UT: Free Will and Rationality Checklists:&nbsp;<span class=\"date\">15 September 2012 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong>&nbsp;</strong><strong></strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>, <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fZK2wvkp7abYeAHTf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 9.814447356633587e-07, "legacy": true, "legacyId": "18572", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-07T20:15:26.518Z", "modifiedAt": null, "url": null, "title": "Jews and Nazis: a version of dust specks vs torture", "slug": "jews-and-nazis-a-version-of-dust-specks-vs-torture", "viewCount": null, "lastCommentedAt": "2021-08-02T00:16:14.745Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mfS9u858bge7gvdnG/jews-and-nazis-a-version-of-dust-specks-vs-torture", "pageUrlRelative": "/posts/mfS9u858bge7gvdnG/jews-and-nazis-a-version-of-dust-specks-vs-torture", "linkUrl": "https://www.lesswrong.com/posts/mfS9u858bge7gvdnG/jews-and-nazis-a-version-of-dust-specks-vs-torture", "postedAtFormatted": "Friday, September 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Jews%20and%20Nazis%3A%20a%20version%20of%20dust%20specks%20vs%20torture&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJews%20and%20Nazis%3A%20a%20version%20of%20dust%20specks%20vs%20torture%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmfS9u858bge7gvdnG%2Fjews-and-nazis-a-version-of-dust-specks-vs-torture%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Jews%20and%20Nazis%3A%20a%20version%20of%20dust%20specks%20vs%20torture%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmfS9u858bge7gvdnG%2Fjews-and-nazis-a-version-of-dust-specks-vs-torture", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmfS9u858bge7gvdnG%2Fjews-and-nazis-a-version-of-dust-specks-vs-torture", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 430, "htmlBody": "<p>This is based on a discussion in #lesswrong a few months back, and I am not sure how to resolve it.</p>\n<p>Setup: suppose the world is populated by two groups of people, one just wants to be left alone (labeled Jews), the other group hates the first one with passion and want them dead (labeled Nazis). The second group is otherwise just as \"good\" as the first one (loves their relatives, their country and is known to be in general quite rational). They just can't help but hate the other guys (this condition is to forestall the objections like \"Nazis ought to change their terminal values\"). Maybe the shape of Jewish noses just creeps the hell out of them, or something. Let's just assume, for the sake of argument, that there is no changing that hatred.</p>\n<p>Is it rational to exterminate the Jews to improve the Nazi's quality of life? Well, this seems like a silly question. Of course not! Now, what if there are many more Nazis than Jews? Is there a number large enough where exterminating Jews would be a net positive utility for the world? Umm... Not sure... I'd like to think that probably not, human life is sacred! What if some day their society invents immortality, then every death is like an extremely large (infinite?) negative utility!</p>\n<p>Fine then, not exterminating. Just send them all to concentration camps, where they will suffer in misery and probably have a shorter lifespan than they would otherwise. This is not an ideal solutions from the Nazi point of view, but it makes them feel a little bit better. And now the utilities are unquestionably comparable, so if there are billions of Nazis and only a handful of Jews, the overall suffering decreases when the Jews are sent to the camps.</p>\n<p>This logic is completely analogous to that in the dust specks vs torture discussions, only my \"little XML labels\", to quote Eliezer, make it more emotionally charged. Thus, if you are a utilitarian anti-specker, you ought to decide that, barring changing Nazi's terminal value of hating Jews, the rational behavior is to herd the Jews into concentration camps, or possibly even exterminate them, provided there are enough Nazi's in the world who benefit from it.</p>\n<p>This is quite a repugnant conclusion, and I don't see a way of fixing it the way the original one is fixed (to paraphrase Eliezer, \"only lives worth celebrating are worth creating\").</p>\n<p><strong><span style=\"font-family: mceinline;\"> </span></strong></p>\n<p><strong>EDIT: Thanks to&nbsp;<a href=\"/r/discussion/lw/ef5/jews_and_nazis_a_version_of_dust_specks_vs_torture/7dcc\">CronoDAS</a>&nbsp;for pointing out that this is known as the 1000 Sadists problem. Once I had this term, I found that&nbsp;<a href=\"http://commonsenseatheism.com/?p=2982\">lukeprog</a>&nbsp;has mentioned it on his old blog.&nbsp;</strong></p>\n<p><strong>\n<p>&nbsp;</p>\n</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mfS9u858bge7gvdnG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 59, "baseScore": 13, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "18689", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 153, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-07T23:35:14.646Z", "modifiedAt": null, "url": null, "title": "[link] One-question survey from Robin Hanson", "slug": "link-one-question-survey-from-robin-hanson", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:31.349Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fortyeridania", "createdAt": "2010-07-21T15:35:12.558Z", "isAdmin": false, "displayName": "fortyeridania"}, "userId": "roBPqtzsvG6dC3YFT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qgFyNHPLyJMwYkrZQ/link-one-question-survey-from-robin-hanson", "pageUrlRelative": "/posts/qgFyNHPLyJMwYkrZQ/link-one-question-survey-from-robin-hanson", "linkUrl": "https://www.lesswrong.com/posts/qgFyNHPLyJMwYkrZQ/link-one-question-survey-from-robin-hanson", "postedAtFormatted": "Friday, September 7th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20One-question%20survey%20from%20Robin%20Hanson&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20One-question%20survey%20from%20Robin%20Hanson%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgFyNHPLyJMwYkrZQ%2Flink-one-question-survey-from-robin-hanson%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20One-question%20survey%20from%20Robin%20Hanson%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgFyNHPLyJMwYkrZQ%2Flink-one-question-survey-from-robin-hanson", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgFyNHPLyJMwYkrZQ%2Flink-one-question-survey-from-robin-hanson", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<p>As many of you probably know, <a href=\"http://www.overcomingbias.com/\">Robin</a> <a href=\"http://hanson.gmu.edu/\">Hanson</a> is writing a book, and it will be&nbsp;geared toward a popular audience. He wants a term that encompasses both humans and AI, so he's soliciting your opinions on the matter. Here's the link: <a href=\"http://www.quicksurveys.com/tqsruntime.aspx?surveyData=AYtdr2WMwCzB981F0qkivSNwbj1tn+xvU6rnauc83iU\">http://www.quicksurveys.com/tqsruntime.aspx?surveyData=AYtdr2WMwCzB981F0qkivSNwbj1tn+xvU6rnauc83iU</a>=</p>\r\n<p>H/T Bryan Caplan at EconLog.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qgFyNHPLyJMwYkrZQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -6, "extendedScore": null, "score": -1.1e-05, "legacy": true, "legacyId": "18691", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-08T06:16:09.920Z", "modifiedAt": null, "url": null, "title": "Friendship is Optimal: A My Little Pony fanfic about an optimization process", "slug": "friendship-is-optimal-a-my-little-pony-fanfic-about-an", "viewCount": null, "lastCommentedAt": "2021-03-14T05:41:46.675Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "iceman", "createdAt": "2011-10-02T05:56:12.967Z", "isAdmin": false, "displayName": "iceman"}, "userId": "WCxJj7a7FGiT9LDQJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CHD5m9fnosr7L3dto/friendship-is-optimal-a-my-little-pony-fanfic-about-an", "pageUrlRelative": "/posts/CHD5m9fnosr7L3dto/friendship-is-optimal-a-my-little-pony-fanfic-about-an", "linkUrl": "https://www.lesswrong.com/posts/CHD5m9fnosr7L3dto/friendship-is-optimal-a-my-little-pony-fanfic-about-an", "postedAtFormatted": "Saturday, September 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Friendship%20is%20Optimal%3A%20A%20My%20Little%20Pony%20fanfic%20about%20an%20optimization%20process&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFriendship%20is%20Optimal%3A%20A%20My%20Little%20Pony%20fanfic%20about%20an%20optimization%20process%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHD5m9fnosr7L3dto%2Ffriendship-is-optimal-a-my-little-pony-fanfic-about-an%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Friendship%20is%20Optimal%3A%20A%20My%20Little%20Pony%20fanfic%20about%20an%20optimization%20process%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHD5m9fnosr7L3dto%2Ffriendship-is-optimal-a-my-little-pony-fanfic-about-an", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHD5m9fnosr7L3dto%2Ffriendship-is-optimal-a-my-little-pony-fanfic-about-an", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 294, "htmlBody": "<p>[EDIT, Nov 14th: And it's posted. <a href=\"/r/discussion/lw/fi8/launched_friendship_is_optimal/\">New discussion about release</a>. Link to <em><a href=\"http://www.fimfiction.net/story/62074/Friendship-is-Optimal\">Friendship is Optimal</a></em>.]</p>\n<p>[EDIT, Nov 13th: I've submitted to FIMFiction, and will update with a link to its&nbsp;permanent&nbsp;home if it passes moderation. I have also removed the docs link and will make the document private once it goes live.]</p>\n<hr />\n<p>Over the last year, I&rsquo;ve spent a lot of my free time writing a semi-rationalist My Little Pony fanfic. Whenever I&rsquo;ve mentioned this side project, I&rsquo;ve received requests to alpha the story.</p>\n<p>I present, as an open beta:&nbsp;Friendship is Optimal. Please do not spread that link outside of LessWrong; Google Docs is not its permanent home. I intend to put it up on fanfiction.net and submit it to Equestria Daily after incorporating any feedback. The story is complete, and I believe I've caught the majority of typographical and grammatical problems. (Though if you find some, comments are open on the doc itself.) Given the subject matter, I&rsquo;m asking for the LessWrong community&rsquo;s help in spotting any major logical flaws or other storytelling problems.</p>\n<p>Cover jacket text:</p>\n<p style=\"margin-left: 36pt;\"><em>Hanna, the CEO of Hofvarpnir Studios, just won the contract to write the official </em>My Little Pony<em> MMO. She had better hurry; a US military contractor is developing weapons based on her artificial intelligence technology, which just </em>may<em> destroy the world. Hana has built an A.I. Princess Celestia and given her one basic drive: to satisfy values through friendship and ponies. What will Princess Celestia do when she&rsquo;s let loose upon the world, following the drives Hanna has given her?</em></p>\n<p>Special thanks to my roommate (who did extensive editing and was invaluable in noticing attempts by me to anthropomorphize an AI), and to Vaniver, who along with my roommate, convinced me to delete what was just a flat out <em>bad</em> chapter.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 13, "ZFrgTgzwEfStg26JL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CHD5m9fnosr7L3dto", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 76, "baseScore": 109, "extendedScore": null, "score": 0.000236, "legacy": true, "legacyId": "18702", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 109, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 152, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hHCBGXkQCbEqBEADE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 13, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-08T09:31:25.639Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Level Above Mine", "slug": "seq-rerun-the-level-above-mine", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XTvRDYEvw8L23ctFN/seq-rerun-the-level-above-mine", "pageUrlRelative": "/posts/XTvRDYEvw8L23ctFN/seq-rerun-the-level-above-mine", "linkUrl": "https://www.lesswrong.com/posts/XTvRDYEvw8L23ctFN/seq-rerun-the-level-above-mine", "postedAtFormatted": "Saturday, September 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Level%20Above%20Mine&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Level%20Above%20Mine%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTvRDYEvw8L23ctFN%2Fseq-rerun-the-level-above-mine%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Level%20Above%20Mine%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTvRDYEvw8L23ctFN%2Fseq-rerun-the-level-above-mine", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXTvRDYEvw8L23ctFN%2Fseq-rerun-the-level-above-mine", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<p>Today's post, <a href=\"/lw/ua/the_level_above_mine/\">The Level Above Mine</a> was originally published on 26 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#The_Level_Above_Mine\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>There are people who have acquired more mastery over various fields than Eliezer has over his.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/eet/seq_rerun_my_naturalistic_awakening/\">My Naturalistic Awakening</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XTvRDYEvw8L23ctFN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.820067523811106e-07, "legacy": true, "legacyId": "18704", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kXSETKZ3X9oidMozA", "dHmssDP6w4x7LHWbJ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-08T16:13:17.835Z", "modifiedAt": null, "url": null, "title": "Integrated Method for Policy Making Using Argument Modelling and Computer Assisted Text Analysis", "slug": "integrated-method-for-policy-making-using-argument-modelling", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:06.282Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "staticIP", "createdAt": "2012-03-18T02:14:47.707Z", "isAdmin": false, "displayName": "staticIP"}, "userId": "wAQ2cTMb2K7a6R8D6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H78GgdhFwcWhSMxHc/integrated-method-for-policy-making-using-argument-modelling", "pageUrlRelative": "/posts/H78GgdhFwcWhSMxHc/integrated-method-for-policy-making-using-argument-modelling", "linkUrl": "https://www.lesswrong.com/posts/H78GgdhFwcWhSMxHc/integrated-method-for-policy-making-using-argument-modelling", "postedAtFormatted": "Saturday, September 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Integrated%20Method%20for%20Policy%20Making%20Using%20Argument%20Modelling%20and%20Computer%20Assisted%20Text%20Analysis&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntegrated%20Method%20for%20Policy%20Making%20Using%20Argument%20Modelling%20and%20Computer%20Assisted%20Text%20Analysis%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH78GgdhFwcWhSMxHc%2Fintegrated-method-for-policy-making-using-argument-modelling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Integrated%20Method%20for%20Policy%20Making%20Using%20Argument%20Modelling%20and%20Computer%20Assisted%20Text%20Analysis%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH78GgdhFwcWhSMxHc%2Fintegrated-method-for-policy-making-using-argument-modelling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH78GgdhFwcWhSMxHc%2Fintegrated-method-for-policy-making-using-argument-modelling", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<blockquote>\n<p>IMPACT is conducting original research to develop and integrate formal, computational models of policy and arguments about policy, to facilitate deliberations about policy at a conceptual, language-independent level. These models will be used to develop and evaluate a prototype of an innovative argumentation toolbox for supporting open, inclusive and transparent deliberations about public policy.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>The <a href=\"http://www.policy-impact.eu/home\">IMPACT project</a>, funded by the EU, is building a tool to make debates easier to keep track of, and presumably more rational. It look sort of like an AI, where all the dirty work and low level stuff is done by humans, but the actual result is determined by the structure of the machine. Certainly you could subvert it by placing incorrect standards of evidence on particular papers/arguments, but on the whole it looks interesting.</p>\n<p>Sort of a wiki-decision framework.</p>\n<p>What do you think about this type of project? Are there any existing argument modelling languages, like UML for arguments? Is this the best approach?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H78GgdhFwcWhSMxHc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 15, "extendedScore": null, "score": 9.822112186236582e-07, "legacy": true, "legacyId": "18705", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-08T20:38:01.580Z", "modifiedAt": null, "url": null, "title": "Checking for the Programming Gear", "slug": "checking-for-the-programming-gear", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.112Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M4RM7548nzXjMicvr/checking-for-the-programming-gear", "pageUrlRelative": "/posts/M4RM7548nzXjMicvr/checking-for-the-programming-gear", "linkUrl": "https://www.lesswrong.com/posts/M4RM7548nzXjMicvr/checking-for-the-programming-gear", "postedAtFormatted": "Saturday, September 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Checking%20for%20the%20Programming%20Gear&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChecking%20for%20the%20Programming%20Gear%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM4RM7548nzXjMicvr%2Fchecking-for-the-programming-gear%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Checking%20for%20the%20Programming%20Gear%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM4RM7548nzXjMicvr%2Fchecking-for-the-programming-gear", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM4RM7548nzXjMicvr%2Fchecking-for-the-programming-gear", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>People on this board have talked about programming as a gear in your brain that, to a first approximation, you have or you don't. I'm wondering if there's some well put-together resource you can direct someone with zero experience and just a web-browser to and say \"if you're having fun an hour from now, you have the gear, good luck\" -- maybe something on Khan academy?</p>\n<p>(I learned to program a long time ago, and I started with BASIC program listings in my math textbook -- I don't actually know what the optimal onramps are now.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M4RM7548nzXjMicvr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 9, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "18706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-08T21:14:34.032Z", "modifiedAt": null, "url": null, "title": "How to Improve Field Cryonics", "slug": "how-to-improve-field-cryonics", "viewCount": null, "lastCommentedAt": "2012-09-09T21:11:15.825Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dolores1984", "createdAt": "2012-04-27T01:13:58.517Z", "isAdmin": false, "displayName": "Dolores1984"}, "userId": "4atqsmycH3WC4Cf5u", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c3ohEg6H4nJPEZz6C/how-to-improve-field-cryonics", "pageUrlRelative": "/posts/c3ohEg6H4nJPEZz6C/how-to-improve-field-cryonics", "linkUrl": "https://www.lesswrong.com/posts/c3ohEg6H4nJPEZz6C/how-to-improve-field-cryonics", "postedAtFormatted": "Saturday, September 8th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Improve%20Field%20Cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Improve%20Field%20Cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3ohEg6H4nJPEZz6C%2Fhow-to-improve-field-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Improve%20Field%20Cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3ohEg6H4nJPEZz6C%2Fhow-to-improve-field-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3ohEg6H4nJPEZz6C%2Fhow-to-improve-field-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 294, "htmlBody": "<p>I just read <a href=\"http://chronopause.com/index.php/2011/02/23/does-personal-identity-survive-cryopreservation/\">this article</a>&nbsp;(which is well worth reading for anyone interested in cryonics). &nbsp;One of the important things that the article points out is that, while it takes some time for the memory structures of the brain to degrade due to ischemia, one of the more rapid effects is blood clotting in the fine&nbsp;capillaries&nbsp;of the brain after fairly brief ischemia. &nbsp;This reduces the flow of cryoprotectant, and causes large swathes of neural tissue to be frozen, instead of vitrified, which would be catastrophic for personal identity. &nbsp;While this is not a problem for best-case 'standby' cryonics, it is a problem for those who cannot afford a standby team, or are simply hit by cars.</p>\n<p>Being an engineer, my first thought is that this is ridiculous, and there has to be a better solution to the problem. &nbsp;It may be possible to build a device, maybe the size of a shoe box, which can be deployed in the field by a minimally-trained amateur (like a defibrillator), and perfuses the brain with cold saline and anti-coagulants -- or even a synthetic oxygen carrier). &nbsp;I'm picturing a cylinder of fluid, large needles with sterilizing caps for tapping the jugular and carotid arteries, and a gas cylinder to provide pressure. &nbsp;You'd simply break a chemical cold pack, put a plastic neck brace in place and insert the needles, and press a button.<br /><br />Such a device could even be useful to non-cryonicists, as a way to prevent ischemic injury in people found medically dead at the scene of an accident, during transport to the hospital. &nbsp;<br /><br />Does anyone with more of a medical background know if such a machine would be at all feasible? &nbsp;I can't imagine it would be expensive to construct. &nbsp; &nbsp; &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c3ohEg6H4nJPEZz6C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 7, "extendedScore": null, "score": 9.823645502802007e-07, "legacy": true, "legacyId": "18707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T04:41:06.895Z", "modifiedAt": null, "url": null, "title": "How to deal with someone in a LessWrong meeting being creepy", "slug": "how-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "viewCount": null, "lastCommentedAt": "2015-03-14T21:29:56.224Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Douglas_Reay", "createdAt": "2012-02-19T14:40:26.403Z", "isAdmin": false, "displayName": "Douglas_Reay"}, "userId": "jpnrRPxHozDiGBqp2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qNkCGc3fRCRy5Gbbp/how-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "pageUrlRelative": "/posts/qNkCGc3fRCRy5Gbbp/how-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "linkUrl": "https://www.lesswrong.com/posts/qNkCGc3fRCRy5Gbbp/how-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20deal%20with%20someone%20in%20a%20LessWrong%20meeting%20being%20creepy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20deal%20with%20someone%20in%20a%20LessWrong%20meeting%20being%20creepy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkCGc3fRCRy5Gbbp%2Fhow-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20deal%20with%20someone%20in%20a%20LessWrong%20meeting%20being%20creepy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkCGc3fRCRy5Gbbp%2Fhow-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNkCGc3fRCRy5Gbbp%2Fhow-to-deal-with-someone-in-a-lesswrong-meeting-being-creepy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 483, "htmlBody": "<p>One of the lessons highlighted in the thread \"<a href=\"/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">Less Wrong NYC: Case Study of a Successful Rationalist Chapter</a>\" is <strong>Gender ratio matters</strong>.</p>\n<p>There have recently been a number of articles addressing one social skills issue that might be affecting this, from the perspective of a geeky/sciencefiction community with similar attributes to LessWrong, and I want to link to these, not just so the people potentially causing problems get to read them, but also so everyone else knows the resource is there and has a name for the problem, which may facilitate wider discussion and make it easier for others to know when to point towards the resources those who would benefit by them.</p>\n<p>However before I do, in the light of <a href=\"/user/RedRobot/\">RedRobot</a>'s comment in the \"<a href=\"/lw/ap/of_gender_and_rationality/\">Of Gender and Rationality</a>\" thread, I'd like to echo a sentiment from one of the articles, that people exhibiting this behaviour may be of any gender and may victimise upon any gender.&nbsp;&nbsp; And so, while it may be correlated with a particular gender, it is the behaviour that should be focused upon, and turning this thread into bashing of one gender (or defensiveness against perceived bashing) would be unhelpful.</p>\n<p>Ok, disclaimers out of the way, here are the links:</p>\n<ul>\n<li><a href=\"http://whatever.scalzi.com/2012/08/09/an-incomplete-guide-to-not-creeping/\">An Incomplete Guide to Not Creeping</a></li>\n<li><a href=\"http://www.doctornerdlove.com/2011/12/dont-be-a-creeper/all/1/\">Don&rsquo;t Be A Creeper</a></li>\n<li><a href=\"http://pervocracy.blogspot.co.uk/2011/07/how-to-not-be-creepy.html\">How to not be creepy</a></li>\n<li><a href=\"http://captainawkward.com/2012/08/07/322-323-my-friend-group-has-a-case-of-the-creepy-dude-how-do-we-clear-that-up/\">My friend group has a case of the Creepy Dude. How do we clear that up?</a></li>\n<li><a href=\"http://captainawkward.com/2012/08/11/the-c-word/\">The C-Word</a></li>\n</ul>\n<p>Some of those raise deeper issues about <a href=\"http://en.wikipedia.org/wiki/Rape_culture#Feminist_theory\">rape culture</a> and <a href=\"http://blog.indieflix.com/2012/04/bystanders/\">audience as enabler</a>, but the TLDR summary is:</p>\n<ol>\n<li>Creepy behaviour is behaviour that tends to make others feel unsafe or uncomfortable.</li>\n<li>If a significant fraction of a group find your behaviour creepy, the responsibility to change the behaviour is yours.</li>\n<li>There are specific objective behaviours listed in the articles (for example, to do with touching, sexual jokes and following people) that even someone 'bad' at social skills can learn to avoid doing.</li>\n<li>If someone is informed that their behaviour is creeping people out, and yet they don't take steps to avoid doing these behaviours, that is a serious problem for the group as a whole, and it needs to be treated seriously and be seen to be treated seriously, especially by the 'audience' who are not being victimised directly.</li>\n</ol>\n<p>EDITED TO ADD:</p>\n<p>Despite the way some of the links are framed as being addressed to creepers, this post is aimed at least as much at the community as a whole, intended to trigger a discussion on how the community should best go about handling such a problem once identified, with the TLDR being \"set of restraints to place on someone who is burning the commons\", rather that a complete description that guarantees that anyone who doesn't meet it isn't creepy.&nbsp; (Thank you to jsteinhardt for clearly verbalising the misinterpretation - for discussion see <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7egj\">his reply to this post</a>)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1, "T57Qd9J3AfxmwhQtY": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qNkCGc3fRCRy5Gbbp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 64, "baseScore": 31, "extendedScore": null, "score": 7.2e-05, "legacy": true, "legacyId": "18341", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 774, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CsKboswS3z5iaiutC", "xsyG7PkMekHud2DMK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2012-09-09T04:41:06.895Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T04:50:10.943Z", "modifiedAt": null, "url": null, "title": "Meetup report: How harmful is cannabis, and will you change your habits?", "slug": "meetup-report-how-harmful-is-cannabis-and-will-you-change", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:07.467Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tEnr7S9BwgubF3E2p/meetup-report-how-harmful-is-cannabis-and-will-you-change", "pageUrlRelative": "/posts/tEnr7S9BwgubF3E2p/meetup-report-how-harmful-is-cannabis-and-will-you-change", "linkUrl": "https://www.lesswrong.com/posts/tEnr7S9BwgubF3E2p/meetup-report-how-harmful-is-cannabis-and-will-you-change", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20report%3A%20How%20harmful%20is%20cannabis%2C%20and%20will%20you%20change%20your%20habits%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20report%3A%20How%20harmful%20is%20cannabis%2C%20and%20will%20you%20change%20your%20habits%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtEnr7S9BwgubF3E2p%2Fmeetup-report-how-harmful-is-cannabis-and-will-you-change%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20report%3A%20How%20harmful%20is%20cannabis%2C%20and%20will%20you%20change%20your%20habits%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtEnr7S9BwgubF3E2p%2Fmeetup-report-how-harmful-is-cannabis-and-will-you-change", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtEnr7S9BwgubF3E2p%2Fmeetup-report-how-harmful-is-cannabis-and-will-you-change", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 295, "htmlBody": "<p>&nbsp;</p>\n<p><a href=\"/lw/eab/meetup_berkeley_meetup_cannabis_decisionmaking/\">A week ago</a> the meetup group in Berkeley discussed a new article&nbsp;in PNAS titled <a href=\"http://www.pnas.org/content/early/2012/08/22/1206820109\">\"Persistent cannabis users show neuropsychological decline from childhood to midlife\"</a>. Several people who didn't attend said they were interested in how that conversation went.</p>\n<p>Before discussing the specifics of the article, we went around the room and stated how many IQ points we'd be willing to spend for some level of cannabis use. The median answer given was 4 points for moderate usage. Then someone pointed out that since we responded out loud, there may have been an anchoring effect here.</p>\n<p>My understanding of the group's understanding of the scientific result is that smoking so much marijuana that you're diagnosable as cannabis-dependent (whatever that means) before the age of 18 will give you an IQ hit of 9-11 points, maybe more, over 20 years, compared to nonusers.</p>\n<p>People who were diagnosable as dependent on cannabis but not before 18 got an IQ hit of 4 or 5 points, on average. We don't know if this is because cannabis is bad for adults, or if it's bad for people just over 18.</p>\n<p>People who have used cannabis but were not diagnosed as dependent got an IQ hit of 1 or 2 points on average. The article gives us little information on what the risks of various moderate levels of cannabis use are.</p>\n<p>We didn't discuss any methodological errors in the study, but the general attitude of the group was that the scientific result is worth taking seriously.</p>\n<p>After the discussion, people who use cannabis opportunistically or not at all &mdash; especially the younger attendees &mdash; said that after learning about the study they now have another reason not to use cannabis. One person who uses cannabis less than once per week said they wouldn't change their usage habits.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tEnr7S9BwgubF3E2p", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 19, "extendedScore": null, "score": 9.82596106120064e-07, "legacy": true, "legacyId": "18709", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["o2fkcocBcvqkHSLua"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T05:35:43.389Z", "modifiedAt": null, "url": null, "title": "Interested in learning Linux? Need hosting? Free shells!", "slug": "interested-in-learning-linux-need-hosting-free-shells", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.199Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JohnWittle", "createdAt": "2011-08-31T09:09:33.751Z", "isAdmin": false, "displayName": "JohnWittle"}, "userId": "xvjDLm9LxcgexuteF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pbgukiwjCyCxQswrT/interested-in-learning-linux-need-hosting-free-shells", "pageUrlRelative": "/posts/pbgukiwjCyCxQswrT/interested-in-learning-linux-need-hosting-free-shells", "linkUrl": "https://www.lesswrong.com/posts/pbgukiwjCyCxQswrT/interested-in-learning-linux-need-hosting-free-shells", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Interested%20in%20learning%20Linux%3F%20Need%20hosting%3F%20Free%20shells!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInterested%20in%20learning%20Linux%3F%20Need%20hosting%3F%20Free%20shells!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpbgukiwjCyCxQswrT%2Finterested-in-learning-linux-need-hosting-free-shells%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Interested%20in%20learning%20Linux%3F%20Need%20hosting%3F%20Free%20shells!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpbgukiwjCyCxQswrT%2Finterested-in-learning-linux-need-hosting-free-shells", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpbgukiwjCyCxQswrT%2Finterested-in-learning-linux-need-hosting-free-shells", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 344, "htmlBody": "<div id=\"body_t1_7c47\" class=\"comment-content \">\n<div class=\"md\">\n<h2>Sign up form: <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dFRIb2VZMEJXSEIzQzAxV3V2UnhQM2c6MQ#gid=0\">Click Here</a><br /></h2>\n<p>&nbsp;</p>\n<p>I own a personal server running Debian Squeeze which has a 1Gb/s symmetric connection and 15TB per month bandwidth.</p>\n<p>I am offering free shell accounts to lesswrongers, with one contingency:</p>\n<p>You'll be placed in a usergroup, 'lw', as opposed to various other usergroups for various other communities I belong to, which will be in other usergroups. Anything that ends up in /var/log is fair game. I intend to make lots of graphs and post them on all the communities I belong to. There won't be any personally identifying data in anything that ends up publicly.</p>\n<p>Your shell account will start out with a disk quota of 5g, and if you need more you can ask me. I'm totally cool with you seeding your torrents. I do not intend to terminate accounts at any point for inactivity or otherwise; you can reasonably expect to have access for at least a year, probably longer.</p>\n<p>Fill out the form at the top of the page, query me on freenode's irc (JohnWittle), send me an email: johnwittle@gmail.com, or reply to this thread with your own contact information.</p>\n<p>If you'd like to ask questions about the server, or what good such a service might be for you, point your IRC client at johnwittle.com and /join #shells (you should also do this if you sign up), or find me on freenode, or comment below.</p>\n<p><del>Also, while the results of my analysis are likely to go in Discussion, I was wondering if this offering of free service itself might go in discussion. I asked in IRC and was told that advertisements are seriously frowned upon and that I would lose all my karma.</del> I was told that this is not too similar to advertising, and that it would fly.</p>\n<p>Edit: As far as illicit activities go... I am precommitting here to fully cooperating with any law enforcement entities who approach me with regards to the server. By using the server, you are agreeing to abstain from any activities which will get me in trouble <strong>even if</strong> I cooperate fully with law enforcement.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pbgukiwjCyCxQswrT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 41, "extendedScore": null, "score": 9.826197079928174e-07, "legacy": true, "legacyId": "18710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T05:42:18.054Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Competent Elites", "slug": "seq-rerun-competent-elites", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b3YaSWEXefNvPzkJT/seq-rerun-competent-elites", "pageUrlRelative": "/posts/b3YaSWEXefNvPzkJT/seq-rerun-competent-elites", "linkUrl": "https://www.lesswrong.com/posts/b3YaSWEXefNvPzkJT/seq-rerun-competent-elites", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Competent%20Elites&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Competent%20Elites%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb3YaSWEXefNvPzkJT%2Fseq-rerun-competent-elites%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Competent%20Elites%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb3YaSWEXefNvPzkJT%2Fseq-rerun-competent-elites", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb3YaSWEXefNvPzkJT%2Fseq-rerun-competent-elites", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<p>Today's post, <a href=\"/lw/ub/competent_elites/\">Competent Elites</a> was originally published on 27 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Competent_Elites\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>People in higher levels of business, science, etc, often really are there because they're significantly more competent than everyone else.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/efk/seq_rerun_the_level_above_mine/\">The Level Above Mine</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b3YaSWEXefNvPzkJT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 9.826230577405243e-07, "legacy": true, "legacyId": "18711", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CKpByWmsZ8WmpHtYa", "XTvRDYEvw8L23ctFN", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T08:39:48.280Z", "modifiedAt": null, "url": null, "title": "Call for Anonymous Narratives by LW Women and Question Proposals (AMA)", "slug": "call-for-anonymous-narratives-by-lw-women-and-question", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.685Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tBraZAHvj2zacSxxu/call-for-anonymous-narratives-by-lw-women-and-question", "pageUrlRelative": "/posts/tBraZAHvj2zacSxxu/call-for-anonymous-narratives-by-lw-women-and-question", "linkUrl": "https://www.lesswrong.com/posts/tBraZAHvj2zacSxxu/call-for-anonymous-narratives-by-lw-women-and-question", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Call%20for%20Anonymous%20Narratives%20by%20LW%20Women%20and%20Question%20Proposals%20(AMA)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACall%20for%20Anonymous%20Narratives%20by%20LW%20Women%20and%20Question%20Proposals%20(AMA)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtBraZAHvj2zacSxxu%2Fcall-for-anonymous-narratives-by-lw-women-and-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Call%20for%20Anonymous%20Narratives%20by%20LW%20Women%20and%20Question%20Proposals%20(AMA)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtBraZAHvj2zacSxxu%2Fcall-for-anonymous-narratives-by-lw-women-and-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtBraZAHvj2zacSxxu%2Fcall-for-anonymous-narratives-by-lw-women-and-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1031, "htmlBody": "<p>In another discussion going on right now, I posted <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dou\">this proposal</a>, asking for feedback on this experiment. The feedback was positive, so here goes...</p>\n<p>Original Post:</p>\n<blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">When these gender discussions come up, I am often tempted to write in with my own experiences and desires. But I generally don't because I don't want to generalize from one example, or claim to be the Voice of Women, etc. However, according to the last survey, I actually AM over 1% of the females on here, and so is every other woman. (i.e. there are less than 100 of us).</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">My idea is to put out a call for women on LessWrong to write openly about their experiences and desires in this community, and send them to me. I will anonymize them all, and put them all up under one post.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">This would have a couple of benefits, including:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">\n<li>\n<p style=\"margin: 0px 0px 1em; \">Anonymity allows for open expression- When you are in the vast minority, speaking out can feel like \"swimming upstream,\" and so may not happen very much.</p>\n</li>\n<li>\n<p style=\"margin: 0px 0px 1em; \">Putting all the women's responses in one posts helps figure out what is/is not a problem- Because of the gender ratio, most discussions on the topic are Men Talking About what Women Want, it can be hard to figure out what&nbsp;<em>women</em>&nbsp;are saying on the issues, versus what men are saying women say.</p>\n</li>\n<li>\n<p style=\"margin: 0px 0px 1em; \">The plural of anecdote is data- If one woman says X, it is an anecdote, and very weak evidence. If 10% of women say X, it is much stronger evidence.</p>\n</li>\n</ul>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Note that with a lot of the above issues, one of the biggest problems in figuring out what is going on isn't purposeful misogyny or anything. Just the fact that the gender ratio is so skewed can make it difficult to hear women (think picking out one voice amongst ten). The idea I'm proposing is an attempt to work around this, not an attempt to marginalize men, who may also have important things to say, but would not be the focus of this investigation.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Even with a sample size of 10 responses (approximately the amount I would say is needed for this to be useful), according to the last survey, that is 10% of the women on this site. A sizable proportion, indeed.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>In the following discussion, the idea was added that fellow LWers could submit questions to the Women of LW. The women can then use these as prompts in their narratives, if they like. If you are interested in submitting questions, please read the guidelines below in \"Call for Questions\" before posting.</p>\n<p>If you are interested in submitting a narrative, please read the Call for Narrative section below.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<h2>Call for Narratives</h2>\n<p><strong>RSVP</strong> -(<strong>ETA- We have reached the needed number of pre-commitments!</strong> You do not need to fill out the form, although you are welcome to, if you like) I think we need to have at least 6 people submitting narratives to provide both the scope and the anonymity to work. So before I ask women to spend their time writing these, I would like to make sure we will get enough submissions to publish. If you are going to write a narrative, <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dFJNenpoSTFzSHRqNThJdTBsNk1SN3c6MQ#gid=0\">fill out this (one-minute) form</a> in the next couple days. If we get at least 6 women pre-committed to writing a narrative, we will move forward. I will PM or email you and let you know. If, in a week, we have not had at least 6 commitments, I will close the form.</p>\n<p><strong>Submissions</strong>- Feel free to submit, even if you did not RSVP. (that part is just to make sure we have minimum amount of people). Just send me a pm, dropbox link, or ask for my email. I'll add more information to this, as it gets worked out.&nbsp;</p>\n<p>Although the discussion that spurred this idea was about \"creep\" behaviors, please don't limit your responses to that subject only. Feel free to discuss any gender-related issues that you find relevant, especially responses to the questions that are posted in the thread below by your fellow LWers.</p>\n<p>The anonymity is to provide you with the opportunity to express non-self-censored thoughts. It is ok if they are half-formed, stream-of-consciousness writings. My goal is to find out what the women on this site think, not nit-pick at the writing style. I don't want to limit submissions by saying that they have to have hours spent on formulating, organizing, and clarifying them. Write as much as you like. Don't worry about length. I will write tl;dr's if needed.</p>\n<p>How I organize the submissions in the final post depends strongly on what is submitted to me. Separate out things that you think are identifiable to you, and I will put them in a section that is not affiliated with the rest of your submission.</p>\n<p><strong>Submissions are due Sept 25th!</strong></p>\n<p><strong>Security</strong>- I am willing to work with people individually to make sure that their narratives aren't identifiable via writing style or little clues. Discussions that are obviously written by you (for example, talking about an incident many LWers know about) can be pulled out of your main narrative, and placed in a separate section. (reading the <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dp7\">original exchange</a>&nbsp;on the topic&nbsp;will clarify what I am trying to explain)</p>\n<p><strong>Verification</strong>- Submissions must be linked to active LW accounts (i.e. older than a week, more than 50 karma). This info will only be known to me. When possible, I would like to have validation (such as a link to a relevant post) that the account is of a female or transgendered user. &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h2>Call for Questions</h2>\n<p>Feel free to ask questions you would like answered by the women of LW. To make everything easier for us, remember the following:</p>\n<p><span style=\"white-space: pre;\"> </span>1) Put questions in response to the comment entitled \"Question submissions\"</p>\n<p><span style=\"white-space: pre;\"> </span>2)Due to the nature of this experiment, all questions will automatically assumed to be operating under Crocker's Rules.</p>\n<p><strong><span style=\"white-space: pre;\"> </span>&nbsp;3) Please only post one question per comment!</strong></p>\n<p>Upvote questions you would like to see answered. The questions with the highest amounts of upvotes are probably the most likely to be answered (based on my model of fellow LW Women).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tBraZAHvj2zacSxxu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 30, "extendedScore": null, "score": 9.827134603823749e-07, "legacy": true, "legacyId": "18712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In another discussion going on right now, I posted <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dou\">this proposal</a>, asking for feedback on this experiment. The feedback was positive, so here goes...</p>\n<p>Original Post:</p>\n<blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">When these gender discussions come up, I am often tempted to write in with my own experiences and desires. But I generally don't because I don't want to generalize from one example, or claim to be the Voice of Women, etc. However, according to the last survey, I actually AM over 1% of the females on here, and so is every other woman. (i.e. there are less than 100 of us).</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">My idea is to put out a call for women on LessWrong to write openly about their experiences and desires in this community, and send them to me. I will anonymize them all, and put them all up under one post.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">This would have a couple of benefits, including:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">\n<li>\n<p style=\"margin: 0px 0px 1em; \">Anonymity allows for open expression- When you are in the vast minority, speaking out can feel like \"swimming upstream,\" and so may not happen very much.</p>\n</li>\n<li>\n<p style=\"margin: 0px 0px 1em; \">Putting all the women's responses in one posts helps figure out what is/is not a problem- Because of the gender ratio, most discussions on the topic are Men Talking About what Women Want, it can be hard to figure out what&nbsp;<em>women</em>&nbsp;are saying on the issues, versus what men are saying women say.</p>\n</li>\n<li>\n<p style=\"margin: 0px 0px 1em; \">The plural of anecdote is data- If one woman says X, it is an anecdote, and very weak evidence. If 10% of women say X, it is much stronger evidence.</p>\n</li>\n</ul>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Note that with a lot of the above issues, one of the biggest problems in figuring out what is going on isn't purposeful misogyny or anything. Just the fact that the gender ratio is so skewed can make it difficult to hear women (think picking out one voice amongst ten). The idea I'm proposing is an attempt to work around this, not an attempt to marginalize men, who may also have important things to say, but would not be the focus of this investigation.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Even with a sample size of 10 responses (approximately the amount I would say is needed for this to be useful), according to the last survey, that is 10% of the women on this site. A sizable proportion, indeed.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>In the following discussion, the idea was added that fellow LWers could submit questions to the Women of LW. The women can then use these as prompts in their narratives, if they like. If you are interested in submitting questions, please read the guidelines below in \"Call for Questions\" before posting.</p>\n<p>If you are interested in submitting a narrative, please read the Call for Narrative section below.</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<h2 id=\"Call_for_Narratives\">Call for Narratives</h2>\n<p><strong>RSVP</strong> -(<strong>ETA- We have reached the needed number of pre-commitments!</strong> You do not need to fill out the form, although you are welcome to, if you like) I think we need to have at least 6 people submitting narratives to provide both the scope and the anonymity to work. So before I ask women to spend their time writing these, I would like to make sure we will get enough submissions to publish. If you are going to write a narrative, <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dFJNenpoSTFzSHRqNThJdTBsNk1SN3c6MQ#gid=0\">fill out this (one-minute) form</a> in the next couple days. If we get at least 6 women pre-committed to writing a narrative, we will move forward. I will PM or email you and let you know. If, in a week, we have not had at least 6 commitments, I will close the form.</p>\n<p><strong>Submissions</strong>- Feel free to submit, even if you did not RSVP. (that part is just to make sure we have minimum amount of people). Just send me a pm, dropbox link, or ask for my email. I'll add more information to this, as it gets worked out.&nbsp;</p>\n<p>Although the discussion that spurred this idea was about \"creep\" behaviors, please don't limit your responses to that subject only. Feel free to discuss any gender-related issues that you find relevant, especially responses to the questions that are posted in the thread below by your fellow LWers.</p>\n<p>The anonymity is to provide you with the opportunity to express non-self-censored thoughts. It is ok if they are half-formed, stream-of-consciousness writings. My goal is to find out what the women on this site think, not nit-pick at the writing style. I don't want to limit submissions by saying that they have to have hours spent on formulating, organizing, and clarifying them. Write as much as you like. Don't worry about length. I will write tl;dr's if needed.</p>\n<p>How I organize the submissions in the final post depends strongly on what is submitted to me. Separate out things that you think are identifiable to you, and I will put them in a section that is not affiliated with the rest of your submission.</p>\n<p><strong id=\"Submissions_are_due_Sept_25th_\">Submissions are due Sept 25th!</strong></p>\n<p><strong>Security</strong>- I am willing to work with people individually to make sure that their narratives aren't identifiable via writing style or little clues. Discussions that are obviously written by you (for example, talking about an incident many LWers know about) can be pulled out of your main narrative, and placed in a separate section. (reading the <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dp7\">original exchange</a>&nbsp;on the topic&nbsp;will clarify what I am trying to explain)</p>\n<p><strong>Verification</strong>- Submissions must be linked to active LW accounts (i.e. older than a week, more than 50 karma). This info will only be known to me. When possible, I would like to have validation (such as a link to a relevant post) that the account is of a female or transgendered user. &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h2 id=\"Call_for_Questions\">Call for Questions</h2>\n<p>Feel free to ask questions you would like answered by the women of LW. To make everything easier for us, remember the following:</p>\n<p><span style=\"white-space: pre;\"> </span>1) Put questions in response to the comment entitled \"Question submissions\"</p>\n<p><span style=\"white-space: pre;\"> </span>2)Due to the nature of this experiment, all questions will automatically assumed to be operating under Crocker's Rules.</p>\n<p><strong id=\"__3__Please_only_post_one_question_per_comment_\"><span style=\"white-space: pre;\"> </span>&nbsp;3) Please only post one question per comment!</strong></p>\n<p>Upvote questions you would like to see answered. The questions with the highest amounts of upvotes are probably the most likely to be answered (based on my model of fellow LW Women).</p>", "sections": [{"title": "Call for Narratives", "anchor": "Call_for_Narratives", "level": 1}, {"title": "Submissions are due Sept 25th!", "anchor": "Submissions_are_due_Sept_25th_", "level": 2}, {"title": "Call for Questions", "anchor": "Call_for_Questions", "level": 1}, {"title": " \u00a03) Please only post one question per comment!", "anchor": "__3__Please_only_post_one_question_per_comment_", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "374 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 375, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T16:10:20.498Z", "modifiedAt": null, "url": null, "title": "fimfiction.net LessWrong group", "slug": "fimfiction-net-lesswrong-group", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.202Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mv7ZqczXJrauhRFgq/fimfiction-net-lesswrong-group", "pageUrlRelative": "/posts/Mv7ZqczXJrauhRFgq/fimfiction-net-lesswrong-group", "linkUrl": "https://www.lesswrong.com/posts/Mv7ZqczXJrauhRFgq/fimfiction-net-lesswrong-group", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20fimfiction.net%20LessWrong%20group&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Afimfiction.net%20LessWrong%20group%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMv7ZqczXJrauhRFgq%2Ffimfiction-net-lesswrong-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=fimfiction.net%20LessWrong%20group%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMv7ZqczXJrauhRFgq%2Ffimfiction-net-lesswrong-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMv7ZqczXJrauhRFgq%2Ffimfiction-net-lesswrong-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 31, "htmlBody": "<p>There is now a <a href=\"http://www.fimfiction.net/index.php?view=group&amp;group=1418\">LessWrong group</a> on fimfiction, to let LWers on fimfiction find each other and collect stories that might be of interest to them.&nbsp; (That?&nbsp; Which?&nbsp; Grammar Nazis, help!)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mv7ZqczXJrauhRFgq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 9.829429848922037e-07, "legacy": true, "legacyId": "18713", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T17:06:31.727Z", "modifiedAt": null, "url": null, "title": "[Link] Article about rationality and CFAR", "slug": "link-article-about-rationality-and-cfar", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.834Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Despard", "createdAt": "2012-06-11T21:21:52.973Z", "isAdmin": false, "displayName": "Despard"}, "userId": "inrBDZgvL5FzK6584", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X6YSv2Gj8MtonkDZG/link-article-about-rationality-and-cfar", "pageUrlRelative": "/posts/X6YSv2Gj8MtonkDZG/link-article-about-rationality-and-cfar", "linkUrl": "https://www.lesswrong.com/posts/X6YSv2Gj8MtonkDZG/link-article-about-rationality-and-cfar", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Article%20about%20rationality%20and%20CFAR&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Article%20about%20rationality%20and%20CFAR%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX6YSv2Gj8MtonkDZG%2Flink-article-about-rationality-and-cfar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Article%20about%20rationality%20and%20CFAR%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX6YSv2Gj8MtonkDZG%2Flink-article-about-rationality-and-cfar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX6YSv2Gj8MtonkDZG%2Flink-article-about-rationality-and-cfar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<p>http://issuu.com/nervemag/docs/issue-2?mode=window&amp;pageNumber=18</p>\n<p>A friend of mine runs Nerve, the new science magazine at the university where I work, and I offered to write about rationality for their second issue. The article is just out, with some quotes from some people you might recognise! Enjoy.</p>\n<p>EDIT: the Wordpress version is now up, for those allergic to Flash.</p>\n<p>http://nervemag.wordpress.com/2012/09/11/why-are-smart-people-so-stupid/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X6YSv2Gj8MtonkDZG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 9.829716158870606e-07, "legacy": true, "legacyId": "18714", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-09T23:45:40.808Z", "modifiedAt": null, "url": null, "title": "Chief Probability Officer", "slug": "chief-probability-officer", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:27.021Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zgcfswz2p3Rjo9Drr/chief-probability-officer", "pageUrlRelative": "/posts/zgcfswz2p3Rjo9Drr/chief-probability-officer", "linkUrl": "https://www.lesswrong.com/posts/zgcfswz2p3Rjo9Drr/chief-probability-officer", "postedAtFormatted": "Sunday, September 9th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Chief%20Probability%20Officer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChief%20Probability%20Officer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzgcfswz2p3Rjo9Drr%2Fchief-probability-officer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Chief%20Probability%20Officer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzgcfswz2p3Rjo9Drr%2Fchief-probability-officer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzgcfswz2p3Rjo9Drr%2Fchief-probability-officer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 603, "htmlBody": "<p>Stanford Professor Sam Savage (also of <a href=\"http://probabilitymanagement.org/\">Probability Management</a>) <a href=\"http://probabilitymanagement.org/Library/Probability_Management_Part1s.pdf\">proposes</a> that large firms appoint a \"Chief Probability Officer.\" Here is a description from Douglas Hubbard's&nbsp;<em><a href=\"http://www.amazon.com/How-Measure-Anything-Intangibles-Business/dp/0470539399/\">How to Measure Anything</a></em>, ch. 6:</p>\n<blockquote>\n<p>&nbsp;</p>\n<p>Sam Savage... has some ideas about how to institutionalize the entire process of creating Monte Carlo simulations [for estimating risk].</p>\n<p>...His idea is to appoint a chief probability officer (CPO) for the firm. The CPO would be in charge of managing a common library of probability distributions for use by anyone running Monte Carlo simulations. Savage invokes concepts like the Stochastic Information Packet (SIP), a pregenerated set of 100,000 random numbers for a particular value. Sometimes different SIPs would be related. For example, the company&rsquo;s revenue might be related to national economic growth. A set of SIPs that are generated so they have these correlations are called &ldquo;SLURPS&rdquo; (Stochastic Library Units with Relationships Preserved). The CPO would manage SIPs and SLURPs so that users of probability distributions don&rsquo;t have to&nbsp;reinvent the wheel every time they need to simulate inflation or healthcare costs.</p>\n<p>&nbsp;</p>\n</blockquote>\n<p><a href=\"http://howtomeasureanything.com/\">Hubbard</a> adds some of his own ideas to the proposal:</p>\n<p>&nbsp;</p>\n<blockquote>\n<ul>\n<li><em>Certification of analysts</em>. Right now, there is not a lot of quality control for decision analysis experts. Only actuaries, in their particular specialty of decision analysis, have extensive certification requirements. As for actuaries, certification in decision analysis should eventually be an independent not-for-profit program run by a professional association. Some other professional certifications now partly cover these topics but fall far short in substance in this particular area. For this reason, I began certifying individuals in Applied Information Economics because there was an immediate need for people to be able to prove their skills to potential employers.</li>\n<li><em>Certification for calibrated estimators</em>. As we discussed earlier, an uncalibrated estimator has a strong tendency to be overconfident. Any calculation of risk based on his or her estimates will likely be significantly understated. However, a survey I once conducted showed that calibration is almost unheard of among those who build Monte Carlo models&nbsp;professionally, even though a majority used at least some subjective estimates. (About a third surveyed used mostly subjective estimates.) Calibration training will be one of the simplest improvements to risk analysis in an organization. </li>\n<li><em>Well-documented procedures and templates for how models are built from the input of various calibrated estimators</em>. It takes some time to smooth out the wrinkles in the process. Most organizations don&rsquo;t need to start from scratch for every new investment they are analyzing; they can base their work on that of others or at least reuse their own prior models. I&rsquo;ve executed nearly the same analysis procedure following similar project plans for a wide variety of decision analysis problems from IT security, military logistics, and entertainment industry investments. But when I applied the same method in the same organization on different problems, I often found that certain parts of the model would be similar to parts of earlier models. An insurance company would have several investments that include estimating the impact on &ldquo;customer retention&rdquo; and &ldquo;claims payout ratio.&rdquo; Manufacturing-related investments would have calculations related to &ldquo;marginal labor costs per unit&rdquo; or &ldquo;average order fulfillment time.&rdquo; These issues don&rsquo;t have to be modeled anew for each new investment problem. They are&nbsp;reusable modules in spreadsheets.&nbsp;</li>\n<li><em>Adoption of a single automated tool set</em>. [In this book I show] a few of the many tool sets available. You can get as sophisticated as you like, but starting out doesn&rsquo;t require any more than some good spreadsheet-based tools. I recommend starting simple and adopting more extensive tool sets as the situations demand.</li>\n</ul>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zgcfswz2p3Rjo9Drr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 23, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "18716", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T01:02:01.972Z", "modifiedAt": null, "url": null, "title": "A My Little Pony fanfic allegedly but not mainly about immortality", "slug": "a-my-little-pony-fanfic-allegedly-but-not-mainly-about", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:33.997Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uPGZBGcBi7nRFwrZY/a-my-little-pony-fanfic-allegedly-but-not-mainly-about", "pageUrlRelative": "/posts/uPGZBGcBi7nRFwrZY/a-my-little-pony-fanfic-allegedly-but-not-mainly-about", "linkUrl": "https://www.lesswrong.com/posts/uPGZBGcBi7nRFwrZY/a-my-little-pony-fanfic-allegedly-but-not-mainly-about", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20My%20Little%20Pony%20fanfic%20allegedly%20but%20not%20mainly%20about%20immortality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20My%20Little%20Pony%20fanfic%20allegedly%20but%20not%20mainly%20about%20immortality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuPGZBGcBi7nRFwrZY%2Fa-my-little-pony-fanfic-allegedly-but-not-mainly-about%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20My%20Little%20Pony%20fanfic%20allegedly%20but%20not%20mainly%20about%20immortality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuPGZBGcBi7nRFwrZY%2Fa-my-little-pony-fanfic-allegedly-but-not-mainly-about", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuPGZBGcBi7nRFwrZY%2Fa-my-little-pony-fanfic-allegedly-but-not-mainly-about", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 308, "htmlBody": "<p>My Little Pony (generation 4) has 2 immortal characters, who get a lot of sympathy from the bronies.&nbsp; \"How sad!&nbsp; Poor Celestia and Luna must see everyone they know grow old and die.&nbsp; How much better to die yourself!\"</p>\n<p>I tried to write a fanfic saying that death was bad.&nbsp; But I had to make it a story, and it ended up having other themes.&nbsp; I don't know whether I like it or not, but it was very popular (now approaching 7000 views in 3 days on fimfiction).</p>\n<p>I was pretty sure the message \"death is bad\" was still in there, because Celestia says things like \"Death is bad\" and \"I'm afraid of dying.\"&nbsp; So imagine my surprise when comment after comment said, \"Yes, immortality is such a curse!\"<a id=\"more\"></a></p>\n<p>Why did so many people come away saying that?&nbsp; Tell me what you think.&nbsp; It will help to know that Twilight regularly writes \"friendship report\" letters to Celestia describing what she has learned about friendship, and that Twilight and Celestia have an especially close relationship.</p>\n<p>Please leave comments on the google doc or here on LessWrong, not on fimfiction or Equestria Daily.&nbsp; Please don't down-vote the story if you aren't familiar with the characters or aren't calibrated to fimfiction voting.</p>\n<p><em>Mortality Report</em> on <a href=\"https://docs.google.com/document/d/1ISmo_vK8fVBFfT9LRWOjomurskE3xjhuPEiXjJvb5wM/edit\">google docs</a> (comment-enabled), 4000 words.</p>\n<p>Spoilers after the bar.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>I can see two things that happened:</p>\n<ol>\n<li>I overplayed the \"death is bad\" angle, to the point where readers thought Celestia wanted to die to get away from having to deal with death.&nbsp; These readers didn't like the story as much, because they thought she was being selfish rather than selfless.</li>\n<li>Most readers who figured out the evolutionary plan kicked back hard and called it evil.&nbsp; That implied that Celestia was rationalizing very badly in agreeing to the plan in theory, and they then presumed her final actions were selfish.</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uPGZBGcBi7nRFwrZY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 13, "extendedScore": null, "score": 9.832139751855573e-07, "legacy": true, "legacyId": "18708", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T01:35:22.839Z", "modifiedAt": null, "url": null, "title": "Counterfactual Reprogramming Decision Theory", "slug": "counterfactual-reprogramming-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.555Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kEhSRsdhK6Dn9in7k/counterfactual-reprogramming-decision-theory", "pageUrlRelative": "/posts/kEhSRsdhK6Dn9in7k/counterfactual-reprogramming-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/kEhSRsdhK6Dn9in7k/counterfactual-reprogramming-decision-theory", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Counterfactual%20Reprogramming%20Decision%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACounterfactual%20Reprogramming%20Decision%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEhSRsdhK6Dn9in7k%2Fcounterfactual-reprogramming-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Counterfactual%20Reprogramming%20Decision%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEhSRsdhK6Dn9in7k%2Fcounterfactual-reprogramming-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEhSRsdhK6Dn9in7k%2Fcounterfactual-reprogramming-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 206, "htmlBody": "<p>Surprisingly, Ben Goertzel's (<a href=\"http://goertzel.org/CounterfactualReprogrammingDecisionTheory.pdf\">2010</a>)&nbsp;Counterfactual Reprogramming Decision Theory (CRDT) has not been discussed even once on Less Wrong, so I present this discussion post as an opportunity to do so.</p>\n<p>Here is Goertzel's abstract:</p>\n<blockquote>\n<p>\n<p>A novel variant of decision theory is presented. The basic idea is that one should ask, at each point in&nbsp;time: What would I do if the reprogrammable parts of my brain were reprogrammed by a superintelligent&nbsp;Master Programmer with the goal of supplying me with a program that would maximize my utility averaged&nbsp;over possible worlds? Problems such as the Prisoner's Dilemma, the value of voting, Newcomb's Problem&nbsp;and the Psychopath Button are reviewed from this perspective and shown to be addressed in a satisfactory&nbsp;way.</p>\n</p>\n</blockquote>\n<p>His first footnote acknowledges some debt to Less Wrong and to <a href=\"/user/Wei_Dai/submitted/\">Wei Dai</a> in particular:</p>\n<blockquote>\n<p>\n<p>Some interesting, albeit often confusing, discussion on CDT and hypothetical replacement decision theories may be found&nbsp;online at the Less Wrong blog... The decision algorithm presented by Dai on that blog page bears some resemblance to&nbsp;CRDT, but due to the rough and very informal exposition there, I'm not sure what is the precise relationship.</p>\n</p>\n</blockquote>\n<p>He also discusses Vladimir Nesov's <a href=\"/lw/3l/counterfactual_mugging/\">counterfactual mugging</a> scenario, and attempts to work toward a formalization of CRDT by making use of AIXI and some other stuff.</p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1, "YpHkTW27iMFR2Dkae": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kEhSRsdhK6Dn9in7k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 9.832309761421216e-07, "legacy": true, "legacyId": "18717", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mg6jDEuQEjBGtibX7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T05:41:16.398Z", "modifiedAt": null, "url": null, "title": "Elitism isn't necessary for refining rationality.", "slug": "elitism-isn-t-necessary-for-refining-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:53.859Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Epiphany", "createdAt": "2012-08-12T03:33:21.256Z", "isAdmin": false, "displayName": "Epiphany"}, "userId": "BbbFp6hQzKF4YX8em", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K9LvyLra4WSyJjZti/elitism-isn-t-necessary-for-refining-rationality", "pageUrlRelative": "/posts/K9LvyLra4WSyJjZti/elitism-isn-t-necessary-for-refining-rationality", "linkUrl": "https://www.lesswrong.com/posts/K9LvyLra4WSyJjZti/elitism-isn-t-necessary-for-refining-rationality", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Elitism%20isn't%20necessary%20for%20refining%20rationality.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AElitism%20isn't%20necessary%20for%20refining%20rationality.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9LvyLra4WSyJjZti%2Felitism-isn-t-necessary-for-refining-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Elitism%20isn't%20necessary%20for%20refining%20rationality.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9LvyLra4WSyJjZti%2Felitism-isn-t-necessary-for-refining-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK9LvyLra4WSyJjZti%2Felitism-isn-t-necessary-for-refining-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1958, "htmlBody": "<p>&nbsp; Note:&nbsp; After writing this post, I realized there's a lot I need to learn about this subject.&nbsp; I've been thinking a lot about how I use the word \"elitism\" and what it meant to me.&nbsp; I was unaware that there are a large number of people who use the word to describe themselves and mean something totally different from the definition that I had.&nbsp; This resulted in my perception that people who were using the word to describe themselves were being socially inept.&nbsp; I now realize that it's not a matter of social ineptness, that it may be more of a matter of political sides.&nbsp; I also realized that mind-kill reactions may be influencing us here (myself included).&nbsp; So, now my goal is to make sure I understand both sides thoroughly to transcend these mind-kill reactions and explain to others how I accomplished this so that none of us has to have them.&nbsp; I think these sides can get along better.&nbsp; That is what I ultimately want - for the gifted population and the rest of the world to understand one another better, for the privileged and the disadvantaged to understand one another better, and for the tensions between those groups to be reduced so that we can work together effectively.&nbsp; I realize that this is not a simple undertaking, but this is a very important problem to me.&nbsp; I see this being an ongoing project in my life.&nbsp; If I don't seem to understand your point of view on this topic, please help me update.&nbsp; I want to understand it.</p>\n<p>&nbsp;</p>\n<p>TLDR: OMG a bunch of people seem to want to use the word \"elitist\" to describe LessWrong but I know that this can provoke hatred.&nbsp; I don't want to be smeared as an elitist.&nbsp; I can't fathom why it would be necessary for us to call ourselves \"elitists\".</p>\n<p>&nbsp;</p>\n<p><del>I have noticed a current of elitism on LessWrong.&nbsp; I know that not every person here is an elitist, but there are enough people here <a href=\"/lw/ec2/preventing_discussion_from_being_watered_down_by/7bk2\">who seem to believe elitism is a good thing</a> (13 upvotes!?) that it's worth addressing this conflict.&nbsp; In my experience, the word \"elitism\" is a triggering word - it's not something you can use easily without offending people.&nbsp; Acknowledging intellectual differences is a touchy subject also, very likely to invite accusations of elitism.&nbsp; From what I've seen, I'm convinced that using the word \"elitism\" casually is a mistake, and referring to intellectual differences incautiously is also risky.</del></p>\n<p><del>Here, I analyze the motives behind the use of the word elitism, make a suggestion for what the main conflict is, mention a possible solution, talk about whether the solution is elitist, what elitism really means, and what the consequences may be if we allow ourselves to be seen as elitists.<br /><br />The theme I am seeing echoed throughout the threads where elitist comments surfaced is \"We want quality\" and \"We want a challenging learning environment\".&nbsp; I agree that quality goals and a challenging environment are necessary for refining rationality, but I disagree that elitism is needed.</del></p>\n<p><del>I think the problem comes in at the point where we think about <em>how </em>challenging the environment should be.&nbsp; There's a conflict between the website's main vision: spreading rationality (detailed in: <a href=\"/lw/66/rationality_common_interest_of_many_causes/\">Rationality: Common Interest of Many Causes</a>) and striving for the highest quality standards possible (detailed in <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/\">Well-Kept Gardens Die By Pacifism</a>).</del></p>\n<p><del>If the discussions are geared for beginners, advanced people will not learn.&nbsp; If the discussions are geared for advanced people, beginners are frustrated.&nbsp; It's built into our brains.&nbsp; Psychologist Mihaly Csikszentmihalyi, author of \"Flow: The psychology of optimal experience\" regards flow, the feeling of motivation and pleasure you get when you're appropriately challenged, to be <a href=\"http://www.ted.com/talks/mihaly_csikszentmihalyi_on_flow.html\">the secret to happiness</a> and he explains that if you aren't appropriately challenged, you're either going to feel bored or frustrated depending on whether the challenge is too small or too great for your ability level.</del></p>\n<p><del>Because our brains never stop rewarding and punishing us with flow, boredom and frustration, we strive for that appropriate challenge constantly.&nbsp; Because we're not all at the same ability level, we're not all going to flow during the same discussions.&nbsp; We can't expect this to change, and it's nobody's fault.</del></p>\n<p><del>This is a real conflict, but we don't have to choose between the elitist move of blocking everyone that's not at our level vs. the flow killing move of letting the challenge level in discussions decrease to the point where it results in everyone's apathy - we can solve this.</del></p>\n<p><del>Why bother to solve it?&nbsp; If your hope is to raise the sanity waterline, you cannot neglect those who are interested in rational thought but haven't yet gotten very far.&nbsp; Doing so would limit your impact to a small group, failing to make a dent in overall sanity.&nbsp; If you neglect the small group of advanced rationalists, then you've lost an important source of rational insights that people at every level might learn from and you will have failed to attract the few and precious teachers who will assist the beginners in developing further faster.</del></p>\n<p><del>And there is a solution; summarized in one paragraph:&nbsp; Make several areas divided by their level of difficulty.&nbsp; Advanced learners can learn in the advanced area, beginners in the beginner area.&nbsp; That way everyone learns.&nbsp; Not every advanced person is a teacher, but if you put a beginner area and an advanced area on the same site, some people from the advanced area will help get the beginners further.&nbsp; One-on-one teaching isn't the only option - advanced people might write articles for beginners and get through to thousands at once.&nbsp; They might write practice quizzes for them to do (not hard to implement from a web developer's perspective).&nbsp; There are other things.&nbsp; (I won't get into them here.)</del></p>\n<p><del>This brings me to another question: if LessWrong separates the learning levels, would the separation qualify as elitism?</del></p>\n<p><del>I think we can all agree that people don't learn well in classes that are too easy for them.&nbsp; If you want advanced people to improve, it's an absolute necessity to have an advanced area.&nbsp; I'm not questioning that.&nbsp; I'm questioning whether it qualifies under the definition of elitism:</del></p>\n<div class=\"header\">\n<h2 class=\"me\"><del>e&middot;lit&middot;ism</del></h2>\n</div>\n<div class=\"pbk\"><del><span class=\"pg\"><span id=\"hotword\"><span id=\"hotword\" style=\"color: #333333; cursor: default;\">noun</span> </span></span></del>\n<div class=\"luna-Ent\"><del><span class=\"dnindex\"><span id=\"hotword\"><span id=\"hotword\" style=\"color: #333333; cursor: default;\">1.</span></span></span><span id=\"hotword\"><span id=\"hotword\" style=\"color: #333333; cursor: default;\">&nbsp; practice</span> <span id=\"hotword\" style=\"color: #333333; cursor: default;\">of</span> <span id=\"hotword\">or</span> <span id=\"hotword\">belief</span> <span id=\"hotword\">in</span> <span id=\"hotword\">rule</span> <span id=\"hotword\">by</span> <span id=\"hotword\">an</span> </span><span><a style=\"font-style:normal; font-weight:normal;\" href=\"http://dictionary.reference.com/browse/elite\">elite</a><span id=\"hotword\">. </span></span></del></div>\n<div class=\"luna-Ent\"><del><span class=\"dnindex\"><span id=\"hotword\"><span id=\"hotword\">2.</span></span></span><span id=\"hotword\" style=\"color: #333333; cursor: default;\">&nbsp; consciousness</span> <span id=\"hotword\">of</span> <span id=\"hotword\">or</span> <span id=\"hotword\">pride</span> <span id=\"hotword\">in</span> <span id=\"hotword\">belonging</span> <span id=\"hotword\">to</span> <span id=\"hotword\">a</span> <span id=\"hotword\">select</span> <span id=\"hotword\">or</span> <span id=\"hotword\">favored</span> <span id=\"hotword\">group.</span></del>\n<div class=\"dndata\"><del><span id=\"hotword\"> </span></del></div>\n</div>\n</div>\n<p><del><a href=\"http://dictionary.reference.com/browse/elitism?s=t\">(dictionary.com)</a></del></p>\n<p><del>Spreading rationality empowers people. If you wanted to take power over them, you'd horde it.&nbsp; By posting our rational insights in public, we share them.&nbsp; We are not hoarding them and demanding to be made rulers because of our power.&nbsp; We are giving them away and hoping they improve the world.&nbsp;</del></p>\n<p><del>Using rationality as a basis for rule makes no sense anyway.&nbsp; If you have a better map of the territory, people should update because you have a better map (assuming you overcome <a href=\"/lw/kg/expecting_short_inferential_distances/\">inferential distances</a>).&nbsp; Forcing an update because you want to rule would only amount to an appeal to authority or coercion.&nbsp; That's not rational.&nbsp; If you show them a more complete map and they update, that isn't about you - you should be updating your map when the time comes, too.&nbsp; It's the territory that rules us all.&nbsp; You are only sharing your map.</del></p>\n<p><del>For the second definition, there are two pieces.&nbsp; \"Consciousness of or pride in\" and \"select or favored group\".&nbsp; I can tell you one thing for certain: if you form a group of intellectual elitists, they will not be considered \"select or favored\" by the general population.&nbsp; They will be treated as the scum on the bottom of scum's shoe.</del></p>\n<p><del>For that reason, any group of intellectual elitists will quickly become an oxymoron.&nbsp; First, they'll have to believe that they are \"select and favored\" when they are not, and perhaps justify this with \"we are so deserving of being select and favored that no one can see it but us\" (which may make them hopelessly unable to update).&nbsp; Second, the attitude of superiority is likely to provoke such anti-intellectual counter-prejudice that the resulting oppression could make them ineffectual.&nbsp; Powerless to get anywhere because they are so hated, their \"superiority\" will make them into second class citizens.&nbsp; You don't achieve elite status by being an intellectual elitist.</del></p>\n<p><del>In the event that LessWrong was considered \"select\" or \"favored\" by the outside population, would \"consciousness\" of that qualify the members as elitists?&nbsp; If you use the literal definition of \"consciousness\", you can claim a literal \"yes\" - but it would mean that simply acknowledging a (hypothetical) fact (independent market research surveys, we'll say) should be taken as automatic proof that you're an arrogant scumbag.&nbsp; That would be committing Yvain's \"worst argument in the world\", <a href=\"/lesswrong.com/lw/ee7/cleaning_up_the_worst_argument_essay\">guilt by association</a>.&nbsp; We can't assume that everyone who acknowledges popularity or excellence is guilty of wrongdoing.</del></p>\n<p><del>So let's ask this: Why does elitism have negative connotations? What does it REALLY mean when people call a group of intellectuals \"elitists\"?</del></p>\n<p><del>I think the answer to this is in Jane Elliot's brown eyes, blue eyes experiment.&nbsp; If you're not familiar with it, a school teacher named Jane Elliot, horrified by the assassination of Martin Luther King, Jr. decided to teach her class a lesson about prejudice.&nbsp; She divided the class into two groups - brown eyes and blue eyes.&nbsp; She told them things like brown eyed kids are smarter and harder-working than blue eyed kids.&nbsp; The children reacted dramatically:</del></p>\n<p><del><a href=\"http://www.uiowa.edu/~poroi/seminars/2004-5/bloom/poroi_paper.pdf\">\"When several of the brown-eyed kids who had problems reading went to their primer that morning, they whizzed through sentences\"</a></del></p>\n<p><del><a href=\"http://www.uiowa.edu/~poroi/seminars/2004-5/bloom/poroi_paper.pdf\">\"A smart blue-eyed girl, who had never had problems with her multiplication tables, started making all kinds of mistakes.\"<br /></a></del></p>\n<p><del><a href=\"http://www.uiowa.edu/~poroi/seminars/2004-5/bloom/poroi_paper.pdf\">\"During afternoon recess, the girl came running back to Room 10, sobbing. Three brown-eyed girls had ganged up on her, and one had hit her, warning, &ldquo;You better apologize to us for getting in our way because we&rsquo;re better than you are.\"</a></del></p>\n<p><del>When people complain of elitism, what they seem to be reacting to is a concern that feeling \"better than others\" will be used as an excuse for abuse - either via coercion, or by sabotaging their sense of self-worth and intellectual performance.</del></p>\n<p><del>The goal of LessWrong is to spread rationality in order to make a bigger difference in the world.&nbsp; This has nothing to do with abusing people.&nbsp; Just because some people with advanced abilities choose to use them as an excuse to abuse other people, it doesn't mean that anybody here has to do that.&nbsp; Just because some of us might have advanced abilities and are also aware of them does not mean we need to commit Yvain's \"the worst argument in the world\" by assuming the guilt that comes with elitism.&nbsp; We can reject this sort of thinking.&nbsp; If people tell you that you're an elitist because you want a challenging social environment to learn in, or because you want to make the project that is the LessWrong blog as high quality as it can be, you can refuse to be labeled guilty.</del></p>\n<p><del>Refusing to be guilty by association takes more work than accepting the status quo but what would happen if we allowed ourselves to be disrespected for challenging ourselves and striving for quality?&nbsp; If we agree with them, we're viewing positive character traits as part of a problem.&nbsp; That encourages people to shoot themselves in the foot - and they can point that same gun at all of humanity's potential, demanding that nobody seeks the challenging social environment they need to grow, that nobody sets any learning goals to strive for because quality standards are elitist.&nbsp; To allow a need for challenges and standards to be smeared as elitist will only hinder the spread of rationality.</del></p>\n<p><del>How many may forgo refining rationality because they worry it will make them look like an elitist?</del></p>\n<p><del>These are the reasons I choose to be non-abusive and to send a message to the world that non-abusive intellectuals exist.</del></p>\n<p><del>What do you think of this?</del></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K9LvyLra4WSyJjZti", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": -32, "extendedScore": null, "score": 9.833563501970752e-07, "legacy": true, "legacyId": "18715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 93, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4PPE6D635iBcGPGRy", "tscc3e5eujrsEeFN4", "HLqWn5LASfhhArZ7w"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T05:50:52.811Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Above-Average AI Scientists", "slug": "seq-rerun-above-average-ai-scientists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:34.515Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E5sLLdFRTCc5ZGJGM/seq-rerun-above-average-ai-scientists", "pageUrlRelative": "/posts/E5sLLdFRTCc5ZGJGM/seq-rerun-above-average-ai-scientists", "linkUrl": "https://www.lesswrong.com/posts/E5sLLdFRTCc5ZGJGM/seq-rerun-above-average-ai-scientists", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Above-Average%20AI%20Scientists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Above-Average%20AI%20Scientists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE5sLLdFRTCc5ZGJGM%2Fseq-rerun-above-average-ai-scientists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Above-Average%20AI%20Scientists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE5sLLdFRTCc5ZGJGM%2Fseq-rerun-above-average-ai-scientists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE5sLLdFRTCc5ZGJGM%2Fseq-rerun-above-average-ai-scientists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/uc/aboveaverage_ai_scientists/\">Above-Average AI Scientists</a> was originally published on 28 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Above-Average_AI_Scientists\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A lot of AI researchers aren't really all that exceptional. This is a problem, though most people don't seem to see it.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/efr/seq_rerun_competent_elites/\">Competent Elites</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E5sLLdFRTCc5ZGJGM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.833612489985132e-07, "legacy": true, "legacyId": "18730", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9HGR5qatMGoz4GhKj", "b3YaSWEXefNvPzkJT", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T12:36:46.075Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow: applied rationality and web resources", "slug": "meetup-moscow-applied-rationality-and-web-resources", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YEgRqchmdKaG9PFFA/meetup-moscow-applied-rationality-and-web-resources", "pageUrlRelative": "/posts/YEgRqchmdKaG9PFFA/meetup-moscow-applied-rationality-and-web-resources", "linkUrl": "https://www.lesswrong.com/posts/YEgRqchmdKaG9PFFA/meetup-moscow-applied-rationality-and-web-resources", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%3A%20applied%20rationality%20and%20web%20resources&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%3A%20applied%20rationality%20and%20web%20resources%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEgRqchmdKaG9PFFA%2Fmeetup-moscow-applied-rationality-and-web-resources%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%3A%20applied%20rationality%20and%20web%20resources%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEgRqchmdKaG9PFFA%2Fmeetup-moscow-applied-rationality-and-web-resources", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEgRqchmdKaG9PFFA%2Fmeetup-moscow-applied-rationality-and-web-resources", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dm'>Moscow: applied rationality and web resources</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 September 2012 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rossiya, Moscow, ulitsa Ostozhenka 14</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet at \u201cSubway\u201d restaurant, entrance from Lopukhinskiy pereulok. Look for a table with \u201cLW\u201d banner, I will be there from 16:00 MSK.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Applied rationality.</p></li>\n<li><p>Web resources about rationality.</p></li>\n<li><p>Planning regular meetups.</p></li>\n</ul>\n\n<p>If you are going for the first time, please fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dFpLNkFMLWRJUDZubkU3TlU4dDYxWVE6MQ\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, to introduce yourself and to help me to plan this meeting.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dm'>Moscow: applied rationality and web resources</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YEgRqchmdKaG9PFFA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 9.8356826409697e-07, "legacy": true, "legacyId": "18734", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow__applied_rationality_and_web_resources\">Discussion article for the meetup : <a href=\"/meetups/dm\">Moscow: applied rationality and web resources</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 September 2012 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rossiya, Moscow, ulitsa Ostozhenka 14</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet at \u201cSubway\u201d restaurant, entrance from Lopukhinskiy pereulok. Look for a table with \u201cLW\u201d banner, I will be there from 16:00 MSK.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Applied rationality.</p></li>\n<li><p>Web resources about rationality.</p></li>\n<li><p>Planning regular meetups.</p></li>\n</ul>\n\n<p>If you are going for the first time, please fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dFpLNkFMLWRJUDZubkU3TlU4dDYxWVE6MQ\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, to introduce yourself and to help me to plan this meeting.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow__applied_rationality_and_web_resources1\">Discussion article for the meetup : <a href=\"/meetups/dm\">Moscow: applied rationality and web resources</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow: applied rationality and web resources", "anchor": "Discussion_article_for_the_meetup___Moscow__applied_rationality_and_web_resources", "level": 1}, {"title": "Discussion article for the meetup : Moscow: applied rationality and web resources", "anchor": "Discussion_article_for_the_meetup___Moscow__applied_rationality_and_web_resources1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T14:12:40.516Z", "modifiedAt": null, "url": null, "title": "Meetup : Cancelled: Longmont Colorado Meetup", "slug": "meetup-cancelled-longmont-colorado-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4ZYg3qsgc9YKgJewk/meetup-cancelled-longmont-colorado-meetup", "pageUrlRelative": "/posts/4ZYg3qsgc9YKgJewk/meetup-cancelled-longmont-colorado-meetup", "linkUrl": "https://www.lesswrong.com/posts/4ZYg3qsgc9YKgJewk/meetup-cancelled-longmont-colorado-meetup", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cancelled%3A%20Longmont%20Colorado%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cancelled%3A%20Longmont%20Colorado%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ZYg3qsgc9YKgJewk%2Fmeetup-cancelled-longmont-colorado-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cancelled%3A%20Longmont%20Colorado%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ZYg3qsgc9YKgJewk%2Fmeetup-cancelled-longmont-colorado-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4ZYg3qsgc9YKgJewk%2Fmeetup-cancelled-longmont-colorado-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dn'>Cancelled: Longmont Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Ziggis, 400 Main Street, Longmont, CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Another trip to the south.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dn'>Cancelled: Longmont Colorado Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4ZYg3qsgc9YKgJewk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.836171910224216e-07, "legacy": true, "legacyId": "18735", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cancelled__Longmont_Colorado_Meetup\">Discussion article for the meetup : <a href=\"/meetups/dn\">Cancelled: Longmont Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Ziggis, 400 Main Street, Longmont, CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Another trip to the south.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cancelled__Longmont_Colorado_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/dn\">Cancelled: Longmont Colorado Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cancelled: Longmont Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Cancelled__Longmont_Colorado_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Cancelled: Longmont Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Cancelled__Longmont_Colorado_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T15:18:43.251Z", "modifiedAt": null, "url": null, "title": "Judea Pearl's Turing Award Lecture video now online", "slug": "judea-pearl-s-turing-award-lecture-video-now-online", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hr26aKshJu9hHjWfg/judea-pearl-s-turing-award-lecture-video-now-online", "pageUrlRelative": "/posts/hr26aKshJu9hHjWfg/judea-pearl-s-turing-award-lecture-video-now-online", "linkUrl": "https://www.lesswrong.com/posts/hr26aKshJu9hHjWfg/judea-pearl-s-turing-award-lecture-video-now-online", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Judea%20Pearl's%20Turing%20Award%20Lecture%20video%20now%20online&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJudea%20Pearl's%20Turing%20Award%20Lecture%20video%20now%20online%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhr26aKshJu9hHjWfg%2Fjudea-pearl-s-turing-award-lecture-video-now-online%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Judea%20Pearl's%20Turing%20Award%20Lecture%20video%20now%20online%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhr26aKshJu9hHjWfg%2Fjudea-pearl-s-turing-award-lecture-video-now-online", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhr26aKshJu9hHjWfg%2Fjudea-pearl-s-turing-award-lecture-video-now-online", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 39, "htmlBody": "<p>Lecture is titled \"The Mechanization of Causal Inference: A &ldquo;mini&rdquo; Turing Test and Beyond\"</p>\n<p>Includes basic overview of the subject and Judea's estimate of \"how it's going\" (I think there are some obvious implications to the AI issues discussed here)</p>\n<p><a href=\"http://amturing.acm.org/vp/pearl_2658896.cfm\">http://amturing.acm.org/vp/pearl_2658896.cfm</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hr26aKshJu9hHjWfg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 7, "extendedScore": null, "score": 9.836508865252976e-07, "legacy": true, "legacyId": "18736", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T17:04:49.430Z", "modifiedAt": null, "url": null, "title": "Meetup : Portland Oregon", "slug": "meetup-portland-oregon", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.901Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Allen", "createdAt": "2010-08-12T18:39:43.418Z", "isAdmin": false, "displayName": "David_Allen"}, "userId": "yKNx2drs5QMLT6iqu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dYzWGC8pHxfKuYwNB/meetup-portland-oregon", "pageUrlRelative": "/posts/dYzWGC8pHxfKuYwNB/meetup-portland-oregon", "linkUrl": "https://www.lesswrong.com/posts/dYzWGC8pHxfKuYwNB/meetup-portland-oregon", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Portland%20Oregon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Portland%20Oregon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdYzWGC8pHxfKuYwNB%2Fmeetup-portland-oregon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Portland%20Oregon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdYzWGC8pHxfKuYwNB%2Fmeetup-portland-oregon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdYzWGC8pHxfKuYwNB%2Fmeetup-portland-oregon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/do'>Portland Oregon</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 September 2012 12:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Lucky Labrador Tap Room 1700 North Killingsworth Street, Portland, OR</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://groups.google.com/group/lesswrong-portland\">LessWrong Portland</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/do'>Portland Oregon</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dYzWGC8pHxfKuYwNB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.8370502302999e-07, "legacy": true, "legacyId": "18737", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Portland_Oregon\">Discussion article for the meetup : <a href=\"/meetups/do\">Portland Oregon</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 September 2012 12:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Lucky Labrador Tap Room 1700 North Killingsworth Street, Portland, OR</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://groups.google.com/group/lesswrong-portland\">LessWrong Portland</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Portland_Oregon1\">Discussion article for the meetup : <a href=\"/meetups/do\">Portland Oregon</a></h2>", "sections": [{"title": "Discussion article for the meetup : Portland Oregon", "anchor": "Discussion_article_for_the_meetup___Portland_Oregon", "level": 1}, {"title": "Discussion article for the meetup : Portland Oregon", "anchor": "Discussion_article_for_the_meetup___Portland_Oregon1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T19:04:07.298Z", "modifiedAt": null, "url": null, "title": "Ted Talk Related to Rationality", "slug": "ted-talk-related-to-rationality", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hackerkiba", "createdAt": "2010-09-17T02:45:39.493Z", "isAdmin": false, "displayName": "hackerkiba"}, "userId": "LssGgJYPEsFHPwyLy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XWuFgXGkc3Md3h492/ted-talk-related-to-rationality", "pageUrlRelative": "/posts/XWuFgXGkc3Md3h492/ted-talk-related-to-rationality", "linkUrl": "https://www.lesswrong.com/posts/XWuFgXGkc3Md3h492/ted-talk-related-to-rationality", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ted%20Talk%20Related%20to%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATed%20Talk%20Related%20to%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXWuFgXGkc3Md3h492%2Fted-talk-related-to-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ted%20Talk%20Related%20to%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXWuFgXGkc3Md3h492%2Fted-talk-related-to-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXWuFgXGkc3Md3h492%2Fted-talk-related-to-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>Newly published presentation shows vividly why <a href=\"http://www.ted.com/talks/scott_fraser_the_problem_with_eyewitness_testimony.html\">eyewitness testimony</a> are false, ironically through storytelling based on the presenter's memory. This is something I know for quite a while, so I am&nbsp;glad&nbsp;that the knowledge is getting dispersed to a wider audience. It also shows how&nbsp;important our phones, dash cam, and our&nbsp;sousveillance units&nbsp;are in recording the truth.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XWuFgXGkc3Md3h492", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 9.837658981705062e-07, "legacy": true, "legacyId": "18738", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-10T21:58:05.689Z", "modifiedAt": null, "url": null, "title": "Kaj Sotala's Posts", "slug": "kaj-sotala-s-posts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:35.694Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bJ7vvyzBoiKSkFmTt/kaj-sotala-s-posts", "pageUrlRelative": "/posts/bJ7vvyzBoiKSkFmTt/kaj-sotala-s-posts", "linkUrl": "https://www.lesswrong.com/posts/bJ7vvyzBoiKSkFmTt/kaj-sotala-s-posts", "postedAtFormatted": "Monday, September 10th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kaj%20Sotala's%20Posts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKaj%20Sotala's%20Posts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbJ7vvyzBoiKSkFmTt%2Fkaj-sotala-s-posts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kaj%20Sotala's%20Posts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbJ7vvyzBoiKSkFmTt%2Fkaj-sotala-s-posts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbJ7vvyzBoiKSkFmTt%2Fkaj-sotala-s-posts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 452, "htmlBody": "<p>Here's an index of <a href=\"/user/Kaj_Sotala/\">Kaj_Sotala's</a> articles (not including meta posts):</p>\n<ul>\n<li><a href=\"/lw/8gv/the_curse_of_identity/\">The Curse of Identity</a> (108) </li>\n<li><a href=\"/lw/28k/the_psychological_diversity_of_mankind/\">The Psychological Diversity of Mankind</a> (71) </li>\n<li><a href=\"/lw/1to/what_is_bayesianism/\">What is Bayesianism?</a> (67) </li>\n<li><a href=\"/lw/9l3/the_substitution_principle/\">The Substitution Principle</a> (64) </li>\n<li><a href=\"/lw/9z0/avoid_misinterpreting_your_emotions/\">Avoid Misinterpreting Your Emotions</a> (61) </li>\n<li><a href=\"/lw/6yh/consistently_inconsistent/\">Consistently Inconsistent</a> (57) </li>\n<li><a href=\"/lw/aq2/fallacies_as_weak_bayesian_evidence/\">Fallacies as Weak Bayesian Evidence</a> (54) </li>\n<li><a href=\"/lw/akr/i_was_not_almost_wrong_but_i_was_almost_right/\">I Was Not Almost Wrong But I Was Almost Right</a> (50) </li>\n<li><a href=\"/lw/2l7/problems_in_evolutionary_psychology/\">Problems in Evolutionary Psychology</a> (50) </li>\n<li><a href=\"/lw/2et/what_cost_for_irrationality/\">What Cost for Irrationality</a> (50) </li>\n<li><a href=\"/lw/2bu/your_intuitions_are_not_magic/\">Your Intuitions are not Magic</a> (49) </li>\n<li><a href=\"/lw/1yz/levels_of_communication/\">Levels of Communication</a> (49) </li>\n<li><a href=\"/lw/2ey/a_taxonomy_of_bias_the_cognitive_miser/\">A Taxonomy of Bias: The Cognitive Miser</a> (48) </li>\n<li><a href=\"/lw/5r9/suffering_as_attentionallocational_conflict/\">Suffering as Attentional-allocational Conflict</a> (46) </li>\n<li><a href=\"/lw/aw/its_okay_to_be_at_least_a_little_irrational/\">It's Okay To Be At Least A Little Irrational</a> (45) </li>\n<li><a href=\"/lw/crs/how_to_run_a_successful_less_wrong_meetup/\">How to Run a Successful Less Wrong Meetup</a> (44) </li>\n<li><a href=\"/lw/11h/controlling_your_inner_control_circuits/\">Controlling Your Inner Control Circuits</a> (43) </li>\n<li><a href=\"/lw/2co/how_to_always_have_interesting_conversations/\">How to Always Have Interesting Conversations</a> (42) </li>\n<li><a href=\"/lw/1zu/compartmentalization_as_a_passive_phenomenon/\">Compartmentalization as a Passive Phenomenon</a> (42) </li>\n<li><a href=\"/lw/1kb/fundamentally_flawed_or_fast_and_frugal/\">Fundamentally Flawed or Fast and Frugal</a> (40) </li>\n<li><a href=\"/lw/dc5/thoughts_on_moral_intuitions/\">Thoughts on Moral Intuitions</a> (38) </li>\n<li><a href=\"/lw/21r/pain_and_gain_motivation/\">Pain and Gain Motivation</a> (37) </li>\n<li><a href=\"/lw/5xx/overcoming_suffering_emotional_acceptance/\">Overcoming Suffering: Emotional Acceptance</a> (35) </li>\n<li><a href=\"/lw/2g1/what_intelligence_tests_miss_the_psychology_of/\">What Intelligence Tests Miss the Psychology Of Rational Thought</a>&nbsp;(34) </li>\n<li><a href=\"/lw/1kp/are_these_cognitive_biases_biases/\">Are These Cognitive Biases, Biases?</a> (34) </li>\n<li><a href=\"/lw/2v/the_tragedy_of_the_anticommons/\">The Tragedy of the Anticommons</a> (32) </li>\n<li><a href=\"/lw/72d/strategic_ignorance_and_plausible_deniability/\">Strategic Ignorance and Plausible Deniability</a> (31) </li>\n<li><a href=\"/lw/5fu/what_data_generated_that_thought/\">What Data Generated That Thought?</a> (30) </li>\n<li><a href=\"/lw/2g0/a_rational_identity/\">A Rational Identity</a> (30)</li>\n<li><a href=\"/lw/7sc/siai_vs_fhi_achievements_20082010/\">SIAI vs. FHI Achivements (2008-2010)</a> (27) </li>\n<li><a href=\"/lw/1oc/you_cannot_be_mistaken_about_not_wanting_to/\">You Cannot be Mistaken About (not) Wanting to Wirehead</a> (27) </li>\n<li><a href=\"/lw/7aa/why_no_archive_of_refuted_research/\">Why No Archive of Refuted Research?</a> (25) </li>\n<li><a href=\"/lw/1qk/applying_utility_functions_to_humans_considered/\">Applying Utility Functions to Humans Considered Harmful</a> (25) </li>\n<li><a href=\"/lw/8z/rationalists_should_beware_rationalism/\">Rationalists Should Beware Rationalism</a> (23) </li>\n<li><a href=\"/lw/6z3/modularity_and_buzzy/\">Modularity and Buzzy</a> (23) </li>\n<li><a href=\"/lw/2el/applied_bayes_theorem_reading_people/\">Applied Bayes' Theorem: Reading People</a> (22) </li>\n<li><a href=\"/lw/8j4/5second_level_case_study_value_of_information/\">5-second Level Case Study: Value of Information</a> (21) </li>\n<li><a href=\"/lw/bs3/intelligence_explosion_vs_cooperative_explosion/\">Intelligence Explosion vs. Co-operative Explosion</a> (20) </li>\n<li><a href=\"/lw/aid/heuristics_and_biases_in_charity/\">Heuristics and Biases in Charity</a> (20) </li>\n<li><a href=\"/lw/6i/deliberate_and_spontaneous_creativity/\">Deliberate and Spontaneous Creativity</a> (20)</li>\n<li><a href=\"/lw/14/does_blind_review_slow_down_science/\">Does Blind Review Slow Down Science?</a> (20) </li>\n<li><a href=\"/lw/by9/to_like_each_other_sing_and_dance_in_synchrony/\">To Like Each Other Sing and Dance in Synchrony</a> (19) </li>\n<li><a href=\"/lw/19v/intuitive_differences_when_to_agree_to_disagree/\">Intuitive Differences: When to Agree to Disagree</a> (18) </li>\n<li><a href=\"/lw/b2/declare_your_signaling_and_hidden_agendas/\">Declare Your Signaling and Hidden Agendas</a> (17) </li>\n<li><a href=\"/lw/8ev/modularity_signaling_and_belief_in_belief/\">Modularity Signaling and Belief in Belief</a> (16) </li>\n<li><a href=\"/lw/dy7/smart_nonreductionists_philosophical_vs/\">Smart Non-Reductionists, Philosophical vs. Engineering Mindsets, and Religion</a> (13)</li>\n<li><a href=\"/lw/2fj/a_taxonomy_of_bias_mindware_problems/\">A Taxonomy of Bias: Mindware Problems</a> (13) </li>\n<li><a href=\"/lw/b1r/what_epistemic_hygiene_norms_should_there_be/\">What Epistemic Hygiene Norms Should There Be?</a> (11) </li>\n<li><a href=\"/lw/18l/ethics_as_a_black_box_function/\">Ethics as a Black Box Function</a> (11) </li>\n<li><a href=\"/lw/za/a_social_norm_against_unjustified_opinions/\">A Social Norm Against Unjustified Opinions</a> (10) </li>\n<li><a href=\"/lw/23r/the_concepts_problem/\">The Concepts Problem</a> (09)</li>\n<li><a href=\"/lw/16p/the_twin_webs_of_knowledge/\">The Twin Webs of Knowledge</a> (05) </li>\n</ul>\n<div>Also see: <a href=\"/lw/6ga/index_of_yvains_excellent_articles/\">Yvain's posts</a> and <a href=\"http://lukeprog.com/writings.html#LWPosts\">lukeprog's posts</a>.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bJ7vvyzBoiKSkFmTt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "18739", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tAXrD8Y6hcJ8dt6Nt", "2oybbEw697CQgcRE5", "AN2cBr6xKWCB8dRQG", "LHtMNz7ua8zu4rSZr", "oiGN8fLCqYyk2xJaT", "WnjGhcRb2c6CabK5d", "YgNLfytckSyKTnDXN", "BmGrj9pRkcbJxae3x", "4MpodyRwdYXEeC3jn", "ujTE9FLWveYz9WTxZ", "Psp8ZpYLCDJjshpRb", "gs8bZCmaWqDaus7Dr", "qMTzv8ATgDtfLq9ME", "9XBhs3dS4XnBwZRan", "Yiv9BeroBhJC6zqSs", "qMuAazqwJvkvo8teR", "fGzPFwAosXXBcv5Jc", "d9CcQ24ukbL8WcMpB", "kD8uzcmjKwSaTHnQJ", "psQYbMLWzS9sTsT2M", "fEFwHBeatkaKpm8ZB", "xNrdYu6p6BRamRBz8", "tNnhxNYcXYdJYtQRh", "zRbh2mYgXtDJk8T42", "b7cWpbXwcQySDq4kK", "RAftfkp3NqDDR2o79", "fxgkYCbG5Hgy58TyC", "rKNuyxFK85yKtwP6G", "wTrgm2meHePfn3ykT", "KB2nF3WFF5n5Pyzds", "3iM8QjvdkPCyLRJM6", "kSgQmZ49fLrkfRndu", "vuN57BvWyT7WZ3b6p", "b88EtWvjyRQc89XzT", "jgkWqbNph57rAfPsi", "KL9iocwykHq53Esrv", "xDiqYyqeqPo92PojS", "rLzMBxew4S4TevtqB", "hiiziojg3R5uwQPm9", "5aaPPRAM6JdLqceqX", "fsSoAMsntpsmrEC6a", "GahkhPWinnAvri8Td", "JF4mv4PbTp6ckN3vG", "yCjofyFSoAq73LT2A", "o6CuZk2oPtDXqeY5A", "H2SayAkY4PuMcREYu", "a5DQxG9NgzSLRZMnQ", "C9JB2GCBTo8Srg8GN", "LCnryDjnrM7Kcikx7", "PZyJSdmRpPbamv5G2", "MLubomnpt8tRXEQMy", "qvnZG2gdBXZ5aWLqL", "xaLHeoRPdb9oQgDEy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-11T03:42:41.314Z", "modifiedAt": null, "url": null, "title": "Circular Preferences Don't Lead To Getting Money Pumped", "slug": "circular-preferences-don-t-lead-to-getting-money-pumped", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:35.452Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mestroyer", "createdAt": "2012-04-15T14:43:35.361Z", "isAdmin": false, "displayName": "Mestroyer"}, "userId": "xCcdyLecNTyFRbYso", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8qMaBePBsGhabLeWk/circular-preferences-don-t-lead-to-getting-money-pumped", "pageUrlRelative": "/posts/8qMaBePBsGhabLeWk/circular-preferences-don-t-lead-to-getting-money-pumped", "linkUrl": "https://www.lesswrong.com/posts/8qMaBePBsGhabLeWk/circular-preferences-don-t-lead-to-getting-money-pumped", "postedAtFormatted": "Tuesday, September 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Circular%20Preferences%20Don't%20Lead%20To%20Getting%20Money%20Pumped&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACircular%20Preferences%20Don't%20Lead%20To%20Getting%20Money%20Pumped%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qMaBePBsGhabLeWk%2Fcircular-preferences-don-t-lead-to-getting-money-pumped%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Circular%20Preferences%20Don't%20Lead%20To%20Getting%20Money%20Pumped%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qMaBePBsGhabLeWk%2Fcircular-preferences-don-t-lead-to-getting-money-pumped", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qMaBePBsGhabLeWk%2Fcircular-preferences-don-t-lead-to-getting-money-pumped", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 306, "htmlBody": "<p>Edit: for reasons given in the comments, I don't think the question of what circular preferences actually do is well defined, so this an answer to a wrong question.</p>\n<p>&nbsp;</p>\n<p>If I like Y more than X, at an exchange rate of 0.9Y for 1X, and I like Z more than Y, at an exchange rate of 0.9Z for 1Y, and I like X more than Z, at an exchange rate of 0.9X for 1Z, you might think that given 1X and the ability to trade X for Y at an exchange rate of 0.95Y for 1X, and Y for Z at an exchange rate of 0.95Z for 1Y, and Z for X at an exchange rate of 0.95X for 1Z, I would trade in a circle until I had nothing left.</p>\n<p>But actually, if I knew that I had circular preferences, and I knew that if I had 0.95Y I would trade it for (0.95^2)Z, which I would trade for (0.95^3)X, then actually I'd be trading 1X for (0.95^3)X, which I'm obviously not going to do.</p>\n<p>Similarly, if the exchange rates are all 1:1, but each trade costs 1 penny, and I care about 1 penny much much less than any of 1X, 1Y, or 1Z, and I trade my X for Y, I know I'm actually going to end up with X - 3 cents, so I won't make the trade.</p>\n<p>Unless I can set a <a href=\"/lw/ase/schelling_fences_on_slippery_slopes/\">Schelling fence</a>, in which case I will end up trading once.</p>\n<p>So if instead of being given X, I have a 1/3 chance of each of X, Y, and Z, I would hope I wouldn't set a Schelling fence, because then my 1/3 chance of each thing becomes a 1/3 chance of each thing minus the trading penalty. So maybe I'd want to be bad at precommitments, or would I precommit not to precommit?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8qMaBePBsGhabLeWk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -4, "extendedScore": null, "score": -1.1e-05, "legacy": true, "legacyId": "18740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Kbm6QnJv9dgWsPHQP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-11T05:28:56.806Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Magnitude of His Own Folly", "slug": "seq-rerun-the-magnitude-of-his-own-folly", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fz5sDPKtHhRNLgdaC/seq-rerun-the-magnitude-of-his-own-folly", "pageUrlRelative": "/posts/Fz5sDPKtHhRNLgdaC/seq-rerun-the-magnitude-of-his-own-folly", "linkUrl": "https://www.lesswrong.com/posts/Fz5sDPKtHhRNLgdaC/seq-rerun-the-magnitude-of-his-own-folly", "postedAtFormatted": "Tuesday, September 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Magnitude%20of%20His%20Own%20Folly&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Magnitude%20of%20His%20Own%20Folly%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5sDPKtHhRNLgdaC%2Fseq-rerun-the-magnitude-of-his-own-folly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Magnitude%20of%20His%20Own%20Folly%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5sDPKtHhRNLgdaC%2Fseq-rerun-the-magnitude-of-his-own-folly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5sDPKtHhRNLgdaC%2Fseq-rerun-the-magnitude-of-his-own-folly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>Today's post, <a href=\"/lw/ue/the_magnitude_of_his_own_folly/\">The Magnitude of His Own Folly</a> was originally published on 30 September 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#The_Magnitude_of_His_Own_Folly\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Eliezer considers his training as a rationalist to have started the day he realized just how awfully he had screwed up.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ega/seq_rerun_aboveaverage_ai_scientists/\">Above-Average AI Scientists</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fz5sDPKtHhRNLgdaC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.840848420945135e-07, "legacy": true, "legacyId": "18741", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fLRPeXihRaiRo5dyX", "E5sLLdFRTCc5ZGJGM", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-11T11:40:53.747Z", "modifiedAt": null, "url": null, "title": "Personal information management", "slug": "personal-information-management", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:07.242Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "John_Maxwell_IV", "createdAt": "2009-02-27T05:45:59.993Z", "isAdmin": false, "displayName": "John_Maxwell"}, "userId": "mcKSiwq2TBrTMZS6X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/stDijTKuto52M5wQT/personal-information-management", "pageUrlRelative": "/posts/stDijTKuto52M5wQT/personal-information-management", "linkUrl": "https://www.lesswrong.com/posts/stDijTKuto52M5wQT/personal-information-management", "postedAtFormatted": "Tuesday, September 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Personal%20information%20management&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersonal%20information%20management%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FstDijTKuto52M5wQT%2Fpersonal-information-management%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Personal%20information%20management%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FstDijTKuto52M5wQT%2Fpersonal-information-management", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FstDijTKuto52M5wQT%2Fpersonal-information-management", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 799, "htmlBody": "<p>Several weeks ago, I began using personal wiki software <a href=\"http://zim-wiki.org/\">Zim Wiki</a> (free and cross-platform for Linux &amp; Windows; I recommend <a href=\"http://brettterpstra.com/projects/nvalt/\">nvALT</a>&nbsp;on Mac OS X) to record all of my notes-to-self.&nbsp; I've found it to be a nice software tool for implementing some of the effectiveness advice I've read on Less Wrong.&nbsp; This post is a fairly personal overview of my usage.</p>\n<p>I looked at a lot of personal information managers before choosing Zim.&nbsp; Here are the features that caused me to choose it over the other software I looked at:</p>\n<ul>\n<li>\n<p>Probably the most important feature: Jump-to-note capability with autocomplete.&nbsp; Pressing Control-J gives a text box.&nbsp; Start typing in the text box and it autocompletes with the names of any of the notes in my notebook (or allows me to create a new note).&nbsp; This is the proverbial 10% of the feature set that provides 90% of the benefit over scattered text files.&nbsp; Opening a specific note to add another thought or idea to it is a very common operation for me and this feature makes it very quick.&nbsp; Only a few tools I've found seem to have comparable functionality: <a href=\"http://wikidpad.sourceforge.net/\">WikidPad</a> (with Control-O), and the <a href=\"http://www.google.com/search?q=notational+velocity\">Notational Velocity</a> family of information managers kind of have it. &nbsp;(For Notational Velocity/nvALT, I recommend coming up with some kind of namespacing scheme so note names collide with note text less frequently in your searches. &nbsp;For example, I prepend reminders for future situations with \"f.\", journal notes with \"j.\", <a href=\"/lw/flr/thoughts_on_designing_policies_for_oneself/\">policy notes</a> with \"p.\", Less Wrong post drafts with \"l.\", etc. &nbsp;Then command-L works as a pretty good \"jump to note\" shortcut.)</p>\n</li>\n<li>\n<p>Pressing Control-D, then pressing return inserts a timestamp at the position of my cursor.&nbsp; This has been useful for a variety of logging-type applications. &nbsp;(I replicated the same thing with nvALT on OS X with <a href=\"https://www.trankynam.com/atext/\">aText</a>.)</p>\n</li>\n<li>\n<p>Zim is a desktop application.&nbsp; This has a couple advantages:</p>\n<ul>\n<li>\n<p>I configured a keyboard shortcut to open it, or bring it to the front if it was already open, using a modified version of the Linux shell script in <a href=\"http://web.archive.org/web/20091121045303/http://ubuntuforums.org/archive/index.php/t-197207.html\">this forum thread</a>. &nbsp;(<a href=\"http://www.alfredapp.com/\">Alfred</a> is nice for this on OS X.)</p>\n</li>\n<li>\n<p>All my notes are stored as plain text files on my hard drive.&nbsp; I keep them under version control, which lets me do things like answer the question \"what new ideas for becoming more effective have I had over the past week?\"&nbsp; (I didn't use the built-in version control plugin because I found its UI glitchy.)</p>\n</li>\n</ul>\n</li>\n<li>\n<p>There's inter-note linking capability, also with an autocompletion dialogue.&nbsp; (Press Control-L to create a link.)</p>\n</li>\n<li>\n<p>Moving through note browsing history can be done with Alt-Left and Alt-Right.</p>\n</li>\n<li>It starts fast.</li>\n</ul>\n<ul>\n<li>Notes are saved automatically, hierarchical note organization is possible, backlinks are tracked, incremental keyword search within a note is possible, and there appear to be a variety of other features I haven't yet had a chance to abuse.</li>\n</ul>\n<p>Using Zim has meant a really low level of <a href=\"http://wiki.lesswrong.com/wiki/Trivial_inconvenience\">friction</a> for writing new stuff and retrieving/reading/adding to stuff I wrote.&nbsp; I've been using it about a month and I've got ~46K words in it, which seems to be around the length of a short novel. <a href=\"http://rescuetime.com/\">RescueTime</a> says I use it 4-8 hours per week.&nbsp; Some stuff I'm using it for:</p>\n<ul>\n<li>\n<p><a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Strategizing</a>.&nbsp; There's something kind of calming about writing my thoughts out when I'm choosing between several options or trying to figure out what to do.&nbsp; I suspect that as soon as the amount of information related to a decision exceeds the capacity of my working memory, I benefit from writing stuff down.</p>\n</li>\n<li>\n<p><a href=\"/lw/deq/where_to_intervene_in_a_human/6yqm\">Logging stuff</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/94t/meta_analysis_of_writing_therapy/\">Writing therapy</a>.</p>\n</li>\n<li>\n<p>Recording business ideas, self-experimentation ideas, essay ideas, etc.</p>\n</li>\n<li>\n<p>Making plans and filing away notes related to future circumstances.</p>\n</li>\n<li>\n<p>Taking notes related to software I'm developing.</p>\n</li>\n</ul>\n<p>It's hard to measure how much benefit I'm getting out of all this, though it feels pretty useful.&nbsp; I'm inclined to agree with <a href=\"http://paulgraham.com/island.html\">Paul Graham</a>:</p>\n<blockquote>\n<p>...actually there is something druglike about [the notebook and pen], in the sense that their main purpose is to make me feel better. I hardly ever go back and read stuff I write down in notebooks. It's just that if I can't write things down, worrying about remembering one idea gets in the way of having the next. Pen and paper wick ideas.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"udPbn9RthmgTtHMiG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "stDijTKuto52M5wQT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 27, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "18747", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aNRYQFnMQbA7uu99u", "PBRWb2Em5SNeWYwwB", "o7nRiBP9W8xR5E4v5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-11T13:00:16.300Z", "modifiedAt": null, "url": null, "title": "[LINK] Interfluidity on \"Rational Astrologies\" ", "slug": "link-interfluidity-on-rational-astrologies", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.874Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Zvi", "createdAt": "2009-03-31T20:54:54.077Z", "isAdmin": false, "displayName": "Zvi"}, "userId": "N9zj5qpTfqmbn9dro", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rwDcykWGBC3i6jcY6/link-interfluidity-on-rational-astrologies", "pageUrlRelative": "/posts/rwDcykWGBC3i6jcY6/link-interfluidity-on-rational-astrologies", "linkUrl": "https://www.lesswrong.com/posts/rwDcykWGBC3i6jcY6/link-interfluidity-on-rational-astrologies", "postedAtFormatted": "Tuesday, September 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Interfluidity%20on%20%22Rational%20Astrologies%22%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Interfluidity%20on%20%22Rational%20Astrologies%22%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrwDcykWGBC3i6jcY6%2Flink-interfluidity-on-rational-astrologies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Interfluidity%20on%20%22Rational%20Astrologies%22%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrwDcykWGBC3i6jcY6%2Flink-interfluidity-on-rational-astrologies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrwDcykWGBC3i6jcY6%2Flink-interfluidity-on-rational-astrologies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<p>The article can be found <a title=\"Rational Astrologies\" href=\"http://www.interfluidity.com/v2/3513.html\" target=\"_blank\">here.</a>&nbsp;While it is not, for many of us, new ground, it is an excellent treatment, and it requires no rationalist background in order to be understood. The subject is the pernicious pull of doing the standard thing, regardless of whether or not the standard thing makes any sense, and it does us the service of giving that phenomenon a descriptive link we can share as well as an excellent name.</p>\n<p>I hope to, after more discussion and thought, write a main post on the subject.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rwDcykWGBC3i6jcY6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 13, "extendedScore": null, "score": 9.8431533604014e-07, "legacy": true, "legacyId": "18748", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-11T19:57:49.672Z", "modifiedAt": null, "url": null, "title": "Random LW-parodying Statement Generator", "slug": "random-lw-parodying-statement-generator", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:05.104Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wwYdchKSSCDczcD32/random-lw-parodying-statement-generator", "pageUrlRelative": "/posts/wwYdchKSSCDczcD32/random-lw-parodying-statement-generator", "linkUrl": "https://www.lesswrong.com/posts/wwYdchKSSCDczcD32/random-lw-parodying-statement-generator", "postedAtFormatted": "Tuesday, September 11th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Random%20LW-parodying%20Statement%20Generator&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARandom%20LW-parodying%20Statement%20Generator%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwwYdchKSSCDczcD32%2Frandom-lw-parodying-statement-generator%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Random%20LW-parodying%20Statement%20Generator%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwwYdchKSSCDczcD32%2Frandom-lw-parodying-statement-generator", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwwYdchKSSCDczcD32%2Frandom-lw-parodying-statement-generator", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>So, I were looking at <a href=\"/lw/d2w/cards_against_rationality/\">this</a>, and then suddenly <a href=\"http://jsbin.com/ibebih/49\">this thing</a> happened.</p>\n<p>EDIT:</p>\n<p><strong><a href=\"http://jsbin.com/ibebih/49\">New version</a>!</strong> I updated the link above to it as well. Added LOADS and LOADS of new content, although I'm not entirely sure if it's actually more fun (my guess is there's more total fun due to varity, but that it's more diluted).</p>\n<p>I ended up working on this basically the entire day to day, and implemented practically all my ideas I have so far, except for some grammar issues that'd require disproportionately much work. So unless there are loads of suggestions or my brain comes up with lots of new ideas over the next few days, this may be the last version in a while and I may call it beta and ask for spell-check. Still alpha as of writing this thou.</p>\n<p>Since there were some close calls already, I'll restate this explicitly: I'd be easier for everyone if there weren't any forks for at least a few more days, even ones just for spell-checking. After that/I move this to beta feel more than free to do whatever you want.</p>\n<p>Thanks to everyone who commented! ^_^</p>\n<p><a href=\"http://jsbin.com/ibebih/3/edit\">old Source</a>, <a href=\"http://jsbin.com/ibebih/3\">old version</a>, <a href=\"http://jsbin.com/ibebih/49/edit\">latest source</a></p>\n<p><sup>Credits: <a href=\"/lw/d2w/cards_against_rationality\">http://lesswrong.com/lw/d2w/cards_against_rationality/</a> , <a href=\"/lw/9ki/shit_rationalists_say\">http://lesswrong.com/lw/9ki/shit_rationalists_say/</a> , various people commenting on this article with suggestions, random people on the bay12 forums that helped me with the engine this is a descendent from ages ago. </sup></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hNFdS3rRiYgqqD8aM": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wwYdchKSSCDczcD32", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 79, "baseScore": 93, "extendedScore": null, "score": 0.000189, "legacy": true, "legacyId": "18749", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 62, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 222, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fn5bJLvJgvxj72Yt9", "8xQ8hTxo6Rk2qqZfj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T01:45:19.423Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Trying to Try", "slug": "seq-rerun-trying-to-try", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.805Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cuYzbMjQDh3SDeMqa/seq-rerun-trying-to-try", "pageUrlRelative": "/posts/cuYzbMjQDh3SDeMqa/seq-rerun-trying-to-try", "linkUrl": "https://www.lesswrong.com/posts/cuYzbMjQDh3SDeMqa/seq-rerun-trying-to-try", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Trying%20to%20Try&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Trying%20to%20Try%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcuYzbMjQDh3SDeMqa%2Fseq-rerun-trying-to-try%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Trying%20to%20Try%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcuYzbMjQDh3SDeMqa%2Fseq-rerun-trying-to-try", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcuYzbMjQDh3SDeMqa%2Fseq-rerun-trying-to-try", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/uh/trying_to_try/\">Trying to Try</a> was originally published on 01 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Trying_to_Try\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>As a human, if you try to try something, you will put much less work into it than if you try something.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/egl/seq_rerun_the_magnitude_of_his_own_folly/\">The Magnitude of His Own Folly</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cuYzbMjQDh3SDeMqa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 9.84706270453863e-07, "legacy": true, "legacyId": "18752", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WLJwTJ7uGPA5Qphbp", "Fz5sDPKtHhRNLgdaC", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T02:56:36.033Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison: Reading Group, Seeing with Fresh Eyes", "slug": "meetup-madison-reading-group-seeing-with-fresh-eyes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ewzA5v7SdZdTSztYM/meetup-madison-reading-group-seeing-with-fresh-eyes", "pageUrlRelative": "/posts/ewzA5v7SdZdTSztYM/meetup-madison-reading-group-seeing-with-fresh-eyes", "linkUrl": "https://www.lesswrong.com/posts/ewzA5v7SdZdTSztYM/meetup-madison-reading-group-seeing-with-fresh-eyes", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%3A%20Reading%20Group%2C%20Seeing%20with%20Fresh%20Eyes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%3A%20Reading%20Group%2C%20Seeing%20with%20Fresh%20Eyes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FewzA5v7SdZdTSztYM%2Fmeetup-madison-reading-group-seeing-with-fresh-eyes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%3A%20Reading%20Group%2C%20Seeing%20with%20Fresh%20Eyes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FewzA5v7SdZdTSztYM%2Fmeetup-madison-reading-group-seeing-with-fresh-eyes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FewzA5v7SdZdTSztYM%2Fmeetup-madison-reading-group-seeing-with-fresh-eyes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 237, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dp'>Madison: Reading Group, Seeing with Fresh Eyes</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1053 Rutledge St #3, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>At this meetup, we'll discuss the <a href=\"http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes\">Seeing with Fresh Eyes</a> sequence. Roughly speaking, this sequence is about the stickiness of old ideas, and how hard they can make it to have new ideas. Try to read this before showing up -- as usual for our reading group sessions, you're welcome to come if you haven't read these lately, but some of the conversation might be incomprehensible. To keep the reading down to a reasonable length, I recommend the following handful of pages.</p>\n\n<p>First, a few well-documented studies, pointing vaguely at the general trend:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment</a></li>\n<li><a href=\"http://lesswrong.com/lw/k3/priming_and_contamination/\">Priming and Contamination</a></li>\n<li><a href=\"http://lesswrong.com/lw/k4/do_we_believe_everything_were_told/\">Do We Believe Everything We&#39;re Told?</a></li>\n</ul>\n\n<p>Then, a mad plunge into related speculation and advice:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/k5/cached_thoughts/\">Cached Thoughts</a></li>\n<li><a href=\"http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/\">We Change Our Minds Less Often Than We Think</a></li>\n<li><a href=\"http://lesswrong.com/lw/ka/hold_off_on_proposing_solutions/\">Hold Off On Proposing Solutions</a></li>\n<li><a href=\"http://lesswrong.com/lw/s3/the_genetic_fallacy/\">The Genetic Fallacy</a></li>\n</ul>\n\n<p>As usual, I <em>also</em> like the rest of the posts in the sequence, but they don't fit together with these so well, I think; so I'll leave those out of this list. If you have the time for those, too, go ahead and read the <a href=\"http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes\">full sequence</a>.</p>\n\n<p>Also, thanks to Nick for offering to host this week!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dp'>Madison: Reading Group, Seeing with Fresh Eyes</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ewzA5v7SdZdTSztYM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 9.847427062117534e-07, "legacy": true, "legacyId": "18754", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison__Reading_Group__Seeing_with_Fresh_Eyes\">Discussion article for the meetup : <a href=\"/meetups/dp\">Madison: Reading Group, Seeing with Fresh Eyes</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1053 Rutledge St #3, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>At this meetup, we'll discuss the <a href=\"http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes\">Seeing with Fresh Eyes</a> sequence. Roughly speaking, this sequence is about the stickiness of old ideas, and how hard they can make it to have new ideas. Try to read this before showing up -- as usual for our reading group sessions, you're welcome to come if you haven't read these lately, but some of the conversation might be incomprehensible. To keep the reading down to a reasonable length, I recommend the following handful of pages.</p>\n\n<p>First, a few well-documented studies, pointing vaguely at the general trend:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment</a></li>\n<li><a href=\"http://lesswrong.com/lw/k3/priming_and_contamination/\">Priming and Contamination</a></li>\n<li><a href=\"http://lesswrong.com/lw/k4/do_we_believe_everything_were_told/\">Do We Believe Everything We're Told?</a></li>\n</ul>\n\n<p>Then, a mad plunge into related speculation and advice:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/k5/cached_thoughts/\">Cached Thoughts</a></li>\n<li><a href=\"http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/\">We Change Our Minds Less Often Than We Think</a></li>\n<li><a href=\"http://lesswrong.com/lw/ka/hold_off_on_proposing_solutions/\">Hold Off On Proposing Solutions</a></li>\n<li><a href=\"http://lesswrong.com/lw/s3/the_genetic_fallacy/\">The Genetic Fallacy</a></li>\n</ul>\n\n<p>As usual, I <em>also</em> like the rest of the posts in the sequence, but they don't fit together with these so well, I think; so I'll leave those out of this list. If you have the time for those, too, go ahead and read the <a href=\"http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes\">full sequence</a>.</p>\n\n<p>Also, thanks to Nick for offering to host this week!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison__Reading_Group__Seeing_with_Fresh_Eyes1\">Discussion article for the meetup : <a href=\"/meetups/dp\">Madison: Reading Group, Seeing with Fresh Eyes</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison: Reading Group, Seeing with Fresh Eyes", "anchor": "Discussion_article_for_the_meetup___Madison__Reading_Group__Seeing_with_Fresh_Eyes", "level": 1}, {"title": "Discussion article for the meetup : Madison: Reading Group, Seeing with Fresh Eyes", "anchor": "Discussion_article_for_the_meetup___Madison__Reading_Group__Seeing_with_Fresh_Eyes1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bMkCEZoBNhgRBtzoj", "BaCWFCxBQYjJXSsah", "TiDGXt3WrQwtCdDj3", "2MD3NMLBPCqPfnfre", "buixYfcXBah9hbSNZ", "uHYYA32CKgKT3FagE", "KZLa74SzyKhSJ3M55"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T03:29:59.041Z", "modifiedAt": null, "url": null, "title": "Meta: LW Policy: When to prohibit Alice from replying to Bob's arguments?", "slug": "meta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:05.988Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v6qDhfkE8prqnSHGt/meta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "pageUrlRelative": "/posts/v6qDhfkE8prqnSHGt/meta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "linkUrl": "https://www.lesswrong.com/posts/v6qDhfkE8prqnSHGt/meta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20LW%20Policy%3A%20When%20to%20prohibit%20Alice%20from%20replying%20to%20Bob's%20arguments%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20LW%20Policy%3A%20When%20to%20prohibit%20Alice%20from%20replying%20to%20Bob's%20arguments%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6qDhfkE8prqnSHGt%2Fmeta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20LW%20Policy%3A%20When%20to%20prohibit%20Alice%20from%20replying%20to%20Bob's%20arguments%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6qDhfkE8prqnSHGt%2Fmeta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv6qDhfkE8prqnSHGt%2Fmeta-lw-policy-when-to-prohibit-alice-from-replying-to-bob-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 169, "htmlBody": "<p>In light of recent (and potential) events, I wanted to start a discussion here about a certain method of handling conflicts on this site's discussion threads, and hopefully form a consensus on when to use the measure described in the title.&nbsp; Even if the discussion has no impact on site policy (\"executive veto\"), I hope administrators will at least clarify when such a measure will be used, and for what reason.</p>\n<p>I also don't want to taint or \"anchor\" the discussion by offering hypothetical situations or arguments for one position or another.&nbsp; Rather, I simply want to ask: <strong>Under what conditions should a specific poster, \"Alice\" be prohibited from replying directly to the arguments in a post/comment made by another poster, \"Bob\"?&nbsp; </strong>(Note: this is referring specifically to replies to ideas and arguments Bob has advanced, not general comments about Bob the person, which should probably go under much closer scrutiny because of the risk of incivility.)</p>\n<p>Please offer your ideas and thoughts here on when this measure should be used.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v6qDhfkE8prqnSHGt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": -6, "extendedScore": null, "score": -1.1e-05, "legacy": true, "legacyId": "18755", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T05:36:33.667Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\"", "slug": "meetup-west-la-meetup-the-unreasonable-effectiveness-of", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3rkfug5PFXE9L96EA/meetup-west-la-meetup-the-unreasonable-effectiveness-of", "pageUrlRelative": "/posts/3rkfug5PFXE9L96EA/meetup-west-la-meetup-the-unreasonable-effectiveness-of", "linkUrl": "https://www.lesswrong.com/posts/3rkfug5PFXE9L96EA/meetup-west-la-meetup-the-unreasonable-effectiveness-of", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20%22The%20Unreasonable%20Effectiveness%20of%20Mathematics%20in%20the%20Natural%20Sciences%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20%22The%20Unreasonable%20Effectiveness%20of%20Mathematics%20in%20the%20Natural%20Sciences%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3rkfug5PFXE9L96EA%2Fmeetup-west-la-meetup-the-unreasonable-effectiveness-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20%22The%20Unreasonable%20Effectiveness%20of%20Mathematics%20in%20the%20Natural%20Sciences%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3rkfug5PFXE9L96EA%2Fmeetup-west-la-meetup-the-unreasonable-effectiveness-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3rkfug5PFXE9L96EA%2Fmeetup-west-la-meetup-the-unreasonable-effectiveness-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 168, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dq'>West LA Meetup - &quot;The Unreasonable Effectiveness of Mathematics in the Natural Sciences&quot;</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, September 12th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> We will discuss the ideas discussed in a paper summarized <a href=\"http://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences\" rel=\"nofollow\">here</a>. Also, read <a href=\"http://plus.maths.org/content/philosophy-applied-mathematics\" rel=\"nofollow\">this</a>.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts\">recent posts</a>. But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dq'>West LA Meetup - &quot;The Unreasonable Effectiveness of Mathematics in the Natural Sciences&quot;</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3rkfug5PFXE9L96EA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 9.848244846160847e-07, "legacy": true, "legacyId": "18756", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup____The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences_\">Discussion article for the meetup : <a href=\"/meetups/dq\">West LA Meetup - \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\"</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm - 9:00pm Wednesday, September 12th.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> We will discuss the ideas discussed in a paper summarized <a href=\"http://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences\" rel=\"nofollow\">here</a>. Also, read <a href=\"http://plus.maths.org/content/philosophy-applied-mathematics\" rel=\"nofollow\">this</a>.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts\">recent posts</a>. But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup____The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences_1\">Discussion article for the meetup : <a href=\"/meetups/dq\">West LA Meetup - \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\"</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\"", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup____The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences_", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\"", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup____The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T15:08:06.292Z", "modifiedAt": null, "url": null, "title": "The Yudkowsky Ambition Scale", "slug": "the-yudkowsky-ambition-scale", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:00.829Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loup-vaillant", "createdAt": "2011-03-23T10:39:25.887Z", "isAdmin": false, "displayName": "loup-vaillant"}, "userId": "wdoZti3BcPbJXsZ66", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mxDAPAuy2b3tkeJRc/the-yudkowsky-ambition-scale", "pageUrlRelative": "/posts/mxDAPAuy2b3tkeJRc/the-yudkowsky-ambition-scale", "linkUrl": "https://www.lesswrong.com/posts/mxDAPAuy2b3tkeJRc/the-yudkowsky-ambition-scale", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Yudkowsky%20Ambition%20Scale&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Yudkowsky%20Ambition%20Scale%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmxDAPAuy2b3tkeJRc%2Fthe-yudkowsky-ambition-scale%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Yudkowsky%20Ambition%20Scale%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmxDAPAuy2b3tkeJRc%2Fthe-yudkowsky-ambition-scale", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmxDAPAuy2b3tkeJRc%2Fthe-yudkowsky-ambition-scale", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p>From <a href=\"http://news.ycombinator.com/item?id=4510702\">Hacker News</a>.</p>\n<blockquote><ol>\n<li><span class=\"comment\"><span style=\"color: #000000;\"> We're going to build the next Facebook! </span></span></li>\n<li><span style=\"color: #000000;\">We're going to found the next Apple!</span></li>\n<li><span style=\"color: #000000;\">Our product will create sweeping political change! This will produce a major economic revolution in at least one country! (Seasteading would be change on this level if it worked; creating a new country successfully is around the same level of change as this.)</span></li>\n<li><span style=\"color: #000000;\">Our product is the next nuclear weapon. You wouldn't want that in the wrong hands, would you?</span></li>\n<li><span style=\"color: #000000;\">This is going to be the equivalent of the invention of electricity if it works out.</span></li>\n<li><span style=\"color: #000000;\">We're going to make an IQ-enhancing drug and produce basic change in the human condition.</span></li>\n<li><span style=\"color: #000000;\">We're going to build serious Drexler-class molecular nanotechnology.</span></li>\n<li><span style=\"color: #000000;\">We're going to upload a human brain into a computer.</span></li>\n<li><span style=\"color: #000000;\">We're going to build a recursively self-improving Artificial Intelligence.</span></li>\n<li><span style=\"color: #000000;\">We think we've figured out how to hack into the computer our universe is running on.</span></li>\n</ol></blockquote>\n<p>This made me laugh, but from the look of it, I'd say there is little work to do to make it serious. Personally, I'd try to shorten it so it is punchier and more memorable.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hNFdS3rRiYgqqD8aM": 1, "hrezrpGqXXdSe76ks": 11}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mxDAPAuy2b3tkeJRc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 64, "extendedScore": null, "score": 0.000155, "legacy": true, "legacyId": "18769", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 64, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T20:07:49.879Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne social meetup", "slug": "meetup-melbourne-social-meetup-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:38.780Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "toner", "createdAt": "2009-02-27T05:14:52.530Z", "isAdmin": false, "displayName": "toner"}, "userId": "XaYyFkpvhiiMscJJZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/inXvgkHKcAKRKB2WB/meetup-melbourne-social-meetup-15", "pageUrlRelative": "/posts/inXvgkHKcAKRKB2WB/meetup-melbourne-social-meetup-15", "linkUrl": "https://www.lesswrong.com/posts/inXvgkHKcAKRKB2WB/meetup-melbourne-social-meetup-15", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20social%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20social%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FinXvgkHKcAKRKB2WB%2Fmeetup-melbourne-social-meetup-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20social%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FinXvgkHKcAKRKB2WB%2Fmeetup-melbourne-social-meetup-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FinXvgkHKcAKRKB2WB%2Fmeetup-melbourne-social-meetup-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dr'>Melbourne social meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 September 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">see mailing list, Carlton VIC 3053</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next social meetup is on Friday 21 September, 6:30 for 7pm, at my house. If you have any trouble working out the location or getting in, you can call me on 0412 996 288 or Scott (shokwave) on 0432 862 932.</p>\n\n<p>We'll get some snacks and organise some form of take-away for dinner. BYO drinks and games.</p>\n\n<p>We always look forward to meeting new people!</p>\n\n<p>This meetup is usually on the third Friday of the month. We also have a regular meetup about practical rationality on the first Friday of each month.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dr'>Melbourne social meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "inXvgkHKcAKRKB2WB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.85270124666255e-07, "legacy": true, "legacyId": "18770", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup\">Discussion article for the meetup : <a href=\"/meetups/dr\">Melbourne social meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 September 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">see mailing list, Carlton VIC 3053</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next social meetup is on Friday 21 September, 6:30 for 7pm, at my house. If you have any trouble working out the location or getting in, you can call me on 0412 996 288 or Scott (shokwave) on 0432 862 932.</p>\n\n<p>We'll get some snacks and organise some form of take-away for dinner. BYO drinks and games.</p>\n\n<p>We always look forward to meeting new people!</p>\n\n<p>This meetup is usually on the third Friday of the month. We also have a regular meetup about practical rationality on the first Friday of each month.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup1\">Discussion article for the meetup : <a href=\"/meetups/dr\">Melbourne social meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T20:35:47.560Z", "modifiedAt": null, "url": null, "title": "Living accommodations for my possibly deconverted Mormon friend", "slug": "living-accommodations-for-my-possibly-deconverted-mormon", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:47.718Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Plubbingworth", "createdAt": "2012-02-26T16:34:03.365Z", "isAdmin": false, "displayName": "Plubbingworth"}, "userId": "yiEBZQB4XeCCPqLf7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yHhxRt7Tf8hsqPL79/living-accommodations-for-my-possibly-deconverted-mormon", "pageUrlRelative": "/posts/yHhxRt7Tf8hsqPL79/living-accommodations-for-my-possibly-deconverted-mormon", "linkUrl": "https://www.lesswrong.com/posts/yHhxRt7Tf8hsqPL79/living-accommodations-for-my-possibly-deconverted-mormon", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Living%20accommodations%20for%20my%20possibly%20deconverted%20Mormon%20friend&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALiving%20accommodations%20for%20my%20possibly%20deconverted%20Mormon%20friend%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyHhxRt7Tf8hsqPL79%2Fliving-accommodations-for-my-possibly-deconverted-mormon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Living%20accommodations%20for%20my%20possibly%20deconverted%20Mormon%20friend%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyHhxRt7Tf8hsqPL79%2Fliving-accommodations-for-my-possibly-deconverted-mormon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyHhxRt7Tf8hsqPL79%2Fliving-accommodations-for-my-possibly-deconverted-mormon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 214, "htmlBody": "<p>Hello. I need a bit of advice, and I'm not quite sure where to put this.</p>\n<p>Ummm, well, here's the deal. I have a friend, my age, who recently prematurely ended his Mormon missionary trip (from Knoxville, TN to... uh... Eastern California?) for his own reasons, and has asked for my help. Seeing as this person is like a brother to me (the two of us have known each other for all of our twenty years), he has asked me for advice on living&nbsp;accommodations, as he does not want to return to his parent's home. I'm not even sure they would let him, as they were very serious about his mission.</p>\n<p>He's perfectly welcome to stay with me, but getting him back on his feet is a must. And I don't think either of us know how to go about figuring this out.</p>\n<p>His reasons are currently known only to himself, so I don't know if it is based on misgivings about his church, or personal problems. Er, assuming the two are even different. Apparently I'm going to be the&nbsp;recipient of some venting from him.&nbsp;</p>\n<p>It might not have been a good idea to ask Less Wrong this (I guess), but if anyone could direct me to a more...&nbsp;appropriate...&nbsp;website or service for these matters, I would appreciate it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yHhxRt7Tf8hsqPL79", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "18771", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T22:02:19.263Z", "modifiedAt": null, "url": null, "title": "Under-acknowledged Value Differences", "slug": "under-acknowledged-value-differences", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:34.224Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4XS5LQA6RadkMqdgt/under-acknowledged-value-differences", "pageUrlRelative": "/posts/4XS5LQA6RadkMqdgt/under-acknowledged-value-differences", "linkUrl": "https://www.lesswrong.com/posts/4XS5LQA6RadkMqdgt/under-acknowledged-value-differences", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Under-acknowledged%20Value%20Differences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnder-acknowledged%20Value%20Differences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4XS5LQA6RadkMqdgt%2Funder-acknowledged-value-differences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Under-acknowledged%20Value%20Differences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4XS5LQA6RadkMqdgt%2Funder-acknowledged-value-differences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4XS5LQA6RadkMqdgt%2Funder-acknowledged-value-differences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 338, "htmlBody": "<p>I've been reading a lot of the recent LW discussions on politics and gender, and noticed that people rarely bring up or explicitly acknowledge that different people affected by some political or gender issue have different values/preferences, and therefore solving the problem involves a strong element of bargaining and is not just a matter of straightforward optimization. Instead, we tend to talk as if there is some way to solve the problem that's best for everyone, and that rational discussion will bring us closer to finding that one best solution.</p>\n<p>For example, when discussing gender-related problems, one solution may be generally better for men, while another solution may be&nbsp;generally&nbsp;better for women. If people are selfish, then they will each prefer the solution that's individually best for them, even if they can agree on all of the facts. (It's <a href=\"/lw/8gk/where_do_selfish_values_come_from/\">unclear</a> whether people <em>should</em>&nbsp;be selfish, but it seems best to assume that most are, for practical purposes.)</p>\n<p>Unfortunately, <a href=\"/lw/f6/epistemic_vs_instrumental_rationality_case_of_the/\">in bargaining situations</a>, epistemic rationality is not necessarily instrumentally rational. In general, convincing others of a falsehood can be useful for moving the negotiated outcome closer to one's own preferences and away from others', and this may be done more easily if one honestly believes the falsehood. (One of these falsehoods may be, for example, \"My preferred solution is best for everyone.\") Given these (subconsciously&nbsp;or&nbsp;evolutionarily&nbsp;processed) incentives, it seems reasonable to think that the more solving a problem resembles bargaining, the more likely we are to be&nbsp;epistemicaly irrationality when thinking and talking about it.</p>\n<p>If we do not acknowledge and keep in mind that we are in a bargaining situation, then we are less likely to detect such failures of&nbsp;epistemic rationality, especially in ourselves.&nbsp;We're also less likely to see that there's an element of Prisoner's&nbsp;Dilemma&nbsp;in participating in such debates: your effort to convince people to adopt your preferred solution is costly (in time and in your and LW's overall sanity level) but may achieve little because someone else is making an opposite argument. Both of you may be better off if neither engaged in the debate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1, "FkzScn5byCs9PxGsA": 1, "wzgcQCrwKfETcBpR9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4XS5LQA6RadkMqdgt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 70, "extendedScore": null, "score": 0.00017863052547499627, "legacy": true, "legacyId": "18772", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 53, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Nz62ZurRkGPigAxMK", "g2Rh4xXALjuyLqm4k"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-12T23:11:46.046Z", "modifiedAt": null, "url": null, "title": "Request for a cryonics decision flowchart", "slug": "request-for-a-cryonics-decision-flowchart", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.531Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tqvxc2GvC3zAEqLeB/request-for-a-cryonics-decision-flowchart", "pageUrlRelative": "/posts/Tqvxc2GvC3zAEqLeB/request-for-a-cryonics-decision-flowchart", "linkUrl": "https://www.lesswrong.com/posts/Tqvxc2GvC3zAEqLeB/request-for-a-cryonics-decision-flowchart", "postedAtFormatted": "Wednesday, September 12th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Request%20for%20a%20cryonics%20decision%20flowchart&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequest%20for%20a%20cryonics%20decision%20flowchart%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqvxc2GvC3zAEqLeB%2Frequest-for-a-cryonics-decision-flowchart%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Request%20for%20a%20cryonics%20decision%20flowchart%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqvxc2GvC3zAEqLeB%2Frequest-for-a-cryonics-decision-flowchart", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqvxc2GvC3zAEqLeB%2Frequest-for-a-cryonics-decision-flowchart", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<p>After occasionally researching cryonics over the past couple years, I remain confused about what happens certain situations. &nbsp;Could we create,&nbsp;collaboratively or otherwise,&nbsp;a comprehensive flowchart or decision tree that represents what options exist if, for example, one is a member of CI, but has not yet funded the procedure, and enters a life-threatening coma? &nbsp;Or which situations one needs to fund SA for standby or transport? &nbsp;</p>\n<p>This or something like it&nbsp;seems&nbsp;like low-hanging fruit for preventing cryocrastination, at least in my case - I want to fully understand the system before investing in it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tqvxc2GvC3zAEqLeB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 9.853642504982451e-07, "legacy": true, "legacyId": "18773", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-13T00:20:18.443Z", "modifiedAt": null, "url": null, "title": "Meetup : Dc Zendo meetup", "slug": "meetup-dc-zendo-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Rv9rCnd4hWLHZbRrN/meetup-dc-zendo-meetup", "pageUrlRelative": "/posts/Rv9rCnd4hWLHZbRrN/meetup-dc-zendo-meetup", "linkUrl": "https://www.lesswrong.com/posts/Rv9rCnd4hWLHZbRrN/meetup-dc-zendo-meetup", "postedAtFormatted": "Thursday, September 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Dc%20Zendo%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Dc%20Zendo%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRv9rCnd4hWLHZbRrN%2Fmeetup-dc-zendo-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Dc%20Zendo%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRv9rCnd4hWLHZbRrN%2Fmeetup-dc-zendo-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRv9rCnd4hWLHZbRrN%2Fmeetup-dc-zendo-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ds'>Dc Zendo meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 September 2012 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Portrait Gallery Courtyard</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be playing Zendo (aka \"science the game\"). We can have it in Chinatown at the portrait gallery courtyard, but if someone can host, that would be ideal. If you want to, just email the list. Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ds'>Dc Zendo meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Rv9rCnd4hWLHZbRrN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 9.853993285932261e-07, "legacy": true, "legacyId": "18774", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Dc_Zendo_meetup\">Discussion article for the meetup : <a href=\"/meetups/ds\">Dc Zendo meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 September 2012 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Portrait Gallery Courtyard</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be playing Zendo (aka \"science the game\"). We can have it in Chinatown at the portrait gallery courtyard, but if someone can host, that would be ideal. If you want to, just email the list. Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Dc_Zendo_meetup1\">Discussion article for the meetup : <a href=\"/meetups/ds\">Dc Zendo meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Dc Zendo meetup", "anchor": "Discussion_article_for_the_meetup___Dc_Zendo_meetup", "level": 1}, {"title": "Discussion article for the meetup : Dc Zendo meetup", "anchor": "Discussion_article_for_the_meetup___Dc_Zendo_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-13T04:59:41.716Z", "modifiedAt": null, "url": null, "title": "[LINK] Meteorologists are Epistemically Rational", "slug": "link-meteorologists-are-epistemically-rational", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.416Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AspiringRationalist", "createdAt": "2012-03-14T02:23:07.389Z", "isAdmin": false, "displayName": "AspiringRationalist"}, "userId": "SiQCqozmtW7TSjo6E", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WqntPehy8kwRQ4BRY/link-meteorologists-are-epistemically-rational", "pageUrlRelative": "/posts/WqntPehy8kwRQ4BRY/link-meteorologists-are-epistemically-rational", "linkUrl": "https://www.lesswrong.com/posts/WqntPehy8kwRQ4BRY/link-meteorologists-are-epistemically-rational", "postedAtFormatted": "Thursday, September 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Meteorologists%20are%20Epistemically%20Rational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Meteorologists%20are%20Epistemically%20Rational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWqntPehy8kwRQ4BRY%2Flink-meteorologists-are-epistemically-rational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Meteorologists%20are%20Epistemically%20Rational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWqntPehy8kwRQ4BRY%2Flink-meteorologists-are-epistemically-rational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWqntPehy8kwRQ4BRY%2Flink-meteorologists-are-epistemically-rational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>Nate Silver of the New York Times's political prediction blog <a href=\"http://fivethirtyeight.blogs.nytimes.com/\">fivethirtyeight</a>&nbsp;has posted an excerpt of his upcoming book on predictions in various disciplines, <em>The Signal and the Noise</em>. &nbsp;The excerpt describes how meteorologists, in contrast to prognosticators in other domains, have substantially improved the accuracy of their predictions by understanding the limitations of both intuition and computer models, enabling them to combine them intelligently rather than relying excessively on one or the other.</p>\n<p>The excerpt is available at&nbsp;<span style=\"text-decoration: underline; color: #0000ee; \">http://www.nytimes.com/2012/09/09/magazine/the-weatherman-is-not-a-moron.html?_r=2&amp;pagewanted=all</span>, and a summary is available at&nbsp;<a href=\"http://fivethirtyeight.blogs.nytimes.com/2012/09/09/why-weather-forecasters-are-role-models/\">http://fivethirtyeight.blogs.nytimes.com/2012/09/09/why-weather-forecasters-are-role-models/</a></p>\n<p>Side note: if you are running up against NYT's 10 article per month limit, opening the links in Incognito Mode will get around it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WqntPehy8kwRQ4BRY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 16, "extendedScore": null, "score": 9.855423395697837e-07, "legacy": true, "legacyId": "18776", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-13T05:27:37.889Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Use the Try Harder, Luke", "slug": "seq-rerun-use-the-try-harder-luke", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.051Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xYN8qWfnB2F9uewp7/seq-rerun-use-the-try-harder-luke", "pageUrlRelative": "/posts/xYN8qWfnB2F9uewp7/seq-rerun-use-the-try-harder-luke", "linkUrl": "https://www.lesswrong.com/posts/xYN8qWfnB2F9uewp7/seq-rerun-use-the-try-harder-luke", "postedAtFormatted": "Thursday, September 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Use%20the%20Try%20Harder%2C%20Luke&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Use%20the%20Try%20Harder%2C%20Luke%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxYN8qWfnB2F9uewp7%2Fseq-rerun-use-the-try-harder-luke%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Use%20the%20Try%20Harder%2C%20Luke%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxYN8qWfnB2F9uewp7%2Fseq-rerun-use-the-try-harder-luke", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxYN8qWfnB2F9uewp7%2Fseq-rerun-use-the-try-harder-luke", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>Today's post, <a href=\"/lw/ui/use_the_try_harder_luke/\">Use the Try Harder, Luke</a> was originally published on 02 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Use_the_Try_Harder.2C_Luke\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A fictional exchange between Mark Hamil and George Lucas over the scene in Empire Strikes Back where Luke Skywalker attempts to lift his X-wing with the force.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/egw/seq_rerun_trying_to_try/\">Trying to Try</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xYN8qWfnB2F9uewp7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.855566413551532e-07, "legacy": true, "legacyId": "18777", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fhEPnveFhb9tmd7Pe", "cuYzbMjQDh3SDeMqa", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-13T07:03:54.167Z", "modifiedAt": null, "url": null, "title": "Fallacies of reification - the placebo effect", "slug": "fallacies-of-reification-the-placebo-effect", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:39.580Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tjTuzmCYxfsgkKdQx/fallacies-of-reification-the-placebo-effect", "pageUrlRelative": "/posts/tjTuzmCYxfsgkKdQx/fallacies-of-reification-the-placebo-effect", "linkUrl": "https://www.lesswrong.com/posts/tjTuzmCYxfsgkKdQx/fallacies-of-reification-the-placebo-effect", "postedAtFormatted": "Thursday, September 13th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fallacies%20of%20reification%20-%20the%20placebo%20effect&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFallacies%20of%20reification%20-%20the%20placebo%20effect%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjTuzmCYxfsgkKdQx%2Ffallacies-of-reification-the-placebo-effect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fallacies%20of%20reification%20-%20the%20placebo%20effect%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjTuzmCYxfsgkKdQx%2Ffallacies-of-reification-the-placebo-effect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjTuzmCYxfsgkKdQx%2Ffallacies-of-reification-the-placebo-effect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 638, "htmlBody": "<p>TL;DR: I align with the minority position that \"there is a lot less to the so-called placebo effect than people tend to think there is (and the name is horribly misleading)\", a <a href=\"http://bobsutton.typepad.com/my_weblog/2006/07/strong_opinions.html\">strong opinion weakly held</a>.</p>\n<p>The following post is an off-the cuff reply to a G+ post of gwern's, but I've been thinking about this on and off for quite a while.&nbsp;Were I to expand this for posting to Main, I would: a) go into more detail about the published research, b) introduce a second fallacy of reification for comparison, the so-called \"10X variance in programmer productivity\".</p>\n<p>My <a href=\"/lw/b2/declare_your_signaling_and_hidden_agendas/\">agenda</a> is to have this join my short <a href=\"/lw/9sv/diseased_disciplines_the_strange_case_of_the/\">series</a> of <a href=\"/lw/amt/causal_diagrams_and_software_engineering/\">articles</a> on \"software engineering as a diseased discipline\", which I view as my modest attempt at \"using Less Wrong ideas in your <a href=\"/lw/9c/mandatory_secret_identities/\">secret identity</a>\" and is covered at greater length in my <a href=\"https://leanpub.com/leprechauns\">book-in-progress</a>.</p>\n<p>I would therefore appreciate your feedback and probing at weak points.</p>\n<hr />\n<p>Most of the time, talk of placebo effects (or worse of \"the\" placebo effect) falls victim to the reification fallacy.</p>\n<p>My position is roughly&nbsp;\"there is a lot less to the so-called placebo effect than people think there is (and the name is horribly misleading)\".</p>\n<p>More precisely: the term \"placebo\" in the context of \"placebo controlled trial\" has some usefulness, when used to mean a particular way of distinguishing between the null and test hypotheses in a trial: namely, that the test and control group receive exactly the same treatment, except that you substitute, in the control group, an inert substance (or inoperative procedure) for the putatively active substance being tested.</p>\n<p>Whatever outcome measures are used, they will generally improve somewhat even in the control group: this can be due to many things, including regression to the mean, the disease running its course, increased compliance with medical instructions due to being in a study, expectancy effects leading to biased verbal self-reports.</p>\n<p>None of these is properly speaking an \"effect\" causally linked to the inert substance (the \"placebo pill\"). The reification fallacy consists of thinking that because we give something a name (\"the placebo effect\") then there must be a corresponding reality. The false inference is \"the people who improved in the control group were healed by the power of the placebo effect\".</p>\n<p>The <em>further</em> false inference is \"there are ailments of which I could be cured by ingesting small sugar pills appropriately labeled\". Some of my friends actually leverage this into justification for buying sugar in pharmacies at a ridiculous markup. I confess to being aghast whenever this happens in my presence.</p>\n<p>A better name has been suggested: the \"control response\". This is experiment-specific, and encompasses all of the various mechanisms which make it look like \"the control group improves when given a sugar pill / saline solution / sham treatment\". Moreover it avoids hinting at mysterious healing powers of the mind.</p>\n<p>Meta-analyses of those few studies that were designed to find an actual \"placebo effect\" (i.e. studies with a non-treatment arm, or studies comparing objective outcome measures for different placebos) have not confirmed it, the few individual studies that find a positive effect are inconclusive for a variety of reasons.</p>\n<p>Doubting the existence of the placebo effect will expose you to immediate contradiction from your educated peers. One explanation seems to be that the \"placebo effect\" is a necessary argumentative prop in the <a href=\"http://wiki.lesswrong.com/wiki/Arguments_as_soldiers\">arsenal of two opposed \"camps\"</a>. On the one hand proponents of CAM (Complementary and Alternative Medicine) will argue that \"even if a herbal remedy is a placebo, who cares as long as it actually works\" and must therefore assume that the placebo effect is real. On the other hand opponents of CAM will say \"homeopathy or herbal remedies only seem to work because of the placebo effect, we can therefore dismiss all positive reports from people treating themselves with such\".</p>\n<p>I don't have a proper list of references yet, but see the following:</p>\n<p>http://www.sciencebasedmedicine.org/index.php/behold-the-spin-what-a-new-survey-of-of-placebo-prescribing-really-tells-us/</p>\n<p>http://www.sciencebasedmedicine.org/index.php/the-placebo-myth/</p>\n<p>http://www.skeptic.com/eskeptic/09-05-20/</p>\n<p>http://www.skepdic.com/placebo.html</p>\n<p>http://content.onlinejacc.org/article.aspx?articleid=1188659</p>\n<p>http://www.ncbi.nlm.nih.gov/pubmed/15257721</p>\n<p>http://www.ncbi.nlm.nih.gov/pubmed/9449934</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tjTuzmCYxfsgkKdQx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 31, "extendedScore": null, "score": 9.85605929645676e-07, "legacy": true, "legacyId": "18787", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yCjofyFSoAq73LT2A", "4ACmfJkXQxkYacdLt", "XHgEbHRmJjE5DonNk", "gBewgmzcEiks2XdoQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T04:33:37.385Z", "modifiedAt": null, "url": null, "title": "Question on decoherence and virtual particles", "slug": "question-on-decoherence-and-virtual-particles", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:37.976Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6L56cHp5WWAdfih5t/question-on-decoherence-and-virtual-particles", "pageUrlRelative": "/posts/6L56cHp5WWAdfih5t/question-on-decoherence-and-virtual-particles", "linkUrl": "https://www.lesswrong.com/posts/6L56cHp5WWAdfih5t/question-on-decoherence-and-virtual-particles", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Question%20on%20decoherence%20and%20virtual%20particles&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuestion%20on%20decoherence%20and%20virtual%20particles%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6L56cHp5WWAdfih5t%2Fquestion-on-decoherence-and-virtual-particles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Question%20on%20decoherence%20and%20virtual%20particles%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6L56cHp5WWAdfih5t%2Fquestion-on-decoherence-and-virtual-particles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6L56cHp5WWAdfih5t%2Fquestion-on-decoherence-and-virtual-particles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p>Doing some insomniac reading of the Quantum Sequence, I think that I've gotten a reasonable grasp of the principles of decoherence, non-interacting bundles of amplitude, etc. I then tried to put that knowledge to work by comparing it with my understanding of virtual particles (whose rate of creation in any area is essentially equivalent to the electromagnetic field), and I had a thought I can't seem to find mentioned elsewhere.</p>\n<p>&nbsp;</p>\n<p>If I understand decoherence right, then quantum events which can't be differentiated from each other get summed together into the same blob of amplitude. Most virtual particles which appear and rapidly disappear do so in ways that can't be detected, let alone distinguished. This seems as if it could potentially imply that the extreme evenness of a vacuum might have to do more with the overall blob of amplitude of the vacuum being smeared out among all the equally-likely vacuum fluctuations, than it does directly with the evenness of the rate of vacuum fluctuations themselves. It also seems possible that there could be some clever way to test for an overall background smear of amplitude, though I'm not awake enough to figure one out just now. (My imagination has thrown out the phrase 'collapse of the vacuum state', but I'm betting that that's just unrelated quantum buzzword bingo.)</p>\n<p>&nbsp;</p>\n<p>Does anything similar to what I've just described have any correlation with actual quantum theory, or will I awaken to discover all my points have been voted away due to this being complete and utter nonsense?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6L56cHp5WWAdfih5t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 1, "extendedScore": null, "score": 9.862666537488881e-07, "legacy": true, "legacyId": "18792", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T05:44:27.525Z", "modifiedAt": null, "url": null, "title": "Experimental psychology on word confusion", "slug": "experimental-psychology-on-word-confusion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.959Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AxaSQkHCsqEkGwaGE/experimental-psychology-on-word-confusion", "pageUrlRelative": "/posts/AxaSQkHCsqEkGwaGE/experimental-psychology-on-word-confusion", "linkUrl": "https://www.lesswrong.com/posts/AxaSQkHCsqEkGwaGE/experimental-psychology-on-word-confusion", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experimental%20psychology%20on%20word%20confusion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperimental%20psychology%20on%20word%20confusion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAxaSQkHCsqEkGwaGE%2Fexperimental-psychology-on-word-confusion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experimental%20psychology%20on%20word%20confusion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAxaSQkHCsqEkGwaGE%2Fexperimental-psychology-on-word-confusion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAxaSQkHCsqEkGwaGE%2Fexperimental-psychology-on-word-confusion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 143, "htmlBody": "<p>There's <a href=\"http://appliedrationality.org/recommended-reading-on-rationality/\">plenty of experimental work</a>&nbsp;about how humans make poor judgments and decisions, but I haven't yet found much about how humans make poor judgments and decisions <em>because of confusions about words</em>. And yet, I expect such errors are common &mdash; I, at least, encounter them frequently.</p>\n<p>It would be nice to have some scientific studies which illustrate the ways in which confusions about words affect everyday decision making, but instead all I can do is make philosophical arguments and point people to things like Yudkowsky's&nbsp;<a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">37 Ways That Words Can Be Wrong</a> or Chalmers'&nbsp;<a href=\"http://consc.net/oxford/chap9.pdf\">Verbal Disputes and Philosophical Progress</a>.</p>\n<p>Which keywords do I need to find experimental work on this topic? I tried Google scholar searches like <a href=\"/&quot;fuzzy concepts&quot; &quot;decision making&quot;\">\"fuzzy concepts\" \"decision making\"</a> and <a href=\"/effect of connotations on choices\">effect of connotations on choices</a> but I didn't find much in my first hour of looking into this.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AxaSQkHCsqEkGwaGE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 9.863029655785886e-07, "legacy": true, "legacyId": "18790", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FaJaCgqBKphrDzDSj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T05:54:09.516Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Beyond the Reach of God", "slug": "seq-rerun-beyond-the-reach-of-god", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:38.582Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RFZnBQ7hwBJTc3XCt/seq-rerun-beyond-the-reach-of-god", "pageUrlRelative": "/posts/RFZnBQ7hwBJTc3XCt/seq-rerun-beyond-the-reach-of-god", "linkUrl": "https://www.lesswrong.com/posts/RFZnBQ7hwBJTc3XCt/seq-rerun-beyond-the-reach-of-god", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Beyond%20the%20Reach%20of%20God&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Beyond%20the%20Reach%20of%20God%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRFZnBQ7hwBJTc3XCt%2Fseq-rerun-beyond-the-reach-of-god%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Beyond%20the%20Reach%20of%20God%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRFZnBQ7hwBJTc3XCt%2Fseq-rerun-beyond-the-reach-of-god", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRFZnBQ7hwBJTc3XCt%2Fseq-rerun-beyond-the-reach-of-god", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 181, "htmlBody": "<p>Today's post, <a href=\"/lw/uk/beyond_the_reach_of_god/\">Beyond the Reach of God</a> was originally published on 04 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Beyond_the_Reach_of_God\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Compare the world in which there is a God, who will intervene at some threshold, against a world in which everything happens as a result of physical laws. Which universe looks more like our own?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ehl/seq_rerun_use_the_try_harder_luke/\">Use the Try Harder, Luke</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RFZnBQ7hwBJTc3XCt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 9.86307937928444e-07, "legacy": true, "legacyId": "18802", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sYgv4eYH82JEsTD34", "xYN8qWfnB2F9uewp7", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T10:28:32.242Z", "modifiedAt": null, "url": null, "title": "How about testing our ideas? ", "slug": "how-about-testing-our-ideas", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:02.761Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tNhBXnafzCAvmzmxD/how-about-testing-our-ideas", "pageUrlRelative": "/posts/tNhBXnafzCAvmzmxD/how-about-testing-our-ideas", "linkUrl": "https://www.lesswrong.com/posts/tNhBXnafzCAvmzmxD/how-about-testing-our-ideas", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20about%20testing%20our%20ideas%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20about%20testing%20our%20ideas%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNhBXnafzCAvmzmxD%2Fhow-about-testing-our-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20about%20testing%20our%20ideas%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNhBXnafzCAvmzmxD%2Fhow-about-testing-our-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtNhBXnafzCAvmzmxD%2Fhow-about-testing-our-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 900, "htmlBody": "<div id=\"body_t1_7fk0\" class=\"comment-content \">\n<div class=\"md\">\n<p><strong>Related to:&nbsp;</strong><em> </em><a href=\"/lw/3wh/science_do_it_yourself/\">Science: Do It Yourself</a>, <a href=\"/lw/ajj/how_to_fix_science/\">How To Fix Science</a>, Rationality and Science posts from <a href=\"/lw/r5/the_quantum_physics_sequence/\">this sequence</a>, <a href=\"http://www.lhup.edu/~DSIMANEK/cargocul.htm\">Cargo Cult Science</a>, \"<a href=\"http://en.wikipedia.org/wiki/Citizen_science\">citizen science</a>\"</p>\n<h3><span>You <em>think</em> you have a good map, what you really have is a working hypothesis</span></h3>\n<p>You did some thought on human rationality, perhaps spurred by intuition or personal experience. Building it up you did your homework and stood on the shoulders of other people's work giving <a href=\"http://www.overcomingbias.com/2011/02/against-diy-academics.html\">proper weight</a> to expert opinion. You write an article on LessWrong, it gets up voted, debated and perhaps accepted and promoted as part of a \"sequence\". But now you'd like to do that thing that's been nagging you since the start, you don't want to be one of those insight junkies consuming fun plausible ideas forgetting to ever get around to testing them. Lets see how the predictions made by your model hold up! You dive into the literature in search of experiments that have conveniently already tested your idea.</p>\n<p><em>It is possible there simply isn't any such experimental material or that it is unavailable.</em> Don't get me wrong, if I had to bet on it I would say it is more likely there is at least something similar to what you need than not. I would also bet that some things we wish where done haven't been so far and are unlikely to be for a long time. In the past I've wondered if we can in the future expect CFAR or LessWrong to do experimental work to test many of the hypotheses we've come up with based on fresh but unreliable insight, anecdotal evidence and long fragile chains of reasoning. This will not happen on its own.</p>\n<p>With mention of <a href=\"http://appliedrationality.org/\">CFAR</a>, the mind jumps to them doing expensive experiments or posing long questionnaires with small samples of students and then publishing papers, like everyone else does. It is the respectable thing to do and it is something that <em>may</em> or <em>may not</em> be worth their effort. It seems doable. The idea of LWers getting into the habit of testing their ideas on human rationality beyond the anecdotal seems utterly impractical. Or is it?</p>\n<h3><span>That ordinary people can band together to rapidly produce new knowledge is anything but a trifle</span></h3>\n<p>How useful would it be if we had a site visited by thousands or tens of thousands solving forms or participating in experiments submitted by LessWrong posters or CFAR researchers? Something like <a rel=\"nofollow\" href=\"http://www.yourmorals.org/\">this site</a>. How useful would it be if we made such a data set publicly available? What if we could in addition to this data mine how people use <a rel=\"nofollow\" href=\"http://appliedrationality.org/apps/\">apps</a> or an <a href=\"/lw/ecf/open_thread_september_115_2012/7cug\">online rationality class</a>? At this point you might be asking yourself if building knowledge this way even possible in fields that takes years to study. A fair question, especially for tasks that require technical competence, <strong><a rel=\"nofollow\" href=\"http://dienekes.blogspot.com/2011/10/citizen-genetics.html\">the answer is yes</a></strong>.</p>\n<p>I'm sure many at this point, have started wondering about what kinds of problems biased samples might create for us. <em>It i</em>s important to keep in mind what kind of sample of people you get to participate in the experiment or fill out your form, since this influences how confident you are allowed to be about generalizations. Learning things about very specific kinds of people is useful too. Recall this is hardly a <a href=\"/lw/17x/beware_of_weird_psychological_samples/\">unique problem</a>, you can't really get away from it in the social sciences. <a href=\"http://www2.psych.ubc.ca/%7Ehenrich/pdfs/Weird_People_BBS_final02.pdf\">WEIRD</a> samples aren't weird in academia. And I didn't say the thousands and tens of thousands people would need to come from our own little corner of the internet, indeed they probably couldn't. There are many approaches to getting them and making the sample as good as we can. Sites like <a href=\"http://www.yourmorals.org/aboutus.php\">yourmorals.org</a> tried a variety of approaches we could learn from them. Even doing something like hiring people from <a href=\"http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk\">Amazon Mechanical Turk</a> can work out <a href=\"http://gureckislab.org/blog/?p=1297\">surprisingly well</a>.&nbsp;</p>\n<h3><span>LessWrong Science: We do what we must because we can </span></h3>\n<p>The harder question is if the resulting<em> </em>data would be used at all<em>. </em>As we currently are? I don't think so.<em> </em>There are many publicly available data sets and plenty of opportunities to mine data online, yet we see little if any original analysis based on them here. We either don't have norms encouraging this or we don't have enough people comfortable with statistics doing so. Problems like this aren't immutable. <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">The Neglected Virtue of Scholarship</a> noticeably changed our community in a similarly profound way with positive results. Feeling that <a href=\"http://wiki.lesswrong.com/wiki/A_sense_that_more_is_possible\">more is possible</a> I think it is time for us to move in this direction.</p>\n<p>Perhaps just creating a way to get the data will attract the right crowd, the <a href=\"http://en.wikipedia.org/wiki/Quantified_Self\">quantified self</a> people are not out of place here. Perhaps LessWrong should become <a href=\"/lw/dg8/should_you_try_to_do_good_work_on_lw/\">less of a site and more of a blogosphere</a>. I'm not sure how and I think for now the question is a distraction anyway. <strong>What clearly can be useful is to create a list of models and ideas we've already assimilated that haven't been really tested or are based on research that still awaits replication.</strong> At the very least this will help us be ready to update if relevant future studies show up. But I think that identifying any low hanging fruit and design some experiments or attempts at replication, then going out there and try to perform them can get us so much more. If people have enough pull to get them done inside academia without community help <em>great</em>, if not we <em>should</em> seek alternatives.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 2, "32DdRimdM7sB5wmKu": 2, "izp6eeJJEg9v5zcur": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tNhBXnafzCAvmzmxD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 41, "extendedScore": null, "score": 0.000156, "legacy": true, "legacyId": "18804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<div id=\"body_t1_7fk0\" class=\"comment-content \">\n<div class=\"md\">\n<p><strong>Related to:&nbsp;</strong><em> </em><a href=\"/lw/3wh/science_do_it_yourself/\">Science: Do It Yourself</a>, <a href=\"/lw/ajj/how_to_fix_science/\">How To Fix Science</a>, Rationality and Science posts from <a href=\"/lw/r5/the_quantum_physics_sequence/\">this sequence</a>, <a href=\"http://www.lhup.edu/~DSIMANEK/cargocul.htm\">Cargo Cult Science</a>, \"<a href=\"http://en.wikipedia.org/wiki/Citizen_science\">citizen science</a>\"</p>\n<h3 id=\"You_think_you_have_a_good_map__what_you_really_have_is_a_working_hypothesis\"><span>You <em>think</em> you have a good map, what you really have is a working hypothesis</span></h3>\n<p>You did some thought on human rationality, perhaps spurred by intuition or personal experience. Building it up you did your homework and stood on the shoulders of other people's work giving <a href=\"http://www.overcomingbias.com/2011/02/against-diy-academics.html\">proper weight</a> to expert opinion. You write an article on LessWrong, it gets up voted, debated and perhaps accepted and promoted as part of a \"sequence\". But now you'd like to do that thing that's been nagging you since the start, you don't want to be one of those insight junkies consuming fun plausible ideas forgetting to ever get around to testing them. Lets see how the predictions made by your model hold up! You dive into the literature in search of experiments that have conveniently already tested your idea.</p>\n<p><em>It is possible there simply isn't any such experimental material or that it is unavailable.</em> Don't get me wrong, if I had to bet on it I would say it is more likely there is at least something similar to what you need than not. I would also bet that some things we wish where done haven't been so far and are unlikely to be for a long time. In the past I've wondered if we can in the future expect CFAR or LessWrong to do experimental work to test many of the hypotheses we've come up with based on fresh but unreliable insight, anecdotal evidence and long fragile chains of reasoning. This will not happen on its own.</p>\n<p>With mention of <a href=\"http://appliedrationality.org/\">CFAR</a>, the mind jumps to them doing expensive experiments or posing long questionnaires with small samples of students and then publishing papers, like everyone else does. It is the respectable thing to do and it is something that <em>may</em> or <em>may not</em> be worth their effort. It seems doable. The idea of LWers getting into the habit of testing their ideas on human rationality beyond the anecdotal seems utterly impractical. Or is it?</p>\n<h3 id=\"That_ordinary_people_can_band_together_to_rapidly_produce_new_knowledge_is_anything_but_a_trifle\"><span>That ordinary people can band together to rapidly produce new knowledge is anything but a trifle</span></h3>\n<p>How useful would it be if we had a site visited by thousands or tens of thousands solving forms or participating in experiments submitted by LessWrong posters or CFAR researchers? Something like <a rel=\"nofollow\" href=\"http://www.yourmorals.org/\">this site</a>. How useful would it be if we made such a data set publicly available? What if we could in addition to this data mine how people use <a rel=\"nofollow\" href=\"http://appliedrationality.org/apps/\">apps</a> or an <a href=\"/lw/ecf/open_thread_september_115_2012/7cug\">online rationality class</a>? At this point you might be asking yourself if building knowledge this way even possible in fields that takes years to study. A fair question, especially for tasks that require technical competence, <strong><a rel=\"nofollow\" href=\"http://dienekes.blogspot.com/2011/10/citizen-genetics.html\">the answer is yes</a></strong>.</p>\n<p>I'm sure many at this point, have started wondering about what kinds of problems biased samples might create for us. <em>It i</em>s important to keep in mind what kind of sample of people you get to participate in the experiment or fill out your form, since this influences how confident you are allowed to be about generalizations. Learning things about very specific kinds of people is useful too. Recall this is hardly a <a href=\"/lw/17x/beware_of_weird_psychological_samples/\">unique problem</a>, you can't really get away from it in the social sciences. <a href=\"http://www2.psych.ubc.ca/%7Ehenrich/pdfs/Weird_People_BBS_final02.pdf\">WEIRD</a> samples aren't weird in academia. And I didn't say the thousands and tens of thousands people would need to come from our own little corner of the internet, indeed they probably couldn't. There are many approaches to getting them and making the sample as good as we can. Sites like <a href=\"http://www.yourmorals.org/aboutus.php\">yourmorals.org</a> tried a variety of approaches we could learn from them. Even doing something like hiring people from <a href=\"http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk\">Amazon Mechanical Turk</a> can work out <a href=\"http://gureckislab.org/blog/?p=1297\">surprisingly well</a>.&nbsp;</p>\n<h3 id=\"LessWrong_Science__We_do_what_we_must_because_we_can_\"><span>LessWrong Science: We do what we must because we can </span></h3>\n<p>The harder question is if the resulting<em> </em>data would be used at all<em>. </em>As we currently are? I don't think so.<em> </em>There are many publicly available data sets and plenty of opportunities to mine data online, yet we see little if any original analysis based on them here. We either don't have norms encouraging this or we don't have enough people comfortable with statistics doing so. Problems like this aren't immutable. <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">The Neglected Virtue of Scholarship</a> noticeably changed our community in a similarly profound way with positive results. Feeling that <a href=\"http://wiki.lesswrong.com/wiki/A_sense_that_more_is_possible\">more is possible</a> I think it is time for us to move in this direction.</p>\n<p>Perhaps just creating a way to get the data will attract the right crowd, the <a href=\"http://en.wikipedia.org/wiki/Quantified_Self\">quantified self</a> people are not out of place here. Perhaps LessWrong should become <a href=\"/lw/dg8/should_you_try_to_do_good_work_on_lw/\">less of a site and more of a blogosphere</a>. I'm not sure how and I think for now the question is a distraction anyway. <strong>What clearly can be useful is to create a list of models and ideas we've already assimilated that haven't been really tested or are based on research that still awaits replication.</strong> At the very least this will help us be ready to update if relevant future studies show up. But I think that identifying any low hanging fruit and design some experiments or attempts at replication, then going out there and try to perform them can get us so much more. If people have enough pull to get them done inside academia without community help <em>great</em>, if not we <em>should</em> seek alternatives.</p>\n</div>\n</div>", "sections": [{"title": "You think you have a good map, what you really have is a working hypothesis", "anchor": "You_think_you_have_a_good_map__what_you_really_have_is_a_working_hypothesis", "level": 1}, {"title": "That ordinary people can band together to rapidly produce new knowledge is anything but a trifle", "anchor": "That_ordinary_people_can_band_together_to_rapidly_produce_new_knowledge_is_anything_but_a_trifle", "level": 1}, {"title": "LessWrong Science: We do what we must because we can ", "anchor": "LessWrong_Science__We_do_what_we_must_because_we_can_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "113 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 113, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K82evF2iRAiRWwvyn", "ETe2SZacmLvvr8H9n", "hc9Eg6erp6hk9bWhn", "33YYcoWwtmqzAq9QR", "64FdKLwmea8MCLWkE", "nFwHtnfLZ9QWia7Zu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T15:57:38.881Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Ohio", "slug": "weekly-lw-meetups-austin-ohio", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/omLrS4hGmaXyWKPBg/weekly-lw-meetups-austin-ohio", "pageUrlRelative": "/posts/omLrS4hGmaXyWKPBg/weekly-lw-meetups-austin-ohio", "linkUrl": "https://www.lesswrong.com/posts/omLrS4hGmaXyWKPBg/weekly-lw-meetups-austin-ohio", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Ohio&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Ohio%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomLrS4hGmaXyWKPBg%2Fweekly-lw-meetups-austin-ohio%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Ohio%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomLrS4hGmaXyWKPBg%2Fweekly-lw-meetups-austin-ohio", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FomLrS4hGmaXyWKPBg%2Fweekly-lw-meetups-austin-ohio", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 445, "htmlBody": "<p><strong>This summary was posted to LW Main on September 7th. The most recent summary can be found <a href=\"/lw/eie/weekly_lw_meetups_austin_brussels_cambridge_ma/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/di\">Brussels meetup:&nbsp;<span class=\"date\">15 September 2012 12:00PM</span></a></li>\n<li><a href=\"/meetups/dl\">Less Wrong Sydney: 17th September: MInd Games:&nbsp;<span class=\"date\">17 September 2012 06:30PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">08 September 2018 01:30PM</span></a></li>\n<li><a href=\"/meetups/cv\">Meetup: Southwestern Ohio:&nbsp;<span class=\"date\">09 September 2012 04:00PM</span></a></li>\n<li><a href=\"/meetups/dk\">Predictions Chi September 15 (September 8 -- cancelled):&nbsp;<span class=\"date\">15 September 2012 01:05PM</span></a></li>\n<li><a href=\"/meetups/d6\">SLC, UT: Free Will and Rationality Checklists:&nbsp;<span class=\"date\">15 September 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/de\">Cambridge (MA) third-Sundays meetup:&nbsp;<span class=\"date\">16 September 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/df\">Cambridge (MA) first-Sundays meetup:&nbsp;<span class=\"date\">07 October 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/dg\">Cambridge (MA) third-Sundays Meetup:&nbsp;<span class=\"date\">21 October 2012 02:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong>&nbsp;</strong><strong></strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>, <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "omLrS4hGmaXyWKPBg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 9.866173978332228e-07, "legacy": true, "legacyId": "18688", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CwJDfG7QRyLXanBu4", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T20:10:43.834Z", "modifiedAt": null, "url": null, "title": "Meetup : Pittsburgh: Mind Hack Show and Tell", "slug": "meetup-pittsburgh-mind-hack-show-and-tell", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rDgStrybqQNANJBpW/meetup-pittsburgh-mind-hack-show-and-tell", "pageUrlRelative": "/posts/rDgStrybqQNANJBpW/meetup-pittsburgh-mind-hack-show-and-tell", "linkUrl": "https://www.lesswrong.com/posts/rDgStrybqQNANJBpW/meetup-pittsburgh-mind-hack-show-and-tell", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Pittsburgh%3A%20Mind%20Hack%20Show%20and%20Tell&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Pittsburgh%3A%20Mind%20Hack%20Show%20and%20Tell%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrDgStrybqQNANJBpW%2Fmeetup-pittsburgh-mind-hack-show-and-tell%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Pittsburgh%3A%20Mind%20Hack%20Show%20and%20Tell%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrDgStrybqQNANJBpW%2Fmeetup-pittsburgh-mind-hack-show-and-tell", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrDgStrybqQNANJBpW%2Fmeetup-pittsburgh-mind-hack-show-and-tell", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dt'>Pittsburgh: Mind Hack Show and Tell</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">EatUnique, Craig St, Pittsburgh</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>How have you made your brain work better? Bring your stories and/or statistics. Failed experiments also welcome.</p>\n\n<p>Eatunique serves salads, wraps, sandwiches, drinks, and that kind of thing. Call 412-304-6258 if you can't find us.</p>\n\n<p>Our mailing list is at https://groups.google.com/group/lw-pgh?pli=1</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dt'>Pittsburgh: Mind Hack Show and Tell</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rDgStrybqQNANJBpW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.86747225742152e-07, "legacy": true, "legacyId": "18808", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh__Mind_Hack_Show_and_Tell\">Discussion article for the meetup : <a href=\"/meetups/dt\">Pittsburgh: Mind Hack Show and Tell</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">EatUnique, Craig St, Pittsburgh</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>How have you made your brain work better? Bring your stories and/or statistics. Failed experiments also welcome.</p>\n\n<p>Eatunique serves salads, wraps, sandwiches, drinks, and that kind of thing. Call 412-304-6258 if you can't find us.</p>\n\n<p>Our mailing list is at https://groups.google.com/group/lw-pgh?pli=1</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh__Mind_Hack_Show_and_Tell1\">Discussion article for the meetup : <a href=\"/meetups/dt\">Pittsburgh: Mind Hack Show and Tell</a></h2>", "sections": [{"title": "Discussion article for the meetup : Pittsburgh: Mind Hack Show and Tell", "anchor": "Discussion_article_for_the_meetup___Pittsburgh__Mind_Hack_Show_and_Tell", "level": 1}, {"title": "Discussion article for the meetup : Pittsburgh: Mind Hack Show and Tell", "anchor": "Discussion_article_for_the_meetup___Pittsburgh__Mind_Hack_Show_and_Tell1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T20:22:39.857Z", "modifiedAt": "2021-12-30T05:16:47.851Z", "url": null, "title": "[Link] Scott Adam's \"God's Debris\" ", "slug": "link-scott-adam-s-god-s-debris", "viewCount": null, "lastCommentedAt": "2012-09-15T01:23:48.811Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "allandong", "createdAt": "2010-12-07T04:40:53.708Z", "isAdmin": false, "displayName": "allandong"}, "userId": "hBNyouSjAycqW26Ty", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7MXbm37sHurReLQzf/link-scott-adam-s-god-s-debris", "pageUrlRelative": "/posts/7MXbm37sHurReLQzf/link-scott-adam-s-god-s-debris", "linkUrl": "https://www.lesswrong.com/posts/7MXbm37sHurReLQzf/link-scott-adam-s-god-s-debris", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Scott%20Adam's%20%22God's%20Debris%22%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Scott%20Adam's%20%22God's%20Debris%22%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7MXbm37sHurReLQzf%2Flink-scott-adam-s-god-s-debris%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Scott%20Adam's%20%22God's%20Debris%22%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7MXbm37sHurReLQzf%2Flink-scott-adam-s-god-s-debris", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7MXbm37sHurReLQzf%2Flink-scott-adam-s-god-s-debris", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>God's Debris is for people who \"enjoy having their brain spun around in their skulls.\" I think I can safely assume that this descriptive of a larger proportion of LessWrongians than the average population.</p>\n<p>Without going too far into depth, I will say that it is one of the more enjoyable reads I've had lately, the philosophy the main character espouses is coherent and astoundingly seductive in it's simplicity - &nbsp;even as it requires you to tilt your head and squint a little to see it.&nbsp;</p>\n<p>&nbsp;</p>\n<p><a href=\"http://nowscape.com/godsdebris.pdf\">Scott Adam's <em>God's Debris</em></a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7MXbm37sHurReLQzf", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -12, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "18809", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2012-09-14T20:22:39.857Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T20:42:31.944Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver!", "slug": "meetup-vancouver-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:39.497Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v4uhyvBMKZfcrteja/meetup-vancouver-3", "pageUrlRelative": "/posts/v4uhyvBMKZfcrteja/meetup-vancouver-3", "linkUrl": "https://www.lesswrong.com/posts/v4uhyvBMKZfcrteja/meetup-vancouver-3", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4uhyvBMKZfcrteja%2Fmeetup-vancouver-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4uhyvBMKZfcrteja%2Fmeetup-vancouver-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4uhyvBMKZfcrteja%2Fmeetup-vancouver-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 485, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/du'>Vancouver!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 September 2012 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2150 macdonald street, vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>TL;DR: We are awesome, come hang out on Thursday at 18:00 in a big brown house. I will present \"Letting Go (sequence)\". Check out our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a>.</p>\n\n<p>I think I'm going to start posting our reports and meetups on here again.</p>\n\n<p><strong>What we've been doing:</strong></p>\n\n<p>We've been meeting reliably every Thursday at 18:00, tho our venue has moved around a bit. Every week, one or two people come in with presentations/discussion topics and lead the discussion on that for an hour or so.</p>\n\n<p>Recently, we had a really good presentation from one of our member of how to make a lot of money, with a bunch of case studies of really rich and successful people that he knows, and what got them rich. That was a lot of fun, and has caused me to start trying to level up my hustle.</p>\n\n<p>A week ago, I presented the practical basics of decision theory and probability theory, including intuitive formulations of Bayes Theorem and EU maximization, and the important implications and things to remember for going out into the world and being a rational agent. That was received quite well, and cleared up some confusion for some of us.</p>\n\n<p>When we lack other stuff to talk about someone (usually me) reads a sequence and summarizes it to the group. That's usually pretty fun, but not as fun as the big original content talks.</p>\n\n<p>Another thing is that we've been making weekly specific commitments to our goals, and getting support and social pressure from the group to help complete them. That's been useful, tho we are currently thinking of other ways to do that without taking up valuable meetup time (talking about each person's goals takes a while).</p>\n\n<p>There are about 10 of us, depending how you count. We're all becoming good friends and it's a lot of fun.</p>\n\n<p><strong>So What?</strong></p>\n\n<p>So you should come out and hang out with us because we are cool and productive and do lots of high-value rationality stuff. This week is our monthly super meetup where we try to get as many people out as possible. That means you, yes even you, should come out see what we're about. If you are looking for an excuse to come out, this is it. If you think you have an excuse to not come out, it's just your imagination.</p>\n\n<p>This week we don't yet have any big talks that anyone has put together, so I'll be presenting the \"Letting Go\" sequence. Meetup is at 2150 macdonald street (on 6th in kits) on Thursday at 18:00. Check out the <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a></p>\n\n<p>(Thursday evening has been working well for all of us who show up, but I know at least one of you out there doesn't like thursday. Please participate in the scheduling discussions. We want things to work for as many people as possible)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/du'>Vancouver!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v4uhyvBMKZfcrteja", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 9.86763541779602e-07, "legacy": true, "legacyId": "18810", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver_\">Discussion article for the meetup : <a href=\"/meetups/du\">Vancouver!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 September 2012 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2150 macdonald street, vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>TL;DR: We are awesome, come hang out on Thursday at 18:00 in a big brown house. I will present \"Letting Go (sequence)\". Check out our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a>.</p>\n\n<p>I think I'm going to start posting our reports and meetups on here again.</p>\n\n<p><strong id=\"What_we_ve_been_doing_\">What we've been doing:</strong></p>\n\n<p>We've been meeting reliably every Thursday at 18:00, tho our venue has moved around a bit. Every week, one or two people come in with presentations/discussion topics and lead the discussion on that for an hour or so.</p>\n\n<p>Recently, we had a really good presentation from one of our member of how to make a lot of money, with a bunch of case studies of really rich and successful people that he knows, and what got them rich. That was a lot of fun, and has caused me to start trying to level up my hustle.</p>\n\n<p>A week ago, I presented the practical basics of decision theory and probability theory, including intuitive formulations of Bayes Theorem and EU maximization, and the important implications and things to remember for going out into the world and being a rational agent. That was received quite well, and cleared up some confusion for some of us.</p>\n\n<p>When we lack other stuff to talk about someone (usually me) reads a sequence and summarizes it to the group. That's usually pretty fun, but not as fun as the big original content talks.</p>\n\n<p>Another thing is that we've been making weekly specific commitments to our goals, and getting support and social pressure from the group to help complete them. That's been useful, tho we are currently thinking of other ways to do that without taking up valuable meetup time (talking about each person's goals takes a while).</p>\n\n<p>There are about 10 of us, depending how you count. We're all becoming good friends and it's a lot of fun.</p>\n\n<p><strong id=\"So_What_\">So What?</strong></p>\n\n<p>So you should come out and hang out with us because we are cool and productive and do lots of high-value rationality stuff. This week is our monthly super meetup where we try to get as many people out as possible. That means you, yes even you, should come out see what we're about. If you are looking for an excuse to come out, this is it. If you think you have an excuse to not come out, it's just your imagination.</p>\n\n<p>This week we don't yet have any big talks that anyone has put together, so I'll be presenting the \"Letting Go\" sequence. Meetup is at 2150 macdonald street (on 6th in kits) on Thursday at 18:00. Check out the <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a></p>\n\n<p>(Thursday evening has been working well for all of us who show up, but I know at least one of you out there doesn't like thursday. Please participate in the scheduling discussions. We want things to work for as many people as possible)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver_1\">Discussion article for the meetup : <a href=\"/meetups/du\">Vancouver!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver!", "anchor": "Discussion_article_for_the_meetup___Vancouver_", "level": 1}, {"title": "What we've been doing:", "anchor": "What_we_ve_been_doing_", "level": 2}, {"title": "So What?", "anchor": "So_What_", "level": 2}, {"title": "Discussion article for the meetup : Vancouver!", "anchor": "Discussion_article_for_the_meetup___Vancouver_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-14T22:31:05.307Z", "modifiedAt": null, "url": null, "title": "The Rosenhan Experiment", "slug": "the-rosenhan-experiment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.788Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chaosmosis", "createdAt": "2012-04-09T14:01:56.694Z", "isAdmin": false, "displayName": "chaosmosis"}, "userId": "vaZqG8uB8YrLtsePw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3jHjrPvKA5oYjWY8A/the-rosenhan-experiment", "pageUrlRelative": "/posts/3jHjrPvKA5oYjWY8A/the-rosenhan-experiment", "linkUrl": "https://www.lesswrong.com/posts/3jHjrPvKA5oYjWY8A/the-rosenhan-experiment", "postedAtFormatted": "Friday, September 14th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Rosenhan%20Experiment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Rosenhan%20Experiment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3jHjrPvKA5oYjWY8A%2Fthe-rosenhan-experiment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Rosenhan%20Experiment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3jHjrPvKA5oYjWY8A%2Fthe-rosenhan-experiment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3jHjrPvKA5oYjWY8A%2Fthe-rosenhan-experiment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 110, "htmlBody": "<p>I haven't seen any links to this on Lesswrong yet, and I just discovered it myself. It's extremely interesting, and has a lot of implications for how the way that people perceive and think of others are largely determined by their environmental context. It's also a fairly good indict of presumably common psychiatric practices, although it's also presumably outdated by now. Maybe some of you are already familiar with it, but I thought I'd mention it and post a link for those of you who aren't.<br /><br />There's probably newer research on this, but I don't have time to investigate it at the moment.<br /><br /><a href=\"http://en.wikipedia.org/wiki/Rosenhan_experiment\">http://en.wikipedia.org/wiki/Rosenhan_experiment</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3jHjrPvKA5oYjWY8A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 9.868192404165114e-07, "legacy": true, "legacyId": "18805", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T00:32:03.383Z", "modifiedAt": null, "url": null, "title": "Eliezer's Sequences and Mainstream Academia", "slug": "eliezer-s-sequences-and-mainstream-academia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:03.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ASpGaS3HGEQCbJbjS/eliezer-s-sequences-and-mainstream-academia", "pageUrlRelative": "/posts/ASpGaS3HGEQCbJbjS/eliezer-s-sequences-and-mainstream-academia", "linkUrl": "https://www.lesswrong.com/posts/ASpGaS3HGEQCbJbjS/eliezer-s-sequences-and-mainstream-academia", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eliezer's%20Sequences%20and%20Mainstream%20Academia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEliezer's%20Sequences%20and%20Mainstream%20Academia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASpGaS3HGEQCbJbjS%2Feliezer-s-sequences-and-mainstream-academia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eliezer's%20Sequences%20and%20Mainstream%20Academia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASpGaS3HGEQCbJbjS%2Feliezer-s-sequences-and-mainstream-academia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FASpGaS3HGEQCbJbjS%2Feliezer-s-sequences-and-mainstream-academia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1075, "htmlBody": "<p>Due in part to Eliezer's writing style (e.g. not many citations), and in part to Eliezer's scholarship preferences (e.g. his <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3rdb\">preference</a> to figure out much of philosophy on his own), Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">Sequences</a> don't accurately reflect the close agreement between the content of The Sequences and work previously done in mainstream academia.</p>\n<p>I predict several effects from this:</p>\n<ol>\n<li>Some readers will mistakenly think that common Less Wrong views are <a href=\"/lw/c2s/do_people_think_less_wrong_rationality_is/\">more parochial than they really are</a>.</li>\n<li>Some readers will mistakenly think Eliezer's Sequences are <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">more original than they really are</a>.</li>\n<li>If readers want to know more about the topic of a given article, it will be more difficult for them to find the related works in academia than if those works had been cited in Eliezer's article.</li>\n</ol>\n<p>I'd like to counteract these effects by connecting the Sequences to the professional literature. <small>(Note: I sort of doubt it would have been a good idea for <em>Eliezer</em> to spend his time tracking down more references and so on, but I realized a few weeks ago that it wouldn't take <em>me</em> much effort to list some of those references.)</small></p>\n<p>I don't mean to minimize the <a href=\"/lw/33j/yes_a_blog/\">awesomeness</a> of the Sequences. There is <em>much</em> original content in them (<em>edit</em>: probably <em>most</em> of their content is original), they are engagingly written, and they often have a more transformative effect on readers than the corresponding academic literature.</p>\n<p>I'll break my list of references into sections based on how likely I think it is that a reader will have <em>missed</em> the agreement between Eliezer's articles and mainstream academic work.</p>\n<p>(This is only a preliminary list of connections.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h3>Obviously connected to mainstream academic work</h3>\n<ul>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Evolution\">posts on evolution</a> mostly cover material you can find in any good evolutionary biology textbook, e.g. <a href=\"http://www.amazon.com/Evolutionary-Analysis-Scott-Freeman/dp/0132275848/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Freeman &amp; Herron (2007)</a>.</p>\n</li>\n<li>\n<p>Likewise, much of the <a href=\"http://wiki.lesswrong.com/wiki/The_Quantum_Physics_Sequence\">Quantum Physics sequence</a> can be found in quantum physics textbooks, e.g.&nbsp;<a href=\"http://www.amazon.com/Modern-Quantum-Mechanics-2nd-Edition/dp/0805382917/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Sakurai &amp; Napolitano (2010)</a>.</p>\n</li>\n<li>\n<p><a href=\"http://yudkowsky.net/rational/bayes\">An Intuitive Explanation of Bayes' Theorem</a>, <a href=\"/lw/jn/how_much_evidence_does_it_take/\">How Much Evidence Does it Take</a>, <a href=\"/lw/oj/probability_is_in_the_mind/\">Probability is in the Mind</a>, <a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence Is Evidence of Absence</a>, <a href=\"/lw/ii/conservation_of_expected_evidence/\">Conservation of Expected Evidence</a>, <a href=\"/lw/na/trust_in_bayes/\">Trust in Bayes</a>: see any textbook on Bayesian probability theory, e.g. <a href=\"http://www.amazon.com/Probability-Theory-The-Logic-Science/dp/0521592712/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Jaynes (2003)</a> or <a href=\"http://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Friedman &amp; Koller (2009)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/gp/whats_a_bias_again/\">What's a Bias, again?</a>, <a href=\"/lw/il/hindsight_bias/\">Hindsight Bias</a>, <a href=\"/lw/hz/correspondence_bias/\">Correspondence Bias</a>; <a href=\"/lw/iw/positive_bias_look_into_the_dark/\">Positive Bias: Look into the Dark</a>, <a href=\"/lw/je/doublethink_choosing_to_be_biased/\">Doublethink: Choosing to be Biased</a>, <a href=\"/lw/ju/rationalization/\">Rationalization</a>, <a href=\"/lw/km/motivated_stopping_and_motivated_continuation/\">Motivated Stopping and Motivated Continuation</a>, <a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think/\">We Change Our Minds Less Often Than We Think</a>, <a href=\"/lw/he/knowing_about_biases_can_hurt_people/\">Knowing About Biases Can Hurt People</a>, <a href=\"/lw/m9/aschs_conformity_experiment/\">Asch's Conformity Experiment</a>, <a href=\"/lw/lg/the_affect_heuristic/\">The Affect Heuristic</a>, <a href=\"/lw/lj/the_halo_effect/\">The Halo Effect</a>, <a href=\"/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment</a>, <a href=\"/lw/k3/priming_and_contamination/\">Priming and Contamination</a>, <a href=\"/lw/k4/do_we_believe_everything_were_told/\">Do We Believe Everything We're Told</a>, <a href=\"/lw/hw/scope_insensitivity/\">Scope Insensitivity</a>: see standard works in the heuristics &amp; biases tradition, e.g. <a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kahneman et al. (1982)</a>, <a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Gilovich et al. 2002</a>, <a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kahneman 2011</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q6d\">According to Eliezer</a>, <a href=\"http://yudkowsky.net/rational/the-simple-truth\">The Simple Truth</a> is <a href=\"http://en.wikipedia.org/wiki/Tarski#Truth_in_formalized_languages\">Tarskian</a> and <a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">Making Beliefs Pay Rent</a> is <a href=\"http://en.wikipedia.org/wiki/Charles_Sanders_Peirce#Pragmatism\">Peircian</a>.</p>\n</li>\n<li>\n<p>The notion of <a href=\"/lw/i4/belief_in_belief/\">Belief in Belief</a> comes from <a href=\"http://www.amazon.com/Breaking-Spell-Religion-Natural-Phenomenon/dp/0143038338/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Dennett (2007)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/is/fake_causality/\">Fake Causality</a> and <a href=\"/lw/qr/timeless_causality/\">Timeless Causality</a> report on work summarized in <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Pearl (2000)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/kx/fake_selfishness/\">Fake Selfishness</a> argues that humans aren't purely selfish, a point argued more forcefully in <a href=\"http://www.amazon.com/Altruism-Humans-C-Daniel-Batson/dp/0195341066/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Batson (2011)</a>.</p>\n</li>\n</ul>\n<h3><br /></h3>\n<h3>Less obviously connected to mainstream academic work</h3>\n<ul>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">metaethics sequences</a> includes dozens of lemmas previously discussed by philosophers (see <a href=\"http://www.amazon.com/Introduction-Contemporary-Metaethics-Alex-Miller/dp/074562345X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Miller 2003</a> for an overview), and the resulting metaethical theory shares much in common with the metaethical theories of <a href=\"http://www.amazon.com/dp/0198250614/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Jackson (1998)</a> and <a href=\"http://www.amazon.com/Facts-Values-Norms-Consequence-Philosophy/dp/0521426936/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Railton (2003)</a>, and must face some of the same critiques as those theories do (e.g. <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sobel-Full-Information-Accounts-of-Well-Being.pdf\">Sobel 1994</a>).</p>\n</li>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Free_will_%28solution%29\">free will mini-sequence</a> includes coverage of topics not usually mentioned when philosophers discuss free will (e.g. <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judea Pearl's work</a> on causality), but the conclusion is standard <a href=\"http://plato.stanford.edu/entries/compatibilism/\">compatibilism</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/no/how_an_algorithm_feels_from_inside/\">How an Algorithm Feels From Inside</a> and <a href=\"/lw/of/dissolving_the_question/\">Dissolving the Question</a> suggest that many philosophical problems can be dissolved into inquiries into the cognitive mechanisms that produce them, as also discussed in, for example, <a href=\"http://books.google.com/books?id=kOjtQwQ0XmkC&amp;lpg=PA59&amp;pg=GBS.PA59&amp;hl=en&amp;output=reader#v=onepage&amp;q&amp;f=false\">Shafir (1998)</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">Talbot (2009)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/l3/thou_art_godshatter/\">Thou Art Godshatter</a>, <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">Not for the Sake of Happiness Alone</a>, and <a href=\"/lw/lq/fake_utility_functions/\">Fake Utility Functions</a> make the point that value is complex, a topic explored in more detail in affective neuroscience (<a href=\"http://www.amazon.com/Pleasures-Brain-Series-Affective-Science/dp/0195331028/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kringelbach &amp; Berridge 2009</a>), neuroeconomics (<a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Glimcher 2010</a>; <a href=\"http://www.amazon.com/Neuroscience-Preference-Choice-Cognitive-Mechanisms/dp/0123814316/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Dolan &amp; Sharot 2011</a>), and other fields.</p>\n</li>\n<li>\n<p><a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem and the Regret of Rationality</a> repeats a common debate among philosophers. Thinking that CDT must be right even though it \"loses\" to EDT on Newcomb's Problem, one group says \"What can we do, if irrationality is rewarded?\" The other group says \"If you're so smart, why aren't you rich? What kind of rationality complains about the reward for irrationality?\" For example, see <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Lewis-Why-Aincha-Rich.pdf\">Lewis (1981)</a>.</p>\n</li>\n</ul>\n<h3><br /></h3>\n<h3>I don't think Eliezer had encountered this mainstream work when he wrote his articles</h3>\n<ul>\n<li>\n<p>Eliezer's TDT decision algorithm (<a href=\"/lw/15z/ingredients_of_timeless_decision_theory/\">2009</a>, <a href=\"http://intelligence.org/files/TDT.pdf\">2010</a>) had been previously discovered as a variant of CDT by Wolfgang Spohn (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Spohn-Dependency-equilibria-and-the-causal-structure-of-decision-and-game-situations.pdf\">2003</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Spohn-5-Questions-on-Formal-Philosophy.pdf\">2005</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/08/Spohn-Reversing-30-years-of-discussion-why-causal-decision-theorists-should-one-box.pdf\">2012</a>). Both TDT and Spohn-CDT (a) use Pearl's causal graphs to describe Newcomblike problems, then add nodes to those graphs to represent the deterministic decision process the agent goes through (Spohn calls them \"intention nodes,\" Yudkowsky calls them \"logical nodes\"), (b) represent interventions at these nodes by severing (<em>edit</em>: or screening off) the causal connections upstream, and (c) propose to maximize expected utility by summing over possible values of the decision node (or \"intention node\" / \"logical node\"). (Beyond this, of course, there are major differences in the motivations behind and further development of Spohn-CDT and TDT.)</p>\n</li>\n<li>\n<p>Many of Eliezer's points about intelligence explosion and machine ethics had been made in earlier writings Eliezer <em>did</em> cite, e.g. <a href=\"http://www.amazon.com/Folded-Searching-Collected-Stories-Williamson/dp/1893887375/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Williamson (1947)</a>, <a href=\"http://www.web-e.stat.vt.edu/dept/web-e/tech_reports/TechReport05-3.pdf\">Good (1965)</a>, and <a href=\"http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html\">Vinge (1993)</a>. Others of Eliezer's points appear in earlier writings he did not cite but probably had <em>read</em>: e.g. <a href=\"http://web.media.mit.edu/~minsky/papers/TrueNames.Afterword.html\">Minsky (1984)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Schmidhuber-Evolutionary-Principles-in-Self-Referential-Learning.pdf\">Schmidhuber (1987)</a>, <a href=\"http://www.nickbostrom.com/old/predict.html\">Bostrom (1997)</a>, <a href=\"http://www.amazon.com/Robot-Mere-Machine-Transcendent-Mind/dp/0195136306/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Moravec (1999)</a>. Others of Eliezer's points appear in earlier writings he probably <em>hadn't</em> read: e.g. <a href=\"http://www.amazon.com/Other-Worlds-Than-Cecil-Maxwell/dp/0800861256/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cade (1966)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Good-Some-future-social-repurcussions-of-computers.pdf\">Good (1970)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Versenyi-Can-Robots-Be-Moral.pdf\">Versenyi (1974)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Lukasiewicz-The-Ignorance-Explosion.pdf\">Lukasiewicz (1974)</a>, <a href=\"http://www.cs.umd.edu/~jkatz/TEACHING/comp_sec_F04/downloads/confinement.pdf\">Lampson (1979)</a>, Clarke (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Clarke-Asimovs-Laws-of-Robotics-implications-for-information-technology-part-1.pdf\">1993</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Clarke-Asimovs-Laws-of-Robotics-implications-for-information-technology-part-2.pdf\">1994</a>), <a href=\"http://www.unl.edu/philosophy/people/faculty/sobel/DotheDesires.pdf\">Sobel (1999)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2009/08/Allen-Prolegomena-to-any-future-artificial-moral-agent.pdf\">Allen et al. (2000)</a>. (For a brief history of these ideas, see <a href=\"/r/discussion/lw/b0v/ai_risk_and_opportunity_humanitys_efforts_so_far/\">here</a> and <a href=\"/r/discussion/lw/bd6/ai_risk_opportunity_a_timeline_of_early_ideas_and/\">here</a>.)</p>\n</li>\n<li>\n<p><a href=\"http://yudkowsky.net/rational/technical\">A Technical Explanation of Technical Explanation</a> retreads much ground from the field of Bayesian epistemology, surveyed for example in <a href=\"http://books.google.com/books?hl=en&amp;lr=&amp;id=vYyJoGKn_ccC&amp;oi=fnd&amp;pg=PA57&amp;ots=2CfItr7r4w&amp;sig=wJZ1pu46-bU0l6lcCa10FsRUCXc#v=onepage&amp;q&amp;f=false\">Niiniluoto (2004)</a>&nbsp;and <a href=\"http://www.amazon.com/Scientific-Reasoning-The-Bayesian-Approach/dp/081269578X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Howson &amp; Urbach (2005)</a>.</p>\n</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 3, "GLykb6NukBeBQtDvQ": 6, "JMD7LTXTisBzGAfhX": 6}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ASpGaS3HGEQCbJbjS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 152, "baseScore": 200, "extendedScore": null, "score": 0.000428, "legacy": true, "legacyId": "18812", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 200, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Due in part to Eliezer's writing style (e.g. not many citations), and in part to Eliezer's scholarship preferences (e.g. his <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3rdb\">preference</a> to figure out much of philosophy on his own), Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">Sequences</a> don't accurately reflect the close agreement between the content of The Sequences and work previously done in mainstream academia.</p>\n<p>I predict several effects from this:</p>\n<ol>\n<li>Some readers will mistakenly think that common Less Wrong views are <a href=\"/lw/c2s/do_people_think_less_wrong_rationality_is/\">more parochial than they really are</a>.</li>\n<li>Some readers will mistakenly think Eliezer's Sequences are <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">more original than they really are</a>.</li>\n<li>If readers want to know more about the topic of a given article, it will be more difficult for them to find the related works in academia than if those works had been cited in Eliezer's article.</li>\n</ol>\n<p>I'd like to counteract these effects by connecting the Sequences to the professional literature. <small>(Note: I sort of doubt it would have been a good idea for <em>Eliezer</em> to spend his time tracking down more references and so on, but I realized a few weeks ago that it wouldn't take <em>me</em> much effort to list some of those references.)</small></p>\n<p>I don't mean to minimize the <a href=\"/lw/33j/yes_a_blog/\">awesomeness</a> of the Sequences. There is <em>much</em> original content in them (<em>edit</em>: probably <em>most</em> of their content is original), they are engagingly written, and they often have a more transformative effect on readers than the corresponding academic literature.</p>\n<p>I'll break my list of references into sections based on how likely I think it is that a reader will have <em>missed</em> the agreement between Eliezer's articles and mainstream academic work.</p>\n<p>(This is only a preliminary list of connections.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h3 id=\"Obviously_connected_to_mainstream_academic_work\">Obviously connected to mainstream academic work</h3>\n<ul>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Evolution\">posts on evolution</a> mostly cover material you can find in any good evolutionary biology textbook, e.g. <a href=\"http://www.amazon.com/Evolutionary-Analysis-Scott-Freeman/dp/0132275848/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Freeman &amp; Herron (2007)</a>.</p>\n</li>\n<li>\n<p>Likewise, much of the <a href=\"http://wiki.lesswrong.com/wiki/The_Quantum_Physics_Sequence\">Quantum Physics sequence</a> can be found in quantum physics textbooks, e.g.&nbsp;<a href=\"http://www.amazon.com/Modern-Quantum-Mechanics-2nd-Edition/dp/0805382917/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Sakurai &amp; Napolitano (2010)</a>.</p>\n</li>\n<li>\n<p><a href=\"http://yudkowsky.net/rational/bayes\">An Intuitive Explanation of Bayes' Theorem</a>, <a href=\"/lw/jn/how_much_evidence_does_it_take/\">How Much Evidence Does it Take</a>, <a href=\"/lw/oj/probability_is_in_the_mind/\">Probability is in the Mind</a>, <a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence Is Evidence of Absence</a>, <a href=\"/lw/ii/conservation_of_expected_evidence/\">Conservation of Expected Evidence</a>, <a href=\"/lw/na/trust_in_bayes/\">Trust in Bayes</a>: see any textbook on Bayesian probability theory, e.g. <a href=\"http://www.amazon.com/Probability-Theory-The-Logic-Science/dp/0521592712/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Jaynes (2003)</a> or <a href=\"http://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Friedman &amp; Koller (2009)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/gp/whats_a_bias_again/\">What's a Bias, again?</a>, <a href=\"/lw/il/hindsight_bias/\">Hindsight Bias</a>, <a href=\"/lw/hz/correspondence_bias/\">Correspondence Bias</a>; <a href=\"/lw/iw/positive_bias_look_into_the_dark/\">Positive Bias: Look into the Dark</a>, <a href=\"/lw/je/doublethink_choosing_to_be_biased/\">Doublethink: Choosing to be Biased</a>, <a href=\"/lw/ju/rationalization/\">Rationalization</a>, <a href=\"/lw/km/motivated_stopping_and_motivated_continuation/\">Motivated Stopping and Motivated Continuation</a>, <a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think/\">We Change Our Minds Less Often Than We Think</a>, <a href=\"/lw/he/knowing_about_biases_can_hurt_people/\">Knowing About Biases Can Hurt People</a>, <a href=\"/lw/m9/aschs_conformity_experiment/\">Asch's Conformity Experiment</a>, <a href=\"/lw/lg/the_affect_heuristic/\">The Affect Heuristic</a>, <a href=\"/lw/lj/the_halo_effect/\">The Halo Effect</a>, <a href=\"/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment</a>, <a href=\"/lw/k3/priming_and_contamination/\">Priming and Contamination</a>, <a href=\"/lw/k4/do_we_believe_everything_were_told/\">Do We Believe Everything We're Told</a>, <a href=\"/lw/hw/scope_insensitivity/\">Scope Insensitivity</a>: see standard works in the heuristics &amp; biases tradition, e.g. <a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kahneman et al. (1982)</a>, <a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Gilovich et al. 2002</a>, <a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kahneman 2011</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q6d\">According to Eliezer</a>, <a href=\"http://yudkowsky.net/rational/the-simple-truth\">The Simple Truth</a> is <a href=\"http://en.wikipedia.org/wiki/Tarski#Truth_in_formalized_languages\">Tarskian</a> and <a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">Making Beliefs Pay Rent</a> is <a href=\"http://en.wikipedia.org/wiki/Charles_Sanders_Peirce#Pragmatism\">Peircian</a>.</p>\n</li>\n<li>\n<p>The notion of <a href=\"/lw/i4/belief_in_belief/\">Belief in Belief</a> comes from <a href=\"http://www.amazon.com/Breaking-Spell-Religion-Natural-Phenomenon/dp/0143038338/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Dennett (2007)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/is/fake_causality/\">Fake Causality</a> and <a href=\"/lw/qr/timeless_causality/\">Timeless Causality</a> report on work summarized in <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Pearl (2000)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/kx/fake_selfishness/\">Fake Selfishness</a> argues that humans aren't purely selfish, a point argued more forcefully in <a href=\"http://www.amazon.com/Altruism-Humans-C-Daniel-Batson/dp/0195341066/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Batson (2011)</a>.</p>\n</li>\n</ul>\n<h3><br></h3>\n<h3 id=\"Less_obviously_connected_to_mainstream_academic_work\">Less obviously connected to mainstream academic work</h3>\n<ul>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">metaethics sequences</a> includes dozens of lemmas previously discussed by philosophers (see <a href=\"http://www.amazon.com/Introduction-Contemporary-Metaethics-Alex-Miller/dp/074562345X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Miller 2003</a> for an overview), and the resulting metaethical theory shares much in common with the metaethical theories of <a href=\"http://www.amazon.com/dp/0198250614/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Jackson (1998)</a> and <a href=\"http://www.amazon.com/Facts-Values-Norms-Consequence-Philosophy/dp/0521426936/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Railton (2003)</a>, and must face some of the same critiques as those theories do (e.g. <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sobel-Full-Information-Accounts-of-Well-Being.pdf\">Sobel 1994</a>).</p>\n</li>\n<li>\n<p>Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Free_will_%28solution%29\">free will mini-sequence</a> includes coverage of topics not usually mentioned when philosophers discuss free will (e.g. <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judea Pearl's work</a> on causality), but the conclusion is standard <a href=\"http://plato.stanford.edu/entries/compatibilism/\">compatibilism</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/no/how_an_algorithm_feels_from_inside/\">How an Algorithm Feels From Inside</a> and <a href=\"/lw/of/dissolving_the_question/\">Dissolving the Question</a> suggest that many philosophical problems can be dissolved into inquiries into the cognitive mechanisms that produce them, as also discussed in, for example, <a href=\"http://books.google.com/books?id=kOjtQwQ0XmkC&amp;lpg=PA59&amp;pg=GBS.PA59&amp;hl=en&amp;output=reader#v=onepage&amp;q&amp;f=false\">Shafir (1998)</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">Talbot (2009)</a>.</p>\n</li>\n<li>\n<p><a href=\"/lw/l3/thou_art_godshatter/\">Thou Art Godshatter</a>, <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">Not for the Sake of Happiness Alone</a>, and <a href=\"/lw/lq/fake_utility_functions/\">Fake Utility Functions</a> make the point that value is complex, a topic explored in more detail in affective neuroscience (<a href=\"http://www.amazon.com/Pleasures-Brain-Series-Affective-Science/dp/0195331028/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Kringelbach &amp; Berridge 2009</a>), neuroeconomics (<a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Glimcher 2010</a>; <a href=\"http://www.amazon.com/Neuroscience-Preference-Choice-Cognitive-Mechanisms/dp/0123814316/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Dolan &amp; Sharot 2011</a>), and other fields.</p>\n</li>\n<li>\n<p><a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem and the Regret of Rationality</a> repeats a common debate among philosophers. Thinking that CDT must be right even though it \"loses\" to EDT on Newcomb's Problem, one group says \"What can we do, if irrationality is rewarded?\" The other group says \"If you're so smart, why aren't you rich? What kind of rationality complains about the reward for irrationality?\" For example, see <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Lewis-Why-Aincha-Rich.pdf\">Lewis (1981)</a>.</p>\n</li>\n</ul>\n<h3><br></h3>\n<h3 id=\"I_don_t_think_Eliezer_had_encountered_this_mainstream_work_when_he_wrote_his_articles\">I don't think Eliezer had encountered this mainstream work when he wrote his articles</h3>\n<ul>\n<li>\n<p>Eliezer's TDT decision algorithm (<a href=\"/lw/15z/ingredients_of_timeless_decision_theory/\">2009</a>, <a href=\"http://intelligence.org/files/TDT.pdf\">2010</a>) had been previously discovered as a variant of CDT by Wolfgang Spohn (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Spohn-Dependency-equilibria-and-the-causal-structure-of-decision-and-game-situations.pdf\">2003</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Spohn-5-Questions-on-Formal-Philosophy.pdf\">2005</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/08/Spohn-Reversing-30-years-of-discussion-why-causal-decision-theorists-should-one-box.pdf\">2012</a>). Both TDT and Spohn-CDT (a) use Pearl's causal graphs to describe Newcomblike problems, then add nodes to those graphs to represent the deterministic decision process the agent goes through (Spohn calls them \"intention nodes,\" Yudkowsky calls them \"logical nodes\"), (b) represent interventions at these nodes by severing (<em>edit</em>: or screening off) the causal connections upstream, and (c) propose to maximize expected utility by summing over possible values of the decision node (or \"intention node\" / \"logical node\"). (Beyond this, of course, there are major differences in the motivations behind and further development of Spohn-CDT and TDT.)</p>\n</li>\n<li>\n<p>Many of Eliezer's points about intelligence explosion and machine ethics had been made in earlier writings Eliezer <em>did</em> cite, e.g. <a href=\"http://www.amazon.com/Folded-Searching-Collected-Stories-Williamson/dp/1893887375/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Williamson (1947)</a>, <a href=\"http://www.web-e.stat.vt.edu/dept/web-e/tech_reports/TechReport05-3.pdf\">Good (1965)</a>, and <a href=\"http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html\">Vinge (1993)</a>. Others of Eliezer's points appear in earlier writings he did not cite but probably had <em>read</em>: e.g. <a href=\"http://web.media.mit.edu/~minsky/papers/TrueNames.Afterword.html\">Minsky (1984)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Schmidhuber-Evolutionary-Principles-in-Self-Referential-Learning.pdf\">Schmidhuber (1987)</a>, <a href=\"http://www.nickbostrom.com/old/predict.html\">Bostrom (1997)</a>, <a href=\"http://www.amazon.com/Robot-Mere-Machine-Transcendent-Mind/dp/0195136306/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Moravec (1999)</a>. Others of Eliezer's points appear in earlier writings he probably <em>hadn't</em> read: e.g. <a href=\"http://www.amazon.com/Other-Worlds-Than-Cecil-Maxwell/dp/0800861256/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cade (1966)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Good-Some-future-social-repurcussions-of-computers.pdf\">Good (1970)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Versenyi-Can-Robots-Be-Moral.pdf\">Versenyi (1974)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Lukasiewicz-The-Ignorance-Explosion.pdf\">Lukasiewicz (1974)</a>, <a href=\"http://www.cs.umd.edu/~jkatz/TEACHING/comp_sec_F04/downloads/confinement.pdf\">Lampson (1979)</a>, Clarke (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Clarke-Asimovs-Laws-of-Robotics-implications-for-information-technology-part-1.pdf\">1993</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/03/Clarke-Asimovs-Laws-of-Robotics-implications-for-information-technology-part-2.pdf\">1994</a>), <a href=\"http://www.unl.edu/philosophy/people/faculty/sobel/DotheDesires.pdf\">Sobel (1999)</a>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2009/08/Allen-Prolegomena-to-any-future-artificial-moral-agent.pdf\">Allen et al. (2000)</a>. (For a brief history of these ideas, see <a href=\"/r/discussion/lw/b0v/ai_risk_and_opportunity_humanitys_efforts_so_far/\">here</a> and <a href=\"/r/discussion/lw/bd6/ai_risk_opportunity_a_timeline_of_early_ideas_and/\">here</a>.)</p>\n</li>\n<li>\n<p><a href=\"http://yudkowsky.net/rational/technical\">A Technical Explanation of Technical Explanation</a> retreads much ground from the field of Bayesian epistemology, surveyed for example in <a href=\"http://books.google.com/books?hl=en&amp;lr=&amp;id=vYyJoGKn_ccC&amp;oi=fnd&amp;pg=PA57&amp;ots=2CfItr7r4w&amp;sig=wJZ1pu46-bU0l6lcCa10FsRUCXc#v=onepage&amp;q&amp;f=false\">Niiniluoto (2004)</a>&nbsp;and <a href=\"http://www.amazon.com/Scientific-Reasoning-The-Bayesian-Approach/dp/081269578X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Howson &amp; Urbach (2005)</a>.</p>\n</li>\n</ul>", "sections": [{"title": "Obviously connected to mainstream academic work", "anchor": "Obviously_connected_to_mainstream_academic_work", "level": 1}, {"title": "Less obviously connected to mainstream academic work", "anchor": "Less_obviously_connected_to_mainstream_academic_work", "level": 1}, {"title": "I don't think Eliezer had encountered this mainstream work when he wrote his articles", "anchor": "I_don_t_think_Eliezer_had_encountered_this_mainstream_work_when_he_wrote_his_articles", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "148 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 157, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wfD6EMTwm4iBCa8jE", "tSgcorrgBnrCH8nL3", "DXcezGmnBcAYL2Y2u", "nj8JKFoLSMEmD3RGp", "f6ZLxEWaankRZ2Crv", "mnS2WYLCGJP2kQkRn", "jiBFC7DcCrZjGmZnJ", "BL9DuE2iTCkrnuYzx", "jnZbHi873v9vcpGpZ", "fkM9XsNvXdYH6PPAx", "DB6wbyrMugYMK5o6a", "rmAbiEKQDpDnZzcRf", "Hs3ymqypvhgFMkgLb", "SFZoEBpLo9frSJGkc", "L32LHWzy9FzSDazEg", "buixYfcXBah9hbSNZ", "AdYdLP2sRqPMoe8fb", "WHK94zXkQm7qm7wXk", "Kow8xRzpfkoY7pa69", "ACGeaAk6KButv2xwQ", "bMkCEZoBNhgRBtzoj", "BaCWFCxBQYjJXSsah", "TiDGXt3WrQwtCdDj3", "2ftJ38y9SRBCBsCzy", "a7n8GdKiAZRX86T5A", "CqyJzDZWvGhhFJ7dY", "RgkqLqkg8vLhsYpfh", "KipiHsTA3pw4joQkG", "Masoq4NdmmGSiq2xw", "yA4gF5KrboK2m2Xu7", "Mc6QcrsbH5NRXbCRX", "cSXZpvqpa9vbGGLtG", "synsRtBKDeAFuo7e3", "NnohDYHNnKDtbiMyp", "6ddcsdA2c2XpNpE5x", "szfxvS8nsxTgJLBHs", "i4susk4W3ieR5K92u", "Qdq2SKyMi8vf7Snxq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 14, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T03:34:02.717Z", "modifiedAt": null, "url": null, "title": "Introducing Simplexity", "slug": "introducing-simplexity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:44.954Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uYtaNaS4KZWWQq5P6/introducing-simplexity", "pageUrlRelative": "/posts/uYtaNaS4KZWWQq5P6/introducing-simplexity", "linkUrl": "https://www.lesswrong.com/posts/uYtaNaS4KZWWQq5P6/introducing-simplexity", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introducing%20Simplexity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroducing%20Simplexity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYtaNaS4KZWWQq5P6%2Fintroducing-simplexity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introducing%20Simplexity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYtaNaS4KZWWQq5P6%2Fintroducing-simplexity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYtaNaS4KZWWQq5P6%2Fintroducing-simplexity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 904, "htmlBody": "<p style=\"padding-left: 30px;\">\"When Charona was trying to explain it to me, she asked me what the most important thing there was. [...]\"<br />\"Very good. Anyone who can give a nonrelative answer to that question is simplex.\"</p>\n<p style=\"padding-left: 30px;\">- <em>Empire Star</em>, Samuel R. Delany</p>\n<p>Here's a small riddle: What do the following three images have in common?</p>\n<p><img src=\"http://farm8.staticflickr.com/7260/7841568324_6607f69a51_q.jpg\" alt=\"WALL&bull;E\" width=\"150\" height=\"150\" /><img src=\"http://farm8.staticflickr.com/7124/7841568416_58402b187d_q.jpg\" alt=\"Electrons orbit nucleus\" width=\"150\" height=\"150\" /><img src=\"http://farm8.staticflickr.com/7248/7841568500_389b6b49c2_q.jpg\" alt=\"Monster and lady\" width=\"150\" height=\"150\" /></p>\n<p>The last picture, which ought be recognizable by readers of the sequences, serves as a clue; so does the quote at the top of the page. But these may be insufficient, so I'll just put into plain words what ideas these images represent, which by itself reveals part of the answer:</p>\n<p><img style=\"float: left; margin-left: 10px; margin-right: 10px;\" src=\"http://farm8.staticflickr.com/7260/7841568324_6607f69a51_s.jpg\" alt=\"WALL&bull;E\" width=\"50\" height=\"50\" /></p>\n<p>\"Human values <a href=\"http://wiki.lesswrong.com/wiki/Complexity_of_value\">are so natural</a> that one could very well achieve friendliness in artificial intelligence pretty much by accident, or at least by letting the machines educate themselves, reaching a human (or superior-to-human) respect for life by themselves.\"</p>\n<p><img style=\"margin-left: 10px; margin-right: 10px; float: left; margin-top: 5px; margin-bottom: 5px;\" src=\"http://farm8.staticflickr.com/7124/7841568416_58402b187d_s.jpg\" alt=\"Electrons orbit nucleus\" width=\"50\" height=\"50\" /></p>\n<p>\"The electrons of an atom can be visualized as <a href=\"/lw/pl/no_individual_particles\">little tiny billiard balls</a> that go around the nucleus in orbits much like planets go around the sun.\"</p>\n<p>&nbsp;</p>\n<p><img style=\"float: left; margin-left: 10px; margin-right: 10px;\" src=\"http://farm8.staticflickr.com/7248/7841568500_389b6b49c2_s.jpg\" alt=\"Monster and Lady\" width=\"50\" height=\"50\" /> \"Characteristics like attractiveness and beauty are <a href=\"/lw/oi/mind_projection_fallacy/\">inherent to the object possessing them</a>, so that even alien minds would have the good sense of recognizing the beauty of a woman according to criteria possessed by 20th century Hollywood advertisers.\"</p>\n<p>All three images, therefore, represent different types of fatally flawed thinking that have been directly addressed in past sequences. But this isn't quite precise, so let me reveal the remainder of the answer as well: These three fallacies can all be said to consist of a very similar pattern of narrow thinking, false fundamental assumptions, and privileged hypotheses.</p>\n<p>And this pattern seems so pervasive (in a large multitude of other fallacies as well) that it probably deserves a name of its own.</p>\n<p>In Samuel R. Delany's novella <em>Empire Star</em>, three terms (<em>simplex</em>, <em>complex</em>, and <em>multiplex</em>) are used throughout the novel to label different minds and different ways of thought. Although never explicitly defined, the reader understands their gist to be roughly as follows:</p>\n<ul>\n<li><em>simple</em>x: Able to look at things only from a single, limited perspective.</li>\n<li><em>complex: </em>Able to perceive and comprehend multiple ways of examining things and situations.</li>\n<li><em>multiplex: </em>Able to integrate these multiple perspectives into a new and fuller understanding of the whole.</li>\n</ul>\n<p>I will now appropriate the first of these terms to name the above mentioned pattern of biases. It might not be exactly how the author intended it (or then again it might be), but it's close enough for our purposes:</p>\n<p style=\"padding-left: 30px;\"><strong>Simplexity: </strong>The erroneous mapping of a territory that occurs due to the treatment of a complex element or a highly specific position or area in configuration space as simpler, more fundamental, or more widely applicable than it actually is.</p>\n<p>But because it's itself rather simplex to think that a single definition would best clarify the meaning for all readers, I'd like to offer a second definition as well.</p>\n<p style=\"padding-left: 30px;\"><strong>Simplexity: </strong>The assumption of too high a probability of correlation between the characteristics of familiar and unfamiliar elements of the same set.</p>\n<p>And here's a third one:</p>\n<p style=\"padding-left: 30px;\"><strong>Simplexity: </strong>Treating intuitive notions of simplicity as if referring to the same thing measured by Kolmogorov complexity or used in Solomonoff induction.</p>\n<p>These all effectively amount to the same bias, the same flawed way of thinking. Getting back to the images:</p>\n<p><img style=\"float: left; margin-left: 10px; margin-right: 10px;\" src=\"http://farm8.staticflickr.com/7260/7841568324_6607f69a51_s.jpg\" alt=\"WALL&bull;E\" width=\"50\" height=\"50\" /></p>\n<p>In the \"Wall-e\" picture (which could also have been a \"Johnny 5\" picture), we see a <strong>simplex view of morality and human values</strong>; where such complex systems are treated as simple enough to be stumbled upon even by artificial intelligences that were never deliberately designed to have them...</p>\n<p><img style=\"margin-left: 10px; margin-right: 10px; float: left; margin-top: 5px; margin-bottom: 5px;\" src=\"http://farm8.staticflickr.com/7124/7841568416_58402b187d_s.jpg\" alt=\"Electrons orbit nucleus\" width=\"50\" height=\"50\" /></p>\n<p>In the \"electron orbits\" picture, we see a <strong>simplex view of the subatomic world</strong>, based on the characteristics of macroscopic objects (like position and velocity) being treated as applicable to the whole of physical reality even at quantum scales.</p>\n<p><img style=\"float: left; margin-left: 10px; margin-right: 10px;\" src=\"http://farm8.staticflickr.com/7248/7841568500_389b6b49c2_s.jpg\" alt=\"Monster and lady\" width=\"50\" height=\"50\" /></p>\n<p>And lastly, in the \"monster and lady\" picture, we see a <strong>simplex view of attractiveness</strong>, based on the personal aesthetic criteria of the artists being treated as applicable to all advanced lifeforms, even ones that have different evolutionary histories.</p>\n<p>For those who dislike portmanteus, perhaps a term such as <em>\"fake-simplicity\"</em> (or even <em>\"naivety\"</em>) sounds better than <em>\"simplexity</em>\". But I think the latter is preferable in a number of ways -- for one thing, it helps remind that what starts out seemingly as simplicity (on the human level) may end up as extreme complexity if described mathematically.</p>\n<p>Among the differences between simplicity and simplexity is that simplicity can be either in the map or in the territory. Indeed, since as reductionists we believe the territory to be simple at the most fundamental level, a simple map would (all other things being equal) be a better one - <a href=\"http://yudkowsky.net/rational/virtues\">simplicity is a virtue</a>.</p>\n<p>But <em>simplexity </em>is always in the map: It's the mind patterning the unfamiliar based on the familiar. Highly useful in an evolutionary sense: humans evolved to be better capable of predicting the actions of other humans than of multiplying three-digit numbers... but ultimately wrong nonetheless whenever it occurs. And the further away from the ancestral environment one gets, the wronger it is likely to be.</p>\n<p>And it's the common basis in cognitive failures that range from <a href=\"/lw/e95/the_worst_argument_in_the_world/\">The Worst Argument In the World</a> all the way to the <a href=\"http://en.wikipedia.org/wiki/Just-world_hypothesis\">just-world fallacy</a> or even to <a href=\"/lw/qa/the_dilemma_science_or_bayes/\">privileging single world hypotheses</a>.</p>\n<p>But, lest we seem simplex about simplexity, applying a familiar pattern indiscriminately, this must now be followed by an examination of its different variations...</p>\n<p><strong>Next Post:&nbsp;</strong><em>Levels of mindspace simplexity</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uYtaNaS4KZWWQq5P6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 9, "extendedScore": null, "score": 9.869747129638496e-07, "legacy": true, "legacyId": "18411", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Cpf2jsZsNFNH5TSpc", "ZTRiSNmeGQK8AkdN2", "yCWPkLi8wJvewPbEp", "viPPjojmChxLGPE2v"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T04:07:35.623Z", "modifiedAt": null, "url": null, "title": "Video (11 min): fallacies in nutrition and cancer research.", "slug": "video-11-min-fallacies-in-nutrition-and-cancer-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.967Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RomeoStevens", "createdAt": "2011-10-28T20:59:30.426Z", "isAdmin": false, "displayName": "RomeoStevens"}, "userId": "5ZpAE3i54eEhMp2ib", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GzxrTMhyAnAwxZk5q/video-11-min-fallacies-in-nutrition-and-cancer-research", "pageUrlRelative": "/posts/GzxrTMhyAnAwxZk5q/video-11-min-fallacies-in-nutrition-and-cancer-research", "linkUrl": "https://www.lesswrong.com/posts/GzxrTMhyAnAwxZk5q/video-11-min-fallacies-in-nutrition-and-cancer-research", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Video%20(11%20min)%3A%20fallacies%20in%20nutrition%20and%20cancer%20research.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVideo%20(11%20min)%3A%20fallacies%20in%20nutrition%20and%20cancer%20research.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGzxrTMhyAnAwxZk5q%2Fvideo-11-min-fallacies-in-nutrition-and-cancer-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Video%20(11%20min)%3A%20fallacies%20in%20nutrition%20and%20cancer%20research.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGzxrTMhyAnAwxZk5q%2Fvideo-11-min-fallacies-in-nutrition-and-cancer-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGzxrTMhyAnAwxZk5q%2Fvideo-11-min-fallacies-in-nutrition-and-cancer-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 23, "htmlBody": "<p>Mentions include selection bias, lack of reproduction of results, naturalistic fallacy, status signalling, habituation, science as attire, and maybe some I didn't catch.</p>\n<p>http://www.youtube.com/watch?v=3g1denSoAbc&amp;feature=player_embedded</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"92SxJsDZ78ApAGq72": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GzxrTMhyAnAwxZk5q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.869919321358084e-07, "legacy": true, "legacyId": "18814", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T04:41:03.869Z", "modifiedAt": null, "url": null, "title": "Open Thread, September 15-30, 2012", "slug": "open-thread-september-15-30-2012", "viewCount": null, "lastCommentedAt": "2012-12-19T15:19:44.127Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iWL4mS9cC6GMYDpvo/open-thread-september-15-30-2012", "pageUrlRelative": "/posts/iWL4mS9cC6GMYDpvo/open-thread-september-15-30-2012", "linkUrl": "https://www.lesswrong.com/posts/iWL4mS9cC6GMYDpvo/open-thread-september-15-30-2012", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20September%2015-30%2C%202012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20September%2015-30%2C%202012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWL4mS9cC6GMYDpvo%2Fopen-thread-september-15-30-2012%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20September%2015-30%2C%202012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWL4mS9cC6GMYDpvo%2Fopen-thread-september-15-30-2012", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWL4mS9cC6GMYDpvo%2Fopen-thread-september-15-30-2012", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 16, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post, even in Discussion, it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iWL4mS9cC6GMYDpvo", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 9.87009111965423e-07, "legacy": true, "legacyId": "18815", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 204, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2012-09-15T04:41:03.869Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T06:05:44.870Z", "modifiedAt": null, "url": null, "title": "High School Lectures", "slug": "high-school-lectures", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.424Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Xece", "createdAt": "2011-09-03T19:16:00.923Z", "isAdmin": false, "displayName": "Xece"}, "userId": "q85BLJerfn3EGYQgA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dXgb3BoBNifDP4LEG/high-school-lectures", "pageUrlRelative": "/posts/dXgb3BoBNifDP4LEG/high-school-lectures", "linkUrl": "https://www.lesswrong.com/posts/dXgb3BoBNifDP4LEG/high-school-lectures", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20High%20School%20Lectures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHigh%20School%20Lectures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdXgb3BoBNifDP4LEG%2Fhigh-school-lectures%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=High%20School%20Lectures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdXgb3BoBNifDP4LEG%2Fhigh-school-lectures", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdXgb3BoBNifDP4LEG%2Fhigh-school-lectures", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 208, "htmlBody": "<p>Just recently at my high school, a group of classmates and I started a science club. A major component of this is listening and giving peer lectures on topics of physics, math, computer science, etc. I picked a topic a bit off to the side: philosophy and decision making. Naturally, this includes rationality. My plan is to start with something based off the sequences, specifically \"How to Actually Change Your Mind\" and \"A Human's Guide to Words\".</p>\n<p>I was hoping the Less Wrong community could give me some suggestions, tips, or even alternative ways to approach this. There is no end goal, we just want to learn more and think better. All our members are among the top 5% academically of their own grade. Most of us are seniors and have finished high school math, taking AP Calculus this year. We have covered basic statistics and Bayes' Theorem, but only applied it to the Disease Problem.</p>\n<p>Any help or ideas are appreciated.</p>\n<p>&nbsp;</p>\n<p>Update: Thank you for all these suggestions! They are incredibly helpful for me. I will attempt to make a recording of the lecture period if possible. I will make another discussion post sometime next weekend (the first lecture is next Friday) to report how it went.</p>\n<p>&nbsp;</p>\n<p>Update 2: Report <a href=\"/r/discussion/lw/emq/high_school_lecture_report/\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dXgb3BoBNifDP4LEG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 9.87052580406414e-07, "legacy": true, "legacyId": "18826", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["R7stnnwWZDqxmfqge"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T13:32:04.978Z", "modifiedAt": null, "url": null, "title": "[study] Ego depletion might disappear with age", "slug": "study-ego-depletion-might-disappear-with-age", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:57.246Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "cJPpT5b3RxNzjTchd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/icTrtuX8jqusCDM93/study-ego-depletion-might-disappear-with-age", "pageUrlRelative": "/posts/icTrtuX8jqusCDM93/study-ego-depletion-might-disappear-with-age", "linkUrl": "https://www.lesswrong.com/posts/icTrtuX8jqusCDM93/study-ego-depletion-might-disappear-with-age", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Bstudy%5D%20Ego%20depletion%20might%20disappear%20with%20age&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Bstudy%5D%20Ego%20depletion%20might%20disappear%20with%20age%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FicTrtuX8jqusCDM93%2Fstudy-ego-depletion-might-disappear-with-age%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Bstudy%5D%20Ego%20depletion%20might%20disappear%20with%20age%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FicTrtuX8jqusCDM93%2Fstudy-ego-depletion-might-disappear-with-age", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FicTrtuX8jqusCDM93%2Fstudy-ego-depletion-might-disappear-with-age", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<p><a href=\"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0026351\">Age Shall Not Weary Us: Deleterious Effects of Self-Regulation Depletion Are Specific to Younger Adults</a></p>\n<p>Brain areas associated with self-regulation don't mature until the mid-twenties. And apparently, if you compare older and younger people in a standard set-up for detecting ego-depletion, older people are not affected. WEIRD, indeed.</p>\n<p>In 2010, there was a <a href=\"http://www.stanford.edu/~gwalton/home/Publications_files/Job,%20Dweck,%20%26%20Walton,%202010.pdf\">study</a> indicating that ego depletion doesn't affect people who don't expect it to (and that one was run on college students). I wonder if part of the effect might be coming from differences in attitudes about effort between older and younger people.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "icTrtuX8jqusCDM93", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 9.872817433164178e-07, "legacy": true, "legacyId": "18829", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T17:20:12.893Z", "modifiedAt": null, "url": null, "title": "Using LW-style Multi-Worlds as source of technobabble", "slug": "using-lw-style-multi-worlds-as-source-of-technobabble", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:39.232Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mw9CwmoBtug3P38fA/using-lw-style-multi-worlds-as-source-of-technobabble", "pageUrlRelative": "/posts/Mw9CwmoBtug3P38fA/using-lw-style-multi-worlds-as-source-of-technobabble", "linkUrl": "https://www.lesswrong.com/posts/Mw9CwmoBtug3P38fA/using-lw-style-multi-worlds-as-source-of-technobabble", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20LW-style%20Multi-Worlds%20as%20source%20of%20technobabble&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20LW-style%20Multi-Worlds%20as%20source%20of%20technobabble%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMw9CwmoBtug3P38fA%2Fusing-lw-style-multi-worlds-as-source-of-technobabble%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20LW-style%20Multi-Worlds%20as%20source%20of%20technobabble%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMw9CwmoBtug3P38fA%2Fusing-lw-style-multi-worlds-as-source-of-technobabble", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMw9CwmoBtug3P38fA%2Fusing-lw-style-multi-worlds-as-source-of-technobabble", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 318, "htmlBody": "<p>In <a href=\"https://www.fimfiction.net/story/33512/93/Myou%27ve-Gotta-be-Kidding-Me/Helping-You-Helping-Me-Helping-You\">my latest chapter</a> of my ongoing My Little Pony crossover fanfic, \"<a href=\"https://www.fimfiction.net/story/33512/Myou've-Gotta-be-Kidding-Me\">Myou've Gotta be Kidding Me</a>\", my protagonist has had a thought. She has discovered that she lives in a universe containing cross-universe travel (which brought her from Earth to Equestria), time travel (which has at least some limits, but can be used for tactical purposes) and magic (of the mana/spell variety). Before arriving there, she read many of the Sequences, even if she hasn't fully absorbed all of their implications, and has been rather busy to think on them very much. I've tried combining all of that by having her posit that the local form of magic is actually a way of implementing outcome pumps, and that the mysterious 'mana' is closely tied to the self-consistency of any given blob of amplitude of quantum wave-functions. My readership seems to generally approve of the technobabble I used</p>\n<p>Since this is fiction, I could just as easily have had her posit angels pushing on every electron, and had that be so; but I'm trying to write rationalist fanfiction, and have her strength be in coming up with ideas my readers can use. I haven't made a concrete decision whether or not to have this set of technobabble be the truth for the setting; but I'm at least going to try to use it as the basis for her to try running some experiments to test it. And, in doing so, cover a bit of ground about such things as the difference between Bayesianism and the social organization of the Scientific Method - particularly given that she feels she is under very heavy time pressure to not just get accurate results, but get them quickly.</p>\n<p>Might anyone reading this have any suggestions for improvements to the technobabble I've used so far, particular experiments she could try, bits of the Sequences that are worth covering in the process, or anything similarly related?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mw9CwmoBtug3P38fA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 0, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "18830", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-15T18:48:16.242Z", "modifiedAt": null, "url": null, "title": "Scientists make monkeys smarter using brain implants [link]", "slug": "scientists-make-monkeys-smarter-using-brain-implants-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:46.946Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R8GaJcRWbZFAJzDJH/scientists-make-monkeys-smarter-using-brain-implants-link", "pageUrlRelative": "/posts/R8GaJcRWbZFAJzDJH/scientists-make-monkeys-smarter-using-brain-implants-link", "linkUrl": "https://www.lesswrong.com/posts/R8GaJcRWbZFAJzDJH/scientists-make-monkeys-smarter-using-brain-implants-link", "postedAtFormatted": "Saturday, September 15th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Scientists%20make%20monkeys%20smarter%20using%20brain%20implants%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScientists%20make%20monkeys%20smarter%20using%20brain%20implants%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8GaJcRWbZFAJzDJH%2Fscientists-make-monkeys-smarter-using-brain-implants-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Scientists%20make%20monkeys%20smarter%20using%20brain%20implants%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8GaJcRWbZFAJzDJH%2Fscientists-make-monkeys-smarter-using-brain-implants-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8GaJcRWbZFAJzDJH%2Fscientists-make-monkeys-smarter-using-brain-implants-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<p><a href=\"http://io9.com/5943379/for-the-first-time-ever-scientists-have-made-monkeys-smarter-using-brain-implants-could-you-be-next\">Article at io9.</a> The paper is available <a href=\"http://iopscience.iop.org/1741-2552/9/5/056012\">here</a>.</p>\n<p>The researchers showed monkeys specific images and then trained them to select those images out of a larger set after a time delay. They recorded the monkeys' brain function to determine which signals were important. The experiment tests the monkey's performance on this task in different cases, as described by io9:</p>\n<blockquote>\n<p>Once they were satisfied that the correct mapping had been done, they  administered cocaine to the monkeys to impair their performance on the  match-to-sample task (seems like a rather severe drug to administer, but  there you have it). Immediately, the monkeys' performance fell by a  factor of 20%.</p>\n<p>It was at this point that the researchers engaged  the neural device. Specifically, they deployed a \"multi-input  multi-output nonlinear\" (MIMO) model to stimulate the neurons that the  monkeys needed to complete the task. The inputs of this device monitored  such things as blood flow, temperature, and the electrical activity of  other neurons, while the outputs triggered the individual neurons  required for decision making. Taken together, the i/o model was able to  predict the output of the cortical neurons &mdash; and in turn deliver  electrical stimulation to the right neurons at the right time.</p>\n<p>And  incredibly, it worked. The researchers successfully restored the  monkeys' decision-making skills even though they were still dealing with  the effects of the cocaine. Moreover, when duplicating the experiment  under normal conditions, the monkeys' performance improved beyond the  75% proficiency level shown earlier. In other words, a kind of cognitive  enhancement had happened.</p>\n</blockquote>\n<p>This research is a remarkable followup to research that was done in rodents <a href=\"/lw/6eu/biomedical_engineers_analyzeand_duplicatethe/\">last year</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb28c": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R8GaJcRWbZFAJzDJH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 32, "extendedScore": null, "score": 9.874441413097064e-07, "legacy": true, "legacyId": "18831", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rGDkzQrnybSkwGifW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T04:57:27.354Z", "modifiedAt": null, "url": null, "title": "[LINK] Motivational Versus Metabolic Effects of Carbohydrates on Self-Control", "slug": "link-motivational-versus-metabolic-effects-of-carbohydrates", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:35.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gzRscwxmMrLPu2SLq/link-motivational-versus-metabolic-effects-of-carbohydrates", "pageUrlRelative": "/posts/gzRscwxmMrLPu2SLq/link-motivational-versus-metabolic-effects-of-carbohydrates", "linkUrl": "https://www.lesswrong.com/posts/gzRscwxmMrLPu2SLq/link-motivational-versus-metabolic-effects-of-carbohydrates", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Motivational%20Versus%20Metabolic%20Effects%20of%20Carbohydrates%20on%20Self-Control&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Motivational%20Versus%20Metabolic%20Effects%20of%20Carbohydrates%20on%20Self-Control%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzRscwxmMrLPu2SLq%2Flink-motivational-versus-metabolic-effects-of-carbohydrates%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Motivational%20Versus%20Metabolic%20Effects%20of%20Carbohydrates%20on%20Self-Control%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzRscwxmMrLPu2SLq%2Flink-motivational-versus-metabolic-effects-of-carbohydrates", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgzRscwxmMrLPu2SLq%2Flink-motivational-versus-metabolic-effects-of-carbohydrates", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<blockquote>Self-control is critical for achievement and well-being. However, people&rsquo;s capacity for self-control is limited and becomes depleted through use. One prominent explanation for this depletion posits that self-control consumes energy through carbohydrate metabolization, which further suggests that ingesting carbohydrates improves self-control. Some evidence has supported this <em>energy model</em>, but because of its broad implications for efforts to improve self-control, we reevaluated the role of carbohydrates in self-control processes. In four experiments, we found that (a) exerting self-control did not increase carbohydrate metabolization, as assessed with highly precise measurements of blood glucose levels under carefully standardized conditions; (b) rinsing one&rsquo;s mouth with, but not ingesting, carbohydrate solutions immediately bolstered self-control; and (c) carbohydrate rinsing did not increase blood glucose. These findings challenge metabolic explanations for the role of carbohydrates in self-control depletion; we therefore propose an alternative <em>motivational model</em> for these and other previously observed effects of carbohydrates on self-control.</blockquote>\n<p><a href=\"http://pss.sagepub.com/content/early/2012/09/12/0956797612439069.short\">Link.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gzRscwxmMrLPu2SLq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 9.87757159786728e-07, "legacy": true, "legacyId": "18835", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T05:47:37.835Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] My Bayesian Enlightenment", "slug": "seq-rerun-my-bayesian-enlightenment", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uipEDXaJTPBuosQ3a/seq-rerun-my-bayesian-enlightenment", "pageUrlRelative": "/posts/uipEDXaJTPBuosQ3a/seq-rerun-my-bayesian-enlightenment", "linkUrl": "https://www.lesswrong.com/posts/uipEDXaJTPBuosQ3a/seq-rerun-my-bayesian-enlightenment", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20My%20Bayesian%20Enlightenment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20My%20Bayesian%20Enlightenment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuipEDXaJTPBuosQ3a%2Fseq-rerun-my-bayesian-enlightenment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20My%20Bayesian%20Enlightenment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuipEDXaJTPBuosQ3a%2Fseq-rerun-my-bayesian-enlightenment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuipEDXaJTPBuosQ3a%2Fseq-rerun-my-bayesian-enlightenment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 153, "htmlBody": "<p>Today's post, <a href=\"/lw/ul/my_bayesian_enlightenment/\">My Bayesian Enlightenment</a> was originally published on 05 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#My_Bayesian_Enlightenment\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The story of how Eliezer Yudkowsky became a Bayesian.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/eia/seq_rerun_beyond_the_reach_of_god/\">Beyond the Reach of God</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uipEDXaJTPBuosQ3a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.877829489239949e-07, "legacy": true, "legacyId": "18836", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ti3Z7eZtud32LhGZT", "RFZnBQ7hwBJTc3XCt", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T15:44:43.116Z", "modifiedAt": null, "url": null, "title": "Problems with forensics, including bias affecting DNA testimony", "slug": "problems-with-forensics-including-bias-affecting-dna", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:38.978Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/seQ3AJJrEd2hM5Jb5/problems-with-forensics-including-bias-affecting-dna", "pageUrlRelative": "/posts/seQ3AJJrEd2hM5Jb5/problems-with-forensics-including-bias-affecting-dna", "linkUrl": "https://www.lesswrong.com/posts/seQ3AJJrEd2hM5Jb5/problems-with-forensics-including-bias-affecting-dna", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problems%20with%20forensics%2C%20including%20bias%20affecting%20DNA%20testimony&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblems%20with%20forensics%2C%20including%20bias%20affecting%20DNA%20testimony%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FseQ3AJJrEd2hM5Jb5%2Fproblems-with-forensics-including-bias-affecting-dna%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problems%20with%20forensics%2C%20including%20bias%20affecting%20DNA%20testimony%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FseQ3AJJrEd2hM5Jb5%2Fproblems-with-forensics-including-bias-affecting-dna", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FseQ3AJJrEd2hM5Jb5%2Fproblems-with-forensics-including-bias-affecting-dna", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<p><a href=\"http://cen.acs.org/articles/90/i37/Forensic-Science-Innocence-Project.html\">Forensic Science and the Innocence Project</a></p>\n<blockquote>What&rsquo;s more, some types of DNA technology have shortcomings, as Boise State University geneticist Greg Hampikian cautioned Philadelphia meeting attendees. Sample collection methods haven&rsquo;t changed since DNA&rsquo;s courtroom debut in the 1980s, even though assay sensitivity has increased dramatically, he said. His group has shown that detectable amounts of DNA can transfer between specimens if a handler forgets to change gloves. Hampikian, director of an Innocence Project affiliate in Idaho, also showed that if exposed to extraneous details about a case, experts can give very different interpretations when analyzing DNA mixtures, as can appear in cases of gang rape <a href=\"/Sci. Justice, DOI: 10.1016/j.scijus.2011.08.004\">Sci. Justice, DOI: 10.1016/j.scijus.2011.08.004</a>. Despite these caveats, DNA testing is the gold standard among forensic disciplines, because it has undergone thorough scientific vetting.</blockquote>\n<p>Unfortunately, Sci.Justice study is behind a pay wall.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "seQ3AJJrEd2hM5Jb5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 9.880899360873113e-07, "legacy": true, "legacyId": "18837", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T18:17:30.291Z", "modifiedAt": null, "url": null, "title": "Meta: What tool turns rich text into clean HTML?", "slug": "meta-what-tool-turns-rich-text-into-clean-html", "viewCount": null, "lastCommentedAt": "2017-06-17T04:36:28.592Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nnQ7HXkdkSX4z7XG6/meta-what-tool-turns-rich-text-into-clean-html", "pageUrlRelative": "/posts/nnQ7HXkdkSX4z7XG6/meta-what-tool-turns-rich-text-into-clean-html", "linkUrl": "https://www.lesswrong.com/posts/nnQ7HXkdkSX4z7XG6/meta-what-tool-turns-rich-text-into-clean-html", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20What%20tool%20turns%20rich%20text%20into%20clean%20HTML%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20What%20tool%20turns%20rich%20text%20into%20clean%20HTML%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnQ7HXkdkSX4z7XG6%2Fmeta-what-tool-turns-rich-text-into-clean-html%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20What%20tool%20turns%20rich%20text%20into%20clean%20HTML%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnQ7HXkdkSX4z7XG6%2Fmeta-what-tool-turns-rich-text-into-clean-html", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnQ7HXkdkSX4z7XG6%2Fmeta-what-tool-turns-rich-text-into-clean-html", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 222, "htmlBody": "<p>If you write an article in <a href=\"http://en.wikipedia.org/wiki/Microsoft_Word\">Word</a>, <a href=\"http://www.libreoffice.org/features/writer/\">Writer</a>, <a href=\"http://www.literatureandlatte.com/scrivener.php\">Scrivener</a>, <a href=\"https://docs.google.com/\">Google Docs</a>, or another rich text editor, and then copy+paste that rich text into an online WYSIWYG editor like the one on Less Wrong or WordPress, the HTML generated by LW or WordPress is <em>incredibly messy</em>&nbsp;and does tons of weird stuff to your text.</p>\n<p>Because of this, I've taken to composing all my posts in <a href=\"http://daringfireball.net/projects/markdown/\">Markdown</a>, which is plain text (like HTML) but easier to read, and can be <a href=\"http://daringfireball.net/projects/markdown/dingus\">easily converted</a> to clean HTML.</p>\n<p>Ideally, though, authors would be able to compose articles in whatever editor they want, and then paste their rich text into a<strong> simple web tool that strips all formatting from the HTML except the formatting they want to keep</strong>.</p>\n<p><a href=\"http://htmlpurifier.org/\">HTML Purifier</a>,&nbsp;<a href=\"http://www.w3.org/People/Raggett/tidy/\">TIDY</a>, and <a href=\"http://infohound.net/tidy/\">HTML Tidy</a> aren't quite what we need.&nbsp;<a href=\"http://word2cleanhtml.com/\">Word2CleanHTML</a>, <a href=\"http://textism.com/wordcleaner/\">Word HTML Cleaner</a> and&nbsp;<a href=\"http://wordoff.org/\">WordOff</a>, along with&nbsp;<a href=\"http://ckeditor.com/demo\">CKEditor</a>'s and&nbsp;<a href=\"http://www.tinymce.com/tryit/full.php\">TinyMCE</a>'s 'Paste from Word' features,&nbsp;<em>kinda</em>&nbsp;work, but not really: they still make mistakes pretty often when I try them.</p>\n<p>What I was hoping to find was something like <a href=\"http://word2cleanhtml.com/\">Word2CleanHTML</a> but with three changes:</p>\n<p>&nbsp;</p>\n<ol>\n<li>Does a good job when pasting from just about <em>any</em>&nbsp;rich text editor, not just Word.</li>\n<li>Allows the user to choose which formatting to keep, using a list of checkboxes for bold, italic, strikethrough, headings, text coloring, blockquotes, etc.</li>\n</ol>\n<div>Does this exist, and I couldn't find it?</div>\n<div>Or, is this relatively easy for a coder to create?</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nnQ7HXkdkSX4z7XG6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 11, "extendedScore": null, "score": 2.5e-05, "legacy": true, "legacyId": "18838", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T19:15:13.794Z", "modifiedAt": null, "url": null, "title": "The raw-experience dogma: Dissolving the \u201cqualia\u201d problem", "slug": "the-raw-experience-dogma-dissolving-the-qualia-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:08.754Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "metaphysicist", "createdAt": "2012-02-17T23:36:50.395Z", "isAdmin": false, "displayName": "metaphysicist"}, "userId": "WhJB5nfwSBQu7wjhz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wmQtgk5cPSD7zS8AZ/the-raw-experience-dogma-dissolving-the-qualia-problem", "pageUrlRelative": "/posts/wmQtgk5cPSD7zS8AZ/the-raw-experience-dogma-dissolving-the-qualia-problem", "linkUrl": "https://www.lesswrong.com/posts/wmQtgk5cPSD7zS8AZ/the-raw-experience-dogma-dissolving-the-qualia-problem", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20raw-experience%20dogma%3A%20Dissolving%20the%20%E2%80%9Cqualia%E2%80%9D%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20raw-experience%20dogma%3A%20Dissolving%20the%20%E2%80%9Cqualia%E2%80%9D%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwmQtgk5cPSD7zS8AZ%2Fthe-raw-experience-dogma-dissolving-the-qualia-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20raw-experience%20dogma%3A%20Dissolving%20the%20%E2%80%9Cqualia%E2%80%9D%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwmQtgk5cPSD7zS8AZ%2Fthe-raw-experience-dogma-dissolving-the-qualia-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwmQtgk5cPSD7zS8AZ%2Fthe-raw-experience-dogma-dissolving-the-qualia-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1382, "htmlBody": "<p><span style=\"color: #808000;\">[<a href=\"http://juridicalcoherence.blogspot.com/2012/09/161-raw-experience-dogma-dissolving.html\">Cross-posted.</a>]</span></p>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">1. Defining the problem: The inverted spectrum</span></strong></h3>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Philosophy has been called a preoccupation with the questions entertained by adolescents, and one adolescent favorite concerns our knowledge of other persons&rsquo; &ldquo;private experience&rdquo; (<em style=\"mso-bidi-font-style: normal;\">raw experience</em> or <em style=\"mso-bidi-font-style: normal;\">qualia</em>). A philosophers&rsquo; version is the &ldquo;inverted spectrum&rdquo;: <strong style=\"mso-bidi-font-weight: normal;\"><span style=\"color: red;\">how do I know you see &ldquo;red&rdquo; rather than &ldquo;blue&rdquo; when you see this red print?</span></strong> How could we tell when we each link the same terms to the same outward descriptions? We each will say &ldquo;red&rdquo; when we see the print, even if you really <em style=\"mso-bidi-font-style: normal;\">see</em> &ldquo;blue.&rdquo; </span></div>\n<div class=\"MsoNormal\"><br /></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">The intuition that allows us to be different this way is the intuition of <em style=\"mso-bidi-font-style: normal;\">raw experience</em> (or of <em style=\"mso-bidi-font-style: normal;\">qualia</em>). Philosophers of mind have devoted considerable attention to reconciling the intuition that raw experience exists with the intuition that inverted-spectrum indeterminacy has unacceptable dualist implications making the mental realm publicly unobservable, but </span><strong>it&rsquo;s time for nihilism about qualia, whose claim to exist rests solely on the strength of a prejudice.</strong></div>\n<div class=\"MsoNormal\"><br /></div>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A. Attempted solutions to the inverted spectrum.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One account would have us examine which parts of the brain are activated by each perception, but then we rely on an unverifiable correlation between brain structures and &ldquo;private experience.&rdquo; With only a single example of private experience&mdash;our own&mdash;we have no basis for knowing what makes private experience the same or different between persons. </span></div>\n<div class=\"MsoNormal\"><br /></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A subtler response to the inverted spectrum is that red and blue as experiences are distinct because red looks &ldquo;red&rdquo; due to its being constituted by certain responses, such as affect. Red makes you alert and tense; blue, tranquil or maybe sad. What we call the experience of red, on this account, just is the sense of alertness, and other manifestations. The hope is that identical observable responses to appropriate wavelengths might explain qualitative redness. Then, we could discover we experience blue when others experience red by finding that we idiosyncratically become tranquil instead of alert when exposed to the long wavelengths constituting physical red. This complication doesn&rsquo;t remove the radical uncertainty about experiential descriptions. </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Emotion only seems more capable than cognition of explaining raw experience because emotional events are memorable. The affect theory</span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> doesn't answer how an emotional reaction can <em style=\"mso-bidi-font-style: normal;\">constitute</em> a raw subjective experience. </span></div>\n<div class=\"MsoNormal\"><br /></div>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">B. The &ldquo;substitution bias&rdquo; of solving the &ldquo;easy problem of consciousness&rdquo; instead of the &ldquo;hard problem.&rdquo;</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">As in those examples, attempts at analyzing raw experience commonly appeal to the <a href=\"/lw/9l3/the_substitution_principle/\">substitution process</a> that psychologist Daniel Kahneman discovered in many cognitive fallacies. <em style=\"mso-bidi-font-style: normal;\">Substitution</em> is the unthoughtful replacement of an easy for a related hard question. In the philosophy of mind, the distinct questions are actually termed the &ldquo;easy problem of consciousness&rdquo; and the &ldquo;hard problem of consciousness,&rdquo; and errors regarding consciousness typically are due to substituting the &ldquo;easy problem&rdquo; for the &ldquo;hard,&rdquo; where the easy problem is to explain some function that typically <em style=\"mso-bidi-font-style: normal;\">accompanies</em> &ldquo;awareness.&rdquo; The philosopher might substitute knowledge of one&rsquo;s own brain processes for raw experience; or, as in the previous example, experience&rsquo;s neural accompaniments or its affective accompaniments. </span><strong>Avoiding the &ldquo;substitution bias&rdquo; is particularly hard when dealing with raw awareness, an unarticulated intuition; articulating it is a present purpose.</strong></div>\n<div class=\"MsoNormal\"><br /></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">2. The false intuition of direct awareness</span></strong></h3>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A. Our sense that the existence of raw experience is self-evident doesn&rsquo;t show that it is true.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">The theory that direct awareness reveals raw experience has long been almost sacrosanct in philosophy. According to the British Empiricists, direct experience consists of sense data and forms the indubitable basis of all synthetic knowledge. For Continental Rationalist Descartes, too, my direct experience&mdash;&ldquo;I think&rdquo;&mdash;indubitably proves my existence. </span></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">We do have a strong intuition that we have raw experience, the substance of direct awareness, but we have other strong intuitions, some turn out true and others false. We have an intuition that space is necessarily flat, an intuition proven false only with non-Euclidean geometries in the 19<sup>th</sup> century. We have an intuition that every event has a cause, which determinists believe but indeterminists deny. </span><strong>Sequestered intuitions aren&rsquo;t knowledge.</strong></div>\n<div class=\"MsoNormal\"><br /></div>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">B. Experience can&rsquo;t reveal the error in the intuition that raw experience exists.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">To correct wayward intuitions, we ordinarily test them against each other. A simple perceptual illusion illustrates: the popular <a href=\"http://en.wikipedia.org/wiki/M%C3%BCller-Lyer_illusion\">Muller-Lyer illusion</a>, where arrowheads on a line make it appear shorter than an identical line with the arrowheads reversed. Invoking the more credible intuition that measuring the lines finds their real length convinces us of the intuitive error that the lines are unequal. In contrast, </span><strong>we have no means to check the truth of the belief in raw experience; it simply seems self-evident, but it might seem equally self-evident if it were false.</strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></div>\n<div class=\"MsoNormal\"><br /></div>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">C. We can&rsquo;t capture the ineffable core of raw experience with language because there&rsquo;s really nothing there.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One task in philosophy is articulating the intuitions implicit in our thinking, and sometimes rejecting the intuition should result from concluding it employs concepts illogically. What shows the intuition of raw experience is incoherent (self-contradictory or vacuous) is that the terms we use to describe raw experience are limited to the terms for its referents; we have no terms to describe the experience as such, but rather, </span><strong>we describe qualia by applying terms denoting the ordinary cause of the supposed raw experience.</strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> The simplest explanation for the absence of a vocabulary to describe the qualitative properties of raw experience is that they don&rsquo;t exist: </span><strong>a process without properties is conceptually vacuous.</strong></div>\n<div class=\"MsoNormal\"><br /></div>\n<h4 class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">D. We believe raw experience exists without detecting it.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One error in thinking about the existence of raw experience comes from confusing perception with belief, which is conceptually distinct. When people universally report that qualia &ldquo;seem&rdquo; to exist, they are only reporting their beliefs&mdash;despite their sense of certainty. Where &ldquo;perception&rdquo; is defined as a nervous system&rsquo;s extraction of a sensory-array&rsquo;s features, people can&rsquo;t report their perceptions except <em style=\"mso-bidi-font-style: normal;\">through</em> beliefs the perceptions sometimes engender: I can&rsquo;t tell you my perceptions except by relating my beliefs about them. This conceptual truth is illustrated by the phenomenon of <em style=\"mso-bidi-font-style: normal;\">blindsight</em>, a condition in&nbsp; patients report complete blindness yet, </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">by discriminating external objects, </span>demonstrate that they can perceive them. Blindsighted patients </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">can report only according to their beliefs, and they </span>perceive <em style=\"mso-bidi-font-style: normal;\">more</em> than they believe and report that they perceive. </span><strong>Qualia nihilism analyzes the intuition of raw experience as perceiving less than you believe and report you perceive, the reverse of blindsight.</strong></div>\n<div class=\"MsoNormal\"><br /></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">3. The conceptual economy of qualia nihilism pays off in philosophical progress </span></strong></h3>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Eliminating raw experience from ontology produces conceptual economy. A summary of its conceptual advantages:</span></div>\n<div class=\"MsoNormal\"><br /></div>\n<div class=\"MsoListParagraphCxSpFirst\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;&nbsp; A. Qualia nihilism resolves an intractable problem for materialism:</span></span></strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> physical concepts are dispositional, whereas raw experiences concern properties that seem, instead, to pertain to noncausal essences. If raw experience was coherent, we could hope for a scientific insight, although no one has been able to define the general character of such an explanation. Removing a fundamental scientific mystery is a conceptual gain.</span></div>\n<div class=\"MsoListParagraphCxSpFirst\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp; </span></div>\n<div class=\"MsoListParagraphCxSpMiddle\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><strong style=\"mso-bidi-font-weight: normal;\"><em style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;&nbsp;&nbsp;</span></em><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> B. Qualia nihilism resolves the private-language problem.</span></span><em style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> </span></em></strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">There seems to be no possible language that uses nonpublic concepts. Eliminating raw experience allows explaining the absence of a private language by the nonexistence of any private referents.</span></div>\n<div class=\"MsoListParagraphCxSpMiddle\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><br /></div>\n<div class=\"MsoListParagraphCxSpLast\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;; mso-bidi-font-family: Verdana; mso-fareast-font-family: Verdana;\"><span style=\"mso-list: Ignore;\">&nbsp; &nbsp; <strong>C.</strong><em><strong>&nbsp;<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\"> </span></strong></em></span></span><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Qualia nihilism offers a compelling diagnosis of where important skeptical arguments regarding the possibility of knowledge go wrong</span></span></strong><em><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">.</span></span></strong></em><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> The arguments&mdash;George Berkeley&rsquo;s are their prototype&mdash;reason that sense data, being indubitable intuitions of direct experience, are the source of our knowledge, which must, in consequence, be <em style=\"mso-bidi-font-style: normal;\">about</em> raw experience rather than the &ldquo;external world.&rdquo; If you accept the existence of raw experience, the argument is notoriously difficult to undermine logically because concepts of &ldquo;raw experience&rdquo; truly can&rsquo;t be analogized to any concepts applying to the external world. Eliminating raw experience provides an effective demolition; rather than the other way around, our belief in raw experience depends on our knowledge of the external world, which is the source of the concepts we apply to fabricate qualia.</span></div>\n<div class=\"MsoListParagraphCxSpLast\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><br /></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">4. Relying on the brute force of an intuition is rationally specious.</span></strong></h3>\n<p><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Against these considerations, the only argument for retaining raw experience in our ontology is the sheer strength of everyone&rsquo;s belief in its existence. How much weight should we attach to a strong belief whose validity we can't check? None. </span><strong>Beliefs ordinarily earn a presumption of truth from the absence of empirical challenge, but when empirical challenge is impossible in principle, the belief deserves no confidence.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8e9e8fzXuW5gGBS3F": 2, "XSryTypw5Hszpa4TS": 2, "RMtdp6eGNjTZcmwJ6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wmQtgk5cPSD7zS8AZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": -4, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "18791", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><span style=\"color: #808000;\">[<a href=\"http://juridicalcoherence.blogspot.com/2012/09/161-raw-experience-dogma-dissolving.html\">Cross-posted.</a>]</span></p>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\" id=\"1__Defining_the_problem__The_inverted_spectrum\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">1. Defining the problem: The inverted spectrum</span></strong></h3>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Philosophy has been called a preoccupation with the questions entertained by adolescents, and one adolescent favorite concerns our knowledge of other persons\u2019 \u201cprivate experience\u201d (<em style=\"mso-bidi-font-style: normal;\">raw experience</em> or <em style=\"mso-bidi-font-style: normal;\">qualia</em>). A philosophers\u2019 version is the \u201cinverted spectrum\u201d: <strong style=\"mso-bidi-font-weight: normal;\"><span style=\"color: red;\">how do I know you see \u201cred\u201d rather than \u201cblue\u201d when you see this red print?</span></strong> How could we tell when we each link the same terms to the same outward descriptions? We each will say \u201cred\u201d when we see the print, even if you really <em style=\"mso-bidi-font-style: normal;\">see</em> \u201cblue.\u201d </span></div>\n<div class=\"MsoNormal\"><br></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">The intuition that allows us to be different this way is the intuition of <em style=\"mso-bidi-font-style: normal;\">raw experience</em> (or of <em style=\"mso-bidi-font-style: normal;\">qualia</em>). Philosophers of mind have devoted considerable attention to reconciling the intuition that raw experience exists with the intuition that inverted-spectrum indeterminacy has unacceptable dualist implications making the mental realm publicly unobservable, but </span><strong>it\u2019s time for nihilism about qualia, whose claim to exist rests solely on the strength of a prejudice.</strong></div>\n<div class=\"MsoNormal\"><br></div>\n<h4 class=\"MsoNormal\" id=\"A__Attempted_solutions_to_the_inverted_spectrum_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A. Attempted solutions to the inverted spectrum.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One account would have us examine which parts of the brain are activated by each perception, but then we rely on an unverifiable correlation between brain structures and \u201cprivate experience.\u201d With only a single example of private experience\u2014our own\u2014we have no basis for knowing what makes private experience the same or different between persons. </span></div>\n<div class=\"MsoNormal\"><br></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A subtler response to the inverted spectrum is that red and blue as experiences are distinct because red looks \u201cred\u201d due to its being constituted by certain responses, such as affect. Red makes you alert and tense; blue, tranquil or maybe sad. What we call the experience of red, on this account, just is the sense of alertness, and other manifestations. The hope is that identical observable responses to appropriate wavelengths might explain qualitative redness. Then, we could discover we experience blue when others experience red by finding that we idiosyncratically become tranquil instead of alert when exposed to the long wavelengths constituting physical red. This complication doesn\u2019t remove the radical uncertainty about experiential descriptions. </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Emotion only seems more capable than cognition of explaining raw experience because emotional events are memorable. The affect theory</span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> doesn't answer how an emotional reaction can <em style=\"mso-bidi-font-style: normal;\">constitute</em> a raw subjective experience. </span></div>\n<div class=\"MsoNormal\"><br></div>\n<h4 class=\"MsoNormal\" id=\"B__The__substitution_bias__of_solving_the__easy_problem_of_consciousness__instead_of_the__hard_problem__\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">B. The \u201csubstitution bias\u201d of solving the \u201ceasy problem of consciousness\u201d instead of the \u201chard problem.\u201d</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">As in those examples, attempts at analyzing raw experience commonly appeal to the <a href=\"/lw/9l3/the_substitution_principle/\">substitution process</a> that psychologist Daniel Kahneman discovered in many cognitive fallacies. <em style=\"mso-bidi-font-style: normal;\">Substitution</em> is the unthoughtful replacement of an easy for a related hard question. In the philosophy of mind, the distinct questions are actually termed the \u201ceasy problem of consciousness\u201d and the \u201chard problem of consciousness,\u201d and errors regarding consciousness typically are due to substituting the \u201ceasy problem\u201d for the \u201chard,\u201d where the easy problem is to explain some function that typically <em style=\"mso-bidi-font-style: normal;\">accompanies</em> \u201cawareness.\u201d The philosopher might substitute knowledge of one\u2019s own brain processes for raw experience; or, as in the previous example, experience\u2019s neural accompaniments or its affective accompaniments. </span><strong>Avoiding the \u201csubstitution bias\u201d is particularly hard when dealing with raw awareness, an unarticulated intuition; articulating it is a present purpose.</strong></div>\n<div class=\"MsoNormal\"><br></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\" id=\"2__The_false_intuition_of_direct_awareness\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">2. The false intuition of direct awareness</span></strong></h3>\n<h4 class=\"MsoNormal\" id=\"A__Our_sense_that_the_existence_of_raw_experience_is_self_evident_doesn_t_show_that_it_is_true_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">A. Our sense that the existence of raw experience is self-evident doesn\u2019t show that it is true.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">The theory that direct awareness reveals raw experience has long been almost sacrosanct in philosophy. According to the British Empiricists, direct experience consists of sense data and forms the indubitable basis of all synthetic knowledge. For Continental Rationalist Descartes, too, my direct experience\u2014\u201cI think\u201d\u2014indubitably proves my existence. </span></div>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">We do have a strong intuition that we have raw experience, the substance of direct awareness, but we have other strong intuitions, some turn out true and others false. We have an intuition that space is necessarily flat, an intuition proven false only with non-Euclidean geometries in the 19<sup>th</sup> century. We have an intuition that every event has a cause, which determinists believe but indeterminists deny. </span><strong>Sequestered intuitions aren\u2019t knowledge.</strong></div>\n<div class=\"MsoNormal\"><br></div>\n<h4 class=\"MsoNormal\" id=\"B__Experience_can_t_reveal_the_error_in_the_intuition_that_raw_experience_exists_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">B. Experience can\u2019t reveal the error in the intuition that raw experience exists.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">To correct wayward intuitions, we ordinarily test them against each other. A simple perceptual illusion illustrates: the popular <a href=\"http://en.wikipedia.org/wiki/M%C3%BCller-Lyer_illusion\">Muller-Lyer illusion</a>, where arrowheads on a line make it appear shorter than an identical line with the arrowheads reversed. Invoking the more credible intuition that measuring the lines finds their real length convinces us of the intuitive error that the lines are unequal. In contrast, </span><strong>we have no means to check the truth of the belief in raw experience; it simply seems self-evident, but it might seem equally self-evident if it were false.</strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></div>\n<div class=\"MsoNormal\"><br></div>\n<h4 class=\"MsoNormal\" id=\"C__We_can_t_capture_the_ineffable_core_of_raw_experience_with_language_because_there_s_really_nothing_there_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">C. We can\u2019t capture the ineffable core of raw experience with language because there\u2019s really nothing there.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One task in philosophy is articulating the intuitions implicit in our thinking, and sometimes rejecting the intuition should result from concluding it employs concepts illogically. What shows the intuition of raw experience is incoherent (self-contradictory or vacuous) is that the terms we use to describe raw experience are limited to the terms for its referents; we have no terms to describe the experience as such, but rather, </span><strong>we describe qualia by applying terms denoting the ordinary cause of the supposed raw experience.</strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> The simplest explanation for the absence of a vocabulary to describe the qualitative properties of raw experience is that they don\u2019t exist: </span><strong>a process without properties is conceptually vacuous.</strong></div>\n<div class=\"MsoNormal\"><br></div>\n<h4 class=\"MsoNormal\" id=\"D__We_believe_raw_experience_exists_without_detecting_it_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">D. We believe raw experience exists without detecting it.</span></span></strong></h4>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">One error in thinking about the existence of raw experience comes from confusing perception with belief, which is conceptually distinct. When people universally report that qualia \u201cseem\u201d to exist, they are only reporting their beliefs\u2014despite their sense of certainty. Where \u201cperception\u201d is defined as a nervous system\u2019s extraction of a sensory-array\u2019s features, people can\u2019t report their perceptions except <em style=\"mso-bidi-font-style: normal;\">through</em> beliefs the perceptions sometimes engender: I can\u2019t tell you my perceptions except by relating my beliefs about them. This conceptual truth is illustrated by the phenomenon of <em style=\"mso-bidi-font-style: normal;\">blindsight</em>, a condition in&nbsp; patients report complete blindness yet, </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">by discriminating external objects, </span>demonstrate that they can perceive them. Blindsighted patients </span><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">can report only according to their beliefs, and they </span>perceive <em style=\"mso-bidi-font-style: normal;\">more</em> than they believe and report that they perceive. </span><strong>Qualia nihilism analyzes the intuition of raw experience as perceiving less than you believe and report you perceive, the reverse of blindsight.</strong></div>\n<div class=\"MsoNormal\"><br></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\" id=\"3__The_conceptual_economy_of_qualia_nihilism_pays_off_in_philosophical_progress_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">3. The conceptual economy of qualia nihilism pays off in philosophical progress </span></strong></h3>\n<div class=\"MsoNormal\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Eliminating raw experience from ontology produces conceptual economy. A summary of its conceptual advantages:</span></div>\n<div class=\"MsoNormal\"><br></div>\n<div class=\"MsoListParagraphCxSpFirst\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;&nbsp; A. Qualia nihilism resolves an intractable problem for materialism:</span></span></strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> physical concepts are dispositional, whereas raw experiences concern properties that seem, instead, to pertain to noncausal essences. If raw experience was coherent, we could hope for a scientific insight, although no one has been able to define the general character of such an explanation. Removing a fundamental scientific mystery is a conceptual gain.</span></div>\n<div class=\"MsoListParagraphCxSpFirst\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp; </span></div>\n<div class=\"MsoListParagraphCxSpMiddle\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><strong style=\"mso-bidi-font-weight: normal;\"><em style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">&nbsp;&nbsp;&nbsp;</span></em><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> B. Qualia nihilism resolves the private-language problem.</span></span><em style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> </span></em></strong><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">There seems to be no possible language that uses nonpublic concepts. Eliminating raw experience allows explaining the absence of a private language by the nonexistence of any private referents.</span></div>\n<div class=\"MsoListParagraphCxSpMiddle\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><br></div>\n<div class=\"MsoListParagraphCxSpLast\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;; mso-bidi-font-family: Verdana; mso-fareast-font-family: Verdana;\"><span style=\"mso-list: Ignore;\">&nbsp; &nbsp; <strong>C.</strong><em><strong>&nbsp;<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\"> </span></strong></em></span></span><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Qualia nihilism offers a compelling diagnosis of where important skeptical arguments regarding the possibility of knowledge go wrong</span></span></strong><em><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"mso-bidi-font-style: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">.</span></span></strong></em><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\"> The arguments\u2014George Berkeley\u2019s are their prototype\u2014reason that sense data, being indubitable intuitions of direct experience, are the source of our knowledge, which must, in consequence, be <em style=\"mso-bidi-font-style: normal;\">about</em> raw experience rather than the \u201cexternal world.\u201d If you accept the existence of raw experience, the argument is notoriously difficult to undermine logically because concepts of \u201craw experience\u201d truly can\u2019t be analogized to any concepts applying to the external world. Eliminating raw experience provides an effective demolition; rather than the other way around, our belief in raw experience depends on our knowledge of the external world, which is the source of the concepts we apply to fabricate qualia.</span></div>\n<div class=\"MsoListParagraphCxSpLast\" style=\"mso-list: l0 level1 lfo1; text-indent: -.25in;\"><br></div>\n<h3 class=\"MsoNormal\" style=\"text-align: center;\" id=\"4__Relying_on_the_brute_force_of_an_intuition_is_rationally_specious_\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">4. Relying on the brute force of an intuition is rationally specious.</span></strong></h3>\n<p><span style=\"font-family: &quot;Verdana&quot;,&quot;sans-serif&quot;;\">Against these considerations, the only argument for retaining raw experience in our ontology is the sheer strength of everyone\u2019s belief in its existence. How much weight should we attach to a strong belief whose validity we can't check? None. </span><strong>Beliefs ordinarily earn a presumption of truth from the absence of empirical challenge, but when empirical challenge is impossible in principle, the belief deserves no confidence.</strong></p>", "sections": [{"title": "1. Defining the problem: The inverted spectrum", "anchor": "1__Defining_the_problem__The_inverted_spectrum", "level": 1}, {"title": "A. Attempted solutions to the inverted spectrum.", "anchor": "A__Attempted_solutions_to_the_inverted_spectrum_", "level": 2}, {"title": "B. The \u201csubstitution bias\u201d of solving the \u201ceasy problem of consciousness\u201d instead of the \u201chard problem.\u201d", "anchor": "B__The__substitution_bias__of_solving_the__easy_problem_of_consciousness__instead_of_the__hard_problem__", "level": 2}, {"title": "2. The false intuition of direct awareness", "anchor": "2__The_false_intuition_of_direct_awareness", "level": 1}, {"title": "A. Our sense that the existence of raw experience is self-evident doesn\u2019t show that it is true.", "anchor": "A__Our_sense_that_the_existence_of_raw_experience_is_self_evident_doesn_t_show_that_it_is_true_", "level": 2}, {"title": "B. Experience can\u2019t reveal the error in the intuition that raw experience exists.", "anchor": "B__Experience_can_t_reveal_the_error_in_the_intuition_that_raw_experience_exists_", "level": 2}, {"title": "C. We can\u2019t capture the ineffable core of raw experience with language because there\u2019s really nothing there.", "anchor": "C__We_can_t_capture_the_ineffable_core_of_raw_experience_with_language_because_there_s_really_nothing_there_", "level": 2}, {"title": "D. We believe raw experience exists without detecting it.", "anchor": "D__We_believe_raw_experience_exists_without_detecting_it_", "level": 2}, {"title": "3. The conceptual economy of qualia nihilism pays off in philosophical progress ", "anchor": "3__The_conceptual_economy_of_qualia_nihilism_pays_off_in_philosophical_progress_", "level": 1}, {"title": "4. Relying on the brute force of an intuition is rationally specious.", "anchor": "4__Relying_on_the_brute_force_of_an_intuition_is_rationally_specious_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "340 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 341, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LHtMNz7ua8zu4rSZr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-16T23:43:31.596Z", "modifiedAt": null, "url": null, "title": "Recommendations for good audio books?", "slug": "recommendations-for-good-audio-books", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:35.782Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsteinhardt", "createdAt": "2010-08-05T03:07:27.568Z", "isAdmin": false, "displayName": "jsteinhardt"}, "userId": "EF8W65G6RaXxZjLBX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q5xMFgm8vGBHhC9bQ/recommendations-for-good-audio-books", "pageUrlRelative": "/posts/Q5xMFgm8vGBHhC9bQ/recommendations-for-good-audio-books", "linkUrl": "https://www.lesswrong.com/posts/Q5xMFgm8vGBHhC9bQ/recommendations-for-good-audio-books", "postedAtFormatted": "Sunday, September 16th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recommendations%20for%20good%20audio%20books%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecommendations%20for%20good%20audio%20books%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5xMFgm8vGBHhC9bQ%2Frecommendations-for-good-audio-books%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recommendations%20for%20good%20audio%20books%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5xMFgm8vGBHhC9bQ%2Frecommendations-for-good-audio-books", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5xMFgm8vGBHhC9bQ%2Frecommendations-for-good-audio-books", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>Audio books have been discussed a bit before, but I never saw a list of recommendations. What books are good in an audio format (especially ones that can be listened to while driving)? I commute 45 minutes a day and would like to put that time to good use.</p>\n<p>ETA: I'm mostly interested in non-fiction (goal here is to learn useful stuff, as opposed to entertainment).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q5xMFgm8vGBHhC9bQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "18840", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-17T00:03:00.695Z", "modifiedAt": null, "url": null, "title": "Gauging interest for an Auckland meetup group.", "slug": "gauging-interest-for-an-auckland-meetup-group", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.160Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Slackson", "createdAt": "2011-09-01T11:35:14.364Z", "isAdmin": false, "displayName": "Slackson"}, "userId": "WrtmGGiKtRX434nnS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hDtBCdWgR7dCfDocW/gauging-interest-for-an-auckland-meetup-group", "pageUrlRelative": "/posts/hDtBCdWgR7dCfDocW/gauging-interest-for-an-auckland-meetup-group", "linkUrl": "https://www.lesswrong.com/posts/hDtBCdWgR7dCfDocW/gauging-interest-for-an-auckland-meetup-group", "postedAtFormatted": "Monday, September 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Gauging%20interest%20for%20an%20Auckland%20meetup%20group.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGauging%20interest%20for%20an%20Auckland%20meetup%20group.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDtBCdWgR7dCfDocW%2Fgauging-interest-for-an-auckland-meetup-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Gauging%20interest%20for%20an%20Auckland%20meetup%20group.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDtBCdWgR7dCfDocW%2Fgauging-interest-for-an-auckland-meetup-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDtBCdWgR7dCfDocW%2Fgauging-interest-for-an-auckland-meetup-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 42, "htmlBody": "<p>This isn't really the time of year for it, but I would like to gauge the interest in a meetup group for Auckland, New Zealand. If you'd like to attend, please reply, and then we can sort out a time and place.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hDtBCdWgR7dCfDocW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 9.88346257911628e-07, "legacy": true, "legacyId": "18841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-17T04:08:50.510Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] On Doing the Impossible", "slug": "seq-rerun-on-doing-the-impossible", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rirdvDzkrDiDQ8gTy/seq-rerun-on-doing-the-impossible", "pageUrlRelative": "/posts/rirdvDzkrDiDQ8gTy/seq-rerun-on-doing-the-impossible", "linkUrl": "https://www.lesswrong.com/posts/rirdvDzkrDiDQ8gTy/seq-rerun-on-doing-the-impossible", "postedAtFormatted": "Monday, September 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20On%20Doing%20the%20Impossible&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20On%20Doing%20the%20Impossible%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrirdvDzkrDiDQ8gTy%2Fseq-rerun-on-doing-the-impossible%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20On%20Doing%20the%20Impossible%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrirdvDzkrDiDQ8gTy%2Fseq-rerun-on-doing-the-impossible", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrirdvDzkrDiDQ8gTy%2Fseq-rerun-on-doing-the-impossible", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>Today's post, <a href=\"/lw/un/on_doing_the_impossible/\">On Doing the Impossible</a> was originally published on 06 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#On_Doing_the_Impossible\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A lot of projects seem impossible, meaning that we don't immediately see a way to do them. But after working on them for a long time, they start to look merely extremely difficult.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ej8/seq_rerun_my_bayesian_enlightenment/\">My Bayesian Enlightenment</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rirdvDzkrDiDQ8gTy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 9.88472756253927e-07, "legacy": true, "legacyId": "18846", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fpecAJLG9czABgCe9", "uipEDXaJTPBuosQ3a", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-17T13:42:22.966Z", "modifiedAt": null, "url": null, "title": "Meetup : Berlin Meetup", "slug": "meetup-berlin-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:57.618Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "blob", "createdAt": "2011-12-09T17:52:34.152Z", "isAdmin": false, "displayName": "blob"}, "userId": "3Yvqo9A3euExjqhsi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ztu4YbQXSGYF2zajN/meetup-berlin-meetup", "pageUrlRelative": "/posts/Ztu4YbQXSGYF2zajN/meetup-berlin-meetup", "linkUrl": "https://www.lesswrong.com/posts/Ztu4YbQXSGYF2zajN/meetup-berlin-meetup", "postedAtFormatted": "Monday, September 17th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berlin%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berlin%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZtu4YbQXSGYF2zajN%2Fmeetup-berlin-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berlin%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZtu4YbQXSGYF2zajN%2Fmeetup-berlin-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZtu4YbQXSGYF2zajN%2Fmeetup-berlin-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dv'>Berlin Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 September 2012 07:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Spreegold, Hufelandstra\u00dfe 20, 10407 Berlin</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Plans from last meetup:</p>\n\n<ul>\n<li>discuss <a href=\"http://lesswrong.com/lw/4su/how_to_be_happy/\" rel=\"nofollow\">http://lesswrong.com/lw/4su/how_to_be_happy/</a></li>\n<li>WingedViper wanted to look at and maybe prepare something from the LW meetup booklet (<a href=\"http://lesswrong.com/lw/crs/how_to_run_a_successful_less_wrong_meetup/\" rel=\"nofollow\">http://lesswrong.com/lw/crs/how_to_run_a_successful_less_wrong_meetup/</a>)</li>\n<li>another round of spuckblase's prediction game</li>\n</ul>\n\n<p>The scheduling poll indicated that there should be at least 3-5 people. I'll bring a sign to point us out to anyone dropping by spontaneously.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dv'>Berlin Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ztu4YbQXSGYF2zajN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 9.887679979281203e-07, "legacy": true, "legacyId": "18857", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berlin_Meetup\">Discussion article for the meetup : <a href=\"/meetups/dv\">Berlin Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 September 2012 07:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Spreegold, Hufelandstra\u00dfe 20, 10407 Berlin</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Plans from last meetup:</p>\n\n<ul>\n<li>discuss <a href=\"http://lesswrong.com/lw/4su/how_to_be_happy/\" rel=\"nofollow\">http://lesswrong.com/lw/4su/how_to_be_happy/</a></li>\n<li>WingedViper wanted to look at and maybe prepare something from the LW meetup booklet (<a href=\"http://lesswrong.com/lw/crs/how_to_run_a_successful_less_wrong_meetup/\" rel=\"nofollow\">http://lesswrong.com/lw/crs/how_to_run_a_successful_less_wrong_meetup/</a>)</li>\n<li>another round of spuckblase's prediction game</li>\n</ul>\n\n<p>The scheduling poll indicated that there should be at least 3-5 people. I'll bring a sign to point us out to anyone dropping by spontaneously.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berlin_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/dv\">Berlin Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berlin Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Berlin Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbgCx2ntD5eu8Cno9", "qMuAazqwJvkvo8teR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T00:50:26.952Z", "modifiedAt": null, "url": null, "title": "[LINK] 'Blue Brain' Project Accurately Predicts Connections Between Neurons", "slug": "link-blue-brain-project-accurately-predicts-connections", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.140Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "olalonde", "createdAt": "2012-04-11T13:14:14.883Z", "isAdmin": false, "displayName": "olalonde"}, "userId": "ZHntRMF8vLDsZ55yQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZZjauY8m7hcPKCJ4M/link-blue-brain-project-accurately-predicts-connections", "pageUrlRelative": "/posts/ZZjauY8m7hcPKCJ4M/link-blue-brain-project-accurately-predicts-connections", "linkUrl": "https://www.lesswrong.com/posts/ZZjauY8m7hcPKCJ4M/link-blue-brain-project-accurately-predicts-connections", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20'Blue%20Brain'%20Project%20Accurately%20Predicts%20Connections%20Between%20Neurons&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20'Blue%20Brain'%20Project%20Accurately%20Predicts%20Connections%20Between%20Neurons%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZjauY8m7hcPKCJ4M%2Flink-blue-brain-project-accurately-predicts-connections%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20'Blue%20Brain'%20Project%20Accurately%20Predicts%20Connections%20Between%20Neurons%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZjauY8m7hcPKCJ4M%2Flink-blue-brain-project-accurately-predicts-connections", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZjauY8m7hcPKCJ4M%2Flink-blue-brain-project-accurately-predicts-connections", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 768, "htmlBody": "<p>From&nbsp;<a href=\"http://www.sciencedaily.com/releases/2012/09/120917152043.htm\">http://www.sciencedaily.com/releases/2012/09/120917152043.htm</a></p>\n<p>Could this be a tiny step towards an AGI?</p>\n<blockquote>\n<h1>'Blue Brain' Project Accurately Predicts Connections Between Neurons</h1>\n<div>\n<p id=\"first\">One of the greatest challenges in neuroscience is to identify the map of synaptic connections between neurons. Called the \"connectome,\" it is the holy grail that will explain how information flows in the brain. In a landmark paper, published the week of 17th of September in the&nbsp;<em>Proceedings of the National Academy of Sciences</em>, the EPFL's Blue Brain Project (BBP) has identified key principles that determine synapse-scale connectivity by virtually reconstructing a cortical microcircuit and comparing it to a mammalian sample. These principles now make it possible to predict the locations of synapses in the neocortex.</p>\n<p>\"This is a major breakthrough, because it would otherwise take decades, if not centuries, to map the location of each synapse in the brain and it also makes it so much easier now to build accurate models,\" says Henry Markram, head of the BBP.</p>\n<p>A longstanding neuroscientific mystery has been whether all the neurons grow independently and just take what they get as their branches bump into each other, or are the branches of each neuron specifically guided by chemical signals to find all its target. To solve the mystery, researchers looked in a virtual reconstruction of a cortical microcircuit to see where the branches bumped into each other. To their great surprise, they found that the locations on the model matched that of synapses found in the equivalent real-brain circuit with an accuracy ranging from 75 percent to 95 percent.</p>\n<p>This means that neurons grow as independently of each other as physically possible and mostly form synapses at the locations where they randomly bump into each other. A few exceptions were also discovered pointing out special cases where signals are used by neurons to change the statistical connectivity. By taking these exceptions into account, the Blue Brain team can now make a near perfect prediction of the locations of all the synapses formed inside the circuit.</p>\n<p><strong>Virtual Reconstruction</strong></p>\n<p>The goal of the BBP is to integrate knowledge from all the specialized branches of neuroscience, to derive from it the fundamental principles that govern brain structure and function, and ultimately, to reconstruct the brains of different species -- including the human brain -- in silico. The current paper provides yet another proof-of-concept for the approach, by demonstrating for the first time that the distribution of synapses or neuronal connections in the mammalian cortex can, to a large extent, be predicted.</p>\n<p>To achieve these results, a team from the Blue Brain Project set about virtually reconstructing a cortical microcircuit based on unparalleled data about the geometrical and electrical properties of neurons -- data from over nearly 20 years of painstaking experimentation on slices of living brain tissue. Each neuron in the circuit was reconstructed into a 3D model on a powerful Blue Gene supercomputer. About 10,000 of virtual neurons were packed into a 3D space in random positions according to the density and ratio of morphological types found in corresponding living tissue. The researchers then compared the model back to an equivalent brain circuit from a real mammalian brain.</p>\n<p><strong>A Major Step Towards Accurate Models of the Brain</strong></p>\n<p>This discovery also explains why the brain can withstand damage and indicates that the positions of synapses in all brains of the same species are more similar than different. \"Positioning synapses in this way is very robust,\" says computational neuroscientist and first author Sean Hill, \"We could vary density, position, orientation, and none of that changed the distribution of positions of the synapses.\"</p>\n<p>They went on to discover that the synapses positions are only robust as long as the morphology of each neuron is slightly different from each other, explaining another mystery in the brain -- why neurons are not all identical in shape. \"It's the diversity in the morphology of neurons that makes brain circuits of a particular species basically the same and highly robust,\" says Hill.</p>\n</div>\n<p>Overall this work represents a major acceleration in the ability to construct detailed models of the nervous system. The results provide important insights into the basic principles that govern the wiring of the nervous system, throwing light on how robust cortical circuits are constructed from highly diverse populations of neurons -- an essential step towards understanding how the brain functions. They also underscore the value of the BBP's constructivist approach. \"Although systematically integrating data across a wide range of scales is slow and painstaking, it allows us to derive fundamental principles of brain structure and hence function,\" explains Hill.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZZjauY8m7hcPKCJ4M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 9.891120955473153e-07, "legacy": true, "legacyId": "18858", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>From&nbsp;<a href=\"http://www.sciencedaily.com/releases/2012/09/120917152043.htm\">http://www.sciencedaily.com/releases/2012/09/120917152043.htm</a></p>\n<p>Could this be a tiny step towards an AGI?</p>\n<blockquote>\n<h1 id=\"_Blue_Brain__Project_Accurately_Predicts_Connections_Between_Neurons\">'Blue Brain' Project Accurately Predicts Connections Between Neurons</h1>\n<div>\n<p id=\"first\">One of the greatest challenges in neuroscience is to identify the map of synaptic connections between neurons. Called the \"connectome,\" it is the holy grail that will explain how information flows in the brain. In a landmark paper, published the week of 17th of September in the&nbsp;<em>Proceedings of the National Academy of Sciences</em>, the EPFL's Blue Brain Project (BBP) has identified key principles that determine synapse-scale connectivity by virtually reconstructing a cortical microcircuit and comparing it to a mammalian sample. These principles now make it possible to predict the locations of synapses in the neocortex.</p>\n<p>\"This is a major breakthrough, because it would otherwise take decades, if not centuries, to map the location of each synapse in the brain and it also makes it so much easier now to build accurate models,\" says Henry Markram, head of the BBP.</p>\n<p>A longstanding neuroscientific mystery has been whether all the neurons grow independently and just take what they get as their branches bump into each other, or are the branches of each neuron specifically guided by chemical signals to find all its target. To solve the mystery, researchers looked in a virtual reconstruction of a cortical microcircuit to see where the branches bumped into each other. To their great surprise, they found that the locations on the model matched that of synapses found in the equivalent real-brain circuit with an accuracy ranging from 75 percent to 95 percent.</p>\n<p>This means that neurons grow as independently of each other as physically possible and mostly form synapses at the locations where they randomly bump into each other. A few exceptions were also discovered pointing out special cases where signals are used by neurons to change the statistical connectivity. By taking these exceptions into account, the Blue Brain team can now make a near perfect prediction of the locations of all the synapses formed inside the circuit.</p>\n<p><strong id=\"Virtual_Reconstruction\">Virtual Reconstruction</strong></p>\n<p>The goal of the BBP is to integrate knowledge from all the specialized branches of neuroscience, to derive from it the fundamental principles that govern brain structure and function, and ultimately, to reconstruct the brains of different species -- including the human brain -- in silico. The current paper provides yet another proof-of-concept for the approach, by demonstrating for the first time that the distribution of synapses or neuronal connections in the mammalian cortex can, to a large extent, be predicted.</p>\n<p>To achieve these results, a team from the Blue Brain Project set about virtually reconstructing a cortical microcircuit based on unparalleled data about the geometrical and electrical properties of neurons -- data from over nearly 20 years of painstaking experimentation on slices of living brain tissue. Each neuron in the circuit was reconstructed into a 3D model on a powerful Blue Gene supercomputer. About 10,000 of virtual neurons were packed into a 3D space in random positions according to the density and ratio of morphological types found in corresponding living tissue. The researchers then compared the model back to an equivalent brain circuit from a real mammalian brain.</p>\n<p><strong id=\"A_Major_Step_Towards_Accurate_Models_of_the_Brain\">A Major Step Towards Accurate Models of the Brain</strong></p>\n<p>This discovery also explains why the brain can withstand damage and indicates that the positions of synapses in all brains of the same species are more similar than different. \"Positioning synapses in this way is very robust,\" says computational neuroscientist and first author Sean Hill, \"We could vary density, position, orientation, and none of that changed the distribution of positions of the synapses.\"</p>\n<p>They went on to discover that the synapses positions are only robust as long as the morphology of each neuron is slightly different from each other, explaining another mystery in the brain -- why neurons are not all identical in shape. \"It's the diversity in the morphology of neurons that makes brain circuits of a particular species basically the same and highly robust,\" says Hill.</p>\n</div>\n<p>Overall this work represents a major acceleration in the ability to construct detailed models of the nervous system. The results provide important insights into the basic principles that govern the wiring of the nervous system, throwing light on how robust cortical circuits are constructed from highly diverse populations of neurons -- an essential step towards understanding how the brain functions. They also underscore the value of the BBP's constructivist approach. \"Although systematically integrating data across a wide range of scales is slow and painstaking, it allows us to derive fundamental principles of brain structure and hence function,\" explains Hill.</p>\n</blockquote>\n<p>&nbsp;</p>", "sections": [{"title": "'Blue Brain' Project Accurately Predicts Connections Between Neurons", "anchor": "_Blue_Brain__Project_Accurately_Predicts_Connections_Between_Neurons", "level": 1}, {"title": "Virtual Reconstruction", "anchor": "Virtual_Reconstruction", "level": 2}, {"title": "A Major Step Towards Accurate Models of the Brain", "anchor": "A_Major_Step_Towards_Accurate_Models_of_the_Brain", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T02:56:32.930Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Make an Extraordinary Effort", "slug": "seq-rerun-make-an-extraordinary-effort", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:03.267Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/exxjxyzrkzEHTcuuY/seq-rerun-make-an-extraordinary-effort", "pageUrlRelative": "/posts/exxjxyzrkzEHTcuuY/seq-rerun-make-an-extraordinary-effort", "linkUrl": "https://www.lesswrong.com/posts/exxjxyzrkzEHTcuuY/seq-rerun-make-an-extraordinary-effort", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Make%20an%20Extraordinary%20Effort&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Make%20an%20Extraordinary%20Effort%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexxjxyzrkzEHTcuuY%2Fseq-rerun-make-an-extraordinary-effort%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Make%20an%20Extraordinary%20Effort%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexxjxyzrkzEHTcuuY%2Fseq-rerun-make-an-extraordinary-effort", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexxjxyzrkzEHTcuuY%2Fseq-rerun-make-an-extraordinary-effort", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/uo/make_an_extraordinary_effort/\">Make an Extraordinary Effort</a> was originally published on 07 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Make_an_Extraordinary_Effort\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>It takes an extraordinary amount of rationality before you stop making stupid mistakes. Doing better requires making extraordinary efforts.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/eji/seq_rerun_on_doing_the_impossible/\">On Doing the Impossible</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "exxjxyzrkzEHTcuuY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 9.891770688055457e-07, "legacy": true, "legacyId": "18861", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["GuEsfTpSDSbXFiseH", "rirdvDzkrDiDQ8gTy", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T03:23:34.489Z", "modifiedAt": null, "url": null, "title": "The Bayesian Agent", "slug": "the-bayesian-agent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:09.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "royf", "createdAt": "2012-05-28T04:41:04.869Z", "isAdmin": false, "displayName": "royf"}, "userId": "Rrw92MqPSK6T8nSBg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/G4XKiJ2Q93JGCJxCT/the-bayesian-agent", "pageUrlRelative": "/posts/G4XKiJ2Q93JGCJxCT/the-bayesian-agent", "linkUrl": "https://www.lesswrong.com/posts/G4XKiJ2Q93JGCJxCT/the-bayesian-agent", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Bayesian%20Agent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Bayesian%20Agent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG4XKiJ2Q93JGCJxCT%2Fthe-bayesian-agent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Bayesian%20Agent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG4XKiJ2Q93JGCJxCT%2Fthe-bayesian-agent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG4XKiJ2Q93JGCJxCT%2Fthe-bayesian-agent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 843, "htmlBody": "<p><strong>Followup to:</strong>&nbsp;<a href=\"/lw/dux/reinforcement_learning_a_nonstandard_introduction/\">Reinforcement Learning: A Non-Standard Introduction</a>,&nbsp;<a href=\"/lw/dz4/reinforcement_preference_and_utility/\">Reinforcement, Preference and Utility</a></p>\n<p>A reinforcement-learning agent interacts with its environment through the perception of observations and the performance of actions.&nbsp;A very abstract and&nbsp;<a href=\"/lw/dux/reinforcement_learning_a_nonstandard_introduction/\">non-standard&nbsp;description</a> of such an agent is in two parts. The first part, the <em>inference policy</em>, tells us what states the agent can be in, and how these states change when the agent receives new input from its environment. The second part, the <em>action policy</em>, tells us what action the agent chooses to perform on the environment, in each of its internal states.</p>\n<p>There are two special choices for the inference policy, marking two extremes. One extreme is for the agent to remain absolutely oblivious to the information coming its way. The transition from a past internal state to a current one is made independent of the observation, and no entanglement is formed between the agent and the environment. A rock, for example, comes close to being this little alive.</p>\n<p>This post focuses on the other extreme, where the agent <a href=\"http://wiki.lesswrong.com/wiki/Belief_update\">updates perfectly</a> for the new information.</p>\n<p>Keeping track of all the information is easy, on paper. All the agent has to do is maintain the sequence of past observations, the <em>observable history</em>&nbsp;O<sub>1</sub>, O<sub>2</sub>, ..., O<sub>t</sub>. As each new observation is perceived, it can simply be appended to the list. Everything the agent can possibly know about the world, anything it can possibly hope to use in choosing actions, is in the observable history - there's no clairvoyance.</p>\n<p>But this is far from practical, for many related reasons. Extracting the useful information from the raw observations can be a demanding task. The number of observations to remember grows indefinitely with time, putting a strain on the resources of an agent attempting longevity. The number of possible agent states grows exponentially with time, making it difficult to even specify (let alone decide) what action to take in each one.</p>\n<p>Clearly we need some sort of compression when producing the agent's memory state from the observable history. Two requirements for the compression process: one, as per the premise of this post, is that it preserves all information about the world; the other is that it can be <a href=\"/lw/dux/reinforcement_learning_a_nonstandard_introduction/\">computed sequentially</a> - when computing M<sub>t</sub>&nbsp;the agent only has access to the new observation O<sub>t</sub>&nbsp;and the previous compression M<sub>t-1</sub>. The explicit value of all previous observations is forever lost.</p>\n<p>This is a good moment to introduce proper terminology. A function of the observable history is called a <em>statistic</em>. Intuitively, applying a function to the data can only decrease, never increase the <a href=\"/lw/o2/mutual_information_and_density_in_thingspace/\">amount of information</a> we end up having about the world. This intuition is solid, as the <a href=\"http://www.scholarpedia.org/article/Mutual_information#Properties\">Data Processing Inequality</a> proves. If the function does not lose any information about the world, if looking at the agent's memory is enough and there's nothing more relevant in the observations themselves, then the memory state is a <em>sufficient statistic</em>&nbsp;of the observable history, for the world state. The things the agent does forget about past perceptions are not at all informative for the present. Ultimately, when nothing further can be forgotten this way, we are left with a <em>minimal sufficient statistic</em>.</p>\n<p>If I tell you the observable history of the agent, what will you know about the world state? If you know the dynamics of the world and how observations are generated, you'll have the <em><a href=\"http://yudkowsky.net/rational/bayes\">Bayesian belief</a></em>, assigning to each world state the posterior distribution:</p>\n<p style=\"padding-left: 30px; \">B<sub>t</sub>(W<sub>t</sub>)&nbsp;= Pr(W<sub>t</sub>|O<sub>1</sub>,...,O<sub>t</sub>)</p>\n<p>(where Pr stands for \"probability\"). Importantly, this can be computed sequentially from B<sub>t-1</sub>&nbsp;and O<sub>t</sub>, using <a href=\"http://wiki.lesswrong.com/wiki/Bayes'_theorem\">Bayes' theorem</a>. (The gory details of how to do this are <a href=\"/lw/e6a/the_bayesian_agent/7gej\">below in a comment</a>.)</p>\n<p>Aha! So the Bayesian belief is an expression for <em>precisely everything</em>&nbsp;the agent can possibly know about the world. Why not have the agent's memory represent exactly that?</p>\n<p style=\"padding-left: 30px;\">M<sub>t</sub>&nbsp;= B<sub>t</sub></p>\n<p>As it turns out, the Bayesian belief is indeed a minimal sufficient statistic of the observable history for the world state. For the agent, it is the truth, the whole truth, and nothing but the truth - and a methodical way to remember the truth, to boot.</p>\n<p>Thus we've compressed into the agent's memory all and only the information from its past that is relevant for the present. We've discarded any information that is an artifact of the senses, and is not real. We've discarded any information that <em>used to be</em>&nbsp;real, but isn't anymore, because the world has since changed.</p>\n<p>The observant reader will notice that we haven't discussed actions yet. We're getting there. The question of what information is relevant <em>for future actions</em> is deep enough to justify this meticulous exposition. For the moment, just note that keeping a sufficient statistic for the current world state is also sufficient for the <em>controllable future</em>, since <a href=\"/lw/dsq/reinforcement_learning_a_nonstandard_introduction/\">the future is independent of the past given the present</a>.</p>\n<p>What we have established here is an \"ultimate solution\" for how a reinforcement-learning agent should maintain its memory state. It should update a Bayesian belief of what the current world state is.&nbsp;This inference policy is so powerful and natural, that <a href=\"http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html\">standard reinforcement learning</a> doesn't even make a distinction between the Bayesian belief and the agent's memory state, ignoring anything else we could imagine the latter to be.</p>\n<p><strong>Continue reading:</strong>&nbsp;<a href=\"/lw/eu1/pointbased_value_iteration/\">Point-Based Value Iteration</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "G4XKiJ2Q93JGCJxCT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 9.89190994934348e-07, "legacy": true, "legacyId": "18370", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xdjA6YtE7QBsLYQ3i", "bPeB6RT78k8dXKYKf", "yLcuygFfMfrfK8KjF", "HPAjhrbYk6rPbpSXx", "JyPb4Wpty86tj7Xgn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T05:07:57.726Z", "modifiedAt": null, "url": null, "title": "[LINK] \"Junk\" DNA revealed as information processing system?", "slug": "link-junk-dna-revealed-as-information-processing-system", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.956Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EphemeralNight", "createdAt": "2011-09-07T19:48:02.531Z", "isAdmin": false, "displayName": "EphemeralNight"}, "userId": "uWtJm9TRd8jFyRmwb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DNiycNDfe9QeaEGep/link-junk-dna-revealed-as-information-processing-system", "pageUrlRelative": "/posts/DNiycNDfe9QeaEGep/link-junk-dna-revealed-as-information-processing-system", "linkUrl": "https://www.lesswrong.com/posts/DNiycNDfe9QeaEGep/link-junk-dna-revealed-as-information-processing-system", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20%22Junk%22%20DNA%20revealed%20as%20information%20processing%20system%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20%22Junk%22%20DNA%20revealed%20as%20information%20processing%20system%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNiycNDfe9QeaEGep%2Flink-junk-dna-revealed-as-information-processing-system%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20%22Junk%22%20DNA%20revealed%20as%20information%20processing%20system%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNiycNDfe9QeaEGep%2Flink-junk-dna-revealed-as-information-processing-system", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDNiycNDfe9QeaEGep%2Flink-junk-dna-revealed-as-information-processing-system", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p><a href=\"http://spectrum.ieee.org/tech-talk/at-work/test-and-measurement/re-imagining-our-genes-encode-project-reveals-genome-as-an-information-processing-system/?utm_source=techalert&amp;utm_medium=email&amp;utm_camp\">http://spectrum.ieee.org/tech-talk/at-work/test-and-measurement/re-imagining-our-genes-encode-project-reveals-genome-as-an-information-processing-system/?utm_source=techalert&amp;utm_medium=email&amp;utm_camp</a></p>\n<p>\n<blockquote>\n<p style=\"font-size: 12px; padding: 0px 10px 10px 0px; margin: 0px; line-height: 18px; font-family: Arial, Helvetica, sans-serif;\">Just a few years ago, the prevailing wisdom said that the genome comprises 3 percent or so genes and 97 percent &ldquo;junk&rdquo; (with 2 or 3 percent of that junk consisting of the fossilized remains of retroviruses that infected our ancestors somewhere along the line). After a decade of painstaking analysis by more than 200 scientists, the new ENCODE data show that indeed 2.94 percent of&nbsp;the genome is&nbsp;protein-coding genes, while 80.4 percent of sequences regulate how those genes get turned on, turned off, expressed, processed, and modified.</p>\n<p style=\"font-size: 12px; padding: 0px 10px 10px 0px; margin: 0px; line-height: 18px; font-family: Arial, Helvetica, sans-serif;\">This fundamentally changes how most biologists understand the master instruction set of life: we are, in short, 3 percent &nbsp;input/output and 80 percent logic. (Though perhaps a surprise to biologists, the finding will hardly astound anyone who has designed a complex interactive system.)</p>\n</blockquote>\n</p>\n<p style=\"font-size: 12px; padding: 0px 10px 10px 0px; margin: 0px; line-height: 18px; font-family: Arial, Helvetica, sans-serif;\">Correct me if I'm wrong, but this is a really big deal, right?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DNiycNDfe9QeaEGep", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 7, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "18867", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T07:39:24.554Z", "modifiedAt": null, "url": null, "title": "Which questions about online classes would you ask Peter Norvig? ", "slug": "which-questions-about-online-classes-would-you-ask-peter", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.101Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M7Tb525x8wuEji3NE/which-questions-about-online-classes-would-you-ask-peter", "pageUrlRelative": "/posts/M7Tb525x8wuEji3NE/which-questions-about-online-classes-would-you-ask-peter", "linkUrl": "https://www.lesswrong.com/posts/M7Tb525x8wuEji3NE/which-questions-about-online-classes-would-you-ask-peter", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Which%20questions%20about%20online%20classes%20would%20you%20ask%20Peter%20Norvig%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhich%20questions%20about%20online%20classes%20would%20you%20ask%20Peter%20Norvig%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7Tb525x8wuEji3NE%2Fwhich-questions-about-online-classes-would-you-ask-peter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Which%20questions%20about%20online%20classes%20would%20you%20ask%20Peter%20Norvig%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7Tb525x8wuEji3NE%2Fwhich-questions-about-online-classes-would-you-ask-peter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7Tb525x8wuEji3NE%2Fwhich-questions-about-online-classes-would-you-ask-peter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 593, "htmlBody": "<p>A week ago Google launched an open source project called <a href=\"https://code.google.com/p/course-builder/\">Course Builder</a> it packages the software and technology used to build their July <a href=\"/lw/dej/learn_power_searching_with_google/\">Class Power Searching with Google</a>. The discussion forum for it is <a href=\"https://groups.google.com/forum/?fromgroups#!forum/course-builder-forum\">here</a>. <strong>Tomorrow is the first live hangout where he will be answering questions about MOOC design and technical aspects of using Course Builder.</strong> The live hangout will is scheduled for the 26th of September.</p>\n<blockquote>\n<h3 class=\"title entry-title\"><a rel=\"bookmark\" href=\"http://googleresearch.blogspot.com/2012/09/helping-world-to-teach.html\">Helping the World to Teach</a></h3>\n<p><span class=\"byline-author\">Posted by Peter Norvig, Director of Research</span> <br /> <br /> In July, <a href=\"http://research.google.com/\">Research at Google</a> ran a large open online course, <a href=\"http://www.powersearchingwithgoogle.com/\"><em>Power Searching with Google</em></a>, taught by search expert, Dan Russell. The course was <a href=\"http://googleresearch.blogspot.com/2012/08/teaching-world-to-search.html\">successful</a>, with 155,000 registered students. Through this experiment, we learned that Google technologies can help bring education to a global audience. So we packaged up the technology we used to build Power Searching and are providing it as an open source project called <a href=\"https://code.google.com/p/course-builder/\">Course Builder</a>. We want to make this technology available so that others can experiment with online learning. <br /> <br /> The Course Builder open source project is an experimental early step for us in the world of online education. It is a snapshot of an approach we found useful and an indication of our future direction. We hope to continue development along these lines, but we wanted to make this limited code base available now, to see what early adopters will do with it, and to explore the future of learning technology. We will be hosting a community building event in the upcoming months to help more people get started using this software. <a href=\"https://www.edx.org/\">edX</a> shares in the open source vision for online learning platforms, and Google and the <a href=\"https://www.edx.org/\">edX</a> team are in discussions about open standards and technology sharing for course platforms. <br /> <br /> We are excited that <a href=\"http://stanford.edu/\">Stanford University</a>, <a href=\"http://indiana.edu/\">Indiana University</a>, <a href=\"http://www.ucsd.edu/\">UC San Diego</a>, <a href=\"http://saylor.org/\">Saylor.org</a>, <a href=\"http://learningbygivingfoundation.org/\">LearningByGivingFoundation.org</a>, <a href=\"http://www.epfl.ch/\">Swiss Federal Institute of Technology in Lausanne (EPFL)</a>, and a group of universities in Spain led by <a href=\"http://www.universia.net/\">Universia</a>, <a href=\"http://www.crue.org/\">CRUE</a>, and <a href=\"http://www.santander.com/csgs/Satellite?appID=santander.wc.CFWCSancomQP01&amp;c=GSInformacion&amp;canal=CSCORP&amp;cid=1278679137354&amp;empr=CFWCSancomQP01&amp;leng=es_ES&amp;pagename=CFWCSancomQP01%2FGSInformacion%2FCFQP01_GSInformacionDetalleSimple_PT08\">Banco Santander-Universidades</a> are considering how this experimental technology might work for some of their online courses. Sebastian Thrun at <a href=\"http://www.udacity.com/\">Udacity</a> welcomes this new option for instructors who would like to create an online class, while Daphne Koller at Coursera notes that the educational landscape is changing and it is exciting to see new avenues for teaching and learning emerge. We believe Google&rsquo;s preliminary efforts here may be useful to those looking to scale online education through the cloud. <br /> <br /> Along with releasing the experimental open source code, we&rsquo;ve provided documentation and forums for anyone to learn how to develop and deploy an online course like <a href=\"http://www.powersearchingwithgoogle.com/\">Power Searching</a>. In addition, over the next two weeks we will provide educators the opportunity to connect with the Google team working on the code via Google Hangouts. For access to the code, documentation, user forum, and information about the Hangouts, visit the <a href=\"https://code.google.com/p/course-builder/\">Course Builder Open Source Project Page</a>. To see what is possible with the Course Builder technology register for Google&rsquo;s next version of <a href=\"http://www.powersearchingwithgoogle.com/\">Power Searching</a>. We invite you to explore this brave new world of online learning with us.</p>\n</blockquote>\n<p>A small group of us has been working <a href=\"/lw/ecf/open_thread_september_115_2012/7cug\">on related matters</a> but we are far from done reviewing the relevant literature. Not having any good questions yet, I thought what harm might there be in asking for the broader community to come up with a few questions! If Norvig has answered your questions in some of his other existing material that I've reviewed I'll respond with a link.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M7Tb525x8wuEji3NE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "18872", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Bsa325tntncXWX4uJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T21:07:00.140Z", "modifiedAt": null, "url": null, "title": "The Nanny State Didn't Show Up, You Hired It [LINK]", "slug": "the-nanny-state-didn-t-show-up-you-hired-it-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.596Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RomanDavis", "createdAt": "2010-05-24T13:53:21.653Z", "isAdmin": false, "displayName": "RomanDavis"}, "userId": "ByuTdzKeRn8FFJAPC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/biiPMvRBXEu846jx7/the-nanny-state-didn-t-show-up-you-hired-it-link", "pageUrlRelative": "/posts/biiPMvRBXEu846jx7/the-nanny-state-didn-t-show-up-you-hired-it-link", "linkUrl": "https://www.lesswrong.com/posts/biiPMvRBXEu846jx7/the-nanny-state-didn-t-show-up-you-hired-it-link", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Nanny%20State%20Didn't%20Show%20Up%2C%20You%20Hired%20It%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Nanny%20State%20Didn't%20Show%20Up%2C%20You%20Hired%20It%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbiiPMvRBXEu846jx7%2Fthe-nanny-state-didn-t-show-up-you-hired-it-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Nanny%20State%20Didn't%20Show%20Up%2C%20You%20Hired%20It%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbiiPMvRBXEu846jx7%2Fthe-nanny-state-didn-t-show-up-you-hired-it-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbiiPMvRBXEu846jx7%2Fthe-nanny-state-didn-t-show-up-you-hired-it-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 223, "htmlBody": "<p><a href=\"http://thelastpsychiatrist.com/2012/09/the_nanny_state_didnt_show_up.html\">http://thelastpsychiatrist.com/2012/09/the_nanny_state_didnt_show_up.html</a></p>\n<p>Saw this and I thought it went so well with Beyond the Reach of God and Blue and Green on Regulation that I just had to post it here. It&nbsp;definitely&nbsp;articulates some of the frustrations I've had with &nbsp;people who break out in a rash of Libertarianism over one (on the surface) silly law being passed and reported on and then not:</p>\n<p>A. Using the Principle of Charity to see what the opponent is really about. Even if it's silly, it shouldn't be *that* silly. See Policy Debates Should Not Appear to be One Sided.</p>\n<p>B. Considering how it applies in the larger context. You should be free to buy big sodas but not [insert literally anything the government regulates here, which is a ton of stuff]. Why is this sillier than the other thing? See anything Less Wrong has written about the absurdity heuristic.</p>\n<p>C. Thinking about your source of information, noting the feeling it's giving you, why it's giving you that feeling. Then realizing that it was specifically designed to give that feeling. If they did this, then dropping the line of thought or, deciding that they're so much smarter than the people in charge. *And then forgetting that the fact that they feel that was part of the plan of those who reported it, too.* Seriously, The Last Psychiatrist is great for that stuff.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "biiPMvRBXEu846jx7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": -19, "extendedScore": null, "score": -4.8e-05, "legacy": true, "legacyId": "18876", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T23:33:36.967Z", "modifiedAt": null, "url": null, "title": "A Less Mysterious Mindfulness Exercise", "slug": "a-less-mysterious-mindfulness-exercise", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:06.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "cJPpT5b3RxNzjTchd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8nDfzyimoFcozgGtA/a-less-mysterious-mindfulness-exercise", "pageUrlRelative": "/posts/8nDfzyimoFcozgGtA/a-less-mysterious-mindfulness-exercise", "linkUrl": "https://www.lesswrong.com/posts/8nDfzyimoFcozgGtA/a-less-mysterious-mindfulness-exercise", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Less%20Mysterious%20Mindfulness%20Exercise&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Less%20Mysterious%20Mindfulness%20Exercise%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8nDfzyimoFcozgGtA%2Fa-less-mysterious-mindfulness-exercise%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Less%20Mysterious%20Mindfulness%20Exercise%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8nDfzyimoFcozgGtA%2Fa-less-mysterious-mindfulness-exercise", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8nDfzyimoFcozgGtA%2Fa-less-mysterious-mindfulness-exercise", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2210, "htmlBody": "<p>At the beginning of the year, I stumbled upon a self-help book based on the ideas of Acceptance and Commitment Therapy (ACT). I assimilated it insights and started practicing a simple exercise and quickly noticed its effectiveness, to the point of becoming convinced that I had found a fully general mindhack that would help me deal with all psychological issues that I had or could have in the future. I even still believe it now, after eight months. I want to share this newfound knowledge in the hope that it will help others but I don't feel competent to write a comprehensive introduction to ACT. So I'll focus on describing my experience and hope for the best. I start with some conceptual background and the exercise follows.<a id=\"more\"></a></p>\n<p>A one-sentence summary of acceptance and commitment therapy could look like this: in order to live effectively, we have to accept our negative emotional states and commit ourselves to acting according to our values. The alternative to acceptance is emotional avoidance &mdash; trying to make bad thoughts and emotions go away &mdash; and it doesn't work. Trying to suppress thoughts or emotions backfires as everyone can see by failing to not think about a pink elephant for the next five minutes. Less direct attempts at experiential avoidance fail too. For example, not engaging in social interactions in order to avoid social anxiety until you eventually start feeling really anxious all the time about being a friendless loser or maybe procrastinating to avoid the unpleasantness of work until eventually you have to go through a lot of unpleasantness very quickly if you want to meet your deadline.</p>\n<p>Nevertheless, emotional avoidance seems to be the default mode of operation for most people. The very phrase 'overcoming social anxiety' seems to imply that the way to do it is to figure out how to make anxiety go away and then proceed to have a stress-free social life. It's really tricky to stop trying to do this and maybe even impossible to verbally argue yourself out of it. If someone with the habit of experiential avoidance decides to give acceptance a try, they might end up thinking 'well, trying to destroy emotions <em>directly</em> doesn't seem to work but I can destroy them by <em>pretending that I don't want to</em>' which completely misses the point. And if they decide to try really, really hard, they might end up trying to suppress their dislike of particular emotions or their desire to make them go away which sounds reasonable at first glance (how else to accept stuff than to get rid of the things that interfere with acceptance?) but really it just adds another recursive layer to the problem.</p>\n<p>So we need to make a non-verbal shift into a mental state that will allow us to accept all of our experiences, even those that seem to go against the spirit of acceptance. This state might be that which is referred to as 'mindfulness' in western psychology. For example, one definition of mindfulness states that it is:</p>\n<blockquote>\n<p>a kind of nonelaborative, nonjudgmental, present-centered awareness in which each thought, feeling, or sensation that arises in the attentional field is acknowledged and accepted as it is.</p>\n</blockquote>\n<p>There are two concepts that we can use to turn that very nice sounding but also very vague definition into something actionable. The first of them is indirect realism &mdash; the idea that we don't experience reality directly but we only ever experience our mental representations that might describe reality to a greater or lesser extent. Everyone probably already knows and agrees with it, however there's a difference between acknowledging something verbally and actually living it. Our experiences tend to fill our awareness, we get caught up in them and it's easy to forget that what we're experiencing is just a mental representation. Who had never obsessed about a future situation, going through various scenarios only to later realize that actual events didn't even come close to matching any of them?</p>\n<p>The second concept is the observing self or self-as-context. The idea is to stop identifying with the contents of your experience. Think of your mind as a background against which mental events occur. They are observed by you but they aren't you. So instead of thinking 'I'm anxious' you would think 'I'm having the experience of anxiety.'&nbsp;When you think like that, the idea of accepting all of your experience starts to seem less like giving up and possibly allowing to be overwhelmed by your emotions and more like simply acknowledging what's already there and outside of your control.&nbsp;</p>\n<p>And finally the promised exercise, quoted directly from the book (I'll tell you what book later):</p>\n<blockquote>\n<p>For this exercise, begin by getting comfortable in a quiet space and closing your eyes. With practice, you will probably be able to do this exercise during your daily activities.</p>\n<p>Once you are comfortable, visualize a parade of tiny soldiers marching in front of you. Each soldier is carrying a sign, and each sign has one of your thoughts written on it. Each new thought goes on a sign in this never-ending parade of tiny soldiers. The signs can carry words, images, even sounds and voices. Whatever your mind produces can go on a sign.</p>\n<p>If you prefer, your thoughts can float by on leaves flowing in a stream, as clouds in the sky, as credits on a movie screen, or as widgets on a conveyer belt. What matters is that you imagine watching your mind&rsquo;s activities from a distance as the thought parade goes by.</p>\n<p>When you notice that you&rsquo;ve forgotten what you&rsquo;re doing and you become attached to a particular thought, simply climb back into the bleachers and let the parade resume (adapted from Hayes, Strosahl, and Wilson 1999).</p>\n<p>That&rsquo;s the easy part. The hard part is in simply observing your thoughts without trying to change them or make them go away. It may help to remind yourself that none of the thoughts are facts, even if they seem compelling or if it seems that you must do something with them (like make the parade go faster so a particular thought will disappear).</p>\n<p>You may also notice that you&rsquo;re experiencing judgments about the thoughts. I shouldn&rsquo;t be thinking that or Only a crazy person would have that thought. Take those thoughts, put them on a sign, and add them to the parade. They are not facts, and you need not respond to them.</p>\n</blockquote>\n<p>What I would add to that is to use a timer. It helps with staying focused. I used one set to a five minute interval so that every five minutes I'd decide whether to continue practicing or finish but I setting aside a larger chunk of time up front should work too.</p>\n<p>I would also add that the picture doesn't have to be as vivid as the description suggests. I didn't try to put any writing or even a vague impression of writing on the objects I was visualizing. I just thought 'well, this one corresponds to that thought'. I also couldn't keep track of them for very long and they tended to fade out long before reaching the 'edge' of the picture. And while I was a bit obsessive in trying to picture a stable, vivid backdrop, it would probably work as well if I settled for a uniformly colored background and uniformly colored shapeless blobs as thought-representing tokens.</p>\n<p>The first time I tried this, it took somewhere around 10 minutes to notice a distinct shift in my mental state which I can't really describe better than the above vague definition of mindfulness does. It felt quite awesome. After I tried it a couple more times, the exercise turned out to be reliably effective in bringing about that mental state. My hope in writing all of this is that it will prove similarly effective for you, so if you can spare several minutes right now, I ask you to give it a try (and then tell me whether it worked in the comments).</p>\n<p>In a way, this exercise resembles the typical instructions for mindfulness meditation. There's an object of focus and whenever you stray from it, you're supposed to notice the thought you're having, acknowledge it and get back to the focus of attention. However, the fact that the object of focus has internal structure that gets constantly updated to represent the contents of the mind seems to make a big difference compared to the typically recommended practice of focusing on the breath. Focusing on the movement of objects already in the picture reminds you to expect incoming thoughts and once you have a thought, your attention is drawn back to the picture in order to update it with a new token.</p>\n<p>All of this seems to provide a much more intensive practice in the mysterious skill of 'letting things go' than focusing on your breath. In fact, it's so effective that after a couple of weeks I could do it without the visualization, at which point I dropped it completely, because while it helps it also takes a significant chunk of attention and makes you notice less stuff. The ability to simply will myself into paying nonjudgmental attention to everything that's happening is something that I haven't ever been able to acquire from meditation, even when I practiced it for months at a time (in fact I wasn't even able to reliably reach it while meditating &mdash; maybe I just suck at this).</p>\n<p>Once noting mental events without getting caught up in them became easy, the whole 'accept your experience, ask yourself what you want to do and then go do it' thing started to make much more sense. If I were doing something which caused particularly intense emotions, I could take a break to do the exercise for a couple of minutes. This would allow me to practice accepting the specific thoughts and emotions associated with that activity and also put me in a more accepting state of mind that tended to persist for some time after ending the exercise. And as I practiced, over time my baseline mental state kept shifting so that distancing myself from thoughts and emotions was becoming more automatic. All of this led to a big decrease in social anxiety, increased confidence and self-esteem, less pointless worrying, less anger, more empathy and all around improvement in my life. Self-helpy discussions on LessWrong mostly focus on akrasia and recently I had success with that too. I procrastinate less and manage to walk through my ugh fields without flinching much more often.</p>\n<p>The last point might look unimpressive &mdash; that it took me several months to succeed against akrasia. But I think this could happen much earlier if I hadn't stumbled into a failure mode that seems to be worth warning against. When you stop your attempts at experiential avoidance and accept your thoughts and emotions, they often do go away after a while. I noticed this as I became better at using mindfulness and then I started treating it as a clever trick for controlling the contents of experience, completely forgot about acceptance and reverted back to the old habit of trying to completely get rid of negative experience before moving on with my life. Needless to say, this wasn't good and my progress mostly stopped until I got sufficiently frustrated to read another book about ACT in search of missing insights and got quickly reminded that the 'acceptance' in the name isn't just for decoration.</p>\n<p>This probably means that if any of the above works for you, and you want it to keep working, it will be worth it to read a more comprehensive description of ACT. And even if it didn't work for you but the ideas seemed interesting, reading about ACT might still be worth it because the presentation here is very much based on my personal experience. For example, the described exercise is in no way presented as central in the book I got it from or in ACT in general. It just happened to work really, really well for me.</p>\n<p>Some recommendations. The book that I've first stumbled upon was 'The User's Guide to the Human Mind' by Shawn T. Smith which, as you can probably infer from the title, is a self-help book. It's based rather loosely on ACT and doesn't actually mention it by name but it does get the ideas across. It is the source of the big blockquote with the exercise. The citation in that quote references 'Acceptance and Commitment Therapy: An Experiential Approach to Behavior Change' by Hayes, Strosahl and Wilson which seems to be the seminal textbook on the subject and while it sure seems insightful from my limited reading of it, it's probably not a good introduction. The book that helped me to get out of the failure mode is 'Get Out of Your Mind and Into Your Life' by Steven Hayes and Spencer Smith. Another self-help book that's far more directly based on ACT (what with being written by one of the key people behind it). It's also a workbook which means that the ideas are interspersed with exercises that you're actually expected to complete before moving on. I suspect it might be a better introduction to ACT than the first one but I can't really tell.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AiNyf5iwbpc7mehiX": 1, "DWWZwkxTJs4d5WrcX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8nDfzyimoFcozgGtA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 36, "extendedScore": null, "score": 9.898148724166949e-07, "legacy": true, "legacyId": "18877", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 64, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-18T23:44:08.864Z", "modifiedAt": null, "url": null, "title": "Modifying Universal Intelligence Measure", "slug": "modifying-universal-intelligence-measure", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:51.132Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RvWku4gmGWiLAnidv/modifying-universal-intelligence-measure", "pageUrlRelative": "/posts/RvWku4gmGWiLAnidv/modifying-universal-intelligence-measure", "linkUrl": "https://www.lesswrong.com/posts/RvWku4gmGWiLAnidv/modifying-universal-intelligence-measure", "postedAtFormatted": "Tuesday, September 18th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Modifying%20Universal%20Intelligence%20Measure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModifying%20Universal%20Intelligence%20Measure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRvWku4gmGWiLAnidv%2Fmodifying-universal-intelligence-measure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Modifying%20Universal%20Intelligence%20Measure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRvWku4gmGWiLAnidv%2Fmodifying-universal-intelligence-measure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRvWku4gmGWiLAnidv%2Fmodifying-universal-intelligence-measure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 296, "htmlBody": "<p>In 2007, Legg and Hutter wrote a <a href=\"http://arxiv.org/abs/0712.3329\">paper</a> using the AIXI model to define a measure of intelligence. It's pretty great, but I can think of some directions of improvement.</p>\n<p>\n<ul>\n<li><em>Reinforcement learning.</em> I think this term and formalism are historically from much simpler agent models which actually depended on being reinforced to learn. In its present form (Hutter 2005 section 4.1) it seems arbitrarily general, but it still feels kinda gross to me. Can we formalize AIXI and the intelligence measure in terms of utility functions, instead? And perhaps prove them equivalent?</li>\n<li><em>Choice of Horizon.</em> AIXI discounts the future by requiring that total future reward is bounded, and therefore so does the intelligence measure. This seems to me like a constraint that does not reflect reality, and possibly an infinitely important one. How could we remove this requirement? (Much discussion on the \"Choice of the Horizon\" in Hutter 2005 section 5.7).</li>\n<li><em>Unknown utility function.</em>&nbsp;When we reformulate it in terms of utility functions, let's make sure we can measure its intelligence/optimization power without having to know its utility function. Perhaps by using an average of utility functions weighted by their K-complexity.</li>\n<li><em>AI orientation.</em> Finally, and least importantly, it tests agents across all possible programs, even those which are known to be inconsistent with our universe. This might okay if your agent is a playing arbitrary games on a computer, but if you are trying to determine how powerful an agent will be in <em>this</em> universe, you probably want to replace the Solomonoff prior with the posterior resulting from updating the Solomonoff prior with data from our universe.</li>\n</ul>\n</p>\n<p>Any thought or research on this by others? I imagine lots of discussion has occurred over these topics; any referencing would be appreciated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RvWku4gmGWiLAnidv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "18878", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T03:21:52.634Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley meetup", "slug": "meetup-berkeley-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:52.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7d2mNQxGj3W855iMC/meetup-berkeley-meetup", "pageUrlRelative": "/posts/7d2mNQxGj3W855iMC/meetup-berkeley-meetup", "linkUrl": "https://www.lesswrong.com/posts/7d2mNQxGj3W855iMC/meetup-berkeley-meetup", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d2mNQxGj3W855iMC%2Fmeetup-berkeley-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d2mNQxGj3W855iMC%2Fmeetup-berkeley-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7d2mNQxGj3W855iMC%2Fmeetup-berkeley-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dw'>Berkeley meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup will be at Zendo, as usual. See the mailing list, or contact me, for directions, see the mailing list at <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dw'>Berkeley meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7d2mNQxGj3W855iMC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.899326381723234e-07, "legacy": true, "legacyId": "18879", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup\">Discussion article for the meetup : <a href=\"/meetups/dw\">Berkeley meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup will be at Zendo, as usual. See the mailing list, or contact me, for directions, see the mailing list at <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup1\">Discussion article for the meetup : <a href=\"/meetups/dw\">Berkeley meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley meetup", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup", "level": 1}, {"title": "Discussion article for the meetup : Berkeley meetup", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T06:04:20.655Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Shut up and do the impossible!", "slug": "seq-rerun-shut-up-and-do-the-impossible", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:52.073Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F8oJ4RZEAPAorR7Qx/seq-rerun-shut-up-and-do-the-impossible", "pageUrlRelative": "/posts/F8oJ4RZEAPAorR7Qx/seq-rerun-shut-up-and-do-the-impossible", "linkUrl": "https://www.lesswrong.com/posts/F8oJ4RZEAPAorR7Qx/seq-rerun-shut-up-and-do-the-impossible", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Shut%20up%20and%20do%20the%20impossible!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Shut%20up%20and%20do%20the%20impossible!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF8oJ4RZEAPAorR7Qx%2Fseq-rerun-shut-up-and-do-the-impossible%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Shut%20up%20and%20do%20the%20impossible!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF8oJ4RZEAPAorR7Qx%2Fseq-rerun-shut-up-and-do-the-impossible", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF8oJ4RZEAPAorR7Qx%2Fseq-rerun-shut-up-and-do-the-impossible", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/up/shut_up_and_do_the_impossible/\">Shut up and do the impossible!</a> was originally published on 08 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Shut_up_and_do_the_impossible.21\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The ultimate level of attacking a problem is the point at which you simply shut up and solve the impossible problem.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ejx/seq_rerun_make_an_extraordinary_effort/\">Make an Extraordinary Effort</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F8oJ4RZEAPAorR7Qx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.900164740179182e-07, "legacy": true, "legacyId": "18889", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["nCvvhFBaayaXyuBiD", "exxjxyzrkzEHTcuuY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T06:05:18.882Z", "modifiedAt": null, "url": null, "title": "Brief Question about FAI approaches", "slug": "brief-question-about-fai-approaches", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.727Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dolores1984", "createdAt": "2012-04-27T01:13:58.517Z", "isAdmin": false, "displayName": "Dolores1984"}, "userId": "4atqsmycH3WC4Cf5u", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Et4eh9AKeuxYsXRqC/brief-question-about-fai-approaches", "pageUrlRelative": "/posts/Et4eh9AKeuxYsXRqC/brief-question-about-fai-approaches", "linkUrl": "https://www.lesswrong.com/posts/Et4eh9AKeuxYsXRqC/brief-question-about-fai-approaches", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brief%20Question%20about%20FAI%20approaches&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrief%20Question%20about%20FAI%20approaches%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEt4eh9AKeuxYsXRqC%2Fbrief-question-about-fai-approaches%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brief%20Question%20about%20FAI%20approaches%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEt4eh9AKeuxYsXRqC%2Fbrief-question-about-fai-approaches", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEt4eh9AKeuxYsXRqC%2Fbrief-question-about-fai-approaches", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 297, "htmlBody": "<p>I've been reading through this to get a sense of the state of the art at the moment:<br /><br /><a href=\"http://lukeprog.com/SaveTheWorld.html\">http://lukeprog.com/SaveTheWorld.html</a><br /><br />Near the bottom, when discussing safe utility functions, the discussion seems to center on analyzing human values and extracting from them some sort of clean, mathematical utility function that is universal across humans. &nbsp;This seems like an enormously difficult (potentially impossible) way of solving the problem, due to all the problems mentioned there.<br /><br />Why shouldn't we just try to design an average bounded utility maximizer? &nbsp;You'd build models of all your agents (if you can't model arbitrary ordered information systems, you haven't got an AI), run them through your model of the future resulting from a choice, take the summation of their utility over time, and take the average across all the people all the time. &nbsp;To measure the utility (or at least approximate it), you could just ask the models. &nbsp;The number this spits out is the output of your utility function. &nbsp;It'd probably also be wise to add a reflexive consistency criteria, such that the original state of your model must consider all future states to be 'the same person.' -- and &nbsp;I acknowledge that that last one is going to be a bitch to formalize. &nbsp;When you've got this utility function, you just... maximize it. &nbsp;<br /><br />Something like this approach seems much more robust. &nbsp;Even if human values are inconsistent, we still end up in a universe where most (possibly all) people are happy with their lives, and nobody gets wireheaded. &nbsp;Because it's bounded, you're even protected against utility monsters. &nbsp;Has something like this been considered? &nbsp;Is there an obvious reason it won't work, or would produce undesirable results? <br /><br />Thanks,</p>\n<p>Dolores &nbsp; &nbsp; &nbsp; &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Et4eh9AKeuxYsXRqC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 4, "extendedScore": null, "score": 9.900169748173464e-07, "legacy": true, "legacyId": "18890", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T11:08:39.965Z", "modifiedAt": null, "url": null, "title": "Group rationality diary, 9/17/12", "slug": "group-rationality-diary-9-17-12", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.401Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cata", "createdAt": "2010-06-02T18:13:22.408Z", "isAdmin": false, "displayName": "cata"}, "userId": "X9jdpCokhLjCMZEc3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rvMPfd4xh3oe5ZLLZ/group-rationality-diary-9-17-12", "pageUrlRelative": "/posts/rvMPfd4xh3oe5ZLLZ/group-rationality-diary-9-17-12", "linkUrl": "https://www.lesswrong.com/posts/rvMPfd4xh3oe5ZLLZ/group-rationality-diary-9-17-12", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20rationality%20diary%2C%209%2F17%2F12&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20rationality%20diary%2C%209%2F17%2F12%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrvMPfd4xh3oe5ZLLZ%2Fgroup-rationality-diary-9-17-12%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20rationality%20diary%2C%209%2F17%2F12%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrvMPfd4xh3oe5ZLLZ%2Fgroup-rationality-diary-9-17-12", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrvMPfd4xh3oe5ZLLZ%2Fgroup-rationality-diary-9-17-12", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 206, "htmlBody": "<p><span style=\"text-align: justify;\">T</span><span style=\"color: #333333; text-align: justify;\">his is the public group instrumental rationality diary for the week of September 17th. It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<div id=\"entry_t3_drj\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<ul style=\"padding: 0px; line-height: 19px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\">Thanks to everyone who contributes!</p>\n<p style=\"margin: 0px 0px 1em; line-height: 19px;\"><a style=\"color: #8a8a8b;\" href=\"/lw/edh/group_rationality_diary_9312/\">Previous diary</a>;&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">archive of prior diaries</a>.</p>\n<p>(Sorry for being late, I don't even have an excuse at all! &nbsp;Oh well.)</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rvMPfd4xh3oe5ZLLZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 9.901735435190685e-07, "legacy": true, "legacyId": "18894", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3xpqqjL8Khh47oDQt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T16:15:30.213Z", "modifiedAt": null, "url": null, "title": "Meetup : Urbana-Champaign, IL", "slug": "meetup-urbana-champaign-il", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:01.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MK7z3qcTL96sDgdXE/meetup-urbana-champaign-il", "pageUrlRelative": "/posts/MK7z3qcTL96sDgdXE/meetup-urbana-champaign-il", "linkUrl": "https://www.lesswrong.com/posts/MK7z3qcTL96sDgdXE/meetup-urbana-champaign-il", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Urbana-Champaign%2C%20IL&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Urbana-Champaign%2C%20IL%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMK7z3qcTL96sDgdXE%2Fmeetup-urbana-champaign-il%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Urbana-Champaign%2C%20IL%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMK7z3qcTL96sDgdXE%2Fmeetup-urbana-champaign-il", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMK7z3qcTL96sDgdXE%2Fmeetup-urbana-champaign-il", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dx'>Urbana-Champaign, IL</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 September 2012 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">The Bread Company, 706 South Goodwin, Urbana, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Now that we're all here for the school year, let's get the meetup ball a-rolling. I'll claim a few tables at the Bread Company, buy some appetizers, and teach everyone who comes how to play Blank White Cards.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dx'>Urbana-Champaign, IL</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MK7z3qcTL96sDgdXE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 9.903319560728003e-07, "legacy": true, "legacyId": "18897", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Urbana_Champaign__IL\">Discussion article for the meetup : <a href=\"/meetups/dx\">Urbana-Champaign, IL</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 September 2012 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">The Bread Company, 706 South Goodwin, Urbana, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Now that we're all here for the school year, let's get the meetup ball a-rolling. I'll claim a few tables at the Bread Company, buy some appetizers, and teach everyone who comes how to play Blank White Cards.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Urbana_Champaign__IL1\">Discussion article for the meetup : <a href=\"/meetups/dx\">Urbana-Champaign, IL</a></h2>", "sections": [{"title": "Discussion article for the meetup : Urbana-Champaign, IL", "anchor": "Discussion_article_for_the_meetup___Urbana_Champaign__IL", "level": 1}, {"title": "Discussion article for the meetup : Urbana-Champaign, IL", "anchor": "Discussion_article_for_the_meetup___Urbana_Champaign__IL1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T16:19:36.221Z", "modifiedAt": null, "url": null, "title": "Less Wrong Polls in Comments", "slug": "less-wrong-polls-in-comments", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:21.402Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jTkcrSJCb5jPjyhYi/less-wrong-polls-in-comments", "pageUrlRelative": "/posts/jTkcrSJCb5jPjyhYi/less-wrong-polls-in-comments", "linkUrl": "https://www.lesswrong.com/posts/jTkcrSJCb5jPjyhYi/less-wrong-polls-in-comments", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20Polls%20in%20Comments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20Polls%20in%20Comments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTkcrSJCb5jPjyhYi%2Fless-wrong-polls-in-comments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20Polls%20in%20Comments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTkcrSJCb5jPjyhYi%2Fless-wrong-polls-in-comments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjTkcrSJCb5jPjyhYi%2Fless-wrong-polls-in-comments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<p>You can now write Less Wrong comments that contain polls! John Simon picked up and finished some code I had written back in 2010 but never finished, and our admins Wesley Moore and Matt Fallshaw have deployed it. You can use it right now, so let's give it some testing here in this thread.</p>\n<p>The polls work through the existing Markdown comment formatting, similar to the syntax used for links. Full documentation is in <a href=\"http://wiki.lesswrong.com/wiki/Comment_formatting#Polls\">the wiki</a>; the short version is that you can write comments like this:</p>\n<p style=\"padding-left: 30px; \">What is your favorite color?&nbsp;[poll]{Red}{Green}{Blue}{Other}</p>\n<p style=\"padding-left: 30px; \">How long has it been your favorite color, in years? [poll:number]</p>\n<p style=\"padding-left: 30px; \">Red is a nice color [poll:Agree....Disagree]</p>\n<p style=\"padding-left: 30px; \">Will your favorite color change? [poll:probability]</p>\n<p>To see the results of the poll, you have to vote (you can leave questions blank if you want). The results include a link to the raw poll data, including the usernames of people who submitted votes with the \"Vote anonymously\" box unchecked.&nbsp;After you submit the comment, if you go back and edit your comment all those poll tags will have turned into [pollid:123]. You can edit the rest of the comment without resetting the poll, but you can't change the options.</p>\n<p>It works right now, but it's also new and could be buggy. Let's give it some testing; what have you always wanted to know about Less Wrongers?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jTkcrSJCb5jPjyhYi", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 82, "baseScore": 125, "extendedScore": null, "score": 9.903340731649985e-07, "legacy": true, "legacyId": "18896", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-04-30T02:21:34.677Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 310, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T16:56:17.676Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Thursday 7pm", "slug": "meetup-fort-collins-colorado-meetup-thursday-7pm-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vDntZRSGTRF6NKRSX/meetup-fort-collins-colorado-meetup-thursday-7pm-0", "pageUrlRelative": "/posts/vDntZRSGTRF6NKRSX/meetup-fort-collins-colorado-meetup-thursday-7pm-0", "linkUrl": "https://www.lesswrong.com/posts/vDntZRSGTRF6NKRSX/meetup-fort-collins-colorado-meetup-thursday-7pm-0", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvDntZRSGTRF6NKRSX%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvDntZRSGTRF6NKRSX%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvDntZRSGTRF6NKRSX%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dy'>Fort Collins, Colorado Meetup Thursday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Mugs, 306 West Laurel, Fort Collins CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Trying another new place. Not much parking nearby, but within walking distance of campus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dy'>Fort Collins, Colorado Meetup Thursday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vDntZRSGTRF6NKRSX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.903530188232158e-07, "legacy": true, "legacyId": "18898", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm\">Discussion article for the meetup : <a href=\"/meetups/dy\">Fort Collins, Colorado Meetup Thursday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Mugs, 306 West Laurel, Fort Collins CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Trying another new place. Not much parking nearby, but within walking distance of campus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/dy\">Fort Collins, Colorado Meetup Thursday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T17:25:21.348Z", "modifiedAt": null, "url": null, "title": "Let's talk about politics", "slug": "let-s-talk-about-politics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.766Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "WingedViper", "createdAt": "2012-07-01T09:00:25.788Z", "isAdmin": false, "displayName": "WingedViper"}, "userId": "QefnMuzQtnwHGjfAN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GsCGRQ9dh2urtMNyH/let-s-talk-about-politics", "pageUrlRelative": "/posts/GsCGRQ9dh2urtMNyH/let-s-talk-about-politics", "linkUrl": "https://www.lesswrong.com/posts/GsCGRQ9dh2urtMNyH/let-s-talk-about-politics", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Let's%20talk%20about%20politics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALet's%20talk%20about%20politics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsCGRQ9dh2urtMNyH%2Flet-s-talk-about-politics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Let's%20talk%20about%20politics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsCGRQ9dh2urtMNyH%2Flet-s-talk-about-politics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGsCGRQ9dh2urtMNyH%2Flet-s-talk-about-politics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<p>Hello fellow LWs,</p>\n<p>As I have read repeatedly on LW (<a title=\"politics is the mindkiller\" href=\"/lw/gw/politics_is_the_mindkiller/\">http://lesswrong.com/lw/gw/politics_is_the_mindkiller/</a>) you don't like discussing politics because it produces biased thinking/arguing which I agree is true for the general populace. What I find curious is that you don't seem to even try it here where people would be very likely to keep their identities small (<a title=\"keeping your identity small\" href=\"http://www.paulgraham.com/identity.html\">www.paulgraham.com/identity.html</a>). It should be the perfect (or close enough) environment to talk politics because you can have reasonable discussions here.</p>\n<p>I do understand that you don't like to bring politics into discussions about rationality, but I don't understand why there shouldn't be dedicated political threads here. (Maybe you could flag them?)</p>\n<p>all the best</p>\n<p>Viper</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GsCGRQ9dh2urtMNyH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": -24, "extendedScore": null, "score": 9.903680252724761e-07, "legacy": true, "legacyId": "18899", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T17:31:20.733Z", "modifiedAt": null, "url": null, "title": "Thinking in another language could reduce biases", "slug": "thinking-in-another-language-could-reduce-biases", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.767Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HnL9ZWbDBrjSB23Xa/thinking-in-another-language-could-reduce-biases", "pageUrlRelative": "/posts/HnL9ZWbDBrjSB23Xa/thinking-in-another-language-could-reduce-biases", "linkUrl": "https://www.lesswrong.com/posts/HnL9ZWbDBrjSB23Xa/thinking-in-another-language-could-reduce-biases", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thinking%20in%20another%20language%20could%20reduce%20biases&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThinking%20in%20another%20language%20could%20reduce%20biases%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHnL9ZWbDBrjSB23Xa%2Fthinking-in-another-language-could-reduce-biases%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thinking%20in%20another%20language%20could%20reduce%20biases%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHnL9ZWbDBrjSB23Xa%2Fthinking-in-another-language-could-reduce-biases", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHnL9ZWbDBrjSB23Xa%2Fthinking-in-another-language-could-reduce-biases", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 406, "htmlBody": "<p>From <a href=\"http://www.wired.com/wiredscience/2012/05/the-benefits-of-being-bilingual/\">Wired</a>:</p>\n<blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; line-height: 20px; \">The experiments themselves relied on classic paradigms borrowed from prospect theory, in which people are asked to make decisions under varying conditions of uncertainty and risk. For instance, native English speakers in Chicago who had learned Spanish in the classroom were given a $15 stake. Then, they were asked to make various bets based on a coin toss: If they correctly picked heads or tails, they would win $1.50, while an incorrect guess would cost them $1. From a rational perspective, these bets are a smart wager &ndash; a subject who chooses to bet on all 15 trials would most likely come out far ahead.</p>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; line-height: 20px; \">But people aren&rsquo;t rational creatures. When thinking in English, students only chose to bet 54 percent of their time; their fear of losses kept them from properly assessing the situation. However, when the same options were described in Spanish, subjects made significantly better decisions, choosing to place bets 71 percent of the time.</p>\n</blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-family: Arial, Verdana, sans-serif; font-size: 14px; line-height: 20px; \">When faced with <a style=\"font-size: 14px; \" href=\"http://wiki.lesswrong.com/wiki/Shut_up_and_multiply\">mathematically identical but differently-worded decisions</a> about whether to take a 'risky' or 'safe' option in saving people:</p>\n<blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; \">When 121 American students were given a version of the scenario above, nearly 80 percent chose the safe option, just like those doctors. However, when the same situation was placed in a loss frame, that number plummeted to 47 percent. So far, so obvious: we are consistently inconsistent creatures.</p>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; \">But when native English speakers were presented with the same problem in Japanese, the inconsistency vanished. In both frames, the number of people choosing the safer option was just over 40 percent.</p>\n</blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; \">Their interpretation:</p>\n<blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; \">Instead, the psychologists found that the reduced emotional valence of a second language &ndash; the words aren&rsquo;t so weighted with feeling &ndash; made it easier to resist the tug of loss aversion. (Similar results have been achieved with neurological patients who, after suffering a serious brain injury, are unable to experience any emotion at all.) The scientists argue that second-language thinking can systematically improve decision-making: &ldquo;People who routinely make decisions in a foreign language might be less biased in their savings, investment and retirement decisions,&rdquo; they write. &ldquo;Over a long time horizon, this might very well be beneficial.&rdquo; Given the known costs of loss aversion among financial traders &ndash; it&rsquo;s a huge issue &ndash; perhaps it&rsquo;s time that those on Wall Street begin thinking in a non-native tongue.</p>\n</blockquote>\n<p style=\"margin: 20px 0px; padding: 0px; font-size: 14px; \">At least one of the studies is available <a href=\"http://pss.sagepub.com/content/early/2012/04/18/0956797611432178\">here</a>, but I haven't found the other one.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HnL9ZWbDBrjSB23Xa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -7, "extendedScore": null, "score": -5e-06, "legacy": true, "legacyId": "18900", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T18:44:39.338Z", "modifiedAt": null, "url": null, "title": "The utility-maximizing complexity of conscious beings", "slug": "the-utility-maximizing-complexity-of-conscious-beings", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:52.365Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "snowball", "createdAt": "2012-09-10T13:06:25.938Z", "isAdmin": false, "displayName": "snowball"}, "userId": "ehbFxH5Tq5Hv2v37M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TvqMzbu2QyX9WErtK/the-utility-maximizing-complexity-of-conscious-beings", "pageUrlRelative": "/posts/TvqMzbu2QyX9WErtK/the-utility-maximizing-complexity-of-conscious-beings", "linkUrl": "https://www.lesswrong.com/posts/TvqMzbu2QyX9WErtK/the-utility-maximizing-complexity-of-conscious-beings", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20utility-maximizing%20complexity%20of%20conscious%20beings&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20utility-maximizing%20complexity%20of%20conscious%20beings%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTvqMzbu2QyX9WErtK%2Fthe-utility-maximizing-complexity-of-conscious-beings%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20utility-maximizing%20complexity%20of%20conscious%20beings%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTvqMzbu2QyX9WErtK%2Fthe-utility-maximizing-complexity-of-conscious-beings", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTvqMzbu2QyX9WErtK%2Fthe-utility-maximizing-complexity-of-conscious-beings", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<p>An AI that runs conscious beings has finite resources. Complex conscious beings consume more of these resources than do simpler conscious beings. Suppose, for purposes of discussion, that a friendly AI would maximize the aggregate utility of the beings it runs by modulating their level of complexity.</p>\n<p>The utility-maximizing level of complexity would depend on the natural laws that govern the relation between the complexity of a being and the magnitude of the utility that it can experience.</p>\n<p>When you are uploaded to the AI, then, one of three things will happen, depending on the result above:</p>\n<p>1. You may wake up to discover that most of your mind, memory, and identity had disappeared, because most of your computational resources had been stolen in order to create a set of new, simple beings who, in total, would enjoy more utility than you had thereby lost. You may even be much less happy than you now are.</p>\n<p>2. You may not wake up at all, because the totality of your computational resources had been stolen from you and given to a superbeing who was capable, because of some economy of scale in utility consumption, of extracting more utility from them than you could.</p>\n<p>3. You may wake up to discover that you are much smarter and happier than you now are, because the utility-maximizing level of complexity is larger than your own, but not so large that, if all people were to upload, it would exhaust the AI's resources, thus making rationing necessary.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TvqMzbu2QyX9WErtK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -6, "extendedScore": null, "score": 9.904089757070505e-07, "legacy": true, "legacyId": "18901", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T20:03:21.463Z", "modifiedAt": null, "url": null, "title": "Meetup : Research Triangle Less Wrong", "slug": "meetup-research-triangle-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:53.462Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "evand", "createdAt": "2012-05-14T16:45:50.150Z", "isAdmin": false, "displayName": "evand"}, "userId": "QSBopDfW3DLzeMG7L", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xhkf8TJG4KLAGrNBr/meetup-research-triangle-less-wrong", "pageUrlRelative": "/posts/Xhkf8TJG4KLAGrNBr/meetup-research-triangle-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/Xhkf8TJG4KLAGrNBr/meetup-research-triangle-less-wrong", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Research%20Triangle%20Less%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Research%20Triangle%20Less%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhkf8TJG4KLAGrNBr%2Fmeetup-research-triangle-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Research%20Triangle%20Less%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhkf8TJG4KLAGrNBr%2Fmeetup-research-triangle-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhkf8TJG4KLAGrNBr%2Fmeetup-research-triangle-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/dz'>Research Triangle Less Wrong</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Bryan Center Plaza at Duke, Durham, NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>From Gordon's announcement email:</p>\n\n<p>So, Madeleine and I have been thinking over when is best for the group to meet.</p>\n\n<p>Until we can figure out better times and places, the two of us are going to pre-commit to spending the 3 hours from 6pm to 9pm on the Bryan Center Plaza every Thursday Evening.</p>\n\n<p>I hope we might see some of you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/dz'>Research Triangle Less Wrong</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xhkf8TJG4KLAGrNBr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 9.904496202789829e-07, "legacy": true, "legacyId": "18902", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong\">Discussion article for the meetup : <a href=\"/meetups/dz\">Research Triangle Less Wrong</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 September 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Bryan Center Plaza at Duke, Durham, NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>From Gordon's announcement email:</p>\n\n<p>So, Madeleine and I have been thinking over when is best for the group to meet.</p>\n\n<p>Until we can figure out better times and places, the two of us are going to pre-commit to spending the 3 hours from 6pm to 9pm on the Bryan Center Plaza every Thursday Evening.</p>\n\n<p>I hope we might see some of you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong1\">Discussion article for the meetup : <a href=\"/meetups/dz\">Research Triangle Less Wrong</a></h2>", "sections": [{"title": "Discussion article for the meetup : Research Triangle Less Wrong", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong", "level": 1}, {"title": "Discussion article for the meetup : Research Triangle Less Wrong", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-19T23:56:52.149Z", "modifiedAt": null, "url": null, "title": "Cooperative Surplus Splitting", "slug": "cooperative-surplus-splitting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.478Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "GuySrinivasan", "createdAt": "2009-02-27T21:00:32.986Z", "isAdmin": false, "displayName": "GuySrinivasan"}, "userId": "HMnfd9HdRCfuRcdBG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vArvERrdXjqCGDQpd/cooperative-surplus-splitting", "pageUrlRelative": "/posts/vArvERrdXjqCGDQpd/cooperative-surplus-splitting", "linkUrl": "https://www.lesswrong.com/posts/vArvERrdXjqCGDQpd/cooperative-surplus-splitting", "postedAtFormatted": "Wednesday, September 19th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cooperative%20Surplus%20Splitting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACooperative%20Surplus%20Splitting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvArvERrdXjqCGDQpd%2Fcooperative-surplus-splitting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cooperative%20Surplus%20Splitting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvArvERrdXjqCGDQpd%2Fcooperative-surplus-splitting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvArvERrdXjqCGDQpd%2Fcooperative-surplus-splitting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 419, "htmlBody": "<p>Often we cooperate to extract surplus value from the government, hotels, the physics that makes operating cars cost money, or other sources - value that we could not extract individually. When I notice such a surplus I often wonder how the surplus should be split. What is fair? Purely cooperatively, without anyone trying to game the surplus-allocation-function, and assuming the stated coalitions are fixed rather than negotiable, how much of the surplus should be attributed to each contributing party?</p>\n<p>Some concrete examples that have come up recently in real life*:</p>\n<p><span style=\"white-space: pre;\"> </span>1. Matching donations. The company I work for will match donations to charity, dollar for dollar, up to a certain maximum. Viscerally, how should I feel about donating $100 to puppies**? More than $100, since puppies get $200, certainly. But less than $200, since my employer should feel puppy-love too, and presumably there's a conservation of visceral feeling law that should apply here. Further suppose that my employer's matching offer caused me to donate $100 instead of, say, $50. What math should be done and why?</p>\n<p><span style=\"white-space: pre;\"> </span>2. Exemption splitting. An amicable divorce leaves two parents wondering who should claim their student daughter as a dependent. As a purely \"what is fair?\" financial question, how much of the tax savings from that exemption should be distributed to the father, mother, and daughter? Suppose the father's marginal tax rate is 25% and overall tax rate is 18%, and the mother's marginal rate is 15% and overall is 12%. What math should be done and why?</p>\n<p><span style=\"white-space: pre;\"> </span>3. Refinancing. My friend has a debt at 12% and for silly reasons is obviously able to pay it off but cannot this year. I can pay it off, though, and so could several other people***. Assume there are 3 people including me who could pay it off, and our current expected returns on invested money are (say) 2%, 3.5%, and 6%, and for simplicity she will repay the loan plus any surplus due in one year. Who should pay off how much of the loan (say it's $5000)? I assume the 2% person should pay all of it. That's a 10% surplus - how much do each of the four of us get? What math should be done and why?</p>\n<p>As in <a title=\"The Bedrock of Fairness\" href=\"/lw/ru/the_bedrock_of_fairness/\">The Bedrock of Fairness</a>, are there qualities of the solutions we have strong opinions on, even if we do not know the procedure which would generate solutions with those qualities?&nbsp;</p>\n<p>*Details changed.<br />**I do not donate to puppies.<br />***Assume default risk is negligible.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vArvERrdXjqCGDQpd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 9.90570231826862e-07, "legacy": true, "legacyId": "18903", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iAxkfiyG8WizPSPbq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-20T04:28:37.011Z", "modifiedAt": "2022-01-11T23:20:25.208Z", "url": null, "title": "A Critique of Leverage Research's Connection Theory", "slug": "a-critique-of-leverage-research-s-connection-theory", "viewCount": null, "lastCommentedAt": "2014-08-01T11:53:28.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8j4zirwfhWhT8nwsc/a-critique-of-leverage-research-s-connection-theory", "pageUrlRelative": "/posts/8j4zirwfhWhT8nwsc/a-critique-of-leverage-research-s-connection-theory", "linkUrl": "https://www.lesswrong.com/posts/8j4zirwfhWhT8nwsc/a-critique-of-leverage-research-s-connection-theory", "postedAtFormatted": "Thursday, September 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Critique%20of%20Leverage%20Research's%20Connection%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Critique%20of%20Leverage%20Research's%20Connection%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8j4zirwfhWhT8nwsc%2Fa-critique-of-leverage-research-s-connection-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Critique%20of%20Leverage%20Research's%20Connection%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8j4zirwfhWhT8nwsc%2Fa-critique-of-leverage-research-s-connection-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8j4zirwfhWhT8nwsc%2Fa-critique-of-leverage-research-s-connection-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1831, "htmlBody": "<p><a href=\"http://www.leverageresearch.org/\">Leverage Research</a> is a recently formed New York-based research group \"dedicate[d] to making the world a better place by the best and most effective means possible\". I personally empathize and connect with this mission statement a lot, and I myself have made more or less an identical dedication personally, and through my involvement with the organizations <a href=\"http://www.givingwhatwecan.org\">GivingWhatWeCan</a> and <a href=\"http://www.80000hours.org\">80000 Hours</a>.</p>\n<p>One of the pieces of research developed by Leverage Research founder Geoff Anders (and presumably tested and developed by Leverage Research) is Connection Theory. Broadly, <a href=\"http://www.leverageresearch.org/tiki-index.php?page=Connection+Theory+Research\">Connection Theory</a> (CT) is a theory of mind that proports to explain and predict nearly all mental phenomena -- such as why people believe, desire, think, and act the way they do.</p>\n<p>CT, if true, would be an amazing and profound success for psychology as a discipline. However, I don't think CT is true. Or rather, even if CT is true, I don't think the case made for CT is persuasive. In this essay, I intend to articulate my case against CT.</p>\n<!--more-->\n<p>&nbsp;</p>\n<h2>Disclaimer</h2>\n<p>I don't write this essay with the intent to \"hurt\" Leverage Research or Geoff Anders, but rather with the intent to either:<br />(1) be persuaded for the truth of CT and understand how to use it to better make the world a better place, or<br />(2) successfully criticize CT and help an organization with a very laudable mission better accomplish it by correcting the errors they've made.</p>\n<p>In many ways, I expect my criticism to \"miss the mark\" and misunderstand CT. In doing so, I hope to allow Leverage Research to clarify their theory in light of my objections to make it less misunderstood. In other ways, I expect my criticism to reveal flaws in CT that require revision and reassessment.</p>\n<p>(Lastly, I make this essay with the disclaimer that I have no specialized knowledge or formal training in psychology, beyond pursuing an undergraduate degree in the field. I am currently in my Junior Year at <a href=\"http://www.denison.edu\">Denison University</a>.)</p>\n<p>&nbsp;</p>\n<h2>Connection Theory in More Detail</h2>\n<p>Connection Theory is a combination of the following four premises:</p>\n<blockquote>1. Everything a mind is aware of is (a) a sensation, (b) a spatial relation between sensations, (c) a representation, (d) an awareness of something, or (e) a combination of these.</blockquote>\n<blockquote>2. Every mind is such that its representational content at a moment is determined entirely by it updating its representational content in the most elegant possible way on the basis of its representational content at the preceding moment, if it had any, and its current sensations, given the restriction that it believe that each of its intrinsic goods will be permanently achieved.</blockquote>\n<blockquote>3. Every mind is such that at every moment it exists, it acts exactly in the way it believes will lead to each of its intrinsic goods being permanently achieved.</blockquote>\n<blockquote>4. Every mind is such that something is one of its intrinsic goods if and only if it is one of that mind&rsquo;s concepts and it is on the List of Intrinsic Goods.</blockquote>\n<p>Put more simply, CT asserts that every single person has certain fundamental desires about the way they want the world to be (usually just a few, like social acceptance and world peace), people always believe that their fundamental desires will eventually be satisfied, and that people will change their beliefs in completely rational ways except if such a change would cause them to stop believing their fundamental beliefs will be satisfied. CT also asserts that people will always act to best satisfy their fundamental desires, according to their beliefs.</p>\n<p>&nbsp;</p>\n<h2>The Evidence for Connection Theory</h2>\n<p>The Evidence for Connection Theory has been gathered in <a href=\"http://www.leverageresearch.org/tiki-download_wiki_attachment.php?attId=30&amp;download=y\">\"Connection Theory: The Current Evidence\"</a> (link to an automatic download of a PDF file). The article mentions six pieces of evidence for CT: (1) Recommendation Tests, (2) Mind Mapping Tests, (3) Results from Everyday Use, (4) Results from Practical Application, (5) Explanation of Sociological Phenomena, and (6) Philosophical Arguments.</p>\n<h4>Recommendation Tests</h4>\n<p>The recommendation test starts with a CT chart -- that is, using Connection Theory to create a chart for a person that aims to explain their thoughts, feelings, and behavior by reference to their \"intrinsic goods\" (goals they fundamentally want to accomplish), \"modes\" (different attitudes toward life that can be triggered by various events), and \"path diagrams\" which connect various actions to instrumental goals that can eventually accomplish intrinsic goods.</p>\n<p>The process for making a chart is given lengthy treatment in <a href=\"http://www.leverageresearch.org/tiki-download_wiki_attachment.php?attId=9&amp;download=y\">\"Connection Theory: Theory and Practice\"</a> (link to an automatic download of the PDF) starting from page 32, though reading the whole document is probably necessary to understanding what is going on.</p>\n<p>To make a long story short, the Recommendation Test involves creating the CT chart, then reviewing it to create a prediction in the form \"If the participant takes {specified actions}, the participant will change in {specified way}\". Using two different CT charts (one for Anders by Anders, the author of CT; and second for a friend of Anders by Anders), 60 predictions were made. Of those, 22 were tested, 16 came true, 5 were ruled too difficult to confirm, and 1 was ruled false but because of an error made in the first chart. This predictive success is taken as \"strong evidence of CT\".</p>\n<h4>Mind Mapping Tests</h4>\n<p>Mind Mapping Tests are a bit different -- for this test, one needs to generate a CT chart for a person again, but this time look through all the beliefs of the participant. For each belief, the CT theorist should be able to provide a \"CT-compliant answer\", ie an answer that shows the belief was derived either through \"elegant updating\" (being completely and ideally rational) or through a need to believe in order to believe one can still accomplish one's \"intrinsic goods\". Anders claims to have done CT charts for seven different people and has always been able to describe beliefs in CT-compliant ways. This is taken as \"a moderate amount of evidence\" for CT.</p>\n<h4>\"Other\"</h4>\n<p>Unfortunately for the remaining four types of evidence for CT, very little elaboration is provided; instead, the existence of results is simply declared. For example:</p>\n<blockquote><span>Regarding the everyday use of CT, several people have used CT to achieved very noteworthy results in their everyday lives. People have improved relationships with their parents, kicked irrational fears of illness, maintained astonishing work ethics and more. Unfortunately, these results are not measured systematically enough to provide a lot of high-quality evidence in favor of CT. Still, it is better than nothing.</span></blockquote>\n<p>More distressingly, the existence of sociological explanations and philosophical arguments are not mentioned at all! Instead, there are promises that we'll see more, later...:</p>\n<blockquote><span>Just as CT can be used to explain psychological phenomena, it should be able to be used to explain sociological phenomena. I and some of my colleagues have begun attempting to give such explanations. So far, we have explained a few sociological phenomena. I will describe our results here in full in a later version of this document. Finally, there are a number of high-quality philosophical arguments that can be used to establish claims that relate to the central claims of CT. I will discuss these arguments fully in a later version of this document as well.</span></blockquote>\n<p>&nbsp;</p>\n<h2>Objection #1: The Case For CT Is Very Incomplete and Inadequate</h2>\n<p>So what's wrong with CT? Well, first it's clear that a lot of the evidence provided for CT doesn't count. Obviously, we cannot accept the existence of \"high-quality philosophical arguments\" or the ability to \"explain sociological phenomena\" without that information actually being provided. Likewise, CT's \"noteworthy results in [...] everyday lives\" aren't actually documented -- we have to take Ander's word for it that these things occurred.</p>\n<p>Mind Mapping and Recommendation Testing are more thorough, but still incomplete. For Mind Mapping, again Anders merely asserts that he's yet to find a belief that couldn't be explained in a CT-compliant way, though the beliefs surveyed and CT-compliant responses given are not listed.</p>\n<p>Recommendation Testing is thus the only evidence for which usable data is given, however there is a lot of patchiness: Why were 38 predictions made left completely untested? What should we make of the 5 predictions ruled too difficult to confirm or deny? Why should 16 successes out of 60 predictions be taken as phenomenal results?</p>\n<p>&nbsp;</p>\n<h2>Objection #2: The Case For CT Uses Flawed Methodology</h2>\n<p>A second objection to CT is that the methodology used to produce CT is flawed. The gold standard for demonstrating a psychological theory is demonstrating explanatory power through a psychological experiment. For CT, no psychological experiments were provided and many confounding factors were left uncontrolled. For instance, in the Reccomendation Testing, one's improvement could be for a wide variety of reasons unrelated to the CT map.</p>\n<p>The CT methodology also lends itself to significant issues of bias. The sample size in the Reccomendation Testing was only two participants -- the author of the study and someone closely related to the author. The participants could easily suffer from confirmation bias when constructing and using CT charts, guided by a conscious and/or subconscious wish for CT to be true.</p>\n<p>A better standard for CT would be to evaluate over a dozen different charts of people who are unassociated with the author of the study and unaware of CT.</p>\n<p>&nbsp;</p>\n<h2>Objection #3: CT Conflicts With Established Science</h2>\n<p>Lastly, CT conflicts with established science. \"Connection Theory: Current Evidence\" concedes that documentation that beliefs can be changed from brain damage is one outstanding, yet to be investigated problem. Additional studies pile on in this direction to the point where postulating that people are ideally rational in all cases unrelated to their internal beliefs is quite implausible.</p>\n<p>Between <a href=\"http://en.wikipedia.org/wiki/Scope_insensitivity\">scope insensitivity</a>, <a href=\"http://en.wikipedia.org/wiki/Affect_heuristic\">the affect heuristic</a>, <a href=\"http://en.wikipedia.org/wiki/Anchoring\">the anchoring effect</a>, <a href=\"http://en.wikipedia.org/wiki/Priming_(psychology)\">the priming effect</a>, <a href=\"http://en.wikipedia.org/wiki/Confirmation_bias\">confirmation bias</a>, <a href=\"http://en.wikipedia.org/wiki/Clustering_illusion\">clustering illusions</a>, <a href=\"http://en.wikipedia.org/wiki/Pareidolia\">pareidolia</a>, <a href=\"http://en.wikipedia.org/wiki/Attentional_bias\">attentional biases</a>, <a href=\"http://en.wikipedia.org/wiki/Availability_heuristic\">the availability heuristic</a>, <a href=\"http://en.wikipedia.org/wiki/Illusory_correlation\">illusory correlations</a>, <a href=\"http://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect\">the Dunning-Kuger effect</a>, <a href=\"http://en.wikipedia.org/wiki/Forer_effect\">the Forer Effect</a>, etc., enough cognitive biases have been documented to fill a book -- indeed, with <a href=\"http://www.amazon.com/dp/0374275637\">Daniel Kahneman's <strong>Thinking Fast and Slow</strong></a>, they actually have! The myth of the rational person has been so thoroughly shattered in so many ways that don't ostensibly relate to intrinsic beliefs, that I don't think CT has much to stand on.</p>\n<p>&nbsp;</p>\n<h2>Conclusion</h2>\n<p>Thus CT should not be taken as a candidate for a psychological theory without significant improvement -- it is incomplete and inadequate, has flawed methodology, and conflicts well established science. For what it's worth, Leverage Research has had an appropriate lack of confidence in CT. None of their documentation asserts that CT is true, but rather makes it clear that the current evidence is circumstantial, and more data needs to be collected.</p>\n<p>It's also worth noting that CT could be tested via <em>replication</em>, a process in which independent researchers seek to duplicate the results -- if the results can be duplicated, the theory is more likely to be true, and vice versa. Someone could follow the instructions and create a CT chart and see if it could be used to make accurate psychological predictions, especially under controlled circumstances. Personally, I don't want to invest the time needed to preform the replication until CT has stronger legs to stand on and has made an adequate case.</p>\n<h6><span style=\"font-weight: normal;\"><em>&nbsp;(Note: This was cross-posted <a href=\"http://www.greatplay.net/essays/a-critique-of-leverage-researchs-connection-theory\">from my blog</a>.)</em></span></h6>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 3, "3uE2pXvbcnS9nnZRE": 1, "sYbszETv5rKst6gxD": 10}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8j4zirwfhWhT8nwsc", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 42, "extendedScore": null, "score": 9.7e-05, "legacy": true, "legacyId": "18909", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 42, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"http://www.leverageresearch.org/\">Leverage Research</a> is a recently formed New York-based research group \"dedicate[d] to making the world a better place by the best and most effective means possible\". I personally empathize and connect with this mission statement a lot, and I myself have made more or less an identical dedication personally, and through my involvement with the organizations <a href=\"http://www.givingwhatwecan.org\">GivingWhatWeCan</a> and <a href=\"http://www.80000hours.org\">80000 Hours</a>.</p>\n<p>One of the pieces of research developed by Leverage Research founder Geoff Anders (and presumably tested and developed by Leverage Research) is Connection Theory. Broadly, <a href=\"http://www.leverageresearch.org/tiki-index.php?page=Connection+Theory+Research\">Connection Theory</a> (CT) is a theory of mind that proports to explain and predict nearly all mental phenomena -- such as why people believe, desire, think, and act the way they do.</p>\n<p>CT, if true, would be an amazing and profound success for psychology as a discipline. However, I don't think CT is true. Or rather, even if CT is true, I don't think the case made for CT is persuasive. In this essay, I intend to articulate my case against CT.</p>\n<!--more-->\n<p>&nbsp;</p>\n<h2 id=\"Disclaimer\">Disclaimer</h2>\n<p>I don't write this essay with the intent to \"hurt\" Leverage Research or Geoff Anders, but rather with the intent to either:<br>(1) be persuaded for the truth of CT and understand how to use it to better make the world a better place, or<br>(2) successfully criticize CT and help an organization with a very laudable mission better accomplish it by correcting the errors they've made.</p>\n<p>In many ways, I expect my criticism to \"miss the mark\" and misunderstand CT. In doing so, I hope to allow Leverage Research to clarify their theory in light of my objections to make it less misunderstood. In other ways, I expect my criticism to reveal flaws in CT that require revision and reassessment.</p>\n<p>(Lastly, I make this essay with the disclaimer that I have no specialized knowledge or formal training in psychology, beyond pursuing an undergraduate degree in the field. I am currently in my Junior Year at <a href=\"http://www.denison.edu\">Denison University</a>.)</p>\n<p>&nbsp;</p>\n<h2 id=\"Connection_Theory_in_More_Detail\">Connection Theory in More Detail</h2>\n<p>Connection Theory is a combination of the following four premises:</p>\n<blockquote>1. Everything a mind is aware of is (a) a sensation, (b) a spatial relation between sensations, (c) a representation, (d) an awareness of something, or (e) a combination of these.</blockquote>\n<blockquote>2. Every mind is such that its representational content at a moment is determined entirely by it updating its representational content in the most elegant possible way on the basis of its representational content at the preceding moment, if it had any, and its current sensations, given the restriction that it believe that each of its intrinsic goods will be permanently achieved.</blockquote>\n<blockquote>3. Every mind is such that at every moment it exists, it acts exactly in the way it believes will lead to each of its intrinsic goods being permanently achieved.</blockquote>\n<blockquote>4. Every mind is such that something is one of its intrinsic goods if and only if it is one of that mind\u2019s concepts and it is on the List of Intrinsic Goods.</blockquote>\n<p>Put more simply, CT asserts that every single person has certain fundamental desires about the way they want the world to be (usually just a few, like social acceptance and world peace), people always believe that their fundamental desires will eventually be satisfied, and that people will change their beliefs in completely rational ways except if such a change would cause them to stop believing their fundamental beliefs will be satisfied. CT also asserts that people will always act to best satisfy their fundamental desires, according to their beliefs.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Evidence_for_Connection_Theory\">The Evidence for Connection Theory</h2>\n<p>The Evidence for Connection Theory has been gathered in <a href=\"http://www.leverageresearch.org/tiki-download_wiki_attachment.php?attId=30&amp;download=y\">\"Connection Theory: The Current Evidence\"</a> (link to an automatic download of a PDF file). The article mentions six pieces of evidence for CT: (1) Recommendation Tests, (2) Mind Mapping Tests, (3) Results from Everyday Use, (4) Results from Practical Application, (5) Explanation of Sociological Phenomena, and (6) Philosophical Arguments.</p>\n<h4 id=\"Recommendation_Tests\">Recommendation Tests</h4>\n<p>The recommendation test starts with a CT chart -- that is, using Connection Theory to create a chart for a person that aims to explain their thoughts, feelings, and behavior by reference to their \"intrinsic goods\" (goals they fundamentally want to accomplish), \"modes\" (different attitudes toward life that can be triggered by various events), and \"path diagrams\" which connect various actions to instrumental goals that can eventually accomplish intrinsic goods.</p>\n<p>The process for making a chart is given lengthy treatment in <a href=\"http://www.leverageresearch.org/tiki-download_wiki_attachment.php?attId=9&amp;download=y\">\"Connection Theory: Theory and Practice\"</a> (link to an automatic download of the PDF) starting from page 32, though reading the whole document is probably necessary to understanding what is going on.</p>\n<p>To make a long story short, the Recommendation Test involves creating the CT chart, then reviewing it to create a prediction in the form \"If the participant takes {specified actions}, the participant will change in {specified way}\". Using two different CT charts (one for Anders by Anders, the author of CT; and second for a friend of Anders by Anders), 60 predictions were made. Of those, 22 were tested, 16 came true, 5 were ruled too difficult to confirm, and 1 was ruled false but because of an error made in the first chart. This predictive success is taken as \"strong evidence of CT\".</p>\n<h4 id=\"Mind_Mapping_Tests\">Mind Mapping Tests</h4>\n<p>Mind Mapping Tests are a bit different -- for this test, one needs to generate a CT chart for a person again, but this time look through all the beliefs of the participant. For each belief, the CT theorist should be able to provide a \"CT-compliant answer\", ie an answer that shows the belief was derived either through \"elegant updating\" (being completely and ideally rational) or through a need to believe in order to believe one can still accomplish one's \"intrinsic goods\". Anders claims to have done CT charts for seven different people and has always been able to describe beliefs in CT-compliant ways. This is taken as \"a moderate amount of evidence\" for CT.</p>\n<h4 id=\"_Other_\">\"Other\"</h4>\n<p>Unfortunately for the remaining four types of evidence for CT, very little elaboration is provided; instead, the existence of results is simply declared. For example:</p>\n<blockquote><span>Regarding the everyday use of CT, several people have used CT to achieved very noteworthy results in their everyday lives. People have improved relationships with their parents, kicked irrational fears of illness, maintained astonishing work ethics and more. Unfortunately, these results are not measured systematically enough to provide a lot of high-quality evidence in favor of CT. Still, it is better than nothing.</span></blockquote>\n<p>More distressingly, the existence of sociological explanations and philosophical arguments are not mentioned at all! Instead, there are promises that we'll see more, later...:</p>\n<blockquote><span>Just as CT can be used to explain psychological phenomena, it should be able to be used to explain sociological phenomena. I and some of my colleagues have begun attempting to give such explanations. So far, we have explained a few sociological phenomena. I will describe our results here in full in a later version of this document. Finally, there are a number of high-quality philosophical arguments that can be used to establish claims that relate to the central claims of CT. I will discuss these arguments fully in a later version of this document as well.</span></blockquote>\n<p>&nbsp;</p>\n<h2 id=\"Objection__1__The_Case_For_CT_Is_Very_Incomplete_and_Inadequate\">Objection #1: The Case For CT Is Very Incomplete and Inadequate</h2>\n<p>So what's wrong with CT? Well, first it's clear that a lot of the evidence provided for CT doesn't count. Obviously, we cannot accept the existence of \"high-quality philosophical arguments\" or the ability to \"explain sociological phenomena\" without that information actually being provided. Likewise, CT's \"noteworthy results in [...] everyday lives\" aren't actually documented -- we have to take Ander's word for it that these things occurred.</p>\n<p>Mind Mapping and Recommendation Testing are more thorough, but still incomplete. For Mind Mapping, again Anders merely asserts that he's yet to find a belief that couldn't be explained in a CT-compliant way, though the beliefs surveyed and CT-compliant responses given are not listed.</p>\n<p>Recommendation Testing is thus the only evidence for which usable data is given, however there is a lot of patchiness: Why were 38 predictions made left completely untested? What should we make of the 5 predictions ruled too difficult to confirm or deny? Why should 16 successes out of 60 predictions be taken as phenomenal results?</p>\n<p>&nbsp;</p>\n<h2 id=\"Objection__2__The_Case_For_CT_Uses_Flawed_Methodology\">Objection #2: The Case For CT Uses Flawed Methodology</h2>\n<p>A second objection to CT is that the methodology used to produce CT is flawed. The gold standard for demonstrating a psychological theory is demonstrating explanatory power through a psychological experiment. For CT, no psychological experiments were provided and many confounding factors were left uncontrolled. For instance, in the Reccomendation Testing, one's improvement could be for a wide variety of reasons unrelated to the CT map.</p>\n<p>The CT methodology also lends itself to significant issues of bias. The sample size in the Reccomendation Testing was only two participants -- the author of the study and someone closely related to the author. The participants could easily suffer from confirmation bias when constructing and using CT charts, guided by a conscious and/or subconscious wish for CT to be true.</p>\n<p>A better standard for CT would be to evaluate over a dozen different charts of people who are unassociated with the author of the study and unaware of CT.</p>\n<p>&nbsp;</p>\n<h2 id=\"Objection__3__CT_Conflicts_With_Established_Science\">Objection #3: CT Conflicts With Established Science</h2>\n<p>Lastly, CT conflicts with established science. \"Connection Theory: Current Evidence\" concedes that documentation that beliefs can be changed from brain damage is one outstanding, yet to be investigated problem. Additional studies pile on in this direction to the point where postulating that people are ideally rational in all cases unrelated to their internal beliefs is quite implausible.</p>\n<p>Between <a href=\"http://en.wikipedia.org/wiki/Scope_insensitivity\">scope insensitivity</a>, <a href=\"http://en.wikipedia.org/wiki/Affect_heuristic\">the affect heuristic</a>, <a href=\"http://en.wikipedia.org/wiki/Anchoring\">the anchoring effect</a>, <a href=\"http://en.wikipedia.org/wiki/Priming_(psychology)\">the priming effect</a>, <a href=\"http://en.wikipedia.org/wiki/Confirmation_bias\">confirmation bias</a>, <a href=\"http://en.wikipedia.org/wiki/Clustering_illusion\">clustering illusions</a>, <a href=\"http://en.wikipedia.org/wiki/Pareidolia\">pareidolia</a>, <a href=\"http://en.wikipedia.org/wiki/Attentional_bias\">attentional biases</a>, <a href=\"http://en.wikipedia.org/wiki/Availability_heuristic\">the availability heuristic</a>, <a href=\"http://en.wikipedia.org/wiki/Illusory_correlation\">illusory correlations</a>, <a href=\"http://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect\">the Dunning-Kuger effect</a>, <a href=\"http://en.wikipedia.org/wiki/Forer_effect\">the Forer Effect</a>, etc., enough cognitive biases have been documented to fill a book -- indeed, with <a href=\"http://www.amazon.com/dp/0374275637\">Daniel Kahneman's <strong>Thinking Fast and Slow</strong></a>, they actually have! The myth of the rational person has been so thoroughly shattered in so many ways that don't ostensibly relate to intrinsic beliefs, that I don't think CT has much to stand on.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>Thus CT should not be taken as a candidate for a psychological theory without significant improvement -- it is incomplete and inadequate, has flawed methodology, and conflicts well established science. For what it's worth, Leverage Research has had an appropriate lack of confidence in CT. None of their documentation asserts that CT is true, but rather makes it clear that the current evidence is circumstantial, and more data needs to be collected.</p>\n<p>It's also worth noting that CT could be tested via <em>replication</em>, a process in which independent researchers seek to duplicate the results -- if the results can be duplicated, the theory is more likely to be true, and vice versa. Someone could follow the instructions and create a CT chart and see if it could be used to make accurate psychological predictions, especially under controlled circumstances. Personally, I don't want to invest the time needed to preform the replication until CT has stronger legs to stand on and has made an adequate case.</p>\n<h6><span style=\"font-weight: normal;\"><em>&nbsp;(Note: This was cross-posted <a href=\"http://www.greatplay.net/essays/a-critique-of-leverage-researchs-connection-theory\">from my blog</a>.)</em></span></h6>", "sections": [{"title": "Disclaimer", "anchor": "Disclaimer", "level": 1}, {"title": "Connection Theory in More Detail", "anchor": "Connection_Theory_in_More_Detail", "level": 1}, {"title": "The Evidence for Connection Theory", "anchor": "The_Evidence_for_Connection_Theory", "level": 1}, {"title": "Recommendation Tests", "anchor": "Recommendation_Tests", "level": 2}, {"title": "Mind Mapping Tests", "anchor": "Mind_Mapping_Tests", "level": 2}, {"title": "\"Other\"", "anchor": "_Other_", "level": 2}, {"title": "Objection #1: The Case For CT Is Very Incomplete and Inadequate", "anchor": "Objection__1__The_Case_For_CT_Is_Very_Incomplete_and_Inadequate", "level": 1}, {"title": "Objection #2: The Case For CT Uses Flawed Methodology", "anchor": "Objection__2__The_Case_For_CT_Uses_Flawed_Methodology", "level": 1}, {"title": "Objection #3: CT Conflicts With Established Science", "anchor": "Objection__3__CT_Conflicts_With_Established_Science", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "31 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 10, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2012-09-20T04:28:37.011Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-20T04:43:11.062Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Crisis of Faith", "slug": "seq-rerun-crisis-of-faith", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.874Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nMefdwW7AwrfXTojq/seq-rerun-crisis-of-faith", "pageUrlRelative": "/posts/nMefdwW7AwrfXTojq/seq-rerun-crisis-of-faith", "linkUrl": "https://www.lesswrong.com/posts/nMefdwW7AwrfXTojq/seq-rerun-crisis-of-faith", "postedAtFormatted": "Thursday, September 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Crisis%20of%20Faith&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Crisis%20of%20Faith%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMefdwW7AwrfXTojq%2Fseq-rerun-crisis-of-faith%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Crisis%20of%20Faith%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMefdwW7AwrfXTojq%2Fseq-rerun-crisis-of-faith", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMefdwW7AwrfXTojq%2Fseq-rerun-crisis-of-faith", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/ur/crisis_of_faith/\">Crisis of Faith</a> was originally published on 10 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When an idea has become deeply entrenched in your mind, it requires an awful lot of work to doubt that idea properly.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ekp/seq_rerun_shut_up_and_do_the_impossible/\">Shut up and do the impossible!</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nMefdwW7AwrfXTojq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 9.90718152551533e-07, "legacy": true, "legacyId": "18910", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BcYBfG8KomcpcxkEg", "F8oJ4RZEAPAorR7Qx", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-20T09:44:07.943Z", "modifiedAt": null, "url": null, "title": "Any existential risk angles to the US presidential election?", "slug": "any-existential-risk-angles-to-the-us-presidential-election", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:36.291Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/93CAEBq88DGq9WzAW/any-existential-risk-angles-to-the-us-presidential-election", "pageUrlRelative": "/posts/93CAEBq88DGq9WzAW/any-existential-risk-angles-to-the-us-presidential-election", "linkUrl": "https://www.lesswrong.com/posts/93CAEBq88DGq9WzAW/any-existential-risk-angles-to-the-us-presidential-election", "postedAtFormatted": "Thursday, September 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Any%20existential%20risk%20angles%20to%20the%20US%20presidential%20election%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAny%20existential%20risk%20angles%20to%20the%20US%20presidential%20election%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F93CAEBq88DGq9WzAW%2Fany-existential-risk-angles-to-the-us-presidential-election%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Any%20existential%20risk%20angles%20to%20the%20US%20presidential%20election%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F93CAEBq88DGq9WzAW%2Fany-existential-risk-angles-to-the-us-presidential-election", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F93CAEBq88DGq9WzAW%2Fany-existential-risk-angles-to-the-us-presidential-election", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 238, "htmlBody": "<p>Don't let <a href=\"/lw/gw/politics_is_the_mindkiller/\">your minds be killed</a>, but I was wondering if there were any existential risk angles to the coming American election (if there isn't, then I'll simply retreat to raw, enjoyable and empty tribalism).</p>\n<p>I can see three (quite tenuous) angles:</p>\n<ol>\n<li>Obama seems more likely to attempt to get some sort of global warming agreement. While not directly related to Xrisks per se, this would lead to better global coordination and agreement, which improves the outlook for a lot of other Xrisks. However, pretty unlikely to succeed.</li>\n<li>I have a mental image that Republicans would be more likely to invest in space exploration. This is a lot due to Newt Gingrich, I have to admit, and to the closeness between civilian and military space projects, the last of which are more likely to get boosts in Republican governments.</li>\n<li>If we are holding out for increased population rationality as being a helping factor for some Xrisks, then the fact the the Republicans have gone so strongly anti-science is certainly a bad sign. But on the other hand, its not clear whether them winning or losing the election is more likely to improve the general environment for science among their supporters.</li>\n</ol>\n<p>But these all seem weak factors. So, less wronger, let me know: are the things I should care about in the election, or can I just lie back and enjoy it as a piece of interesting theatre?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "93CAEBq88DGq9WzAW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": -16, "extendedScore": null, "score": -2.7e-05, "legacy": true, "legacyId": "18922", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 218, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-20T11:03:48.603Z", "modifiedAt": null, "url": null, "title": "A Mathematical Explanation of Why Charity Donations Shouldn't Be Diversified", "slug": "a-mathematical-explanation-of-why-charity-donations-shouldn", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:02.492Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pJrqGvou8ah8poRn2/a-mathematical-explanation-of-why-charity-donations-shouldn", "pageUrlRelative": "/posts/pJrqGvou8ah8poRn2/a-mathematical-explanation-of-why-charity-donations-shouldn", "linkUrl": "https://www.lesswrong.com/posts/pJrqGvou8ah8poRn2/a-mathematical-explanation-of-why-charity-donations-shouldn", "postedAtFormatted": "Thursday, September 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Mathematical%20Explanation%20of%20Why%20Charity%20Donations%20Shouldn't%20Be%20Diversified&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Mathematical%20Explanation%20of%20Why%20Charity%20Donations%20Shouldn't%20Be%20Diversified%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpJrqGvou8ah8poRn2%2Fa-mathematical-explanation-of-why-charity-donations-shouldn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Mathematical%20Explanation%20of%20Why%20Charity%20Donations%20Shouldn't%20Be%20Diversified%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpJrqGvou8ah8poRn2%2Fa-mathematical-explanation-of-why-charity-donations-shouldn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpJrqGvou8ah8poRn2%2Fa-mathematical-explanation-of-why-charity-donations-shouldn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 913, "htmlBody": "<p style=\"padding-left: 30px;\"><em>There is a standard argument against diversification of donations, popularly explained by Steven Landsburg in the essay <a href=\"http://web.archive.org/web/20110201203530/http://www.slate.com/id/2034/\">Giving Your All</a>. This post is an attempt to communicate a narrow special case of that argument in a form that resists misinterpretation better, for the benefit of people with a bit of mathematical training. Understanding this special case in detail might be useful as a stepping stone to the understanding of the more general argument. (If you already agree that one should donate only to the charity that provides the greatest marginal value, and that it makes sense to talk about the comparison of marginal value of different charities, there is probably no point in reading this post.)<sup>1</sup></em></p>\n<p>Suppose you are considering two charities, one that accomplishes the saving of antelopes, and the other the saving of babies. Depending on how much funding these charities secure, they are able to save respectively <strong>A</strong> antelopes and <strong>B</strong> babies, so the outcome can be described by a point <strong>(A,B)</strong> that specifies both pieces of data.</p>\n<p>Let's say you have a complete transitive preference over possible values of <strong>(A,B)</strong>, that is you can make a comparison between any two points, and if you prefer <strong>(A1,B1)</strong> over <strong>(A2,B2)</strong> and also <strong>(A2,B2)</strong> over <strong>(A3,B3)</strong>, then you prefer <strong>(A1,B1)</strong> over <strong>(A3,B3)</strong>. Let's further suppose that this preference can be represented by a sufficiently smooth real-valued function <strong>U(A,B)</strong>, such that <strong>U(A1,B1)&gt;U(A2,B2)</strong> precisely when you prefer <strong>(A1,B1)</strong> to <strong>(A2,B2)</strong>. <strong>U</strong> doesn't need to be a utility function in the standard sense, since we won't be considering uncertainty, it only needs to represent ordering over individual points, so let's call it \"preference level\".</p>\n<p>Let <strong>A(Ma)</strong> be the dependence of the number of antelopes saved by the Antelopes charity if it attains the level of funding <strong>Ma</strong>, and <strong>B(Mb)</strong> the corresponding function for the Babies charity. (For simplicity, let's work with <strong>U</strong>, <strong>A</strong>, <strong>B</strong>, <strong>Ma</strong> and <strong>Mb</strong> as variables that depend on each other in specified ways.)</p>\n<p>You are considering a decision to donate, and at the moment the charities have already secured <strong>Ma</strong> and <strong>Mb</strong> amounts of money, sufficient to save <strong>A</strong> antelopes and <strong>B</strong> babies, which would result in your preference level <strong>U</strong>. You have a relatively small amount of money <strong>dM</strong> that you want to distribute between these charities. <strong>dM</strong> is such that it's small compared to <strong>Ma</strong> and <strong>Mb</strong>, and if donated to either charity, it will result in changes of <strong>A</strong> and <strong>B</strong> that are small compared to <strong>A</strong> and <strong>B</strong>, and in a change of <strong>U</strong> that is small compared to <strong>U</strong>.<a id=\"more\"></a></p>\n<p>Let's say you split the sum of money <strong>dM</strong> by giving its part <strong>dMa=s&middot;dM</strong> (<strong>0&le;s&le;1</strong>) to A and the remaining part <strong>dMb=(1&minus;s)&middot;dM</strong> to B. The question is then what value of <strong>s</strong> should you choose. Donating everything to A corresponds to <strong>s=1</strong> and donating everything to B corresponds to <strong>s=0</strong>, with values in between corresponding to splitting of the donation.</p>\n<p>Donating <strong>s&middot;dM</strong> to A results in its funding level becoming <strong>Ma+dMa</strong>, or differential funding level of <strong>dMa</strong>, and in <strong>A+dA = A+(&part;A/&part;Ma)&middot;dMa = A+(&part;A/&part;Ma)&middot;s&middot;dM</strong> antelopes getting saved, with differential number of antelopes saved being <strong>(&part;A/&part;Ma)&middot;s&middot;dM</strong>, correspondingly the differential number of babies saved is <strong>(&part;B/&part;Mb)&middot;(1&minus;s)&middot;dM</strong>. This results in the change of preference level <strong>dU = (&part;U/&part;A)&middot;dA+(&part;U/&part;B)&middot;dB = (&part;U/&part;A)&middot;(&part;A/&part;Ma)&middot;s&middot;dM+(&part;U/&part;B)&middot;(&part;B/&part;Mb)&middot;(1&minus;s)&middot;dM</strong>. What you want is to maximize the value of <strong>U+dU</strong>, and since <strong>U</strong> is fixed, you want to maximize the value of <strong>dU</strong>.</p>\n<p>Let's interpret some of the terms in that formula to make better sense of it. <strong>(&part;U/&part;A)</strong> is current marginal value of more antelopes getting saved, according to your preference <strong>U</strong>, correspondingly <strong>(&part;U/&part;B)</strong> is the marginal value of more babies getting saved. <strong>(&part;A/&part;Ma)</strong> is current marginal efficiency of the Antelopes charity at getting antelopes saved for a given unit of money, and <strong>(&part;B/&part;Mb)</strong> is the corresponding value for the Babies charity. Together, <strong>(&part;U/&part;A)&middot;(&part;A/&part;Ma)</strong> is the value you get out of donating a unit of money to charity A, and <strong>(&part;U/&part;B)&middot;(&part;B/&part;Mb)</strong> is the same for charity B. These partial derivatives depend on the current values of <strong>Ma</strong> and <strong>Mb</strong>, so they reflect only the current situation and its response to relatively small changes.</p>\n<p>The parameter you control is <strong>s</strong>, and <strong>dM</strong> is fixed (it's all the money you are willing to donate to both charities together) so let's rearrange the terms in <strong>dU</strong> a bit: <strong>dU = (&part;U/&part;A)&middot;(&part;A/&part;Ma)&middot;s&middot;dM+(&part;U/&part;B)&middot;(&part;B/&part;Mb)&middot;(1&minus;s)&middot;dM = (s&middot;((&part;U/&part;A)&middot;(&part;A/&part;Ma)&minus;(&part;U/&part;B)&middot;(&part;B/&part;Mb))+(&part;U/&part;B)&middot;(&part;B/&part;Mb))&middot;dM = (s&middot;K+L)&middot;dM</strong>, where <strong>K</strong> and <strong>L</strong> are not controllable by your actions (<strong>K = (&part;U/&part;A)&middot;(&part;A/&part;Ma)&minus;(&part;U/&part;B)&middot;(&part;B/&part;Mb)</strong>, <strong>L = (&part;U/&part;B)&middot;(&part;B/&part;Mb)</strong>).</p>\n<p>Since <strong>dM</strong> and <strong>s</strong> are nonnegative, we have two relevant cases in the maximization of <strong>dU=(s&middot;K+L)&middot;dM</strong>: when <strong>K</strong> is positive, and when it's negative. If it's positive, then <strong>dU</strong> is maximized by boosting <strong>K</strong>'s influence as much as possible by setting <strong>s=1</strong>, that is donating all of <strong>dM</strong> to charity A. It it's negative, then <strong>dU</strong> is maximized by reducing <strong>K</strong>'s influence as much as possible by setting <strong>s=0</strong>, that is donating all of <strong>dM</strong> to charity B.</p>\n<p>What does the value of <strong>K</strong> mean? It's the difference between <strong>(&part;U/&part;A)&middot;(&part;A/&part;Ma)</strong> and <strong>(&part;U/&part;B)&middot;(&part;B/&part;Mb)</strong>, that is between the marginal value you get out of donating a unit of money to A and the marginal value of donating to B. The result is that if the marginal value of charity A is greater than the marginal value of charity B, you donate everything to A, otherwise you donate everything to B.</p>\n<p>&nbsp;</p>\n<hr />\n<p><strong>1:</strong> This started as a reply to <a href=\"/lw/ein/open_thread_september_1530_2012/7g3o\">Anatoly Vorobey</a>, but grew into an explanation that I thought might be useful to others in the future, so I turned it into a post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pJrqGvou8ah8poRn2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 6, "extendedScore": null, "score": 9.90914436532036e-07, "legacy": true, "legacyId": "18924", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 66, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-20T18:14:33.437Z", "modifiedAt": null, "url": null, "title": "New study on choice blindness in moral positions", "slug": "new-study-on-choice-blindness-in-moral-positions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:27.421Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nerfhammer", "createdAt": "2009-07-21T19:45:50.831Z", "isAdmin": false, "displayName": "nerfhammer"}, "userId": "TnRcc3ezfxzQs7Phn", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ekkB4qRZ5yFnMwZGr/new-study-on-choice-blindness-in-moral-positions", "pageUrlRelative": "/posts/ekkB4qRZ5yFnMwZGr/new-study-on-choice-blindness-in-moral-positions", "linkUrl": "https://www.lesswrong.com/posts/ekkB4qRZ5yFnMwZGr/new-study-on-choice-blindness-in-moral-positions", "postedAtFormatted": "Thursday, September 20th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20study%20on%20choice%20blindness%20in%20moral%20positions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20study%20on%20choice%20blindness%20in%20moral%20positions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekkB4qRZ5yFnMwZGr%2Fnew-study-on-choice-blindness-in-moral-positions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20study%20on%20choice%20blindness%20in%20moral%20positions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekkB4qRZ5yFnMwZGr%2Fnew-study-on-choice-blindness-in-moral-positions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekkB4qRZ5yFnMwZGr%2Fnew-study-on-choice-blindness-in-moral-positions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 305, "htmlBody": "<p>Change blindness is the phenomenon whereby people fail to notice changes in scenery and whatnot if they're not directed to pay attention to it. There are countless videos online demonstrating this effect (<a href=\"http://www.youtube.com/watch?v=voAntzB7EwE\">one of my favorites here, by Richard Wiseman</a>).</p>\n<p>One of the most audacious and famous experiments is known informally as <a href=\"http://www.youtube.com/watch?v=FWSxSQsspiQ\">\"the door study\"</a>: an experimenter asks a passerby for directions, but is interrupted by a pair of construction workers carrying an unhinged door, concealing another person whom replaces the experimenter as the door passes. Incredibly, the person giving directions rarely notices they are now talking to a completely different person. This effect was reproduced by Derren Brown on British TV (<a href=\"http://www.youtube.com/watch?v=4-HxtKgKrL8\">here's an amateur re-enactment</a>).</p>\n<p>Subsequently a <a href=\"http://www.lucs.lu.se/choice-blindness-group/\">pair of Swedish researchers</a> familiar with some sleight-of-hand magic conceived a new twist on this line of research, arguably even more audacious: have participants make a choice and quietly swap that choice with something else. People not only fail to notice the change, but confabulate reasons why they had preferred the counterfeit choice (<a href=\"http://www.youtube.com/watch?v=wRqyw-EwgTk\">video here</a>). They called their new paradigm \"<em>Choice Blindness</em>\".</p>\n<p>Just recently the same Swedish researchers published a new study that is even more shocking. Rather than demonstrating choice blindness by having participants choose between two photographs, they demonstrated the same effect <strong>with moral propositions</strong>. Participants completed a survey asking them to agree or disagree with statements such as \"<em>large scale governmental surveillance of e-mail and Internet traffic ought to be forbidden as a means to combat international crime and terrorism</em>\". When they reviewed their copy of the survey their responses had been covertly changed, but 69% failed to notice at least one of two changes, and when asked to explain their answers&nbsp;<strong>53% argued in favor of what they falsely believed was their original choice</strong>, when they had previously indicated the opposite moral position (<a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0045457?imageURI=info:doi/10.1371/journal.pone.0045457.t001\">study here</a>, <a href=\"http://vimeo.com/32511676\">video here</a>).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 1, "nSHiKwWyMZFdZg5qt": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ekkB4qRZ5yFnMwZGr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 79, "baseScore": 101, "extendedScore": null, "score": 0.000256, "legacy": true, "legacyId": "18916", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 101, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 152, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T03:41:55.923Z", "modifiedAt": null, "url": null, "title": "Principals, agents, negotiation, and precommitments", "slug": "principals-agents-negotiation-and-precommitments", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.762Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwillen", "createdAt": "2010-02-05T02:13:04.467Z", "isAdmin": false, "displayName": "gwillen"}, "userId": "gtGo7CY7mqFKNAdq3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vPW6qPcjsWoQ6LhHS/principals-agents-negotiation-and-precommitments", "pageUrlRelative": "/posts/vPW6qPcjsWoQ6LhHS/principals-agents-negotiation-and-precommitments", "linkUrl": "https://www.lesswrong.com/posts/vPW6qPcjsWoQ6LhHS/principals-agents-negotiation-and-precommitments", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Principals%2C%20agents%2C%20negotiation%2C%20and%20precommitments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrincipals%2C%20agents%2C%20negotiation%2C%20and%20precommitments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPW6qPcjsWoQ6LhHS%2Fprincipals-agents-negotiation-and-precommitments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Principals%2C%20agents%2C%20negotiation%2C%20and%20precommitments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPW6qPcjsWoQ6LhHS%2Fprincipals-agents-negotiation-and-precommitments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPW6qPcjsWoQ6LhHS%2Fprincipals-agents-negotiation-and-precommitments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 284, "htmlBody": "<p>I'm sure this observation has been made plenty of times before: a principal can gain negotiating power by delegating negotiations to an agent, and restricting that agent's ability to negotiate.</p>\n<p><a id=\"more\"></a>For example: If I'm at a family-owned pizza joint, and I want a slice of pepperoni but all they've got is meat-lover's, I can negotiate for the latter at the price of the former. This is a good deal with well-aligned incentives, and is likely to be accepted. But at a chain restaurant, the employees are not empowered to negotiate: It's the menu prices or nothing. Since I'm aware of their lack of power, and my demand for pizza is not very elastic, I'm likely to give them the higher price.</p>\n<p>If I squint, this looks a lot like a precommitment, on the part of the pizza store, not to negotiate prices. But if they explicitly made such a precommitment, it might turn off customers -- nobody likes to feel like they're getting a bad deal, and a statement of precommitment (e.g. a sign reading \"all prices are final\") is likely to make customers feel marginally negative towards the business by drawing their attention to the money they aren't saving.</p>\n<p>By contrast, the corporate form -- such as the chain store has -- gives this kind of 'precommitment' as a side-effect of the otherwise socially-normal behavior of delegating limited responsibility to employees. Same benefit, but without the drawback, mostly because the practice is socially-accepted.</p>\n<p>Is there any literature that covers this kind of thing further? Particularly the link between precommitment and agents with limited negotating ability.</p>\n<p>(I am sitting in a chain pizza store as I write this. Guess what I wanted to order, and what I got instead?)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YhZLQQKsREKE7fC4F": 1, "TBPFC5fwpkzLB87xJ": 2, "jxMoPnsWXBnDzXBwE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vPW6qPcjsWoQ6LhHS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 33, "extendedScore": null, "score": 7.3e-05, "legacy": true, "legacyId": "18931", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T04:43:27.290Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Ritual", "slug": "seq-rerun-the-ritual", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.744Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ionMrBmDs2sbYQrMe/seq-rerun-the-ritual", "pageUrlRelative": "/posts/ionMrBmDs2sbYQrMe/seq-rerun-the-ritual", "linkUrl": "https://www.lesswrong.com/posts/ionMrBmDs2sbYQrMe/seq-rerun-the-ritual", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Ritual&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Ritual%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FionMrBmDs2sbYQrMe%2Fseq-rerun-the-ritual%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Ritual%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FionMrBmDs2sbYQrMe%2Fseq-rerun-the-ritual", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FionMrBmDs2sbYQrMe%2Fseq-rerun-the-ritual", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>Today's post, <a href=\"/lw/us/the_ritual/\">The Ritual</a> was originally published on 11 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Depiction of crisis of faith in Beisutsukai world.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ela/seq_rerun_crisis_of_faith/\">Crisis of Faith</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ionMrBmDs2sbYQrMe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.914628413092119e-07, "legacy": true, "legacyId": "18932", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kXAb5riiaJNrfR8v8", "nMefdwW7AwrfXTojq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T16:02:38.906Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Brussels, Cambridge MA, Chicago, Madison, Melbourne, Salt Lake City, Sydney, Washington DC", "slug": "weekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.066Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CwJDfG7QRyLXanBu4/weekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "pageUrlRelative": "/posts/CwJDfG7QRyLXanBu4/weekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "linkUrl": "https://www.lesswrong.com/posts/CwJDfG7QRyLXanBu4/weekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Chicago%2C%20Madison%2C%20Melbourne%2C%20Salt%20Lake%20City%2C%20Sydney%2C%20Washington%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Chicago%2C%20Madison%2C%20Melbourne%2C%20Salt%20Lake%20City%2C%20Sydney%2C%20Washington%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwJDfG7QRyLXanBu4%2Fweekly-lw-meetups-austin-brussels-cambridge-ma-chicago%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Chicago%2C%20Madison%2C%20Melbourne%2C%20Salt%20Lake%20City%2C%20Sydney%2C%20Washington%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwJDfG7QRyLXanBu4%2Fweekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwJDfG7QRyLXanBu4%2Fweekly-lw-meetups-austin-brussels-cambridge-ma-chicago", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 489, "htmlBody": "<p><strong>This summary was posted to LW Main on September 14th, and has now been moved to discussion. The current summary is <a href=\"/lw/em1/weekly_lw_meetups_austin_berlin_portland/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/di\">Brussels meetup:&nbsp;<span class=\"date\">15 September 2012 12:00PM</span></a></li>\n<li><a href=\"/meetups/ds\">(Washington DC) Dc Zendo meetup:&nbsp;<span class=\"date\">16 September 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/dl\">Less Wrong Sydney: 17th September: MInd Games:&nbsp;<span class=\"date\">17 September 2012 06:30PM</span></a></li>\n<li><a href=\"/meetups/dm\">Moscow: applied rationality and web resources:&nbsp;<span class=\"date\">29 September 2012 04:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/dk\">Predictions Chi September 15 (September 8 -- cancelled):&nbsp;<span class=\"date\">15 September 2012 01:05PM</span></a></li>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">15 September 2018 01:30PM</span></a></li>\n<li><a href=\"/meetups/d6\">SLC, UT: Free Will and Rationality Checklists:&nbsp;<span class=\"date\">15 September 2012 03:00PM</span></a></li>\n<li><a href=\"/meetups/de\">Cambridge (MA) third-Sundays meetup:&nbsp;<span class=\"date\">16 September 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/dp\">Madison: Reading Group, Seeing with Fresh Eyes:&nbsp;<span class=\"date\">16 September 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/dr\">Melbourne social meetup:&nbsp;<span class=\"date\">21 September 2012 07:00PM</span></a></li>\n<li><a href=\"/meetups/do\">Portland Oregon:&nbsp;<span class=\"date\">22 September 2012 12:00PM</span></a></li>\n<li><a href=\"/meetups/df\">Cambridge (MA) first-Sundays meetup:&nbsp;<span class=\"date\">07 October 2012 02:00PM</span></a></li>\n<li><a href=\"/meetups/dg\">Cambridge (MA) third-Sundays Meetup:&nbsp;<span class=\"date\">21 October 2012 02:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong>&nbsp;</strong><strong></strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>, <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CwJDfG7QRyLXanBu4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.91814360726192e-07, "legacy": true, "legacyId": "18806", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8Lz9awP2W8RyoSBFZ", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T16:27:04.468Z", "modifiedAt": null, "url": null, "title": "Life-changing decisions pertaining to education. Help.", "slug": "life-changing-decisions-pertaining-to-education-help", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.667Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tomme", "createdAt": "2012-03-14T19:51:35.247Z", "isAdmin": false, "displayName": "tomme"}, "userId": "uyGXufxNcB7WRQ63C", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fCa7C5TpysGK6S39t/life-changing-decisions-pertaining-to-education-help", "pageUrlRelative": "/posts/fCa7C5TpysGK6S39t/life-changing-decisions-pertaining-to-education-help", "linkUrl": "https://www.lesswrong.com/posts/fCa7C5TpysGK6S39t/life-changing-decisions-pertaining-to-education-help", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Life-changing%20decisions%20pertaining%20to%20education.%20Help.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALife-changing%20decisions%20pertaining%20to%20education.%20Help.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfCa7C5TpysGK6S39t%2Flife-changing-decisions-pertaining-to-education-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Life-changing%20decisions%20pertaining%20to%20education.%20Help.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfCa7C5TpysGK6S39t%2Flife-changing-decisions-pertaining-to-education-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfCa7C5TpysGK6S39t%2Flife-changing-decisions-pertaining-to-education-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 342, "htmlBody": "<p>I just graduated from high school and I want to continue my formal education by studying for a bachelor's degree in science.</p>\n<p>I can go on to study in: Hungary, England, the USA.</p>\n<p><strong>Hungay.</strong> I'll graduate debt-free and I will spend little on my cost of living(e.g., accommodation, food). However, I'll earn a useless degree in that the university I would attend is poor in terms of academic performance. So, Hungary's a good choice from a financial standpoint, but horrible when it comes to the value of the education.</p>\n<p><strong>USA. </strong>I'll graduate with some negligible debt and I will spend a modest sum of money for my cost of living, but overall it's still affordable. The education I will receive is so-so, but still better than the one in Hungary. The USA is somewhere in between England and Hungary in terms of financial matters and education.</p>\n<p><strong>England</strong>. I'll graduate with the most debt and I won't even afford to pay for accommodation; I'll probably have to squat somewhere. The quality of the education is top-notch.</p>\n<p>It seems that every place I could go on to study involves a trade-off&mdash;England's best for education, Hungary for money.</p>\n<p>Now, another dilemma I've ran into is whether I should study Biology or Medicine. I can study Medicine in Hungary, but not in the USA or in England. I am an introvert and a very private person and I enjoy solitude, so some might argue that Medicine is not the best career path, but I contend that some medical specialties, like Pathology, involve less human contact than others. Biology is also appealing as I think I would thrive on doing pure research. I did some job shadowing at a hospital and I can't tell whether a career in Medicine would make me happy. But I definitely won't be happy being an unemployed biologist or a technician who does the same stuff over and over again.</p>\n<p>Since I'm confused and depressed, I come to you asking for advice about: (1) What and how should I decide to study; (2) Where should I study.</p>\n<p>Thanks for reading!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fCa7C5TpysGK6S39t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 3, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "18938", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T19:59:01.453Z", "modifiedAt": null, "url": null, "title": "What are the best books on evolutionary psychology?", "slug": "what-are-the-best-books-on-evolutionary-psychology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.928Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PuWy22bHm5mdj8zC3/what-are-the-best-books-on-evolutionary-psychology", "pageUrlRelative": "/posts/PuWy22bHm5mdj8zC3/what-are-the-best-books-on-evolutionary-psychology", "linkUrl": "https://www.lesswrong.com/posts/PuWy22bHm5mdj8zC3/what-are-the-best-books-on-evolutionary-psychology", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20the%20best%20books%20on%20evolutionary%20psychology%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20the%20best%20books%20on%20evolutionary%20psychology%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuWy22bHm5mdj8zC3%2Fwhat-are-the-best-books-on-evolutionary-psychology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20the%20best%20books%20on%20evolutionary%20psychology%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuWy22bHm5mdj8zC3%2Fwhat-are-the-best-books-on-evolutionary-psychology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuWy22bHm5mdj8zC3%2Fwhat-are-the-best-books-on-evolutionary-psychology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 164, "htmlBody": "<p>I'd like to divide three classes of reasons to read a discipline:</p>\n<p>1) You are curious and want to begin reading by something 100-500 pages. I'd go for Pinker's 1990's&nbsp; \"How the mind works\"</p>\n<p>2) You want to screen the whole field, by reading something 500-1500 pages. I definitely recommend David Buss 2004 \"The Handbook of Evolutionary Psychology\" which defeats the usual SI recommendations on the field</p>\n<p>3) You want to know the state of the art of the field, so you really need something that is very recent, say from the last 2 or 3 years at most.&nbsp; This is me. Please help me if you know what should I read.&nbsp; 300-1500 seems a good interval.</p>\n<p>Just for a comparative, in Cognitive Neuroscience, 3 would be 2009 \"MIT The Cognitive Neurosciences IV\"</p>\n<p>&nbsp;</p>\n<p>Post your opinions on what 1 2 and 3 should be for Evolutionary Psychology.</p>\n<p>Oh, and if you like Evolutionary Cognitive Neuroscience (a field so new I don't know any of the 3) please post yours too...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PuWy22bHm5mdj8zC3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 7, "extendedScore": null, "score": 9.919367497164107e-07, "legacy": true, "legacyId": "18939", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-21T20:10:39.525Z", "modifiedAt": null, "url": null, "title": "[LINK] Why Your Customers Would Be Happier If You Charged More", "slug": "link-why-your-customers-would-be-happier-if-you-charged-more", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.761Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lincolnquirk", "createdAt": "2011-03-25T20:46:17.071Z", "isAdmin": false, "displayName": "lincolnquirk"}, "userId": "ScJE7nuW8ti5kzfcA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/j6WrfdDWPyGXtTW3d/link-why-your-customers-would-be-happier-if-you-charged-more", "pageUrlRelative": "/posts/j6WrfdDWPyGXtTW3d/link-why-your-customers-would-be-happier-if-you-charged-more", "linkUrl": "https://www.lesswrong.com/posts/j6WrfdDWPyGXtTW3d/link-why-your-customers-would-be-happier-if-you-charged-more", "postedAtFormatted": "Friday, September 21st 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Why%20Your%20Customers%20Would%20Be%20Happier%20If%20You%20Charged%20More&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Why%20Your%20Customers%20Would%20Be%20Happier%20If%20You%20Charged%20More%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6WrfdDWPyGXtTW3d%2Flink-why-your-customers-would-be-happier-if-you-charged-more%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Why%20Your%20Customers%20Would%20Be%20Happier%20If%20You%20Charged%20More%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6WrfdDWPyGXtTW3d%2Flink-why-your-customers-would-be-happier-if-you-charged-more", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6WrfdDWPyGXtTW3d%2Flink-why-your-customers-would-be-happier-if-you-charged-more", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 218, "htmlBody": "<p><a href=\"http://www.kalzumeus.com/2012/09/21/ramit-sethi-and-patrick-mckenzie-on-why-your-customers-would-be-happier-if-you-charged-more/\">http://www.kalzumeus.com/2012/09/21/ramit-sethi-and-patrick-mckenzie-on-why-your-customers-would-be-happier-if-you-charged-more/</a></p>\n<p>Surprising material to discover on Less Wrong, I know, but has some core insights about effectiveness and entrepreneurship and freelancing which I think people here will appreciate.</p>\n<p>Quotes:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p style=\"font-family: arial, sans-serif; font-size: 13px;\">So you have to understand that if you make an amazing product and you&rsquo;ve tested it and you know it will help, it is your obligation to get it out to the market as aggressively as possible.</p>\n<p style=\"font-family: arial, sans-serif; font-size: 13px;\"><strong>[Patrick notes:&nbsp;</strong>I think this is important enough to emphasize, twice. If you got into this business to make peoples&rsquo; lives better, and you have produced something which will succeed with that, and you are aware of truth about reality such as &ldquo;better marketed products beat better engineered products every single bloody time&rdquo;, then you have an&nbsp;<em>obligation</em>&nbsp;to get better at marketing yourself. To do otherwise is to&nbsp;<em>compromise the value of your offering to the world</em>&nbsp;based on selfish desires such as appeasing your own vanity (&ldquo;Everyone should realize how great my work is without me needing to tell them&rdquo;) or indulging your own unspoken fears (&ldquo;If this were really good, it would sell itself, so if I try selling it, it must not be good.&rdquo;)<strong>]</strong></p>\n</blockquote>\n<p style=\"font-family: arial, sans-serif; font-size: 13px;\"><strong><br /></strong></p>\n<blockquote>\n<p style=\"font-family: arial, sans-serif; font-size: 13px;\">I was inventing excuses &ndash; in real time! &ndash; as to why I couldn&rsquo;t have possibly delivered the value he already reported having gotten from the conversation we just had.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "j6WrfdDWPyGXtTW3d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": 9.919427744367742e-07, "legacy": true, "legacyId": "18940", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-22T04:35:27.325Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Why Does Power Corrupt?", "slug": "seq-rerun-why-does-power-corrupt", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:38.221Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xn9E3LDSqmhwGCoD7/seq-rerun-why-does-power-corrupt", "pageUrlRelative": "/posts/xn9E3LDSqmhwGCoD7/seq-rerun-why-does-power-corrupt", "linkUrl": "https://www.lesswrong.com/posts/xn9E3LDSqmhwGCoD7/seq-rerun-why-does-power-corrupt", "postedAtFormatted": "Saturday, September 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Why%20Does%20Power%20Corrupt%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Why%20Does%20Power%20Corrupt%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxn9E3LDSqmhwGCoD7%2Fseq-rerun-why-does-power-corrupt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Why%20Does%20Power%20Corrupt%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxn9E3LDSqmhwGCoD7%2Fseq-rerun-why-does-power-corrupt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxn9E3LDSqmhwGCoD7%2Fseq-rerun-why-does-power-corrupt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<p>Today's post, <a href=\"/lw/uu/why_does_power_corrupt/\">Why Does Power Corrupt?</a> was originally published on 14 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Why_Does_Power_Corrupt.3F\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>There are simple evolutionary reasons why power corrupts humans. They can be beaten, though.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/elw/seq_rerun_the_ritual/\">The Ritual</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xn9E3LDSqmhwGCoD7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "18947", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["v8rghtzWCziYuMdJ5", "ionMrBmDs2sbYQrMe", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-22T13:14:23.668Z", "modifiedAt": null, "url": null, "title": "Meetup : Vienna meetup", "slug": "meetup-vienna-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:57.075Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MfDeEbZqFhQzTwxwi/meetup-vienna-meetup", "pageUrlRelative": "/posts/MfDeEbZqFhQzTwxwi/meetup-vienna-meetup", "linkUrl": "https://www.lesswrong.com/posts/MfDeEbZqFhQzTwxwi/meetup-vienna-meetup", "postedAtFormatted": "Saturday, September 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vienna%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vienna%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfDeEbZqFhQzTwxwi%2Fmeetup-vienna-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vienna%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfDeEbZqFhQzTwxwi%2Fmeetup-vienna-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMfDeEbZqFhQzTwxwi%2Fmeetup-vienna-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e0'>Vienna meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 September 2012 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Favoritenstra\u00dfe 55, 110  Vienna, Austria</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Let's have a meetup in Vienna!</p>\n\n<p>The Cafe Illy at Favoritenstra\u00dfe 55 is on the southeast corner of Favoritenstra\u00dfe and Johannitergasse. You can take the underground line U1 to the S\u00fcdtiroler Platz station. Inside the station, follow the \"Bahnorama\" signs to get to the southern exit. Then walk south through the construction site to get to Favoritenstra\u00dfe.</p>\n\n<p>Alternatively, you can take U1 to Keplerplatz and simply walk north to the intersection with Johannitergasse.</p>\n\n<p>I will be sitting inside at 19:00 with a sign that says \"Less Wrong\". I look forward to meeting you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e0'>Vienna meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MfDeEbZqFhQzTwxwi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 9.924731512621416e-07, "legacy": true, "legacyId": "18956", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vienna_meetup\">Discussion article for the meetup : <a href=\"/meetups/e0\">Vienna meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 September 2012 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Favoritenstra\u00dfe 55, 110  Vienna, Austria</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Let's have a meetup in Vienna!</p>\n\n<p>The Cafe Illy at Favoritenstra\u00dfe 55 is on the southeast corner of Favoritenstra\u00dfe and Johannitergasse. You can take the underground line U1 to the S\u00fcdtiroler Platz station. Inside the station, follow the \"Bahnorama\" signs to get to the southern exit. Then walk south through the construction site to get to Favoritenstra\u00dfe.</p>\n\n<p>Alternatively, you can take U1 to Keplerplatz and simply walk north to the intersection with Johannitergasse.</p>\n\n<p>I will be sitting inside at 19:00 with a sign that says \"Less Wrong\". I look forward to meeting you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vienna_meetup1\">Discussion article for the meetup : <a href=\"/meetups/e0\">Vienna meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vienna meetup", "anchor": "Discussion_article_for_the_meetup___Vienna_meetup", "level": 1}, {"title": "Discussion article for the meetup : Vienna meetup", "anchor": "Discussion_article_for_the_meetup___Vienna_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-22T15:17:29.793Z", "modifiedAt": null, "url": null, "title": "RFC: A Self-quantification Essay (ongoing draft)", "slug": "rfc-a-self-quantification-essay-ongoing-draft", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:57.198Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hackerkiba", "createdAt": "2010-09-17T02:45:39.493Z", "isAdmin": false, "displayName": "hackerkiba"}, "userId": "LssGgJYPEsFHPwyLy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2v7LRYi56nuW6G8bH/rfc-a-self-quantification-essay-ongoing-draft", "pageUrlRelative": "/posts/2v7LRYi56nuW6G8bH/rfc-a-self-quantification-essay-ongoing-draft", "linkUrl": "https://www.lesswrong.com/posts/2v7LRYi56nuW6G8bH/rfc-a-self-quantification-essay-ongoing-draft", "postedAtFormatted": "Saturday, September 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20RFC%3A%20A%20Self-quantification%20Essay%20(ongoing%20draft)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARFC%3A%20A%20Self-quantification%20Essay%20(ongoing%20draft)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v7LRYi56nuW6G8bH%2Frfc-a-self-quantification-essay-ongoing-draft%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=RFC%3A%20A%20Self-quantification%20Essay%20(ongoing%20draft)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v7LRYi56nuW6G8bH%2Frfc-a-self-quantification-essay-ongoing-draft", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v7LRYi56nuW6G8bH%2Frfc-a-self-quantification-essay-ongoing-draft", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<p>I am not the best writer on the block, but I been working on a <a href=\"http://kibabase.com/articles/self-quantification\">self quantification essay</a>.&nbsp;It is of interest to lesswrongers since it is about &nbsp;It's about applying epistemic and instrumental rationality to self improvement in the form of running scientific experiments and data analysis on one self.</p>\n<p>If you have any criticism or comment, let me know. Also, it needs grammar fixing since I suck at grammar. Thanks.</p>\n<p>&nbsp;</p>\n<p>Be advised that the essay is undergoing&nbsp;continuous&nbsp;revisions. Some of the content may change drastically.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2v7LRYi56nuW6G8bH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 9.925369617717929e-07, "legacy": true, "legacyId": "18957", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-22T15:50:22.934Z", "modifiedAt": null, "url": null, "title": "[link] Betting on bad futures", "slug": "link-betting-on-bad-futures", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.609Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fortyeridania", "createdAt": "2010-07-21T15:35:12.558Z", "isAdmin": false, "displayName": "fortyeridania"}, "userId": "roBPqtzsvG6dC3YFT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oKqsCP82KNWFio6sf/link-betting-on-bad-futures", "pageUrlRelative": "/posts/oKqsCP82KNWFio6sf/link-betting-on-bad-futures", "linkUrl": "https://www.lesswrong.com/posts/oKqsCP82KNWFio6sf/link-betting-on-bad-futures", "postedAtFormatted": "Saturday, September 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Betting%20on%20bad%20futures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Betting%20on%20bad%20futures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoKqsCP82KNWFio6sf%2Flink-betting-on-bad-futures%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Betting%20on%20bad%20futures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoKqsCP82KNWFio6sf%2Flink-betting-on-bad-futures", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoKqsCP82KNWFio6sf%2Flink-betting-on-bad-futures", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p><a href=\"http://economics.gmu.edu/people/gjonesb\">Garett Jones</a>, an economist at George Mason University and guest blogger for <a href=\"http://econlog.econlib.org/\">EconLog</a>, suggests a way for people to bet on apocalyptic events:</p>\r\n<p><a href=\"http://econlog.econlib.org/archives/2012/09/how_to_bet_on_b.html\">http://econlog.econlib.org/archives/2012/09/how_to_bet_on_b.html</a></p>\r\n<p>The basic idea:</p>\r\n<p>Suppose Alice and Bob disagree on whether the world will end a year from tomorrow, with Alice believing it will end. If she is right, then there will be no way to settle the bet, what with the apocalypse and all that. Thus there is no way for her to collect, and so she has no incentive to bet on the apocalypse, no matter how certain she is.</p>\r\n<p>Or so it would seem! The way around the difficulty is simply for Alice to get her money today, and enjoy it for a year. If she turns out to have been right, then she will have been paid properly. If the world doesn't end, then of course she'll have to return the money, plus interest--plus a penalty for being wrong.</p>\r\n<p>The actual terms should depend on the confidence Alice and Bob place in their respective positions.</p>\r\n<p>Personal note: Several people at my place of work have told me that they are worried about the world ending later this year. They saw <a href=\"http://www.imdb.com/title/tt1190080/\">a movie</a> about it, or something. So far, they have rejected my bet proposals.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E8PHMuf7tsr8teXAe": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oKqsCP82KNWFio6sf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 27, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "18958", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-22T21:34:08.557Z", "modifiedAt": null, "url": null, "title": "Meetup : Research Triangle Area Less Wrong", "slug": "meetup-research-triangle-area-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:05.760Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ELHoaTazdsJutkjMt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mahq7jpPs5zDuuwKH/meetup-research-triangle-area-less-wrong", "pageUrlRelative": "/posts/Mahq7jpPs5zDuuwKH/meetup-research-triangle-area-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/Mahq7jpPs5zDuuwKH/meetup-research-triangle-area-less-wrong", "postedAtFormatted": "Saturday, September 22nd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Research%20Triangle%20Area%20Less%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Research%20Triangle%20Area%20Less%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMahq7jpPs5zDuuwKH%2Fmeetup-research-triangle-area-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Research%20Triangle%20Area%20Less%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMahq7jpPs5zDuuwKH%2Fmeetup-research-triangle-area-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMahq7jpPs5zDuuwKH%2Fmeetup-research-triangle-area-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e1'>Research Triangle Area Less Wrong</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 October 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Francesca's Dessert Cafe 706 9th St Durham, NC 27705\u200e</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll get together and play Zendo, with interspersed discussion of the biases involved. We'll also determine readings for future groups</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e1'>Research Triangle Area Less Wrong</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mahq7jpPs5zDuuwKH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 9.927322430317631e-07, "legacy": true, "legacyId": "18959", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Area_Less_Wrong\">Discussion article for the meetup : <a href=\"/meetups/e1\">Research Triangle Area Less Wrong</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 October 2012 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Francesca's Dessert Cafe 706 9th St Durham, NC 27705\u200e</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll get together and play Zendo, with interspersed discussion of the biases involved. We'll also determine readings for future groups</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Area_Less_Wrong1\">Discussion article for the meetup : <a href=\"/meetups/e1\">Research Triangle Area Less Wrong</a></h2>", "sections": [{"title": "Discussion article for the meetup : Research Triangle Area Less Wrong", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Area_Less_Wrong", "level": 1}, {"title": "Discussion article for the meetup : Research Triangle Area Less Wrong", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Area_Less_Wrong1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T00:05:45.858Z", "modifiedAt": null, "url": null, "title": "Memes?", "slug": "memes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.836Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Crystalist", "createdAt": "2012-08-03T09:14:54.158Z", "isAdmin": false, "displayName": "Crystalist"}, "userId": "fmFNZemrwWrtGNfv3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m8umj7J4QHrwF3SgM/memes", "pageUrlRelative": "/posts/m8umj7J4QHrwF3SgM/memes", "linkUrl": "https://www.lesswrong.com/posts/m8umj7J4QHrwF3SgM/memes", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Memes%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMemes%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8umj7J4QHrwF3SgM%2Fmemes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Memes%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8umj7J4QHrwF3SgM%2Fmemes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm8umj7J4QHrwF3SgM%2Fmemes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 504, "htmlBody": "<p style=\"padding-left: 30px;\">\"All models are wrong, but some are useful\" &mdash; George E. P. Box</p>\n<p>As a student of linguistics, I&rsquo;ve run into the idea of a meme quite a lot. I&rsquo;ve even looked into some of the proposed mathematical models for how they transmit across generations.</p>\n<p>And it certainly is a compelling idea, not least because the potential for modeling cultural evolution alone is incredible. But while I was researching the idea (and admittedly, this was some time ago; I could well be out of date) I never once saw a test of the model. Oh, there were several proposed applications, and a few people were playing around with models borrowed from population genetics, but I saw no proof of concept.</p>\n<p>This became more of a problem when I tried to make the idea <a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">pay rent</a>. I don&rsquo;t think anyone disputes that ideas, behaviors, etc. are transmitted across and within generations, or that these ideas, behaviors, etc. change over time. As I understand it, though, memetics argues that these ideas and behaviors change over time in a pattern analogous to the way that genes change.</p>\n<p>The most obvious problem with this is that genes can be broken down into discrete units. What&rsquo;s the fundamental unit of an idea? Of course, in a sense, we could think of the idea as discrete, if we look at the neural pattern it&rsquo;s being stored as. This exact pattern is not necessarily transmitted through whatever channel(s) you&rsquo;re using to communicate it &mdash; the pattern that forms in someone else&rsquo;s brain could be different. But having a mechanism of reproduction isn&rsquo;t so important as showing a pattern to the results of that reproduction: after all, Darwin had no mechanism, and yet we think of him as one of the key figures in discovering evolution.</p>\n<p>But I haven&rsquo;t seen evidence for the assertion that memes change through time like genes. I have seen anecdotes and examples of ideas and behaviors that have spread through a culture, but no evidence that the pattern is the same. I haven&rsquo;t even seen a clear way of identifying a meme, observing it&rsquo;s reproduction, or tracking its offspring. Not so much as a study on the change of frequency of memes in an isolated population. Memetics today has less evidence than Darwin did when he started out; at least Darwin could point to discrete entities that were changing.</p>\n<p>Without this sort of evidence, all the concept of a meme gives me is that ideas and behaviors can get transmitted, and that they can change. And I don&rsquo;t need a new concept for that. Every now and then I&rsquo;ll run a search on memetics just to see if anyone&rsquo;s tried to address these problems &mdash; after all, a model describing how the frequency of ideas change in a population could be extremely useful to me &mdash; but so far I&rsquo;ve seen nothing, and I don&rsquo;t usually have the time to run a truly thorough search.</p>\n<p>If any of you have, and if you know of evidence for the concept, please send me a link.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"T4GgauaEfp6dHsR5P": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m8umj7J4QHrwF3SgM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 9.92810874155841e-07, "legacy": true, "legacyId": "18960", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a7n8GdKiAZRX86T5A"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T01:25:48.023Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver", "slug": "meetup-vancouver", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:54.988Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LmaLEqN2FqQiBjBmz/meetup-vancouver", "pageUrlRelative": "/posts/LmaLEqN2FqQiBjBmz/meetup-vancouver", "linkUrl": "https://www.lesswrong.com/posts/LmaLEqN2FqQiBjBmz/meetup-vancouver", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLmaLEqN2FqQiBjBmz%2Fmeetup-vancouver%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLmaLEqN2FqQiBjBmz%2Fmeetup-vancouver", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLmaLEqN2FqQiBjBmz%2Fmeetup-vancouver", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e2'>Vancouver</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 September 2012 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">885 west georgia vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Last meetup was fun, it's almost time for the next!</p>\n\n<p>Meet us in the lobby of 885 west georgia at 18:00 on thursday. Better to be early than late. We go upstairs at about 18:30, after which it will be very difficult to meet up with us. Come on out.</p>\n\n<p>I'll be leading a discussion of Yvain's <a href=\"http://lesswrong.com/lw/7am/rational_home_buying/\">rational home buying</a> and <a href=\"http://lesswrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">disolving questions about desiese</a> because they are such good examples of LW ideas in action.</p>\n\n<p>Last time, I presented <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">Letting Go from HTACYM</a>. The consensus on the\nLetting Go sequence was that it was a bag of tricks and inspiration for dealing with the\nneed to face reality (when you are trying to actually change the world).\nWe had a lot of discussion of what you can expect from other people vs\nwhat you expect from yourself, dealing with emotions, value of\npredictive vs descriptive explanations, some rationality fundamentals,\nsome fun math proofs, etc.</p>\n\n<p>Hopefully we'll have some more cool discussion and maybe even some application of these ideas to our own lives.</p>\n\n<p>As usual, join us on the <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a>. Be there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e2'>Vancouver</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LmaLEqN2FqQiBjBmz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 9.92852385362393e-07, "legacy": true, "legacyId": "18961", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver\">Discussion article for the meetup : <a href=\"/meetups/e2\">Vancouver</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 September 2012 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">885 west georgia vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Last meetup was fun, it's almost time for the next!</p>\n\n<p>Meet us in the lobby of 885 west georgia at 18:00 on thursday. Better to be early than late. We go upstairs at about 18:30, after which it will be very difficult to meet up with us. Come on out.</p>\n\n<p>I'll be leading a discussion of Yvain's <a href=\"http://lesswrong.com/lw/7am/rational_home_buying/\">rational home buying</a> and <a href=\"http://lesswrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">disolving questions about desiese</a> because they are such good examples of LW ideas in action.</p>\n\n<p>Last time, I presented <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">Letting Go from HTACYM</a>. The consensus on the\nLetting Go sequence was that it was a bag of tricks and inspiration for dealing with the\nneed to face reality (when you are trying to actually change the world).\nWe had a lot of discussion of what you can expect from other people vs\nwhat you expect from yourself, dealing with emotions, value of\npredictive vs descriptive explanations, some rationality fundamentals,\nsome fun math proofs, etc.</p>\n\n<p>Hopefully we'll have some more cool discussion and maybe even some application of these ideas to our own lives.</p>\n\n<p>As usual, join us on the <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a>. Be there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver1\">Discussion article for the meetup : <a href=\"/meetups/e2\">Vancouver</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver", "anchor": "Discussion_article_for_the_meetup___Vancouver", "level": 1}, {"title": "Discussion article for the meetup : Vancouver", "anchor": "Discussion_article_for_the_meetup___Vancouver1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YSWa8rYeD3aDaofSP", "895quRDaK6gR2rM82"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T02:06:02.191Z", "modifiedAt": null, "url": null, "title": "High School Lecture - Report", "slug": "high-school-lecture-report", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.872Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Xece", "createdAt": "2011-09-03T19:16:00.923Z", "isAdmin": false, "displayName": "Xece"}, "userId": "q85BLJerfn3EGYQgA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R7stnnwWZDqxmfqge/high-school-lecture-report", "pageUrlRelative": "/posts/R7stnnwWZDqxmfqge/high-school-lecture-report", "linkUrl": "https://www.lesswrong.com/posts/R7stnnwWZDqxmfqge/high-school-lecture-report", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20High%20School%20Lecture%20-%20Report&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHigh%20School%20Lecture%20-%20Report%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR7stnnwWZDqxmfqge%2Fhigh-school-lecture-report%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=High%20School%20Lecture%20-%20Report%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR7stnnwWZDqxmfqge%2Fhigh-school-lecture-report", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR7stnnwWZDqxmfqge%2Fhigh-school-lecture-report", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 308, "htmlBody": "<p>This post is a followup report to <a href=\"/r/discussion/lw/eiy/high_school_lectures/\">this</a>.</p>\n<p>&nbsp;</p>\n<p>On Friday's lecture, I was able to briefly cover several topics as an introduction. They centred around rationality (what it is), truth (what it is and why we should pursue it), and Newcomb's Paradox.</p>\n<p>The turnout was as expected (6 out of a total 7 group members, with 1 having other obligations that day). Throughout the talk I would ask for some proposed definitions before giving them. It is unfortunate when I asked what \"truth\" is, mysterious answers such as \"truth is the meaning of life\", and \"truth is the pursuit of truth\". When asked what they meant by their answers, they either rephrased what they said with the same vagueness or were unable to give an answer. One member, however, did say that \"Truth is what is real\", only to have other members ask what he meant by \"real\". It offered a rather nice opportunity for a map-and-territory tangent before giving some version of \"The Simple Truth\".</p>\n<p>I used the definitions given in 'What Do We Mean By \"Rationality\"?' to describe epistemic and instrumental rationality, and gave several examples as to what rationality is not (Dr. Spock, logic/reason, etc). As a practice, I introduced Newcomb's Paradox. There was ample debate with an even split between one-box and two-boxers. Due to time constraints, we weren't able to come to a conclusion (although the one-boxing side was making a stronger argument). By the end of lunch period, everyone seemed to have a good grasp that rationality is simply making the best decision to achieve one's goals, whatever they may be.</p>\n<p>Overall, I'd say it was successful. My next turn is on October 3rd, and apart from a little review, I'm going to go over the 5-second level, and use of words. Saying what they mean is something we as a group need to work on.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7ow6EFpypbH4hzFuz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R7stnnwWZDqxmfqge", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 31, "extendedScore": null, "score": 9.928732551624333e-07, "legacy": true, "legacyId": "18962", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dXgb3BoBNifDP4LEG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T05:42:24.475Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Ends Don't Justify Means (Among Humans)", "slug": "seq-rerun-ends-don-t-justify-means-among-humans", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.520Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ntkH89kYk7PTJ2XuM/seq-rerun-ends-don-t-justify-means-among-humans", "pageUrlRelative": "/posts/ntkH89kYk7PTJ2XuM/seq-rerun-ends-don-t-justify-means-among-humans", "linkUrl": "https://www.lesswrong.com/posts/ntkH89kYk7PTJ2XuM/seq-rerun-ends-don-t-justify-means-among-humans", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Ends%20Don't%20Justify%20Means%20(Among%20Humans)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Ends%20Don't%20Justify%20Means%20(Among%20Humans)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntkH89kYk7PTJ2XuM%2Fseq-rerun-ends-don-t-justify-means-among-humans%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Ends%20Don't%20Justify%20Means%20(Among%20Humans)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntkH89kYk7PTJ2XuM%2Fseq-rerun-ends-don-t-justify-means-among-humans", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FntkH89kYk7PTJ2XuM%2Fseq-rerun-ends-don-t-justify-means-among-humans", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p>Today's post, <a href=\"/lw/uv/ends_dont_justify_means_among_humans/\">Ends Don't Justify Means (Among Humans)</a> was originally published on 14 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>There may be consequentialist reasons for why humans should not reason in an explicitly consequentialist way. We are running on corrupted hardware, and it may seem to us that something benefits others when it does not.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/emb/seq_rerun_why_does_power_corrupt/\">Why Does Power Corrupt?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ntkH89kYk7PTJ2XuM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "18964", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K9ZaZXDnL3SEmYZqB", "xn9E3LDSqmhwGCoD7", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T10:33:06.994Z", "modifiedAt": null, "url": null, "title": "No Anthropic Evidence", "slug": "no-anthropic-evidence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:05.847Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Nesov", "createdAt": "2009-02-27T09:55:13.458Z", "isAdmin": false, "displayName": "Vladimir_Nesov"}, "userId": "qf77EiaoMw7tH3GSr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tzjWC9Lvqfe454Ttc/no-anthropic-evidence", "pageUrlRelative": "/posts/tzjWC9Lvqfe454Ttc/no-anthropic-evidence", "linkUrl": "https://www.lesswrong.com/posts/tzjWC9Lvqfe454Ttc/no-anthropic-evidence", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20No%20Anthropic%20Evidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANo%20Anthropic%20Evidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtzjWC9Lvqfe454Ttc%2Fno-anthropic-evidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=No%20Anthropic%20Evidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtzjWC9Lvqfe454Ttc%2Fno-anthropic-evidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtzjWC9Lvqfe454Ttc%2Fno-anthropic-evidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 513, "htmlBody": "<p><strong>Closely related to:</strong> <a href=\"/lw/u5/how_many_lhc_failures_is_too_many/\">How Many LHC Failures Is Too Many?</a></p>\n<p>Consider the following thought experiment. At the start, an \"original\" coin is tossed, but not shown. If it was \"tails\", a gun is loaded, otherwise it's not. After that, you are offered a big number of rounds of decision, where in each one you can either quit the game, or toss a coin of your own. If your coin falls \"tails\", the gun gets triggered, and depending on how the original coin fell (whether the gun was loaded), you either get shot or not (if the gun doesn't fire, i.e. if the original coin was \"heads\", you are free to go). If your coin is \"heads\", you are all right for the round. If you quit the game, you will get shot at the exit with probability 75% independently of what was happening during the game (and of the original coin). The question is, should you keep playing or quit if you observe, say, 1000 \"heads\" in a row?</p>\n<p>Intuitively, it seems as if 1000 \"heads\" is \"anthropic evidence\" for the original coin being \"tails\", that the long sequence of \"heads\" can only be explained by the fact that \"tails\" would have killed you. If you know that the original coin was \"tails\", then to keep playing is to face the certainty of eventually tossing \"tails\" and getting shot, which is worse than quitting, with only 75% chance of death. Thus, it seems preferable to quit.</p>\n<p>On the other hand, each \"heads\" you observe doesn't distinguish the hypothetical where the original coin was \"heads\" from one where it was \"tails\". The first round can be modeled by a 4-element finite probability space consisting of options {HH, HT, TH, TT}, where HH and HT correspond to the original coin being \"heads\" and HH and TH to the coin-for-the-round being \"heads\". Observing \"heads\" is the event {HH, TH} that has the same 50% posterior probabilities for \"heads\" and \"tails\" of the original coin. Thus, each round that ends in \"heads\" doesn't change the knowledge about the original coin, even if there were 1000 rounds of this type. And since you only get shot if the original coin was \"tails\", you only get to 50% probability of dying as the game continues, which is better than the 75% from quitting the game.</p>\n<p>(See also the comments by <a href=\"/lw/u5/how_many_lhc_failures_is_too_many/neg\">simon2</a> and <a href=\"/lw/u5/how_many_lhc_failures_is_too_many/net\">Benja Fallenstein</a> on the LHC post, and <a href=\"/lw/u5/how_many_lhc_failures_is_too_many/tjg\">this thought experiment</a> by Benja Fallenstein.)</p>\n<p>The result of this exercise could be generalized by saying that counterfactual possibility of dying doesn't in itself influence the conclusions that can be drawn from observations that happened within the hypotheticals where one didn't die. Only if the possibility of dying influences the probability of observations that did take place, would it be possible to detect that possibility. For example, if in the above exercise, a loaded gun would cause the coin to become biased in a known way, only then would it be possible to detect the state of the gun (1000 \"heads\" would imply either that the gun is likely loaded, or that it's likely not).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tzjWC9Lvqfe454Ttc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 19, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "18965", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jE3npTEBtHnZBuAcg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-23T19:20:35.283Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison: Generating More Ideas", "slug": "meetup-madison-generating-more-ideas", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jJ9CPB65BkQKxMBdP/meetup-madison-generating-more-ideas", "pageUrlRelative": "/posts/jJ9CPB65BkQKxMBdP/meetup-madison-generating-more-ideas", "linkUrl": "https://www.lesswrong.com/posts/jJ9CPB65BkQKxMBdP/meetup-madison-generating-more-ideas", "postedAtFormatted": "Sunday, September 23rd 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%3A%20Generating%20More%20Ideas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%3A%20Generating%20More%20Ideas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJ9CPB65BkQKxMBdP%2Fmeetup-madison-generating-more-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%3A%20Generating%20More%20Ideas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJ9CPB65BkQKxMBdP%2Fmeetup-madison-generating-more-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjJ9CPB65BkQKxMBdP%2Fmeetup-madison-generating-more-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 81, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e3'>Madison: Generating More Ideas</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">4371 Doncaster Dr, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We've discussed some methods and basic principles for idea generation.</p>\n\n<p>But, of course, there are more!</p>\n\n<p>I'll review what we've discussed before about straightforward, rapid, \"make a list\" idea generation, and introduce some other methods; in particular, DeBono's \"concept fan\" and \"provocations\". And, of course, we'll actually try these out a few times.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e3'>Madison: Generating More Ideas</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jJ9CPB65BkQKxMBdP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 9.934101283250726e-07, "legacy": true, "legacyId": "18966", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison__Generating_More_Ideas\">Discussion article for the meetup : <a href=\"/meetups/e3\">Madison: Generating More Ideas</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 September 2012 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">4371 Doncaster Dr, Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We've discussed some methods and basic principles for idea generation.</p>\n\n<p>But, of course, there are more!</p>\n\n<p>I'll review what we've discussed before about straightforward, rapid, \"make a list\" idea generation, and introduce some other methods; in particular, DeBono's \"concept fan\" and \"provocations\". And, of course, we'll actually try these out a few times.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison__Generating_More_Ideas1\">Discussion article for the meetup : <a href=\"/meetups/e3\">Madison: Generating More Ideas</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison: Generating More Ideas", "anchor": "Discussion_article_for_the_meetup___Madison__Generating_More_Ideas", "level": 1}, {"title": "Discussion article for the meetup : Madison: Generating More Ideas", "anchor": "Discussion_article_for_the_meetup___Madison__Generating_More_Ideas1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T03:48:51.862Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Entangled Truths, Contagious Lies", "slug": "seq-rerun-entangled-truths-contagious-lies", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:55.236Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2qEdwD5hxzhgCjwgi/seq-rerun-entangled-truths-contagious-lies", "pageUrlRelative": "/posts/2qEdwD5hxzhgCjwgi/seq-rerun-entangled-truths-contagious-lies", "linkUrl": "https://www.lesswrong.com/posts/2qEdwD5hxzhgCjwgi/seq-rerun-entangled-truths-contagious-lies", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Entangled%20Truths%2C%20Contagious%20Lies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Entangled%20Truths%2C%20Contagious%20Lies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qEdwD5hxzhgCjwgi%2Fseq-rerun-entangled-truths-contagious-lies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Entangled%20Truths%2C%20Contagious%20Lies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qEdwD5hxzhgCjwgi%2Fseq-rerun-entangled-truths-contagious-lies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qEdwD5hxzhgCjwgi%2Fseq-rerun-entangled-truths-contagious-lies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>Today's post, <a href=\"/lw/uw/entangled_truths_contagious_lies/\">Entangled Truths, Contagious Lies</a> was originally published on 15 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Given that things are often entangled with other things in ways which we do not know, it is really really difficult to tell a perfect lie.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ems/seq_rerun_ends_dont_justify_means_among_humans/\">Ends Don't Justify Means (Among Humans)</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2qEdwD5hxzhgCjwgi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 9.93674082921397e-07, "legacy": true, "legacyId": "18967", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wyyfFfaRar2jEdeQK", "ntkH89kYk7PTJ2XuM", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T05:24:08.248Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne, practical rationality", "slug": "meetup-melbourne-practical-rationality-7", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fa5MuaCocYWwP69Lo/meetup-melbourne-practical-rationality-7", "pageUrlRelative": "/posts/fa5MuaCocYWwP69Lo/meetup-melbourne-practical-rationality-7", "linkUrl": "https://www.lesswrong.com/posts/fa5MuaCocYWwP69Lo/meetup-melbourne-practical-rationality-7", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%2C%20practical%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%2C%20practical%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffa5MuaCocYWwP69Lo%2Fmeetup-melbourne-practical-rationality-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%2C%20practical%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffa5MuaCocYWwP69Lo%2Fmeetup-melbourne-practical-rationality-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffa5MuaCocYWwP69Lo%2Fmeetup-melbourne-practical-rationality-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e4'>Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 October 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">55 Walsh St West Melbourne 3003 Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality. \nThis meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e4'>Melbourne, practical rationality</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fa5MuaCocYWwP69Lo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.937235732998678e-07, "legacy": true, "legacyId": "18968", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality\">Discussion article for the meetup : <a href=\"/meetups/e4\">Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 October 2012 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">55 Walsh St West Melbourne 3003 Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Practical rationality. \nThis meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality1\">Discussion article for the meetup : <a href=\"/meetups/e4\">Melbourne, practical rationality</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality", "level": 1}, {"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T14:29:37.636Z", "modifiedAt": null, "url": null, "title": "Is xkcd \"Think Logically\" talking about this site?", "slug": "is-xkcd-think-logically-talking-about-this-site", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:03.889Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "summerstay", "createdAt": "2011-06-15T22:18:28.917Z", "isAdmin": false, "displayName": "summerstay"}, "userId": "qkcFeNZSPyEibsWwK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mco8Apq4y6LpQ79Qs/is-xkcd-think-logically-talking-about-this-site", "pageUrlRelative": "/posts/mco8Apq4y6LpQ79Qs/is-xkcd-think-logically-talking-about-this-site", "linkUrl": "https://www.lesswrong.com/posts/mco8Apq4y6LpQ79Qs/is-xkcd-think-logically-talking-about-this-site", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20xkcd%20%22Think%20Logically%22%20talking%20about%20this%20site%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20xkcd%20%22Think%20Logically%22%20talking%20about%20this%20site%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmco8Apq4y6LpQ79Qs%2Fis-xkcd-think-logically-talking-about-this-site%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20xkcd%20%22Think%20Logically%22%20talking%20about%20this%20site%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmco8Apq4y6LpQ79Qs%2Fis-xkcd-think-logically-talking-about-this-site", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmco8Apq4y6LpQ79Qs%2Fis-xkcd-think-logically-talking-about-this-site", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<p>I think we could apply the lessons, anyway, but Munroe might have our community in mind specifically. The alt-text refers to emotional biases. I'm just curious if others got the same impression.</p>\n<p><a style=\"font-family: Lucida, Helvetica, sans-serif; font-size: 16px; font-variant: small-caps; text-align: center;\" title=\"xkcd comic &quot;Think Logically&quot;\" href=\"http://xkcd.com/1112/\" target=\"_blank\">http://xkcd.com/1112/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mco8Apq4y6LpQ79Qs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": -19, "extendedScore": null, "score": -3.1e-05, "legacy": true, "legacyId": "18975", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T14:46:05.475Z", "modifiedAt": null, "url": null, "title": "Meetup : Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party", "slug": "meetup-pre-singularity-summit-overcoming-bias-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:00.221Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zJhPNdPt87fMRKFqd/meetup-pre-singularity-summit-overcoming-bias-less-wrong", "pageUrlRelative": "/posts/zJhPNdPt87fMRKFqd/meetup-pre-singularity-summit-overcoming-bias-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/zJhPNdPt87fMRKFqd/meetup-pre-singularity-summit-overcoming-bias-less-wrong", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Pre-Singularity%20Summit%20Overcoming%20Bias%20%2F%20Less%20Wrong%20Meetup%20Party&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Pre-Singularity%20Summit%20Overcoming%20Bias%20%2F%20Less%20Wrong%20Meetup%20Party%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzJhPNdPt87fMRKFqd%2Fmeetup-pre-singularity-summit-overcoming-bias-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Pre-Singularity%20Summit%20Overcoming%20Bias%20%2F%20Less%20Wrong%20Meetup%20Party%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzJhPNdPt87fMRKFqd%2Fmeetup-pre-singularity-summit-overcoming-bias-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzJhPNdPt87fMRKFqd%2Fmeetup-pre-singularity-summit-overcoming-bias-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 120, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e5'>Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 October 2012 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2135 Oregon St., Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In anticipation of the Singularity Summit, there will be a small Overcoming Bias / Less Wrong meetup party, featuring Robin Hanson and Katja Grace of Overcoming Bias. Please join us on Thursday, October 11, between 7pm and 10pm for conversations about important and interesting things, and maybe dancing. OG House has generously offered their home for this event. Bringing drinks or snacks is not required but greatly appreciated. There is street parking, and Ashby BART is half a mile away.</p>\n\n<p><a href=\"http://www.overcomingbias.com/2012/09/oblw-party-berkeley.html\" rel=\"nofollow\">http://www.overcomingbias.com/2012/09/oblw-party-berkeley.html</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e5'>Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zJhPNdPt87fMRKFqd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 9.940155734048021e-07, "legacy": true, "legacyId": "18976", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Pre_Singularity_Summit_Overcoming_Bias___Less_Wrong_Meetup_Party\">Discussion article for the meetup : <a href=\"/meetups/e5\">Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 October 2012 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2135 Oregon St., Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In anticipation of the Singularity Summit, there will be a small Overcoming Bias / Less Wrong meetup party, featuring Robin Hanson and Katja Grace of Overcoming Bias. Please join us on Thursday, October 11, between 7pm and 10pm for conversations about important and interesting things, and maybe dancing. OG House has generously offered their home for this event. Bringing drinks or snacks is not required but greatly appreciated. There is street parking, and Ashby BART is half a mile away.</p>\n\n<p><a href=\"http://www.overcomingbias.com/2012/09/oblw-party-berkeley.html\" rel=\"nofollow\">http://www.overcomingbias.com/2012/09/oblw-party-berkeley.html</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Pre_Singularity_Summit_Overcoming_Bias___Less_Wrong_Meetup_Party1\">Discussion article for the meetup : <a href=\"/meetups/e5\">Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party</a></h2>", "sections": [{"title": "Discussion article for the meetup : Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party", "anchor": "Discussion_article_for_the_meetup___Pre_Singularity_Summit_Overcoming_Bias___Less_Wrong_Meetup_Party", "level": 1}, {"title": "Discussion article for the meetup : Pre-Singularity Summit Overcoming Bias / Less Wrong Meetup Party", "anchor": "Discussion_article_for_the_meetup___Pre_Singularity_Summit_Overcoming_Bias___Less_Wrong_Meetup_Party1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T18:15:41.175Z", "modifiedAt": null, "url": null, "title": "Finally Ending My Cryo-Crastination", "slug": "finally-ending-my-cryo-crastination", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:07.641Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AXWvvCPFfiowFp6hB/finally-ending-my-cryo-crastination", "pageUrlRelative": "/posts/AXWvvCPFfiowFp6hB/finally-ending-my-cryo-crastination", "linkUrl": "https://www.lesswrong.com/posts/AXWvvCPFfiowFp6hB/finally-ending-my-cryo-crastination", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Finally%20Ending%20My%20Cryo-Crastination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFinally%20Ending%20My%20Cryo-Crastination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAXWvvCPFfiowFp6hB%2Ffinally-ending-my-cryo-crastination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Finally%20Ending%20My%20Cryo-Crastination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAXWvvCPFfiowFp6hB%2Ffinally-ending-my-cryo-crastination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAXWvvCPFfiowFp6hB%2Ffinally-ending-my-cryo-crastination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 353, "htmlBody": "<p>I've finally decided to take the plunge and make the arrangements for my eventual cryonic preservation. To help myself make sure that I actually follow through with everything necessary, I'm publicly pre-committing myself here to accomplish that.</p>\n<p>&nbsp;</p>\n<p>As initial evidence that I'm actually serious about doing this, I've sent an email to <a href=\"http://www.cryonics.org/\">The Cryonics Institute</a> today, whose contents were as follows:</p>\n<p><br /> <br /> <br /> <br /> I have decided to finally stop procrastinating and make the necessary arrangements for my eventual cryonic preservation, and I have chosen CI to make those arrangements with.<br /> <br /> I have looked through your membership pages and online sample forms, and I believe that I can work through my end of the paperwork without any real trouble, although I would still appreciate any advice you have to offer. For example, I live in Canada, about an hour's drive from Toronto, which might affect which forms are necessary.<br /> <br /> Before I send my initial payment, I would at least like to confirm the basic details, and let you know who the money is coming from. It appears that, to start things off, I can Paypal you USD $110, for the yearly membership fee plus the first quarter's dues; after which I would mail you a physical, signed copy of the yearly membership application. After that, there will be a variety of documents to sign and have witnessed; and the insurance plan to arrange for. Is that a reasonable summary?<br /> <br /> For the life insurance, I am thinking of a 20-year term policy with RBC (Royal Bank of Canada). Have you had any dealings with them previously, to know whether or not there will be any problems in setting the Cryonics Institute as the beneficiary? Do you have any recommendations about how large a benefit in excess of the basic USD $35,000 amount the policy should pay out, such as to cover currency-exchange fluctuations or the 'local help' rider?<br /> <br /> Is there anything else you would recommend be discussed before I make that initial payment and set the ball in motion?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AXWvvCPFfiowFp6hB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 19, "extendedScore": null, "score": 4.9e-05, "legacy": true, "legacyId": "18977", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-24T19:40:11.947Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Thursday 7pm *New Place*", "slug": "meetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yrZdju2JRKp7rySRP/meetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "pageUrlRelative": "/posts/yrZdju2JRKp7rySRP/meetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "linkUrl": "https://www.lesswrong.com/posts/yrZdju2JRKp7rySRP/meetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "postedAtFormatted": "Monday, September 24th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%20*New%20Place*&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%20*New%20Place*%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyrZdju2JRKp7rySRP%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Thursday%207pm%20*New%20Place*%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyrZdju2JRKp7rySRP%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyrZdju2JRKp7rySRP%2Fmeetup-fort-collins-colorado-meetup-thursday-7pm-new-place-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e6'>Fort Collins, Colorado Meetup Thursday 7pm *New Place*</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Mugs, 306 West Laurel, Fort Collins CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting at a coffee shop on the north side of the university.\nWhat do you think of Bayesian networks and Probabalistic Graphical Models?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e6'>Fort Collins, Colorado Meetup Thursday 7pm *New Place*</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yrZdju2JRKp7rySRP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.941684570532197e-07, "legacy": true, "legacyId": "18978", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm__New_Place_\">Discussion article for the meetup : <a href=\"/meetups/e6\">Fort Collins, Colorado Meetup Thursday 7pm *New Place*</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 September 2012 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Mugs, 306 West Laurel, Fort Collins CO</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting at a coffee shop on the north side of the university.\nWhat do you think of Bayesian networks and Probabalistic Graphical Models?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm__New_Place_1\">Discussion article for the meetup : <a href=\"/meetups/e6\">Fort Collins, Colorado Meetup Thursday 7pm *New Place*</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm *New Place*", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm__New_Place_", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Thursday 7pm *New Place*", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Thursday_7pm__New_Place_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T01:28:58.612Z", "modifiedAt": null, "url": null, "title": "Coursera classes relevant to LW", "slug": "coursera-classes-relevant-to-lw", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.133Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Curiouskid", "createdAt": "2011-05-13T23:30:04.967Z", "isAdmin": false, "displayName": "Curiouskid"}, "userId": "Y4xxvuP743fwKcZQY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YaEx2NFPMhcKGEGSC/coursera-classes-relevant-to-lw", "pageUrlRelative": "/posts/YaEx2NFPMhcKGEGSC/coursera-classes-relevant-to-lw", "linkUrl": "https://www.lesswrong.com/posts/YaEx2NFPMhcKGEGSC/coursera-classes-relevant-to-lw", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Coursera%20classes%20relevant%20to%20LW&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACoursera%20classes%20relevant%20to%20LW%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYaEx2NFPMhcKGEGSC%2Fcoursera-classes-relevant-to-lw%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Coursera%20classes%20relevant%20to%20LW%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYaEx2NFPMhcKGEGSC%2Fcoursera-classes-relevant-to-lw", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYaEx2NFPMhcKGEGSC%2Fcoursera-classes-relevant-to-lw", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<p>I assume You're familiar with Coursera. They have several on going classes that are relevant to LW such as:</p>\n<p>1. Intro to Logic.&nbsp;</p>\n<p>2.&nbsp;Probabilistic&nbsp;Graphical Models</p>\n<p>3. Introduction to Mathematical thinking</p>\n<p>&nbsp;</p>\n<p>Would anybody be interested in taking these classes with me?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YaEx2NFPMhcKGEGSC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 9.943498132548848e-07, "legacy": true, "legacyId": "18980", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T01:46:30.363Z", "modifiedAt": null, "url": null, "title": "Meetup : Purdue Meetup", "slug": "meetup-purdue-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.052Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Curiouskid", "createdAt": "2011-05-13T23:30:04.967Z", "isAdmin": false, "displayName": "Curiouskid"}, "userId": "Y4xxvuP743fwKcZQY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YekjReubaN2ThJwMR/meetup-purdue-meetup-0", "pageUrlRelative": "/posts/YekjReubaN2ThJwMR/meetup-purdue-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/YekjReubaN2ThJwMR/meetup-purdue-meetup-0", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Purdue%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Purdue%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYekjReubaN2ThJwMR%2Fmeetup-purdue-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Purdue%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYekjReubaN2ThJwMR%2Fmeetup-purdue-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYekjReubaN2ThJwMR%2Fmeetup-purdue-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e7'>Purdue Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 September 2012 09:45:46PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Purdue</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We don't have a regular meet-up group at Purdue, which is a shame because meetups are great.</p>\n\n<p>I thought we weren't having meetups because there weren't very many LWers at Purdue. However, the last time I put out a survey was last year, and since then, I've run into a few LWers randomly, so I decided to see if more LWers would respond.</p>\n\n<p>Note: This isn't an actual meetup. It's a survey to see if people would want to do a meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e7'>Purdue Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YekjReubaN2ThJwMR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.94358929553652e-07, "legacy": true, "legacyId": "18981", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Purdue_Meetup\">Discussion article for the meetup : <a href=\"/meetups/e7\">Purdue Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 September 2012 09:45:46PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Purdue</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We don't have a regular meet-up group at Purdue, which is a shame because meetups are great.</p>\n\n<p>I thought we weren't having meetups because there weren't very many LWers at Purdue. However, the last time I put out a survey was last year, and since then, I've run into a few LWers randomly, so I decided to see if more LWers would respond.</p>\n\n<p>Note: This isn't an actual meetup. It's a survey to see if people would want to do a meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Purdue_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/e7\">Purdue Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Purdue Meetup", "anchor": "Discussion_article_for_the_meetup___Purdue_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Purdue Meetup", "anchor": "Discussion_article_for_the_meetup___Purdue_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T03:39:20.395Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Traditional Capitalist Values", "slug": "seq-rerun-traditional-capitalist-values", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.164Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EcH9sEFykS95En7YL/seq-rerun-traditional-capitalist-values", "pageUrlRelative": "/posts/EcH9sEFykS95En7YL/seq-rerun-traditional-capitalist-values", "linkUrl": "https://www.lesswrong.com/posts/EcH9sEFykS95En7YL/seq-rerun-traditional-capitalist-values", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Traditional%20Capitalist%20Values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Traditional%20Capitalist%20Values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcH9sEFykS95En7YL%2Fseq-rerun-traditional-capitalist-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Traditional%20Capitalist%20Values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcH9sEFykS95En7YL%2Fseq-rerun-traditional-capitalist-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEcH9sEFykS95En7YL%2Fseq-rerun-traditional-capitalist-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>Today's post, <a href=\"/lw/ux/traditional_capitalist_values/\">Traditional Capitalist Values</a> was originally published on 17 October 2008.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries#Traditional_Capitalist_Values\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Before you start talking about a system of values, try to actually understand the values of that system as believed by its practitioners.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/emv/seq_rerun_entangled_truths_contagious_lies/#comments\">Entangled Truths, Contagious Lies</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EcH9sEFykS95En7YL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "18984", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3bfWCPfu9AFspnhvf", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T05:31:44.630Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley meetup: choice blindness", "slug": "meetup-berkeley-meetup-choice-blindness", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iYduY3jD3T2JmZ5Sk/meetup-berkeley-meetup-choice-blindness", "pageUrlRelative": "/posts/iYduY3jD3T2JmZ5Sk/meetup-berkeley-meetup-choice-blindness", "linkUrl": "https://www.lesswrong.com/posts/iYduY3jD3T2JmZ5Sk/meetup-berkeley-meetup-choice-blindness", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%20meetup%3A%20choice%20blindness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%20meetup%3A%20choice%20blindness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYduY3jD3T2JmZ5Sk%2Fmeetup-berkeley-meetup-choice-blindness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%20meetup%3A%20choice%20blindness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYduY3jD3T2JmZ5Sk%2Fmeetup-berkeley-meetup-choice-blindness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYduY3jD3T2JmZ5Sk%2Fmeetup-berkeley-meetup-choice-blindness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/e8'>Berkeley meetup: choice blindness</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup will be at Zendo, as usual. The discussion topic will be choice blindness, particularly the recent experiment showing that choice blindness applies to moral positions (<a href=\"http://www.nature.com/news/how-to-confuse-a-moral-compass-1.11447\" rel=\"nofollow\">http://www.nature.com/news/how-to-confuse-a-moral-compass-1.11447</a>), and what this means for good epistemic practice.\nRecent Less Wrong discussion on the matter: <a href=\"http://lesswrong.com/lw/elg/new_study_on_choice_blindness_in_moral_positions/\" rel=\"nofollow\">http://lesswrong.com/lw/elg/new_study_on_choice_blindness_in_moral_positions/</a>\nFor directions to Zendo, see the mailing list <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/e8'>Berkeley meetup: choice blindness</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iYduY3jD3T2JmZ5Sk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9.944760808367606e-07, "legacy": true, "legacyId": "18985", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__choice_blindness\">Discussion article for the meetup : <a href=\"/meetups/e8\">Berkeley meetup: choice blindness</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup will be at Zendo, as usual. The discussion topic will be choice blindness, particularly the recent experiment showing that choice blindness applies to moral positions (<a href=\"http://www.nature.com/news/how-to-confuse-a-moral-compass-1.11447\" rel=\"nofollow\">http://www.nature.com/news/how-to-confuse-a-moral-compass-1.11447</a>), and what this means for good epistemic practice.\nRecent Less Wrong discussion on the matter: <a href=\"http://lesswrong.com/lw/elg/new_study_on_choice_blindness_in_moral_positions/\" rel=\"nofollow\">http://lesswrong.com/lw/elg/new_study_on_choice_blindness_in_moral_positions/</a>\nFor directions to Zendo, see the mailing list <a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a> or call me at four-zero-eight-nine-six-six-nine-two-seven-four.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley_meetup__choice_blindness1\">Discussion article for the meetup : <a href=\"/meetups/e8\">Berkeley meetup: choice blindness</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley meetup: choice blindness", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__choice_blindness", "level": 1}, {"title": "Discussion article for the meetup : Berkeley meetup: choice blindness", "anchor": "Discussion_article_for_the_meetup___Berkeley_meetup__choice_blindness1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ekkB4qRZ5yFnMwZGr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T08:29:15.481Z", "modifiedAt": null, "url": null, "title": "Meetup : Munich Meetup, October 28th", "slug": "meetup-munich-meetup-october-28th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:28.048Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wallowinmaya", "createdAt": "2011-03-21T00:39:18.855Z", "isAdmin": false, "displayName": "David Althaus"}, "userId": "xY8DDzk6TyvRroJEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ejiwAx7DrQgvhuacP/meetup-munich-meetup-october-28th", "pageUrlRelative": "/posts/ejiwAx7DrQgvhuacP/meetup-munich-meetup-october-28th", "linkUrl": "https://www.lesswrong.com/posts/ejiwAx7DrQgvhuacP/meetup-munich-meetup-october-28th", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Munich%20Meetup%2C%20October%2028th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Munich%20Meetup%2C%20October%2028th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejiwAx7DrQgvhuacP%2Fmeetup-munich-meetup-october-28th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Munich%20Meetup%2C%20October%2028th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejiwAx7DrQgvhuacP%2Fmeetup-munich-meetup-october-28th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejiwAx7DrQgvhuacP%2Fmeetup-munich-meetup-october-28th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/e9\">Munich Meetup, October 28th</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">28 October 2012 03:00:00PM (+0200)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Munich Central Station, Coffee Fellows cafe, inside the central station, *second* floor</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The last meetup took place more than a year ago, so it's time for another one. Some of the topics discussed last time: Existential risks, anthropics, AI, metaethics, self-improvement and probably more that I can't remember. Of course there is much more to talk about and maybe we'll try some of those fancy rationality-games. (If the cafe sucks, we could easily go elsewhere. I've merely chosen the place, because it's relatively nice, near the central station and easy to find.) I'll be there with a LessWrong sign. Newbies and lurkers are very welcome!</p>\n<p>&nbsp;</p>\n<p>ETA:&nbsp;<span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 10.857142448425293px; text-align: justify;\">I created a google group for the Munich LW meetup.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 10.857142448425293px; text-align: justify; background-color: #f7f7f8;\">Send me your email adress to&nbsp;<em>myusername</em>@gmx.de and I'll add you.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/e9\">Munich Meetup, October 28th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ejiwAx7DrQgvhuacP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 9.94568427107377e-07, "legacy": true, "legacyId": "18996", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup__October_28th\">Discussion article for the meetup : <a href=\"/meetups/e9\">Munich Meetup, October 28th</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">28 October 2012 03:00:00PM (+0200)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Munich Central Station, Coffee Fellows cafe, inside the central station, *second* floor</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The last meetup took place more than a year ago, so it's time for another one. Some of the topics discussed last time: Existential risks, anthropics, AI, metaethics, self-improvement and probably more that I can't remember. Of course there is much more to talk about and maybe we'll try some of those fancy rationality-games. (If the cafe sucks, we could easily go elsewhere. I've merely chosen the place, because it's relatively nice, near the central station and easy to find.) I'll be there with a LessWrong sign. Newbies and lurkers are very welcome!</p>\n<p>&nbsp;</p>\n<p>ETA:&nbsp;<span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 10.857142448425293px; text-align: justify;\">I created a google group for the Munich LW meetup.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 10.857142448425293px; text-align: justify; background-color: #f7f7f8;\">Send me your email adress to&nbsp;<em>myusername</em>@gmx.de and I'll add you.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup__October_28th1\">Discussion article for the meetup : <a href=\"/meetups/e9\">Munich Meetup, October 28th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Munich Meetup, October 28th", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup__October_28th", "level": 1}, {"title": "Discussion article for the meetup : Munich Meetup, October 28th", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup__October_28th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T21:57:11.931Z", "modifiedAt": null, "url": null, "title": "Why humans are sometimes less rational than animals", "slug": "why-humans-are-sometimes-less-rational-than-animals", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:31.714Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AndgY2pd96TDdHGFH/why-humans-are-sometimes-less-rational-than-animals", "pageUrlRelative": "/posts/AndgY2pd96TDdHGFH/why-humans-are-sometimes-less-rational-than-animals", "linkUrl": "https://www.lesswrong.com/posts/AndgY2pd96TDdHGFH/why-humans-are-sometimes-less-rational-than-animals", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20humans%20are%20sometimes%20less%20rational%20than%20animals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20humans%20are%20sometimes%20less%20rational%20than%20animals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAndgY2pd96TDdHGFH%2Fwhy-humans-are-sometimes-less-rational-than-animals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20humans%20are%20sometimes%20less%20rational%20than%20animals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAndgY2pd96TDdHGFH%2Fwhy-humans-are-sometimes-less-rational-than-animals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAndgY2pd96TDdHGFH%2Fwhy-humans-are-sometimes-less-rational-than-animals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p><a href=\"http://commonsenseatheism.com/wp-content/uploads/2012/09/Stanovich-Why-Humans-are-Sometimes-Less-Rational-Than-Animals.pdf\">New paper</a> from Keith Stanovich (one of my favorite cognitive scientists):&nbsp;</p>\n<blockquote>\n<p>Several formal analyses in decision theory have shown that if people&rsquo;s&nbsp;preferences follow certain logical patterns (the so-called axioms of rational&nbsp;choice) then they are behaving as if they are maximising utility. However,&nbsp;numerous studies in the decision-making literature have indicated that humans&nbsp;often violate the axioms of rational choice. Additionally, studies of nonhuman&nbsp;animals indicate that they are largely rational in an axiomatic sense. It is&nbsp;important to understand why the finding that humans are less rational than&nbsp;other animals is not paradoxical. This paper discusses three reasons why the&nbsp;principles of rational choice are actually easier to follow when the cognitive&nbsp;architecture of the organism is simpler: contextual complexity, symbolic&nbsp;complexity, and the strong evaluator struggle.</p>\n</blockquote>\n<p>Enjoy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AndgY2pd96TDdHGFH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 30, "extendedScore": null, "score": 9.949889257236397e-07, "legacy": true, "legacyId": "19000", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T22:30:38.328Z", "modifiedAt": null, "url": null, "title": "Shutting up and doing the impossible: Leslie Gordon", "slug": "shutting-up-and-doing-the-impossible-leslie-gordon", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.827Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/imxLc5rtN9A2WCcaQ/shutting-up-and-doing-the-impossible-leslie-gordon", "pageUrlRelative": "/posts/imxLc5rtN9A2WCcaQ/shutting-up-and-doing-the-impossible-leslie-gordon", "linkUrl": "https://www.lesswrong.com/posts/imxLc5rtN9A2WCcaQ/shutting-up-and-doing-the-impossible-leslie-gordon", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shutting%20up%20and%20doing%20the%20impossible%3A%20Leslie%20Gordon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShutting%20up%20and%20doing%20the%20impossible%3A%20Leslie%20Gordon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FimxLc5rtN9A2WCcaQ%2Fshutting-up-and-doing-the-impossible-leslie-gordon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shutting%20up%20and%20doing%20the%20impossible%3A%20Leslie%20Gordon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FimxLc5rtN9A2WCcaQ%2Fshutting-up-and-doing-the-impossible-leslie-gordon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FimxLc5rtN9A2WCcaQ%2Fshutting-up-and-doing-the-impossible-leslie-gordon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<p>Progeria is an extremely rare condition, 15 years ago almost nothing was known about it. Then Leslie Gordon and Scott Berns, both physicians, had a son who was diagnosed with it at 2 years old. They were able to find the cause, isolate the genes responsible, and adapt a drug to combat many of the more fatal symptoms. They had help, and luck. But they are doing the impossible.</p>\n<p><a href=\"http://www.npr.org/blogs/health/2012/09/25/161691083/experimental-drug-is-first-to-help-kids-with-premature-aging-disease\">http://www.npr.org/blogs/health/2012/09/25/161691083/experimental-drug-is-first-to-help-kids-with-premature-aging-disease</a></p>\n<p>&nbsp;</p>\n<p>Bonus: the drug may help slow aging in healthy humans as well.</p>\n<p>Also: this has been <a href=\"/lw/8ah/links_recent_developments_in_lifeextension/\">mentioned on LW before</a>, but without the awesome <a href=\"/lw/up/shut_up_and_do_the_impossible/\">Do The Impossible</a> narrative. I blame the BBC.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "imxLc5rtN9A2WCcaQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 9, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "19001", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EBgxWap8FBJ57DEe2", "nCvvhFBaayaXyuBiD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T22:41:12.568Z", "modifiedAt": null, "url": null, "title": "Petrov Day Image", "slug": "petrov-day-image", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:56.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7Q8cNnqbKFDcXMh85/petrov-day-image", "pageUrlRelative": "/posts/7Q8cNnqbKFDcXMh85/petrov-day-image", "linkUrl": "https://www.lesswrong.com/posts/7Q8cNnqbKFDcXMh85/petrov-day-image", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Petrov%20Day%20Image&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APetrov%20Day%20Image%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Q8cNnqbKFDcXMh85%2Fpetrov-day-image%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Petrov%20Day%20Image%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Q8cNnqbKFDcXMh85%2Fpetrov-day-image", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Q8cNnqbKFDcXMh85%2Fpetrov-day-image", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p><a href=\"/lw/jq/926_is_petrov_day/\">9/26 is Petrov Day</a></p>\n<p>While mentioning this in Facebook statuses, Tweets, and face-to-face conversation is good, things often stick better when there's a picture associated with them. Image macros are popular, and more fun to share. So here's one for Petrov Day I threw together.</p>\n<p><span style=\"color: #0000ee;\"><span style=\"text-decoration: underline;\">http://i.imgur.com/3GNms.jpg</span></span></p>\n<p><span style=\"color: #0000ee;\"><span style=\"text-decoration: underline;\"><img src=\"http://i.imgur.com/3GNms.jpg\" alt=\"\" width=\"800\" height=\"500\" /><br /></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7Q8cNnqbKFDcXMh85", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 21, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "19002", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QtyKq4BDyuJ3tysoK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-25T23:15:01.700Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Utilitarianism", "slug": "meetup-west-la-meetup-utilitarianism", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mc78FqaFsxrr6iWJH/meetup-west-la-meetup-utilitarianism", "pageUrlRelative": "/posts/Mc78FqaFsxrr6iWJH/meetup-west-la-meetup-utilitarianism", "linkUrl": "https://www.lesswrong.com/posts/Mc78FqaFsxrr6iWJH/meetup-west-la-meetup-utilitarianism", "postedAtFormatted": "Tuesday, September 25th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Utilitarianism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Utilitarianism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMc78FqaFsxrr6iWJH%2Fmeetup-west-la-meetup-utilitarianism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Utilitarianism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMc78FqaFsxrr6iWJH%2Fmeetup-west-la-meetup-utilitarianism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMc78FqaFsxrr6iWJH%2Fmeetup-west-la-meetup-utilitarianism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 192, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ea'>West LA Meetup - Utilitarianism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm  Wednesday, September 26th.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> The topic du jour is the value of <a href=\"http://wiki.lesswrong.com/wiki/Utilitarianism\">Utilitarianism</a>. Utilitarianism seems to have <a href=\"http://en.wikipedia.org/wiki/Mere_addition_paradox\" rel=\"nofollow\">some problems</a>, and they <a href=\"http://www.overcomingbias.com/2012/08/no-theory-x-in-shining-armour.html\">may not be resolvable</a>. This topic has generated a lot of interesting discussion on Less Wrong - for starters, see the list of articles linked on the <a href=\"http://wiki.lesswrong.com/wiki/Utilitarianism\">lw wiki page</a>.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts/\">recent posts</a> (also check out LW's sister site, <a href=\"http://www.overcomingbias.com/\">Overcoming Bias</a> ). But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ea'>West LA Meetup - Utilitarianism</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mc78FqaFsxrr6iWJH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9.95029449217659e-07, "legacy": true, "legacyId": "19003", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Utilitarianism\">Discussion article for the meetup : <a href=\"/meetups/ea\">West LA Meetup - Utilitarianism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 September 2012 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm  Wednesday, September 26th.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion Topic:</strong> The topic du jour is the value of <a href=\"http://wiki.lesswrong.com/wiki/Utilitarianism\">Utilitarianism</a>. Utilitarianism seems to have <a href=\"http://en.wikipedia.org/wiki/Mere_addition_paradox\" rel=\"nofollow\">some problems</a>, and they <a href=\"http://www.overcomingbias.com/2012/08/no-theory-x-in-shining-armour.html\">may not be resolvable</a>. This topic has generated a lot of interesting discussion on Less Wrong - for starters, see the list of articles linked on the <a href=\"http://wiki.lesswrong.com/wiki/Utilitarianism\">lw wiki page</a>.</p>\n\n<p>There will be general discussion too, and there are lots of interesting <a href=\"http://lesswrong.com/recentposts/\">recent posts</a> (also check out LW's sister site, <a href=\"http://www.overcomingbias.com/\">Overcoming Bias</a> ). But don't worry if you don't have time to read any articles, or even if you've never read any Less Wrong! Bring a friend! The atmosphere is casual, and good, intelligent conversation with friendly people is guaranteed.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Utilitarianism1\">Discussion article for the meetup : <a href=\"/meetups/ea\">West LA Meetup - Utilitarianism</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Utilitarianism", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Utilitarianism", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Utilitarianism", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Utilitarianism1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2012-09-26T00:15:34.355Z", "modifiedAt": null, "url": null, "title": "Modafinil now covered by insurance", "slug": "modafinil-now-covered-by-insurance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.347Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/evrXtGr4LdgnDstkd/modafinil-now-covered-by-insurance", "pageUrlRelative": "/posts/evrXtGr4LdgnDstkd/modafinil-now-covered-by-insurance", "linkUrl": "https://www.lesswrong.com/posts/evrXtGr4LdgnDstkd/modafinil-now-covered-by-insurance", "postedAtFormatted": "Wednesday, September 26th 2012", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Modafinil%20now%20covered%20by%20insurance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModafinil%20now%20covered%20by%20insurance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevrXtGr4LdgnDstkd%2Fmodafinil-now-covered-by-insurance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Modafinil%20now%20covered%20by%20insurance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevrXtGr4LdgnDstkd%2Fmodafinil-now-covered-by-insurance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FevrXtGr4LdgnDstkd%2Fmodafinil-now-covered-by-insurance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Modafinil#Cognitive_enhancement\">Modafinil</a> is now being covered by at least one insurance company in Massachusetts under which it costs less than $1 for a 200 MG pill. &nbsp;I predict a huge college&nbsp;black-market&nbsp;trade in the drug.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "evrXtGr4LdgnDstkd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": -1, "extendedScore": null, "score": 9.950609748257365e-07, "legacy": true, "legacyId": "19004", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}