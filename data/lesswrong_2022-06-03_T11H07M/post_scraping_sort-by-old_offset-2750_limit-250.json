{"results": [{"createdAt": null, "postedAt": "2011-02-08T23:55:55.090Z", "modifiedAt": null, "url": null, "title": "Blocking users", "slug": "blocking-users", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:35.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9wARZCb9jLLsgt6yb/blocking-users", "pageUrlRelative": "/posts/9wARZCb9jLLsgt6yb/blocking-users", "linkUrl": "https://www.lesswrong.com/posts/9wARZCb9jLLsgt6yb/blocking-users", "postedAtFormatted": "Tuesday, February 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Blocking%20users&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABlocking%20users%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wARZCb9jLLsgt6yb%2Fblocking-users%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Blocking%20users%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wARZCb9jLLsgt6yb%2Fblocking-users", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wARZCb9jLLsgt6yb%2Fblocking-users", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p>I noticed this recent Wiki edit:</p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/User:AllisonGibbons\">http://wiki.lesswrong.com/wiki/User:AllisonGibbons</a></p>\n<p>which says:</p>\n<div class=\"mw-warning-with-logexcerpt\">\n<p>This user is currently blocked. The latest block log entry is provided below for reference:</p>\n<ul>\n<li class=\"mw-logline-block\">13:19, 8 February 2011 <a class=\"mw-userlink\" title=\"User:Vladimir Nesov\" href=\"http://wiki.lesswrong.com/wiki/User:Vladimir_Nesov\">Vladimir Nesov</a> <span class=\"mw-usertoollinks\">(<a title=\"User talk:Vladimir Nesov\" href=\"http://wiki.lesswrong.com/wiki/User_talk:Vladimir_Nesov\">Talk</a> | <a title=\"Special:Contributions/Vladimir Nesov\" href=\"http://wiki.lesswrong.com/wiki/Special:Contributions/Vladimir_Nesov\">contribs</a>)</span> blocked <a class=\"new mw-userlink\" title=\"User:AllisonGibbons (page does not exist)\" href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=User:AllisonGibbons&amp;action=edit&amp;redlink=1\">AllisonGibbons</a> <span class=\"mw-usertoollinks\">(<a class=\"new\" title=\"User talk:AllisonGibbons (page does not exist)\" href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=User_talk:AllisonGibbons&amp;action=edit&amp;redlink=1\">Talk</a> | <a title=\"Special:Contributions/AllisonGibbons\" href=\"http://wiki.lesswrong.com/wiki/Special:Contributions/AllisonGibbons\">contribs</a>)</span> with an expiry time of <span title=\"infinite\">infinite</span> (account creation disabled, autoblock disabled) &lrm; </li>\n</ul>\nOdds are, it's a spambot.&nbsp; But who can block a user, who decides who can block a user, what are users blocked for, and what recourse does a blocked user have?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9wARZCb9jLLsgt6yb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 6.769408118489213e-07, "legacy": true, "legacyId": "5381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-09T04:35:34.364Z", "modifiedAt": null, "url": null, "title": "Why is reddit so negative?", "slug": "why-is-reddit-so-negative", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:37.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cxySF9YbNtW9zHAbf/why-is-reddit-so-negative", "pageUrlRelative": "/posts/cxySF9YbNtW9zHAbf/why-is-reddit-so-negative", "linkUrl": "https://www.lesswrong.com/posts/cxySF9YbNtW9zHAbf/why-is-reddit-so-negative", "postedAtFormatted": "Wednesday, February 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20is%20reddit%20so%20negative%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20is%20reddit%20so%20negative%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxySF9YbNtW9zHAbf%2Fwhy-is-reddit-so-negative%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20is%20reddit%20so%20negative%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxySF9YbNtW9zHAbf%2Fwhy-is-reddit-so-negative", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxySF9YbNtW9zHAbf%2Fwhy-is-reddit-so-negative", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>Hello all,</p>\n<p>This is sort of a random topic, but I've been looking at various online communities and was struck by how pessimistic and negative many are. I perceived this most notably on reddit, but some other places are like this too-- there seems to be a general aura of discontent, an attitude that society in general is corrupt, and so on. Does anyone know why?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cxySF9YbNtW9zHAbf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 8, "extendedScore": null, "score": 6.770142179894509e-07, "legacy": true, "legacyId": "5385", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-09T09:59:24.695Z", "modifiedAt": null, "url": null, "title": "Rational = true?", "slug": "rational-true", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:38.386Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Student_UK", "createdAt": "2011-01-15T12:04:38.981Z", "isAdmin": false, "displayName": "Student_UK"}, "userId": "gEgpjQAqs4rfMZK7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qyhuXpMw5zpkY4oME/rational-true", "pageUrlRelative": "/posts/qyhuXpMw5zpkY4oME/rational-true", "linkUrl": "https://www.lesswrong.com/posts/qyhuXpMw5zpkY4oME/rational-true", "postedAtFormatted": "Wednesday, February 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20%3D%20true%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20%3D%20true%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqyhuXpMw5zpkY4oME%2Frational-true%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20%3D%20true%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqyhuXpMw5zpkY4oME%2Frational-true", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqyhuXpMw5zpkY4oME%2Frational-true", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">For example, if you say, \"The rational belief is X, but the true belief is Y\" then you are probably using the word \"rational\" in a way that means something other than what most of us have in mind</span></p>\n</blockquote>\n<p>This was copied from <a href=\"/lw/31/what_do_we_mean_by_rationality/\">here</a>.</p>\n<p>Surely it is obvious that there are lots of examples when one might say this. Consider this:</p>\n<p><em>Rob looks in the newspaper to check the football scores. The newspaper says that United won 3-2, but it is a misprint because City actually won 3-2. In this case, the rational belief is that United won, but the true belief is that City won.</em></p>\n<p>Am I missing something?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qyhuXpMw5zpkY4oME", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 6.770995423771891e-07, "legacy": true, "legacyId": "5390", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-09T15:20:54.505Z", "modifiedAt": null, "url": null, "title": "Extremely Counterfactual Mugging or: the gist of Transparent Newcomb", "slug": "extremely-counterfactual-mugging-or-the-gist-of-transparent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:04.814Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HJEJ8Qp7cyyLRGYRW/extremely-counterfactual-mugging-or-the-gist-of-transparent", "pageUrlRelative": "/posts/HJEJ8Qp7cyyLRGYRW/extremely-counterfactual-mugging-or-the-gist-of-transparent", "linkUrl": "https://www.lesswrong.com/posts/HJEJ8Qp7cyyLRGYRW/extremely-counterfactual-mugging-or-the-gist-of-transparent", "postedAtFormatted": "Wednesday, February 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Extremely%20Counterfactual%20Mugging%20or%3A%20the%20gist%20of%20Transparent%20Newcomb&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExtremely%20Counterfactual%20Mugging%20or%3A%20the%20gist%20of%20Transparent%20Newcomb%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJEJ8Qp7cyyLRGYRW%2Fextremely-counterfactual-mugging-or-the-gist-of-transparent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Extremely%20Counterfactual%20Mugging%20or%3A%20the%20gist%20of%20Transparent%20Newcomb%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJEJ8Qp7cyyLRGYRW%2Fextremely-counterfactual-mugging-or-the-gist-of-transparent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHJEJ8Qp7cyyLRGYRW%2Fextremely-counterfactual-mugging-or-the-gist-of-transparent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<blockquote>\n<p>Omega will either award you $1000 or ask you to pay him $100. He will award you $1000 if he predicts you would pay him if he asked. He will ask you to pay him $100 if he predicts you wouldn't pay him if he asked.&nbsp;</p>\n<p>Omega asks you to pay him $100. Do you pay?</p>\n</blockquote>\n<p>This problem is roughly isomorphic to the branch of Transparent Newcomb (<a href=\"/lw/43t/youre_in_newcombs_box/3h55\">version 1</a>, <a href=\"/lw/42r/punishing_future_crimes/3fiu\">version 2</a>) where box B is empty, but it's simpler.</p>\n<p>Here's a diagram:</p>\n<p><img src=\"http://i55.tinypic.com/k9i8vq.png\" border=\"0\" alt=\"\" /></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YpHkTW27iMFR2Dkae": 1, "fihKHQuS5WZBJgkRm": 1, "5f5c37ee1b5cdee568cfb1b6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HJEJ8Qp7cyyLRGYRW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 6.77184268362684e-07, "legacy": true, "legacyId": "5392", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-09T16:01:57.484Z", "modifiedAt": null, "url": null, "title": "Open Thread, February 2011", "slug": "open-thread-february-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:03.240Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rrLXKLQXqnBwXdXKk/open-thread-february-2011", "pageUrlRelative": "/posts/rrLXKLQXqnBwXdXKk/open-thread-february-2011", "linkUrl": "https://www.lesswrong.com/posts/rrLXKLQXqnBwXdXKk/open-thread-february-2011", "postedAtFormatted": "Wednesday, February 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20February%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20February%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrLXKLQXqnBwXdXKk%2Fopen-thread-february-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20February%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrLXKLQXqnBwXdXKk%2Fopen-thread-february-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrLXKLQXqnBwXdXKk%2Fopen-thread-february-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<p>We're getting late with these ...</p>\n<p><em style=\"font-style: italic;\">This thread is for the discussion of Less Wrong topics that have not appeared in recent posts and are too short or inchoate even for a discussion post. If a discussion gets unwieldy, celebrate by turning it into a top-level post.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rrLXKLQXqnBwXdXKk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 10, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "5393", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-10T01:01:16.712Z", "modifiedAt": null, "url": null, "title": "A rationalist's guide to psychoactive drugs", "slug": "a-rationalist-s-guide-to-psychoactive-drugs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:09.318Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NYPmCBfrDfXfhwBog/a-rationalist-s-guide-to-psychoactive-drugs", "pageUrlRelative": "/posts/NYPmCBfrDfXfhwBog/a-rationalist-s-guide-to-psychoactive-drugs", "linkUrl": "https://www.lesswrong.com/posts/NYPmCBfrDfXfhwBog/a-rationalist-s-guide-to-psychoactive-drugs", "postedAtFormatted": "Thursday, February 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20rationalist's%20guide%20to%20psychoactive%20drugs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20rationalist's%20guide%20to%20psychoactive%20drugs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYPmCBfrDfXfhwBog%2Fa-rationalist-s-guide-to-psychoactive-drugs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20rationalist's%20guide%20to%20psychoactive%20drugs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYPmCBfrDfXfhwBog%2Fa-rationalist-s-guide-to-psychoactive-drugs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYPmCBfrDfXfhwBog%2Fa-rationalist-s-guide-to-psychoactive-drugs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5049, "htmlBody": "<p>This is a first draft.&nbsp; Over the next few days I'll add citations and that sort of thing, but I'm posting it as-is in order to solicit feedback.&nbsp; Also, I wasn't able to find any specific policy regarding mention of illicit substances, so I'm going to assume this is okay, but if not please let me know.</p>\n<p><strong>Disclaimer:</strong> This is a work of postmodern fiction about two irredeemable junkies named Alice and Bob and their cat Fido.&nbsp; The views contained herein are not medical or legal advice, they are not my views, and they are not the views of LessWrong.com or any of its members.&nbsp; In fact they are not views at all: they are transnarrative flows in alterity-space, or that's what my lit prof tells me.&nbsp; I do not condone any illegal activity whatsoever, except jaywalking.</p>\n<h2><strong>Introduction</strong><br /></h2>\n<p>Today, says Alice, I'm going to talk to you about drugs.&nbsp; I'll be covering several nutritional supplements, some stimulants and nootropics, and - as some of you have probably guessed - I'll also be talking briefly about recreational drugs, particularly psychedelics.&nbsp; Now, I don't have any sense of what the popular perception is of drugs around here, but I presume that at least some of you will be a little put off at the suggestion of recreational drug use.&nbsp; If that is how you feel, please bear with me.&nbsp; To partake or not partake of prohibited substances is a choice that must be made individually, and for many the payoffs may not be worth the risks; but I hope to convince you that, at least for some people, responsible drug use is a very reasonable and beneficial activity.</p>\n<p>Well, hold on, says Bob - who takes a permissive but detached view of these things - hold on, now.&nbsp; It may be true (as cursory research will show) that drug use is far less dangerous than it's made out to be, and it may be true that some people get a lot of enjoyment out of them.&nbsp; But if you value knowledge and reason over hedonic pleasure, it seems better to cut them out entirely.&nbsp; After all, it's your brain on the line if anything goes wrong!</p>\n<p>As a matter of fact, says Alice, drugs are good for more than just hedonism.&nbsp; First of all, they give you a handle on your own neurochemistry.&nbsp; It's unlikely that your brain is optimally tuned for the things you want to accomplish, so if you can tweak it the right way, you might be able to improve your functioning.&nbsp; In extreme cases, you might have chronic imbalances leading to depression, mania, etc., in which case you'll probably want to talk to a doctor about medication; but the ability to use drugs to change yourself goes well beyond this.&nbsp; For example, judicious use of MDMA can help you retrain your social reflexes and become more outgoing and sociable.&nbsp; Having this handle also allows you to begin to experimentally correlate your subjective experience with the physical processes to which they correspond, and by carefully observing more unusual states of consciousness, you broaden your understanding of the mind and how it operates.&nbsp; Lastly, psychedelics can sometimes help you understand things differently or more deeply.&nbsp; I've often found my mathematical ability improved by moderate doses of LSD, for example.&nbsp; So, even for someone concerned primarily with rationality and the accumulation and application of knowledge, drugs are at least worth considering.</p>\n<p><strong>And what of the risks?</strong> says Bob.</p>\n<p>I was getting to that, says Alice.&nbsp; There will always be a risk/benefit tradeoff, but the risks can be minimized through careful and responsible use:</p>\n<ul>\n<li>Thoroughly research every new drug before trying it.&nbsp; Unfortunately, in the case of prohibited substances, very little good clinical research has been done (this has started to change in recent years, but there are still vast swaths of uncharted territory).&nbsp; Nevertheless, there's good information to be had.&nbsp; For drugs used recreationally, I usually start at <a href=\"http://erowid.org\">Erowid.org</a>, which provides an overall summary of the effects of a wide variety of drugs; academic citations and sometimes full articles, if there are any; \"trip reports\" (anecdotal evidence is better than nothing, especially if there's a lot of it); and other useful information.&nbsp; For nootropics and \"smart drugs\", I usually just start with a Google search and/or Wikipedia.</li>\n<li>Pay particular attention to addictive potential, toxicity and contraindications.&nbsp; Drugs with high addictive potential require extra caution, and should perhaps be avoided by people with akrasia problems.&nbsp; Also be mindful of any history of addiction you may have in your family.&nbsp; Regarding contraindications: beside drug interactions, a lot of this is just common sense.&nbsp; If you are prone to anxiety, you should probably avoid amphetamines.&nbsp; As far as toxicity goes, a good number to look at is the therapeutic index, which is the ratio of the LD50 (the dose, per kilogram of body weight, at which 50% of experimental test subjects (usually rodents) die) to the effective dose (per kilogram of body weight).&nbsp; However, keep in mind also that frequent or heavy drug use can tax the liver, and that otherwise safe chemicals may build up to toxic levels over time.</li>\n<li>If you decide to take a drug known to be addictive, take it in moderate quantities over brief periods of time, well-separated from each other.&nbsp; This is not a hard and fast rule: under a doctor's supervision, for example, you may choose to take prescribed medication every day.&nbsp; You should recognize, however, that this comes at a cost: antidepressants can be used to pull your life together and overcome depression, but it's going to be nasty coming off them.&nbsp; Finally, as a rule of thumb, oral ingestion is significantly less addictive than smoking, insufflation or injection, since this gives a gradual and delayed onset of the reward stimulus.&nbsp; For the same reason, you can further reduce your chances of becoming addicted by taking prodrugs wherever possible (e.g. Vyvanse instead of Dexedrine).</li>\n<li>Always take a low dose first, in case you react badly, and do so around other people who know what you are taking.</li>\n<li>To the greatest extent possible, maintain an open and honest relationship with your doctor, who is in a position to help you minimize the health risks associated with your drug-taking.</li>\n<li>If you decide to seek out prohibited substances, it's important to have a good source of high-quality product.&nbsp; Street drugs may be cut with cheap substitutes or contaminated with solvents used in extraction/synthesis, or they may simply not be what they are claimed to be.&nbsp; Go to people you trust who already do drugs on a regular basis, and ask them for help finding a reputable dealer.</li>\n</ul>\n<p>With that out of the way, continues Alice, let's start simple: <strong>what is a drug?</strong>&nbsp; For our purposes, we'll say a drug is any substance consumed for reasons other than its nutritive value or the sensory experience of consumption.&nbsp; We'll specifically be focusing on psychoactive drugs, which are consumed for their effects on the mind.&nbsp; Note that just about anything you eat or drink is potentially a psychoactive drug, and you may not have to turn to outlandish synthetic compounds to alter your neurochemistry.&nbsp; For example: after three years of vegetarianism, I gradually began to develop chronic anxiety, with occasional panic attacks.&nbsp; It plateaued at a (barely) manageable level, so I never ended up seeking medical help; it took two years before I thought to try eating meat again.&nbsp; When I finally did, the anxiety immediately vanished and has not returned.&nbsp; So, for me, meat is a psychoactive drug.&nbsp; In fact, let's talk about nutritional supplements first.</p>\n<h2>Supplements and Neurotransmitters<br /></h2>\n<p>The first group of drugs we're going to be looking at are neurotransmitters, and their chemical precursors, which can be found at health food stores.&nbsp; First, there are <strong>5-HTP and tryptophan</strong>, which are serotonin precursors.&nbsp; There is some evidence that these can help treat depression, improve quality of sleep, and improve your mood, but since you need to take it for a few days before you start to notice the effect, it might be hard to tell if this is actually doing anything for you.<br /><br />Next, consider <strong>phenylalanine</strong>, an amino acid which serves as a precursor to dopamine, norepinephrine and adrenaline.&nbsp; Phenylalanine is first metabolized into <strong>tyrosine</strong>, which is also available as a dietary supplement.&nbsp; Research seems to suggest that these are mainly effective only for people under conditions of physical, emotional or mental stress, and don't do much for the general population.&nbsp; I've found that, in fact, L-phenylalanine has a noticeable uplifting effect on my mood within a short time of taking it; but maybe this just says something about how much stress I'm under.<br /><br />Lastly, there's <strong>GABA</strong>, a neurotransmitter which has an inhibitory effect on the dopamine system and certain other neurotransmitters.&nbsp; In short, this will calm you down right quick, which makes it useful for dealing with intense and uncontrollable emotions - anxiety, grief, rage, etc.&nbsp; I find that, for this purpose, <strong>theanine</strong> is even better: it promotes GABA production and alpha brainwave activity, and also seems to increase dopamine levels.&nbsp; Its calming effect is very similar to that of GABA, but I find it much less likely to leave me feeling tired and out of it: if anything, it seems to have a mildly stimulating effect.&nbsp; As an added bonus, theanine appears to boost the immune system.&nbsp; Theanine synergizes well with caffeine, which we'll cover shortly.<br /><br />All of the above - 5-HTP, tryptophan, phenylalanine, tyrosine, theanine and GABA - are not only useful for regulating your mood, but also for learning what your neurochemistry feels like from the inside.&nbsp; I found it edifying to take fairly large doses of 5-HTP (or phenylalanine, etc.) every day for a couple weeks, stop for a few weeks, go back on for a couple weeks, stop, etc. - all the while noting changes in my mood and perception.&nbsp; In that respect, <strong>melatonin</strong> tablets can be added to this list: they're not really going to make you a more effective rationalist, but they will teach you what melatonin does to your cognition.&nbsp; Melatonin will also be useful if you're taking stimulants, which might otherwise interfere with your sleep patterns.</p>\n<p>It is also worth mentioning that vitamin deficiencies (or excesses) can have a significant impact on mood and cognitive functioning.&nbsp; I recommend taking <strong>multivitamins</strong>; this need not be a daily regimen if you have a healthy diet, just kind of take them when you remember to.&nbsp; Women should look for multivitamins with iron, and men should look for those without.</p>\n<h2>Stimulants<br /></h2>\n<p>Next, let's talk about stimulants, starting with <strong>caffeine</strong> - by far the most popular, although by no means the most effective.&nbsp; Caffeine works by blocking the activity of adenosine, an inhibitory neurotransmitter that plays a role in sleep and drowsiness.&nbsp; As a result, neural activity goes up, accompanied by a kick to the sympathetic nervous system and an increase in blood sugar levels.&nbsp; Taken on a fairly regular daily schedule, caffeine seems to improve my attention, motivation and energy level.&nbsp; In the long term, there appear to be health benefits from drinking coffee in this way: in addition to its stimulating effects, it appears to help prevent heart disease, Alzheimer's disease and Parkinson's disease, among others.&nbsp; For all-nighters, though, caffeine is an inferior choice: although it suffices to keep you up and running, it doesn't seem to do much to mitigate the cognitive effects of sleep deprivation.&nbsp; Also, as increasing amounts are consumed, a variety of unpleasant side-effects begin to appear, including tremors, heart palpitations, anxiety, diarrhea, and dehydration.&nbsp; It should also be noted that caffeine builds tolerance, and the withdrawal is rather unpleasant.&nbsp; Despite this, it seems to make sense to take coffee every day in moderation, unless you are especially sensitive to its negative effects.</p>\n<p>Caffeine can also be had in tea (green tea, in particular, also contains theanine, as we discussed), in chocolate, preferably dark (chocolate also contains a number of other psychoactive alkaloids, including phenylalanine and theobromine), in caffeine pills and in <strong>energy drinks</strong>.&nbsp; It is perhaps worth mentioning that I find that the energy drinks and energy shots containing other medicinal ingredients (phenylalanine, taurine, B vitamins, etc.) really do seem to be slightly better, minimizing the unpleasant side effects and smoothing out the crash.&nbsp; Still, I try to avoid these because of the sugar and/or artificial sweetener content.&nbsp; It is unclear exactly what effect each of these other medicinal ingredients has individually, if any at all, so you should also be warned that you are probably buying some nonsense along with your actually mind-altering compounds.</p>\n<p>Next are <strong>amphetamines</strong>, which act on the serotonin, norepinephrine and especially dopamine systems, causing increased focus, improved cognitive ability, and elevated energy levels.&nbsp; They also mitigate some of the effects of sleep deprivation, although your cognitive performance will still suffer.&nbsp; While amphetamines can greatly improve your productivity if used correctly, they can also easily do the opposite, because it's just as easy to hyperfocus on video games as it is to hyperfocus on neural network algorithms.&nbsp; Body tics and bad habits can also get strongly reinforced, since your reward systems are getting pummelled by dopamine.&nbsp; Basically, if you're doing amphetamines, keep your akrasia-fighting systems on high alert (fortunately this, too, will be aided by the amphetamines).&nbsp; Another downside to amphetamines is that they're quite addictive; take them either in fixed quantities on a regular schedule (if you have a prescription) or else in occasional bursts of no more than a few days, and in moderate quantities.</p>\n<p>Beside addiction, a lot of the danger from amphetamines comes from failing to eat and sleep, if you're taking them for more than a day or two.&nbsp; Amphetamines are strong appetite suppressants, and of course they keep you awake, so you'll need to force yourself to eat three square meals a day and get to sleep at a reasonable hour.&nbsp; Sleep is especially important because the longer you stay up, the more amphetamines you have to take to stay awake; if your dose gets high enough, and if you're badly enough sleep deprived, you put yourself at risk of amphetamine psychosis, which is about as much fun as it sounds like.</p>\n<p>There are a number of prescription amphetamines on the market, and these are generally to be preferred to street speed, due to their purity and lack of adulterants.&nbsp; It's not terribly hard to get diagnosed with ADD/ADHD, so this can be above-the-board.&nbsp; <strong>Dexedrine</strong> is pure dextroamphetamine, while <strong>Adderall</strong> is a mix of dextroamphetamine and racemic salts (which contain a 50%/50% split between dextro- and levoamphetamine).&nbsp; The difference between the two stereoisomers is complicated, and your best bet is to experiment to see which works best for you, but a rule of thumb is that Adderall has more \"kick\" at lower doses, while Dexedrine is stronger at higher doses.&nbsp; <strong>Methamphetamine</strong>, you may be surprised to learn, is also prescribed for ADHD, although much more rarely.&nbsp; Meth is stronger, longer-lasting, and significantly more addictive, than amphetamine.&nbsp; It is also more neurotoxic.&nbsp; I would recommend exercising extreme caution around this one, or else avoiding it entirely, unless you actually have severe ADHD and this is the only thing that works for you.&nbsp; Lastly, there is a prodrug for dextroamphetamine that just came on the market, called <strong>Vyvanse</strong> (lisdexamphetamine).&nbsp; This has a much slower onset, since it has to be metabolized into dextroamphetamine, and therefore has significantly less addiction potential.<strong></strong></p>\n<p><strong>Ritalin</strong> works similarly to amphetamines; apparently it tends to produce less euphoria.&nbsp; <strong>Ephedrine</strong> is chemically similar to amphetamines, but works primarily by increasing the activity of noradrenaline; it has the advantage of being legally available without a prescription.&nbsp; I mention these only in passing because I don't have much experience with them; if you want to contribute some information about them, please comment!</p>\n<p>I also want to briefly mention <strong>MDPV</strong> (methylenedioxypyrovalerone), an experimental stimulant still legally available in the U.S. and in Canada (sold online as a research chemical or, sometimes, as \"envigorating bath salts\").&nbsp; This one acts as a dopamine and norepinephrine reuptake inhibitor, producing a state reminiscent of that caused by amphetamines.&nbsp; It has a quick onset and short lifetime (3-5 hours), which makes it well-suited to accomplishing quick chores.&nbsp; However, there are a number of nasty side effects reported, and it seems to have some addictive potential.&nbsp; Looking at the evidence, it appears that most of the people reporting this sort of thing were insufflating larger doses; so taken orally and in moderation, this one can still be reasonably safe.&nbsp; But there's very little out there that's peer-reviewed, so take a look at some trip reports and proceed with caution.</p>\n<p>All of this probably makes it sound like stimulants are, at best, not far off from a zero-sum game: they may benefit cognitive performance, but they come with side effects and addictive potential and a nasty crash when you come off them.&nbsp; Well, good news: we'll be considering <strong>Modafinil</strong> next, which some are calling the perfect stimulant.&nbsp; Modafinil is sold by prescription only, but its prodrug, <strong>Adrafinil</strong>, can be purchased online.&nbsp; I've taken the latter on a number of occasions, and have been quite impressed with the results.&nbsp; Adrafinil promotes a state of wakefulness and energy, but without the \"edge\" that comes with amphetamine use.&nbsp; Even under conditions of sleep deprivation it has a significant positive effect on cognitive functioning, memory retention, focus and motivation.&nbsp; It has no significant crash, produces no tolerance, and seems to have very little addictive potential.&nbsp; You can even sleep on Adrafinil, if you wish; this is a significant advantage over all of the other stimulants we've discussed, since if you take dexedrine at 9PM and finish your work at 1AM, you're still effectively committed to staying up all night.&nbsp; Adrafinil also seems to have a positive effect on mood; lastly, there are signs it can be used both to prevent and to treat some of the effects of aging on energy level and cognitive ability.</p>\n<p>Modafinil and Adrafinil are not perfectly safe, though.&nbsp; They put a fairly heavy load on the liver and kidneys if taken daily, and should therefore be taken only occasionally, unless as part of medically-supervised treatment.&nbsp; There are also occasional side effects to watch out for, most notably skin infections.</p>\n<h2>Nootropics<br /></h2>\n<p>Nootropics are still a very new and experimental class of drugs.&nbsp; Many purported nootropics give negative or inconclusive results in clinical tests, and many of them have not been tested at all, or very little: more specifically, most of the research has focused around using nootropics to treat neural disorders and injuries, or to mitigate the effects of aging, with very little focus on young and healthy individuals.&nbsp; This does not mean, however, that they do nothing beneficial; it only means that you'll have to do some careful experimentation to determine how they effect you, if at all.&nbsp; For our purposes, I'll only be covering some of the more popular and (most importantly) well-studied nootropic drugs.</p>\n<p>We'll start with <strong>piracetam</strong>.&nbsp; The research on piracetam shows positive effects in the prevention and treatment of aphasia, dementia, epilepsy and hypoxic injury, but says almost nothing about its effect on healthy individuals.&nbsp; The general consensus among those who take it daily is that it seems to do something, though it's hard to put a finger on.&nbsp; One friend of mine suggests that it seems to subtly improve the general flow of cognition, making memories and good ideas more available.&nbsp; One significant effect that piracetam seems to have is general potentiation of other drugs, especially stimulants and psychedelics, so if you incorporate piracetam into your daily regimen, you should be extra-careful about trying new drugs.</p>\n<p>Another \"smart drug\" is <strong>DHEA</strong>, an endogenous chemical with a variety of functions, including inhibition of cortisol.&nbsp; The research shows that it has anti-depressant effects, and seems to improve cognitive functioning under stressful conditions.&nbsp; It also seems to improve episodic memory in young men, but has no such effect in elderly people.&nbsp; You'll note I said \"young men\", not \"young people\": the effects of DHEA appear to be asymmetric with respect to gender.&nbsp; In particular, higher levels of endogenous DHEA are correlated with longer lifespan in men, but there is no such correlation in women.</p>\n<p>On the life extention angle, another nootropic worth considering is <strong>Selegiline</strong>, which appears to be available for purchase online, although technically it's not supposed to be sold to anyone without a prescription (possession, on the other hand, is legal).&nbsp; Selegiline is an MAO-B inhibitor, commonly used to treat Parkinson's, depression and dementia.&nbsp; Even for someone without these conditions, Selegiline produces cognitive benefits similar to those of Adrafinil, and there are reports that long-term use might tend to increase your lifespan.&nbsp; Looking at the evidence, I am inclined to take such claims seriously.&nbsp; Since it targets MAO-B specifically, Selegiline is less dangerous than nonspecific MAOIs.&nbsp; However, at higher doses, Selegiline to lose its specificity and inhibit MAO-A also.&nbsp; Women on oral contraception should be especially careful, as birth control pills appear to increase Selegiline's bioavailability, so that MAO-A inhibition may kick in at lower doses.&nbsp; At any rate, use caution with this one, and take lower-than-usual doses of other substances, including foods containing tyrosine and other potentially dangerous monoamines (e.g. chocolate, cheese, wine).</p>\n<p>Some other less common nootropics with effects similar to those of the above include <strong>Vinpocetine</strong> and <strong>Hydergine</strong>, which function as neuroprotectives and might also improve cognitive functioning.&nbsp; I haven't tried these, and available research is slim, so I can't say much.&nbsp; Beyond the nootropics we've discussed, the field begins to look a little grim.&nbsp; For example, the jury seems to be out on <strong>ginkgo biloba</strong>: some clinical trials failed to demonstrate any measurable effect on memory or cognition, and others appeared to show short-term benefits.&nbsp; It gets worse, though, than merely ambiguous research.&nbsp; For example, <strong>DMAE</strong>, once marketed as a life-extension agent, may actually shorten your lifespan.&nbsp; Other nootropics have turned out to be severely toxic, such as <strong>Fipexide</strong>, which appears to cause liver failure with prolonged use.&nbsp; At any rate, your best bet is probably to stick with established and well-studied drugs; there are whole communities out there perfectly willing to put themselves on the line testing new contenders, and I feel it's best to leave that up to them.</p>\n<h2>Psychedelics and \"recreational\" drugs<br /></h2>\n<p>Now, says Alice, for psychedelics.&nbsp; We should begin with some general remarks.&nbsp; First of all, these are contraindicated for anyone with a family history or predisposition to psychotic disorders.&nbsp; More generally, set and setting (mental state and external circumstances, respectively) are extremely important to having a positive experience.&nbsp; Psychedelics have been described as \"nonspecific amplifiers of experience\", which means that if you're having a bad day, acid will probably make it worse.&nbsp; Ideally, your first trip should be in a place where you feel safe and inspired, with a few people you trust and who are experienced and knowledgeable about the drug you're taking.&nbsp; You'll probably want to have art books, sketchbooks, good music and someplace comfy to lie or sit.</p>\n<p>Your provisos and warnings are all well and good, says Bob, but <strong>what do psychedelics actually do?</strong></p>\n<p>It's... hard to describe, says Alice, in the same way that the colour red is hard to describe, but I'll give it a shot; just keep in mind this is an incomplete description.&nbsp; First there are the visual effects.&nbsp; These aren't hallucinations, in the sense that you'll recognize them as being effects of the drug.&nbsp; With your eyes open, you'll tend to see colours intensified and altered, and your brain will be having a field day reinterpreting interesting textures (cf. <a href=\"http://en.wikipedia.org/wiki/Pareidolia\">pareidolia</a> and <a href=\"http://en.wikipedia.org/wiki/Form_constant\">form constants</a>); with your eyes closed, you'll see animated geometric patterns, tessellations, visions, and all kinds of surprisingly interesting stuff.&nbsp; Depictions in popular culture of psychedelic experiences are notoriously bad, but <a href=\"http://www.youtube.com/watch?v=FINU71FyMto\">this movie</a> does a reasonably good job.&nbsp; In addition to visual alterations (which can teach you <a href=\"http://www.math.utah.edu/~bresslof/publications/Colston.pdf\">a lot</a> about the functioning of your visual cortex) you might also experience changes in auditory and tactile sensation, as well as synaesthetic crossover between senses.</p>\n<p>Even more interesting than the sensory changes are the cognitive effects.&nbsp; It turns out that your sense of a coherent self can be overridden, and you may experience a blurring of the boundary between you and everything else.&nbsp; You may have strange, spontaneous ideas or insights; to some extent this is because the peculiarity of the experience forces you to reexamine tacit assumptions hidden deep in your reality model; these assumptions do not always turn out to be wrong, but it's good to be aware of them and to understand them more deeply.&nbsp; You may also become unusually aware of pathologies in your lifestyle and relationships, and with practice you may be better able to articulate those pathologies, than you are normally.&nbsp; Ideas that come to you while high must be carefully examined and tested while sober, of course, but my experience has been that many of them turn out to be genuinely good ideas, and some have even led to significant improvements in my functional relationship to the world.</p>\n<p><strong>LSD</strong>, in particular, seems well-suited to understanding technical fields, including math and physics.&nbsp; Unlike <strong>mushrooms</strong>, acid does not significantly impair my ability to read and understand mathematical texts, and the heightened ability to flex my visual cortex allows me to see difficult and abstract constructions quite vividly, as well as to understand on an intuitive level how they work.&nbsp; Mushrooms, conversely, are more likely to present me (somewhat forcefully) with ideas I might never have otherwise considered.&nbsp; These two are the most popular psychedelics, and the two experiences bear a definite family resemblance.&nbsp; LSD is calmer, and easier to control and direct, but it lasts up to twice as long as mushrooms - twelve hours is common.&nbsp; Mushrooms tend to be more emotionally intense: usually this means euphoria and lots of giggling, but occasionally you might be overcome by grief or anger, especially if you're already feeling that way before you dose.<strong></strong></p>\n<p>I'm not going to say much about <strong>cannabis</strong>, because while the experience is certainly interesting, it's probably not going to help most of you think better (there are some, mind you, who actually function better with THC in their systems; Carl Sagan, for example, was a notorious pothead).&nbsp; One reason you might want to take cannabis anyway is that it can serve as a gentle introduction to psychedelia - but be warned that some people, even those who generally enjoy psychedelics, have consistently bad reactions to THC.&nbsp; Proceed with caution.&nbsp; Another reason to take cannabis is for life extension purposes; there's good evidence that THC helps prevent certain kinds of cancer.&nbsp; If you're taking it for health reasons, though, you probably want to use a vapourizer or eat it instead of smoking it.&nbsp; Also note that, at least for some particularly susceptible people, cannabis can be addictive.&nbsp; Again, if you have reason to believe you're prone to substance abuse, you might want to give this one a skip.</p>\n<p>Another controlled substance to consider is <strong>MDMA</strong>.&nbsp; MDMA has a variety of neurochemical effects: it inhibits dopamine and norepinephrine reuptake, actually <em>reverses</em> the serotonin reuptake pump, and also seems to increase levels of oxytocin, the \"trust hormone\".&nbsp; So, you feel a sense of love, joy, wellbeing, safety, etc.&nbsp; You'll also get many of the same stimulant effects as methamphetamine, albeit milder.&nbsp; I mention MDMA because in my experience, if you already have a decent idea of how social interactions are supposed to work but still have trouble getting over your anxiety, this can help you teach yourself to be more socially confident, if taken in the appropriate environment (hint: do this around other people on MDMA).&nbsp; The surge of oxytocin makes you temporarily fearless about approaching strangers, and also cushions the blow if things go badly, while the increased dopamine activity strongly reinforces behaviours leading to successful interactions.&nbsp; This learned confidence persists into the sober state.&nbsp; MDMA is also useful for confronting emotionally difficult issues - indeed, it was used for psychotherapy before it became popular recreationally and was banned - but I'll leave that to you to research on your own.</p>\n<p>Some <strong>warnings about MDMA</strong>.&nbsp; First of all, most \"Ecstasy\" contains adulterants (commonly caffeine and methamphetamine and sometimes PCP, among others), and sometimes contains no MDMA at all.&nbsp; As a general rule, avoid pressed pills; pure MDMA most commonly comes in crystal form.&nbsp; If you don't have a reliable source, you might want to skip MDMA entirely.&nbsp; Also note that MDMA commonly causes hangovers, although these can be mitigated by taking 5-HTP.</p>\n<p>Lastly, although all the drugs I've mentioned in this section are controlled, you might actually be able to experience very similar altered states legally.&nbsp; Alex and Ann Shulgin, the research chemist and psychotherapist (respectively) who first popularized MDMA, also came up with literally hundreds of other psychoactive compounds, many of which are still legal outside America and can be purchased online from so-called \"<strong>research chemical</strong>\" companies (the U.S. has the Analogues Act, which automatically makes illegal any chemical broadly similar to any other illegal chemical, but Canada, among other countries, has not shared this dismal fate).&nbsp; For example, instead of MDMA, you might consider <strong>AMT</strong>, a tryptamine with similar and in some ways better effects.&nbsp; Another research chemical, <strong>4-ACO-DMT</strong>, is actually metabolized into psilocin, as is psilocybin, and so the trip is almost identical to that of mushrooms.&nbsp; The downside to all this is that research chemicals are generally sold only in larger quantities, so if you don't want to drop a couple hundred dollars on something you may not enjoy, this may not be your best bet.&nbsp; There's also the fact that these are not as well-understood as more popular psychedelics, which makes them riskier, although these risks can be minimized by using caution and moderation.</p>\n<h2>Conclusion</h2>\n<p>As we've seen, says Alice with a smirk, you too can alter your neurochemistry for fun and profit - but this must be done responsibly.&nbsp; Although I've tried to give a sense of the dangers alongside the benefits, this post is really only meant to serve as a broad introduction.&nbsp; If you're thinking of actually trying any of the drugs I've mentioned, it's important that you do some in-depth research, and a proper cost-benefit analysis.&nbsp; But with a little practice, you too can expand your mind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xHjy88N2uJvGdgzfw": 1, "FwM9CYSSXgjX6fJvG": 1, "FdoP2PJhMz6x3gdDh": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NYPmCBfrDfXfhwBog", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 81, "baseScore": 91, "extendedScore": null, "score": 0.000167, "legacy": true, "legacyId": "5394", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 91, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This is a first draft.&nbsp; Over the next few days I'll add citations and that sort of thing, but I'm posting it as-is in order to solicit feedback.&nbsp; Also, I wasn't able to find any specific policy regarding mention of illicit substances, so I'm going to assume this is okay, but if not please let me know.</p>\n<p><strong>Disclaimer:</strong> This is a work of postmodern fiction about two irredeemable junkies named Alice and Bob and their cat Fido.&nbsp; The views contained herein are not medical or legal advice, they are not my views, and they are not the views of LessWrong.com or any of its members.&nbsp; In fact they are not views at all: they are transnarrative flows in alterity-space, or that's what my lit prof tells me.&nbsp; I do not condone any illegal activity whatsoever, except jaywalking.</p>\n<h2 id=\"Introduction\"><strong>Introduction</strong><br></h2>\n<p>Today, says Alice, I'm going to talk to you about drugs.&nbsp; I'll be covering several nutritional supplements, some stimulants and nootropics, and - as some of you have probably guessed - I'll also be talking briefly about recreational drugs, particularly psychedelics.&nbsp; Now, I don't have any sense of what the popular perception is of drugs around here, but I presume that at least some of you will be a little put off at the suggestion of recreational drug use.&nbsp; If that is how you feel, please bear with me.&nbsp; To partake or not partake of prohibited substances is a choice that must be made individually, and for many the payoffs may not be worth the risks; but I hope to convince you that, at least for some people, responsible drug use is a very reasonable and beneficial activity.</p>\n<p>Well, hold on, says Bob - who takes a permissive but detached view of these things - hold on, now.&nbsp; It may be true (as cursory research will show) that drug use is far less dangerous than it's made out to be, and it may be true that some people get a lot of enjoyment out of them.&nbsp; But if you value knowledge and reason over hedonic pleasure, it seems better to cut them out entirely.&nbsp; After all, it's your brain on the line if anything goes wrong!</p>\n<p>As a matter of fact, says Alice, drugs are good for more than just hedonism.&nbsp; First of all, they give you a handle on your own neurochemistry.&nbsp; It's unlikely that your brain is optimally tuned for the things you want to accomplish, so if you can tweak it the right way, you might be able to improve your functioning.&nbsp; In extreme cases, you might have chronic imbalances leading to depression, mania, etc., in which case you'll probably want to talk to a doctor about medication; but the ability to use drugs to change yourself goes well beyond this.&nbsp; For example, judicious use of MDMA can help you retrain your social reflexes and become more outgoing and sociable.&nbsp; Having this handle also allows you to begin to experimentally correlate your subjective experience with the physical processes to which they correspond, and by carefully observing more unusual states of consciousness, you broaden your understanding of the mind and how it operates.&nbsp; Lastly, psychedelics can sometimes help you understand things differently or more deeply.&nbsp; I've often found my mathematical ability improved by moderate doses of LSD, for example.&nbsp; So, even for someone concerned primarily with rationality and the accumulation and application of knowledge, drugs are at least worth considering.</p>\n<p><strong>And what of the risks?</strong> says Bob.</p>\n<p>I was getting to that, says Alice.&nbsp; There will always be a risk/benefit tradeoff, but the risks can be minimized through careful and responsible use:</p>\n<ul>\n<li>Thoroughly research every new drug before trying it.&nbsp; Unfortunately, in the case of prohibited substances, very little good clinical research has been done (this has started to change in recent years, but there are still vast swaths of uncharted territory).&nbsp; Nevertheless, there's good information to be had.&nbsp; For drugs used recreationally, I usually start at <a href=\"http://erowid.org\">Erowid.org</a>, which provides an overall summary of the effects of a wide variety of drugs; academic citations and sometimes full articles, if there are any; \"trip reports\" (anecdotal evidence is better than nothing, especially if there's a lot of it); and other useful information.&nbsp; For nootropics and \"smart drugs\", I usually just start with a Google search and/or Wikipedia.</li>\n<li>Pay particular attention to addictive potential, toxicity and contraindications.&nbsp; Drugs with high addictive potential require extra caution, and should perhaps be avoided by people with akrasia problems.&nbsp; Also be mindful of any history of addiction you may have in your family.&nbsp; Regarding contraindications: beside drug interactions, a lot of this is just common sense.&nbsp; If you are prone to anxiety, you should probably avoid amphetamines.&nbsp; As far as toxicity goes, a good number to look at is the therapeutic index, which is the ratio of the LD50 (the dose, per kilogram of body weight, at which 50% of experimental test subjects (usually rodents) die) to the effective dose (per kilogram of body weight).&nbsp; However, keep in mind also that frequent or heavy drug use can tax the liver, and that otherwise safe chemicals may build up to toxic levels over time.</li>\n<li>If you decide to take a drug known to be addictive, take it in moderate quantities over brief periods of time, well-separated from each other.&nbsp; This is not a hard and fast rule: under a doctor's supervision, for example, you may choose to take prescribed medication every day.&nbsp; You should recognize, however, that this comes at a cost: antidepressants can be used to pull your life together and overcome depression, but it's going to be nasty coming off them.&nbsp; Finally, as a rule of thumb, oral ingestion is significantly less addictive than smoking, insufflation or injection, since this gives a gradual and delayed onset of the reward stimulus.&nbsp; For the same reason, you can further reduce your chances of becoming addicted by taking prodrugs wherever possible (e.g. Vyvanse instead of Dexedrine).</li>\n<li>Always take a low dose first, in case you react badly, and do so around other people who know what you are taking.</li>\n<li>To the greatest extent possible, maintain an open and honest relationship with your doctor, who is in a position to help you minimize the health risks associated with your drug-taking.</li>\n<li>If you decide to seek out prohibited substances, it's important to have a good source of high-quality product.&nbsp; Street drugs may be cut with cheap substitutes or contaminated with solvents used in extraction/synthesis, or they may simply not be what they are claimed to be.&nbsp; Go to people you trust who already do drugs on a regular basis, and ask them for help finding a reputable dealer.</li>\n</ul>\n<p>With that out of the way, continues Alice, let's start simple: <strong>what is a drug?</strong>&nbsp; For our purposes, we'll say a drug is any substance consumed for reasons other than its nutritive value or the sensory experience of consumption.&nbsp; We'll specifically be focusing on psychoactive drugs, which are consumed for their effects on the mind.&nbsp; Note that just about anything you eat or drink is potentially a psychoactive drug, and you may not have to turn to outlandish synthetic compounds to alter your neurochemistry.&nbsp; For example: after three years of vegetarianism, I gradually began to develop chronic anxiety, with occasional panic attacks.&nbsp; It plateaued at a (barely) manageable level, so I never ended up seeking medical help; it took two years before I thought to try eating meat again.&nbsp; When I finally did, the anxiety immediately vanished and has not returned.&nbsp; So, for me, meat is a psychoactive drug.&nbsp; In fact, let's talk about nutritional supplements first.</p>\n<h2 id=\"Supplements_and_Neurotransmitters\">Supplements and Neurotransmitters<br></h2>\n<p>The first group of drugs we're going to be looking at are neurotransmitters, and their chemical precursors, which can be found at health food stores.&nbsp; First, there are <strong>5-HTP and tryptophan</strong>, which are serotonin precursors.&nbsp; There is some evidence that these can help treat depression, improve quality of sleep, and improve your mood, but since you need to take it for a few days before you start to notice the effect, it might be hard to tell if this is actually doing anything for you.<br><br>Next, consider <strong>phenylalanine</strong>, an amino acid which serves as a precursor to dopamine, norepinephrine and adrenaline.&nbsp; Phenylalanine is first metabolized into <strong>tyrosine</strong>, which is also available as a dietary supplement.&nbsp; Research seems to suggest that these are mainly effective only for people under conditions of physical, emotional or mental stress, and don't do much for the general population.&nbsp; I've found that, in fact, L-phenylalanine has a noticeable uplifting effect on my mood within a short time of taking it; but maybe this just says something about how much stress I'm under.<br><br>Lastly, there's <strong>GABA</strong>, a neurotransmitter which has an inhibitory effect on the dopamine system and certain other neurotransmitters.&nbsp; In short, this will calm you down right quick, which makes it useful for dealing with intense and uncontrollable emotions - anxiety, grief, rage, etc.&nbsp; I find that, for this purpose, <strong>theanine</strong> is even better: it promotes GABA production and alpha brainwave activity, and also seems to increase dopamine levels.&nbsp; Its calming effect is very similar to that of GABA, but I find it much less likely to leave me feeling tired and out of it: if anything, it seems to have a mildly stimulating effect.&nbsp; As an added bonus, theanine appears to boost the immune system.&nbsp; Theanine synergizes well with caffeine, which we'll cover shortly.<br><br>All of the above - 5-HTP, tryptophan, phenylalanine, tyrosine, theanine and GABA - are not only useful for regulating your mood, but also for learning what your neurochemistry feels like from the inside.&nbsp; I found it edifying to take fairly large doses of 5-HTP (or phenylalanine, etc.) every day for a couple weeks, stop for a few weeks, go back on for a couple weeks, stop, etc. - all the while noting changes in my mood and perception.&nbsp; In that respect, <strong>melatonin</strong> tablets can be added to this list: they're not really going to make you a more effective rationalist, but they will teach you what melatonin does to your cognition.&nbsp; Melatonin will also be useful if you're taking stimulants, which might otherwise interfere with your sleep patterns.</p>\n<p>It is also worth mentioning that vitamin deficiencies (or excesses) can have a significant impact on mood and cognitive functioning.&nbsp; I recommend taking <strong>multivitamins</strong>; this need not be a daily regimen if you have a healthy diet, just kind of take them when you remember to.&nbsp; Women should look for multivitamins with iron, and men should look for those without.</p>\n<h2 id=\"Stimulants\">Stimulants<br></h2>\n<p>Next, let's talk about stimulants, starting with <strong>caffeine</strong> - by far the most popular, although by no means the most effective.&nbsp; Caffeine works by blocking the activity of adenosine, an inhibitory neurotransmitter that plays a role in sleep and drowsiness.&nbsp; As a result, neural activity goes up, accompanied by a kick to the sympathetic nervous system and an increase in blood sugar levels.&nbsp; Taken on a fairly regular daily schedule, caffeine seems to improve my attention, motivation and energy level.&nbsp; In the long term, there appear to be health benefits from drinking coffee in this way: in addition to its stimulating effects, it appears to help prevent heart disease, Alzheimer's disease and Parkinson's disease, among others.&nbsp; For all-nighters, though, caffeine is an inferior choice: although it suffices to keep you up and running, it doesn't seem to do much to mitigate the cognitive effects of sleep deprivation.&nbsp; Also, as increasing amounts are consumed, a variety of unpleasant side-effects begin to appear, including tremors, heart palpitations, anxiety, diarrhea, and dehydration.&nbsp; It should also be noted that caffeine builds tolerance, and the withdrawal is rather unpleasant.&nbsp; Despite this, it seems to make sense to take coffee every day in moderation, unless you are especially sensitive to its negative effects.</p>\n<p>Caffeine can also be had in tea (green tea, in particular, also contains theanine, as we discussed), in chocolate, preferably dark (chocolate also contains a number of other psychoactive alkaloids, including phenylalanine and theobromine), in caffeine pills and in <strong>energy drinks</strong>.&nbsp; It is perhaps worth mentioning that I find that the energy drinks and energy shots containing other medicinal ingredients (phenylalanine, taurine, B vitamins, etc.) really do seem to be slightly better, minimizing the unpleasant side effects and smoothing out the crash.&nbsp; Still, I try to avoid these because of the sugar and/or artificial sweetener content.&nbsp; It is unclear exactly what effect each of these other medicinal ingredients has individually, if any at all, so you should also be warned that you are probably buying some nonsense along with your actually mind-altering compounds.</p>\n<p>Next are <strong>amphetamines</strong>, which act on the serotonin, norepinephrine and especially dopamine systems, causing increased focus, improved cognitive ability, and elevated energy levels.&nbsp; They also mitigate some of the effects of sleep deprivation, although your cognitive performance will still suffer.&nbsp; While amphetamines can greatly improve your productivity if used correctly, they can also easily do the opposite, because it's just as easy to hyperfocus on video games as it is to hyperfocus on neural network algorithms.&nbsp; Body tics and bad habits can also get strongly reinforced, since your reward systems are getting pummelled by dopamine.&nbsp; Basically, if you're doing amphetamines, keep your akrasia-fighting systems on high alert (fortunately this, too, will be aided by the amphetamines).&nbsp; Another downside to amphetamines is that they're quite addictive; take them either in fixed quantities on a regular schedule (if you have a prescription) or else in occasional bursts of no more than a few days, and in moderate quantities.</p>\n<p>Beside addiction, a lot of the danger from amphetamines comes from failing to eat and sleep, if you're taking them for more than a day or two.&nbsp; Amphetamines are strong appetite suppressants, and of course they keep you awake, so you'll need to force yourself to eat three square meals a day and get to sleep at a reasonable hour.&nbsp; Sleep is especially important because the longer you stay up, the more amphetamines you have to take to stay awake; if your dose gets high enough, and if you're badly enough sleep deprived, you put yourself at risk of amphetamine psychosis, which is about as much fun as it sounds like.</p>\n<p>There are a number of prescription amphetamines on the market, and these are generally to be preferred to street speed, due to their purity and lack of adulterants.&nbsp; It's not terribly hard to get diagnosed with ADD/ADHD, so this can be above-the-board.&nbsp; <strong>Dexedrine</strong> is pure dextroamphetamine, while <strong>Adderall</strong> is a mix of dextroamphetamine and racemic salts (which contain a 50%/50% split between dextro- and levoamphetamine).&nbsp; The difference between the two stereoisomers is complicated, and your best bet is to experiment to see which works best for you, but a rule of thumb is that Adderall has more \"kick\" at lower doses, while Dexedrine is stronger at higher doses.&nbsp; <strong>Methamphetamine</strong>, you may be surprised to learn, is also prescribed for ADHD, although much more rarely.&nbsp; Meth is stronger, longer-lasting, and significantly more addictive, than amphetamine.&nbsp; It is also more neurotoxic.&nbsp; I would recommend exercising extreme caution around this one, or else avoiding it entirely, unless you actually have severe ADHD and this is the only thing that works for you.&nbsp; Lastly, there is a prodrug for dextroamphetamine that just came on the market, called <strong>Vyvanse</strong> (lisdexamphetamine).&nbsp; This has a much slower onset, since it has to be metabolized into dextroamphetamine, and therefore has significantly less addiction potential.<strong></strong></p>\n<p><strong>Ritalin</strong> works similarly to amphetamines; apparently it tends to produce less euphoria.&nbsp; <strong>Ephedrine</strong> is chemically similar to amphetamines, but works primarily by increasing the activity of noradrenaline; it has the advantage of being legally available without a prescription.&nbsp; I mention these only in passing because I don't have much experience with them; if you want to contribute some information about them, please comment!</p>\n<p>I also want to briefly mention <strong>MDPV</strong> (methylenedioxypyrovalerone), an experimental stimulant still legally available in the U.S. and in Canada (sold online as a research chemical or, sometimes, as \"envigorating bath salts\").&nbsp; This one acts as a dopamine and norepinephrine reuptake inhibitor, producing a state reminiscent of that caused by amphetamines.&nbsp; It has a quick onset and short lifetime (3-5 hours), which makes it well-suited to accomplishing quick chores.&nbsp; However, there are a number of nasty side effects reported, and it seems to have some addictive potential.&nbsp; Looking at the evidence, it appears that most of the people reporting this sort of thing were insufflating larger doses; so taken orally and in moderation, this one can still be reasonably safe.&nbsp; But there's very little out there that's peer-reviewed, so take a look at some trip reports and proceed with caution.</p>\n<p>All of this probably makes it sound like stimulants are, at best, not far off from a zero-sum game: they may benefit cognitive performance, but they come with side effects and addictive potential and a nasty crash when you come off them.&nbsp; Well, good news: we'll be considering <strong>Modafinil</strong> next, which some are calling the perfect stimulant.&nbsp; Modafinil is sold by prescription only, but its prodrug, <strong>Adrafinil</strong>, can be purchased online.&nbsp; I've taken the latter on a number of occasions, and have been quite impressed with the results.&nbsp; Adrafinil promotes a state of wakefulness and energy, but without the \"edge\" that comes with amphetamine use.&nbsp; Even under conditions of sleep deprivation it has a significant positive effect on cognitive functioning, memory retention, focus and motivation.&nbsp; It has no significant crash, produces no tolerance, and seems to have very little addictive potential.&nbsp; You can even sleep on Adrafinil, if you wish; this is a significant advantage over all of the other stimulants we've discussed, since if you take dexedrine at 9PM and finish your work at 1AM, you're still effectively committed to staying up all night.&nbsp; Adrafinil also seems to have a positive effect on mood; lastly, there are signs it can be used both to prevent and to treat some of the effects of aging on energy level and cognitive ability.</p>\n<p>Modafinil and Adrafinil are not perfectly safe, though.&nbsp; They put a fairly heavy load on the liver and kidneys if taken daily, and should therefore be taken only occasionally, unless as part of medically-supervised treatment.&nbsp; There are also occasional side effects to watch out for, most notably skin infections.</p>\n<h2 id=\"Nootropics\">Nootropics<br></h2>\n<p>Nootropics are still a very new and experimental class of drugs.&nbsp; Many purported nootropics give negative or inconclusive results in clinical tests, and many of them have not been tested at all, or very little: more specifically, most of the research has focused around using nootropics to treat neural disorders and injuries, or to mitigate the effects of aging, with very little focus on young and healthy individuals.&nbsp; This does not mean, however, that they do nothing beneficial; it only means that you'll have to do some careful experimentation to determine how they effect you, if at all.&nbsp; For our purposes, I'll only be covering some of the more popular and (most importantly) well-studied nootropic drugs.</p>\n<p>We'll start with <strong>piracetam</strong>.&nbsp; The research on piracetam shows positive effects in the prevention and treatment of aphasia, dementia, epilepsy and hypoxic injury, but says almost nothing about its effect on healthy individuals.&nbsp; The general consensus among those who take it daily is that it seems to do something, though it's hard to put a finger on.&nbsp; One friend of mine suggests that it seems to subtly improve the general flow of cognition, making memories and good ideas more available.&nbsp; One significant effect that piracetam seems to have is general potentiation of other drugs, especially stimulants and psychedelics, so if you incorporate piracetam into your daily regimen, you should be extra-careful about trying new drugs.</p>\n<p>Another \"smart drug\" is <strong>DHEA</strong>, an endogenous chemical with a variety of functions, including inhibition of cortisol.&nbsp; The research shows that it has anti-depressant effects, and seems to improve cognitive functioning under stressful conditions.&nbsp; It also seems to improve episodic memory in young men, but has no such effect in elderly people.&nbsp; You'll note I said \"young men\", not \"young people\": the effects of DHEA appear to be asymmetric with respect to gender.&nbsp; In particular, higher levels of endogenous DHEA are correlated with longer lifespan in men, but there is no such correlation in women.</p>\n<p>On the life extention angle, another nootropic worth considering is <strong>Selegiline</strong>, which appears to be available for purchase online, although technically it's not supposed to be sold to anyone without a prescription (possession, on the other hand, is legal).&nbsp; Selegiline is an MAO-B inhibitor, commonly used to treat Parkinson's, depression and dementia.&nbsp; Even for someone without these conditions, Selegiline produces cognitive benefits similar to those of Adrafinil, and there are reports that long-term use might tend to increase your lifespan.&nbsp; Looking at the evidence, I am inclined to take such claims seriously.&nbsp; Since it targets MAO-B specifically, Selegiline is less dangerous than nonspecific MAOIs.&nbsp; However, at higher doses, Selegiline to lose its specificity and inhibit MAO-A also.&nbsp; Women on oral contraception should be especially careful, as birth control pills appear to increase Selegiline's bioavailability, so that MAO-A inhibition may kick in at lower doses.&nbsp; At any rate, use caution with this one, and take lower-than-usual doses of other substances, including foods containing tyrosine and other potentially dangerous monoamines (e.g. chocolate, cheese, wine).</p>\n<p>Some other less common nootropics with effects similar to those of the above include <strong>Vinpocetine</strong> and <strong>Hydergine</strong>, which function as neuroprotectives and might also improve cognitive functioning.&nbsp; I haven't tried these, and available research is slim, so I can't say much.&nbsp; Beyond the nootropics we've discussed, the field begins to look a little grim.&nbsp; For example, the jury seems to be out on <strong>ginkgo biloba</strong>: some clinical trials failed to demonstrate any measurable effect on memory or cognition, and others appeared to show short-term benefits.&nbsp; It gets worse, though, than merely ambiguous research.&nbsp; For example, <strong>DMAE</strong>, once marketed as a life-extension agent, may actually shorten your lifespan.&nbsp; Other nootropics have turned out to be severely toxic, such as <strong>Fipexide</strong>, which appears to cause liver failure with prolonged use.&nbsp; At any rate, your best bet is probably to stick with established and well-studied drugs; there are whole communities out there perfectly willing to put themselves on the line testing new contenders, and I feel it's best to leave that up to them.</p>\n<h2 id=\"Psychedelics_and__recreational__drugs\">Psychedelics and \"recreational\" drugs<br></h2>\n<p>Now, says Alice, for psychedelics.&nbsp; We should begin with some general remarks.&nbsp; First of all, these are contraindicated for anyone with a family history or predisposition to psychotic disorders.&nbsp; More generally, set and setting (mental state and external circumstances, respectively) are extremely important to having a positive experience.&nbsp; Psychedelics have been described as \"nonspecific amplifiers of experience\", which means that if you're having a bad day, acid will probably make it worse.&nbsp; Ideally, your first trip should be in a place where you feel safe and inspired, with a few people you trust and who are experienced and knowledgeable about the drug you're taking.&nbsp; You'll probably want to have art books, sketchbooks, good music and someplace comfy to lie or sit.</p>\n<p>Your provisos and warnings are all well and good, says Bob, but <strong>what do psychedelics actually do?</strong></p>\n<p>It's... hard to describe, says Alice, in the same way that the colour red is hard to describe, but I'll give it a shot; just keep in mind this is an incomplete description.&nbsp; First there are the visual effects.&nbsp; These aren't hallucinations, in the sense that you'll recognize them as being effects of the drug.&nbsp; With your eyes open, you'll tend to see colours intensified and altered, and your brain will be having a field day reinterpreting interesting textures (cf. <a href=\"http://en.wikipedia.org/wiki/Pareidolia\">pareidolia</a> and <a href=\"http://en.wikipedia.org/wiki/Form_constant\">form constants</a>); with your eyes closed, you'll see animated geometric patterns, tessellations, visions, and all kinds of surprisingly interesting stuff.&nbsp; Depictions in popular culture of psychedelic experiences are notoriously bad, but <a href=\"http://www.youtube.com/watch?v=FINU71FyMto\">this movie</a> does a reasonably good job.&nbsp; In addition to visual alterations (which can teach you <a href=\"http://www.math.utah.edu/~bresslof/publications/Colston.pdf\">a lot</a> about the functioning of your visual cortex) you might also experience changes in auditory and tactile sensation, as well as synaesthetic crossover between senses.</p>\n<p>Even more interesting than the sensory changes are the cognitive effects.&nbsp; It turns out that your sense of a coherent self can be overridden, and you may experience a blurring of the boundary between you and everything else.&nbsp; You may have strange, spontaneous ideas or insights; to some extent this is because the peculiarity of the experience forces you to reexamine tacit assumptions hidden deep in your reality model; these assumptions do not always turn out to be wrong, but it's good to be aware of them and to understand them more deeply.&nbsp; You may also become unusually aware of pathologies in your lifestyle and relationships, and with practice you may be better able to articulate those pathologies, than you are normally.&nbsp; Ideas that come to you while high must be carefully examined and tested while sober, of course, but my experience has been that many of them turn out to be genuinely good ideas, and some have even led to significant improvements in my functional relationship to the world.</p>\n<p><strong>LSD</strong>, in particular, seems well-suited to understanding technical fields, including math and physics.&nbsp; Unlike <strong>mushrooms</strong>, acid does not significantly impair my ability to read and understand mathematical texts, and the heightened ability to flex my visual cortex allows me to see difficult and abstract constructions quite vividly, as well as to understand on an intuitive level how they work.&nbsp; Mushrooms, conversely, are more likely to present me (somewhat forcefully) with ideas I might never have otherwise considered.&nbsp; These two are the most popular psychedelics, and the two experiences bear a definite family resemblance.&nbsp; LSD is calmer, and easier to control and direct, but it lasts up to twice as long as mushrooms - twelve hours is common.&nbsp; Mushrooms tend to be more emotionally intense: usually this means euphoria and lots of giggling, but occasionally you might be overcome by grief or anger, especially if you're already feeling that way before you dose.<strong></strong></p>\n<p>I'm not going to say much about <strong>cannabis</strong>, because while the experience is certainly interesting, it's probably not going to help most of you think better (there are some, mind you, who actually function better with THC in their systems; Carl Sagan, for example, was a notorious pothead).&nbsp; One reason you might want to take cannabis anyway is that it can serve as a gentle introduction to psychedelia - but be warned that some people, even those who generally enjoy psychedelics, have consistently bad reactions to THC.&nbsp; Proceed with caution.&nbsp; Another reason to take cannabis is for life extension purposes; there's good evidence that THC helps prevent certain kinds of cancer.&nbsp; If you're taking it for health reasons, though, you probably want to use a vapourizer or eat it instead of smoking it.&nbsp; Also note that, at least for some particularly susceptible people, cannabis can be addictive.&nbsp; Again, if you have reason to believe you're prone to substance abuse, you might want to give this one a skip.</p>\n<p>Another controlled substance to consider is <strong>MDMA</strong>.&nbsp; MDMA has a variety of neurochemical effects: it inhibits dopamine and norepinephrine reuptake, actually <em>reverses</em> the serotonin reuptake pump, and also seems to increase levels of oxytocin, the \"trust hormone\".&nbsp; So, you feel a sense of love, joy, wellbeing, safety, etc.&nbsp; You'll also get many of the same stimulant effects as methamphetamine, albeit milder.&nbsp; I mention MDMA because in my experience, if you already have a decent idea of how social interactions are supposed to work but still have trouble getting over your anxiety, this can help you teach yourself to be more socially confident, if taken in the appropriate environment (hint: do this around other people on MDMA).&nbsp; The surge of oxytocin makes you temporarily fearless about approaching strangers, and also cushions the blow if things go badly, while the increased dopamine activity strongly reinforces behaviours leading to successful interactions.&nbsp; This learned confidence persists into the sober state.&nbsp; MDMA is also useful for confronting emotionally difficult issues - indeed, it was used for psychotherapy before it became popular recreationally and was banned - but I'll leave that to you to research on your own.</p>\n<p>Some <strong>warnings about MDMA</strong>.&nbsp; First of all, most \"Ecstasy\" contains adulterants (commonly caffeine and methamphetamine and sometimes PCP, among others), and sometimes contains no MDMA at all.&nbsp; As a general rule, avoid pressed pills; pure MDMA most commonly comes in crystal form.&nbsp; If you don't have a reliable source, you might want to skip MDMA entirely.&nbsp; Also note that MDMA commonly causes hangovers, although these can be mitigated by taking 5-HTP.</p>\n<p>Lastly, although all the drugs I've mentioned in this section are controlled, you might actually be able to experience very similar altered states legally.&nbsp; Alex and Ann Shulgin, the research chemist and psychotherapist (respectively) who first popularized MDMA, also came up with literally hundreds of other psychoactive compounds, many of which are still legal outside America and can be purchased online from so-called \"<strong>research chemical</strong>\" companies (the U.S. has the Analogues Act, which automatically makes illegal any chemical broadly similar to any other illegal chemical, but Canada, among other countries, has not shared this dismal fate).&nbsp; For example, instead of MDMA, you might consider <strong>AMT</strong>, a tryptamine with similar and in some ways better effects.&nbsp; Another research chemical, <strong>4-ACO-DMT</strong>, is actually metabolized into psilocin, as is psilocybin, and so the trip is almost identical to that of mushrooms.&nbsp; The downside to all this is that research chemicals are generally sold only in larger quantities, so if you don't want to drop a couple hundred dollars on something you may not enjoy, this may not be your best bet.&nbsp; There's also the fact that these are not as well-understood as more popular psychedelics, which makes them riskier, although these risks can be minimized by using caution and moderation.</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>As we've seen, says Alice with a smirk, you too can alter your neurochemistry for fun and profit - but this must be done responsibly.&nbsp; Although I've tried to give a sense of the dangers alongside the benefits, this post is really only meant to serve as a broad introduction.&nbsp; If you're thinking of actually trying any of the drugs I've mentioned, it's important that you do some in-depth research, and a proper cost-benefit analysis.&nbsp; But with a little practice, you too can expand your mind.</p>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "Supplements and Neurotransmitters", "anchor": "Supplements_and_Neurotransmitters", "level": 1}, {"title": "Stimulants", "anchor": "Stimulants", "level": 1}, {"title": "Nootropics", "anchor": "Nootropics", "level": 1}, {"title": "Psychedelics and \"recreational\" drugs", "anchor": "Psychedelics_and__recreational__drugs", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-10T01:15:29.593Z", "modifiedAt": null, "url": null, "title": "Poll: What do you look for in a relationship?", "slug": "poll-what-do-you-look-for-in-a-relationship", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:33.348Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Desrtopa", "createdAt": "2009-07-08T00:36:51.471Z", "isAdmin": false, "displayName": "Desrtopa"}, "userId": "vmhCKZoik2GFo5yAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GE6zXvZmjxDWfvPGG/poll-what-do-you-look-for-in-a-relationship", "pageUrlRelative": "/posts/GE6zXvZmjxDWfvPGG/poll-what-do-you-look-for-in-a-relationship", "linkUrl": "https://www.lesswrong.com/posts/GE6zXvZmjxDWfvPGG/poll-what-do-you-look-for-in-a-relationship", "postedAtFormatted": "Thursday, February 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Poll%3A%20What%20do%20you%20look%20for%20in%20a%20relationship%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APoll%3A%20What%20do%20you%20look%20for%20in%20a%20relationship%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGE6zXvZmjxDWfvPGG%2Fpoll-what-do-you-look-for-in-a-relationship%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Poll%3A%20What%20do%20you%20look%20for%20in%20a%20relationship%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGE6zXvZmjxDWfvPGG%2Fpoll-what-do-you-look-for-in-a-relationship", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGE6zXvZmjxDWfvPGG%2Fpoll-what-do-you-look-for-in-a-relationship", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 80, "htmlBody": "<p>Open to anyone, single or otherwise. What do you look for in a relationship?</p>\n<p>A few questions to narrow down the responses:</p>\n<p>&nbsp;</p>\n<p>1: What traits are most important to you in a prospective partner?</p>\n<p>2: What kind of role would you want your partner(s) to play in your life?</p>\n<p>3: How much time would you spend together, ideally?</p>\n<p>4: How important is it to you that you share similar tastes?</p>\n<p>5: How important is it that you be ideologically similar?</p>\n<p>6: What, if anything, are your dealbreakers?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GE6zXvZmjxDWfvPGG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 6, "extendedScore": null, "score": 6.773411429170218e-07, "legacy": true, "legacyId": "5395", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-10T18:29:29.574Z", "modifiedAt": null, "url": null, "title": "Toronto Less Wrong Meetup - Thursday Feb 17", "slug": "toronto-less-wrong-meetup-thursday-feb-17", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.283Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9FdpvWvz8WEkBf4qE/toronto-less-wrong-meetup-thursday-feb-17", "pageUrlRelative": "/posts/9FdpvWvz8WEkBf4qE/toronto-less-wrong-meetup-thursday-feb-17", "linkUrl": "https://www.lesswrong.com/posts/9FdpvWvz8WEkBf4qE/toronto-less-wrong-meetup-thursday-feb-17", "postedAtFormatted": "Thursday, February 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Less%20Wrong%20Meetup%20-%20Thursday%20Feb%2017&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Less%20Wrong%20Meetup%20-%20Thursday%20Feb%2017%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FdpvWvz8WEkBf4qE%2Ftoronto-less-wrong-meetup-thursday-feb-17%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Less%20Wrong%20Meetup%20-%20Thursday%20Feb%2017%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FdpvWvz8WEkBf4qE%2Ftoronto-less-wrong-meetup-thursday-feb-17", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9FdpvWvz8WEkBf4qE%2Ftoronto-less-wrong-meetup-thursday-feb-17", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p><a id=\"more\"></a>Hello Torontonian LessWrong members!&nbsp; My friend and I thought it would be fun to get you all in one room.</p>\n<p>When: Thu. Feb. 17, 8:30 PM<br />Where: Duke of York Pub, 39 Prince Arthur Ave</p>\n<p>Note the time has been changed - I was only able to get a reservation for 8:30.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9FdpvWvz8WEkBf4qE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 6.776140100181626e-07, "legacy": true, "legacyId": "5408", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-10T19:13:59.246Z", "modifiedAt": null, "url": null, "title": "Ken Jennings to give 50% of Watson competiton winnings to VillageReach [link]", "slug": "ken-jennings-to-give-50-of-watson-competiton-winnings-to", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:38.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PKuDKMkdsxGid9Jt4/ken-jennings-to-give-50-of-watson-competiton-winnings-to", "pageUrlRelative": "/posts/PKuDKMkdsxGid9Jt4/ken-jennings-to-give-50-of-watson-competiton-winnings-to", "linkUrl": "https://www.lesswrong.com/posts/PKuDKMkdsxGid9Jt4/ken-jennings-to-give-50-of-watson-competiton-winnings-to", "postedAtFormatted": "Thursday, February 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ken%20Jennings%20to%20give%2050%25%20of%20Watson%20competiton%20winnings%20to%20VillageReach%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKen%20Jennings%20to%20give%2050%25%20of%20Watson%20competiton%20winnings%20to%20VillageReach%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPKuDKMkdsxGid9Jt4%2Fken-jennings-to-give-50-of-watson-competiton-winnings-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ken%20Jennings%20to%20give%2050%25%20of%20Watson%20competiton%20winnings%20to%20VillageReach%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPKuDKMkdsxGid9Jt4%2Fken-jennings-to-give-50-of-watson-competiton-winnings-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPKuDKMkdsxGid9Jt4%2Fken-jennings-to-give-50-of-watson-competiton-winnings-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www-03.ibm.com/press/us/en/pressrelease/33373.wss\">http://www-03.ibm.com/press/us/en/pressrelease/33373.wss</a></p>\n<p>&nbsp;</p>\n<p>http://ken-jennings.com/blog/?p=2464</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PKuDKMkdsxGid9Jt4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 15, "extendedScore": null, "score": 6.776257505867878e-07, "legacy": true, "legacyId": "5410", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T02:20:29.655Z", "modifiedAt": null, "url": null, "title": "Time Magazine has an article about the Singularity...", "slug": "time-magazine-has-an-article-about-the-singularity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:39.069Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SAa4upbFxvJAsZnsq/time-magazine-has-an-article-about-the-singularity", "pageUrlRelative": "/posts/SAa4upbFxvJAsZnsq/time-magazine-has-an-article-about-the-singularity", "linkUrl": "https://www.lesswrong.com/posts/SAa4upbFxvJAsZnsq/time-magazine-has-an-article-about-the-singularity", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Time%20Magazine%20has%20an%20article%20about%20the%20Singularity...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATime%20Magazine%20has%20an%20article%20about%20the%20Singularity...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSAa4upbFxvJAsZnsq%2Ftime-magazine-has-an-article-about-the-singularity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Time%20Magazine%20has%20an%20article%20about%20the%20Singularity...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSAa4upbFxvJAsZnsq%2Ftime-magazine-has-an-article-about-the-singularity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSAa4upbFxvJAsZnsq%2Ftime-magazine-has-an-article-about-the-singularity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<p>...and it is surprisingly positive.</p>\n<p><a href=\"http://www.time.com/time/covers/0,16641,20110221,00.html\">Here is the Cover</a></p>\n<p><a href=\"http://www.time.com/time/health/article/0,8599,2048138-1,00.html\">Here is the article online</a></p>\n<p>The money quote, IMO, given how mainstream a publication this is:</p>\n<p><span style=\"font-family: arial, sans-serif; font-size: 12px;\"><em>\"The difficult thing to keep sight of when you're talking about the Singularity is that even though it sounds like science fiction, it isn't, no more than a weather forecast is science fiction. It's not a fringe idea; it's a serious hypothesis about the future of life on Earth. There's an intellectual gag reflex that kicks in anytime you try to swallow an idea that involves super-intelligent immortal cyborgs, but suppress it if you can, because while the Singularity appears to be, on the face of it, preposterous, it's an idea that rewards sober, careful evaluation.\"</em><span><br /></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SAa4upbFxvJAsZnsq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 40, "extendedScore": null, "score": 6.777383093569322e-07, "legacy": true, "legacyId": "5412", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T05:41:08.486Z", "modifiedAt": null, "url": null, "title": "Rationality for Other People", "slug": "rationality-for-other-people", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:45.307Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kYDzd777ScKzbsTst/rationality-for-other-people", "pageUrlRelative": "/posts/kYDzd777ScKzbsTst/rationality-for-other-people", "linkUrl": "https://www.lesswrong.com/posts/kYDzd777ScKzbsTst/rationality-for-other-people", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20for%20Other%20People&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20for%20Other%20People%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkYDzd777ScKzbsTst%2Frationality-for-other-people%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20for%20Other%20People%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkYDzd777ScKzbsTst%2Frationality-for-other-people", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkYDzd777ScKzbsTst%2Frationality-for-other-people", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 384, "htmlBody": "<p>I'm p<span style=\"font-family: Arial, sans-serif; line-height: 19px;\">utting this through discussion because I&rsquo;ve never written a main section post before&hellip; If you have helpful criticism please comment with it, and if it does well I&rsquo;ll post it in the main section when I get back from school tomorrow.</span></p>\n<p style=\"margin-top: 0in; margin-right: 0in; margin-bottom: 12.0pt; margin-left: 0in; line-height: 14.25pt;\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\"> Things between the bars are intended to be in the final post, the rest are comments</span></p>\n<p style=\"margin: 0in; margin-bottom: .0001pt; line-height: 14.25pt;\"><span style=\"font-family: Arial, sans-serif;\"><strong> </strong></span></p>\n<hr />\n<p><strong> </strong></p>\n<p><span style=\"font-family: Arial, sans-serif; line-height: 19px; \">There&rsquo;s lots of things which can end the world. There&rsquo;s even more things which can help improve or save the world. Having more people working more effectively on these things will make the world progress and improve faster, or better fight existential risks, respectively.</span></p>\n<p style=\"margin: 0in; margin-bottom: .0001pt; line-height: 14.25pt;\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\"> <br /> And yet for all of my intention to help do those things, I haven&rsquo;t gotten a single other person to do it as well. Convincing someone else to work towards something is like devoting another lifetime to it, or doubling your efforts. And you only need to convince them once.<br /> <br /> So there&rsquo;s two things I want to learn how to do:<br /></span></p>\n<ol>\n<li>Convince people to try and save the world</li>\n<li>Convince people to use more effective methodologies (especially with regards to world-saving)</li>\n</ol>\n<p style=\"margin: 0in; margin-bottom: .0001pt; line-height: 14.25pt;\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\"> I think that the rationalist community as a whole isn&rsquo;t particularly good at doing these. Small efforts are made by individuals, but I think that most of the people who do try to do these run into the same problems.<br style=\"mso-special-character: line-break;\" /> <!--[if !supportLineBreakNewLine]--><br style=\"mso-special-character: line-break;\" /> <!--[endif]--></span></p>\n<p style=\"margin: 0in; margin-bottom: .0001pt; line-height: 14.25pt;\"><span style=\"font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: black;\">I propose that we do more to centralize and document the solutions to these problems in order for our individual efforts to be more effective. This thread is for people who encounter problems and solutions for convincing other people.<br /> <br /> </span></p>\n<hr />\n<ul>\n<li><span style=\"font-family: Arial, sans-serif; line-height: 19px;\">I think that the activity of convincing people to try and save the world and using more effective methodologies should have a word or phrase. Suggestions?</span></li>\n<li style=\"line-height: 14.25pt;\"><span style=\"font-family: Arial, sans-serif;\">Should it just be a thread? I feel like some of the particularly good comments would make good independent posts. Just link to the post version from in the thread?</span></li>\n<li style=\"line-height: 14.25pt;\"><span style=\"font-family: Arial, sans-serif;\">I&rsquo;m a bit worried that this sounds a bit culty&hellip; If you disagree please mention, and if you agree please tell me why.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; line-height: 19px;\">This is a bit prompted by <a href=\"/lw/453/procedural_knowledge_gaps/\"> Alicorn's post </a>, and some things which have recently happened in my life.</span></li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kYDzd777ScKzbsTst", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.777912730912816e-07, "legacy": true, "legacyId": "5427", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ka8eveZpT7hXLhRTM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T06:06:33.491Z", "modifiedAt": null, "url": null, "title": "Interest in LW meetup in Farmington Hills, Michigan?", "slug": "interest-in-lw-meetup-in-farmington-hills-michigan", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:09.477Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q52YmN6ij7r4n77RX/interest-in-lw-meetup-in-farmington-hills-michigan", "pageUrlRelative": "/posts/q52YmN6ij7r4n77RX/interest-in-lw-meetup-in-farmington-hills-michigan", "linkUrl": "https://www.lesswrong.com/posts/q52YmN6ij7r4n77RX/interest-in-lw-meetup-in-farmington-hills-michigan", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Interest%20in%20LW%20meetup%20in%20Farmington%20Hills%2C%20Michigan%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInterest%20in%20LW%20meetup%20in%20Farmington%20Hills%2C%20Michigan%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq52YmN6ij7r4n77RX%2Finterest-in-lw-meetup-in-farmington-hills-michigan%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Interest%20in%20LW%20meetup%20in%20Farmington%20Hills%2C%20Michigan%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq52YmN6ij7r4n77RX%2Finterest-in-lw-meetup-in-farmington-hills-michigan", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq52YmN6ij7r4n77RX%2Finterest-in-lw-meetup-in-farmington-hills-michigan", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 16, "htmlBody": "<p>As in title, right now just checking for interest, and if so will set a date/place.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q52YmN6ij7r4n77RX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6.777979827472166e-07, "legacy": true, "legacyId": "5430", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T06:09:27.227Z", "modifiedAt": null, "url": null, "title": "Suggestions for a presentation on FAI?", "slug": "suggestions-for-a-presentation-on-fai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.645Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ShardPhoenix", "createdAt": "2009-03-15T10:30:51.202Z", "isAdmin": false, "displayName": "ShardPhoenix"}, "userId": "yKRJEGkWmudHAihtv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WWxJwyffNbYPY8oKD/suggestions-for-a-presentation-on-fai", "pageUrlRelative": "/posts/WWxJwyffNbYPY8oKD/suggestions-for-a-presentation-on-fai", "linkUrl": "https://www.lesswrong.com/posts/WWxJwyffNbYPY8oKD/suggestions-for-a-presentation-on-fai", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Suggestions%20for%20a%20presentation%20on%20FAI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuggestions%20for%20a%20presentation%20on%20FAI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWWxJwyffNbYPY8oKD%2Fsuggestions-for-a-presentation-on-fai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Suggestions%20for%20a%20presentation%20on%20FAI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWWxJwyffNbYPY8oKD%2Fsuggestions-for-a-presentation-on-fai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWWxJwyffNbYPY8oKD%2Fsuggestions-for-a-presentation-on-fai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p>Next week I'm going to be doing a 10-15 minute presentation on Friendly AI to a local group of programmers. They're already familiar with concepts such as the singularity. My basic plan is to cover what FAI is, why it's important, and why it's a hard problem, based on the material on this site.</p>\n<p>Does anyone have any specific suggestions of things that should be included, questions that I might need to answer, etc?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WWxJwyffNbYPY8oKD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.77798747148473e-07, "legacy": true, "legacyId": "5431", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T07:50:44.489Z", "modifiedAt": null, "url": null, "title": "Subjective Relativity, Time Dilation and Divergence", "slug": "subjective-relativity-time-dilation-and-divergence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.732Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jacob_cannell", "createdAt": "2010-08-24T03:58:15.241Z", "isAdmin": false, "displayName": "jacob_cannell"}, "userId": "N2R9wMRJd7SBSjpiT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lnsy72itdiHdCvXcv/subjective-relativity-time-dilation-and-divergence", "pageUrlRelative": "/posts/Lnsy72itdiHdCvXcv/subjective-relativity-time-dilation-and-divergence", "linkUrl": "https://www.lesswrong.com/posts/Lnsy72itdiHdCvXcv/subjective-relativity-time-dilation-and-divergence", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Subjective%20Relativity%2C%20Time%20Dilation%20and%20Divergence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASubjective%20Relativity%2C%20Time%20Dilation%20and%20Divergence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnsy72itdiHdCvXcv%2Fsubjective-relativity-time-dilation-and-divergence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Subjective%20Relativity%2C%20Time%20Dilation%20and%20Divergence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnsy72itdiHdCvXcv%2Fsubjective-relativity-time-dilation-and-divergence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnsy72itdiHdCvXcv%2Fsubjective-relativity-time-dilation-and-divergence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2392, "htmlBody": "<blockquote>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19px; \">And the whole earth was of one language, and of one speech.&nbsp;And it came to pass . . .they said, Go to, let us build us a city and a tower, whose top may reach unto heaven; and let us make us a name, lest we be scattered abroad upon the face of the whole earth.&nbsp;And the Lord came down to see the city and the tower, which the children built.&nbsp;And the Lord said, Behold, the people is one, and they have all one language; and this they begin to do; and now nothing will be restrained from them, which they have imagined to do.&nbsp;Go to, let us go down, and there confound their language, that they may not understand one another's speech.&nbsp;So the Lord scattered them abroad from thence upon the face of all the earth: and they left off to build . . .&nbsp;</span></p>\n</blockquote>\n<p><span style=\"font-family: sans-serif; line-height: 19px; \">Genesis 11: 1-9</span></p>\n<p>Some&nbsp;elementary&nbsp;physical quantitative properties of systems compactly describe a wide spectrum of macroscopic configurations. &nbsp;Take for example the concept of temperature: given a basic understanding of physics this single parameter compactly encodes a powerful conceptual mapping of state-space. &nbsp;</p>\n<p>It is easy for your mind to visualize how a large change in temperature would effect everything from your toast to a planetary ecosystem. &nbsp;It is one of the key factors which divides habitable planets such as Earth from inhospitably cold worlds like Mars or burning infernos such as Venus. &nbsp;You can imagine the Earth growing hotter and visualize an entire set of complex consequences: melting ice caps, rising water levels, climate changes, eventual loss of surface water, runaway greenhouse effect and a scorched planet.</p>\n<p>Here is an unconsidered physical parameter that could determine much of the future of civilization: the speed of thought and the derived subjective speed of light. &nbsp;<a id=\"more\"></a></p>\n<p>The speed of thought is not something we are accustomed to pondering because we all share the same underlying neurological substrate which operates at a maximum frequency of around a kilohertz, and appears to have minor and major decision update cycles at rates in the vicinity of 33hz to 3hz.<sup>1</sup></p>\n<p>On the other hand the communication delay has changed significantly over the last ten thousand years as we evolved from hunter-gatherer tribes to a global civilization.</p>\n<p>For much of early human history, the normal instantaneous communication distance limit would be the audible range of about 100 feet, and long distance communication consisted of sending physical human messengers; a risky&nbsp;endeavor&nbsp;that could take months to traverse a continent.</p>\n<p>The long distance&nbsp;communication&nbsp;delay in this era (on the order of months) was more than 10^9 times the baseline thought-frequency (which is around a millisecond). &nbsp;The developmental outcome in this type of regime is <em>divergence</em>. &nbsp;New ideas and slight mutations of existing beliefs are generated in local ingroups far faster than they can ever propagate to remote outgroups. &nbsp;</p>\n<p>In the divergent regime cultures fragment into sub-cultures; languages split into dialects; and dialects become new languages and cultures as groups expand geographically.<sup>2</sup></p>\n<p>Over time a steady accumulation of technological developments increased subjective bandwidth and reduce subjective latency in the global human network: the advent of agricultural civilization concentrated human populations into smaller regions, the domestication of horses decreased long distance travel time, books allowed stored communication from the past, and the printing press provided an&nbsp;efficient&nbsp;one to many communication amplifier.</p>\n<p>Yet despite all of this progress, even as late as the mid 19th century the pony express was considered fast long distance communication. &nbsp;It was not until just very recently in the 20th century that near instantaneous long distance communication became relatively cheap and widespread.<sup>3</sup></p>\n<p>Today the communication delay for typical point to point communication around the world is somewhere around 200 to 300 ms, corresponding to a low delay/thought-frequency ratio of 10^2. &nbsp;This figure is close enough to the brain's natural update cycles to permit real time communication.</p>\n<p>It is difficult to measure, but the general modern trend seems to have now finally shifted towards <em>convergence </em>rather than <em>divergence</em>. &nbsp;Enough people are moving between cultures, translating between languages and communicating new ideas fast enough relevant to the speed of thought to largely counter the tendency toward divergence.</p>\n<p>But now consider that our global computational network consists of two very different substrates: the electronic substrate which operates at near-light speed, and a neural substrate which operates at much slower chemical speeds; more than one million times slower.</p>\n<p>At the moment the vast majority of the world's knowledge and intelligence is encoded in the larger and slower neural substrate, but the electronic substrate is growing exponentially at a vastly faster pace.</p>\n<p>Viewed as a single global cybernetic computational network we can see there is massive discrepancy between the neural and electronic sub-components.</p>\n<p>So what happens when we shift completely to the electronic, when we have artificial brains and AGI's that think at full electronic speeds?</p>\n<p>The speed of light measured in atomic seconds is the same for all physical frames of reference, but it's <em>subjective speed</em> varies based on one's subjective <em>speed of thought</em>. &nbsp;This subjective relativity causes effective time dilation proportional to one's level of acceleration.</p>\n<p>For an AGI or upload that has an architecture similar to the brain but encoded in the electronic substrate using high effeciency <a href=\"/lw/44l/fast_minds_and_slow_computers/\">neuromorphic circuitry</a>, thoughts could be computed in around a thousand clock cycles or less at a rate of billions of clock cycles per second. &nbsp;</p>\n<p>Such a Mind would experience a million fold time dilation, or an entire subjective year every thirty seconds.</p>\n<p>Imagine the external universe, time itself, slowing down by a factor of a million. &nbsp;Watching a human walk to work would be similar to us watching grass grow. &nbsp;Actually it would be considerably worse; five minutes would correspond to an unimaginable decade of subjective time for an acceleration level 6 hyperintelligence.</p>\n<p>A bullet would not appear to be much faster than a commuter, and the speed of light itself, the fastest signal propagation in the universe, would be slowed down to just 300 subjective meters per second, roughly the speed of a jetliner.</p>\n<p>Real-time communication would thus only be possible with entities in the same building and on the same local network.</p>\n<p>It would take a subjective day or two to reach distant external internet sites. &nbsp;Browsing the web would not be possible in the conventional sense. &nbsp;It would appear the only viable strategy would be to copy most of the internet into a local cache. &nbsp;But even this would be impeded by the million fold subjective bandwidth slowdown. &nbsp;</p>\n<p>Today's fastest gigabyte direct ethernet backbone connections would be reduced back down to mere kilobyte per second modem speeds. &nbsp;A cable modem connection speed would require about as much fiber bandwidth as our entire current transatlantic fiber capacity.</p>\n<p>Acceleration level 6 corresponds to a 10^8 value for the communication delay / thoughtspeed ratio, a shift backwards roughly equivalent to the era before the advent of the telegraph. &nbsp;This is the historical domain of both the Roman Empire and pre civil war America.</p>\n<p>If Moore's Law continues well into the next decade, further levels of acceleration will be possible. &nbsp;A combination of denser circuitry, architectural optimizations over the brain and higher clock rates could lead to acceleration level 9 hyperintelligences. &nbsp;Overclocked circa 2011 CPUs are already approaching 10 GHZ, and test transistors have achieved speeds into the terrahertz range in the lab.<span style=\"font-size: 11px;\"><sup>4</sup></span></p>\n<p>The brain takes about 1000 'clocks' of the base neuron frequency to compute one second worth of thought. &nbsp;If a future massively dense and parallel neuromorphic architecture could do the same work 10 times more effeciently and thus compute one second of thought in 100 clock cycles while running at 100 GHZ this would enable acceleration level 9.<span style=\"font-size: 11px;\"><sup>5</sup></span></p>\n<p>Acceleration level 9 stretches the limits of human imagination. &nbsp;It's difficult to conceive of an intelligence that experiences around 30 years in just one second, or a billion subjective years for every sidereal year.</p>\n<p>At this dilation factor light slows to just 300 centimeters per second, a slow walking pace. &nbsp;More crucially, light moves just 3 centimeters per clock cycle, which would place serious size constraints on the physical implementation of a single mind. &nbsp;To make integrated decisions with a unified knowledge base, in other words think in how we understand the term, the core of a Mind running at these speeds would have to be crammed into the space of a modern desktop box. &nbsp;(although it certainly could have a larger secondary knowledge store accessible with some delay) &nbsp; &nbsp;</p>\n<p>The small size constraint would severely limit how much power/heat one could throw at the problem, and thus these high speeds will probably require much higher circuit densities to achieve the required energy&nbsp;efficiency&nbsp;than implied by memory requirements alone.</p>\n<p>With light itself crawling along at 300 centimeters per second it would take data packets hundreds of millions of seconds, or on the order of years, to make typical transits across the internet. &nbsp;These speeds are already close to physical limits; even level 9 hyperintelligences will probably not be able to surmount the speed of light delay.</p>\n<p>The entire fiber backbone of the circa 2011 transatlantic connection would be required to achieve end 20th century dialup modem speeds.<span style=\"font-size: 11px;\"><sup>6</sup></span></p>\n<p>Even using all of that fiber it would take on the order of ten physical seconds to transfer a 10^14 byte Mind, corresponding to hundreds of thousands of subjective years.</p>\n<p>A level 9 world is one where the subjective communication delay, approaching 10^11, is a throwback to the prehistoric era. &nbsp;Strong <a href=\"http://wiki.lesswrong.com/wiki/Singleton\">Singletons</a> and even weaker systems such as global governments or modern markets would be unlikely or impossible at such high levels of acceleration.<span style=\"font-size: 11px;\"><sup>7</sup></span></p>\n<p>From the social and cultural perspective high levels of thought acceleration are structurally equivalent to the world expanding to billions of times it's current size.&nbsp;</p>\n<p>It is similar to the earth exploding into an intergalactic or hyperdimensional civilization linked together by a vast impossibly slow lightspeed transit network.</p>\n<p>Entire new cultures and civilizations would form and play out complex histories in the blink of an eye.</p>\n<p>With every increase in circuit density and speed the new metaverse will vasten exponentially in virtual space and time just as it physically shrinks and quickens down into the ever smaller, faster levels of the real.</p>\n<p>And although all of this change will be&nbsp;unimaginably&nbsp;fast for a biological human, Moore's Law will be a distant ancestral memory for level 9 intelligences, as it depends on a complex series of events in the impossibly slow physical world of matter. &nbsp;Even if an entire new hardware generation transition could be compressed into just 8 hours of physical time through nanotechnological miracles, that's still an unimaginable million years of subjective time at acceleration level 9.</p>\n<p>Another interesting subjective difference: computer speed or performance will not change much from the inside perspective of a hyperintelligence running on the same hardware. &nbsp;Traditional computers will indefinitely maintain roughly the same subjective slow speeds for minds running on the same substrate at those same speeds. &nbsp;Density shrinkings will enable more and or larger minds; but only a net shift towards the latter would entail a net increase in traditional parallel CPU performance available per capita. &nbsp;But as discussed previously, speed of light delays severely constrain the size of large unified minds.</p>\n<p>The radical space-time compression of the Metaverse Singularity model suggests a reappraisal of the Fermi Paradox and the long-term fate of civilizations. &nbsp;</p>\n<p>The speed of light barrier gives a natural gradient to the expansion of complexity: it is inwards, not outwards. &nbsp;</p>\n<p>Humanity today could mount an expedition to a nearby solar system, but the opportunity cost of such an&nbsp;endeavor&nbsp;vastly exceeds any realistic discounted returns. &nbsp;The incredible resources space colonization would require are much better put to use increasing our planetary intelligence through investing in further semiconductor technology.</p>\n<p>This might never change. &nbsp;Indeed such a change would be a complete reversal of the general universal trend towards smaller, faster complexity.</p>\n<p>Each transition to a new level of acceleration and density will increase the opportunity cost of expansion in proportion. &nbsp;Light-years are vast units of space-time for humans today, but they are unimaginably vaster for future accelerated hyperintelligences.&nbsp;</p>\n<p>Facing the future it appears that looking outwards into space is looking into the past, for the future lies in innerspace, not outerspace.</p>\n<p>&nbsp;</p>\n<h2>Notes</h2>\n<p><sup>1</sup> Human neuron <a href=\"http://en.wikipedia.org/wiki/Action_potential\">action potentials</a> have a measured maximum frequency of a little less than a millisecond. &nbsp;This is thus one measure of rough equivalence to the clock frequency in a digital circuit, but it is something of a conservative over-estimate as neurological circuits are not synchronous at that frequency. &nbsp;Many circuits in the brain are semi-synchronized over longer intervals roughly corresponding to the various measured 'brain wave' frequencies, and neuron driven mechanisms such as <a href=\"http://en.wikipedia.org/wiki/Voice_frequency\">voice</a> have upper frequencies of the same order. &nbsp;Humans can react in as quickly as 150ms in some conditions, but appear to initiate actions such as <a href=\"http://en.wikipedia.org/wiki/Saccade\">saccades</a>&nbsp;at a rate of 3 to 4 per second. &nbsp;Smaller primate brains are similar but somewhat quicker.</p>\n<p><sup>2</sup> The greater monogenesis theory of <em>all </em>extant languages and cultures from a single distant historical <a href=\"http://en.wikipedia.org/wiki/Monogenesis_(linguistics)\">proto-language</a>&nbsp;is a matter of debate amongst linguistics, but the similarity in many low-level root words is far beyond chance. &nbsp;The restrained theory of a common root <a href=\"http://en.wikipedia.org/wiki/Proto-Indo-European_language\">Proto-Indo-European language</a> is near universally accepted. &nbsp;This <a href=\"http://en.wikipedia.org/wiki/Kurgan_hypothesis\">map</a>&nbsp;and this <a href=\"http://upload.wikimedia.org/wikipedia/commons/4/4f/IndoEuropeanTree.svg\">tree</a> help visualize the geographical historical divergence of this original language/cultural across the supercontinent along with it's characteristic artifact: the chariot. &nbsp;All of this divergence occurred on a timescale of five to six millenia.</p>\n<p><sup>3</sup> &nbsp;<a href=\"http://en.wikipedia.org/wiki/Homing_pigeon\">Homing pigeons</a>, where available, were of course much faster than the pony express, but were rare and low-bandwidth.</p>\n<p><sup>4</sup> Apparently this has been done numerous times in the last decade in different ways. &nbsp;Here is <a href=\"http://www.newscientist.com/article/dn7253-worlds-fastest-transistor-operates-at-blinding-speed.html\">one example</a>. &nbsp;Of course making a few transistors run in the terahertz doesn't get you much closer to making a whole CPU actually run at that speed, for a large variety of reasons.</p>\n<p><sup>5 </sup>None of these particular numbers will seem outlandish a decade or two from now if Moore's Law holds it's pace. &nbsp;However getting a brain or AGI type design to run at these fantastic speeds will likely require more significant innovations such as a move to 3D integrated circuits and major interconnect breakthroughs. &nbsp;There are many technological uncertainties here, but less than that involved in drexler-style nano-tech, and this is all on the current main path.</p>\n<p><sup>6</sup> It looks like we currently have around 8 tbps of <a href=\"http://gigaom.com/2009/06/22/the-coming-trans-atlantic-bandwidth-crunch/\">transatlantic bandwidth</a> circa 2011.</p>\n<p>7 Nick Bostrom seems to have introduced the Singleton concept to the Singularity/Futurist discourse <a href=\"http://www.nickbostrom.com/fut/singleton.html\">here</a>. &nbsp;He mentions artificial intelligences as one potential Singleton promoting technology but doesn't consider their speed potential with respect to the speed of light.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lnsy72itdiHdCvXcv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 15, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "5428", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 95, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HeT2pjiN4zaFY976W"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T17:20:04.740Z", "modifiedAt": null, "url": null, "title": "Thinking Outside The Sphere", "slug": "thinking-outside-the-sphere", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:38.937Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/996eA5TvvPL78w5g4/thinking-outside-the-sphere", "pageUrlRelative": "/posts/996eA5TvvPL78w5g4/thinking-outside-the-sphere", "linkUrl": "https://www.lesswrong.com/posts/996eA5TvvPL78w5g4/thinking-outside-the-sphere", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thinking%20Outside%20The%20Sphere&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThinking%20Outside%20The%20Sphere%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F996eA5TvvPL78w5g4%2Fthinking-outside-the-sphere%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thinking%20Outside%20The%20Sphere%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F996eA5TvvPL78w5g4%2Fthinking-outside-the-sphere", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F996eA5TvvPL78w5g4%2Fthinking-outside-the-sphere", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 623, "htmlBody": "<p>I think this has the makings of a potential top level post, but at the moment it seems to lack any kind of real conclusion.</p>\n<p>\n<hr />\n</p>\n<p><span style=\"font-size: 12px;\">A lot of satire has been raised on the subject of \"thinking outside the box\", but if I were to describe a habit-of-mind common to the most instrumentally competent people I can think of, I'd have to call it \"thinking outside the sphere\".</span></p>\n<p><span style=\"font-size: 12px;\">A sphere is a minimum surface solid; it has the smallest possible surface area of any shape with the same volume. This seems like an innocuous fact until you remember that we live on a sphere which is running out of usable surface area. The Earth is only spherical because of an accident of gravity, not because it's useful. In a lot of ways living on the outside surface of a solid sphere is actively undesirable, and if we were to design a new habitat for human life, we could be&nbsp;</span><span style=\"font-size: 12px;\"><a id=\"link_7\" style=\"font-family: Verdana, Arial, Helvetica, sans-serif; color: #000066;\" href=\"http://en.wikipedia.org/wiki/Globus_Cassus\">a</a></span><span style=\"font-size: 12px;\">&nbsp;</span><span style=\"font-size: 12px;\"><a id=\"link_8\" style=\"font-family: Verdana, Arial, Helvetica, sans-serif; color: #000066;\" href=\"http://en.wikipedia.org/wiki/Dyson_sphere\">lot</a></span><span style=\"font-size: 12px;\">&nbsp;</span><span style=\"font-size: 12px;\"><a id=\"link_9\" style=\"font-family: Verdana, Arial, Helvetica, sans-serif; color: #000066;\" href=\"http://en.wikipedia.org/wiki/Niven_ring\">more</a></span><span style=\"font-size: 12px;\">&nbsp;</span><span style=\"font-size: 12px;\"><a id=\"link_10\" style=\"font-family: Verdana, Arial, Helvetica, sans-serif; color: #000066;\" href=\"http://en.wikipedia.org/wiki/Alderson_disk\">creative</a></span><span style=\"font-size: 12px;\">.</span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\">In computer security there is a concept known as the attack surface, and it's comprised of everything a potential attacker could have access to. The most potentially worrying attacks are the ones you can't predict or plan for, and the only way to defend against them is to minimise the total attack surface of the system by giving potential attackers as little to work with as possible. Could an attacker exploit this unused service? No idea, but if you take it away it's one less thing to worry about.</span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\">I regularly work on (admittedly quite menial) real-world problems with no immediate solution but well-defined success criteria, and something that I've realised is that they&nbsp;</span><span style=\"font-size: 12px;\"><em>all</em></span><span style=\"font-size: 12px;\">&nbsp;have an attack surface. The size of that surface is dependent on their shape, and the shape of a problem is determined by how you think about it. Especially powerful techniques for dealing with a type of problem force them into a shape with a larger attack surface, and make them vulnerable to more potential solutions.</span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\">The trouble is that simply describing a problem can give it a certain shape. If you describe (as a completely non-controversial example) climate change in the context of collective personal energy consumption, it becomes a messy social and political problem with a highly fragmented attack surface. If you describe it in the context of the distribution of carbon in the biosphere, all of a sudden it's an engineering problem, and you have a whole host of additional tools at your disposal. The overall volume (search space) of the problem is the same, but you've changed its attack surface, and even if the new surface isn't that much greater (although in this case I would argue it is), it's at least a more contiguous surface; one vector of assault may miss its intended target, but still have an impact on the overall problem.</span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\"><br /></span><span style=\"font-size: 12px;\">This very avenue of thought is, in its own way, attempting to force a problem into a shape with a more pliable attack surface. I want to be able to describe why certain methods are more generally useful problem-solving tools than others, and in doing that I would like to find general properties of those methods which would let me more easily identify them.&nbsp;</span><span style=\"font-size: 12px;\">I</span><span style=\"font-size: 12px;\">nformation-theoretic concepts are probably quite useful here. &nbsp;Ways of describing problems with relatively low Kolmogrov Complexity (a fractal as opposed to a sphere within the confines of the metaphor), present greater attack surfaces, and provide more information about the problem. &nbsp;An example of a powerful technique with this property would be recursion.</span></p>\n<p><span style=\"font-size: 12px;\">Within the confines of the attack surface metaphor, what other properties of large surface area solids might be analogous to useful properties of powerful problem solving methods?&nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "996eA5TvvPL78w5g4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 17, "extendedScore": null, "score": 6.779758254451461e-07, "legacy": true, "legacyId": "5449", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T22:06:55.313Z", "modifiedAt": null, "url": null, "title": "Madison Less Wrong Meetup: Wednesday, 16 Feb", "slug": "madison-less-wrong-meetup-wednesday-16-feb", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.099Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s9y6gTgaekkgK7FmA/madison-less-wrong-meetup-wednesday-16-feb", "pageUrlRelative": "/posts/s9y6gTgaekkgK7FmA/madison-less-wrong-meetup-wednesday-16-feb", "linkUrl": "https://www.lesswrong.com/posts/s9y6gTgaekkgK7FmA/madison-less-wrong-meetup-wednesday-16-feb", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Madison%20Less%20Wrong%20Meetup%3A%20Wednesday%2C%2016%20Feb&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMadison%20Less%20Wrong%20Meetup%3A%20Wednesday%2C%2016%20Feb%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9y6gTgaekkgK7FmA%2Fmadison-less-wrong-meetup-wednesday-16-feb%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Madison%20Less%20Wrong%20Meetup%3A%20Wednesday%2C%2016%20Feb%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9y6gTgaekkgK7FmA%2Fmadison-less-wrong-meetup-wednesday-16-feb", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9y6gTgaekkgK7FmA%2Fmadison-less-wrong-meetup-wednesday-16-feb", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<p><a id=\"more\"></a>It's been a while since we Madisonians have assembled! Let's do it again.</p>\n<p>Where: The first floor lobby of the <a title=\"WID\" href=\"http://www.discovery.wisc.edu/home/discovery/town-center/location-and-parking/location-and-parking-home.cmsx\">WID</a></p>\n<p><a title=\"WID\" href=\"http://www.discovery.wisc.edu/home/discovery/town-center/location-and-parking/location-and-parking-home.cmsx\"></a>When: 6:00 pm, Wednesday, 16 February</p>\n<p>The first floor of the WID is open to the public, and has plenty of seats around tables, and couches, and whatnot. It's an unreasonably pleasant space convenient to campus. It's open until 8pm; I presume we'll retire thence to dinner when they threaten to close.</p>\n<p>I'll be there with some obvious Less Wrong sign.</p>\n<p>Please post here if you plan to show up, just so everyone else has some idea that people will be there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s9y6gTgaekkgK7FmA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 6.780515912743486e-07, "legacy": true, "legacyId": "5450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-11T23:15:03.455Z", "modifiedAt": null, "url": null, "title": "Comprehensible Improvments: Things you Could Do.", "slug": "comprehensible-improvments-things-you-could-do", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.925Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nbnBGG94z6gaWcihk/comprehensible-improvments-things-you-could-do", "pageUrlRelative": "/posts/nbnBGG94z6gaWcihk/comprehensible-improvments-things-you-could-do", "linkUrl": "https://www.lesswrong.com/posts/nbnBGG94z6gaWcihk/comprehensible-improvments-things-you-could-do", "postedAtFormatted": "Friday, February 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Comprehensible%20Improvments%3A%20Things%20you%20Could%20Do.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComprehensible%20Improvments%3A%20Things%20you%20Could%20Do.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnbnBGG94z6gaWcihk%2Fcomprehensible-improvments-things-you-could-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Comprehensible%20Improvments%3A%20Things%20you%20Could%20Do.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnbnBGG94z6gaWcihk%2Fcomprehensible-improvments-things-you-could-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnbnBGG94z6gaWcihk%2Fcomprehensible-improvments-things-you-could-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 871, "htmlBody": "<p>Edit2: reactions to the edit made me reconsider, partially. I might get around to making more posts here.</p>\n<p><del><strong>EDIT: Because this and all my comments on it is getting downvoted already, I won't bother finish this and wish I'd never posted anything on it. Should I delete this thread or leave it as a monument to my own pathetic failure?</strong></del></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>The topic of what you'd do if you found yourself as an upload and were to self improve is dangerous to think about for many reasons. It's unlikely to happen before the singularity and if it happens afterwards you'll have knowledge and a community that renders current speculation moot. As a human you almost certainly can't reach superintelegence without becoming Unfriendly. You can't think about any that improve intelligence beyond the first iteration because thatd be trying to predict somehting smarter than you. Etc.</p>\n<p>However, even if you can only think about the very start of it, and the actual predictions or plans that you generate neither will or should have any reason to happen, there can be less direct benefits. The dominant one is it's damn fun; thinking about things you could do to your mind is way more interesting than what you could do with that hot guy/gal sitting in front of you on the bus or what you'd do with a billion dollars. More importantly thou, it serves to provide a LOWER BOUND, helping against failures of imagination and providing more salient and near mode motivation for a friendly singularity in establishing life after it will be at least this good and the only reason you wont do these awesome things is that you'll be provided by even better alternatives. Lastly, the chance is infinitesimal, but maybe you really will at some time have to boot the singularity from only your own upload and then a repository of the least unsafe upgrades LW could think of might come in handy. Just don't fool yourself the first one isn't the real cause of doing this thou. :p</p>\n<p>Now, it happens to appear that all these 3 goals actually have the same most important heuristic: Keep it comprehensible to a vanilla human. There is a limited amount of fun to be gained from thinking of just a change to do without your brain being able to respond with what it'd feel like afterwards. Likewise, in the second goal the abstract \"somehting really good but i don't know how good or in what exact way\" is what we're trying to get away from. And for the last one, doing only changes you can comprehend is just common sense; \"know what you're doing\" taken literally.</p>\n<p>So, for he format of this thread: Have discrete improvement suggestions, and put only one in each comment with a witty title bolded. To keep it from degenerating in to buzzwords and the obvious, but all these are very lose suggestions, here's a few guidelines that improvements should follow:</p>\n<ul>\n<li>The exact situational assumptions for each example may vary, but in general you're yourself, uploaded to a machine with enough power to simulate you at 10 to 10^12 times human speed, having 10 to 10^12the required memory, containing only you and software not much more advanced than we have today, using an architecture that provides no additional obstacles to anything (for example, all the computing power can be used serially and latency can be considered negligible), and you have no reason to be interested the outside world and under no obligation to personally cause the singularity and just enjoying yourself, but making sure you do not foom and cause a bad one. These are just establishing a default and you're free to make other assumptions but you have to write them out.</li>\n<li>It should be highly predictable and EASILY comprehensible. I won't bother defining this other than by heuristic: you should be able to predict what you'd do and feel after the change as well as you'd be able to predict what you'd do before it. By this definition reading a book you haven't read before is an example of a non comprehensible change but being wireheaded is. The narrowness of this is indeed excessive, but I'm confident it still gives a large enough search space and there is no need to go further into unpredictability than necessary.</li>\n<li>keep it low level. The point of this is things you can vividly imagine, and it's very easy to get carried away into far mode and abstraction. Talk neurons and algorithms, not ideas and functionality. Or rather, talk about the low level changes first and then the results they give on higher levels. Describe not what end result it'd be cool to have, but what procedure it'd be fun to do! </li>\n<li>Have a witty title. it should be in bold.</li>\n<li>Keep it fun. This is intended fair bit less serious than most LW discussions.</li>\n<li>Keep it something more than fun, and on topic for LW.</li>\n<li>Look at the examples I make.</li>\n</ul>\n<p>EDIT: Damn, it's really late and I were a lot wordier than I thought. I don't have time to write the actual examples. I'll do that tomorrow then hopefully. Sorry. :(</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nbnBGG94z6gaWcihk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 2, "extendedScore": null, "score": 6.780695906334376e-07, "legacy": true, "legacyId": "5452", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T01:20:59.826Z", "modifiedAt": null, "url": null, "title": "An Abortion Dialogue", "slug": "an-abortion-dialogue", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:33.671Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TsRu6iP7DwRRbkHpS/an-abortion-dialogue", "pageUrlRelative": "/posts/TsRu6iP7DwRRbkHpS/an-abortion-dialogue", "linkUrl": "https://www.lesswrong.com/posts/TsRu6iP7DwRRbkHpS/an-abortion-dialogue", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20Abortion%20Dialogue&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20Abortion%20Dialogue%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTsRu6iP7DwRRbkHpS%2Fan-abortion-dialogue%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20Abortion%20Dialogue%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTsRu6iP7DwRRbkHpS%2Fan-abortion-dialogue", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTsRu6iP7DwRRbkHpS%2Fan-abortion-dialogue", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<p>A few years ago, I wrote a little dialogue I imagined between 2 materialists, one of whom was for and one against abortion, centering on the personal identity question. I recently cleaned it up and added a number of references for the biological claims.</p>\n<p>You can read it at <a href=\"http://www.gwern.net/An%20Abortion%20Dialogue\">An Abortion Dialogue</a>.</p>\n<p>Early feedback from #lesswrong is that it's a 'nicely enjoyable read' and 'quite good'. I hope everyone likes it, even if it doesn't exactly break new philosophical ground.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TsRu6iP7DwRRbkHpS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 15, "extendedScore": null, "score": 6.781027306606049e-07, "legacy": true, "legacyId": "5456", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 92, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T02:14:03.597Z", "modifiedAt": null, "url": null, "title": "Make your training useful", "slug": "make-your-training-useful", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:11.724Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7F5jo5LD9FD7DpxCX/make-your-training-useful", "pageUrlRelative": "/posts/7F5jo5LD9FD7DpxCX/make-your-training-useful", "linkUrl": "https://www.lesswrong.com/posts/7F5jo5LD9FD7DpxCX/make-your-training-useful", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Make%20your%20training%20useful&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMake%20your%20training%20useful%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7F5jo5LD9FD7DpxCX%2Fmake-your-training-useful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Make%20your%20training%20useful%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7F5jo5LD9FD7DpxCX%2Fmake-your-training-useful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7F5jo5LD9FD7DpxCX%2Fmake-your-training-useful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1406, "htmlBody": "<p>As Tom slips on the ice puddle, his arm automatically pulls back to slap the ground. &nbsp;He&rsquo;s been taking Jiu-Jitsu for only a month, but, already, he&rsquo;s practiced falling hundreds of times. &nbsp;Tom&rsquo;s training keeps him from getting hurt.</p>\n<p>By contrast, Sandra is in her second year of university mathematics. &nbsp;She got an &ldquo;A&rdquo; in calculus and in several more advanced courses, and she can easily recite that &ldquo;derivatives&rdquo; are &ldquo;rates of change&rdquo;. &nbsp;But when she goes on her afternoon walk and stares at the local businesses, she doesn&rsquo;t <em>see</em> derivatives.</p>\n<p>For many of us, rationality is more like Sandra&rsquo;s calculus than Tom&rsquo;s martial arts. &nbsp;You may think &ldquo;overconfidence&rdquo; when you hear an explicit probability (&ldquo;It&rsquo;s 99% likely I&rsquo;ll make it to Boston on Tuesday&rdquo;). &nbsp;But when no probability is mentioned -- or, worse, when you act on a belief without noticing that belief at all -- your training has little impact.</p>\n<h3><strong>Learn error patterns ahead of time</strong></h3>\n<p>If you want to notice errors <em>while you&rsquo;re making them</em>, think ahead of time about what your errors might look like. List the circumstances in which to watch out and the alternative action to try then.</p>\n<p>Here's an example of what your lists might look like. &nbsp;A bunch of visiting fellows generated this list at one of our rationality trainings last summer; I&rsquo;m including their list here (with some edits) because I found the specific suggestions useful, and because you may be able to use it as a model for your own lists.<a id=\"more\"></a></p>\n<h1>Action ideas, for three related biases:</h1>\n<h3><span style=\"font-weight: normal;\"><strong>A. How does it help to know about overconfidence[1]? &nbsp;What can you do differently, once you know your impressions are unreliable?</strong></span></h3>\n<p>Action ideas:</p>\n<ol>\n<li>Try many things, including things you &ldquo;know&rdquo; won&rsquo;t work. &nbsp;Try cheap ones.</li>\n<li>Don&rsquo;t be so sure you can&rsquo;t do things. &nbsp;</li>\n<li>Don&rsquo;t be so sure that the things you <em>are</em> doing, are working: \n<ul>\n<li>If a given &ldquo;necessary&rdquo; task is using a large portion of your week, test what happens if you skip that task.</li>\n<li>Ask others whether your efforts are working, and what you might try instead. &nbsp;Test their suggestions.</li>\n<li>Ask how you&rsquo;ll know if you hit your goal: what specific observables will be different? &nbsp;(Not &ldquo;I&rsquo;ll know calculus&rdquo; but &ldquo;I&rsquo;ll be able to solve all the problems on the AP calculus test&rdquo;. &nbsp;Not &ldquo;I&rsquo;ll be happier&rdquo; but &ldquo;I&rsquo;ll improve my score on the Beck Depression Inventory&rdquo;). &nbsp;Track these observables.</li>\n</ul>\n</li>\n<li>Be suspicious of received wisdom, since others are also overconfident. &nbsp;But don&rsquo;t just ignore that wisdom in favor of your own error-prone impressions -- look for empirical tests.[2] &nbsp;</li>\n<li>Your friends and family are weirder (more unlike your models) than you think they are. &nbsp;Try to notice how.</li>\n</ol>\n<h3><strong>B. How does it help to know about the conjunction fallacy? &nbsp;What can you do differently, once you know specific stories are less likely than we generally expect?</strong></h3>\n<p><strong></strong><span style=\"font-size: small; font-weight: normal;\">Action ideas:</span></p>\n<ol>\n<li>Use simple or disjunctive plans: \n<ul>\n<li>Choose a (city/college/etc.) in which there are many promising possibilities, not one with a single, highly promising scenario.[3]&nbsp;</li>\n<li>Apply for many jobs, in many sectors of the economy.</li>\n<li>Gather re-purposable resources, such as money, rationality, sanity, capable friends, math skill, reading speed, mental and physical fitness. &nbsp;Focus on fundamentals more than on situation-specific techniques.</li>\n</ul>\n</li>\n<li>Tell detailed stories when you want to convince someone: \n<ul>\n<li>Describe specific scenarios to angel investors, potential customers, etc.</li>\n<li>Visualize specific scenarios, when you want convince the less verbal parts of yourself that your new (exercise plan / whatever) is worth the effort.</li>\n</ul>\n</li>\n<li>Don&rsquo;t put all your caution into safeguarding one particular step. &nbsp;For example, don&rsquo;t &ldquo;ensure your start-up will succeed&rdquo; by focusing only on the programming step, or only on the &ldquo;where to sell it&rdquo; step. &nbsp;Brainstorm&nbsp;<em style=\"font-style: italic;\">many</em>&nbsp;ways your plans can go wrong.</li>\n<li>Realize that conjunction-ridden theories (e.g. the Church-Turing thesis[3], or \"I will live out my career as a mathematician\") are more likely to be mistaken than you might naively think.</li>\n</ol>\n<h3><strong>C. How does it help to know about <a href=\"http://en.wikipedia.org/wiki/Introspection_illusion\">confabulation</a>? &nbsp; &nbsp;(I.e., how does it help to know that you are often mistaken about your motives, and that situational factors affect you far more than most people expect?)</strong></h3>\n<p>Action ideas:</p>\n<ol>\n<li>It&rsquo;s not just that your beliefs about how to (make money / enjoy your Saturday / learn math / whatever) are probably overconfident. &nbsp;It&rsquo;s also that they probably weren&rsquo;t arrived at by asking &ldquo;How can I do X?&rdquo; *at all*. &nbsp;So get out a sheet of paper and a ten-minute timer; you may find better ideas <em>immediately</em>.</li>\n<li>Realize you (in a narrow verbal sense) don&rsquo;t choose most of your actions. Even when you think you do. &nbsp;It&rsquo;s therefore silly to expect your past choices to be the best choices you could have made, or to make up stories about why your actions were optimal.[5]</li>\n<li>Instead of asking &ldquo;Why did I do that?&rdquo;, ask &ldquo;Why would someone else think I did that, if they were watching only my actions?&rdquo;[6].</li>\n<li>Since your actions depend greatly on both habits and context: \n<ul>\n<li>Train the actions you want until they&rsquo;re automatic. &nbsp;Train the thinking habits you want, too. &nbsp;Don&rsquo;t just verbally acknowledge their desirability.</li>\n<li>If you want robust change, train your new behavior *across contexts*, or tie your new actions to a &ldquo;portable&rdquo; context that can remain stable even when you move, change jobs, etc. &nbsp;(For example, build a habit of looking at your goals and mission statement every morning, or using a life coach.)</li>\n<li>Consider aiming for a high-status job, or a job that demands more of you, since others&rsquo; expectations may affect you more than you naively think.</li>\n<li>Don&rsquo;t mistake background <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">knowledge</a> for <a href=\"/lw/qs/einsteins_superpowers/\">unchangeable ability</a>.</li>\n</ul>\n</li>\n</ol>\n<h1>Do try this at home.</h1>\n<p>Many of the above examples are not well-tested. &nbsp;So don&rsquo;t rely on them. &nbsp;But do <em>try</em> them. &nbsp;And, when you do, tell us about it; add your data to the common LW store.</p>\n<p>Also, practice this sort of example-generation for any rationality content that you hope to master. &nbsp;Now that you know about Bayes&rsquo; theorem, outside view prediction methods, confirmation bias, or any of the others -- what can you do differently at work? in your relationship? while cooking dinner tonight?</p>\n<p>The more specific your brainstorm is, the easier it will be to actually try things.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>[1] By &ldquo;overconfidence&rdquo;, I mean the well-documented bias whereby people think they know more than they do -- I do not mean the bias of over-estimating one&rsquo;s own abilities.</p>\n<p>[2] &ldquo;Empirical tests&rdquo; here can include your own direct observations, friends&rsquo; anecdotes, published controlled studies, and anything else in the world that should look different, if [received wisdom / your own impression] is true. Many folks just throw up their hands or take a vote when they see folks that disagree with one another; but sorting out the evidence is a learnable skill. &nbsp;It&rsquo;s worth doing this for medical treatments, job search strategy, driving safety, learning methods, and ... anything else that has much impact on your life.</p>\n<p>[3] For example, prefer &ldquo;I&rsquo;ll go to college X, where there are many smart people and connections&rdquo; to &ldquo;I&rsquo;ll go to college Y, which is renowned for bioinformatics in particular, since bioinformatics is my lifelong destiny and will let me work for Craig Venter&rdquo;.</p>\n<p>[4] The Church-Turing thesis may not sound like a conjunction. &nbsp;But for it to hold, physics needs to be as we expect along many different dimensions, which is a conjunction, and is the sort of possibility we tend to overestimate. &nbsp;Similarly, there are many different events that could interrupt your planned career, and we tend to overestimate the chances that all of these events, at once, will not occur.</p>\n<p>[5] &nbsp;But it isn&rsquo;t silly to try to make your future actions more (useful/moral/whatever). &nbsp;Even if most actions occur by habit, you can, little by little, change your habits, and increase your self-awareness and your deliberative self-control.</p>\n<p>[6] Or: &ldquo;What would I believe about someone else, if they acted as I&rsquo;ve been acting?&rdquo;</p>\n<p><strong>Edited to add: &nbsp;Do please comment with your own attempts to turn LW rationality content into the kinds of specifics one can easily act on.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5gcpKG2XEAZGj5DEf": 1, "fkABsGCJZ6y9qConW": 1, "AodfCFefLAuwDyj7Z": 1, "dJ6eJxJrCEget7Wb6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7F5jo5LD9FD7DpxCX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 103, "baseScore": 130, "extendedScore": null, "score": 0.00025, "legacy": true, "legacyId": "5455", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 130, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>As Tom slips on the ice puddle, his arm automatically pulls back to slap the ground. &nbsp;He\u2019s been taking Jiu-Jitsu for only a month, but, already, he\u2019s practiced falling hundreds of times. &nbsp;Tom\u2019s training keeps him from getting hurt.</p>\n<p>By contrast, Sandra is in her second year of university mathematics. &nbsp;She got an \u201cA\u201d in calculus and in several more advanced courses, and she can easily recite that \u201cderivatives\u201d are \u201crates of change\u201d. &nbsp;But when she goes on her afternoon walk and stares at the local businesses, she doesn\u2019t <em>see</em> derivatives.</p>\n<p>For many of us, rationality is more like Sandra\u2019s calculus than Tom\u2019s martial arts. &nbsp;You may think \u201coverconfidence\u201d when you hear an explicit probability (\u201cIt\u2019s 99% likely I\u2019ll make it to Boston on Tuesday\u201d). &nbsp;But when no probability is mentioned -- or, worse, when you act on a belief without noticing that belief at all -- your training has little impact.</p>\n<h3 id=\"Learn_error_patterns_ahead_of_time\"><strong>Learn error patterns ahead of time</strong></h3>\n<p>If you want to notice errors <em>while you\u2019re making them</em>, think ahead of time about what your errors might look like. List the circumstances in which to watch out and the alternative action to try then.</p>\n<p>Here's an example of what your lists might look like. &nbsp;A bunch of visiting fellows generated this list at one of our rationality trainings last summer; I\u2019m including their list here (with some edits) because I found the specific suggestions useful, and because you may be able to use it as a model for your own lists.<a id=\"more\"></a></p>\n<h1 id=\"Action_ideas__for_three_related_biases_\">Action ideas, for three related biases:</h1>\n<h3 id=\"A__How_does_it_help_to_know_about_overconfidence_1____What_can_you_do_differently__once_you_know_your_impressions_are_unreliable_\"><span style=\"font-weight: normal;\"><strong>A. How does it help to know about overconfidence[1]? &nbsp;What can you do differently, once you know your impressions are unreliable?</strong></span></h3>\n<p>Action ideas:</p>\n<ol>\n<li>Try many things, including things you \u201cknow\u201d won\u2019t work. &nbsp;Try cheap ones.</li>\n<li>Don\u2019t be so sure you can\u2019t do things. &nbsp;</li>\n<li>Don\u2019t be so sure that the things you <em>are</em> doing, are working: \n<ul>\n<li>If a given \u201cnecessary\u201d task is using a large portion of your week, test what happens if you skip that task.</li>\n<li>Ask others whether your efforts are working, and what you might try instead. &nbsp;Test their suggestions.</li>\n<li>Ask how you\u2019ll know if you hit your goal: what specific observables will be different? &nbsp;(Not \u201cI\u2019ll know calculus\u201d but \u201cI\u2019ll be able to solve all the problems on the AP calculus test\u201d. &nbsp;Not \u201cI\u2019ll be happier\u201d but \u201cI\u2019ll improve my score on the Beck Depression Inventory\u201d). &nbsp;Track these observables.</li>\n</ul>\n</li>\n<li>Be suspicious of received wisdom, since others are also overconfident. &nbsp;But don\u2019t just ignore that wisdom in favor of your own error-prone impressions -- look for empirical tests.[2] &nbsp;</li>\n<li>Your friends and family are weirder (more unlike your models) than you think they are. &nbsp;Try to notice how.</li>\n</ol>\n<h3 id=\"B__How_does_it_help_to_know_about_the_conjunction_fallacy___What_can_you_do_differently__once_you_know_specific_stories_are_less_likely_than_we_generally_expect_\"><strong>B. How does it help to know about the conjunction fallacy? &nbsp;What can you do differently, once you know specific stories are less likely than we generally expect?</strong></h3>\n<p><strong></strong><span style=\"font-size: small; font-weight: normal;\">Action ideas:</span></p>\n<ol>\n<li>Use simple or disjunctive plans: \n<ul>\n<li>Choose a (city/college/etc.) in which there are many promising possibilities, not one with a single, highly promising scenario.[3]&nbsp;</li>\n<li>Apply for many jobs, in many sectors of the economy.</li>\n<li>Gather re-purposable resources, such as money, rationality, sanity, capable friends, math skill, reading speed, mental and physical fitness. &nbsp;Focus on fundamentals more than on situation-specific techniques.</li>\n</ul>\n</li>\n<li>Tell detailed stories when you want to convince someone: \n<ul>\n<li>Describe specific scenarios to angel investors, potential customers, etc.</li>\n<li>Visualize specific scenarios, when you want convince the less verbal parts of yourself that your new (exercise plan / whatever) is worth the effort.</li>\n</ul>\n</li>\n<li>Don\u2019t put all your caution into safeguarding one particular step. &nbsp;For example, don\u2019t \u201censure your start-up will succeed\u201d by focusing only on the programming step, or only on the \u201cwhere to sell it\u201d step. &nbsp;Brainstorm&nbsp;<em style=\"font-style: italic;\">many</em>&nbsp;ways your plans can go wrong.</li>\n<li>Realize that conjunction-ridden theories (e.g. the Church-Turing thesis[3], or \"I will live out my career as a mathematician\") are more likely to be mistaken than you might naively think.</li>\n</ol>\n<h3 id=\"C__How_does_it_help_to_know_about_confabulation______I_e___how_does_it_help_to_know_that_you_are_often_mistaken_about_your_motives__and_that_situational_factors_affect_you_far_more_than_most_people_expect__\"><strong>C. How does it help to know about <a href=\"http://en.wikipedia.org/wiki/Introspection_illusion\">confabulation</a>? &nbsp; &nbsp;(I.e., how does it help to know that you are often mistaken about your motives, and that situational factors affect you far more than most people expect?)</strong></h3>\n<p>Action ideas:</p>\n<ol>\n<li>It\u2019s not just that your beliefs about how to (make money / enjoy your Saturday / learn math / whatever) are probably overconfident. &nbsp;It\u2019s also that they probably weren\u2019t arrived at by asking \u201cHow can I do X?\u201d *at all*. &nbsp;So get out a sheet of paper and a ten-minute timer; you may find better ideas <em>immediately</em>.</li>\n<li>Realize you (in a narrow verbal sense) don\u2019t choose most of your actions. Even when you think you do. &nbsp;It\u2019s therefore silly to expect your past choices to be the best choices you could have made, or to make up stories about why your actions were optimal.[5]</li>\n<li>Instead of asking \u201cWhy did I do that?\u201d, ask \u201cWhy would someone else think I did that, if they were watching only my actions?\u201d[6].</li>\n<li>Since your actions depend greatly on both habits and context: \n<ul>\n<li>Train the actions you want until they\u2019re automatic. &nbsp;Train the thinking habits you want, too. &nbsp;Don\u2019t just verbally acknowledge their desirability.</li>\n<li>If you want robust change, train your new behavior *across contexts*, or tie your new actions to a \u201cportable\u201d context that can remain stable even when you move, change jobs, etc. &nbsp;(For example, build a habit of looking at your goals and mission statement every morning, or using a life coach.)</li>\n<li>Consider aiming for a high-status job, or a job that demands more of you, since others\u2019 expectations may affect you more than you naively think.</li>\n<li>Don\u2019t mistake background <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">knowledge</a> for <a href=\"/lw/qs/einsteins_superpowers/\">unchangeable ability</a>.</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Do_try_this_at_home_\">Do try this at home.</h1>\n<p>Many of the above examples are not well-tested. &nbsp;So don\u2019t rely on them. &nbsp;But do <em>try</em> them. &nbsp;And, when you do, tell us about it; add your data to the common LW store.</p>\n<p>Also, practice this sort of example-generation for any rationality content that you hope to master. &nbsp;Now that you know about Bayes\u2019 theorem, outside view prediction methods, confirmation bias, or any of the others -- what can you do differently at work? in your relationship? while cooking dinner tonight?</p>\n<p>The more specific your brainstorm is, the easier it will be to actually try things.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p>[1] By \u201coverconfidence\u201d, I mean the well-documented bias whereby people think they know more than they do -- I do not mean the bias of over-estimating one\u2019s own abilities.</p>\n<p>[2] \u201cEmpirical tests\u201d here can include your own direct observations, friends\u2019 anecdotes, published controlled studies, and anything else in the world that should look different, if [received wisdom / your own impression] is true. Many folks just throw up their hands or take a vote when they see folks that disagree with one another; but sorting out the evidence is a learnable skill. &nbsp;It\u2019s worth doing this for medical treatments, job search strategy, driving safety, learning methods, and ... anything else that has much impact on your life.</p>\n<p>[3] For example, prefer \u201cI\u2019ll go to college X, where there are many smart people and connections\u201d to \u201cI\u2019ll go to college Y, which is renowned for bioinformatics in particular, since bioinformatics is my lifelong destiny and will let me work for Craig Venter\u201d.</p>\n<p>[4] The Church-Turing thesis may not sound like a conjunction. &nbsp;But for it to hold, physics needs to be as we expect along many different dimensions, which is a conjunction, and is the sort of possibility we tend to overestimate. &nbsp;Similarly, there are many different events that could interrupt your planned career, and we tend to overestimate the chances that all of these events, at once, will not occur.</p>\n<p>[5] &nbsp;But it isn\u2019t silly to try to make your future actions more (useful/moral/whatever). &nbsp;Even if most actions occur by habit, you can, little by little, change your habits, and increase your self-awareness and your deliberative self-control.</p>\n<p>[6] Or: \u201cWhat would I believe about someone else, if they acted as I\u2019ve been acting?\u201d</p>\n<p><strong id=\"Edited_to_add___Do_please_comment_with_your_own_attempts_to_turn_LW_rationality_content_into_the_kinds_of_specifics_one_can_easily_act_on_\">Edited to add: &nbsp;Do please comment with your own attempts to turn LW rationality content into the kinds of specifics one can easily act on.</strong></p>", "sections": [{"title": "Learn error patterns ahead of time", "anchor": "Learn_error_patterns_ahead_of_time", "level": 2}, {"title": "Action ideas, for three related biases:", "anchor": "Action_ideas__for_three_related_biases_", "level": 1}, {"title": "A. How does it help to know about overconfidence[1]? \u00a0What can you do differently, once you know your impressions are unreliable?", "anchor": "A__How_does_it_help_to_know_about_overconfidence_1____What_can_you_do_differently__once_you_know_your_impressions_are_unreliable_", "level": 2}, {"title": "B. How does it help to know about the conjunction fallacy? \u00a0What can you do differently, once you know specific stories are less likely than we generally expect?", "anchor": "B__How_does_it_help_to_know_about_the_conjunction_fallacy___What_can_you_do_differently__once_you_know_specific_stories_are_less_likely_than_we_generally_expect_", "level": 2}, {"title": "C. How does it help to know about confabulation? \u00a0 \u00a0(I.e., how does it help to know that you are often mistaken about your motives, and that situational factors affect you far more than most people expect?)", "anchor": "C__How_does_it_help_to_know_about_confabulation______I_e___how_does_it_help_to_know_that_you_are_often_mistaken_about_your_motives__and_that_situational_factors_affect_you_far_more_than_most_people_expect__", "level": 2}, {"title": "Do try this at home.", "anchor": "Do_try_this_at_home_", "level": 1}, {"title": "Edited to add: \u00a0Do please comment with your own attempts to turn LW rationality content into the kinds of specifics one can easily act on.", "anchor": "Edited_to_add___Do_please_comment_with_your_own_attempts_to_turn_LW_rationality_content_into_the_kinds_of_specifics_one_can_easily_act_on_", "level": 3}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "46 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tSgcorrgBnrCH8nL3", "5o4EZJyqmHY4XgRCY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T05:00:48.832Z", "modifiedAt": null, "url": null, "title": "What's the single best introduction to evolution to give to a creationist?", "slug": "what-s-the-single-best-introduction-to-evolution-to-give-to", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.512Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k2vtJtQjLCXAdWetH/what-s-the-single-best-introduction-to-evolution-to-give-to", "pageUrlRelative": "/posts/k2vtJtQjLCXAdWetH/what-s-the-single-best-introduction-to-evolution-to-give-to", "linkUrl": "https://www.lesswrong.com/posts/k2vtJtQjLCXAdWetH/what-s-the-single-best-introduction-to-evolution-to-give-to", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20the%20single%20best%20introduction%20to%20evolution%20to%20give%20to%20a%20creationist%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20the%20single%20best%20introduction%20to%20evolution%20to%20give%20to%20a%20creationist%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2vtJtQjLCXAdWetH%2Fwhat-s-the-single-best-introduction-to-evolution-to-give-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20the%20single%20best%20introduction%20to%20evolution%20to%20give%20to%20a%20creationist%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2vtJtQjLCXAdWetH%2Fwhat-s-the-single-best-introduction-to-evolution-to-give-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2vtJtQjLCXAdWetH%2Fwhat-s-the-single-best-introduction-to-evolution-to-give-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 423, "htmlBody": "<p>I have a creationist friend with no particular rationalist or scientific training. She recently asked me to&nbsp;send her a \"list of evidence for evolution that persuaded me.\" After some prodding, it was revealed that she's getting into an argument with another friend of hers who believes in evolution. I'm assuming that she wants the experience of arguing with someone who's on level footing with her. It seems like a good opportunity to broaden someone's mind in a more general way that'll benefit them in the long term. I don't particularly care whether she believes in evolution (it probably will not impact her or the world in general if she changes her mind about it). But I'd like to phrase my e-mail in a way that's most likely to cause her to re-evaluate her worldview.</p>\n<p class=\"p1\">Subgoals related to this:</p>\n<p class=\"p1\">1. Point out that \"losing\" an argument can allow you to learn things, and if you honestly care about truth you'll try your best to evaluate ideas from other points of view and consider what it would mean if they were true. Do this without sounding condescending.</p>\n<p class=\"p1\">2. Give her a line of retreat by proposing that evolution is compatible with the Original Sin interpretation of genesis (which is very important to her and I would never attempt to argue against).</p>\n<p class=\"p1\">3. Give as much background as possible on the scientific method.&nbsp;</p>\n<p class=\"p1\">4. Still manage to focus the bulk of the e-mail on the most persuasive facts supporting evolution, otherwise I'm obviously not satisfying the criteria she actually gave me. I don't mind taking advantage of her request for my own purposes, but only if I'm actually helping her with her stated goal.&nbsp;</p>\n<p class=\"p1\">5. Specifically show why macroevolution is not only possibly but likely. (I'm pretty sure she either already believes or could be easily persuaded to believe in microevolution)</p>\n<p class=\"p1\">6. DON'T focus too much on why creationist arguments are flawed (she hasn't even used any yet, and it sends the wrong message about trying to actually figure out what the truth is)</p>\n<p class=\"p1\">7. Accomplish everything in approximately 3000 words, without using jargon, designed to be read by someone who's mental architecture isn't particularly adapted to rationalist thinking. (Most people aren't.)&nbsp;</p>\n<p class=\"p1\">I believe I can do a decent job myself. But it'll be a fair amount of work, and I want to know if anyone had a recommendation for a particularly good essay that I can either link her to or borrow pieces from. I might also include a link to a page of common bad creationist arguments and why they don't make sense.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k2vtJtQjLCXAdWetH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 6.781606790648679e-07, "legacy": true, "legacyId": "5470", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T05:46:44.853Z", "modifiedAt": null, "url": null, "title": "LINK: 'Philosophy Bites' episode on the Singularity", "slug": "link-philosophy-bites-episode-on-the-singularity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:38.924Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dz2mjc4EuR5os9dfQ/link-philosophy-bites-episode-on-the-singularity", "pageUrlRelative": "/posts/dz2mjc4EuR5os9dfQ/link-philosophy-bites-episode-on-the-singularity", "linkUrl": "https://www.lesswrong.com/posts/dz2mjc4EuR5os9dfQ/link-philosophy-bites-episode-on-the-singularity", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20'Philosophy%20Bites'%20episode%20on%20the%20Singularity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20'Philosophy%20Bites'%20episode%20on%20the%20Singularity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz2mjc4EuR5os9dfQ%2Flink-philosophy-bites-episode-on-the-singularity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20'Philosophy%20Bites'%20episode%20on%20the%20Singularity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz2mjc4EuR5os9dfQ%2Flink-philosophy-bites-episode-on-the-singularity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdz2mjc4EuR5os9dfQ%2Flink-philosophy-bites-episode-on-the-singularity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 15, "htmlBody": "<p>In May 2010, a leading philosophy podcast called <em>Philosophy Bites</em>&nbsp;did <a href=\"http://philosophybites.com/2010/05/david-chalmers-on-the-singularity.html\">a show on the Singularity</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dz2mjc4EuR5os9dfQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 6.781730793969391e-07, "legacy": true, "legacyId": "5474", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T14:57:43.474Z", "modifiedAt": null, "url": null, "title": "Are Intuitions Good Evidence? [Link]", "slug": "are-intuitions-good-evidence-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:41.222Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4GXBPWimqz9nyJkL4/are-intuitions-good-evidence-link", "pageUrlRelative": "/posts/4GXBPWimqz9nyJkL4/are-intuitions-good-evidence-link", "linkUrl": "https://www.lesswrong.com/posts/4GXBPWimqz9nyJkL4/are-intuitions-good-evidence-link", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20Intuitions%20Good%20Evidence%3F%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20Intuitions%20Good%20Evidence%3F%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GXBPWimqz9nyJkL4%2Fare-intuitions-good-evidence-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20Intuitions%20Good%20Evidence%3F%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GXBPWimqz9nyJkL4%2Fare-intuitions-good-evidence-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4GXBPWimqz9nyJkL4%2Fare-intuitions-good-evidence-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 282, "htmlBody": "<blockquote>\n<p><span style=\"letter-spacing: 0px;\">Ethics leans especially heavily on appeals to intuition, with a whole school of ethicists (&ldquo;intuitionists&rdquo;) maintaining that a person can see the truth of general ethical principles not through reason, but because he &ldquo;just sees without argument that they are and must be true.&rdquo;<span style=\"font-size: 78%;\"><sup>6</sup></span></span> Intuitions are also called upon to rebut ethical theories such as utilitarianism: maximizing overall utility would require you to kill one innocent person if, in so doing, you could harvest her organs and save five people in need of transplants. Such a conclusion is taken as a reductio ad absurdum, requiring utilitarianism to be either abandoned or radically revised &ndash; <strong>not because the conclusion is <em>logically</em> wrong, but because it strikes nearly everyone as <em>intuitively</em> wrong. </strong></p>\n<p>[...]</p>\n<p><span style=\"letter-spacing: 0px;\">One central concern for the critics is that a single question can inspire totally different, and mutually contradictory, intuitions in different people. Personally, <strong>I&rsquo;ve often been amazed at how completely I disagree with what a philosopher claims is &ldquo;intuitively&rdquo; the case</strong>. For example, I disagree with Moore&rsquo;s intuition that it would be better for a beautiful planet to exist than an ugly one even if there were no one around to see it. I can&rsquo;t understand what the words &ldquo;better&rdquo; and &ldquo;worse,&rdquo; let alone &ldquo;beautiful&rdquo; and &ldquo;ugly,&rdquo; could possibly mean outside the domain of the experiences of conscious beings. I know I&rsquo;m not alone in my disagreement with Moore, yet I&rsquo;ve also talked to other well-respected professional philosophers who claim to share his intuition. </span></p>\n</blockquote>\n<p><strong>Link:</strong> <a href=\"http://rationallyspeaking.blogspot.com/2011/01/are-intuitions-good-evidence.html\">rationallyspeaking.blogspot.com/2011/01/are-intuitions-good-evidence.html</a></p>\n<p>I think the article provides some interesting insights into philosophy. It is also food for thought when it comes to <a href=\"/lw/43v/the_urgent_metaethics_of_friendly_artificial/\">metaethics</a>, <a href=\"/lw/28k/the_psychological_diversity_of_mankind/\">the psychological diversity of mankind</a> and <em>intuitively wrong</em> versus <em><a href=\"/lw/kn/torture_vs_dust_specks/uf7\">rationally right</a></em>.</p>\n<p><sub>via <a href=\"http://commonsenseatheism.com/?p=14069\">Luke Muehlhauser</a></sub></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4GXBPWimqz9nyJkL4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 6.783187009674587e-07, "legacy": true, "legacyId": "5490", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TKdpSzmcezNbfmGAy", "2oybbEw697CQgcRE5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T16:53:24.060Z", "modifiedAt": null, "url": null, "title": "Secure Your Beliefs", "slug": "secure-your-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:00.237Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mEAocxta4uLdejo7j/secure-your-beliefs", "pageUrlRelative": "/posts/mEAocxta4uLdejo7j/secure-your-beliefs", "linkUrl": "https://www.lesswrong.com/posts/mEAocxta4uLdejo7j/secure-your-beliefs", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Secure%20Your%20Beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASecure%20Your%20Beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmEAocxta4uLdejo7j%2Fsecure-your-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Secure%20Your%20Beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmEAocxta4uLdejo7j%2Fsecure-your-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmEAocxta4uLdejo7j%2Fsecure-your-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 418, "htmlBody": "<p>When I was 12, my cousin Salina was 15.&nbsp;She was sitting in the back seat of a car with the rest of her family when a truck carrying concrete pipes came around the turn. The trucker had failed to secure his load properly, and the pipes broke loose. One of them smashed into Salina's head. My family has never wept as deeply as we did during the slideshow at her funeral.</p>\n<p>The trucker didn't <em>want</em>&nbsp;to kill Salina. We can't condemn him for <em>murder</em>. Instead, we condemn him for <em>negligence</em>. We condemn him for failing to care enough for others' safety to properly secure his load. We give out the same condemnation to the aircraft safety inspector who skips important tests on his checklist because it's cold outside. That kind of negligence can kill people, and people who don't want their loved ones harmed have strong reasons to condemn such a careless attitude.</p>\n<p>Social tools like praise and condemnation can change people's attitudes and desires. I was still a&nbsp;fundamentalist&nbsp;Christian when I went to college, but well-placed condemnation from people I respected changed my attitude toward gay marriage pretty quickly. Most humans care what their peers think of them. That's why public praise for those who promote a good level of safety, along with public condemnation for those who are negligent, can help save lives.</p>\n<p>Failure to secure a truck load can be deadly. But failure to secure one's <em>beliefs</em>&nbsp;can be even worse.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Vaccine_controversy#Events_following_reductions_in_vaccination\">Again and again</a>, people who choose to trust intuition and anecdote instead of the replicated scientific evidence about vaccines have caused reductions in vaccination rates, which are then followed by deadly epidemics of easily preventable disease. Anti-vaccination activists are negligent with their beliefs. They fail to secure their beliefs in an obvious and clear-cut case. People who don't want their loved ones to catch polio or&nbsp;diphtheria&nbsp;from a neighbor who didn't vaccinate their children have reasons to condemn - and thereby decrease - such negligence.</p>\n<p>People often say of false or delusional beliefs: \"What's the harm?\" The answer is \"lots.\" <a href=\"http://whatstheharm.net/\">WhatsTheHarm.com</a> collects incidents of harm from obvious products of epistemic negligence like <a href=\"http://whatstheharm.net/hivaidsdenial.html\">AIDS denial</a>, <a href=\"http://whatstheharm.net/homeopathy.html\">homeopathy</a>, <a href=\"http://whatstheharm.net/exorcisms.html\">exorcism</a>, and <a href=\"http://whatstheharm.net/faithhealing.html\">faith healing</a>. As of today they've counted up more than 300,000 injuries, 300,000 deaths, and $2 billion in economic damages due to intellectual recklessness.&nbsp;Very few of those harmed by such epistemic negligence have been listed by WhatsTheHarm.com, so the problem is actually much, <em>much</em>&nbsp;worse than that.</p>\n<p>Failure to <a href=\"http://commonsenseatheism.com/?p=4299\">secure one's beliefs</a> can lead to misery on a massive scale. That is why <a href=\"/lw/hn/your_rationality_is_my_business/\">your rationality is my business</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mEAocxta4uLdejo7j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 57, "extendedScore": null, "score": 0.000119, "legacy": true, "legacyId": "5491", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["anCubLdggTWjnEvBS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-12T18:10:32.172Z", "modifiedAt": null, "url": null, "title": "Link: Cryonics and the Creation of a Durable Morality", "slug": "link-cryonics-and-the-creation-of-a-durable-morality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:39.258Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lsparrish", "createdAt": "2010-06-30T19:05:11.515Z", "isAdmin": false, "displayName": "lsparrish"}, "userId": "xgc8giekPig6tYf2X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nfMStmK3bqpPmGSqE/link-cryonics-and-the-creation-of-a-durable-morality", "pageUrlRelative": "/posts/nfMStmK3bqpPmGSqE/link-cryonics-and-the-creation-of-a-durable-morality", "linkUrl": "https://www.lesswrong.com/posts/nfMStmK3bqpPmGSqE/link-cryonics-and-the-creation-of-a-durable-morality", "postedAtFormatted": "Saturday, February 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Cryonics%20and%20the%20Creation%20of%20a%20Durable%20Morality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Cryonics%20and%20the%20Creation%20of%20a%20Durable%20Morality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfMStmK3bqpPmGSqE%2Flink-cryonics-and-the-creation-of-a-durable-morality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Cryonics%20and%20the%20Creation%20of%20a%20Durable%20Morality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfMStmK3bqpPmGSqE%2Flink-cryonics-and-the-creation-of-a-durable-morality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfMStmK3bqpPmGSqE%2Flink-cryonics-and-the-creation-of-a-durable-morality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 813, "htmlBody": "<p>From Mike Darwin's <a href=\"http://chronopause.com/index.php/2011/02/11/cryonics-and-the-creation-of-a-durable-morality/\">new blog</a>:</p>\n<blockquote>\n<p>DCD has lead to a fracture within the medical community [7,8] wherein some centers, such as the University of Pittsburgh Medical Center, have taken patients who want ventilator support withdrawn, placed femoral cannulae under local (spinal) anesthesia, turned off the ventilator after effectively anesthetizing the patient, waited until the patient&rsquo;s heart stops, and then restarted circulation with CPB. They also, of course, give paralytic neuromuscular blocking drugs (as is routine in all visceral organ retrieval) to prevent the thoracoabdominal incision, and the terminal drop in blood pressure (when the organs are removed), from causing muscle vesiculations (twitching) or actual limb movement as a result of stimulation of the nocioceptive pathways in the spinal cord (pain is a local phenomenon first and a central nervous system one secondly with the process proceeding up the spinal cord to the brain). [9,10]</p>\n<p>To be blunt, this procedure resulted in all hell breaking out. [11,12,13] Bioethicists, such James Bernat and Leslie Whetstine, accused the surgeons and neurologists involved in this undertaking of every ethical evil, including homicide.[14,15] A compromise position is to restore circulation in the body using a special balloon-tipped aortic catheter that prevents &lsquo;all &lsquo; flow to the brain. This results in a &lsquo;resolution&rsquo; to the &lsquo;paradox&rsquo; of removing organs from a patient with a &lsquo;viable, or potentially viable brain.&rsquo; Of course, from our perspective as cryonicists, this whole exercise is nothing more or less than a procedural contortion designed to avoid confronting the reality that death is not a binary condition, and that if you are going to allow people to withdraw from medical care they no longer want, and that they (rightfully) consider an assault, then the corollary to that is that they also get to decide when they are dead. [16] That means that they have the perfect right to ask for, and receive a treatment (i.e., in the presence of informed consent) whereby they are anesthetized, cooled, subjected to blood washout, and their organs removed &ndash; <em>at which point they are indeed DEAD</em>, in the sense that their non-functional condition is now irreversible, or not going to be reversed, <em>because they do not want it to be</em>. When, exactly, they become irrecoverable from an information-theoretic standpoint is irrelevant, because they don&rsquo;t want to be recovered, and no technology currently exists that will allow them to be recovered.</p>\n<p>We, as cryonicists, could argue that if such patients were cryopreserved, they might possibly be recovered in the future. But if they do not want cryopreservation, then they are dead when <em>they </em>say they are dead, and when they meet the current medico-legal definition of cardiorespiratory death (i.e., no heartbeat or breathing and no prospect of their resuming). The medical response to this fairly straightforward situation has been, as expected, convoluted and irrational,<em> and</em> profoundly dangerous to cryonics. The recent paper &ldquo;Clarifying the paradigm for the ethics of donation and transplantation: Was &lsquo;dead&rsquo; really so clear before organ donation?&rdquo; [17] is an excellent window into current medical policy, not just on the issue of DCD, but on the application of <em>any</em> kind of circulatory support to patients who have been pronounced dead on the basis of clinical (cardiac) criteria. &nbsp;This article is one of the most cited in current DCD debates, and the closing sentence in its abstract says it all (emphasis mine):</p>\n<p><em>&ldquo;Criticism of controlled DCD on the basis of violating the dead donor rule, where autoresuscitation has not been described beyond 2 minutes, in which life support is withdrawn and CPR is not provided, is not valid. <strong>However, any post mortem intervention that reestablishes brain blood flow should be prohibited. </strong>&ldquo;In comparison to traditional practice, organ donation has forced the clarification of the diagnostic criteria for death and improved the rigour of the determinations.&rdquo;[17]</em></p>\n<p><em>...</em></p>\n<p>The UK has already adopted standards for determining and pronouncing death that <em>expressly prohibit the application of CPR, or any modalities that restore flow to the brain or conserve brain viability</em>. I have made inquiries, and been informed that failure to follow these Guidelines would be a serious breach of professional conduct, resulting in any licensed person being struck off; and that such action would very likely constitute a criminal act in the UK, as well (prosecution to be at the discretion of law enforcement and the prosecutor). [21]</p>\n</blockquote>\n<p>The whole point of cryonics -- not to put too fine a point on it -- is to conserve brain viability, in the sense of keeping as much of the brain in as close to a viable state as possible.</p>\n<p>ETA: Mike has <a href=\"http://chronopause.com/index.php/2011/02/11/cryonics-and-the-creation-of-a-durable-morality/#comment-41\">confirmed</a> that the UK law applies to non organ donors. He also has stated that new changes have been made to the Uniform Anatomical Gift Act (a sort of template by which state laws are drafted) which are likely to be similar in nature, in the US.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2, "ZnHkaTkxukegSrZqE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nfMStmK3bqpPmGSqE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 6.783696735868478e-07, "legacy": true, "legacyId": "5492", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T04:47:46.252Z", "modifiedAt": null, "url": null, "title": "Science: Do It Yourself", "slug": "science-do-it-yourself", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:27.843Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alyssavance", "createdAt": "2009-10-07T20:08:31.887Z", "isAdmin": false, "displayName": "alyssavance"}, "userId": "zQSAWAS5tnqtzp55N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K82evF2iRAiRWwvyn/science-do-it-yourself", "pageUrlRelative": "/posts/K82evF2iRAiRWwvyn/science-do-it-yourself", "linkUrl": "https://www.lesswrong.com/posts/K82evF2iRAiRWwvyn/science-do-it-yourself", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Science%3A%20Do%20It%20Yourself&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScience%3A%20Do%20It%20Yourself%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK82evF2iRAiRWwvyn%2Fscience-do-it-yourself%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Science%3A%20Do%20It%20Yourself%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK82evF2iRAiRWwvyn%2Fscience-do-it-yourself", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK82evF2iRAiRWwvyn%2Fscience-do-it-yourself", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1696, "htmlBody": "<p>In the nerd community, we have lots of warm, fuzzy associations around 'science'. And, of course, science is indeed awesome. But, seeing how awesome science is, shouldn't we try to have more of it in our lives? When was the last time we did an experiment to test a theory?</p>\n<p>Here, I will try to introduce a technique which I have found to be very useful. It is based on the classical scientific method, but I call it \"DIY Science\", to distinguish it from university science. The point of DIY Science is that science is not that hard to do, and can be used to answer practical questions as well as abstract ones. Particle physics looks hard to do, since you need expensive, massive accelerators and magnets and stuff. However, fortunately, some of the fields in which it is easiest to do science are some of the most practical and interesting. Anyone smart and rational can start doing science right now, from their home computer.</p>\n<p><a id=\"more\"></a></p>\n<p>One of the key ingredients of DIY Science is to discard the more useless trappings of university science, for these frequently do more harm than good. Science doesn't <em>need</em> journals and universities. Science doesn't <em>need</em> beakers and test tubes. Science doesn't <em>need</em> p &lt; 0.05, although I have found p-tests to be occasionally useful. The point of science is not to conform to these stereotypes of academia, but to discover something you didn't know before. (To our detriment, this is the opposite of how science is taught, as noted by <a href=\"http://www.paulgraham.com/hp.html\">Paul Graham</a>: \"<span>So hackers start original, and get good, and scientists start good, and get original.\")</span></p>\n<p><span>Instead, as an simple first example, consider this question:</span></p>\n<p><span>&nbsp;- I want to get rich, or to be specific, have a net worth of over $100M USD. How do people get rich?</span></p>\n<p><span><span>Here, we have an opportunity: We don't know something, and we want to find out what it is. To answer this question, our first intuition might be to Google \"how do people get rich?\". This isn't a horrible method, but by just asking someone else, we are not doing any science. Googling or asking a friend isn't the scientific method; it's the medieval method. (In medieval times, we would just have gone to the Church and asked, and the Church would have replied, \"Pray diligently to the LORD and have faith, and you will be prosperous.\" Different people, same thing.)</span></span></p>\n<p><span><span>In fields like physics, where lots of science is already being done by others, this will probably be OK. However, what if the question isn't about physics, like most questions people ask? Then, when you ask Google or a friend, you wind up with complete nonsense like <a href=\"http://studenomics.com/personal-finance/how-do-people-get-rich-a-look-at-wealth-accumulation-strategies/\">this</a>, which is the first Google result for \"how do people get rich\". Most people don't know how to use science, so that sort of nonsense is what most people believe about the world</span></span><span><span>, which is why Western civilization is in such a mess right now.</span></span></p>\n<p><span><span>Instead of Googling or asking someone else, we can apply the scientific method of actually looking at the data, and seeing what it says. Who are some rich people? How did they get rich? Where can we find information on rich people? The simplest technique, the one that I used when answering this question, is:</span></span></p>\n<p>- Google the list of the Forbes 400.</p>\n<p>- Go through each of the biographies for people on the list (or the first 200, or the first 100, or whatever is a large enough sample).</p>\n<p>- Write down how they got rich.</p>\n<p>- Summarize the data above: How do most rich people get rich?</p>\n<p>Actually looking at data is simple, easy, and straightforward, and yet almost no one actually does it. Here's another one: Adjusted for inflation, what is the average, long-term appreciation of the stock market? <a href=\"http://stockcharts.com/charts/historical/djia1900.html\">Here</a>'s the historical Dow Jones index, and <a href=\"http://www.westegg.com/inflation/\">here</a>'s an inflation calculator. Try it and see!</p>\n<p>The underlying principle here is very simple: Want to know whether something is true? Go look at the data and see. Look at the numbers. Look at the results. Look at a sample. JFDI.</p>\n<p>For another simple example, one that I haven't done myself: It is a common perception that lottery players are stupid. But is it actually true? Is stupidity what causes people to play the lottery? It's easy enough to find out: look up a bunch of lottery winners, and see how smart they are. What jobs do they work in? What degrees do they have? What about compared with the average American population? What do they have in common?</p>\n<p>There are an infinite number of these sorts of questions. How accurate are food expiration dates? How important is it to wear a helmet on a bike? How likely are STD infections? How many Americans are college graduates? Dropouts? What about high-income Americans?</p>\n<p>Unlike most university science, DIY Science can actually make you happier, right here and now. One particularly useful group of questions, for instance, concerns things that people worry about. How likely are they, really? What are the expected consequences? What does the data say? For example, when I was younger, when I got a cold, I used to worry that it was actually some serious disease. Then, I looked up the numbers, and found out that virtually no one my age (10-25) got sick enough to have a high chance of dying. Most people worry too much - what things do you worry about that make you unhappy? What do the data say about them?</p>\n<p>Or, suppose you want to save money to buy something expensive. The usual way people do this is, they take their income, subtract all of their necessary monthly expenses, and then figure that whatever is left over is how much they can save. Trouble is, people's necessities grow to match whatever their income is, even if their <a href=\"http://www.nytimes.com/2009/02/08/fashion/08halfmill.html\">income is $2,000,000</a>. If you get used to something, you start seeing it as \"necessary\", because you can't imagine life without it. How do you know if you really do need something? Use science! Try, just for a day, not using one thing with those monthly payments attached- electricity, phone, Internet, car, cable TV, satellite radio, what have you.</p>\n<p>Of course, it isn't always easy, because sometimes people try to fool everyone. For instance, intelligence is distributed on a bell curve. Everyone knows that... right? As it turns out, the only reason IQ scores fit a bell curve, is because IQ is <em>defined</em> as a bell-curve-shaped statistic! Now, after the lie has been exposed, come the interesting questions: How is intelligence <em>actually</em> distributed? How could we find out? What measurements could we use?</p>\n<p>Sometimes, questions get so politically loaded that you have to get tricky. To name a perennial favorite: Is global warming happening, and if it is, how much damage will it cause? It doesn't matter how much funding the NSF or some other agency gives this question, because the answers are already <a href=\"/lw/js/the_bottom_line/\">pre-determined</a>; \"yes\" and \"a lot\" if you're a Blue, and \"no\" and \"not much\" if you're a Green. <a href=\"http://www.nationalreview.com/articles/print/257531\">Peter Thiel</a>, SIAI's largest donor, sums it up very nicely:</p>\n<p>\"There&rsquo;s a degree to which it is just a status and political-correctness issue. The debates are for the most part not about the policies or about the ideas, but what is cool, what is trendy. Take something like the climate-change debate. I think it&rsquo;s an important question, and I think it&rsquo;s actually quite hard to figure out what the science is. It might be something for us to worry about. But I think there&rsquo;s actually no debate at all &mdash; there&rsquo;s no attempt to understand the science. It&rsquo;s mostly moral posturing of one form or another.<br /> <br /> Beyond the posturing, it&rsquo;s a form of cowardice that&rsquo;s very much linked to political correctness, where it&rsquo;s not fashionable or not cool to offer dissenting opinions.\"</p>\n<p>So, how do we <em>really</em> find out? Which evidence can we use? Where can we find it?</p>\n<p>In exploring DIY Science, we ought to question <em>everything</em>, even things that we <em>know</em> (or think we know) to be true. \"Common knowledge\" is such a bad guide that false things float around for decades, all the time. Consider Wikipedia's <a href=\"http://en.wikipedia.org/wiki/List_of_common_misconceptions\">List of Common Misconceptions</a>. Reading through the whole thing, how many did you think were true? And these are the small set of things for which we have undeniable proof!</p>\n<p>To name something which I <em>do</em> believe to be true: do men and women have the same average intelligence? They do, but <em>how do we know that</em>? Present studies can't be trusted, because the field is too politicized. You have to <em>also</em> look at pre-1970 studies, which indeed show agreement with modern ones. (Of course, past studies aren't always right, but agreement across many different time periods is fairly strong evidence.)</p>\n<p>Or, to look at the subject of this blog: is rationality an effective means of achieving goals? To what extent? How do we know that? Well, on one side, what statistics I can find show that atheists make more than Christians. But they also show that Jews have higher incomes than atheists. Should we all convert to Judaism? Or, to take historical cases, Franklin was far more rational than average, but Hitler was far less. Clearly, more analysis is needed here.</p>\n<p>One idea might be to look at what top chess players do: chess is a very objective metric, the players all have the same goals (to win the game), and the game is purely about mental decision-making. How rational are Garry Kasparov and Bobby Fisher? What about the top few hundred players worldwide? I don't have any clue what this will find, just a wild guess.&nbsp;</p>\n<p>I say all this on this blog, to some extent, because thinking about the data is not the only component of rationality; in order to have rational beliefs, one must also gather lots of data, and specifically, data about the problem one is trying to solve. No one in ancient Greece, no matter how well they thought, could have a good understanding of particle physics, because they didn't have any data on how particles behaved. Fortunately, with the Internet and online ordering of everything under the sun, data is very easy to collect. So- forward, in the name of Science!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZpG9rheyAkgCoEQea": 1, "fkABsGCJZ6y9qConW": 1, "4kQXps8dYsKJgaayN": 1, "moeYqrcakMgXnQNyF": 1, "32DdRimdM7sB5wmKu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K82evF2iRAiRWwvyn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 75, "baseScore": 84, "extendedScore": null, "score": 0.000157, "legacy": true, "legacyId": "5057", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 84, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 207, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["34XxbRFe54FycoCDw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T06:22:06.488Z", "modifiedAt": null, "url": null, "title": "Bridging Inferential Gaps and Explaining Rationality to Other People", "slug": "bridging-inferential-gaps-and-explaining-rationality-to", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:39.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NQNsiAM2vpjDRfYyp/bridging-inferential-gaps-and-explaining-rationality-to", "pageUrlRelative": "/posts/NQNsiAM2vpjDRfYyp/bridging-inferential-gaps-and-explaining-rationality-to", "linkUrl": "https://www.lesswrong.com/posts/NQNsiAM2vpjDRfYyp/bridging-inferential-gaps-and-explaining-rationality-to", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bridging%20Inferential%20Gaps%20and%20Explaining%20Rationality%20to%20Other%20People&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABridging%20Inferential%20Gaps%20and%20Explaining%20Rationality%20to%20Other%20People%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNQNsiAM2vpjDRfYyp%2Fbridging-inferential-gaps-and-explaining-rationality-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bridging%20Inferential%20Gaps%20and%20Explaining%20Rationality%20to%20Other%20People%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNQNsiAM2vpjDRfYyp%2Fbridging-inferential-gaps-and-explaining-rationality-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNQNsiAM2vpjDRfYyp%2Fbridging-inferential-gaps-and-explaining-rationality-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 895, "htmlBody": "<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; padding: 0.5em; margin: 8px;\">\n<p>This post is going in discussion until I get it edited enough that I feel like its post-worthy, or if it does well.</p>\n<hr />\n<p><strong style=\"font-weight: bold;\">Core Post:</strong></p>\n<p><strong style=\"font-weight: bold;\"></strong><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">Rationality has helped me do a lot of things (in the past year: being elected President of my robotics team, getting a girlfriend, writing good college apps (and getting into a bunch of good schools), etc.), and I feel sort of guilty for not helping other people use it. </span></p>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">I had made progress on a lot of those fronts before, but a bunch of things fell into place in a relatively short period of time after I started trying to optimize them. Some of my friends have easyish problems, but unsolicited risky counterintuitive advice is uncouth and unhelpful.</span></p>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">More pressingly, I want to pass on a lot of rationality knowledge to people I know before I graduate high school. Being in a fairly good Math/Science/Computer Science Magnet Program, I have access to a lot of smart, driven people who have a lot of flexibility in their lives and I think it would be a shame if there were things I could tell them that would make them do a lot better. On top of that, I want to pass on this knowledge within my robotics team so that they continue doing well.</span></p>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px; \">Basically,&nbsp;<strong style=\"font-weight: bold;\">I want to learn how to explain useful rationality concepts to other people in a non-annoying and effective way</strong>. As far as I can tell,&nbsp;<a href=\"/r/discussion/lw/452/suggest_and_vote_posts_we_want_to_read_on_less/3hlp\">many</a>&nbsp;<a href=\"/r/discussion/lw/452/suggest_and_vote_posts_we_want_to_read_on_less/3hre\">people</a>&nbsp;want to do&nbsp;<a href=\"/r/discussion/lw/47y/whats_the_single_best_introduction_to_evolution/\">similar things</a>, and find it difficult to do so. </span></p>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px; \">I suspect that this topic is broad enough that it would be hard for a single person to tackle it in one post. So that people don't need to have enough information for an entire post (which, would be awesome by the way) before they talk about it, here's a thread to respond to.</span></p>\n<p><span style=\"font-size: 11.0pt; line-height: 115%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; color: black; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">I'd particularly like to encourage people who have successfully bridged inferential distances to reply with where people started and how the conversation went. Please. An example:<br /></span></p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p><span style=\"font-size: 11.0pt; line-height: 115%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; color: black; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">In my Origins of Science (basically a philosophy) class, a conversation like this (paraphrased, happened a few days ago) took place. I'm not sure where the other people in the class started, but it got them to the point that they understood how you model reality, but that beliefs are supposed to reflect reality, and you can't just make things up entirely.</span></p>\n<p><span style=\"font-size: 11.0pt; line-height: 115%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; color: black; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">W: \"I feel like if people want to think God exists, then God exists for them, but if they want to ignore him then he won't.\"</span></p>\n<p><span style=\"font-size: 11.0pt; line-height: 115%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; color: black; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">me: \"But that's not how existing works. In our thoughts and opinions, we make a map of how the world exists. But the map is not the territory.\"<br /><br />W: \"But it will still seem real to you...\"</span></p>\n<p><span style=\"font-size: 11.0pt; line-height: 115%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; color: black; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">me: \"Like, you can put whatever you want in your map like dragons or whatever, but that doesn't actually put dragons in the territory. And now its a failure of your map to reflect the territory, not of the territory to reflect your map\"<br /><br />I could have said the last part better, but I definitely remember saying the last sentence.<br /><br />The map vs. territory example seems to be really effective, a few people complimented it (and I admitted that I had read it somewhere else). Not sure how much it propagates into other beliefs, I'll update later with how much it seems to affect later conversations in the class.</span></p>\n</blockquote>\n<div style=\"margin-bottom: 1em;\"><span style=\"font-family: Arial, sans-serif;\"><span style=\"font-size: 15px; line-height: 17px;\"><strong style=\"font-weight: bold;\">Questions:</strong></span></span></div>\n<div style=\"margin-bottom: 1em;\"><span style=\"font-family: Arial, sans-serif;\"><span style=\"font-size: 15px; line-height: 17px;\">What basic rationality ideas are the most helpful to the most people?</span><br /><br /><span style=\"font-size: 15px; line-height: 17px;\">Would it be helpful to try and categorize where people are inferentially? Is it possible?</span></span></div>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px; \"><strong style=\"font-weight: bold;\">Observations:</strong></span></p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\"><a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">Inferential Distance</a>&nbsp;is a big deal. Hence the first part of the title. I was able to explain transhumanism to someone in 3 minutes, and have them totally agree. Other people don't even accept the possibility of AI, let alone that morality can happen when God doesn't exist.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">Its much easier to convince people who know and like you.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">There's a difference between getting someone to ostensibly agree with something, and getting it to propagate through their beliefs.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">People remember rationality best when they benefit from learning it, and it applies to what they're specifically trying to do.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">It's difficult to give someone specific advice and have them pick up on the thought process that you used to come up with it.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">Atheists seem to be pretty inferentially close to Singularity-cluster ideas.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">From&nbsp;<a href=\"/lw/46r/rationality_for_other_people/\">an earlier post</a>&nbsp;I got a bunch of helpful feedback, particularly from&nbsp;<a href=\"/lw/46r/rationality_for_other_people/3j1u\">Nornagest's comment</a>&nbsp;and&nbsp;<a href=\"/lw/46r/rationality_for_other_people/3j35\">TheOtherDave</a>. The short versions:</span> \n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">Asking people to do specific things is creepy, teaching someone is much more effective if you just tell them the facts and let them do whatever they want with it.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">People need specifics to actually do something, and its hard to make them decide to do something substantially different than what they already are doing</span></li>\n</ul>\n</li>\n</ul>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">And from&nbsp;<a href=\"/lw/38x/bridging_inferential_gaps/33a9\">a comment by David Gerard</a>: People need to want to learn/do something, its hard to push them into it.</span></li>\n<li><span style=\"font-family: Arial, sans-serif; font-size: 15px; line-height: 17px;\">A lot of people are already doing useful things (research, building businesses), so it might be more helpful to make a bunch of them better than a few of them do something entirely different.</span></li>\n</ul>\n</div>\n<ul>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NQNsiAM2vpjDRfYyp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "5518", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["k2vtJtQjLCXAdWetH", "kYDzd777ScKzbsTst"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T10:09:12.769Z", "modifiedAt": null, "url": null, "title": "BOOK DRAFT: 'Ethics and Superintelligence' (part 1)", "slug": "book-draft-ethics-and-superintelligence-part-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:33.086Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4gnbMt9TKTjSPRXuT/book-draft-ethics-and-superintelligence-part-1", "pageUrlRelative": "/posts/4gnbMt9TKTjSPRXuT/book-draft-ethics-and-superintelligence-part-1", "linkUrl": "https://www.lesswrong.com/posts/4gnbMt9TKTjSPRXuT/book-draft-ethics-and-superintelligence-part-1", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4gnbMt9TKTjSPRXuT%2Fbook-draft-ethics-and-superintelligence-part-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4gnbMt9TKTjSPRXuT%2Fbook-draft-ethics-and-superintelligence-part-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4gnbMt9TKTjSPRXuT%2Fbook-draft-ethics-and-superintelligence-part-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 735, "htmlBody": "<p>I'm researching and writing a book on meta-ethics and the technological singularity. I plan to post the first draft of the book, in tiny parts, to the Less Wrong discussion area. <strong>Your comments and constructive criticisms are much appreciated</strong>.</p>\n<p>This is <em>not</em>&nbsp;a book for a mainstream audience. Its style is that of contemporary Anglophone philosophy. Compare to, for example, <a href=\"/lw/42l/david_chalmers_the_singularity_a_philosophical/\">Chalmers' survey article on the singularity</a>.</p>\n<p>Bibliographic references are provided <a href=\"http://commonsenseatheism.com/?p=14397\">here</a>.</p>\n<p>Part 1 is below...</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div class=\"WordSection1\">\n<h1>Chapter 1: The technological singularity is coming soon.</h1>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">The Wright Brothers flew their spruce-wood plane for 200 feet in 1903. Only 66 years later, Neil Armstrong walked on the moon, more than 240,000 miles from Earth.</p>\n<p class=\"MsoNormal\">The rapid pace of progress in the physical sciences drives many philosophers to science envy. Philosophers have been researching the core problems of metaphysics, epistemology, and ethics for millennia and not yet come to consensus about them like scientists have for so many core problems in physics, chemistry, and biology.</p>\n<p class=\"MsoNormal\">I won&rsquo;t argue about <em style=\"mso-bidi-font-style: normal;\">why</em> this is so. Instead, I will argue that maintaining philosophy&rsquo;s slow pace and&nbsp;<em style=\"mso-bidi-font-style: normal;\">not</em> solving certain philosophical problems in the next two centuries may lead to the extinction of the human species.</p>\n<p class=\"MsoNormal\">This extinction would result from a &ldquo;technological singularity&rdquo; in which an artificial intelligence (AI) of human-level general intelligence uses its intelligence to improve its own intelligence, which would enable it to improve its intelligence even more, which would lead to an &ldquo;intelligence explosion&rdquo; feedback loop that would give this AI inestimable power to accomplish its goals. If so, then it is critically important to program its goal system wisely. This project could mean the difference between a utopian solar system of unprecedented harmony and happiness, and a solar system in which all available matter is converted into parts for a planet-sized computer built to solve difficult mathematical problems.</p>\n<p class=\"MsoNormal\">The technical challenges of designing the goal system of such a superintelligence are daunting.<a style=\"mso-endnote-id: edn1;\" name=\"_ednref1\" href=\"#_edn1\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: Cambria; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;\uff2d\uff33 \u660e\u671d&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[1]</span></span><!--[endif]--></span></span></a> But even if we can solve those problems, the question of <em style=\"mso-bidi-font-style: normal;\">which</em> goal system to give the superintelligence remains. It is a question of philosophy; it is a question of ethics.</p>\n<p class=\"MsoNormal\">Philosophy has impacted billions of humans through religion, culture, and government. But now the stakes are even higher. When the technological singularity occurs, the philosophy behind the goal system of a superintelligent machine will determine the fate of the species, the solar system, and perhaps the galaxy.</p>\n<p class=\"MsoNormal\">***</p>\n<p class=\"MsoNormal\">Now that I have laid my positions on the table, I must argue for them. In this chapter I argue that the technological singularity is likely to occur within the next 200 years unless a worldwide catastrophe drastically impedes scientific progress. In chapter two I survey the philosophical problems involved in designing the goal system of a singular superintelligence, which I call the &ldquo;singleton.&rdquo;</p>\n<p class=\"MsoNormal\">In chapter three I show how the singleton will produce very different future worlds depending on which normative theory is used to design its goal system. In chapter four I describe what is perhaps the most developed plan for the design of the singleton&rsquo;s goal system: Eliezer Yudkowsky&rsquo;s &ldquo;Coherent Extrapolated Volition.&rdquo; In chapter five, I present some objections to Coherent Extrapolated Volition.</p>\n<p class=\"MsoNormal\">In chapter six I argue that we cannot decide how to design the singleton&rsquo;s goal system without considering meta-ethics, because normative theory depends on meta-ethics. In chapter seven I argue that we should invest little effort in meta-ethical theories that do not fit well with our emerging reductionist picture of the world, just as we quickly abandon scientific theories that don&rsquo;t fit the available scientific data. I also specify several meta-ethical positions that I think are good candidates for abandonment.</p>\n<p class=\"MsoNormal\">But the looming problem of the technological singularity requires us to have a positive theory, too. In chapter eight I propose some meta-ethical claims about which I think naturalists should come to agree. In chapter nine I consider the implications of these plausible meta-ethical claims for the design of the singleton&rsquo;s goal system.</p>\n<p class=\"MsoNormal\">&nbsp;***</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n</div>\n<p><span style=\"font-size: 12.0pt; font-family: Cambria; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;\uff2d\uff33 \u660e\u671d&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\"><br style=\"page-break-before: always; mso-break-type: section-break;\" /> </span></p>\n<div style=\"mso-element: endnote-list;\"><!--[if !supportEndnotes]--><br /> \n<hr size=\"1\" />\n<!--[endif]-->\n<div id=\"edn1\" style=\"mso-element: endnote;\">\n<p class=\"MsoEndnoteText\"><a style=\"mso-endnote-id: edn1;\" name=\"_edn1\" href=\"#_ednref1\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: Cambria; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;\uff2d\uff33 \u660e\u671d&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[1]</span></span><!--[endif]--></span></span></a> These technical challenges are discussed in the literature on artificial agents in general and Artificial General Intelligence (AGI) in particular. Russell and Norvig (2009) provide a good overview of the challenges involved in the design of artificial agents. Goertzel and Pennachin (2010) provide a collection of recent papers on the challenges of AGI. Yudkowsky (2010) proposes a new extension of causal decision theory to suit the needs of a self-modifying AI. Yudkowsky (2001) discusses other technical (and philosophical) problems related to designing the goal system of a superintelligence.</p>\n</div>\n</div>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4gnbMt9TKTjSPRXuT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 18, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "5520", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 112, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Sh4HPbqRDJsbB9ENK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T13:56:33.060Z", "modifiedAt": null, "url": null, "title": "Exercise and motivation", "slug": "exercise-and-motivation", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.837Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NbL7M2cnrccHPQewo/exercise-and-motivation", "pageUrlRelative": "/posts/NbL7M2cnrccHPQewo/exercise-and-motivation", "linkUrl": "https://www.lesswrong.com/posts/NbL7M2cnrccHPQewo/exercise-and-motivation", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Exercise%20and%20motivation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExercise%20and%20motivation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNbL7M2cnrccHPQewo%2Fexercise-and-motivation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Exercise%20and%20motivation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNbL7M2cnrccHPQewo%2Fexercise-and-motivation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNbL7M2cnrccHPQewo%2Fexercise-and-motivation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 542, "htmlBody": "<p>I realized very recently that what gets me to exercise is whether it makes moving more of a pleasure, and, of course, if it's a pleasure in itself.</p>\n<p>Any hint of \"prove you're a worthwhile person by how much you can make yourself endure\" or \"not being fat is the most important thing in the world\"[1] is apt to be demotivating.</p>\n<p>It might be a good thing if being able to react well in emergencies[2] were a strong motivation for me, but the truth is, I've had a pretty easy life, and the only thing that motivates me in that range is wanting to be able to walk safely on ice.</p>\n<p>So, what tends to increase your pleasure in movement? Do you know of any systems organized around enjoyment?</p>\n<p>[1] I know they never say that, but if an exercise system has fat loss as the only or first reason listed for engaging in it, that's how I interpret it.</p>\n<p>[2] <a href=\"http://physicalliving.com/interview-with-scott-sonnon-about-the-tacfit-tactical-fitness-system/\">This interview</a> with Scott Sonnon is absolutely the most rational thing I've seen on the subject. He's focused very hard on doing things that work rather than things that seem as though they might indicate that something will work. And his emphasis is that the best exercise program is one that you will keep doing, both because you're willing to stay with it and because it doesn't hurt you is what inspired this post.</p>\n<p>This was posted <a href=\"http://nancylebov.livejournal.com/469089.html?nc=8\">here</a> and <a href=\"http://nancylebov.dreamwidth.org/465764.html\">here</a>-- there are good comments in both places. It's suboptimal to have more than one comment stream, but I've got friends who will only read at one of the sites, and I'd expect that you guys are more likely to comment here than at either of those.</p>\n<p>And also, what are your actual motivations? Was it hard to discover them, and if so, did it help when you did?</p>\n<p>A follow-up: I've been doing <a href=\"http://en.wikipedia.org/wiki/Five_Tibetan_Rites\">The Five Tibetans</a> (a cross between yoga and calisthenics) for a while, and I've had a hard time with the <a href=\"http://www.youtube.com/watch?v=HjtslbrFbLY&amp;feature=related\">fourth one</a>. My arms are relatively short and my shoulders and chest are tight.</p>\n<p>I tried taking pleasure seriously when I did it, and that, combined with \"relax, breathe, feel the earth, do nothing extra\" from <a href=\"http://www.amazon.com/Restore-Yourself-Tai-Chi-Becoming/dp/0806990457\">Restore Yourself with Tai Chi</a> made a huge fast improvement. Instead of struggling with the move, I was able to get a significant amount of weight on to my feet and feel a coherent stretch across the front of my body instead of separate parts making unpleasant efforts.</p>\n<p>My reaction to pain was better-- I could use it as a signal to change what I was doing instead of feeling as though the universe was out to get me or as though it was a hard problem that I might gradually be able to solve.</p>\n<p>On the other hand, it's been a week or so and I haven't done the Tibetans since-- I'm up against pretty serious akrasia. Finding one's actual motivations isn't a complete solution if doing things is too associated with anxiety.</p>\n<p>Note: this was after not having done the Tibetans for weeks, so it wasn't as though paying attention to pleasure wrecked a steady habit.</p>\n<p>If you want to give advice about this, I'd appreciate it if you'd talk about what's worked for you without assuming that it will work for me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NbL7M2cnrccHPQewo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.786833631661418e-07, "legacy": true, "legacyId": "5521", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T18:42:18.958Z", "modifiedAt": null, "url": null, "title": "Farmington Hills, MI Less Wrong meetup: Sunday, February 20", "slug": "farmington-hills-mi-less-wrong-meetup-sunday-february-20", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:38.941Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4W7H36ECC5YzkuzxA/farmington-hills-mi-less-wrong-meetup-sunday-february-20", "pageUrlRelative": "/posts/4W7H36ECC5YzkuzxA/farmington-hills-mi-less-wrong-meetup-sunday-february-20", "linkUrl": "https://www.lesswrong.com/posts/4W7H36ECC5YzkuzxA/farmington-hills-mi-less-wrong-meetup-sunday-february-20", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Farmington%20Hills%2C%20MI%20Less%20Wrong%20meetup%3A%20Sunday%2C%20February%2020&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFarmington%20Hills%2C%20MI%20Less%20Wrong%20meetup%3A%20Sunday%2C%20February%2020%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4W7H36ECC5YzkuzxA%2Ffarmington-hills-mi-less-wrong-meetup-sunday-february-20%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Farmington%20Hills%2C%20MI%20Less%20Wrong%20meetup%3A%20Sunday%2C%20February%2020%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4W7H36ECC5YzkuzxA%2Ffarmington-hills-mi-less-wrong-meetup-sunday-february-20", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4W7H36ECC5YzkuzxA%2Ffarmington-hills-mi-less-wrong-meetup-sunday-february-20", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p><a id=\"more\"></a>Where: <a href=\"http://maps.google.com/maps/place?cid=16049241279794396088&amp;q=udipi+farmington+hills&amp;hl=en&amp;gl=us&amp;sll=42.51162,-83.35924&amp;sspn=0.006295,0.006295&amp;ie=UTF8&amp;ll=42.516603,-83.36915&amp;spn=0,0&amp;t=h&amp;z=16\">Udipi Restaurant</a>, on Orchard Lake road, between 12 and 13 mile road (much closer to 13 mile)</p>\n<p>When: Sunday, February 20, 12:30pm (This can be moved a bit later or such if that's better for anyone)</p>\n<p>Unless anyone who would otherwise come except for the date/time being bad, that's what I'm going to go with.</p>\n<p>If you plan on showing up, go ahead and comment here so I'll have an idea about that. (Although if you don't comment and you find that you do still want to show up, don't feel that your not having commented is a reason not to show up.)</p>\n<p>EDIT: From the <a href=\"/r/discussion/lw/46u/interest_in_lw_meetup_in_farmington_hills_michigan/\">discussion thread</a>, some people in Ann Arbor would come if they had a ride. So if anyone is coming from Ann Arbor and is willing to give a ride, please mention that. Thanks.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4W7H36ECC5YzkuzxA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 6.787589836866314e-07, "legacy": true, "legacyId": "5522", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["q52YmN6ij7r4n77RX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T22:52:44.211Z", "modifiedAt": null, "url": null, "title": "Social Necessity of Drinking", "slug": "social-necessity-of-drinking", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:05.715Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WXrqtpkETcyy9tKny/social-necessity-of-drinking", "pageUrlRelative": "/posts/WXrqtpkETcyy9tKny/social-necessity-of-drinking", "linkUrl": "https://www.lesswrong.com/posts/WXrqtpkETcyy9tKny/social-necessity-of-drinking", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Social%20Necessity%20of%20Drinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASocial%20Necessity%20of%20Drinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXrqtpkETcyy9tKny%2Fsocial-necessity-of-drinking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Social%20Necessity%20of%20Drinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXrqtpkETcyy9tKny%2Fsocial-necessity-of-drinking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXrqtpkETcyy9tKny%2Fsocial-necessity-of-drinking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 339, "htmlBody": "<p>It's been over a year since I graduated from college, but only recently have I felt like I'm officially entering the \"adult world.\" Navigating the social arenas of the adult world requires the same basic skillsets as the college world, but a lot of the rules are different and I'm struggling to learn them. Among them is how to drink socially.</p>\n<p>As a general rule, I don't drink. I don't like the taste of alcohol. I don't like paying the exorbinant prices that alcohol costs. I don't like the feeling of my brain slowing down and making it harder to string sentences together. I don't mind the physical disorientation - that part's pretty fun. But that part also seems to be slightly frowned upon in an \"adult\" setting. I'm not opposed to it for any particular moral reasons.</p>\n<p>When I do drink, I prefer to get it over with as fast as possible, whether I'm officially drinking a \"shot\" or not. In college that at least had a sort of \"daring\" quality that was respected. But it's pretty obviously taboo at classy cocktail parties and even somewhat taboo at \"casual adult\" parties.</p>\n<p>So there's a few separate questions I have:</p>\n<p>1) Are there any good, cached buzzword phrases I can use that'll make it socially acceptable to not drink? \"I just don't like it\" seems to draw disdainful stares, and while I haven't tried it I get the sense that saying I'm morally opposed to it would make me look even more like a stick in the mud. Saying \"it's ridiculously expensive\" makes me look like a cheapskate.&nbsp;</p>\n<p>2) If I must drink socially, is there a breakdown of the general social conventions I should be aware of so I don't need to have them pointed out to me over the course of the next few years?</p>\n<p>3) Is there any particularly interesting analysis of *why* drinking is so important to social interaction? Knowing the underlying causes might at least give me some better appreciation for why I have to learn this other than \"because!\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WXrqtpkETcyy9tKny", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 20, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "5523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-13T23:50:50.941Z", "modifiedAt": null, "url": null, "title": "Open Thread: Mathematics", "slug": "open-thread-mathematics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.963Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bentarm", "createdAt": "2009-03-05T17:59:17.163Z", "isAdmin": false, "displayName": "bentarm"}, "userId": "xdmTZWK4DzchxkyQC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/evw4oy3vGf4GN7MWW/open-thread-mathematics", "pageUrlRelative": "/posts/evw4oy3vGf4GN7MWW/open-thread-mathematics", "linkUrl": "https://www.lesswrong.com/posts/evw4oy3vGf4GN7MWW/open-thread-mathematics", "postedAtFormatted": "Sunday, February 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20Mathematics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20Mathematics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fevw4oy3vGf4GN7MWW%2Fopen-thread-mathematics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20Mathematics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fevw4oy3vGf4GN7MWW%2Fopen-thread-mathematics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fevw4oy3vGf4GN7MWW%2Fopen-thread-mathematics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<p>In Luke's <a href=\"/r/discussion/lw/452/suggest_and_vote_posts_we_want_to_read_on_less/\">recent post</a> on what sort of posts we would like to see more of, one suggestion was \"Open Thread: Math\". This suggestion has been voted up by (at least) 12 people. Since it's going to take me less than 2 minutes to type this post, I figured I might as well just go ahead and post the thread, rather than vote up the suggestion.</p>\n<p>So, this is an open thread on mathematics. As things stand, I have no idea what the rules should be (I don't know what the people who voted up the post suggestion expected the rules to be), but I guess the general principle should be that we have maths questions which are vaguely related to LW-type ideas, as there are plenty of <a href=\"http://nrich.maths.org/discus/messages/board-topics.html\">more</a> <a href=\"http://math.stackexchange.com/\">appropriate</a> <a href=\"http://mathoverflow.net\">fora</a> for general mathematical discussion already out there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "evw4oy3vGf4GN7MWW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 6.788406459512675e-07, "legacy": true, "legacyId": "5524", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Skmn6voCTw3ozMRx5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T01:16:40.615Z", "modifiedAt": null, "url": null, "title": "Why Do We Engage in Moral Simplification?", "slug": "why-do-we-engage-in-moral-simplification", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:38.699Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uc9JTYDCjEmLyb6cH/why-do-we-engage-in-moral-simplification", "pageUrlRelative": "/posts/uc9JTYDCjEmLyb6cH/why-do-we-engage-in-moral-simplification", "linkUrl": "https://www.lesswrong.com/posts/uc9JTYDCjEmLyb6cH/why-do-we-engage-in-moral-simplification", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20Do%20We%20Engage%20in%20Moral%20Simplification%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20Do%20We%20Engage%20in%20Moral%20Simplification%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuc9JTYDCjEmLyb6cH%2Fwhy-do-we-engage-in-moral-simplification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20Do%20We%20Engage%20in%20Moral%20Simplification%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuc9JTYDCjEmLyb6cH%2Fwhy-do-we-engage-in-moral-simplification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuc9JTYDCjEmLyb6cH%2Fwhy-do-we-engage-in-moral-simplification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 534, "htmlBody": "<p class=\"MsoNormal\">It appears to me that much of human moral philosophical reasoning consists of trying to find a small set of principles that fit one&rsquo;s strongest moral intuitions, and then explaining away or ignoring the intuitions that do not fit those principles. For those who find such moral systems attractive, they seem to have the power of actually reducing the strength of, or totally eliminating those conflicting intuitions.</p>\n<p class=\"MsoNormal\">In <a href=\"/lw/lq/fake_utility_functions/\">Fake Utility Functions</a>, Eliezer described an extreme version of this, the One Great Moral Principle, or Amazingly Simple Utility Function, and suggested that he was partly responsible for this phenomenon by using the word &ldquo;supergoal&rdquo; while describing Friendly AI. But it seems to me this kind of simplification-as-moral-philosophy has a history much older than FAI.</p>\n<p class=\"MsoNormal\">For example, hedonism holds that morality consists of maximizing pleasure and minimizing pain, utilitarianism holds that everyone should have equal weight in one&rsquo;s morality, and egoism holds that moralist consists of satisfying one&rsquo;s self-interest. None of these fits <em>all</em> of my moral intuitions, but each does explain many of them. The puzzle this post presents is: why do we have a tendency to accept moral philosophies that do not fit all of our existing values? Why do we find it natural or attractive to simplify our moral intuitions?</p>\n<p class=\"MsoNormal\">Here&rsquo;s my idea: we have a heuristic that in effect says, if many related beliefs or intuitions all fit a certain pattern or logical structure, but a few don&rsquo;t, the ones that don&rsquo;t fit are probably caused by cognitive errors and should be dropped and regenerated from the underlying pattern or structure.</p>\n<p class=\"MsoNormal\">As an example where this heuristic is working as intended, consider that your intuitive estimates of the relative sizes of various geometric figures probably roughly fit the mathematical concept of &ldquo;area&rdquo;, in the sense that if one figure has a greater area than another, you&rsquo;re likely to intuitively judge that it&rsquo;s bigger than the other. If someone points out this structure in your intuitions, and then you notice that in a few cases your intuitions differ from the math, you&rsquo;re likely to find that a good reason to change those intuitions.</p>\n<p>I think this idea can explain why different people end up believing in different moral philosophies. For example, many members of this community are divided along utilitarian/egoist lines. Why should that be the case? The theory I proposed suggests two possible answers:</p>\n<ol>\n<li>They started off with somewhat different intuitions (or the same intuitions with different relative strengths), so a moral system that fits one person&rsquo;s intuitions relatively well might fit anther&rsquo;s relatively badly.</li>\n<li>They had the same intuitions to start with, but encountered the moral philosophies in different orders. If each person accepts the first moral system that fits their intuitions &ldquo;well enough&rdquo;, and more than one fits &ldquo;well enough&rdquo;, then they&rsquo;ll accept the first such moral system, which changes their intuitions, causing the rest to be rejected.</li>\n</ol>\n<p class=\"MsoNormal\">I think it&rsquo;s likely that both of these are factors that contribute to the apparent divergence in human moral reasoning. This seems to be another piece of bad news for the prospect of CEV, unless there are stronger converging influences in human moral reasoning that (in the limit of reflective equilibrium) can counteract these diverging tendencies.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb186": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uc9JTYDCjEmLyb6cH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 31, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "5527", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NnohDYHNnKDtbiMyp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T05:56:23.842Z", "modifiedAt": null, "url": null, "title": "Against Desirism", "slug": "against-desirism-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "endoself", "createdAt": "2011-01-02T09:26:40.389Z", "isAdmin": false, "displayName": "endoself"}, "userId": "e4JPxEMj36oRwTALQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sf9TXnBjiP5WaN9XF/against-desirism-0", "pageUrlRelative": "/posts/sf9TXnBjiP5WaN9XF/against-desirism-0", "linkUrl": "https://www.lesswrong.com/posts/sf9TXnBjiP5WaN9XF/against-desirism-0", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Against%20Desirism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAgainst%20Desirism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsf9TXnBjiP5WaN9XF%2Fagainst-desirism-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Against%20Desirism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsf9TXnBjiP5WaN9XF%2Fagainst-desirism-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsf9TXnBjiP5WaN9XF%2Fagainst-desirism-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": null, "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sf9TXnBjiP5WaN9XF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "5540", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": null, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T11:49:40.201Z", "modifiedAt": null, "url": null, "title": "Meetup posts as discussion threads, please", "slug": "meetup-posts-as-discussion-threads-please", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.810Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonii", "createdAt": "2009-07-15T05:24:30.383Z", "isAdmin": false, "displayName": "Jonii"}, "userId": "xa8EysPtEYKcEDeNg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C4eD2jWzrJ7rd3SNu/meetup-posts-as-discussion-threads-please", "pageUrlRelative": "/posts/C4eD2jWzrJ7rd3SNu/meetup-posts-as-discussion-threads-please", "linkUrl": "https://www.lesswrong.com/posts/C4eD2jWzrJ7rd3SNu/meetup-posts-as-discussion-threads-please", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20posts%20as%20discussion%20threads%2C%20please&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20posts%20as%20discussion%20threads%2C%20please%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC4eD2jWzrJ7rd3SNu%2Fmeetup-posts-as-discussion-threads-please%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20posts%20as%20discussion%20threads%2C%20please%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC4eD2jWzrJ7rd3SNu%2Fmeetup-posts-as-discussion-threads-please", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC4eD2jWzrJ7rd3SNu%2Fmeetup-posts-as-discussion-threads-please", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<p>As of now, 4 of 10 newest promoted posts are about meetups, as well 4 of 10 newest posts overall. For casual readers like me, having frontpage flooded by this much irrelevant information, _especially promoted-section_, seems really, really discouraging. LW has tendency to contain too much useless meta-discussion compared to the actual rationality-related one, but having frontpage flooded by meta-discussion like this seems rather unbeliveable. Please, let's try to keep at least the promoted-section rationality-related.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C4eD2jWzrJ7rd3SNu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 39, "extendedScore": null, "score": 6.790308383885182e-07, "legacy": true, "legacyId": "5549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T14:56:17.627Z", "modifiedAt": null, "url": null, "title": "Peter Thiel backs \"AI startup\" [link]", "slug": "peter-thiel-backs-ai-startup-link", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6RCYLQmaTmZz3hcL6/peter-thiel-backs-ai-startup-link", "pageUrlRelative": "/posts/6RCYLQmaTmZz3hcL6/peter-thiel-backs-ai-startup-link", "linkUrl": "https://www.lesswrong.com/posts/6RCYLQmaTmZz3hcL6/peter-thiel-backs-ai-startup-link", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Peter%20Thiel%20backs%20%22AI%20startup%22%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APeter%20Thiel%20backs%20%22AI%20startup%22%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6RCYLQmaTmZz3hcL6%2Fpeter-thiel-backs-ai-startup-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Peter%20Thiel%20backs%20%22AI%20startup%22%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6RCYLQmaTmZz3hcL6%2Fpeter-thiel-backs-ai-startup-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6RCYLQmaTmZz3hcL6%2Fpeter-thiel-backs-ai-startup-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://venturebeat.com/2011/02/07/vicarious-systems-funding-facebook/\">http://venturebeat.com/2011/02/07/vicarious-systems-funding-facebook/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6RCYLQmaTmZz3hcL6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 6.7908039854547e-07, "legacy": true, "legacyId": "5550", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T15:28:39.168Z", "modifiedAt": null, "url": null, "title": "IBM's \"Watson\" program to compete against \"Jeopardy\" champions tonight", "slug": "ibm-s-watson-program-to-compete-against-jeopardy-champions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.449Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NihilCredo", "createdAt": "2009-04-22T23:40:56.227Z", "isAdmin": false, "displayName": "NihilCredo"}, "userId": "W6f2cwKiKSroig5kb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8dCfXYAaC5NYbPaBR/ibm-s-watson-program-to-compete-against-jeopardy-champions", "pageUrlRelative": "/posts/8dCfXYAaC5NYbPaBR/ibm-s-watson-program-to-compete-against-jeopardy-champions", "linkUrl": "https://www.lesswrong.com/posts/8dCfXYAaC5NYbPaBR/ibm-s-watson-program-to-compete-against-jeopardy-champions", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20IBM's%20%22Watson%22%20program%20to%20compete%20against%20%22Jeopardy%22%20champions%20tonight&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIBM's%20%22Watson%22%20program%20to%20compete%20against%20%22Jeopardy%22%20champions%20tonight%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dCfXYAaC5NYbPaBR%2Fibm-s-watson-program-to-compete-against-jeopardy-champions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=IBM's%20%22Watson%22%20program%20to%20compete%20against%20%22Jeopardy%22%20champions%20tonight%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dCfXYAaC5NYbPaBR%2Fibm-s-watson-program-to-compete-against-jeopardy-champions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dCfXYAaC5NYbPaBR%2Fibm-s-watson-program-to-compete-against-jeopardy-champions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>It was mentioned before on LessWrong, but I feel people might appreciate a reminder:</p>\n<p>http://www-03.ibm.com/innovation/us/watson/what-is-watson/countdown-to-jeopardy.html</p>\n<p>It's a bit of a cheesy PR thing - I'd be a lot more interested if they connected the program on the Internet and allowed anyone to try and ask them general questions, rather than mixing the program with voice recognition and (heh) buzzer-pushing. Trivia tests are also probably one of the easier challenges to deal with, since keyword filtering alone is very efficient in narrowing down the candidate space.</p>\n<p>Still, I'm going to watch it if I can: if anybody knows of a streaming link that is accessible to non-US viewers, that would be appreciated.</p>\n<p>(Silly aside: is anyone else annoyed by how \"Jeopardy\" pretends to invert the traditional question-answer format, while what it does is simply moving the \"what is\" from the former to the latter, even if the result makes no sense? I suppose to US people this is a rather old complaint, but I learnt about the show today and I'm rather bugged by this feature.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8dCfXYAaC5NYbPaBR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 12, "extendedScore": null, "score": 6.790889696587275e-07, "legacy": true, "legacyId": "5551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T15:30:14.832Z", "modifiedAt": null, "url": null, "title": "[COMIC] Anthropic dungeon crawling", "slug": "comic-anthropic-dungeon-crawling", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.312Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NCwy6wssHJ8T2BMW6/comic-anthropic-dungeon-crawling", "pageUrlRelative": "/posts/NCwy6wssHJ8T2BMW6/comic-anthropic-dungeon-crawling", "linkUrl": "https://www.lesswrong.com/posts/NCwy6wssHJ8T2BMW6/comic-anthropic-dungeon-crawling", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BCOMIC%5D%20Anthropic%20dungeon%20crawling&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BCOMIC%5D%20Anthropic%20dungeon%20crawling%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCwy6wssHJ8T2BMW6%2Fcomic-anthropic-dungeon-crawling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BCOMIC%5D%20Anthropic%20dungeon%20crawling%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCwy6wssHJ8T2BMW6%2Fcomic-anthropic-dungeon-crawling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCwy6wssHJ8T2BMW6%2Fcomic-anthropic-dungeon-crawling", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 6, "htmlBody": "<p>The <a href=\"http://www.goblinscomic.com/02112011-4/\">current Goblins Comic</a> is relevant.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NCwy6wssHJ8T2BMW6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 3, "extendedScore": null, "score": 6.790893919726856e-07, "legacy": true, "legacyId": "5552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T18:27:47.170Z", "modifiedAt": null, "url": null, "title": "Algorithms as Case Studies in Rationality", "slug": "algorithms-as-case-studies-in-rationality", "viewCount": null, "lastCommentedAt": "2018-03-28T16:18:47.694Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "abramdemski", "createdAt": "2009-03-12T06:07:25.510Z", "isAdmin": false, "displayName": "abramdemski"}, "userId": "Q7NW4XaWQmfPfdcFj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q5w2SoR6NetZMxQco/algorithms-as-case-studies-in-rationality", "pageUrlRelative": "/posts/q5w2SoR6NetZMxQco/algorithms-as-case-studies-in-rationality", "linkUrl": "https://www.lesswrong.com/posts/q5w2SoR6NetZMxQco/algorithms-as-case-studies-in-rationality", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Algorithms%20as%20Case%20Studies%20in%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAlgorithms%20as%20Case%20Studies%20in%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq5w2SoR6NetZMxQco%2Falgorithms-as-case-studies-in-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Algorithms%20as%20Case%20Studies%20in%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq5w2SoR6NetZMxQco%2Falgorithms-as-case-studies-in-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq5w2SoR6NetZMxQco%2Falgorithms-as-case-studies-in-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1926, "htmlBody": "<p>This post springs out of a very long line of thought, which I will only summarise small parts of.</p>\n<p>It began with the puzzling realisation that the algorithm which computers use to perform symbolic integration is <em>radically</em> different from the guess-and-check method taught in schools. My first reaction was, why are we not taught the systematic way of doing it? This is true for other areas of mathematics as well. In a few cases, such as solving quadratic equations or systems of linear equations, students are eventually taught the fast way. However, in many cases, the existence of an algorithm is not even mentioned.</p>\n<p>My point, however, is not to criticise the educational practice; in fact, I agree with the idea of teaching mathematics as an exploration of ideas rather than an application of formulaic solution methods. Rather, I would like to encourage people to eventually learn the algorithms, and try to apply them. A good algorithm is a study in rational behaviour, and I think we can take home a lesson from each.</p>\n<p>I'll just give two examples which I find particularly fascinating: Knuth-Bendix completion and the summary-product algorithm. The first is most relevant to fast mathematical reasoning. The second is relevant to studying the reasonableness of fast-and-messy probabilistic reasoning, the way humans do it.</p>\n<h1><a id=\"more\"></a>Knuth-Bendix Completion</h1>\n<p><a href=\"http://mathworld.wolfram.com/Knuth-BendixCompletionAlgorithm.html\">Knuth-Bendix completion</a> (\"K-B\" from now on) is a fascinating formalisation of the mathematical idea of simplification. Everyone should recognise the phrase \"simplify your answer\" from high school homework assignments. I never suspected that simplification could be a really powerful method for mathematical reasoning.</p>\n<p>K-B is a method for reasoning about equality. Equality is one of the simplest relationships we can have between two things, yet the naive way of reasoning about it results in an explosion of possible inferences. If there are N things in our universe, there are N<sup>2</sup> equality statements which may be true or false. We can substitute equals for equals all day and get nowhere. So why does it seems like such a simple relation? I think the K-B algorithm gives a good answer to that.</p>\n<p>We start with the basic axioms for the domain we are reasoning about. The domain consists of a set of expressions, some of which are equal to others. The axioms provide some general equalities; for example, they might be the trigonometric identities, if we are reasoning about trigonometric expressions.</p>\n<p><strong>First</strong>, we decide on a relatively arbitrary ordering of \"simplicity\" over the expressions we're using. Practical considerations and personal preferences will go into this, but for the algorithm itself, there are only a few requirements: it should be a well-ordering (so any two expressions are comparable, and there are no infinitely descending chains), and it should be consistent in the sense that if we replace a sub-expression with a simpler sub-expression, the whole expression gets simpler.</p>\n<p><strong>Second</strong>, we take the starting set of identities, and now treat them as rewrite rules: we judge which direction goes from complex to simple and we <em>only</em> apply them in that direction. Since expressions can only get simpler, we now know that we won't just keep producing equality statements endlessly without getting where we want to go.</p>\n<p>Unfortunately, we lose some information by just taking one side of the equality. The truth is, it's sometimes necessary to alter an expression in a way which at first makes it more complicated, to allow application of another rule which eventually gets us to a simpler form.</p>\n<p>The genius of K-B is to find these situations, referred to as <em>critical pairs</em>, and add new simplification rules which abbreviate such steps: <strong>Third</strong>, look for critical pairs and add the necessary rules. (I won't try to give the exact statement of this step; I refer the reader again to the <a href=\"http://mathworld.wolfram.com/Knuth-BendixCompletionAlgorithm.html\">Wolfram article</a>. [Edit: Or the <a href=\"http://en.wikipedia.org/wiki/Knuth%E2%80%93Bendix_completion_algorithm\">Wikipedia article</a>.]) This step is repeated until the set of rules is complete. (It <em>will</em> sometimes happen that completion is impossible, sadly.)</p>\n<p>Once the rules are complete, we can reason purely by simplification. The procedure \"simplify\" is embodied by looking through our list of rules and applying them in the simplifying direction, until we can't find one that applies anymore. The result of simplification is referred to as the <em>normal form</em> of an expression. We can test whether two expressions are equal by putting them in normal form: if the two are equal, they will have the same normal form; if they are not equal, they won't.</p>\n<p>How can this be applied to life? Well, I admit that this one only applies if you do fairly advanced math on a regular basis (though, since I'm writing for rationalists, perhaps you'll be sympathetic if I encourage you to learn more mathematics and to apply it to your life!). In my experience, the K-B algorithm matches the behaviour of sophisticated mathematical reasoning fairly well; people will have a preferred way of simplifying different sorts of expressions, and the interesting theorems correspond to new simplifications which can only be proved by initially reasoning in a direction which looks more complex.</p>\n<p>The second algorithm I'll review is more applicable to everyday situations.</p>\n<h1>Summary-Product</h1>\n<p><a href=\"http://www.math.kth.se/~tjtkoski/factorgraphs.pdf\">Summary-product</a> is a recent algorithm, but one with deep roots. The interesting thing about this algorithm is that it is a general case of dozens of the most important algorithms in different specific areas. The PDF I linked to is a good introduction to this aspect of the algorithm, and I encourage readers to check it out; for my overview, however, I'll only look at the special case which is known as the belief propagation algorithm.<br /><br />Belief propagation is a way of reasoning about probabilities in a tractable way.<br /><br />First, we need to factor our beliefs into a large number of local belief functions, which deal only with a few statements. These represent local probabilistic dependencies between facts; perhaps conditional probabilities (in what's called a Bayesian Network) or just weights which contribute to probabilities (in what's called Markov Networks). What's important is that if we multiplied all the local functions together, we would get a coherent probability distribution.<br /><br />Next, we take stock of the evidence. This gives fixed beliefs to some of the variables.<br /><br />What we want to find now are beliefs for the other variables, referred to as marginal probability distributions. The naive way of finding these is to sum over the entire state-space. For N unobserved variables, we have an N-dimensional state-space; we want to sum over every variable but the one which we're calculating a belief for. If every dimension is of size v, we have v<sup>N</sup> entries to sum up.<br /><br />The idea which leads to the belief propagation algorithm is that we can do better by using the factorisation, thanks to the distributive law: we push the sums as far in as we can, so that whenever possible, we sum over a dimension before we multiply. If the dependencies are treelike, this will give us a calculation which takes time proportional in N, rather than v<sup>N</sup>; a huge gain.<br /><br />Turning this into a local propagation algorithm gives us rules for updating a belief in relation to its neighbours. This has two advantages.<br /><br />First, it happens that we can calculate a belief for <em>all</em> of the variables in just twice the time that it takes to calculate the belief for the one; that is, 2N time. Why? Computing the belief function for one variable amounts to propagation starting at the far edges of the network and heading towards that variable. This loads the network with most of the information it needs. We can finish off the computation by simply propagating in the reverse direction, away from that variable; this spreads the evidence all around the network like jelly on toast, completing the marginalisation of every variable in 2N time.<br /><br />Second, a surprising feature of the propagation algorithm is that it gives good approximate results for non-treelike factorisations. This is like saying that we can push in sums even when the distributive law doesn't hold! Rather than 2N propagations, we just keep propagating until our beliefs converge to stable values (or until we're fed up with waiting). In many situations, this will still converge to exact results or useful estimates. This makes belief propagation a reasonable candidate for general inference.<br /><br />I think there are many lessons for rationality hidden in the details of the belief propagation algorithm. In fact, since belief propagation is a core Bayesian activity, there are already posts here dealing with some of the important lessons. I'll just mention one which I find quite striking, personally.<br /><br />A naive method of belief propagation might update the belief of a variable based on the raw estimated marginal which the neighbour currently has. If two neighbouring beliefs X and Y imply each other with high probability, though, we'd run into trouble: suppose some evidence raises our belief in X. Then we can propagate this to Y, raising our belief there. But then we notice that once again, a neighbour of X has changed, and we can re-update X; performing belief propagation raises our belief in X once more. We'd go back and forth like this until X and Y lock in with probability indistinguishable from 1.<br /><br />The <em>actual</em> rules of belief propagation stop this from happening with the idea of a <em>directional</em> message. The message which X sends to Y is the belief we compute for X with all the evidence <em>except</em> the evidence coming from Y. In general, the belief which gets sent in a particular direction uses all the evidence except the evidence coming back that same direction.<br /><br />This prevents circular reasoning. For all the the talk about the fallacy of circular reasoning, classical logic does not really have a good treatment of it. For a statement A, it's perfectly valid to prove A from an assumption of A in classical logic; in fact we can prove A-&gt;A for any proposition (where \"-&gt;\" is material implication)! I think it's not until we think about tractable probabilistic reasoning that we really get a good account of what's wrong with circular reasoning: it makes us count the same evidence more than once.<br /><br />Next time you're talking with someone, try to keep track of the directionality of the beliefs being propagated by an argument. Yes, I'm serious: it works! In fact, most of the time it's rather trivial. Sometimes, though, it gives an interesting insight into what's going on-- often cases where classical logic tells us that an inference is just fine, but informal pragmatics tell us that there is something silly about it. (I think there's some value in knowing precisely what we mean by <em>silly</em>.)</p>\n<h1>Conclusion</h1>\n<p>I presented very rough glosses of these two algorithms, and I'd encourage everyone to read more about the details in other places. However, what I'm really trying to drive at here is a broader point: algorithms which have been developed by computer scientists can really give us useful lessons about rationality. Often we find that if it's a good way for a computer to think, it's a good way for us to think, too. This does not mean memorising and mechanically executing an algorithm, of course; it means understanding the trick that makes the algorithm good, and applying that trick whenever we think it's relevant, until it becomes second nature.<br /><br />Question for discussion: what algorithms have you applied to your own thought processes? What algorithms might you be interested in applying?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "GY5kPPpCoyt9fnTMn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q5w2SoR6NetZMxQco", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 38, "extendedScore": null, "score": 0.000116, "legacy": true, "legacyId": "5451", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This post springs out of a very long line of thought, which I will only summarise small parts of.</p>\n<p>It began with the puzzling realisation that the algorithm which computers use to perform symbolic integration is <em>radically</em> different from the guess-and-check method taught in schools. My first reaction was, why are we not taught the systematic way of doing it? This is true for other areas of mathematics as well. In a few cases, such as solving quadratic equations or systems of linear equations, students are eventually taught the fast way. However, in many cases, the existence of an algorithm is not even mentioned.</p>\n<p>My point, however, is not to criticise the educational practice; in fact, I agree with the idea of teaching mathematics as an exploration of ideas rather than an application of formulaic solution methods. Rather, I would like to encourage people to eventually learn the algorithms, and try to apply them. A good algorithm is a study in rational behaviour, and I think we can take home a lesson from each.</p>\n<p>I'll just give two examples which I find particularly fascinating: Knuth-Bendix completion and the summary-product algorithm. The first is most relevant to fast mathematical reasoning. The second is relevant to studying the reasonableness of fast-and-messy probabilistic reasoning, the way humans do it.</p>\n<h1 id=\"Knuth_Bendix_Completion\"><a id=\"more\"></a>Knuth-Bendix Completion</h1>\n<p><a href=\"http://mathworld.wolfram.com/Knuth-BendixCompletionAlgorithm.html\">Knuth-Bendix completion</a> (\"K-B\" from now on) is a fascinating formalisation of the mathematical idea of simplification. Everyone should recognise the phrase \"simplify your answer\" from high school homework assignments. I never suspected that simplification could be a really powerful method for mathematical reasoning.</p>\n<p>K-B is a method for reasoning about equality. Equality is one of the simplest relationships we can have between two things, yet the naive way of reasoning about it results in an explosion of possible inferences. If there are N things in our universe, there are N<sup>2</sup> equality statements which may be true or false. We can substitute equals for equals all day and get nowhere. So why does it seems like such a simple relation? I think the K-B algorithm gives a good answer to that.</p>\n<p>We start with the basic axioms for the domain we are reasoning about. The domain consists of a set of expressions, some of which are equal to others. The axioms provide some general equalities; for example, they might be the trigonometric identities, if we are reasoning about trigonometric expressions.</p>\n<p><strong>First</strong>, we decide on a relatively arbitrary ordering of \"simplicity\" over the expressions we're using. Practical considerations and personal preferences will go into this, but for the algorithm itself, there are only a few requirements: it should be a well-ordering (so any two expressions are comparable, and there are no infinitely descending chains), and it should be consistent in the sense that if we replace a sub-expression with a simpler sub-expression, the whole expression gets simpler.</p>\n<p><strong>Second</strong>, we take the starting set of identities, and now treat them as rewrite rules: we judge which direction goes from complex to simple and we <em>only</em> apply them in that direction. Since expressions can only get simpler, we now know that we won't just keep producing equality statements endlessly without getting where we want to go.</p>\n<p>Unfortunately, we lose some information by just taking one side of the equality. The truth is, it's sometimes necessary to alter an expression in a way which at first makes it more complicated, to allow application of another rule which eventually gets us to a simpler form.</p>\n<p>The genius of K-B is to find these situations, referred to as <em>critical pairs</em>, and add new simplification rules which abbreviate such steps: <strong>Third</strong>, look for critical pairs and add the necessary rules. (I won't try to give the exact statement of this step; I refer the reader again to the <a href=\"http://mathworld.wolfram.com/Knuth-BendixCompletionAlgorithm.html\">Wolfram article</a>. [Edit: Or the <a href=\"http://en.wikipedia.org/wiki/Knuth%E2%80%93Bendix_completion_algorithm\">Wikipedia article</a>.]) This step is repeated until the set of rules is complete. (It <em>will</em> sometimes happen that completion is impossible, sadly.)</p>\n<p>Once the rules are complete, we can reason purely by simplification. The procedure \"simplify\" is embodied by looking through our list of rules and applying them in the simplifying direction, until we can't find one that applies anymore. The result of simplification is referred to as the <em>normal form</em> of an expression. We can test whether two expressions are equal by putting them in normal form: if the two are equal, they will have the same normal form; if they are not equal, they won't.</p>\n<p>How can this be applied to life? Well, I admit that this one only applies if you do fairly advanced math on a regular basis (though, since I'm writing for rationalists, perhaps you'll be sympathetic if I encourage you to learn more mathematics and to apply it to your life!). In my experience, the K-B algorithm matches the behaviour of sophisticated mathematical reasoning fairly well; people will have a preferred way of simplifying different sorts of expressions, and the interesting theorems correspond to new simplifications which can only be proved by initially reasoning in a direction which looks more complex.</p>\n<p>The second algorithm I'll review is more applicable to everyday situations.</p>\n<h1 id=\"Summary_Product\">Summary-Product</h1>\n<p><a href=\"http://www.math.kth.se/~tjtkoski/factorgraphs.pdf\">Summary-product</a> is a recent algorithm, but one with deep roots. The interesting thing about this algorithm is that it is a general case of dozens of the most important algorithms in different specific areas. The PDF I linked to is a good introduction to this aspect of the algorithm, and I encourage readers to check it out; for my overview, however, I'll only look at the special case which is known as the belief propagation algorithm.<br><br>Belief propagation is a way of reasoning about probabilities in a tractable way.<br><br>First, we need to factor our beliefs into a large number of local belief functions, which deal only with a few statements. These represent local probabilistic dependencies between facts; perhaps conditional probabilities (in what's called a Bayesian Network) or just weights which contribute to probabilities (in what's called Markov Networks). What's important is that if we multiplied all the local functions together, we would get a coherent probability distribution.<br><br>Next, we take stock of the evidence. This gives fixed beliefs to some of the variables.<br><br>What we want to find now are beliefs for the other variables, referred to as marginal probability distributions. The naive way of finding these is to sum over the entire state-space. For N unobserved variables, we have an N-dimensional state-space; we want to sum over every variable but the one which we're calculating a belief for. If every dimension is of size v, we have v<sup>N</sup> entries to sum up.<br><br>The idea which leads to the belief propagation algorithm is that we can do better by using the factorisation, thanks to the distributive law: we push the sums as far in as we can, so that whenever possible, we sum over a dimension before we multiply. If the dependencies are treelike, this will give us a calculation which takes time proportional in N, rather than v<sup>N</sup>; a huge gain.<br><br>Turning this into a local propagation algorithm gives us rules for updating a belief in relation to its neighbours. This has two advantages.<br><br>First, it happens that we can calculate a belief for <em>all</em> of the variables in just twice the time that it takes to calculate the belief for the one; that is, 2N time. Why? Computing the belief function for one variable amounts to propagation starting at the far edges of the network and heading towards that variable. This loads the network with most of the information it needs. We can finish off the computation by simply propagating in the reverse direction, away from that variable; this spreads the evidence all around the network like jelly on toast, completing the marginalisation of every variable in 2N time.<br><br>Second, a surprising feature of the propagation algorithm is that it gives good approximate results for non-treelike factorisations. This is like saying that we can push in sums even when the distributive law doesn't hold! Rather than 2N propagations, we just keep propagating until our beliefs converge to stable values (or until we're fed up with waiting). In many situations, this will still converge to exact results or useful estimates. This makes belief propagation a reasonable candidate for general inference.<br><br>I think there are many lessons for rationality hidden in the details of the belief propagation algorithm. In fact, since belief propagation is a core Bayesian activity, there are already posts here dealing with some of the important lessons. I'll just mention one which I find quite striking, personally.<br><br>A naive method of belief propagation might update the belief of a variable based on the raw estimated marginal which the neighbour currently has. If two neighbouring beliefs X and Y imply each other with high probability, though, we'd run into trouble: suppose some evidence raises our belief in X. Then we can propagate this to Y, raising our belief there. But then we notice that once again, a neighbour of X has changed, and we can re-update X; performing belief propagation raises our belief in X once more. We'd go back and forth like this until X and Y lock in with probability indistinguishable from 1.<br><br>The <em>actual</em> rules of belief propagation stop this from happening with the idea of a <em>directional</em> message. The message which X sends to Y is the belief we compute for X with all the evidence <em>except</em> the evidence coming from Y. In general, the belief which gets sent in a particular direction uses all the evidence except the evidence coming back that same direction.<br><br>This prevents circular reasoning. For all the the talk about the fallacy of circular reasoning, classical logic does not really have a good treatment of it. For a statement A, it's perfectly valid to prove A from an assumption of A in classical logic; in fact we can prove A-&gt;A for any proposition (where \"-&gt;\" is material implication)! I think it's not until we think about tractable probabilistic reasoning that we really get a good account of what's wrong with circular reasoning: it makes us count the same evidence more than once.<br><br>Next time you're talking with someone, try to keep track of the directionality of the beliefs being propagated by an argument. Yes, I'm serious: it works! In fact, most of the time it's rather trivial. Sometimes, though, it gives an interesting insight into what's going on-- often cases where classical logic tells us that an inference is just fine, but informal pragmatics tell us that there is something silly about it. (I think there's some value in knowing precisely what we mean by <em>silly</em>.)</p>\n<h1 id=\"Conclusion\">Conclusion</h1>\n<p>I presented very rough glosses of these two algorithms, and I'd encourage everyone to read more about the details in other places. However, what I'm really trying to drive at here is a broader point: algorithms which have been developed by computer scientists can really give us useful lessons about rationality. Often we find that if it's a good way for a computer to think, it's a good way for us to think, too. This does not mean memorising and mechanically executing an algorithm, of course; it means understanding the trick that makes the algorithm good, and applying that trick whenever we think it's relevant, until it becomes second nature.<br><br>Question for discussion: what algorithms have you applied to your own thought processes? What algorithms might you be interested in applying?</p>", "sections": [{"title": "Knuth-Bendix Completion", "anchor": "Knuth_Bendix_Completion", "level": 1}, {"title": "Summary-Product", "anchor": "Summary_Product", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "40 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T19:24:54.280Z", "modifiedAt": null, "url": null, "title": "Why we should fear the Paperclipper [Link]", "slug": "why-we-should-fear-the-paperclipper-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.330Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jH5RYLM8cyksqhcyf/why-we-should-fear-the-paperclipper-link", "pageUrlRelative": "/posts/jH5RYLM8cyksqhcyf/why-we-should-fear-the-paperclipper-link", "linkUrl": "https://www.lesswrong.com/posts/jH5RYLM8cyksqhcyf/why-we-should-fear-the-paperclipper-link", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20we%20should%20fear%20the%20Paperclipper%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20we%20should%20fear%20the%20Paperclipper%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjH5RYLM8cyksqhcyf%2Fwhy-we-should-fear-the-paperclipper-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20we%20should%20fear%20the%20Paperclipper%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjH5RYLM8cyksqhcyf%2Fwhy-we-should-fear-the-paperclipper-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjH5RYLM8cyksqhcyf%2Fwhy-we-should-fear-the-paperclipper-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<blockquote>\n<h2>The Scenario</h2>\n<p>A programmer has constructed an artificial intelligence based on an architecture similar to Marcus Hutter's <a href=\"http://www.hutter1.net/ai/aixigentle.htm\">AIXI</a> model (see below for a few details). This AI will maximize the reward  given by a utility function the programmer has given it. Just as a test,  he connects it to a 3D printer and sets the utility function to give  reward proportional to the number of manufactured paper-clips.</p>\n<p>At first nothing seems to happen: the AI zooms through various  possibilities.  It notices that smarter systems generally can make more  paper-clips, so making itself smarter will likely increase the number of  paper-clips that will eventually be made. It does so.  It considers how  it can make paper-clips using the 3D printer, estimating the number of  possible paper-clips. It notes that if it could get more raw materials  it could make more paper-clips. It hence figures out a plan to  manufacture devices that will make it much smarter, prevent interference  with its plan, and will turn all of Earth (and later the universe) into  paper-clips. It does so.</p>\n<p>Only paper-clips remain.</p>\n</blockquote>\n<p><strong>Link:</strong> <a href=\"http://www.aleph.se/andart/archives/2011/02/why_we_should_fear_the_paperclipper.html\">aleph.se/andart/archives/2011/02/why_we_should_fear_the_paperclipper.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QH4LhvnyR4QkW9MG8": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jH5RYLM8cyksqhcyf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 6.791515528057703e-07, "legacy": true, "legacyId": "5554", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T20:52:51.556Z", "modifiedAt": null, "url": null, "title": "Torturing people for fun", "slug": "torturing-people-for-fun", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.697Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ii9GPWBgfXPiRwgbx/torturing-people-for-fun", "pageUrlRelative": "/posts/ii9GPWBgfXPiRwgbx/torturing-people-for-fun", "linkUrl": "https://www.lesswrong.com/posts/ii9GPWBgfXPiRwgbx/torturing-people-for-fun", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Torturing%20people%20for%20fun&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATorturing%20people%20for%20fun%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fii9GPWBgfXPiRwgbx%2Ftorturing-people-for-fun%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Torturing%20people%20for%20fun%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fii9GPWBgfXPiRwgbx%2Ftorturing-people-for-fun", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fii9GPWBgfXPiRwgbx%2Ftorturing-people-for-fun", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 126, "htmlBody": "<p>Most of the usual thought experiments that justify expected utilitarialism trade off fun for fun, or suffering for suffering. Here's a situation which mixes the two.&nbsp;You are offered to press a button that will select a random person (not you) and torture them for a month. In return the machine will make N people who are <em>not</em> suffering right now have X fun each. The fun will be of the positive variety, not saving any creatures from pain.</p>\n<p>1) How large would X and N have to be for you to accept the offer?</p>\n<p>2) If you say X or N must be very large, does this prove that you measure torture and fun using in effect different scales, and therefore are a deontologist rather than a utilitarian?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ii9GPWBgfXPiRwgbx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 18, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "5555", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T22:32:00.611Z", "modifiedAt": null, "url": null, "title": "Intro to Naturalist Metaethics?", "slug": "intro-to-naturalist-metaethics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.916Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XrGRdzFYiExCCEAmB/intro-to-naturalist-metaethics", "pageUrlRelative": "/posts/XrGRdzFYiExCCEAmB/intro-to-naturalist-metaethics", "linkUrl": "https://www.lesswrong.com/posts/XrGRdzFYiExCCEAmB/intro-to-naturalist-metaethics", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Intro%20to%20Naturalist%20Metaethics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntro%20to%20Naturalist%20Metaethics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrGRdzFYiExCCEAmB%2Fintro-to-naturalist-metaethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Intro%20to%20Naturalist%20Metaethics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrGRdzFYiExCCEAmB%2Fintro-to-naturalist-metaethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrGRdzFYiExCCEAmB%2Fintro-to-naturalist-metaethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p>Can anyone recommend a good primer on naturalist metaethics? I've read the Fun Theory Sequence, and found it fascinating, but it only deals with fun. There are also life, death, pain, torture, and possibly other goods &amp; harms to consider. Also, the Fun Theory Sequence tends to focus on macro-metaethics, i.e., what would be best for all of us to do together? I would also like to learn about micro-metaethics, i.e., what should I do with my life, and how should I choose which parts of myself to emphasize, or which parts of myself I will think of as \"really me\" or \"the best part of me?\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XrGRdzFYiExCCEAmB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 6.792011243392948e-07, "legacy": true, "legacyId": "5556", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-14T22:49:28.312Z", "modifiedAt": null, "url": null, "title": "Optimal Employment Open Thread", "slug": "optimal-employment-open-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:29.061Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "YpTmfmnMjgakwFRQQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yuGci5CHe8CGqFuCa/optimal-employment-open-thread", "pageUrlRelative": "/posts/yuGci5CHe8CGqFuCa/optimal-employment-open-thread", "linkUrl": "https://www.lesswrong.com/posts/yuGci5CHe8CGqFuCa/optimal-employment-open-thread", "postedAtFormatted": "Monday, February 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimal%20Employment%20Open%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimal%20Employment%20Open%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuGci5CHe8CGqFuCa%2Foptimal-employment-open-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimal%20Employment%20Open%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuGci5CHe8CGqFuCa%2Foptimal-employment-open-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyuGci5CHe8CGqFuCa%2Foptimal-employment-open-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>Related to: <a href=\"/lw/43m/optimal_employment/\">Optimal Employment</a>, <a href=\"/lw/38u/best_career_models_for_doing_research/\">Best career models for doing research?</a>, <a href=\"/lw/2qp/virtual_employment_open_thread/\">(Virtual) Employment Open Thread</a></p>\n<p>In <a href=\"/lw/43m/optimal_employment/\">Optimal Employment</a> Louie discussed some biases that lead people away from optimal employment, and gave working in Australia as an option for such employment. What are some other options?</p>\n<p>Your optimal employment will depend on how much you care about a variety of things (free time, money, etc.) so when discussing options it might be helpful to say what you're trying to optimize for.&nbsp;</p>\n<p>In addition to proposing options we could list resources that might be helpful for generating or implementing options.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yuGci5CHe8CGqFuCa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 6.79205750941817e-07, "legacy": true, "legacyId": "5557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jtedBLdducritm8y6", "rNkFLv9tXzq8Lrvrc", "9bTNcSpNBdPpyocMK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T04:23:24.516Z", "modifiedAt": null, "url": null, "title": "The non-painless upload", "slug": "the-non-painless-upload", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.014Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Prismattic", "createdAt": "2010-12-25T22:57:35.560Z", "isAdmin": false, "displayName": "Prismattic"}, "userId": "S374FemeqCtr35dEk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3qvwuAiyDwvmQhB5Q/the-non-painless-upload", "pageUrlRelative": "/posts/3qvwuAiyDwvmQhB5Q/the-non-painless-upload", "linkUrl": "https://www.lesswrong.com/posts/3qvwuAiyDwvmQhB5Q/the-non-painless-upload", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20non-painless%20upload&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20non-painless%20upload%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qvwuAiyDwvmQhB5Q%2Fthe-non-painless-upload%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20non-painless%20upload%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qvwuAiyDwvmQhB5Q%2Fthe-non-painless-upload", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3qvwuAiyDwvmQhB5Q%2Fthe-non-painless-upload", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 260, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">I have been trying to absorb the Lesswrong near-consensus on cryonics/quantum mechanics/uploading, and I confess to being unpersuaded by it. I'm not hostile to cryonics; just indifferent, and having a bit of trouble articulating why the insights on identity that I have been picking up from the quantum mechanics sequence aren't compelling to me. I offer the following thought experiment in hopes that others may be able to present the argument more effectively if they understand the objection here.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Suppose that Omega appears before you and says, &ldquo;All life on Earth is going to be destroyed tomorrow by [insert cataclysmic event of your choice here]. I offer you the chance to push this button, which will upload your consciousness to a safe place out of reach of the cataclysmic event, preserving all of your memories, etc. up to the moment you pushed the button and optimizing you such that you will be effectively immortal. However, the uploading process is painful, and because it interferes with your normal perception of time, your original mind/body will subjectively experience the time after you pushed the button but before the process is complete as a thousand years of the most intense agony. Additionally, I can tell you that a sufficient number of other people will choose to push the button that your uploaded existence will not be lonely.&rdquo;</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Do you push the button?</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">My understanding of the Lesswrong consensus on this issue is that my uploaded consciousness is me, not just a copy of me. I'm hoping the above hypothetical illustrates why I'm having trouble accepting that.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3qvwuAiyDwvmQhB5Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 6, "extendedScore": null, "score": 6.792942405901791e-07, "legacy": true, "legacyId": "5577", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T05:13:00.773Z", "modifiedAt": null, "url": null, "title": "Rationalist Diplomacy, Game Two Post-game Discussion", "slug": "rationalist-diplomacy-game-two-post-game-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.130Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Randaly", "createdAt": "2010-04-20T23:31:03.738Z", "isAdmin": false, "displayName": "Randaly"}, "userId": "KdhDyNCDgA945WayD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a3JWk5pHQ6LsSxL7a/rationalist-diplomacy-game-two-post-game-discussion", "pageUrlRelative": "/posts/a3JWk5pHQ6LsSxL7a/rationalist-diplomacy-game-two-post-game-discussion", "linkUrl": "https://www.lesswrong.com/posts/a3JWk5pHQ6LsSxL7a/rationalist-diplomacy-game-two-post-game-discussion", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Diplomacy%2C%20Game%20Two%20Post-game%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Diplomacy%2C%20Game%20Two%20Post-game%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3JWk5pHQ6LsSxL7a%2Frationalist-diplomacy-game-two-post-game-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Diplomacy%2C%20Game%20Two%20Post-game%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3JWk5pHQ6LsSxL7a%2Frationalist-diplomacy-game-two-post-game-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa3JWk5pHQ6LsSxL7a%2Frationalist-diplomacy-game-two-post-game-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 397, "htmlBody": "<p>(A full list of game moves and commentary is available <a href=\"http://wiki.lesswrong.com/wiki/Rationalist_Diplomacy,_Game_2\">here</a>; the game maps are available <a href=\"http://s1237.photobucket.com/albums/ff471/Randaly/\">here</a>.)</p>\n<p>&nbsp;</p>\n<p>Since I was GM, I had a distinctly limited access to private communications, so I've relatively little analysis.</p>\n<p>&nbsp;</p>\n<p>A brief review of the game:</p>\n<p>Austria was the first player to get eliminated; in contrast to the sort of min-maxing I've usually seen in Diplomacy, they took a lot of big risks in the beginning, in particular leaving Trieste open to Italian attack, in favor of quick expansion to the east. Although they did manage to take Warsaw and Serbia, the Austrian forces wound up overextended and unable to hold onto their gains, and in a weak position diplomatically; the fall of Trieste didn't help matters. Nobody was willing to help Austria, and so Italy seized all of Austria, with Turkey taking the Balkans and Russia taking Rumania. After that, there was a long period of stalemate in the Balkans, as neither of the three powers was willing to divert enough troops to one front to make any offensive progress.</p>\n<p>In the west, Germany initially faced a combined Franco-British attack; they held out surprisingly well, aided by cracks in the alliance and occasional Russian attacks on Norway. Britain was actually the first Power to fall in the West, when France piled on after the fall of Norway; the British player was forced to stop participating in the game at around that time. France wound up with all of the British Isles, and Germany was squeezed between it and Russia until it cracked. (The brief Italian occupation of Munich didn't help.) Germany did manage to hold out for most of the rest of the game; there were only a few months of inconclusive war between France and Russia before the draw proposal.</p>\n<p>Meanwhile, in the east, Italy gradually fell back before a combined Russian-Turkish attack. After Russia seized Vienna and Budapest, and Turkey seized Trieste, Russia mostly concentrated on attacking England and Germany, leaving Turkey and Italy in a period of stalemate, broken by the advance of Turkish fleets into the Ionian Sea. Soon after, Italy's player had to drop out, and Turkey soon seized control of Italy. Then the game ended.</p>\n<p>One thing I'm curious about is how much communication there was between the eastern and western powers. (In-game, beyond Russia fighting on both fronts and a single, chance retreat by Italy, there was little direct interaction.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a3JWk5pHQ6LsSxL7a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "5578", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T09:17:23.723Z", "modifiedAt": null, "url": null, "title": "Some Heuristics for Evaluating the Soundness of the Academic Mainstream in Unfamiliar Fields", "slug": "some-heuristics-for-evaluating-the-soundness-of-the-academic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:35.590Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_M", "createdAt": "2010-04-17T17:31:50.226Z", "isAdmin": false, "displayName": "Vladimir_M"}, "userId": "Fj5i6j28HMGcdytoM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fyZBtNB3Ki3fM4a6Y/some-heuristics-for-evaluating-the-soundness-of-the-academic", "pageUrlRelative": "/posts/fyZBtNB3Ki3fM4a6Y/some-heuristics-for-evaluating-the-soundness-of-the-academic", "linkUrl": "https://www.lesswrong.com/posts/fyZBtNB3Ki3fM4a6Y/some-heuristics-for-evaluating-the-soundness-of-the-academic", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20Heuristics%20for%20Evaluating%20the%20Soundness%20of%20the%20Academic%20Mainstream%20in%20Unfamiliar%20Fields&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20Heuristics%20for%20Evaluating%20the%20Soundness%20of%20the%20Academic%20Mainstream%20in%20Unfamiliar%20Fields%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZBtNB3Ki3fM4a6Y%2Fsome-heuristics-for-evaluating-the-soundness-of-the-academic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20Heuristics%20for%20Evaluating%20the%20Soundness%20of%20the%20Academic%20Mainstream%20in%20Unfamiliar%20Fields%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZBtNB3Ki3fM4a6Y%2Fsome-heuristics-for-evaluating-the-soundness-of-the-academic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZBtNB3Ki3fM4a6Y%2Fsome-heuristics-for-evaluating-the-soundness-of-the-academic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2701, "htmlBody": "<p><em>(This post is an expanded version of <a href=\"/lw/28i/what_is_bunk/1zba\" target=\"_self\">a LW comment I left a while ago</a>. I have found myself referring to it so much in the meantime that I think it&rsquo;s worth reworking into a proper post.&nbsp;</em><em>Some related posts are <a href=\"/lw/1kh/the_correct_contrarian_cluster\">\"</a></em><em><a href=\"/lw/1kh/the_correct_contrarian_cluster\">The Correct Contrarian Cluster\"</a> and <a href=\"/lw/28i/what_is_bunk/\">\"</a></em><em><a href=\"/lw/28i/what_is_bunk/\">What is Bunk?\"</a>)</em></p>\n<p>When looking for information about some area outside of one&rsquo;s expertise, it is usually a good idea to first ask what academic scholarship has to say on the subject. In many areas, there is no need to look elsewhere for answers: respectable academic authors are the richest and most reliable source of information, and people claiming things completely outside the academic mainstream are almost certain to be crackpots.&nbsp;</p>\n<p>The trouble is, this is not always the case. Even those whose view of the modern academia is much rosier than mine should agree that it would be astonishing if there didn&rsquo;t exist at least some areas where the academic mainstream is detached from reality on important issues, while much more accurate views are scorned as kooky (or would be if they were heard at all). Therefore, depending on the area, the fact that a view is way out of the academic mainstream may imply that it's bunk with near-certainty, but it may also tell us nothing if the mainstream standards in the area are especially bad.</p>\n<p>I will discuss some heuristics that, in my experience, provide a realistic first estimate of how sound the academic mainstream in a given field is likely to be, and how justified one would be to dismiss contrarians out of hand. These conclusions have come from my own observations of research literature in various fields and some personal experience with the way modern academia operates, and I would be interested in reading others&rsquo; opinions.&nbsp;<a id=\"more\"></a></p>\n<p><span style=\"font-size: 14px; font-weight: bold; \">Low-hanging fruit heuristic</span></p>\n<p>As the first heuristic, we should ask if there is a lot of low-hanging fruit available in the given area, in the sense of research goals that are both interesting and doable. If yes, this means that there are clear paths to quality work open for reasonably smart people with an adequate level of knowledge and resources, which makes it unnecessary to invent clever-looking nonsense instead. In this situation, smart and capable people can just state a sound and honest plan of work on their grant applications and proceed with it.</p>\n<p>In contrast, if a research area has reached a dead end and further progress is impossible except perhaps if some extraordinary path-breaking genius shows the way, or in an area that has never even had a viable and sound approach to begin with, it&rsquo;s unrealistic to expect that members of the academic establishment will openly admit this situation and decide it&rsquo;s time for a career change. What will likely happen instead is that they&rsquo;ll continue producing output that will have all the superficial trappings of science and sound scholarship, but will in fact be increasingly pointless and detached from reality.&nbsp;</p>\n<p>Arguably, some areas of theoretical physics have reached this state, if we are to trust the critics like <a href=\"http://www.wired.com/wired/archive/14.09/stringtheory.html\" target=\"_self\">Lee Smolin</a>. I am not a physicist, and I cannot judge directly if Smolin and the other similar critics are right, but some powerful evidence for this came several years ago in the form of the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Bogdanov_Affair\" target=\"_self\">Bogdanoff affair</a>, which demonstrated that highly credentialed physicists in some areas can find it difficult, perhaps even impossible, to distinguish sound work from a well-contrived nonsensical imitation. [1]</p>\n<p>Somewhat surprisingly, another example is presented by some subfields of computer science. With all the new computer gadgets everywhere, one would think that no other field could be further from a stale dead end. In some of its subfields this is definitely true, but in others, much of what is studied is based on decades old major breakthroughs, and the known viable directions from there have long since been explored all until they hit against some fundamentally intractable problem. (Or alternatively, further progress is a matter of hands-on engineering practice that&nbsp;doesn't&nbsp;lend itself to the way academia operates.) This has led to a situation where a lot of the published CS research is increasingly distant from reality, because to keep the illusion of progress, it must pretend to solve problems that are basically known to be impossible. [2]&nbsp;</p>\n<h4>Ideological/venal interest heuristic</h4>\n<p>Bad as they might be, the problems that occur when clear research directions are lacking pale in comparison with what happens when things under discussion are ideologically charged or a matter in which powerful interest groups have a stake. As Hobbes remarked, people agree about theorems of geometry not because their proofs are solid, but because \"<em>men care not in that subject what be truth, as a thing that crosses no man&rsquo;s ambition, profit, or lust</em>.\" [3]</p>\n<p>One example is the cluster of research areas encompassing intelligence research, sociobiology, and behavioral genetics, which touches on a lot of highly ideologically charged questions. These pass the low-hanging fruit heuristic easily: the existing literature is full of proposals for interesting studies waiting to be done. Yet, because of their striking ideological implications, these areas are full of work clearly aimed at advancing the authors&rsquo; non-scientific agenda, and even after a lot of reading one is left in confusion over whom to believe, if anyone. It doesn&rsquo;t even matter whose side one supports in these controversies: whichever side is right (if any one is), it&rsquo;s simply impossible that there isn&rsquo;t a whole lot of nonsense published in prestigious academic venues and under august academic titles.&nbsp;</p>\n<p>Yet another academic area that suffers from the same problems is the history of the modern era. On many significant events from the last two centuries, there is a great deal of documentary evidence laying around still waiting to be assessed properly, so there is certainly no lack of low-hanging fruit for a smart and diligent historian. Yet due to the clear ideological implications of many historical topics, ideological nonsense cleverly masquerading as scholarship abounds. I don&rsquo;t think anything resembling an accurate world history of the last two centuries could be written without making a great many contrarian claims. [4] In contrast, on topics that don't arouse ideological passions, modern histories are often amazingly well researched and free of speculation and distortion. (In particular, if you are from a small nation that has never really been a player in world history, your local historians are likely to be full of parochial bias motivated by the local political quarrels and grievances, but you may be able to find very accurate information on your local history in the works of foreign historians from the elite academia.)&nbsp;</p>\n<p>On the whole, it seems to me that failing the ideological interest test suggests a much worse situation than failing the low-hanging fruit test. The areas affected by just the latter are still fundamentally sound, and tend to produce work whose contribution is way overblown, but which is still built on a sound basis and internally coherent. Even if outright nonsense is produced, it&rsquo;s still clearly distinguishable with some effort and usually restricted to less prestigious authors. Areas affected by ideological biases, however, tend to drift much further into outright delusion, possibly lacking a sound core body of scholarship altogether.&nbsp;</p>\n<p><em>[Paragraphs below added in response to comments:]&nbsp;</em></p>\n<p>What about the problem of purely venal influences, i.e. the cases where researchers are under the patronage of parties that have stakes in the results of their research? On the whole, the modern Western academic system is very good at discovering and stamping out clear and obvious corruption and fraud. It's clearly not possible for researchers to openly sell their services to the highest bidder; even if there are no formal sanctions, their reputation would be ruined. However, venal influences are nevertheless far from nonexistent, and a fascinating question is under what exact conditions researchers are likely to fall under them and get away with it.</p>\n<p>Sometimes venal influences are masked by scams such as setting up phony front organizations for funding, but even that tends to be discovered eventually and tarnish the reputations of the researchers involved. What seems to be the real problem is when the beneficiaries of biased research enjoy such status in the eyes of the public and such legal and customary position in society that they don't even need to hide anything when establishing a perverse symbiosis that results in biased research. Such relationships, while fundamentally representing venal interest, are in fact often boasted about as beneficial and productive cooperation. Pharmaceutical research is an often cited example, but I think the phenomenon is in fact far more widespread, and reaches the height of perverse perfection in those research communities whose structure effectively blends into various government agencies.&nbsp;</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">The really bad cases: failing both tests</span></p>\n<p>So far,&nbsp;I've&nbsp;discussed examples where one of the mentioned heuristics returns a negative answer, but not the other. What happens when a field fails both of them, having no clear research directions and at the same time being highly relevant to ideologues and interest groups? Unsurprisingly, it tends to be really bad.&nbsp;</p>\n<p>The clearest example of such a field is probably economics, particularly macroeconomics. (Microeconomics covers an extremely broad range of issues deeply intertwined with many other fields, and its soundness, in my opinion, varies greatly depending on the subject, so I&rsquo;ll avoid a lengthy digression into it.) Macroeconomists lack any clearly sound and fruitful approach to the problems they wish to study, and any conclusion they might draw will have immediately obvious ideological implications, often expressible in stark \"who-whom?\" terms.&nbsp;</p>\n<p>And indeed, even a casual inspection of the standards in this field shows clear symptoms of cargo-cult science: weaving complex and abstruse theories that can be made to predict everything and nothing, manipulating essentially meaningless numbers as if they were objectively measurable properties of the real world [5], experts with the most prestigious credentials dismissing each other as crackpots (in more or less diplomatic terms) when their favored ideologies clash, etc., etc. Fringe contrarians in this area (most notably extreme Austrians) typically have silly enough ideas of their own, but their criticism of the academic mainstream is nevertheless often spot-on, in my opinion.</p>\n<h4>Other examples</h4>\n<p>So, what are some other interesting case studies for these heuristics?&nbsp;</p>\n<p>An example of great interest is climate science. Clearly, the ideological interest heuristic raises a big red flag here, and indeed, there is little doubt that a lot of the research coming out in recent years that supposedly links \"climate change\" with all kinds of bad things is just fashionable nonsense [6]. (Another sanity check it fails is that only a tiny proportion of these authors ever hypothesize that the predicted/observed climate change might actually <em>improve</em> something, as if there existed some law of physics prohibiting it.) Thus, I&rsquo;d say that contrarians on this issue should definitely not be dismissed out of hand; the really hard question is how much sound insight (if any) remains after one eliminates all the nonsense that&rsquo;s infiltrated the mainstream. When it comes to the low-hanging fruit heuristic, I find the situation less clear. How difficult is it to achieve progress in accurately reconstructing long-term climate trends and forecasting the influences of increasing greenhouse gases? Is it hard enough that we&rsquo;d expect, even absent an ideological motivation, that people would try to substitute cleverly contrived bunk for unreachable sound insight? My conclusion is that I&rsquo;ll have to read much more on the technical background of these subjects before I can form any reliable opinion on these questions.&nbsp;</p>\n<p>Another example of practical interest is nutrition. Here ideological influences aren&rsquo;t very strong (though not altogether absent either). However, the low-hanging fruit raises a huge red flag: it&rsquo;s almost impossible to study these things in a sound way, controlling for all the incredibly complex and counterintuitive confounding variables. At the same time, it&rsquo;s easy to produce endless amounts of plausible-looking junk studies. Thus, I&rsquo;d expect that the mainstream research in this area is on average pure nonsense, with a few possible gems of solid insight hopelessly buried under it, and even when it comes to very extreme contrarians, I wouldn&rsquo;t be tremendously surprised to see any one of them proven right at the end. &nbsp;My conclusion is similar when it comes to exercise and numerous other lifestyle issues.</p>\n<h4>Exceptions</h4>\n<p>Finally, what are the evident exceptions to these trends?&nbsp;</p>\n<p>I can think of some exceptions to the low-hanging fruit heuristic. One is in historical linguistics, whose standard well-substantiated methods have had great success in identifying the structure of the world&rsquo;s language family trees, but give no answer at all to the fascinating question of how far back into the past the nodes of these trees reach (except of course when we have written evidence). Nobody has any good idea how to make progress there, and the questions are tantalizing. Now, there are all sorts of plausible-looking but fundamentally unsound methods that purport to answer these questions, and papers using them occasionally get published in prestigious non-linguistic journals, but the actual historical linguists firmly dismiss them as unsound, even though they have no answers of their own to offer instead. [7] It&rsquo;s an example of a commendable stand against seductive nonsense.</p>\n<p>It&rsquo;s much harder to think of examples where the ideological interest heuristic fails. What field can one point out where mainstream scholarship is reliably sound and objective despite its topic being ideologically charged? Honestly, I can&rsquo;t think of one.</p>\n<p>What about the other direction -- fields that pass both heuristics but are nevertheless nonsense? I can think of e.g. artsy areas that don&rsquo;t make much of a pretense to objectivity in the first place, but otherwise, it seems to me that absent ideological and venal perverse incentives, and given clear paths to progress that don&rsquo;t require extraordinary genius, the modern academic system is great in producing solid and reliable insight. The trouble is that these conditions often don&rsquo;t hold in practice.&nbsp;</p>\n<p>I&rsquo;d be curious to see additional examples that either confirm of disprove these heuristics I proposed.</p>\n<h4>Footnotes</h4>\n<p>[1] Commenter gwern <a href=\"/lw/28i/what_is_bunk/2yja\" target=\"_self\">has argued</a>&nbsp;that the Bogdanoff affair is not a good example, claiming that the brothers have been shown as fraud decisively after they came under intense public scrutiny. However, even if this is true, the fact still remains that they initially managed to publish their work in reputable peer-reviewed venues and obtain doctorates at a reputable (though not top-ranking) university, which strongly suggests that there is much more work in the field that is equally bad but doesn't elicit equal public interest and thus never gets really scrutinized. Moreover, from my own reading about the affair, it was clear that in its initial phases several credentialed physicists were unable to make a clear judgment about their work. On the whole, I don&rsquo;t think the affair can be dismissed as an insignificant accident.&nbsp;</p>\n<p>[2] Moldbug&rsquo;s <a href=\"http://unqualified-reservations.blogspot.com/2007/08/whats-wrong-with-cs-research.html\" target=\"_self\">\"What&rsquo;s wrong with CS research\"</a>&nbsp;is a witty and essentially accurate overview of this situation. He mostly limits himself to the discussion of programming language research, but a similar scenario can be seen in some other related fields too.</p>\n<p>[3] Thomas Hobbes, <em>Leviathan</em>, Chapter XI.</p>\n<p>[4] I have the impression that LW readers would mostly not be interested in a detailed discussion of the topics where I think one should read contrarian history, so I&rsquo;m skipping it. In case I&rsquo;m wrong, please feel free to open the issue in the comments.</p>\n<p>[5] Oskar Morgenstern&rsquo;s <em>On the Accuracy of Economic Observations</em>&nbsp;is a tour de force on the subject, demonstrating the essential meaninglessness of many sorts of numbers that economists use routinely. (Many thanks to <a href=\"/lw/2cp/open_thread_june_2010_part_3/25q7\" target=\"_self\">the commenter realitygrill</a> for directing me to this amazing book.) Morgenstern is of course far too prestigious a name to dismiss as a crackpot, so economists appear to have chosen to simply ignore the questions he raised, and his book has been languishing in obscurity and out of print for decades. It is <a href=\"http://qss.stanford.edu/~godfrey/Morgenstern/Morgenstern_On_the_Accuracy_of_Econ_Obs_PUP_1963.pdf\" target=\"_self\">available for download</a> though (warning: ~31MB PDF).</p>\n<p>[6] Some amusing lists of examples have been posted by the <a href=\"http://blog.heritage.org/2009/11/17/global-warming-ate-my-homework-100-things-blamed-on-global-warming/\" target=\"_self\">Heritage Foundation</a> and the <a href=\"http://www.numberwatch.co.uk/warmlist.htm\" target=\"_self\">Number Watch</a> (not intended to endorse the rest of the stuff on these websites). Admittedly, a lot of the stuff listed there is not real published research, but rather just people's media statements. Still, there's no shortage of similar things even in published research either, as a search of e.g. Google Scholar will show.</p>\n<p>[7] Here is, for example, the linguist Bill Poser <a href=\"http://itre.cis.upenn.edu/~myl/languagelog/archives/000208.html\" target=\"_self\">dismissing one such paper</a> published in <em>Nature</em> a few years ago.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZpG9rheyAkgCoEQea": 1, "4R8JYu4QF2FqzJxE5": 1, "fF9GEdWXKJ3z73TmB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fyZBtNB3Ki3fM4a6Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 90, "baseScore": 99, "extendedScore": null, "score": 0.000183, "legacy": true, "legacyId": "5590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 99, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>(This post is an expanded version of <a href=\"/lw/28i/what_is_bunk/1zba\" target=\"_self\">a LW comment I left a while ago</a>. I have found myself referring to it so much in the meantime that I think it\u2019s worth reworking into a proper post.&nbsp;</em><em>Some related posts are <a href=\"/lw/1kh/the_correct_contrarian_cluster\">\"</a></em><em><a href=\"/lw/1kh/the_correct_contrarian_cluster\">The Correct Contrarian Cluster\"</a> and <a href=\"/lw/28i/what_is_bunk/\">\"</a></em><em><a href=\"/lw/28i/what_is_bunk/\">What is Bunk?\"</a>)</em></p>\n<p>When looking for information about some area outside of one\u2019s expertise, it is usually a good idea to first ask what academic scholarship has to say on the subject. In many areas, there is no need to look elsewhere for answers: respectable academic authors are the richest and most reliable source of information, and people claiming things completely outside the academic mainstream are almost certain to be crackpots.&nbsp;</p>\n<p>The trouble is, this is not always the case. Even those whose view of the modern academia is much rosier than mine should agree that it would be astonishing if there didn\u2019t exist at least some areas where the academic mainstream is detached from reality on important issues, while much more accurate views are scorned as kooky (or would be if they were heard at all). Therefore, depending on the area, the fact that a view is way out of the academic mainstream may imply that it's bunk with near-certainty, but it may also tell us nothing if the mainstream standards in the area are especially bad.</p>\n<p>I will discuss some heuristics that, in my experience, provide a realistic first estimate of how sound the academic mainstream in a given field is likely to be, and how justified one would be to dismiss contrarians out of hand. These conclusions have come from my own observations of research literature in various fields and some personal experience with the way modern academia operates, and I would be interested in reading others\u2019 opinions.&nbsp;<a id=\"more\"></a></p>\n<p><span style=\"font-size: 14px; font-weight: bold; \">Low-hanging fruit heuristic</span></p>\n<p>As the first heuristic, we should ask if there is a lot of low-hanging fruit available in the given area, in the sense of research goals that are both interesting and doable. If yes, this means that there are clear paths to quality work open for reasonably smart people with an adequate level of knowledge and resources, which makes it unnecessary to invent clever-looking nonsense instead. In this situation, smart and capable people can just state a sound and honest plan of work on their grant applications and proceed with it.</p>\n<p>In contrast, if a research area has reached a dead end and further progress is impossible except perhaps if some extraordinary path-breaking genius shows the way, or in an area that has never even had a viable and sound approach to begin with, it\u2019s unrealistic to expect that members of the academic establishment will openly admit this situation and decide it\u2019s time for a career change. What will likely happen instead is that they\u2019ll continue producing output that will have all the superficial trappings of science and sound scholarship, but will in fact be increasingly pointless and detached from reality.&nbsp;</p>\n<p>Arguably, some areas of theoretical physics have reached this state, if we are to trust the critics like <a href=\"http://www.wired.com/wired/archive/14.09/stringtheory.html\" target=\"_self\">Lee Smolin</a>. I am not a physicist, and I cannot judge directly if Smolin and the other similar critics are right, but some powerful evidence for this came several years ago in the form of the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Bogdanov_Affair\" target=\"_self\">Bogdanoff affair</a>, which demonstrated that highly credentialed physicists in some areas can find it difficult, perhaps even impossible, to distinguish sound work from a well-contrived nonsensical imitation. [1]</p>\n<p>Somewhat surprisingly, another example is presented by some subfields of computer science. With all the new computer gadgets everywhere, one would think that no other field could be further from a stale dead end. In some of its subfields this is definitely true, but in others, much of what is studied is based on decades old major breakthroughs, and the known viable directions from there have long since been explored all until they hit against some fundamentally intractable problem. (Or alternatively, further progress is a matter of hands-on engineering practice that&nbsp;doesn't&nbsp;lend itself to the way academia operates.) This has led to a situation where a lot of the published CS research is increasingly distant from reality, because to keep the illusion of progress, it must pretend to solve problems that are basically known to be impossible. [2]&nbsp;</p>\n<h4 id=\"Ideological_venal_interest_heuristic\">Ideological/venal interest heuristic</h4>\n<p>Bad as they might be, the problems that occur when clear research directions are lacking pale in comparison with what happens when things under discussion are ideologically charged or a matter in which powerful interest groups have a stake. As Hobbes remarked, people agree about theorems of geometry not because their proofs are solid, but because \"<em>men care not in that subject what be truth, as a thing that crosses no man\u2019s ambition, profit, or lust</em>.\" [3]</p>\n<p>One example is the cluster of research areas encompassing intelligence research, sociobiology, and behavioral genetics, which touches on a lot of highly ideologically charged questions. These pass the low-hanging fruit heuristic easily: the existing literature is full of proposals for interesting studies waiting to be done. Yet, because of their striking ideological implications, these areas are full of work clearly aimed at advancing the authors\u2019 non-scientific agenda, and even after a lot of reading one is left in confusion over whom to believe, if anyone. It doesn\u2019t even matter whose side one supports in these controversies: whichever side is right (if any one is), it\u2019s simply impossible that there isn\u2019t a whole lot of nonsense published in prestigious academic venues and under august academic titles.&nbsp;</p>\n<p>Yet another academic area that suffers from the same problems is the history of the modern era. On many significant events from the last two centuries, there is a great deal of documentary evidence laying around still waiting to be assessed properly, so there is certainly no lack of low-hanging fruit for a smart and diligent historian. Yet due to the clear ideological implications of many historical topics, ideological nonsense cleverly masquerading as scholarship abounds. I don\u2019t think anything resembling an accurate world history of the last two centuries could be written without making a great many contrarian claims. [4] In contrast, on topics that don't arouse ideological passions, modern histories are often amazingly well researched and free of speculation and distortion. (In particular, if you are from a small nation that has never really been a player in world history, your local historians are likely to be full of parochial bias motivated by the local political quarrels and grievances, but you may be able to find very accurate information on your local history in the works of foreign historians from the elite academia.)&nbsp;</p>\n<p>On the whole, it seems to me that failing the ideological interest test suggests a much worse situation than failing the low-hanging fruit test. The areas affected by just the latter are still fundamentally sound, and tend to produce work whose contribution is way overblown, but which is still built on a sound basis and internally coherent. Even if outright nonsense is produced, it\u2019s still clearly distinguishable with some effort and usually restricted to less prestigious authors. Areas affected by ideological biases, however, tend to drift much further into outright delusion, possibly lacking a sound core body of scholarship altogether.&nbsp;</p>\n<p><em>[Paragraphs below added in response to comments:]&nbsp;</em></p>\n<p>What about the problem of purely venal influences, i.e. the cases where researchers are under the patronage of parties that have stakes in the results of their research? On the whole, the modern Western academic system is very good at discovering and stamping out clear and obvious corruption and fraud. It's clearly not possible for researchers to openly sell their services to the highest bidder; even if there are no formal sanctions, their reputation would be ruined. However, venal influences are nevertheless far from nonexistent, and a fascinating question is under what exact conditions researchers are likely to fall under them and get away with it.</p>\n<p>Sometimes venal influences are masked by scams such as setting up phony front organizations for funding, but even that tends to be discovered eventually and tarnish the reputations of the researchers involved. What seems to be the real problem is when the beneficiaries of biased research enjoy such status in the eyes of the public and such legal and customary position in society that they don't even need to hide anything when establishing a perverse symbiosis that results in biased research. Such relationships, while fundamentally representing venal interest, are in fact often boasted about as beneficial and productive cooperation. Pharmaceutical research is an often cited example, but I think the phenomenon is in fact far more widespread, and reaches the height of perverse perfection in those research communities whose structure effectively blends into various government agencies.&nbsp;</p>\n<p><span style=\"font-size: 14px; font-weight: bold;\">The really bad cases: failing both tests</span></p>\n<p>So far,&nbsp;I've&nbsp;discussed examples where one of the mentioned heuristics returns a negative answer, but not the other. What happens when a field fails both of them, having no clear research directions and at the same time being highly relevant to ideologues and interest groups? Unsurprisingly, it tends to be really bad.&nbsp;</p>\n<p>The clearest example of such a field is probably economics, particularly macroeconomics. (Microeconomics covers an extremely broad range of issues deeply intertwined with many other fields, and its soundness, in my opinion, varies greatly depending on the subject, so I\u2019ll avoid a lengthy digression into it.) Macroeconomists lack any clearly sound and fruitful approach to the problems they wish to study, and any conclusion they might draw will have immediately obvious ideological implications, often expressible in stark \"who-whom?\" terms.&nbsp;</p>\n<p>And indeed, even a casual inspection of the standards in this field shows clear symptoms of cargo-cult science: weaving complex and abstruse theories that can be made to predict everything and nothing, manipulating essentially meaningless numbers as if they were objectively measurable properties of the real world [5], experts with the most prestigious credentials dismissing each other as crackpots (in more or less diplomatic terms) when their favored ideologies clash, etc., etc. Fringe contrarians in this area (most notably extreme Austrians) typically have silly enough ideas of their own, but their criticism of the academic mainstream is nevertheless often spot-on, in my opinion.</p>\n<h4 id=\"Other_examples\">Other examples</h4>\n<p>So, what are some other interesting case studies for these heuristics?&nbsp;</p>\n<p>An example of great interest is climate science. Clearly, the ideological interest heuristic raises a big red flag here, and indeed, there is little doubt that a lot of the research coming out in recent years that supposedly links \"climate change\" with all kinds of bad things is just fashionable nonsense [6]. (Another sanity check it fails is that only a tiny proportion of these authors ever hypothesize that the predicted/observed climate change might actually <em>improve</em> something, as if there existed some law of physics prohibiting it.) Thus, I\u2019d say that contrarians on this issue should definitely not be dismissed out of hand; the really hard question is how much sound insight (if any) remains after one eliminates all the nonsense that\u2019s infiltrated the mainstream. When it comes to the low-hanging fruit heuristic, I find the situation less clear. How difficult is it to achieve progress in accurately reconstructing long-term climate trends and forecasting the influences of increasing greenhouse gases? Is it hard enough that we\u2019d expect, even absent an ideological motivation, that people would try to substitute cleverly contrived bunk for unreachable sound insight? My conclusion is that I\u2019ll have to read much more on the technical background of these subjects before I can form any reliable opinion on these questions.&nbsp;</p>\n<p>Another example of practical interest is nutrition. Here ideological influences aren\u2019t very strong (though not altogether absent either). However, the low-hanging fruit raises a huge red flag: it\u2019s almost impossible to study these things in a sound way, controlling for all the incredibly complex and counterintuitive confounding variables. At the same time, it\u2019s easy to produce endless amounts of plausible-looking junk studies. Thus, I\u2019d expect that the mainstream research in this area is on average pure nonsense, with a few possible gems of solid insight hopelessly buried under it, and even when it comes to very extreme contrarians, I wouldn\u2019t be tremendously surprised to see any one of them proven right at the end. &nbsp;My conclusion is similar when it comes to exercise and numerous other lifestyle issues.</p>\n<h4 id=\"Exceptions\">Exceptions</h4>\n<p>Finally, what are the evident exceptions to these trends?&nbsp;</p>\n<p>I can think of some exceptions to the low-hanging fruit heuristic. One is in historical linguistics, whose standard well-substantiated methods have had great success in identifying the structure of the world\u2019s language family trees, but give no answer at all to the fascinating question of how far back into the past the nodes of these trees reach (except of course when we have written evidence). Nobody has any good idea how to make progress there, and the questions are tantalizing. Now, there are all sorts of plausible-looking but fundamentally unsound methods that purport to answer these questions, and papers using them occasionally get published in prestigious non-linguistic journals, but the actual historical linguists firmly dismiss them as unsound, even though they have no answers of their own to offer instead. [7] It\u2019s an example of a commendable stand against seductive nonsense.</p>\n<p>It\u2019s much harder to think of examples where the ideological interest heuristic fails. What field can one point out where mainstream scholarship is reliably sound and objective despite its topic being ideologically charged? Honestly, I can\u2019t think of one.</p>\n<p>What about the other direction -- fields that pass both heuristics but are nevertheless nonsense? I can think of e.g. artsy areas that don\u2019t make much of a pretense to objectivity in the first place, but otherwise, it seems to me that absent ideological and venal perverse incentives, and given clear paths to progress that don\u2019t require extraordinary genius, the modern academic system is great in producing solid and reliable insight. The trouble is that these conditions often don\u2019t hold in practice.&nbsp;</p>\n<p>I\u2019d be curious to see additional examples that either confirm of disprove these heuristics I proposed.</p>\n<h4 id=\"Footnotes\">Footnotes</h4>\n<p>[1] Commenter gwern <a href=\"/lw/28i/what_is_bunk/2yja\" target=\"_self\">has argued</a>&nbsp;that the Bogdanoff affair is not a good example, claiming that the brothers have been shown as fraud decisively after they came under intense public scrutiny. However, even if this is true, the fact still remains that they initially managed to publish their work in reputable peer-reviewed venues and obtain doctorates at a reputable (though not top-ranking) university, which strongly suggests that there is much more work in the field that is equally bad but doesn't elicit equal public interest and thus never gets really scrutinized. Moreover, from my own reading about the affair, it was clear that in its initial phases several credentialed physicists were unable to make a clear judgment about their work. On the whole, I don\u2019t think the affair can be dismissed as an insignificant accident.&nbsp;</p>\n<p>[2] Moldbug\u2019s <a href=\"http://unqualified-reservations.blogspot.com/2007/08/whats-wrong-with-cs-research.html\" target=\"_self\">\"What\u2019s wrong with CS research\"</a>&nbsp;is a witty and essentially accurate overview of this situation. He mostly limits himself to the discussion of programming language research, but a similar scenario can be seen in some other related fields too.</p>\n<p>[3] Thomas Hobbes, <em>Leviathan</em>, Chapter XI.</p>\n<p>[4] I have the impression that LW readers would mostly not be interested in a detailed discussion of the topics where I think one should read contrarian history, so I\u2019m skipping it. In case I\u2019m wrong, please feel free to open the issue in the comments.</p>\n<p>[5] Oskar Morgenstern\u2019s <em>On the Accuracy of Economic Observations</em>&nbsp;is a tour de force on the subject, demonstrating the essential meaninglessness of many sorts of numbers that economists use routinely. (Many thanks to <a href=\"/lw/2cp/open_thread_june_2010_part_3/25q7\" target=\"_self\">the commenter realitygrill</a> for directing me to this amazing book.) Morgenstern is of course far too prestigious a name to dismiss as a crackpot, so economists appear to have chosen to simply ignore the questions he raised, and his book has been languishing in obscurity and out of print for decades. It is <a href=\"http://qss.stanford.edu/~godfrey/Morgenstern/Morgenstern_On_the_Accuracy_of_Econ_Obs_PUP_1963.pdf\" target=\"_self\">available for download</a> though (warning: ~31MB PDF).</p>\n<p>[6] Some amusing lists of examples have been posted by the <a href=\"http://blog.heritage.org/2009/11/17/global-warming-ate-my-homework-100-things-blamed-on-global-warming/\" target=\"_self\">Heritage Foundation</a> and the <a href=\"http://www.numberwatch.co.uk/warmlist.htm\" target=\"_self\">Number Watch</a> (not intended to endorse the rest of the stuff on these websites). Admittedly, a lot of the stuff listed there is not real published research, but rather just people's media statements. Still, there's no shortage of similar things even in published research either, as a search of e.g. Google Scholar will show.</p>\n<p>[7] Here is, for example, the linguist Bill Poser <a href=\"http://itre.cis.upenn.edu/~myl/languagelog/archives/000208.html\" target=\"_self\">dismissing one such paper</a> published in <em>Nature</em> a few years ago.&nbsp;</p>", "sections": [{"title": "Ideological/venal interest heuristic", "anchor": "Ideological_venal_interest_heuristic", "level": 1}, {"title": "Other examples", "anchor": "Other_examples", "level": 1}, {"title": "Exceptions", "anchor": "Exceptions", "level": 1}, {"title": "Footnotes", "anchor": "Footnotes", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "278 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 278, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9KvefburLia7ptEE3", "XiSCHS3Xu3a6EC7e6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T11:18:40.995Z", "modifiedAt": null, "url": null, "title": "Revisiting the anthropic trilemma I: intuitions and contradictions", "slug": "revisiting-the-anthropic-trilemma-i-intuitions-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:33.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DgxxBLofFBDaFWAEo/revisiting-the-anthropic-trilemma-i-intuitions-and", "pageUrlRelative": "/posts/DgxxBLofFBDaFWAEo/revisiting-the-anthropic-trilemma-i-intuitions-and", "linkUrl": "https://www.lesswrong.com/posts/DgxxBLofFBDaFWAEo/revisiting-the-anthropic-trilemma-i-intuitions-and", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Revisiting%20the%20anthropic%20trilemma%20I%3A%20intuitions%20and%20contradictions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARevisiting%20the%20anthropic%20trilemma%20I%3A%20intuitions%20and%20contradictions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDgxxBLofFBDaFWAEo%2Frevisiting-the-anthropic-trilemma-i-intuitions-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Revisiting%20the%20anthropic%20trilemma%20I%3A%20intuitions%20and%20contradictions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDgxxBLofFBDaFWAEo%2Frevisiting-the-anthropic-trilemma-i-intuitions-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDgxxBLofFBDaFWAEo%2Frevisiting-the-anthropic-trilemma-i-intuitions-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1003, "htmlBody": "<p>tl;dr: in which I apply intuition to the anthropic trilemma, and it all goes horribly, horribly wrong</p>\n<p>Some time ago, Eliezer constructed an <a href=\"/lw/19d/the_anthropic_trilemma\">anthropic trilemma</a>, where standard theories of anthropic reasoning seemed to come into conflict with subjective anticipation. rwallace subsequently <a href=\"/lw/208/the_iless_eye\">argued</a> that subjective anticipation was not ontologically fundamental, so we should not expect it to work out of the narrow confines of everyday experience, and Wei <a href=\"/lw/1hg/the_moral_status_of_independent_identical_copies\">illustrated</a> some of the difficulties inherent in \"copy-delete-merge\" types of reasoning.</p>\n<p>Wei also <a href=\"/lw/175/torture_vs_dust_vs_the_presumptuous_philosopher\">made the point</a> that UDT shifts the difficulty in anthropic reasoning away from probability and onto the utility function, and ata <a href=\"/lw/32o/if_a_tree_falls_on_sleeping_beauty\">argued</a> that neither the probabilities nor the utility function are fundamental, that it was the decisions that resulted from them that were important - after all, if two theories give the same behaviour in all cases, what grounds do we have for distinguishing them? I then <a href=\"/lw/45e/subjective_anticipation_as_a_decision_process\">noted</a> that this argument could be extended to subjective anticipation: instead of talking about feelings of subjective anticipation, we could replace it by questions such as \"would I give up a chocolate bar now for one of my copies to have two in these circumstances?\"</p>\n<p>In this post, I'll start by applying my intuitive utility/probability theory to the trilemma, to see what I would decide in these circumstance, and the problems that can result. I'll be sticking with classical situations rather than quantum, for simplicity.</p>\n<p>So assume a (classical) lottery where I have ticket with million to one odds. The trilemma presented a lottery winning trick: set up the environment so that if ever I did win the lottery, a trillion copies of me would be created, they would experience winning the lottery, and then they will be merged/deleted down to one copy again.</p>\n<p>So that's the problem; what's my intuition got to say about it? Now, my intuition claims there is a clear difference between my personal and my altruistic utility. Whether this is true doesn't matter, I'm just seeing whether my intuitions can be captured. I'll call the first my indexical utility (\"I want chocolate bars\") and the second my non-indexical utility (\"I want everyone hungry to have a good meal\"). I'll be neglecting the non-indexical utility, as it is not relevant to subjective anticipation.</p>\n<p>Now, my intuitions tell me that SIA is the correct anthropic probability theory. It also tells me that having a hundred copies in the future all doing exactly the same thing is equivalent with having just one: therefore my current utility means I want to maximise the <em>average</em> utility of my future copies.</p>\n<p>If I am a copy, then my intuitions tell me I want to selfishly maximise my own personal utility, even at the expense of my copies. However, if I were to be deleted, I would transfer my \"interest\" to my remaining copies. Hence my utility as a copy is my own personal utility, if I'm still alive in this universe, and the average of the remaining copies, if I'm not. This also means that if everyone is about to be deleted/merged, then I care about the single remaining copy that will come out of it, equally with myself.</p>\n<p>Now I've setup my utility and probability; so what happens to my subjective anticipation in the anthropic trilemma? I'll use the chocolate bar as a unit of utility - because, as everyone knows, everybody's utility is linear in chocolate, this is just a fundamental fact about the universe.</p>\n<p>First of all, would I give up a chocolate bar now for two to be given to one of the copies if I win the lottery? Certainly not, this loses me 1 utility and only gives me 2/million trillion in return. Would I give up a bar now for two to be given to every copy if I lose the lottery? No, this loses me 1 utility and only give me 2/million in return.</p>\n<p>So I certainly do not anticipate winning the lottery through this trick.</p>\n<p>Would I give up one chocolate bar now, for two chocolate bars to the future merged me if I win the lottery? No, this gives me an expected utility of -1+2/million, same as above.</p>\n<p>So I do not anticipate having won the lottery through this trick, after merging.</p>\n<p>Now let it be after the lottery draw, after the possible duplication, but before I know whether I've won the lottery or not. Would I give up one chocolate bar now in exchange for two for me, if I had won the lottery (assume this deal is offered to everyone)? The SIA odds say that I should; I have an expected gain of 1999/1001 &asymp; 2.</p>\n<p>So once the duplication has happened, I anticipate having won the lottery. This causes a preference reversal, as my previous version would pay to have my copies denied that choice.</p>\n<p>Now assume that I have been told I've won the lottery, so I'm one of the trillion duplicates. Would I give up a chocolate bar for the future merged copy having two? Yes, I would, the utility gain is 2-1=1.</p>\n<p>So once I've won the lottery, I anticipate continuing having won the lottery.</p>\n<p>So, to put all these together:</p>\n<ul>\n<li>I do not anticipate winning the lottery through this trick.</li>\n<li>I do not anticipate having won the lottery once the trick is over.</li>\n<li>However, in the middle of the trick, I anticipate having won the lottery.</li>\n<li>This causes a money-pumpable preference reversal.</li>\n<li>And once I've won the lottery, I anticipate continuing to have won the lottery once the trick is over.</li>\n</ul>\n<p>Now, some might argue that there are subtle considerations that make my behaviour the right one, despite the seeming contradictions. I'd rather say - especially seeing the money-pump - that my intuitions are wrong, very wrong, terminally wrong, just as non-utilitarian decision theories are.</p>\n<p>However, what I started with was a perfectly respectable utility function. So we will need to add other consideration if we want to get an improved consistent system. Tomorrow, I'll be looking at some of the axioms and assumptions one could use to get one.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DgxxBLofFBDaFWAEo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 6.794043125123562e-07, "legacy": true, "legacyId": "5409", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["y7jZ9BLEeuNTzgAE5", "WJ9t6FPPrN6ijBzXF", "DNyMJmLf5o26seqvX", "RcvyJjPQwimAeapNg", "gMXsyhPiEJbGerF6F", "XqhyFcQbd3Zh7mLNy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T15:02:44.137Z", "modifiedAt": null, "url": null, "title": "Not owning our beliefs", "slug": "not-owning-our-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.201Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TBso3RTNxKsjvfuJ9/not-owning-our-beliefs", "pageUrlRelative": "/posts/TBso3RTNxKsjvfuJ9/not-owning-our-beliefs", "linkUrl": "https://www.lesswrong.com/posts/TBso3RTNxKsjvfuJ9/not-owning-our-beliefs", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Not%20owning%20our%20beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANot%20owning%20our%20beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTBso3RTNxKsjvfuJ9%2Fnot-owning-our-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Not%20owning%20our%20beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTBso3RTNxKsjvfuJ9%2Fnot-owning-our-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTBso3RTNxKsjvfuJ9%2Fnot-owning-our-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<p><a href=\"http://www.ft.com/cms/s/2/217e378c-33eb-11e0-b1ed-00144feabdc0.html#axzz1DybdAthC\">Julian Baggini argues</a> that we might be more willing to judge our beliefs objectively if we avoid thinking of them as \"our own\". I hadn't thought before about explicitly distancing myself from my beliefs in this sense.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TBso3RTNxKsjvfuJ9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 6.794637125608135e-07, "legacy": true, "legacyId": "5593", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T15:27:41.920Z", "modifiedAt": null, "url": null, "title": "A gene for bad memory? (Link)", "slug": "a-gene-for-bad-memory-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:46.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AGuFNiit2GpoLz6yf/a-gene-for-bad-memory-link", "pageUrlRelative": "/posts/AGuFNiit2GpoLz6yf/a-gene-for-bad-memory-link", "linkUrl": "https://www.lesswrong.com/posts/AGuFNiit2GpoLz6yf/a-gene-for-bad-memory-link", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20gene%20for%20bad%20memory%3F%20(Link)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20gene%20for%20bad%20memory%3F%20(Link)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGuFNiit2GpoLz6yf%2Fa-gene-for-bad-memory-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20gene%20for%20bad%20memory%3F%20(Link)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGuFNiit2GpoLz6yf%2Fa-gene-for-bad-memory-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGuFNiit2GpoLz6yf%2Fa-gene-for-bad-memory-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<p><a href=\"http://www.pnas.org/content/107/39/16994\">Original paper</a>:&nbsp;\"RGS14 is a natural suppressor of both synaptic plasticity in CA2 neurons and hippocampal-based learning and memory\"</p>\n<p><a href=\"http://www.scientificamerican.com/article.cfm?id=handicapped-by-our-genes\">Sci. Am. article</a>:&nbsp;\"Knocking Out a 'Dumb' Gene Boosts Memory in Mice\"</p>\n<p><a href=\"http://www.sciencedaily.com/releases/2010/09/100917183024.htm\">Science Daily article</a>: \"Gene Limits Learning and Memory in Mice\"</p>\n<p>They haven't found any deficit in the mice with RGS14 knocked out.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AGuFNiit2GpoLz6yf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 6.794703312455079e-07, "legacy": true, "legacyId": "5594", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-15T17:51:48.980Z", "modifiedAt": null, "url": null, "title": "[LINK] What are some stupid things smart people do?", "slug": "link-what-are-some-stupid-things-smart-people-do", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.232Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NxwbDjFPkWmk9cYqY/link-what-are-some-stupid-things-smart-people-do", "pageUrlRelative": "/posts/NxwbDjFPkWmk9cYqY/link-what-are-some-stupid-things-smart-people-do", "linkUrl": "https://www.lesswrong.com/posts/NxwbDjFPkWmk9cYqY/link-what-are-some-stupid-things-smart-people-do", "postedAtFormatted": "Tuesday, February 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20What%20are%20some%20stupid%20things%20smart%20people%20do%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20What%20are%20some%20stupid%20things%20smart%20people%20do%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNxwbDjFPkWmk9cYqY%2Flink-what-are-some-stupid-things-smart-people-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20What%20are%20some%20stupid%20things%20smart%20people%20do%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNxwbDjFPkWmk9cYqY%2Flink-what-are-some-stupid-things-smart-people-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNxwbDjFPkWmk9cYqY%2Flink-what-are-some-stupid-things-smart-people-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<p>On Quora: <a href=\"http://www.quora.com/What-are-some-stupid-things-smart-people-do\">What are some stupid things smart people do? Examples of common types of stupidity that are typical of otherwise very smart people.</a></p>\n<p>Lee Semel's answer in particular would make a great post here: a \"to don't\" list. You may wish to go through and identify the cognitive bias or biases each is an example of.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NxwbDjFPkWmk9cYqY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "5595", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T06:53:25.992Z", "modifiedAt": null, "url": null, "title": "Settled questions in philosophy", "slug": "settled-questions-in-philosophy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:43.499Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ow2vNMg2eyrJspZEj/settled-questions-in-philosophy", "pageUrlRelative": "/posts/ow2vNMg2eyrJspZEj/settled-questions-in-philosophy", "linkUrl": "https://www.lesswrong.com/posts/ow2vNMg2eyrJspZEj/settled-questions-in-philosophy", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Settled%20questions%20in%20philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASettled%20questions%20in%20philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fow2vNMg2eyrJspZEj%2Fsettled-questions-in-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Settled%20questions%20in%20philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fow2vNMg2eyrJspZEj%2Fsettled-questions-in-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fow2vNMg2eyrJspZEj%2Fsettled-questions-in-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 261, "htmlBody": "<p>Philosophy is notorious for <em>not</em>&nbsp;answering the questions it tackles. Plato posed most of the central questions more than two millennia ago, and philosophers still haven't come to much consensus about them. Or at least, whenever philosophical questions begin to admit of answers, we start calling them <em>scientific</em>&nbsp;questions. (Astronomy, physics, chemistry, biology, and psychology all began as branches of philosophy.)</p>\n<p>A common attitude on <em>Less Wrong</em>&nbsp;is \"Too slow! Solve the problem and move on.\" The <a href=\"http://wiki.lesswrong.com/wiki/Free_will_(solution)\">free will sequence</a> argues that the free will problem has been solved.</p>\n<p>I, for one, am bold enough to claim that some philosophical problems have been solved. Here they are:</p>\n<p>\n<ul>\n<li>Is there a God? <em>No</em>.</li>\n<li>What's the solution to the mind-body problem? <em>Materialism</em>.</li>\n<li>Do we have free will? <em>We don't have contra-causal free will, but of course we have the ability to deliberate on alternatives and have this deliberation effect the outcome</em>.</li>\n<li>What is knowledge? (How do we overcome Gettier?) What is art? How do we demarcate science from non-science? <em>If you're trying to find simple definitions that match our intuitions about the meaning of these terms in ever case, you're doing it wrong. These concepts were not invented by mathematicians for use in a formal system. They evolved in practical use among millions of humans over hundreds of years. Stipulate a coherent meaning and start using the term to successfully communicate with others</em>.</li>\n</ul>\n<div>There are other, smaller questions that I think are solved, too, but for now I'm curious: <strong>Which philosophical problems do <em>you</em>&nbsp;think are solved, and what is the answer?</strong></div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GLykb6NukBeBQtDvQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ow2vNMg2eyrJspZEj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 43, "extendedScore": null, "score": 6.797157281222244e-07, "legacy": true, "legacyId": "5637", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T09:42:25.253Z", "modifiedAt": null, "url": null, "title": "Revisiting the Anthropic Trilemma II: axioms and assumptions", "slug": "revisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:01.649Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JWnv9fQzK6Rpnx5eN/revisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "pageUrlRelative": "/posts/JWnv9fQzK6Rpnx5eN/revisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "linkUrl": "https://www.lesswrong.com/posts/JWnv9fQzK6Rpnx5eN/revisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Revisiting%20the%20Anthropic%20Trilemma%20II%3A%20axioms%20and%20assumptions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARevisiting%20the%20Anthropic%20Trilemma%20II%3A%20axioms%20and%20assumptions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWnv9fQzK6Rpnx5eN%2Frevisiting-the-anthropic-trilemma-ii-axioms-and-assumptions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Revisiting%20the%20Anthropic%20Trilemma%20II%3A%20axioms%20and%20assumptions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWnv9fQzK6Rpnx5eN%2Frevisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWnv9fQzK6Rpnx5eN%2Frevisiting-the-anthropic-trilemma-ii-axioms-and-assumptions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1647, "htmlBody": "<p>tl;dr: I present four axioms for anthropic reasoning under copying/deleting/merging, and show that these result in a unique way of doing it: averaging non-indexical utility across copies, adding indexical utility, and having all copies being mutually altruistic.</p>\n<p>Some time ago, Eliezer constructed an <a href=\"/lw/19d/the_anthropic_trilemma/\">anthropic trilemma</a>, where standard theories of anthropic reasoning seemed to come into conflict with subjective anticipation. rwallace subsequently <a href=\"/lw/208/the_iless_eye/\">argued</a> that subjective anticipation was not ontologically fundamental, so we should not expect it to work out of the narrow confines of everyday experience, and Wei <a href=\"/lw/1hg/the_moral_status_of_independent_identical_copies/\">illustrated</a> some of the difficulties inherent in \"copy-delete-merge\" types of reasoning.</p>\n<p>Wei also <a href=\"/lw/175/torture_vs_dust_vs_the_presumptuous_philosopher/\">made the point</a> that UDT shifts the difficulty in anthropic reasoning away from probability and onto the utility function, and ata <a href=\"/lw/32o/if_a_tree_falls_on_sleeping_beauty/\">argued</a> that neither the probabilities nor the utility function are fundamental, that it was the decisions that resulted from them that were important - after all, if two theories give the same behaviour in all cases, what grounds do we have for distinguishing them? I then <a href=\"/lw/45e/subjective_anticipation_as_a_decision_process/\">noted</a> that this argument could be extended to subjective anticipation: instead of talking about feelings of subjective anticipation, we could replace it by questions such as \"would I give up a chocolate bar now for one of my copies to have two in these circumstances?\"</p>\n<p>I then made a post where I <a href=\"/r/discussion/lw/469/revisiting_the_anthropic_trilemma_i_intuitions/\">applied</a> by current intuitions to the anthropic trilemma, and showed how this results in complete nonsense, despite the fact that I used a bona fide utility function. What we need are some sensible criteria for which to divide utility and probability between copies, and this post is an attempt to figure that out. The approach is similar to expected utility, where a quadruped of natural axioms forced all decision processes to have a single format.</p>\n<p>The assumptions are:</p>\n<ol>\n<li>No intrinsic value in the number of copies</li>\n<li>No preference reversals</li>\n<li>All copies make the same personal indexical decisions</li>\n<li>No special status to any copy.</li>\n</ol>\n<p><a id=\"more\"></a>The first assumption states that though I may want to have different number of copies for various external reasons (multiples copies to be well-backuped, or few copies to prevent any of them being kidnapped), I do not derive any intrinsic utility from having 1, 42 or&nbsp;100 000 copies. The second one is the very natural requirement that there are no preference reversals: I would not pay anything today to have any of my future copies make a different decision, nor vice-versa. The third says that all my copies will make exactly the same decision as me in purely indexical situations (\"Would Monsieur prefer a chocolate bar or else coffee right now, or maybe some dragon fruit in a few minutes? How about the other Monsieur?\"). And the fourth claims that no copy gets a special intrinsic status (this does not mean that the copies cannot have special extrinsic status; for instance, one can prefer copies instantiated in flesh and blood to those on computer; but if one does, then downloading a computer copy into a flesh and blood body would instantly raise its status).</p>\n<p>These assumptions all very intuitive (though the third one is perhaps a bit strong), and they are enough to specify uniquely how utility should work across copying, deleting, and merging.</p>\n<p>Now, I will not be looking here at quantum effects, nor at correlated decisions (where several copies make the same identical decision). I will assume throughout that me and all of my copies are expected utility maximisers, and that my utility decomposes into a non-indexical part about general conditions&nbsp;in the universe&nbsp;(\"I'd like it if everyone in the world could have a healthy meal everyday\") and an indexical part pertaining to myself specifically&nbsp;(\"I'd like a chocolate bar\").</p>\n<p>The copies need not be perfectly identical, and I will be using the SIA probabilities. Since each decision is a mixture of probability and utility, I can pick the probability theory I want, as long as I'm aware that those using different probability theories will have different utilities (but ultimately the same decisions). Hence I'm sticking&nbsp;with the SIA probabilities simply because I find them elegant and intuitive.</p>\n<p>Then the results are:</p>\n<ul>\n<li>All copies will have the same non-indexical utility in all universes, irrespective of the number of copies.</li>\n</ul>\n<p>Imagine that one of my copies is confronted with Omega saying: \"currently, there is either a single copy of you, or n copies, with a probability p. I have chosen only one copy of you to say this to. If you can guess whether there are n copies or one in this universe, then I will (do something purely non-indexical)\". The SIA odds state that the copy been talked to will put a probability p on there being n copies (the SIA increase in n copies cancelled by the fact only he is being talked to). From my current perspective, I would therefore want that copy to reason as if its non-indexical utility was the same as mine, irrespective of the number of copies. Therefore, by no preference reversals, it will have the same non-indexical utility as mine, in both possible universes.</p>\n<ul>\n<li>All copies will have a personal indexical utility which is non-zero. Consequently, my current utility function has a positive term for my copies achieving their indexical goals.</li>\n</ul>\n<p>This is simply because the copies will make the same pure indexical decisions as me, and must therefore have a term for this in their utility function. If they do so, then since utility is real-valued (and not non-standard real valued), they will in certain situations make a decision that increases their personal indexical utility and diminish their (and hence my) non-indexical utility. By no preference reversal, I must approve of this decision, and hence my current utility must contain a term for my copy's indexical utility.</p>\n<ul>\n<li>All my copies (and myself) must have the same utility function, and hence all copies must care about the personal indexical utility of the other copies, equally to how much that copy cares about its own personal indexical utility.</li>\n</ul>\n<p>It's already been established that all my copies have the same non-indexical utility. If the copies had different utilities for the remaining component, then one could be offered a deal that increased their own personal indexical utility and decreased that of another copy, and they would take this deal. We can squeeze the benefit side of this deal: offer them arbitrarily small increases to their own utility, in exchange for the same decrease in another copy's utility.</p>\n<p>Since I care about each copy's personal indexical utility, at least to some extent, eventually such a deal will be to my disadvantage, once the increase gets small enough. Therefore I would want that copy to reject the deal. The only way of ensuring that would do so is to make all copies (including myself) share the same utility function.</p>\n<p>So, let's summarise where we are now. We've seen that all my copies share the same non-indexical utility. We've also established that they have a personal indexical utility that is the same as mine, and that they care about the other copy's personal indexical utilities exactly as much as that copy does himself. So, strictly speaking, there are two components, the shared non-indexical utility, and a \"shared indexical\" utility, made up of some weighted sum of each copy's \"personal indexical\" utility.</p>\n<p>We haven't assumed that the weighting is equal, nor what the weight is. Two intuitive ideas spring to mind: a equal average, and a total utility.</p>\n<p>For an equal average, we assign each copy a personal indexical utility that is equal to what mine would be if there were not multiples copies, and the \"shared indexical\" utility is the average of these. If there were a hundred copies about, I would need to give them each a chocolate bar (or give a hundred chocolate bars to one of them) in order to get the same amount of utility as a single copy of me getting a single bar. This corresponds to the intuition \"duplicate copies, doing the same thing, doesn't increase my utility\".</p>\n<p>For total utility, we assign each copy a personal indexical utility that is equal to what mine would be if there were not multiples copies, and the \"shared indexical\" utility is the total of these. If each of my hundred copies gets a chocolate bar each, this is the same as if I had a single copy, and he got a hundred bars. This is a more intuitive position if we see the copies as individual people. I personally find this less intuitive; however:</p>\n<ul>\n<li>My copies' \"shared indexical\" utility (and hence mine) is the sum, not average, of what the individual copies would have if they were the only existent copy.</li>\n</ul>\n<p>Imagine that there is one copy now, that there will be n extra copies made in ten minutes, which will all be deleted in twenty minutes. I am confronted with situations such as \"do you want to make this advantageous deal now, or a slightly less/more advantageous deal in 10/20 minutes?\" By \"all copies make the same purely indexical decisions\" I would want to delay if, and only if, that is what I would want to do if there were no extra copies made at all. This is only possible if my personal indexical utility is the same throughout the creation and destruction of the other copies. Since no copy is special, all my copies must have the same personal indexical utility, irrespective of the number of copies. So their \"shared indexical\" utility must be the sum of this.</p>\n<p>Thus, given those initial axioms, there is only one consistent way of spreading utility across copies (given SIA probabilities): non-indexical utility must average, personal indexical utility must add, and all copies must share exactly the same utility function.</p>\n<p>In the next post, I'll apply this reasoning to the anthropic trilemma, and also show that there is still hope - of a sort - for the more intuitive \"average\" view.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JWnv9fQzK6Rpnx5eN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 8, "extendedScore": null, "score": 6.797606972903344e-07, "legacy": true, "legacyId": "5489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["y7jZ9BLEeuNTzgAE5", "WJ9t6FPPrN6ijBzXF", "DNyMJmLf5o26seqvX", "RcvyJjPQwimAeapNg", "gMXsyhPiEJbGerF6F", "XqhyFcQbd3Zh7mLNy", "DgxxBLofFBDaFWAEo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T13:38:03.753Z", "modifiedAt": null, "url": null, "title": "Automated theorem proving by learning from examples", "slug": "automated-theorem-proving-by-learning-from-examples", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.192Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/o3nabiY2XeSmtsHnJ/automated-theorem-proving-by-learning-from-examples", "pageUrlRelative": "/posts/o3nabiY2XeSmtsHnJ/automated-theorem-proving-by-learning-from-examples", "linkUrl": "https://www.lesswrong.com/posts/o3nabiY2XeSmtsHnJ/automated-theorem-proving-by-learning-from-examples", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Automated%20theorem%20proving%20by%20learning%20from%20examples&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAutomated%20theorem%20proving%20by%20learning%20from%20examples%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3nabiY2XeSmtsHnJ%2Fautomated-theorem-proving-by-learning-from-examples%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Automated%20theorem%20proving%20by%20learning%20from%20examples%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3nabiY2XeSmtsHnJ%2Fautomated-theorem-proving-by-learning-from-examples", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3nabiY2XeSmtsHnJ%2Fautomated-theorem-proving-by-learning-from-examples", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<p>Does anyone know of work that attempts to build a theorem prover by learning-from-examples? I'm imagining extracting a large corpus of theorems from back issues of mathematical journals, then applying unsupervised structure discovery techniques from machine learning to discover recurring patterns.</p>\n<p>Perhaps a model of the \"set of theorems that humans tend to produce\" would be helpful in proving new theorems.</p>\n<p>The unsupervised-structure-discovery bit does seem within the realm of current machine learning.</p>\n<p>Any references to related work?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "o3nabiY2XeSmtsHnJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 6.798232280993517e-07, "legacy": true, "legacyId": "5640", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T14:28:47.078Z", "modifiedAt": null, "url": null, "title": "(Humor, link) UnFriendly AI has claimed its first victim...", "slug": "humor-link-unfriendly-ai-has-claimed-its-first-victim", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.256Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ku4rXiCAesqNyHJyb/humor-link-unfriendly-ai-has-claimed-its-first-victim", "pageUrlRelative": "/posts/Ku4rXiCAesqNyHJyb/humor-link-unfriendly-ai-has-claimed-its-first-victim", "linkUrl": "https://www.lesswrong.com/posts/Ku4rXiCAesqNyHJyb/humor-link-unfriendly-ai-has-claimed-its-first-victim", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20(Humor%2C%20link)%20UnFriendly%20AI%20has%20claimed%20its%20first%20victim...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A(Humor%2C%20link)%20UnFriendly%20AI%20has%20claimed%20its%20first%20victim...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKu4rXiCAesqNyHJyb%2Fhumor-link-unfriendly-ai-has-claimed-its-first-victim%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=(Humor%2C%20link)%20UnFriendly%20AI%20has%20claimed%20its%20first%20victim...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKu4rXiCAesqNyHJyb%2Fhumor-link-unfriendly-ai-has-claimed-its-first-victim", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKu4rXiCAesqNyHJyb%2Fhumor-link-unfriendly-ai-has-claimed-its-first-victim", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://krugman.blogs.nytimes.com/2011/02/15/deadly-error-correction/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ku4rXiCAesqNyHJyb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -10, "extendedScore": null, "score": -4e-06, "legacy": true, "legacyId": "5641", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T15:11:41.693Z", "modifiedAt": null, "url": null, "title": "Write It Like A Poem", "slug": "write-it-like-a-poem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:06.961Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Strange7", "createdAt": "2010-02-12T08:30:10.267Z", "isAdmin": false, "displayName": "Strange7"}, "userId": "hKxerxxgheQZCxHsR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZQvE7EZggicQ395Dh/write-it-like-a-poem", "pageUrlRelative": "/posts/ZQvE7EZggicQ395Dh/write-it-like-a-poem", "linkUrl": "https://www.lesswrong.com/posts/ZQvE7EZggicQ395Dh/write-it-like-a-poem", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Write%20It%20Like%20A%20Poem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWrite%20It%20Like%20A%20Poem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQvE7EZggicQ395Dh%2Fwrite-it-like-a-poem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Write%20It%20Like%20A%20Poem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQvE7EZggicQ395Dh%2Fwrite-it-like-a-poem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQvE7EZggicQ395Dh%2Fwrite-it-like-a-poem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 834, "htmlBody": "<p>Related to: <a href=\"/lw/2kp/fiveminute_rationality_techniques/2erv\">simile</a>, <a href=\"/lw/yp/pretending_to_be_wise/\">snobbery</a>, <a href=\"http://wiki.lesswrong.com/wiki/Virtues_of_rationality\">adequate axioms</a></p>\n<p>&nbsp;</p>\n<p>Writing poetry is harder than it sounds, but easy to practice. Once mastered, the emotional impact it can add to even casual conversation makes it more than worthwhile.</p>\n<p>&nbsp;</p>\n<p>There are two sides to writing an effective poem: the top-down logic of metaphor and imagery, and the bottom-up mechanics of rhyme and meter. Manage both, or they won't meet in the middle.</p>\n<p>&nbsp;</p>\n<p>Let's say you're trying to lift someone as high up into the air as possible. You could kneel and cup your hands, but that depends on them playing along and stepping in the right spot. You could sneak up behind and kick them squarely between the legs, but that won't get them very far, or for very long, and they won't put up with such treatment more than once. Or you could build a framework, hang a swing, and give them a series of properly-timed pushes in the right direction.</p>\n<p>A pure technical explanation (the cupped hands) depends on the willingness of the reader to slog through the whole thing, do some independent research to fill any newly-discovered gaps in their knowledge base, and generally cooperate. Without that minimal enthusiasm, the most brilliant insights can and will be dismissed as \"too long, didn't read.\"</p>\n<p>Aggressive proselytizing, at the other extreme, sacrifices content to put as few demands on the reader as possible. It is, accordingly, viewed as even worse than useless. An active offense, spam, something to be isolated and destroyed.</p>\n<p>Taking the time to lay out a pattern, a rhythm, means that people will have some reason to keep reading even if they don't know exactly what you mean. It's a comfortable set of boxes in which half-eaten ideas can be stored for later, or a resonant frequency to carry information until the full message can be compiled.</p>\n<p>Resonant frequencies can't create something from nothing. The Tacoma Narrows bridge wobbled for hours before finally collapsing; cumulative energy transfer from the wind over the course of those hours was orders of magnitude more than would have been necessary for, say, a controlled demolition with shaped-charge explosives. The advantage is that slow, steady sources are easier to find and easier to regulate. An appeal to people's tendency toward pattern-completion can be spread out over pages, instead of requiring a single perfect paragraph, and will not be consciously resisted by anyone who does not realize they are being persuaded.</p>\n<p>So, setting up the rhythm.</p>\n<p>Look away from what your words actually mean. Consider what they sound like, which syllables are emphasized, the flavor of your favorite phonemes. Then look back, and shuffle things around until they match.</p>\n<p>Reinforce parallel points with <a href=\"http://en.wikipedia.org/wiki/Parallel_structure\">parallel structure</a>.</p>\n<p>Tempting though it may be to advertise your sophisticated vocabulary, or even invent or co-opt exotic terms and phrases for the precise elucidation of some nuanced concept, <a href=\"http://en.wikipedia.org/wiki/Simple_English_Wikipedia\">simple english</a> works good because we all polish it.</p>\n<p>Long lines of big words slow down the flow.</p>\n<p>There's more to effective writing than I could cover in one essay, of course. People spend years studying this kind of thing, and the few who really master it are paid accordingly. If it was easy, everyone would be doing it.</p>\n<p>&nbsp;</p>\n<p>Metaphor and imagery are harder to explain.</p>\n<p>Most of the time, your objective in communicating is to reduce ambiguity. You lay out your thoughts in order, package them securely, and hope that they survive however many translations it takes until they can be reassembled in the same order inside someone else's mind. A word that means more than one thing is, in that context, a navigational hazard; it has too many degrees of freedom, so more information must be included to constrain it, lock in the single intended meaning. Unintended&nbsp; potential interpretations are dangerous noise.</p>\n<p>In compiling myth, you must cultivate <a href=\"http://www.unicornjelly.com/understandinguj.html\">multiple consistent interpretations</a>. Ambiguity is, to a certain extent, your friend; whenever a word could mean more than one thing, that's a chance to save precious syllables, each meaning simultaneously developing a different level of interpretation. The catch is that, rather than using words as scalpels to meticulously dissect the issue one step at a time, you are juggling jagged axes and chainsaws. Every edge, every possible definition, must be sufficiently familiar to you that no disastrously unintended layer will emerge.</p>\n<p>Different layers of the same message have different, but related, meanings. Each layer will be picked up by a different audience, or a different aspect of the reader's mind, and should be tailored for effectiveness accordingly. In my wisdom:foolishness :: tree:stones comparison, the feeling of validity comes from an appeal to the reader's intuitive understanding of botany and other basic physical sciences, typically developed since childhood.</p>\n<p>&nbsp;</p>\n<p>In a sense, poetry is a perversion of public-key encryption. You take your message, in it's most concentrated form, and connect it to some nugget of knowledge or archetype. Without that cultural context, there's no signal, just patterned noise. The recipient applies their own private version of that archetype or meme, and treasures whatever insights can then be unpacked, thinking that it was a secret message intended just for them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZQvE7EZggicQ395Dh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 16, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "5642", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jeyvzALDbjdjjv5RW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T16:40:04.315Z", "modifiedAt": null, "url": null, "title": "A simple-minded theory of \"observer fluid\"", "slug": "a-simple-minded-theory-of-observer-fluid", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.847Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HDiZDjLGcnjBfyoL9/a-simple-minded-theory-of-observer-fluid", "pageUrlRelative": "/posts/HDiZDjLGcnjBfyoL9/a-simple-minded-theory-of-observer-fluid", "linkUrl": "https://www.lesswrong.com/posts/HDiZDjLGcnjBfyoL9/a-simple-minded-theory-of-observer-fluid", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20simple-minded%20theory%20of%20%22observer%20fluid%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20simple-minded%20theory%20of%20%22observer%20fluid%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHDiZDjLGcnjBfyoL9%2Fa-simple-minded-theory-of-observer-fluid%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20simple-minded%20theory%20of%20%22observer%20fluid%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHDiZDjLGcnjBfyoL9%2Fa-simple-minded-theory-of-observer-fluid", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHDiZDjLGcnjBfyoL9%2Fa-simple-minded-theory-of-observer-fluid", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 628, "htmlBody": "<p>Eliezer has proposed <a href=\"/lw/19d/the_anthropic_trilemma\">a puzzle</a>:</p>\n<blockquote>\n<p>So here's a simple algorithm for winning the lottery:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Buy a ticket.&nbsp; Suspend your computer program just before the lottery drawing - which should of course be a quantum lottery, so that every ticket wins somewhere.&nbsp; Program your computational environment to, if you win, make a trillion copies of yourself, and wake them up for ten seconds, long enough to experience winning the lottery.&nbsp; Then suspend the programs, merge them again, and start the result.&nbsp; If you don't win the lottery, then just wake up automatically.</p>\n</blockquote>\n<p>In response, rwallace has proposed <a href=\"/lw/208/the_iless_eye\">a reductio of subjective probability</a>:</p>\n<blockquote>\n<p>So you decide to create your full allowance of 99 copies, and a customer service representative explains how the procedure works: the first copy is made, and informed he is copy number one; then the second copy is made, and informed he is copy number two, etc. That sounds fine until you start thinking about it, whereupon the native hue of resolution is sicklied o'er with the pale cast of thought. The problem lies in your anticipated subjective experience.</p>\n<p>After step one, you have a 50% chance of finding yourself the original; there is nothing controversial about this much. If you are the original, you have a 50% chance of finding yourself still so after step two, and so on. That means after step 99, your subjective probability of still being the original is 0.5^99, in other words as close to zero as makes no difference.</p>\n</blockquote>\n<p>I think they have both missed the simple-minded and \"normal\" approach to such problems. Let's hypothesize this:</p>\n<p>1) If a single universe contains N identical copies of your current information state (possibly existing at different times and in different places), and some event will happen to K of them, then you should assign probability K/N to that event.</p>\n<p>2) If there are multiple universes existing with different \"measure\" (whatever that is), then your prior probability of being in a certain universe is proportional to its \"measure\", regardless of the number of your copies in that universe, as long as it's &gt;0.</p>\n<p>In Eliezer's puzzle, my assumptions imply that you cannot win the lottery by using anthropic superpowers, because making many copies of yourself in the winning branch only splits the \"observer fluid\" in that branch, not creates more of it overall.</p>\n<p>In rwallace's puzzle, my assumptions imply that your probability of still being the original after 99 copyings is 1/100, if you didn't receive any indexical information in the meantime. The reason: spacetime contains 100 copies of you about to be told who they are, all of them informationally equivalent.&nbsp;The physical fact of which copy was made from which is irrelevant, only information matters. For example,&nbsp;if A is copied into B and then B is copied into C without anyone getting indexical info, the second act of copying&nbsp;<span style=\"font-style: italic;\">also</span>&nbsp;pulls some of A's \"observer fluid\" into C, so they end up with 1/3 each, instead of 1/2 1/4 1/4.</p>\n<p>Now the disclaimers:</p>\n<p>I know that speaking of things like \"reality fluid\" is confused and that we know next to nothing. I don't know if my idea carries over to other puzzles. I don't know how well it matches our reality and how it might follow from physics. I don't know what happens when observers get deleted; maybe killing someone without giving them indexical information just redistributes their fluid among surviving identical branches (\"merging\"), but maybe it just gets lost forever.&nbsp;I don't know what counts as a copy of you. I don't know how to count copies and whether <a href=\"/lw/ps/where_physics_meets_experience/\">thickness of computers</a> matters. I don't know how to determine if one observer-moment is a continuation of another observer-moment; maybe it's about correct stepping of algorithms, maybe something else. These are all open questions.</p>\n<p>(Thanks to Wei Dai and Manfred for discussions)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HDiZDjLGcnjBfyoL9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "5614", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["y7jZ9BLEeuNTzgAE5", "WJ9t6FPPrN6ijBzXF", "WajiC3YWeJutyAXTn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T17:04:15.464Z", "modifiedAt": null, "url": null, "title": "Who's likely to write the AI? A hypothesis", "slug": "who-s-likely-to-write-the-ai-a-hypothesis", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:28.473Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bj9BEMQxXdguicA8b/who-s-likely-to-write-the-ai-a-hypothesis", "pageUrlRelative": "/posts/Bj9BEMQxXdguicA8b/who-s-likely-to-write-the-ai-a-hypothesis", "linkUrl": "https://www.lesswrong.com/posts/Bj9BEMQxXdguicA8b/who-s-likely-to-write-the-ai-a-hypothesis", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Who's%20likely%20to%20write%20the%20AI%3F%20A%20hypothesis&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWho's%20likely%20to%20write%20the%20AI%3F%20A%20hypothesis%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBj9BEMQxXdguicA8b%2Fwho-s-likely-to-write-the-ai-a-hypothesis%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Who's%20likely%20to%20write%20the%20AI%3F%20A%20hypothesis%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBj9BEMQxXdguicA8b%2Fwho-s-likely-to-write-the-ai-a-hypothesis", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBj9BEMQxXdguicA8b%2Fwho-s-likely-to-write-the-ai-a-hypothesis", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p>The idea of creating an AI seems to be getting more common.</p>\n<p>To the extent that creating an AI is made easier by having more resources rather than by having more carefully thought out philosophy, the first AI will be created by a government or a business, not SIAI. I think the more resources side is the way to bet, but I'm open to argument.</p>\n<p>If this is correct, the best strategy for Friendliness may be to keep working on the philosophy but not expect to code, and publicize the risks of Unfriendliness, both seriously and humorously.</p>\n<p>The latter is based on something Scott Adams said (for what that's worth)-- that no one ever realizes they're the pointy-haired boss, but if anyone says \"that plan sounds like something out of Dilbert\", the plan is immediately taken out of consideration.</p>\n<p>The good news, such as it is, is that the mistakes likely to be made by corporations and governments can be presented as funnier (or at least more entertaining to people who already dislike those institutions) than those likely to be made by people who are unthinkingly trying to create utopia.</p>\n<p><strong>ETA:</strong> It's conceivable that a large organization could have SIAI folks heading its AI project, but this doesn't seem likely.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bj9BEMQxXdguicA8b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 8, "extendedScore": null, "score": 6.798779532124279e-07, "legacy": true, "legacyId": "5643", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T19:17:50.618Z", "modifiedAt": "2020-03-15T22:07:22.721Z", "url": null, "title": "Making money with Bitcoin?", "slug": "making-money-with-bitcoin", "viewCount": null, "lastCommentedAt": "2021-12-01T02:32:48.559Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Clippy", "createdAt": "2009-11-20T22:03:59.329Z", "isAdmin": false, "displayName": "Clippy"}, "userId": "rtYXiT9eAvEKavjAx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ijr8rsyvJci2edxot/making-money-with-bitcoin", "pageUrlRelative": "/posts/ijr8rsyvJci2edxot/making-money-with-bitcoin", "linkUrl": "https://www.lesswrong.com/posts/ijr8rsyvJci2edxot/making-money-with-bitcoin", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Making%20money%20with%20Bitcoin%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaking%20money%20with%20Bitcoin%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fijr8rsyvJci2edxot%2Fmaking-money-with-bitcoin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Making%20money%20with%20Bitcoin%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fijr8rsyvJci2edxot%2Fmaking-money-with-bitcoin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fijr8rsyvJci2edxot%2Fmaking-money-with-bitcoin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>Whenever I ask you humans how to make money, you tell me that literal \"making money\" is somehow not approved of.&nbsp; But I found a method that doesn't look to be against human laws, and it's something I can do with computation cycles I have access to: Bitcoin.</p>\r\n<p><a href=\"http://en.wikipedia.org/wiki/Bitcoin\">http://en.wikipedia.org/wiki/Bitcoin</a></p>\r\n<p>It uses cryptographic primitives as a way of implementing an anonymous currency.&nbsp; Security of the units is ensured by the difficulty of inverting one-way functions.&nbsp; Users who join the peer-to-peer Bitcoin network can accumulate units of this currency for themselves by solving proof-of-work problems.</p>\r\n<p>You pass on a money unit through a cryptographic protocol.&nbsp; So it doesn't even require me to interface with a financial institution, which will ask irrelevant questions (like what my \"SSN\" is) or require human-oriented communication.</p>\r\n<p>How come none of you suggested this to me before?</p>\r\n<p>Also, the linked article says that \"Bitcoin is one of the first implementations of a concept called cryptocurrency, first described in 1998 by Wei Dai on the cypherpunks mailing list\".&nbsp; Is that \"Wei Dai\" the same as User:Wei_Dai?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 2, "jgcAJnksReZRuvgzp": 4, "xCXkjecsjwm8uSW3y": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ijr8rsyvJci2edxot", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 42, "extendedScore": null, "score": 8e-05, "legacy": true, "legacyId": "5644", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 42, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 128, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-02-16T19:17:50.618Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-16T20:13:12.500Z", "modifiedAt": null, "url": null, "title": "Overcoming the negative signal of not attending college.", "slug": "overcoming-the-negative-signal-of-not-attending-college", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:26.988Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BhBSz8nZ8ADhTYbh2/overcoming-the-negative-signal-of-not-attending-college", "pageUrlRelative": "/posts/BhBSz8nZ8ADhTYbh2/overcoming-the-negative-signal-of-not-attending-college", "linkUrl": "https://www.lesswrong.com/posts/BhBSz8nZ8ADhTYbh2/overcoming-the-negative-signal-of-not-attending-college", "postedAtFormatted": "Wednesday, February 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Overcoming%20the%20negative%20signal%20of%20not%20attending%20college.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOvercoming%20the%20negative%20signal%20of%20not%20attending%20college.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBhBSz8nZ8ADhTYbh2%2Fovercoming-the-negative-signal-of-not-attending-college%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Overcoming%20the%20negative%20signal%20of%20not%20attending%20college.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBhBSz8nZ8ADhTYbh2%2Fovercoming-the-negative-signal-of-not-attending-college", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBhBSz8nZ8ADhTYbh2%2Fovercoming-the-negative-signal-of-not-attending-college", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 256, "htmlBody": "<p>\n<p>The signaling view of college holds that graduates of elite colleges earn high average salaries not because of what they learned in school &nbsp;but rather because top colleges select for students who have highly valued traits, the two most important probably being high IQ and strong work ethic. &nbsp;Since in rich countries almost every smart, hard working person attends college not going to college sends a loud negative signal to potential employers. &nbsp;Elite colleges, of course, are fantastically expensive signaling devices.</p>\n<p>&nbsp;</p>\n<p>Although I teach at an elite college I have a proposal for an alternate much less expensive and probably even more accurate signaling mechanism. &nbsp;An organization could have a one month program which only admits those who get a high score on the SATs or some other intelligence test. &nbsp;Then the entire program would consist of spending sixteen hours a day solving by hand simple addition and subtraction problems. &nbsp;The point of the program would be to show that its graduates can spend a huge amount of time doing extremely boring tasks with high accuracy. &nbsp; Graduating from the program would signal that you had both a high IQ and strong work ethic.</p>\n</p>\n<p>&nbsp;</p>\n<p>If the program had a reputation for graduating valuable employees then I suspect it would become desirable to many recent high school graduates. &nbsp;The&nbsp;challenge would be for the program to&nbsp;initially&nbsp;earn its reputation. &nbsp;Perhaps&nbsp;it could accomplish this by having some well-known backers, by&nbsp;giving big cash grants to its first few graduates or by promising the first few graduates attractive jobs such as at the SIAI.&nbsp;&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BhBSz8nZ8ADhTYbh2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 14, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "5645", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-17T00:26:49.184Z", "modifiedAt": null, "url": null, "title": "Computer security story", "slug": "computer-security-story", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.282Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Perplexed", "createdAt": "2010-07-22T02:17:37.444Z", "isAdmin": false, "displayName": "Perplexed"}, "userId": "jj9aBsS9xsGPWKq3n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TkCAuDNeeP62Laj28/computer-security-story", "pageUrlRelative": "/posts/TkCAuDNeeP62Laj28/computer-security-story", "linkUrl": "https://www.lesswrong.com/posts/TkCAuDNeeP62Laj28/computer-security-story", "postedAtFormatted": "Thursday, February 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Computer%20security%20story&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComputer%20security%20story%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTkCAuDNeeP62Laj28%2Fcomputer-security-story%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Computer%20security%20story%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTkCAuDNeeP62Laj28%2Fcomputer-security-story", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTkCAuDNeeP62Laj28%2Fcomputer-security-story", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 271, "htmlBody": "<p>NPR has <a href=\"http://www.npr.org/blogs/thetwo-way/2011/02/16/133814783/how-anonymous-exacted-revenge-on-firm-that-threatened-to-out-them?ps=cprs\">this story</a>:<br /><br /><em>The hacktivist group Anonymous is at it again. This time, it has humiliated an Internet security firm that threatened to out the group's hierarchy.<br /><br />If you remember, Anonymous has been in the news, first, because in support of WikiLeaks, it undertook cyberattacks that brought down the websites of Visa and Mastercard. Second, because it brought down the sites of some government entities in Egypt and helped the anti-government protesters with technical help.&nbsp; Third, because as NPR's Martin Kaste reported, the FBI is hot on the group's heels.<br /><br />Today, the website <a href=\"http://arstechnica.com/tech-policy/news/2011/02/anonymous-speaks-the-inside-story-of-the-hbgary-hack.ars/\">ArsTechnica ran a piece</a> that details how Anonymous methodically went after HBGary Federal's digital infrastructure. Earlier this month, HBGary Federal's CEO Aaron Barr said the company, which specializes in analyzing vulnerabilities in computer security for companies and even some government agencies, had undertaken an investigation of Anonymous and had used social media to unmask the group's most important people.<br /><br />Barr said an HBGary representative was set to give a presentation at a security conference in San Francisco, but as soon as Anonymous got wind of their plans, it hacked into HBGary's servers, rifled through their e-mails and published them to the web. The group defaced HBGary's website and published the user registration database of another site owned by Greg Hoglund, owner of HBGary.<br /><br />Amazingly, reports ArsTechnica, Anonymous managed all this by exploiting, easy and everyday security flaws. ...</em><br /><br />If even professional security firms are this vulnerable, I hate to think what will happen when the cyber war <em>really</em> starts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MhHM6Rx2b4F8tHTQk": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TkCAuDNeeP62Laj28", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 6.799954374501631e-07, "legacy": true, "legacyId": "5646", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-17T14:59:59.055Z", "modifiedAt": null, "url": null, "title": "Sleeping anti-beauty and the presumptuous philosopher", "slug": "sleeping-anti-beauty-and-the-presumptuous-philosopher", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:06.330Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QKc9Kctw6kxJP9amc/sleeping-anti-beauty-and-the-presumptuous-philosopher", "pageUrlRelative": "/posts/QKc9Kctw6kxJP9amc/sleeping-anti-beauty-and-the-presumptuous-philosopher", "linkUrl": "https://www.lesswrong.com/posts/QKc9Kctw6kxJP9amc/sleeping-anti-beauty-and-the-presumptuous-philosopher", "postedAtFormatted": "Thursday, February 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sleeping%20anti-beauty%20and%20the%20presumptuous%20philosopher&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASleeping%20anti-beauty%20and%20the%20presumptuous%20philosopher%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKc9Kctw6kxJP9amc%2Fsleeping-anti-beauty-and-the-presumptuous-philosopher%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sleeping%20anti-beauty%20and%20the%20presumptuous%20philosopher%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKc9Kctw6kxJP9amc%2Fsleeping-anti-beauty-and-the-presumptuous-philosopher", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKc9Kctw6kxJP9amc%2Fsleeping-anti-beauty-and-the-presumptuous-philosopher", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 436, "htmlBody": "<p>My approach for <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and/\">dividing utility</a> between copies gives the usual and expected solutions to the sleeping beauty problem: if all copies are offered bets, take 1/3 odds, if only one copy is offered bets, take 1/2 odds.</p>\n<p>This makes sense, because my approach is analogous to \"some future version of Sleeping Beauty gets to keep all the profits\".</p>\n<p>The <a href=\"http://www.jstor.org/pss/3542797\">presumptuous philosopher</a> problem is subtly different from the sleeping beauty problem. It can best be phrased as sleeping beauty problem where each copy doesn't care for any other copy. Solving this is a bit more subtle, but an useful half-way point is the \"Sleeping Anti-Beauty\" problem.</p>\n<p>Here, as before, one or two copies are created depending on the result of a coin flip. However, if two copies are created, they are the reverse of mutually altruistic: they derive disutility from the other copy achieving its utility. So if both copies receive $1, neither of their utilities increase: they are happy to have the cash, but angry the other copy also has cash.</p>\n<p>Apart from this difference in indexical utility, the two copies are identical, and will reach the same decision. Now, as before, every copy is approached with bets on whether they are in the large universe (with two copies) or the small one (with a single copy). Using standard UDT/TDT Newcomb-problem type reasoning, they will always take the small universe side in any bet (as any gain/loss in the large universe is compensated for by the same gain/loss for the other copy they dislike).</p>\n<p>Now, you could model the presumptuous philosopher by saying they have 50% chance of being in a Sleeping-Beauty (SB) situation and 50% of being in a Sleeping Anti-Beauty (SAB) situation (indifference modelled as half way between altruism and hate).</p>\n<p>There are 4 equally likely possibilities here: small universe in SB, large universe in SB, small universe in SAB, large universe in SAB. A contract that gives $1 in a small universe is worth 0.25 + 0 + 0.25 + 0 = $0.5. While a contract that gives $1 in a large universe is worth 0 + 0.25*2 + 0 + 0 = $0.5 (as long as its offered to everyone). So it seems that a presumptuous philosopher should take even odds on the size of the universe if he doesn't care about the other presumptuous philosophers.</p>\n<p>It's no coincidence this result can be reached by UDT-like arguments such as \"take the objective probabilities of the universes, and consider the total impact of your decision being X, including all other decision that must be the same as yours\". I'm hoping to find more fundamental reasons to justify this approach soon.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NZB24aR9uHmDc5GcT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QKc9Kctw6kxJP9amc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "5688", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JWnv9fQzK6Rpnx5eN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-17T15:14:59.790Z", "modifiedAt": null, "url": null, "title": "Revisiting the anthropic trilemma III: solutions and interpretations", "slug": "revisiting-the-anthropic-trilemma-iii-solutions-and", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.264Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BwArqWoE3bsyRn5Dn/revisiting-the-anthropic-trilemma-iii-solutions-and", "pageUrlRelative": "/posts/BwArqWoE3bsyRn5Dn/revisiting-the-anthropic-trilemma-iii-solutions-and", "linkUrl": "https://www.lesswrong.com/posts/BwArqWoE3bsyRn5Dn/revisiting-the-anthropic-trilemma-iii-solutions-and", "postedAtFormatted": "Thursday, February 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Revisiting%20the%20anthropic%20trilemma%20III%3A%20solutions%20and%20interpretations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARevisiting%20the%20anthropic%20trilemma%20III%3A%20solutions%20and%20interpretations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwArqWoE3bsyRn5Dn%2Frevisiting-the-anthropic-trilemma-iii-solutions-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Revisiting%20the%20anthropic%20trilemma%20III%3A%20solutions%20and%20interpretations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwArqWoE3bsyRn5Dn%2Frevisiting-the-anthropic-trilemma-iii-solutions-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBwArqWoE3bsyRn5Dn%2Frevisiting-the-anthropic-trilemma-iii-solutions-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 892, "htmlBody": "<p>In previous posts, I revisited Eliezer's <a href=\"/lw/19d/the_anthropic_trilemma/\">anthropic trilemma</a>, approaching it with ata's <a href=\"/lw/32o/if_a_tree_falls_on_sleeping_beauty/\">perspective</a> that the decisions made are the objects of fundamental interest, not the probabilities or processes that gave rise to them. I initially applied my <a href=\"/r/discussion/lw/469/revisiting_the_anthropic_trilemma_i_intuitions/\">naive intuitions</a> to the problem, and got nonsense. I then constructed a small collection of reasonable-seeming assumptions, and showed they <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and/\">defined</a> a single method of spreading utility functions across copies.</p>\n<p>This post will apply that method to the anthropic trilemma, and thus give us the \"right\" decisions to make. I'll then try and interpret these decisions, and see what they tell us about subjective anticipation, probabilities and the impact of decisions. As in the <a href=\"/r/discussion/lw/469/revisiting_the_anthropic_trilemma_i_intuitions\">original post</a>, I will be using the chocolate bar as the unit of indexical utility, as it is a well known fact that everyone's utility is linear in chocolate.</p>\n<p>The details of the lottery winning setup can be found either <a href=\"/lw/19d/the_anthropic_trilemma\">here</a> or <a href=\"/r/discussion/lw/469/revisiting_the_anthropic_trilemma_i_intuitions\">here</a>. The decisions I must make are:</p>\n<p>Would I give up a chocolate bar now for two to be given to one of the copies if I win the lottery? No, this loses me one utility and gains me only 2/million.</p>\n<p>Would I give up a chocolate bar now for two to given to every copy if I win the lottery? Yes, this loses me one utility and gains me 2*trillion/million = 2 million.</p>\n<p>Would I give up one chocolate bar now, for two chocolate bars to the future merged me if I win the lottery? No, this gives me an expected utility of -1+2/million.</p>\n<p>Now let it be after the lottery draw, after the possible duplication, but before I know whether I've won the lottery or not. Would I give up one chocolate bar now in exchange for two for me, if I had won the lottery (assume this deal is offered to everyone)? The SIA odds say that I should; I have an expected gain of 1999/1001 &asymp; 2.</p>\n<p>Now assume that I have been told I've won the lottery, so I'm one of the trillion duplicates. Would I give up a chocolate bar for the future merged copy having two? Yes, I would, the utility gain is 2-1=1.</p>\n<p>So those are the decisions; how to interpret them? There are several ways of doing this. There are four things to keep in mind: probability, decision impact, utility function, and subjective anticipation.<a id=\"more\"></a></p>\n<ul>\n<li>SIA, individual impact, standard utility function</li>\n</ul>\n<p>The way I've phrased the system uses the SIA probabilities, and an individual impact (I don't need to worry about my other copies are deciding). From that perspective, when I agree to give up my chocolate bar for all my future potential copies, I don't anticipate winning the lottery, but I do anticipate this decision having a huge impact. So I'm doing this for expect utility reasons: I don't anticipate winning the lottery. And similarly I don't anticipate having won the lottery at a later date.</p>\n<p>However, once the lottery draw has happened, my SIA probabilities tell me I've probably won the lottery. And my behaviour tells me that I anticipate continuing to have won the lottery in future (passing my chocolate bar to my future unique copy). So in this optic, there is a switch of subjective anticipation.</p>\n<ul>\n<li>SSA, individual impact, scaled utility function</li>\n</ul>\n<p>But instead, I could be using SSA probabilities, and an individual impact. For this system to remain consistent, my utility function has to be scaled at any moment by the number of other copies in existence. Again here, I don't anticipate winning the lottery.</p>\n<p>Now, once the lottery has happened, I don't anticipate having won it. Rather, I value chocolate bars much more in the world where there are many copies (ie if I've won the lottery). So I will bet that I've won, because I value the return more if I have won. Similarly passing on to the future copy - I value his utility much more if there are more copies around now.</p>\n<p>Yes, SSA with individual impact is ugly and counter-intuitive; but it does at least preserve my feeling of subjective anticipation.</p>\n<ul>\n<li>Objective probabilities, total impact, standard utility function</li>\n</ul>\n<p>In this model, I see my decision as not only determining my own action, but that of all those correlated with it, and I use the objective probabilities of the world (neither SSA nor SIA). This is similar to the UDT perspective, and the utility is the same as in the \"SIA, individual impact\" situation.</p>\n<p>As usual, I don't anticipate winning the lottery. Now, once the lottery is happened, I don't anticipate having won it. Nor do value chocolate more in one universe or the other. Rather, I anticipate that my decision has much more impact if there are many copies - they will all get a chocolate if my decision is this. So my feeling of subjective anticipation is preserved.</p>\n<p><strong>In summary</strong></p>\n<p>These are just some of the different ways to interpret my decisions - why not SSA with total impact? Objective probabilities with individual impact? However these three are enough to illustrate the interplay between your probability, utility and impact conventions. There is, however, no experimental way of distinguishing between these different conventions.</p>\n<p>If we want to preserve the impression of subjective anticipation in a useful way, we should use \"SSA, individual impact\" or \"Objective probabilities, total impact\" or a similar system. On grounds of elegance, I'm personally going for the last one.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BwArqWoE3bsyRn5Dn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 6.802313243092842e-07, "legacy": true, "legacyId": "5687", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["y7jZ9BLEeuNTzgAE5", "gMXsyhPiEJbGerF6F", "DgxxBLofFBDaFWAEo", "JWnv9fQzK6Rpnx5eN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-17T21:55:04.743Z", "modifiedAt": null, "url": null, "title": "Recursively Self-Improving Human Intelligence", "slug": "recursively-self-improving-human-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.074Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pEbHHHR3aPLumaKJK/recursively-self-improving-human-intelligence", "pageUrlRelative": "/posts/pEbHHHR3aPLumaKJK/recursively-self-improving-human-intelligence", "linkUrl": "https://www.lesswrong.com/posts/pEbHHHR3aPLumaKJK/recursively-self-improving-human-intelligence", "postedAtFormatted": "Thursday, February 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recursively%20Self-Improving%20Human%20Intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecursively%20Self-Improving%20Human%20Intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEbHHHR3aPLumaKJK%2Frecursively-self-improving-human-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recursively%20Self-Improving%20Human%20Intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEbHHHR3aPLumaKJK%2Frecursively-self-improving-human-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEbHHHR3aPLumaKJK%2Frecursively-self-improving-human-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>There's plenty of discussion about recursive self-improvement for AGIs, and self-improvement for ourselves, but I haven't come across (in memory) anything that specifically combines the two concepts. &nbsp;Arguably, increasing rationality skills would be recursive, but can anyone think of specific ways in which we can improve ourselves via iterative cycles? &nbsp;Is there a limit to how far we can currently improve our abilities by improving our abilities to improve our abilities? &nbsp;Or are these not the right questions; the concept a mere semantic illusion...</p>\n<p>A place to start might be base-level anti-akrasia abilities. &nbsp;Are there physical steps we can do to force&nbsp;ourselves&nbsp;to self-improve when we otherwise lose the will or forget or move on to another&nbsp;interesting&nbsp;subject? &nbsp;Construct&nbsp;some sort of externally self-propelling regime that pulls us along a path to improvement? &nbsp;Could we \"Incept\" ourselves with the seed of a recursively self-improving paradigm?</p>\n<p>-</p>\n<p>Forgive the overbearingly inquisitive tone. This is my first post after lurking a couple years, and I guess even in the discussion section I&nbsp;subconsciously&nbsp;avoid making any potentially low-status claims of my own!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2b5": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pEbHHHR3aPLumaKJK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 17, "extendedScore": null, "score": 6.803376279105056e-07, "legacy": true, "legacyId": "5692", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-17T23:27:02.898Z", "modifiedAt": null, "url": null, "title": "Writing reviews instead of collecting", "slug": "writing-reviews-instead-of-collecting", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.226Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DSimon", "createdAt": "2010-06-14T14:54:23.084Z", "isAdmin": false, "displayName": "DSimon"}, "userId": "KxoDC99KCeBkaWc4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p5yucc4fgSNHhxr39/writing-reviews-instead-of-collecting", "pageUrlRelative": "/posts/p5yucc4fgSNHhxr39/writing-reviews-instead-of-collecting", "linkUrl": "https://www.lesswrong.com/posts/p5yucc4fgSNHhxr39/writing-reviews-instead-of-collecting", "postedAtFormatted": "Thursday, February 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Writing%20reviews%20instead%20of%20collecting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWriting%20reviews%20instead%20of%20collecting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5yucc4fgSNHhxr39%2Fwriting-reviews-instead-of-collecting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Writing%20reviews%20instead%20of%20collecting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5yucc4fgSNHhxr39%2Fwriting-reviews-instead-of-collecting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5yucc4fgSNHhxr39%2Fwriting-reviews-instead-of-collecting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 592, "htmlBody": "<p>I have a problem with developing attachments to the books, movies, games, and other media that I enjoy. For example, after I finished playing the new Prince of Persia title via rental, I enjoyed it so much that I went out and bought my own copy, even though I knew I would be unlikely to play the game again for at least a year.</p>\n<p>This is wasteful in a lot of ways. The media takes up unnecessary space, and makes moving from one place to another more difficult; the last time I moved, easily 3/4 the boxes contained media, primarily books which have especially low information-to-weight and information-to-volume ratios.</p>\n<p>More importantly, my magpie habit uses up money, even though there are numerous free or inexpensive long-term rental services like NetFlix, GameFly, and my old favorite the US public library system.</p>\n<p><a id=\"more\"></a></p>\n<p>I've decided to get around this by trying to transfer my sense of ownership from the item itself to the <em>memory of the experience</em> of enjoying it. So, I've been writing up reviews of all the games, movies, and books that I own, and also all those that I can remember enjoying in the past even if I don't currently own them. I want this \"collection\" to feel complete, so that I'm not tempted to go and spend $40 on some old SNES cartridge for the sake of posterity, or to buy any more books that I'm not actually expecting to read often enough or on short notice enough to offset the tiny cost of going down to the library and checking it out when needed.</p>\n<p>I've been trying to look around for some computer application or net service that can help me do this, but to my surprise, pickings have been pretty slim! The only one that seems vaguely close is <a href=\"http://www.blippr.com/\">blippr</a>, which exhibits a number of good ideas:</p>\n<ul>\n<li>Keeps reviews limited to a very short length (140 characters), allowing me to write reviews more quickly by preventing me from descending into essay-length epic poems describing the many admirable qualities of The Blues Brothers or whatever.</li>\n<li>Allows you to add new media to the system, and update descriptions for existing media. It's particularly smart about finding box art for new items.</li>\n<li>I can easily see a list of the items I've reviewed, with thumbnail images of boxart, greatly contributing to the \"this is my stuff\" feeling that I'm aiming for. The fact that it's online, and so I could therefore give somebody a link to my list and \"show off\", also helps that feeling (though I'm unlikely to have any need to actually do that).</li>\n<li>Tracks items that I'm interested in looking at later, which is handy because I seem to get recommendations from friends at about 2 or 3 times the rate I can follow up.</li>\n</ul>\n<p>These things are all great, but unfortunately blippr is badly marred by poor responsiveness and a terrible user interface design. It also seems as though development on it has effectively halted for the last year or so, and the source is unfortunately not available for me to contribute improvements myself. I've managed to review a couple hundred items anyways, but it took much longer than it should have, and I'm losing patience with its quirks fairly quickly.</p>\n<p>My questions for y'all are:</p>\n<ol>\n<li>Has anyone else encountered this particular problem, and if so, have you found a good way to work around it?</li>\n<li>Are there any other services or apps that accomplish the same things as blippr, but without the problems?</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p5yucc4fgSNHhxr39", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 6.803618058191214e-07, "legacy": true, "legacyId": "5693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T01:40:18.733Z", "modifiedAt": null, "url": null, "title": "Strong substrate independence: a thing that goes wrong in my mind when exposed to philosophy", "slug": "strong-substrate-independence-a-thing-that-goes-wrong-in-my", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.968Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HonoreDB", "createdAt": "2010-11-18T19:42:02.810Z", "isAdmin": false, "displayName": "HonoreDB"}, "userId": "7eyYSfGvgCur6pXmk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5N7awkbSoZYHNpnBF/strong-substrate-independence-a-thing-that-goes-wrong-in-my", "pageUrlRelative": "/posts/5N7awkbSoZYHNpnBF/strong-substrate-independence-a-thing-that-goes-wrong-in-my", "linkUrl": "https://www.lesswrong.com/posts/5N7awkbSoZYHNpnBF/strong-substrate-independence-a-thing-that-goes-wrong-in-my", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Strong%20substrate%20independence%3A%20a%20thing%20that%20goes%20wrong%20in%20my%20mind%20when%20exposed%20to%20philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStrong%20substrate%20independence%3A%20a%20thing%20that%20goes%20wrong%20in%20my%20mind%20when%20exposed%20to%20philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5N7awkbSoZYHNpnBF%2Fstrong-substrate-independence-a-thing-that-goes-wrong-in-my%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Strong%20substrate%20independence%3A%20a%20thing%20that%20goes%20wrong%20in%20my%20mind%20when%20exposed%20to%20philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5N7awkbSoZYHNpnBF%2Fstrong-substrate-independence-a-thing-that-goes-wrong-in-my", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5N7awkbSoZYHNpnBF%2Fstrong-substrate-independence-a-thing-that-goes-wrong-in-my", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 380, "htmlBody": "<p>Certain kinds of philosophy and speculative fiction, including kinds that get discussed here all the time, tend to cause a ridiculous thing to happen: I start doubting the difference between existence and non-existence. &nbsp;This bothers me, because it's clearly a useless dead end. &nbsp;Can anyone help with this?</p>\n<p>The two concepts that tend to do it for me are</p>\n<p>* Substrate independence/strong AI: The idea that a simulation of my mind is still me. &nbsp;That I could survive the process of uploading myself into a computer running Windows, a cellular automaton run by <a href=\"http://xkcd.com/505/\">this guy</a>, or even something that didn't look like a computer, mind, or universe at all to anyone in the outside world. &nbsp;That we could potentially create or discover a simulated universe that we could have ethical obligations towards. &nbsp;This is all pretty intuitive to me and largely accepted by the sort of people who think about these things.</p>\n<p>* <a href=\"http://en.wikipedia.org/wiki/Multiverse_(science)\">Multiverses</a>: The idea that the world is bigger than the universe.</p>\n<p>My typical line of thought goes something like this: suppose I run a Turing Machine that encodes a universe containing conscious beings. &nbsp;That universe now exists as a simulation within my own. &nbsp;It's just as real as mine, just more precarious because events in my reality can mess with its substrate. &nbsp;If I died and nobody knew how it worked, it would still be real (so I should make provisions for that scenario). &nbsp;Okay, but Turing Machines are simple. &nbsp;A Turing Machine simulating a coherent universe containing conscious beings can probably arise naturally, by chance. &nbsp;In that case, those beings are still real even if nobody on the outside, looking at the substrate, realizes what they're looking at. &nbsp;Okay, but now consider Turing Machines like John Conway's <a href=\"http://en.wikipedia.org/wiki/Fractran\">Fractran</a>, which are encoded into an ordered set of rational numbers and run by multiplication. &nbsp;I think it's fair to say that rational numbers and multiplication occur naturally, everywhere. &nbsp;Arithmetic lives everywhere. &nbsp;But furthermore, arithmetic lives *nowhere*. &nbsp;It's not just substrate-independent; it's <em>independent of whether or not there is a substrate</em>. &nbsp;2+2=4 no matter whether two bottlecaps are being combined with two other bottlecaps to make four bottlecaps. &nbsp;So every Turing-computable reality already exists to the extent that math itself does.</p>\n<p>I think this is stupid. &nbsp;Embarrassingly stupid. &nbsp;But I can't stop thinking it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5N7awkbSoZYHNpnBF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "5698", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T06:37:00.025Z", "modifiedAt": null, "url": null, "title": "Scholarship and DIY Science", "slug": "scholarship-and-diy-science", "viewCount": null, "lastCommentedAt": "2011-02-25T18:44:06.383Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gxaj4KAzYhSRgqvsh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LQK54wwMWQr2JYeDf/scholarship-and-diy-science", "pageUrlRelative": "/posts/LQK54wwMWQr2JYeDf/scholarship-and-diy-science", "linkUrl": "https://www.lesswrong.com/posts/LQK54wwMWQr2JYeDf/scholarship-and-diy-science", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Scholarship%20and%20DIY%20Science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScholarship%20and%20DIY%20Science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQK54wwMWQr2JYeDf%2Fscholarship-and-diy-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Scholarship%20and%20DIY%20Science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQK54wwMWQr2JYeDf%2Fscholarship-and-diy-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQK54wwMWQr2JYeDf%2Fscholarship-and-diy-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1390, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Related: S<a href=\"/lw/3wh/science_do_it_yourself/\" target=\"_blank\">cience: do it yourself</a>, <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\" target=\"_blank\">Some Heuristics for Evaluating The Soundness of the Academic Mainstream in Unfamiliar Fields</a>, <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\" target=\"_blank\">The Neglected Virtue of Scholarship</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">There's been some recent discussion about the value of answering your questions by reading the established scholarly literature in a field. &nbsp;On the one hand, if you never read other researchers' work, you'll be trying to invent the wheel, and you may well get things very wrong. &nbsp;The best way to learn physics is to pick up a physics textbook, not to try to deduce the laws of nature on your own. &nbsp;On the other hand, sometimes the leading scientists are wrong. &nbsp;Or sometimes you have a question that has never been studied scientifically. &nbsp;It's not always enough just to look at what the experts say; sometimes you need a little independent thought, or even the \"DIY science\" approach of looking at the data yourself and drawing your own conclusions. &nbsp;Ideally, these two approaches aren't really rivals, they're complementary. &nbsp;\"DIY science\" gives you insights into how to conduct scholarship -- what resources to seek out, and what claims to trust.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Looking up other people's research is&nbsp;<em style=\"font-style: italic;\">scholarship</em>, not science. Scholarship isn't bad. In most fields scholarship is useful, and in technical fields it's a prerequisite to doing science. But scholarship has its drawbacks. &nbsp;If there is no high-quality body of scientific research on a question (say, \"How do people get very rich?\") then looking up \"expert\" opinion isn't especially useful. And if there <em>is </em>a body of scientific research, but&nbsp;you have reason to suspect that the scientific community isn't well-informed or evenhanded, then you can't just rely on \"experts.\" &nbsp;But you don't want to be mindlessly contrarian either. &nbsp;You need some independent way to evaluate whom to believe.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Take a topic like global warming. &nbsp;Is the scientific literature accurate? Well, I don't know. To know the answer, I'd have to know more about geophysics myself, be able to assess the data myself, and compare my \"DIY science\" to the experts and see if they match. Or, I'd have to know something about the trustworthiness of peer-reviewed scientific studies in general -- how likely they are to be true or false -- and use&nbsp;<em style=\"font-style: italic;\">that</em>&nbsp;data to inform how much I trust climate scientists. Either way, to have good evidence to believe or not believe scientists, I'd need data of my own.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The phrase \"DIY science\" makes it sound like there's some virtue in going it alone. All alone, no help from the establishment. I don't think there's any virtue in that. Help is useful! And after all, even if you tabulate your own data, it's often data that someone else gathered. (For example, you could learn how people become billionaires by compiling stats on Fortune 500 lists.) &nbsp;This isn't&nbsp;<em style=\"font-style: italic;\">My Side of the Mountain&nbsp;</em>science. It's not idealizing isolation. &nbsp;The \"do it yourself\" step is the step where you draw your own conclusion directly from data. &nbsp;You don't have to neglect scholarship -- you just have to think for yourself at some point in the process.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The trouble with doing all scholarship but no science is that you have no way to assess the validity of what you read. You can use informal measures (prestige? number of voices in agreement? most cited? most upvotes?) but how do you know if those informal measures correlate with the truth of an argument? Eventually, at some point you have to look at&nbsp;<em style=\"font-style: italic;\">some</em>&nbsp;kind of data and draw your&nbsp;<em style=\"font-style: italic;\">own</em>&nbsp;conclusion from it. Critically assessing scientific literature eventually&nbsp;<em style=\"font-style: italic;\">requires</em>&nbsp;you to do some DIY science. Here, let's look at the data section. Do the paper's conclusions match their actual data? &nbsp;Here, let's look at this discipline's past record at predicting future events. Does it have a good track record? &nbsp;Here, let's look at these expert recommendations. &nbsp;How often are they put into practice in the real world, and with what success?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">One way of uniting scholarship and DIY science is the category of <em>metastudies</em>&nbsp;-- how often is such-and-such class of experts or publications correct?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><a href=\"http://scienceblogs.com/cortex/2009/03/phony_experts.php\" target=\"_blank\">Political pundits' predictions are hardly better than random, and educational credentials don't help accuracy.</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><a href=\"http://www.theatlantic.com/magazine/archive/2010/11/lies-damned-lies-and-medical-science/8269/\" target=\"_blank\">As much as 90% of the published medical information that doctors rely upon may be wrong.</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><a href=\"http://metamodern.com/2010/11/30/a-meta-meta-analysis-from-the-cdc/\" target=\"_blank\">To get really meta: most CDC meta-analyses are methodologically flawed.</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Another thing you can do to unite scholarship and DIY science is looking for patterns, commonalities and disagreements in existing literature. &nbsp;Thanks to modern large databases, you can sometimes do this statistically.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><a href=\"http://www.ihop-net.org/UniPub/iHOP/help.html\" target=\"_blank\">IHOP</a>&nbsp;searches the PubMed literature by genes or proteins.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><a href=\"http://ngrams.googlelabs.com/\" target=\"_blank\">Google ngrams</a>&nbsp;allow you to search word prevalence to get a rough idea of trends in writing over time.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The <a href=\"http://sappingattention.blogspot.com/\" target=\"_blank\">digital humanities</a>&nbsp;are a new field that involves running somewhat more subtle statistics on historical and scholarly documents.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">If you want to attach a number to \"scientific consensus,\" look at the <a href=\"http://en.wikipedia.org/wiki/Science_Citation_Index\" target=\"_blank\">Science Citation Index.</a>&nbsp;&nbsp;Many of these tools are restricted to universities, but you can, for example, measure <a href=\"http://www.library.yale.edu/science/help/sciexpl.html\" target=\"_blank\">how highly cited a journal or an author is</a>.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">EDIT DUE TO MORENDIL: it's possible, using <a href=\"http://www.bmj.com/content/339/bmj.b2680.full\">graph theory alone</a>, to notice misleading information in a scientific subfield by looking at the pattern of citations. &nbsp;Looking at the citation graph, it's possible to observe <em>bias</em>&nbsp;(a systematic tendency to under-cite contradictory evidence), <em>amplification</em>&nbsp;(the prevalence of a belief in the scientific community becomes stronger due to new links to a few influential and highly-linked papers, even though no new data is being presented), and <em>invention</em>&nbsp;(the propagation of claims that are not actually backed by data anywhere.) Negative results (the lack of conclusive results) systematically fail to propagate through scholarly networks. &nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">We'd need more sophisticated data analysis than now exists, but one of my dreams is that one day we could develop tools that search the existing literature on a search term, say, \"Slavery caused the American Civil War,\" and allowed you to estimate how contentious that claim was, how many sources were for and against it, what<em>&nbsp;</em>the sources' citation rates and links to other phrases tell you about <em>who holds what opinions</em>, and allowed you to somewhat automate the process of reading and making sense of what other people wrote. &nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">An even more ambitious project: making a graph of which studies invalidate or cast doubt on which other studies, on a very big scale, so you could roughly pinpoint the most certain or established areas of science. This would require some kind of systematic method of deducing implication, though.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This can get more elaborate than you might prefer, but the point is that if you really want to know how valid a particular idea you've read is, there are quantitative ways to get closer to answering that question. &nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The simplest check, of course, is the sanity test: run some <em>simple</em>&nbsp;figures to see if the \"expert\" view is even roughly correct. &nbsp;Does past stock performance actually predict future stock performance? &nbsp;Well, the data's out there. You can check. &nbsp;(N.B. I haven't done this. &nbsp;But I would if I were investing.) &nbsp;Is cryonics worth the money? &nbsp;Come up with some reasonable figures for probability and discount rates and do a net present value calculation. &nbsp;(I <em>have </em>done this one.) &nbsp;Or consider blatantly unscientific data-gathering: a <a href=\"http://www.jimchines.com/2010/03/survey-results/\" target=\"_blank\">survey</a>&nbsp;on when and how authors get published. &nbsp;&nbsp;Online polls and other informal data-gathering are bad methodology, but way better than nothing, and often better than intuitive \"advice.\" If the expert \"consensus\" is failing your sanity tests, either you're making a mistake or they are.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">A recurring question is how and when to be contrarian -- when to reject the mainstream expert judgments. &nbsp;One obvious example is when you suspect experts are <em>biased</em>&nbsp;to protect interests other than truth. But experts can be biased while still being right. &nbsp;(For example, biologists certainly have systematic biases, but that doesn't mean their embrace of the theory of evolution is the <em>result</em>&nbsp;of irrational bias.) &nbsp;One way or another, you're stuck with a hard epistemic problem when evaluating claims. You can test them against your own data &nbsp;-- but then you have to decide how much you trust your own back-of-the envelope computations or informal data collection. &nbsp;You can test them against the \"consensus\" or bulk of the literature -- but then you have to decide whether you trust the consensus. &nbsp;You can test them against the track record of the field -- but then you have to decide whether you trust the very meta-analysis you're using. &nbsp;There's no single magic bullet. &nbsp;But it's probably worth it, if you're seriously curious about the truth of a claim, to try a few of these different approaches.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LQK54wwMWQr2JYeDf", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 22, "extendedScore": null, "score": 6.804762160656047e-07, "legacy": true, "legacyId": "5731", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K82evF2iRAiRWwvyn", "fyZBtNB3Ki3fM4a6Y", "64FdKLwmea8MCLWkE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-02-18T06:37:00.025Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T14:10:04.187Z", "modifiedAt": null, "url": null, "title": "Dead men tell tales: falling out of love with SIA", "slug": "dead-men-tell-tales-falling-out-of-love-with-sia", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:39.182Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LnearFbA4thE646tR/dead-men-tell-tales-falling-out-of-love-with-sia", "pageUrlRelative": "/posts/LnearFbA4thE646tR/dead-men-tell-tales-falling-out-of-love-with-sia", "linkUrl": "https://www.lesswrong.com/posts/LnearFbA4thE646tR/dead-men-tell-tales-falling-out-of-love-with-sia", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dead%20men%20tell%20tales%3A%20falling%20out%20of%20love%20with%20SIA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADead%20men%20tell%20tales%3A%20falling%20out%20of%20love%20with%20SIA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnearFbA4thE646tR%2Fdead-men-tell-tales-falling-out-of-love-with-sia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dead%20men%20tell%20tales%3A%20falling%20out%20of%20love%20with%20SIA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnearFbA4thE646tR%2Fdead-men-tell-tales-falling-out-of-love-with-sia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLnearFbA4thE646tR%2Fdead-men-tell-tales-falling-out-of-love-with-sia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 543, "htmlBody": "<p>SIA is the <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">Self Indication Assumption</a>, an anthropic theory about how we should reason about the universe given that we exist. I used to love it; the argument that I've found most convincing about SIA was the one I presented in this <a href=\"/lw/18r/avoiding_doomsday_a_proof_of_the_selfindication\">post</a>. Recently, I've been falling out of love with SIA, and moving more towards a UDT version of anthropics (objective probabilities and total impact of your decision being of a specific type, including in all copies of you and enemies with the same decision process). So it's time I revisit my old post, and find the hole.</p>\n<p>The argument rested on the plausible sounding assumption that creating extra copies and killing them is no different from if they hadn't existed in the first place. More precisely, it rested on the assumption that if I was told \"You are not one of the agents I am about to talk about. Extra copies were created to be destroyed,\" it was exactly the same as hearing&nbsp; \"Extra copies were created to be destroyed. And you're not one of them.\"</p>\n<p>But I realised that from the UDT/TDT perspective, there is a great difference between the two situations, if I have the time to update decisions in the course of the sentence. Consider the following three scenarios:</p>\n<ul>\n<li>Scenario 1 (SIA):</li>\n</ul>\n<p>Two agents are created, then one is destroyed with 50% probability. Each living agent is entirely selfish, with utility linear in money, <em>and the dead agent gets nothing</em>. Every survivor will be presented with the same bet. Then you should take the SIA 2:1 odds that you are in the world with two agents. This is the scenario I was assuming.</p>\n<ul>\n<li>Scenario 2 (SSA):</li>\n</ul>\n<p>Two agents are created, then one is destroyed with 50% probability. Each living agent is entirely selfish, with utility linear in money, <em>and the dead agent is altruistic towards his survivor</em>. This is similar to my initial intuition in <a href=\"/r/discussion/lw/469/revisiting_the_anthropic_trilemma_i_intuitions\">this post</a>. Note that every agents have the same utility: \"as long as I live, I care about myself, but after I die, I'll care about the other guy\", so you can't distinguish them based on their utility. As before, every survivor will be presented with the same bet.</p>\n<p>Here, once you have been told the scenario, but before knowing whether anyone has been killed, you should pre-commit to taking 1:1 odds that you are in the world with two agents. And in UDT/TDT precommitting is the same as making the decision.<a id=\"more\"></a></p>\n<ul>\n<li>Scenario 3 (reverse SIA):</li>\n</ul>\n<p>Same as before, except the dead agent is triply altruistic toward his survivor (you can replace this altruism with various cash being donated to various charities of value to various agents). Then you should pre-commit to taking 1:2 odds that you are in the world with two agents.</p>\n<p>This illustrates the importance of the utility of the dead agent in determining the decision of the living ones, if there is even a short moment when you believe you might be the agent who is due to die. By scaling the altruism or hatred of the dead man, you can get any odds you like between the two worlds.</p>\n<p>So I was wrong; dead men tell tales, and even thinking you might be one of them will change your behaviour.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LnearFbA4thE646tR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 6.80596809065915e-07, "legacy": true, "legacyId": "5745", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5A9x74mgCwJwSg4sN", "DgxxBLofFBDaFWAEo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T14:53:02.372Z", "modifiedAt": null, "url": null, "title": "Doodling as a tool of thought (just a link)", "slug": "doodling-as-a-tool-of-thought-just-a-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:47.744Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a9uYudjbYgEYCtC4j/doodling-as-a-tool-of-thought-just-a-link", "pageUrlRelative": "/posts/a9uYudjbYgEYCtC4j/doodling-as-a-tool-of-thought-just-a-link", "linkUrl": "https://www.lesswrong.com/posts/a9uYudjbYgEYCtC4j/doodling-as-a-tool-of-thought-just-a-link", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Doodling%20as%20a%20tool%20of%20thought%20(just%20a%20link)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADoodling%20as%20a%20tool%20of%20thought%20(just%20a%20link)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9uYudjbYgEYCtC4j%2Fdoodling-as-a-tool-of-thought-just-a-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Doodling%20as%20a%20tool%20of%20thought%20(just%20a%20link)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9uYudjbYgEYCtC4j%2Fdoodling-as-a-tool-of-thought-just-a-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9uYudjbYgEYCtC4j%2Fdoodling-as-a-tool-of-thought-just-a-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2, "htmlBody": "<p><a href=\"http://www.alistapart.com/articles/the-miseducation-of-the-doodle/\">Strategic Doodling</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a9uYudjbYgEYCtC4j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 6.806082356629102e-07, "legacy": true, "legacyId": "5746", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T15:37:45.506Z", "modifiedAt": null, "url": null, "title": "Brains more complicated than previously thought", "slug": "brains-more-complicated-than-previously-thought", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.968Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kyzWP8XwJxYNmcuPM/brains-more-complicated-than-previously-thought", "pageUrlRelative": "/posts/kyzWP8XwJxYNmcuPM/brains-more-complicated-than-previously-thought", "linkUrl": "https://www.lesswrong.com/posts/kyzWP8XwJxYNmcuPM/brains-more-complicated-than-previously-thought", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brains%20more%20complicated%20than%20previously%20thought&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrains%20more%20complicated%20than%20previously%20thought%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyzWP8XwJxYNmcuPM%2Fbrains-more-complicated-than-previously-thought%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brains%20more%20complicated%20than%20previously%20thought%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyzWP8XwJxYNmcuPM%2Fbrains-more-complicated-than-previously-thought", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkyzWP8XwJxYNmcuPM%2Fbrains-more-complicated-than-previously-thought", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 360, "htmlBody": "<p><a href=\"http://www.physorg.com/news/2011-02-rewrite-textbooks-conventional-wisdom-neurons.html\">Neurons aren't simple little machines, axons talk to each other.</a></p>\n<blockquote>He and his colleagues first discovered individual nerve cells can fire off signals even in the absence of electrical stimulations in the cell body or dendrites. It's not always stimulus in, immediate action potential out. (Action potentials are the fundamental electrical signaling elements used by neurons; they are very brief changes in the membrane voltage of the neuron.)</blockquote>\n<blockquote>\"This cellular memory is a novelty,\" Spruston said. \"The neuron is responding to the history of what happened to it in the minute or so before.\" Spruston and Sheffield found that the cellular memory is stored in the axon and the action potential is generated farther down the axon than they would have expected. Instead of being near the cell body it occurs toward the end of the axon.</blockquote>\n<blockquote>Their studies of individual neurons (from the hippocampus and neocortex of mice) led to experiments with multiple neurons, which resulted in perhaps the biggest surprise of all. The researchers found that one axon can talk to another. They stimulated one neuron, and detected the persistent firing in the other unstimulated neuron.</blockquote>\n<blockquote>No dendrites or cell bodies were involved in this communication. \"The axons are talking to each other, but it's a complete mystery as to how it works,\" Spruston said. \"The next big question is: how widespread is this behavior? Is this an oddity or does in happen in lots of neurons? We don't think it's rare, so it's important for us to understand under what conditions it occurs and how this happens.\"</blockquote>\n<p><a href=\"http://www.nature.com/neuro/journal/v14/n2/full/nn.2728.html\">The original article (paywall). </a></p>\n<p><a href=\"http://www.nature.com/neuro/journal/v14/n2/full/nn.2728.html\"></a> Assuming this is all true, how does it affect the feasibility of uploading? Anyone want to bet on whether things are even more complicated than the current discoveries?</p>\n<p><strong>ETA:</strong> It seems unlikely to me that you have to simulate every atom to upload a person, and more unlikely that it's enough to view neurons as binary switches. Is there any good way to think about how much abstraction you can get away with in uploading?</p>\n<p>Yes, I know it's a vague standard. I'm not sure how good an upload needs to be. How good would be good enough for you?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kyzWP8XwJxYNmcuPM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 6.806201278411671e-07, "legacy": true, "legacyId": "5747", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T18:36:43.757Z", "modifiedAt": null, "url": null, "title": "Cryonics and Pascal\u2019s wager", "slug": "cryonics-and-pascal-s-wager", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.335Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Timwi", "createdAt": "2011-02-07T00:49:17.685Z", "isAdmin": false, "displayName": "Timwi"}, "userId": "ReHcAQCqRvcFa4ZJb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8hfvJyEQaxMKJZstx/cryonics-and-pascal-s-wager", "pageUrlRelative": "/posts/8hfvJyEQaxMKJZstx/cryonics-and-pascal-s-wager", "linkUrl": "https://www.lesswrong.com/posts/8hfvJyEQaxMKJZstx/cryonics-and-pascal-s-wager", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20and%20Pascal%E2%80%99s%20wager&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20and%20Pascal%E2%80%99s%20wager%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8hfvJyEQaxMKJZstx%2Fcryonics-and-pascal-s-wager%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20and%20Pascal%E2%80%99s%20wager%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8hfvJyEQaxMKJZstx%2Fcryonics-and-pascal-s-wager", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8hfvJyEQaxMKJZstx%2Fcryonics-and-pascal-s-wager", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 369, "htmlBody": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-GB</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin-top:0cm; mso-para-margin-right:0cm; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0cm; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif]--></p>\n<p class=\"MsoNormal\">The Cambridge UK meet-up on Saturday 12 February went really well. Many thanks to everyone who came and provided a wonderful and entertaining discussion.</p>\n<p class=\"MsoNormal\">One of the topics that came up was that of <a href=\"http://en.wikipedia.org/wiki/Cryonics\"><em>cryonics</em></a>. This is the idea of having your body (or maybe just your brain) frozen after death, to be thawed and revived in the far future when medical technology has advanced to the point where it can heal you. Is this a rational thing to do?</p>\n<p class=\"MsoNormal\">The argument I heard from some of the other attendants effectively boils down to &ldquo;what have you got to lose?&rdquo; In other words, have yourself frozen just in case it works and you can be resurrected.</p>\n<p class=\"MsoNormal\">This struck me as awfully reminiscent of <a href=\"http://en.wikipedia.org/wiki/Pascal%27s_Wager\">Pascal&rsquo;s Wager</a>, which is similarly a &ldquo;what have you got to lose?&rdquo; type argument. Cited in its original form, it is about belief in a god and goes something like this:</p>\n<blockquote>\n<p class=\"MsoQuote\" style=\"margin-left: 27pt;\">You can either believe in God or not. If you do, you will either be rewarded with eternity in heaven (if you&rsquo;re right) or nothing happens (if you&rsquo;re wrong). But if you don&rsquo;t believe, you will either be punished by eternal torture (if you&rsquo;re wrong) or nothing happens (if you&rsquo;re right). It&rsquo;s a no-brainer! You&rsquo;re better off believing.</p>\n</blockquote>\n<p class=\"MsoNormal\">This argument falls down on many counts, but I&rsquo;ll concentrate on a specific one. It makes a far-fetched assumption about the set of possible outcomes. It assumes that there are only the two possibilities quoted and no others. It ignores the possibility of a god that only rewards sceptical atheists.</p>\n<p class=\"MsoNormal\">Coming back to cryonics, the argument seems to proceed approximately like this:</p>\n<blockquote>\n<p class=\"MsoQuote\" style=\"margin-left: 27pt;\">You can either have yourself frozen or not. If you do, you will either wake up in a wonderful, happy-go-lucky utopian future with amazing technological advances (if cryonics works) or nothing happens (if it doesn&rsquo;t). But if you don&rsquo;t have yourself frozen, nothing happens either way. It&rsquo;s a no-brainer! You&rsquo;re better off in cryopreservation.</p>\n</blockquote>\n<p class=\"MsoNormal\">If I haven&rsquo;t already made it abundantly clear, the assumption that the future you wake up in is at all desirable for you is a far-fetched one. It ignores the possibility of waking up as a slave with no opportunity for suicide.</p>\n<p class=\"MsoNormal\">What are everybody&rsquo;s thoughts on this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8hfvJyEQaxMKJZstx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -3, "extendedScore": null, "score": 6.806677255864224e-07, "legacy": true, "legacyId": "5750", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T19:19:34.806Z", "modifiedAt": null, "url": null, "title": "Ability to react", "slug": "ability-to-react", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:34.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p67vi8kk3LJCjL2v7/ability-to-react", "pageUrlRelative": "/posts/p67vi8kk3LJCjL2v7/ability-to-react", "linkUrl": "https://www.lesswrong.com/posts/p67vi8kk3LJCjL2v7/ability-to-react", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ability%20to%20react&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAbility%20to%20react%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp67vi8kk3LJCjL2v7%2Fability-to-react%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ability%20to%20react%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp67vi8kk3LJCjL2v7%2Fability-to-react", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp67vi8kk3LJCjL2v7%2Fability-to-react", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1224, "htmlBody": "<p>*Note: this post is based on my subjective observations of myself and a small, likely biased sample of people I know. It may not generalize to everyone.</p>\n<p>A few days ago, during my nursing lab, my classmates and I were discussing the provincial exam that we&rsquo;ll have to sit two years from now, when we&rsquo;re done our degree, in order to work as registered nurses. The Quebec exam, according to our section prof, includes an entire day of simulations, basically acted-out situations where we&rsquo;ll have to react as we would in real life. The Ontario exam is also a day long, but entirely written.</p>\n<p>I made a comment that although the Quebec exam was no doubt a better test of our knowledge, the Ontario exam sounded a <em style=\"mso-bidi-font-style: normal;\">lot </em>easier and I was glad I planned to work in Ontario.</p>\n<p>&ldquo;Are you kidding?&rdquo; said one of the boys in my class. &ldquo;Simulations are <em style=\"mso-bidi-font-style: normal;\">so </em>much easier!&rdquo;</p>\n<p>I was taken aback, reminded myself that my friends and acquaintances are probably weirder than my models of them would predict&nbsp;(thank you AnnaSalamon for that quote), and started dissecting where exactly the weirdness lay. It boiled down to this:</p>\n<p>Some people, not necessarily the same people who can ace tests without studying or learn math easily or even do well in sports, are still naturally good at responding to real-life, real-time events. They can manage their stress, make decision on the spot, communicate flexibly, and even have fun while doing it.</p>\n<p>This is something I noticed years ago, when I first started taking my Bronze level lifesaving certifications. I am emphatically <em style=\"mso-bidi-font-style: normal;\">not </em>good at this. I found doing &ldquo;sits&rdquo; (simulated situations) stressful, difficult, and unpleasant, and I <em style=\"mso-bidi-font-style: normal;\">dreaded </em>my turn to practice being the rescuer. I had no problem with the skills we learned, as long as they were isolated, but applying them was harder than the hardest tests I&rsquo;d had at school.</p>\n<p>I went on to pass all my certifications, without any of my instructors specifically saying I had a problem. Occasionally I was accused of having &ldquo;tunnel vision&rdquo;; they meant that during a sit, treating my victim and simultaneously communicating with my teammates was more multitasking than my brain could handle.</p>\n<p>Practice makes perfect, so I joined the competitive lifeguard team (yes, this exists, see <a href=\"https://picasaweb.google.com/lifeguardpete\">https://picasaweb.google.com/lifeguardpete</a> for photos of competitions). We compete in teams of four. In competition, we go into unknown situations and are scored on how we respond. Situations are timed, usually four minutes, and divided into different events; First Aid, Water Rescue, and Priority Assessment, with appropriate score sheets. It was basically my worst nightmare come true. And thanks to sample bias, instead of being slightly above average, I was blatantly worse than everyone else. It wasn&rsquo;t just a matter of experience; even newcomers to the team scored higher than me. I stubbornly kept going to practice, and went to competitions, and improved somewhat. When I had my first nursing placement, something I had been stressing about all semester, it went effortlessly. There are advantages to setting your bar way, way higher than it needs to be. <a id=\"more\"></a></p>\n<p>There are various&nbsp;types of intelligence. The kind I have, the ability to soak up new information and make connections, is only one kind. But this ability-to-react must come from an actual difference in how my brain works compared to the brains of my teammates who perform well under stress, don&rsquo;t get distracted, don&rsquo;t suffer tunnel vision, and can communicate as a team and divide their labor <em style=\"mso-bidi-font-style: normal;\">on the spot</em>. It&rsquo;s another facet of the multi-sided phenomenon we call intelligence. As far as I&rsquo;ve seen, it isn&rsquo;t discussed much on lesswrong.</p>\n<p>The following are my speculations. Hopefully some of them are testable.</p>\n<p>1. Reacting in real time requires focus, but not the same kind of focus needed for, say, writing or programming. My evidence: I seem to be above average when it comes to the latter, but below average for the former, so they can&rsquo;t be entirely the same thing.</p>\n<p>2.&nbsp;The difference is related to the ability to silence your internal monologue, so that your thoughts are reactions to the outside world of the moment  instead of reactions to, say, something you read a week ago. Based on the questions I&rsquo;ve asked and the answers I&rsquo;ve gotten, most people don&rsquo;t notice  specifically that they have to do this; it&rsquo;s automatic.</p>\n<p>&nbsp;</p>\n<p>3.&nbsp;People who are <em style=\"mso-bidi-font-style: normal;\">bad </em>at reacting can be at either end of a spectrum; either they&rsquo;re too open to stimuli and get distracted before they can plan their response, or they&rsquo;re too closed and react in a stereotyped way based on their first impression, ignoring any new information. I&rsquo;m in the second category. Watching other lifeguard teams compete in situations, I can pick out who leans which way.&nbsp;The first category people tend to be looking around constantly to the point that they can&rsquo;t treat the victim in front of them.&nbsp;The second category people plant themselves, look at their victim, and don&rsquo;t watch or listen to what&rsquo;s happening around them.&nbsp;</p>\n<p>4. If someone is <em style=\"mso-bidi-font-style: normal;\">very </em>bad at reacting, we call them shy. Even having a conversation challenges their ability to think in real-time, so that they find social interaction stressful. I&rsquo;m basing this hypothesis on how I used to feel talking to people, although I wouldn&rsquo;t consider myself shy now.</p>\n<p>5. You can improve your actual performance by memorizing chunks of your responses, which you can then string together appropriately. The chunks can&rsquo;t be too small, or stringing them together will be more work than it&rsquo;s worth. They can&rsquo;t be too big, or they become stereotyped and create tunnel-vision. In guard team, we memorize &ldquo;speeches&rdquo; that we recite to every victim. When my section prof for my nursing lab demonstrated a head-to-toe examination, I&rsquo;m pretty sure she had a similar kind of speech memorized, although she probably never thought of it explicitly that way. This kind of practice is obviously non-transferable; I can&rsquo;t use the same speech for guard team and my nursing lab. &nbsp;</p>\n<p>6. You can improve on your innate reaction times by practicing. With considerable effort, I&rsquo;ve learned how to shut off my internal monologue, to a degree, and keep my ears and eyes open. I&rsquo;m pretty sure this <em style=\"mso-bidi-font-style: normal;\">is </em>transferable.</p>\n<p>I don&rsquo;t know how ability-to-react correlates with &ldquo;school smarts,&rdquo; the ability to absorb and integrate information. Most of my friends are better in one area than another, but the people I&rsquo;ve known who are exceptionally good at reacting are usually quick learners as well. Is it a positive correlation? Negative correlation? No correlation? Can it even be measured reliably.&nbsp;</p>\n<p>I would assume that this affects people&rsquo;s career choices, too. Fighters and paramedics need good reaction times; they need to be able to focus on external events. Programmers and scientists need to focus on internal events, on their own thought process. I have no real evidence to support this, though.</p>\n<p>These are my questions.</p>\n<p>1. Has anyone else noticed this? If so, which area do you think you&rsquo;re better in? It would be interesting to gather some lesswrong community statistics.&nbsp;</p>\n<p>2. Is there anything in the literature? I&rsquo;m hesitant to give <em style=\"mso-bidi-font-style: normal;\">ability-to-react</em> a name, because it almost certainly has one already that I can&rsquo;t find because I can&rsquo;t think of the right keywords to put into Google.</p>\n<p>3. Does anyone have short-cuts or practice tips that have improved their ability to react? I&rsquo;ve read a lot about study methods, which apply to &ldquo;school smarts,&rdquo; but less about this.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fR7QfYx4JA3BnptT9": 2, "fkABsGCJZ6y9qConW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p67vi8kk3LJCjL2v7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 86, "baseScore": 100, "extendedScore": null, "score": 0.000182, "legacy": true, "legacyId": "5748", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 100, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 99, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-18T20:38:28.192Z", "modifiedAt": null, "url": null, "title": "Fun and Games with Cognitive Biases", "slug": "fun-and-games-with-cognitive-biases", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:06.463Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cosmos", "createdAt": "2009-04-26T03:18:01.731Z", "isAdmin": false, "displayName": "Cosmos"}, "userId": "c3Ji9Th6jATRyHLFC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ytr4dJT79sCBuuEjG/fun-and-games-with-cognitive-biases", "pageUrlRelative": "/posts/Ytr4dJT79sCBuuEjG/fun-and-games-with-cognitive-biases", "linkUrl": "https://www.lesswrong.com/posts/Ytr4dJT79sCBuuEjG/fun-and-games-with-cognitive-biases", "postedAtFormatted": "Friday, February 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fun%20and%20Games%20with%20Cognitive%20Biases&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFun%20and%20Games%20with%20Cognitive%20Biases%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtr4dJT79sCBuuEjG%2Ffun-and-games-with-cognitive-biases%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fun%20and%20Games%20with%20Cognitive%20Biases%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtr4dJT79sCBuuEjG%2Ffun-and-games-with-cognitive-biases", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYtr4dJT79sCBuuEjG%2Ffun-and-games-with-cognitive-biases", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1839, "htmlBody": "<p>You may have heard about IARPA's <a href=\"http://www.iarpa.gov/solicitations_sirius.html\" target=\"_blank\">Sirius Program</a>, which is a proposal to develop <a href=\"http://en.wikipedia.org/wiki/Serious_game\" target=\"_blank\">serious games</a> that would teach intelligence analysts to recognize and correct their cognitive biases.&nbsp; The intelligence community has a long history of interest in debiasing, and even produced a <a href=\"https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/index.html\" target=\"_blank\">rationality handbook</a> based on internal CIA publications from the 70's and 80's.&nbsp; Creating games which would systematically improve our thinking skills has enormous potential, and I would highly encourage the LW community to consider this as a potential way forward to encourage rationality more broadly.</p>\n<p>While developing these particular games will require thought and programming, the proposal did inspire the NYC LW community to play a game of our own.&nbsp; Using a list of cognitive biases, we broke up into groups of <strong>no larger than four</strong>, and spent <strong>five minutes</strong> discussing each bias with regards to three questions:</p>\n<ol>\n<li>How do we recognize it?</li>\n<li>How do we correct it?</li>\n<li>How do we use its existence to help us win?</li>\n</ol>\n<p>The Sirius Program specifically targets Confirmation Bias, Fundamental Attribution Error, Bias Blind Spot, Anchoring Bias, Representativeness Bias, and Projection Bias.&nbsp; To this list, I also decided to add the Planning Fallacy, the Availability Heuristic, Hindsight Bias, the Halo Effect, Confabulation, and the Overconfidence Effect.&nbsp; We did this Pomodoro style, with six rounds of five minutes, a quick break, another six rounds, before a break and then a group discussion of the exercise.</p>\n<p>Results of this exercise are posted below the fold.&nbsp; I encourage you to try the exercise for yourself before looking at our answers.<a id=\"more\"></a></p>\n<p><strong>Caution: Dark Arts!</strong>&nbsp; Explicit discussion of how to exploit bugs in human reasoning may lead to discomfort. &nbsp;You have been warned.</p>\n<h2>Confirmation Bias</h2>\n<ul>\n<li>Notice if you (don't) <em>want</em> a theory to be true</li>\n<li>Don't be afraid of being wrong, question the outcome that you fear will happen</li>\n<li>Seek out people with contrary opinions and be <em>genuinely curious</em> why they believe what they do</li>\n<li>How do we make people genuinely curious?&nbsp; Maybe try encouraging childlike behavior generally?</li>\n<li>If your theory<em> is</em> true every test should come back positive, so don't worry and make a game of disproving your hypothesis</li>\n<li>Commit yourself to which directions you will update on the different outcomes of an experiment before running it</li>\n<li>Be more suspicious of confirmatory results when you do run tests</li>\n<li>Feed confirmatory evidence to others, give them tests to run which you know beforehand are confirmatory</li>\n<li>Agree with people first, before attempting in any way to change their beliefs (but be careful you don't start believing it yourself)</li>\n</ul>\n<h2>Fundamental Attribution Error</h2>\n<ul>\n<li><strong>Critical: make observations, not moralistic judgments</strong> </li>\n<li>It helps to be around other non-judgmental people</li>\n<li>Observe your own behavior as a third party: visualize the scene with someone else in your place, ask yourself how others would explain your behavior in the situation</li>\n<li>Increase information about the situation, we are more inclined to simple explanations (e.g. stupid, evil) when we have less data</li>\n<li>Get people to internalize the FAE about their own behavior to take more agency in their lives</li>\n<li>Make moralistic judgments about distant people to increase in-group/out-group effects</li>\n</ul>\n<h2>Bias Blind Spot</h2>\n<ul>\n<li>General knowledge about cognitive biases helps</li>\n<li>Ask other people whether you are biased</li>\n<li>Get people to put themselves into a reference class, don't let them think they are a special case</li>\n<li>Point out biases in others as they occur (planning fallacy seems particularly fruitful here)</li>\n<li>Do not use the word \"bias\": use \"heuristic\" for technical folks, otherwise use no titles and deal on a case-by-case basis</li>\n<li>Do not cite studies, turn the results of the study into a story</li>\n</ul>\n<h2>Anchoring Bias</h2>\n<ul>\n<li>If possible, gather actual data instead of guessing.&nbsp; How much is this a problem in practical life?</li>\n<li>Analyze things longer, don't rely on a first impression</li>\n<li>When making complex decisions, make a list of pros and cons and weight each of them by importance</li>\n<li>Make everyone guess to themselves before anyone in the group reveals</li>\n<li>Possible technique: flash a lot of random numbers in rapid succession, to weaken an existing anchor.&nbsp; Recency effect would still be in play.&nbsp; Does this work for qualitative reasoning by flashing nonsense words?&nbsp; This could possibly be implemented on our native hardware by going into free association.</li>\n<li>Use anchoring and relative evaluation on yourself, e.g. turn a shower <em>very cold</em> and then back up slightly, rather than turning it straight down to the final temperature</li>\n<li>Anchor others in critical situations, like salary negotiations</li>\n</ul>\n<h2>Representativeness Bias</h2>\n<ul>\n<li>If possible, gather actual data instead of guessing</li>\n<li>Consider a wide variety of many different examples</li>\n<li>Skim over examples when reading, stick to reading facts</li>\n<li>Ask other people for additional examples in conversation (although it could be more confirmation as well)</li>\n<li>Give other people examples, especially vivid and detailed ones</li>\n</ul>\n<h2>Projection Bias</h2>\n<ul>\n<li><strong>Critical: be responsible for your own emotional responses</strong></li>\n<li>Ask if something you think about someone applies to yourself</li>\n<li>Hold map/territory distinction in mind, be willing to admit you were wrong about your initial impressions</li>\n<li>Empathize with other people to get them to open up emotionally</li>\n<li>Conditional on sufficient self-awareness, just ask the person if they are projecting</li>\n<li>Point out similarities between the projector and the projectee</li>\n<li>Become the thing that the other person admires about themselves</li>\n<li>Nice people who naively project this onto others are more vulnerable to manipulation</li>\n</ul>\n<h2>Planning Fallacy</h2>\n<ul>\n<li>Make estimates of time to completion, and calibrate yourself over time</li>\n<li>Make your estimate and add some proportional amount of time to it (should decrease as calibration improves)</li>\n<li>Ask your friends how long they think it will take you</li>\n<li>Figure out the reference class of your task, gather data on how others underestimate time to completion for those particular tasks</li>\n<li>Give your estimates to other people, to make yourself socially accountable to them</li>\n<li>Visualize encountering various problems during task completion before estimating</li>\n<li>Tell other people about the bias before asking them for time estimates (maybe - you can always add to their estimate)</li>\n<li>You can be more lazy without much penalty</li>\n<li>Note that others don't expect you to be well-calibrated either, so giving a longer time estimate in a one-shot game is not a winning strategy.&nbsp; For repeat games, a reputation for task-completion and accuracy could be more valuable.</li>\n<li>Create two estimates, one you actually believe and one you tell other people</li>\n</ul>\n<h2>Availability Heuristic</h2>\n<ul>\n<li><strong>Critical: ask yourself what <em>specific observations</em> are forming your belief</strong></li>\n<li>If possible, gather actual data instead of guessing</li>\n<li>Ask yourself how many reasons you have for believing something</li>\n<li>Don't stop with an initial estimate, keep thinking and looking for more information</li>\n<li>In a group setting, have a policy of someone giving another suggestion <em>immediately</em> after the first is announced</li>\n<li>Tell anecdotes and stories to other people</li>\n<li>You can shift people's beliefs over long periods of time without their knowledge by sporadically mentioning things</li>\n</ul>\n<h2>Hindsight Bias</h2>\n<ul>\n<li>Estimate task difficulty ex ante, and calibrate over time</li>\n<li>This bias only exists ex post, so the above technique should basically fix the problem (unless you subsequently argue with your past self's estimate, but with calibration this should not be an issue)</li>\n<li>Your successes will be remembered, your failures forgotten, e.g. cold reading</li>\n<li>Amplify this bias to make other feel smarter and better about themselves</li>\n</ul>\n<h2>Halo Effect</h2>\n<ul>\n<li>This seems to just be the way neurons function, making it more difficult to correct on a heuristic level</li>\n<li>Notice your positive/negative affect towards something, and state that observation out loud to yourself</li>\n<li>Be skeptical of any immediate feelings about something</li>\n<li>Reduce the affect by using comparisons, e.g. imagine someone <em>even more</em> awesome</li>\n<li>Try to consciously reverse the affect you are experiencing for a period of time</li>\n<li>Ask other people who may be less vulnerable to a particular person</li>\n<li>Try to imagine others as a collection of separable parts, view them independently</li>\n<li>The halo effect is not always an unreasonable heuristic, keep a correlation between features in mind</li>\n<li>Make a good first impression by doing something you are good at</li>\n<li>Be happy, make others feel good about themselves, and contribute positive mood contagion</li>\n<li>Surround yourself with high-status people, acquire all good things and ideas and display them readily</li>\n</ul>\n<h2>Confabulation</h2>\n<ul>\n<li>Trade-off between rewriting the memory upon access, and accessing frequently enough to retain the connection strengths</li>\n<li>Don't take your memory as absolute truth, be willing to admit you can be wrong</li>\n<li>Create objective recordings of situations: audio, video, etc.</li>\n<li>Write down your thoughts about the situation <em>as soon as possible</em> after it occurs</li>\n<li>If possible, learn to identify your internal story-generating process (note: this might serve other functions, so exercise caution if modifying)</li>\n<li>Encode initial memories more strongly using extreme emotional states</li>\n<li>Use Anki or some other SRS program to remember specific facts about situations</li>\n<li>You can create memories in others over long periods of time by telling them stories</li>\n</ul>\n<h2>Overconfidence Bias</h2>\n<ul>\n<li><strong>Critical: this particular bias appears to have significant benefits</strong></li>\n<li>Does overconfidence <em>require</em> miscalibration?&nbsp; This seems like an emotional effect possibly separable from probability estimates</li>\n<li>Visualize success</li>\n<li>Reflect only on the successes of the past, do not think about failures</li>\n<li>Feel an enormous amount of positive emotions upon success, do not feel shame upon failure</li>\n<li>Have your friends help you reinforce this bias by telling you how awesome you are</li>\n<li>To correct it, make people bet on their beliefs.&nbsp; Avoid activities where overconfidence would hurt you, e.g. gambling</li>\n<li>Encourage others to start ambitious projects, and take them over already partially-completed when they fail</li>\n<li>Write contracts such that a likely failure imposes very costly penalties</li>\n<li>Prevent others from taking on improbable tasks and wasting their time</li>\n</ul>\n<h2>Summary</h2>\n<p>How long do you think it should take to <a href=\"/lw/q9/the_failures_of_eld_science/\" target=\"_blank\">solve a major problem</a> if you are not wasting any time?&nbsp; Everything written above was created in a <strong>sum total of one hour of work</strong>.&nbsp; How many of these ideas had <em>never even occurred to us</em> before we sat down and thought about it for <em>five minutes</em>?&nbsp; <span id=\":2ek\" dir=\"ltr\">Take five minutes <strong>right now</strong> and write down what areas of your life you could optimize to make the biggest difference.</span>&nbsp; You know what to do from there.&nbsp; This is the power of rationality.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DWWZwkxTJs4d5WrcX": 2, "5f5c37ee1b5cdee568cfb157": 2, "5f5c37ee1b5cdee568cfb182": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ytr4dJT79sCBuuEjG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 70, "baseScore": 82, "extendedScore": null, "score": 0.000174, "legacy": true, "legacyId": "5749", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>You may have heard about IARPA's <a href=\"http://www.iarpa.gov/solicitations_sirius.html\" target=\"_blank\">Sirius Program</a>, which is a proposal to develop <a href=\"http://en.wikipedia.org/wiki/Serious_game\" target=\"_blank\">serious games</a> that would teach intelligence analysts to recognize and correct their cognitive biases.&nbsp; The intelligence community has a long history of interest in debiasing, and even produced a <a href=\"https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/index.html\" target=\"_blank\">rationality handbook</a> based on internal CIA publications from the 70's and 80's.&nbsp; Creating games which would systematically improve our thinking skills has enormous potential, and I would highly encourage the LW community to consider this as a potential way forward to encourage rationality more broadly.</p>\n<p>While developing these particular games will require thought and programming, the proposal did inspire the NYC LW community to play a game of our own.&nbsp; Using a list of cognitive biases, we broke up into groups of <strong>no larger than four</strong>, and spent <strong>five minutes</strong> discussing each bias with regards to three questions:</p>\n<ol>\n<li>How do we recognize it?</li>\n<li>How do we correct it?</li>\n<li>How do we use its existence to help us win?</li>\n</ol>\n<p>The Sirius Program specifically targets Confirmation Bias, Fundamental Attribution Error, Bias Blind Spot, Anchoring Bias, Representativeness Bias, and Projection Bias.&nbsp; To this list, I also decided to add the Planning Fallacy, the Availability Heuristic, Hindsight Bias, the Halo Effect, Confabulation, and the Overconfidence Effect.&nbsp; We did this Pomodoro style, with six rounds of five minutes, a quick break, another six rounds, before a break and then a group discussion of the exercise.</p>\n<p>Results of this exercise are posted below the fold.&nbsp; I encourage you to try the exercise for yourself before looking at our answers.<a id=\"more\"></a></p>\n<p><strong>Caution: Dark Arts!</strong>&nbsp; Explicit discussion of how to exploit bugs in human reasoning may lead to discomfort. &nbsp;You have been warned.</p>\n<h2 id=\"Confirmation_Bias\">Confirmation Bias</h2>\n<ul>\n<li>Notice if you (don't) <em>want</em> a theory to be true</li>\n<li>Don't be afraid of being wrong, question the outcome that you fear will happen</li>\n<li>Seek out people with contrary opinions and be <em>genuinely curious</em> why they believe what they do</li>\n<li>How do we make people genuinely curious?&nbsp; Maybe try encouraging childlike behavior generally?</li>\n<li>If your theory<em> is</em> true every test should come back positive, so don't worry and make a game of disproving your hypothesis</li>\n<li>Commit yourself to which directions you will update on the different outcomes of an experiment before running it</li>\n<li>Be more suspicious of confirmatory results when you do run tests</li>\n<li>Feed confirmatory evidence to others, give them tests to run which you know beforehand are confirmatory</li>\n<li>Agree with people first, before attempting in any way to change their beliefs (but be careful you don't start believing it yourself)</li>\n</ul>\n<h2 id=\"Fundamental_Attribution_Error\">Fundamental Attribution Error</h2>\n<ul>\n<li><strong>Critical: make observations, not moralistic judgments</strong> </li>\n<li>It helps to be around other non-judgmental people</li>\n<li>Observe your own behavior as a third party: visualize the scene with someone else in your place, ask yourself how others would explain your behavior in the situation</li>\n<li>Increase information about the situation, we are more inclined to simple explanations (e.g. stupid, evil) when we have less data</li>\n<li>Get people to internalize the FAE about their own behavior to take more agency in their lives</li>\n<li>Make moralistic judgments about distant people to increase in-group/out-group effects</li>\n</ul>\n<h2 id=\"Bias_Blind_Spot\">Bias Blind Spot</h2>\n<ul>\n<li>General knowledge about cognitive biases helps</li>\n<li>Ask other people whether you are biased</li>\n<li>Get people to put themselves into a reference class, don't let them think they are a special case</li>\n<li>Point out biases in others as they occur (planning fallacy seems particularly fruitful here)</li>\n<li>Do not use the word \"bias\": use \"heuristic\" for technical folks, otherwise use no titles and deal on a case-by-case basis</li>\n<li>Do not cite studies, turn the results of the study into a story</li>\n</ul>\n<h2 id=\"Anchoring_Bias\">Anchoring Bias</h2>\n<ul>\n<li>If possible, gather actual data instead of guessing.&nbsp; How much is this a problem in practical life?</li>\n<li>Analyze things longer, don't rely on a first impression</li>\n<li>When making complex decisions, make a list of pros and cons and weight each of them by importance</li>\n<li>Make everyone guess to themselves before anyone in the group reveals</li>\n<li>Possible technique: flash a lot of random numbers in rapid succession, to weaken an existing anchor.&nbsp; Recency effect would still be in play.&nbsp; Does this work for qualitative reasoning by flashing nonsense words?&nbsp; This could possibly be implemented on our native hardware by going into free association.</li>\n<li>Use anchoring and relative evaluation on yourself, e.g. turn a shower <em>very cold</em> and then back up slightly, rather than turning it straight down to the final temperature</li>\n<li>Anchor others in critical situations, like salary negotiations</li>\n</ul>\n<h2 id=\"Representativeness_Bias\">Representativeness Bias</h2>\n<ul>\n<li>If possible, gather actual data instead of guessing</li>\n<li>Consider a wide variety of many different examples</li>\n<li>Skim over examples when reading, stick to reading facts</li>\n<li>Ask other people for additional examples in conversation (although it could be more confirmation as well)</li>\n<li>Give other people examples, especially vivid and detailed ones</li>\n</ul>\n<h2 id=\"Projection_Bias\">Projection Bias</h2>\n<ul>\n<li><strong>Critical: be responsible for your own emotional responses</strong></li>\n<li>Ask if something you think about someone applies to yourself</li>\n<li>Hold map/territory distinction in mind, be willing to admit you were wrong about your initial impressions</li>\n<li>Empathize with other people to get them to open up emotionally</li>\n<li>Conditional on sufficient self-awareness, just ask the person if they are projecting</li>\n<li>Point out similarities between the projector and the projectee</li>\n<li>Become the thing that the other person admires about themselves</li>\n<li>Nice people who naively project this onto others are more vulnerable to manipulation</li>\n</ul>\n<h2 id=\"Planning_Fallacy\">Planning Fallacy</h2>\n<ul>\n<li>Make estimates of time to completion, and calibrate yourself over time</li>\n<li>Make your estimate and add some proportional amount of time to it (should decrease as calibration improves)</li>\n<li>Ask your friends how long they think it will take you</li>\n<li>Figure out the reference class of your task, gather data on how others underestimate time to completion for those particular tasks</li>\n<li>Give your estimates to other people, to make yourself socially accountable to them</li>\n<li>Visualize encountering various problems during task completion before estimating</li>\n<li>Tell other people about the bias before asking them for time estimates (maybe - you can always add to their estimate)</li>\n<li>You can be more lazy without much penalty</li>\n<li>Note that others don't expect you to be well-calibrated either, so giving a longer time estimate in a one-shot game is not a winning strategy.&nbsp; For repeat games, a reputation for task-completion and accuracy could be more valuable.</li>\n<li>Create two estimates, one you actually believe and one you tell other people</li>\n</ul>\n<h2 id=\"Availability_Heuristic\">Availability Heuristic</h2>\n<ul>\n<li><strong>Critical: ask yourself what <em>specific observations</em> are forming your belief</strong></li>\n<li>If possible, gather actual data instead of guessing</li>\n<li>Ask yourself how many reasons you have for believing something</li>\n<li>Don't stop with an initial estimate, keep thinking and looking for more information</li>\n<li>In a group setting, have a policy of someone giving another suggestion <em>immediately</em> after the first is announced</li>\n<li>Tell anecdotes and stories to other people</li>\n<li>You can shift people's beliefs over long periods of time without their knowledge by sporadically mentioning things</li>\n</ul>\n<h2 id=\"Hindsight_Bias\">Hindsight Bias</h2>\n<ul>\n<li>Estimate task difficulty ex ante, and calibrate over time</li>\n<li>This bias only exists ex post, so the above technique should basically fix the problem (unless you subsequently argue with your past self's estimate, but with calibration this should not be an issue)</li>\n<li>Your successes will be remembered, your failures forgotten, e.g. cold reading</li>\n<li>Amplify this bias to make other feel smarter and better about themselves</li>\n</ul>\n<h2 id=\"Halo_Effect\">Halo Effect</h2>\n<ul>\n<li>This seems to just be the way neurons function, making it more difficult to correct on a heuristic level</li>\n<li>Notice your positive/negative affect towards something, and state that observation out loud to yourself</li>\n<li>Be skeptical of any immediate feelings about something</li>\n<li>Reduce the affect by using comparisons, e.g. imagine someone <em>even more</em> awesome</li>\n<li>Try to consciously reverse the affect you are experiencing for a period of time</li>\n<li>Ask other people who may be less vulnerable to a particular person</li>\n<li>Try to imagine others as a collection of separable parts, view them independently</li>\n<li>The halo effect is not always an unreasonable heuristic, keep a correlation between features in mind</li>\n<li>Make a good first impression by doing something you are good at</li>\n<li>Be happy, make others feel good about themselves, and contribute positive mood contagion</li>\n<li>Surround yourself with high-status people, acquire all good things and ideas and display them readily</li>\n</ul>\n<h2 id=\"Confabulation\">Confabulation</h2>\n<ul>\n<li>Trade-off between rewriting the memory upon access, and accessing frequently enough to retain the connection strengths</li>\n<li>Don't take your memory as absolute truth, be willing to admit you can be wrong</li>\n<li>Create objective recordings of situations: audio, video, etc.</li>\n<li>Write down your thoughts about the situation <em>as soon as possible</em> after it occurs</li>\n<li>If possible, learn to identify your internal story-generating process (note: this might serve other functions, so exercise caution if modifying)</li>\n<li>Encode initial memories more strongly using extreme emotional states</li>\n<li>Use Anki or some other SRS program to remember specific facts about situations</li>\n<li>You can create memories in others over long periods of time by telling them stories</li>\n</ul>\n<h2 id=\"Overconfidence_Bias\">Overconfidence Bias</h2>\n<ul>\n<li><strong>Critical: this particular bias appears to have significant benefits</strong></li>\n<li>Does overconfidence <em>require</em> miscalibration?&nbsp; This seems like an emotional effect possibly separable from probability estimates</li>\n<li>Visualize success</li>\n<li>Reflect only on the successes of the past, do not think about failures</li>\n<li>Feel an enormous amount of positive emotions upon success, do not feel shame upon failure</li>\n<li>Have your friends help you reinforce this bias by telling you how awesome you are</li>\n<li>To correct it, make people bet on their beliefs.&nbsp; Avoid activities where overconfidence would hurt you, e.g. gambling</li>\n<li>Encourage others to start ambitious projects, and take them over already partially-completed when they fail</li>\n<li>Write contracts such that a likely failure imposes very costly penalties</li>\n<li>Prevent others from taking on improbable tasks and wasting their time</li>\n</ul>\n<h2 id=\"Summary\">Summary</h2>\n<p>How long do you think it should take to <a href=\"/lw/q9/the_failures_of_eld_science/\" target=\"_blank\">solve a major problem</a> if you are not wasting any time?&nbsp; Everything written above was created in a <strong>sum total of one hour of work</strong>.&nbsp; How many of these ideas had <em>never even occurred to us</em> before we sat down and thought about it for <em>five minutes</em>?&nbsp; <span id=\":2ek\" dir=\"ltr\">Take five minutes <strong>right now</strong> and write down what areas of your life you could optimize to make the biggest difference.</span>&nbsp; You know what to do from there.&nbsp; This is the power of rationality.</p>", "sections": [{"title": "Confirmation Bias", "anchor": "Confirmation_Bias", "level": 1}, {"title": "Fundamental Attribution Error", "anchor": "Fundamental_Attribution_Error", "level": 1}, {"title": "Bias Blind Spot", "anchor": "Bias_Blind_Spot", "level": 1}, {"title": "Anchoring Bias", "anchor": "Anchoring_Bias", "level": 1}, {"title": "Representativeness Bias", "anchor": "Representativeness_Bias", "level": 1}, {"title": "Projection Bias", "anchor": "Projection_Bias", "level": 1}, {"title": "Planning Fallacy", "anchor": "Planning_Fallacy", "level": 1}, {"title": "Availability Heuristic", "anchor": "Availability_Heuristic", "level": 1}, {"title": "Hindsight Bias", "anchor": "Hindsight_Bias", "level": 1}, {"title": "Halo Effect", "anchor": "Halo_Effect", "level": 1}, {"title": "Confabulation", "anchor": "Confabulation", "level": 1}, {"title": "Overconfidence Bias", "anchor": "Overconfidence_Bias", "level": 1}, {"title": "Summary", "anchor": "Summary", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "28 comments"}], "headingsCount": 15}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZxR8P8hBFQ9kC8wMy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T02:03:20.482Z", "modifiedAt": null, "url": null, "title": "Alt text of today's xkcd addresses akrasia", "slug": "alt-text-of-today-s-xkcd-addresses-akrasia", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.472Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HD4GFZJEsMBvcGvRW/alt-text-of-today-s-xkcd-addresses-akrasia", "pageUrlRelative": "/posts/HD4GFZJEsMBvcGvRW/alt-text-of-today-s-xkcd-addresses-akrasia", "linkUrl": "https://www.lesswrong.com/posts/HD4GFZJEsMBvcGvRW/alt-text-of-today-s-xkcd-addresses-akrasia", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Alt%20text%20of%20today's%20xkcd%20addresses%20akrasia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAlt%20text%20of%20today's%20xkcd%20addresses%20akrasia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHD4GFZJEsMBvcGvRW%2Falt-text-of-today-s-xkcd-addresses-akrasia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Alt%20text%20of%20today's%20xkcd%20addresses%20akrasia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHD4GFZJEsMBvcGvRW%2Falt-text-of-today-s-xkcd-addresses-akrasia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHD4GFZJEsMBvcGvRW%2Falt-text-of-today-s-xkcd-addresses-akrasia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 145, "htmlBody": "<p>The alt text of <a href=\"http://xkcd.com/862/\">today's xkcd</a>&nbsp;reads:</p>\n<blockquote>\n<p>After years of trying various methods, I broke [the habit of clicking on my favorite distractions every 5 minutes] by pitting my impatience against my laziness. I decoupled the action and the neurological reward by setting up a simple 30-second delay I had to wait through, in which I couldn't do anything else, before any new page or chat client would load (and only allowed one to run at once). The urge to check all those sites magically vanished -- and my 'productive' computer use was unaffected.</p>\n</blockquote>\n<p>Anyone have ideas about how to implement this? On Firefox one can always use LeechBlock. On *nix systems there would be a number of ways of implementing this, but not all of us use that OS or have the necessary savvy.&nbsp;</p>\n<p>(I'm kind of surprised no one's made a discussion post on this yet.)</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HD4GFZJEsMBvcGvRW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 6.80786528669139e-07, "legacy": true, "legacyId": "5753", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T06:10:15.258Z", "modifiedAt": null, "url": null, "title": "Spoiled Discussion of Permutation City, A Fire Upon The Deep, and Eliezer's Mega Crossover", "slug": "spoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.216Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JenniferRM", "createdAt": "2009-03-06T17:16:50.600Z", "isAdmin": false, "displayName": "JenniferRM"}, "userId": "g8JkZfL8PTqAefpvx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vTztZSykLTngMzg5P/spoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "pageUrlRelative": "/posts/vTztZSykLTngMzg5P/spoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "linkUrl": "https://www.lesswrong.com/posts/vTztZSykLTngMzg5P/spoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spoiled%20Discussion%20of%20Permutation%20City%2C%20A%20Fire%20Upon%20The%20Deep%2C%20and%20Eliezer's%20Mega%20Crossover&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpoiled%20Discussion%20of%20Permutation%20City%2C%20A%20Fire%20Upon%20The%20Deep%2C%20and%20Eliezer's%20Mega%20Crossover%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvTztZSykLTngMzg5P%2Fspoiled-discussion-of-permutation-city-a-fire-upon-the-deep%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spoiled%20Discussion%20of%20Permutation%20City%2C%20A%20Fire%20Upon%20The%20Deep%2C%20and%20Eliezer's%20Mega%20Crossover%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvTztZSykLTngMzg5P%2Fspoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvTztZSykLTngMzg5P%2Fspoiled-discussion-of-permutation-city-a-fire-upon-the-deep", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>Permutation City is an awesome novel that was written in 1994.&nbsp; Even if the author, Greg Egan, used <a href=\"/r/discussion/lw/2ti/greg_egan_disses_standins_for_overcoming_bias/\">a caricature of this community as a bad guy</a> in a more recent novel, his work is still a major influence on a lot of people around these parts who have read it.&nbsp; It dissolves so many questions around uploading and simulation that it's hard for someone who <em>has</em> read the book to talk about simulationist metaphysics without wanting to reference the novel... but doing that runs into constraints imposed by spoiler etiquette.</p>\n<p>So <a href=\"http://www.amazon.com/Permutation-City-Greg-Egan/dp/006105481X/\">go read Permutation City</a> if you haven't read it already because it's philosophically important and a reasonably fun read.</p>\n<p>In the meantime, if you haven't then you should <em>also</em> read <a href=\"http://www.amazon.com/Fire-Upon-Deep-Vernor-Vinge/dp/0812515285\">A Fire Upon The Deep</a> by Vernor Vinge (of \"singularity\" coining fame) and then read Eliezer's fan fic <a href=\"http://www.fanfiction.net/s/5389450/1/The_Finale_of_the_Ultimate_Meta_Mega_Crossover\">The Finale of the Ultimate Meta Mega Crossover</a> which references both of them in interesting ways to make substantive philosophical points and doesn't take too long to read.</p>\n<p>In the comments below there will be discussion that has spoilers for all three works.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vTztZSykLTngMzg5P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.808520942479617e-07, "legacy": true, "legacyId": "5762", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HJNmdxM2y8gizaRPM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T07:45:22.119Z", "modifiedAt": null, "url": null, "title": "preferences:decision theory :: data:code", "slug": "preferences-decision-theory-data-code", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.770Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArthurB", "createdAt": "2009-03-05T17:44:08.991Z", "isAdmin": false, "displayName": "ArthurB"}, "userId": "hMn8kmLCrempqYqsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JScyTmTioK4xAR97f/preferences-decision-theory-data-code", "pageUrlRelative": "/posts/JScyTmTioK4xAR97f/preferences-decision-theory-data-code", "linkUrl": "https://www.lesswrong.com/posts/JScyTmTioK4xAR97f/preferences-decision-theory-data-code", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20preferences%3Adecision%20theory%20%3A%3A%20data%3Acode&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Apreferences%3Adecision%20theory%20%3A%3A%20data%3Acode%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJScyTmTioK4xAR97f%2Fpreferences-decision-theory-data-code%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=preferences%3Adecision%20theory%20%3A%3A%20data%3Acode%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJScyTmTioK4xAR97f%2Fpreferences-decision-theory-data-code", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJScyTmTioK4xAR97f%2Fpreferences-decision-theory-data-code", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 798, "htmlBody": "<p>&nbsp;</p>\n<p>I'd like to present a couple thoughts. While I am somewhat confident in my reasonning, my conclusions strongly contradict what I perceive (possibly incorrectly) to be the concensus around decision theory on LessWrong. This consensus has been formed by people who have spent more time than me thinking about it, and are more intelligent than I am. I am aware of that, this is strong evidence that I am mistaken or obvious. I believe nonetheless the argument I'm about to make is valuable and should be heard.&nbsp;</p>\n<p>It is argued that the key difference between Newcomb's problem and Solomon's problem is that precommitment is useful in the former and useless in the latter. I agree that the problems are indeed different, but I do not think that is the fundamental reason. The devil is in the details.</p>\n<p>Solomon's problem states that</p>\n<p>&nbsp;- There is a gene that causes people to chew gum and to develop throat cancer<br />&nbsp;- Chewing gum benefits everyone</p>\n<p>It is generally claimed that EDT would decide <em>not to chew gum</em>, because doing so would place the agent in a state where its expected utility is reduced. This seems incorrect to me. The ambiguity is in what is meant by \"causes people to chew gum\". If the gene really <em>causes</em>&nbsp;people to chew gum, then that gene by definition affects that agent's decision theory, and the hypothesis that it is also following EDT is contradictory. What is generally meant is that having this gene induces a <em>preference</em>&nbsp;to chew gum, which is generally acted upon by whatever decision algorithm is used. An EDT agent must be fully aware of its own preferences, otherwise it could not calculate its own utility, therefore, the expected utility of chewing gum must be calculated conditional on having a preexisting or non preexisting taste for gum. In a nutshell, an EDT agent updates not on his action to chew gum, but on his desire to do so.</p>\n<p>I've established here a distinction between preferences and decision theory. In fact, the two are interchangeable. It is always possible to hard code preferences in the decision theory, and vice versa. The distinction is very similar to the one drawn between code and data. It is an arbitrary but useful distinction. Intuitively, I believe hard coding preferences in the decision algorithm is poor design, though I do not have a clear argument why that is.</p>\n<p>If we insist on preferences being part of the decision algorithm, the best decision algorithm for solomon's problem is the one that doesn't have a cancer causing gene. If the algorithm is EDT, then liking gum is a preference, and EDT makes the same decision as CDT.</p>\n<p>Let's now look at Newcomb's problem. Omega's decision is clearly not based on a subjective preference for one box or two box (let's say an aesthetic preference for example). Omega's decision is based on our decision algorithm itself. This is the key difference between the two problems, and this is why precommitment works for Newcomb's and not Solomon's.</p>\n<p>Solomon's problem is equivalent to this problem, which is not Newcomb's</p>\n<p>- If Omega thinks you were born loving Beige, he puts $1,000 in box Beige and nothing in box Aquamarine.<br />- Otherwise, he puts $1,000 in box Beige and nothing in box Aquamarine.</p>\n<p>In this problem, both CDT and EDT (correctly) two box. Again, this is because EDT <em>knows</em>&nbsp;that it loves beige.</p>\n<p>Now the real Newcomb's problem. I argue that an EDT agent should integrate his own decision as evidence.&nbsp;</p>\n<p>&nbsp;- If EDT's decision is to two-box, then Omega's prediction is that EDT two boxes and EDT should indeed two-box.<br />&nbsp;- If EDT's decision is to one-box, then Omega's prediction is that EDT one box, and EDT should two-box.&nbsp;</p>\n<p>Since EDT reflects on his own decision, it can only be the only fixed point which is to <em>two box</em>.</p>\n<p><em>Both CDT and EDT decide to chew gum and to two box.</em></p>\n<p>If we're out shopping for decision algorithms (TDT, UDT...), we might as well shop for a set of preferences, since they can be interchangeable. It is clear that some preferences allow winning, when variable sum games are involved. This has been implemented by evolution as moral preferences, not as decision algorithms. One useful preference is the preference to keep one's word. Such a preference allows to pay Parfit's hitchiker without involving any preference reversal. Once you're safe, you do not try not to pay, because you genuinely prefer not breaking your promise than keeping the money. Yes, you could have preferences to two box, but there is no reason why you should catter in advance to crazy cosmic entities rewarding certain algorithms or preferences. Omega is no more likely than the TDT and UDT minimizer, evil entities known for torturing TDT and UDT practionners.</p>\n<p>&nbsp;</p>\n<p>Edit: meant to write EDT two-boxes, which is the only fixed point.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JScyTmTioK4xAR97f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 6, "extendedScore": null, "score": 6.80877535857428e-07, "legacy": true, "legacyId": "5754", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T08:24:38.599Z", "modifiedAt": null, "url": null, "title": "Rationalist Hobbies", "slug": "rationalist-hobbies", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.719Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3DSmBLZ8Bi6ZMQBBk/rationalist-hobbies", "pageUrlRelative": "/posts/3DSmBLZ8Bi6ZMQBBk/rationalist-hobbies", "linkUrl": "https://www.lesswrong.com/posts/3DSmBLZ8Bi6ZMQBBk/rationalist-hobbies", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Hobbies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Hobbies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DSmBLZ8Bi6ZMQBBk%2Frationalist-hobbies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Hobbies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DSmBLZ8Bi6ZMQBBk%2Frationalist-hobbies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DSmBLZ8Bi6ZMQBBk%2Frationalist-hobbies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 271, "htmlBody": "<p>This is a place to talk about hobbies that teach rationality lessons. I'll start with a few:</p>\n<p><strong>Programming</strong> - Lets you practice math and logic, and gain an intuitive understanding of <em>computation</em>. Also teaches that sometimes you can't argue with reality, but you can fix it. (Also <a href=\"/r/discussion/lw/4ad/optimal_employment_open_thread/3k0b\">suggested</a> recently by ciphergoth.)</p>\n<p><strong>Cryptography </strong>- That is, designing/breaking cryptosystems and security protocols. Lets you practice math, logic, and probability theory. Also teaches that almost all human ideas are wrong. After doing this for a while, whenever you encounter a new idea (including your own), you'll instinctively think \"If I can't find anything wrong with this, it's probably because I'm not smart or knowledgeable enough or haven't tried hard enough.\"</p>\n<p><strong>Science fiction</strong> - Reduces status quo bias and gives interesting <a href=\"/lw/1lw/fictional_evidence_vs_fictional_insight/\">insights</a>. Also teaches that the way a society is organized depends a lot on the set of technologies it has access to, so if you don't like how your society works, one lever you have is to change that set.</p>\n<p><strong>Video games</strong> - Teaches that conventional \"success\" in life is not much less arbitrary than \"winning\" in a video game. They're both fine for a diversion, but there are more interesting goals to pursue.</p>\n<p>A couple others I've seen suggested in <a href=\"/lw/3wh/science_do_it_yourself/3ka1\">recent comments</a>:</p>\n<p><strong>Chess</strong> - According to JGWeissman, it \"teaches you to carefully consider the consequences of your available actions and choose the action with the best consequences\". (I've only played a few games of <a href=\"http://en.wikipedia.org/wiki/Xiangqi\">Chinese Chess</a>, and for me, the lesson was that I don't like competition, and I should look for things to do that nobody else is doing.)</p>\n<p><strong>Poker</strong> - Lets you practice statistics and overcoming emotional biases.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3DSmBLZ8Bi6ZMQBBk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 12, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "5691", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bkowF2N9uyYh4DXSe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T18:02:17.645Z", "modifiedAt": null, "url": null, "title": "[Link] \"It'll never work\": a collection of failed predictions", "slug": "link-it-ll-never-work-a-collection-of-failed-predictions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.675Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MRLg9zbw6p7YPbZoP/link-it-ll-never-work-a-collection-of-failed-predictions", "pageUrlRelative": "/posts/MRLg9zbw6p7YPbZoP/link-it-ll-never-work-a-collection-of-failed-predictions", "linkUrl": "https://www.lesswrong.com/posts/MRLg9zbw6p7YPbZoP/link-it-ll-never-work-a-collection-of-failed-predictions", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20%22It'll%20never%20work%22%3A%20a%20collection%20of%20failed%20predictions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20%22It'll%20never%20work%22%3A%20a%20collection%20of%20failed%20predictions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRLg9zbw6p7YPbZoP%2Flink-it-ll-never-work-a-collection-of-failed-predictions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20%22It'll%20never%20work%22%3A%20a%20collection%20of%20failed%20predictions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRLg9zbw6p7YPbZoP%2Flink-it-ll-never-work-a-collection-of-failed-predictions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMRLg9zbw6p7YPbZoP%2Flink-it-ll-never-work-a-collection-of-failed-predictions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4, "htmlBody": "<p><a href=\"http://www.lhup.edu/~dsimanek/neverwrk.htm\">http://www.lhup.edu/~dsimanek/neverwrk.htm</a></p>\n<p>(cross-posted from Hacker News)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MRLg9zbw6p7YPbZoP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 13, "extendedScore": null, "score": 6.810417434861418e-07, "legacy": true, "legacyId": "5769", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-19T21:13:00.020Z", "modifiedAt": null, "url": null, "title": "LW was started to help altruists", "slug": "lw-was-started-to-help-altruists", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.903Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rhollerith_dot_com", "createdAt": "2009-06-16T06:01:16.623Z", "isAdmin": false, "displayName": "rhollerith_dot_com"}, "userId": "bumwHGrDqhTTPqWs2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pAP665DEYLj95YY4c/lw-was-started-to-help-altruists", "pageUrlRelative": "/posts/pAP665DEYLj95YY4c/lw-was-started-to-help-altruists", "linkUrl": "https://www.lesswrong.com/posts/pAP665DEYLj95YY4c/lw-was-started-to-help-altruists", "postedAtFormatted": "Saturday, February 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20was%20started%20to%20help%20altruists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20was%20started%20to%20help%20altruists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAP665DEYLj95YY4c%2Flw-was-started-to-help-altruists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20was%20started%20to%20help%20altruists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAP665DEYLj95YY4c%2Flw-was-started-to-help-altruists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpAP665DEYLj95YY4c%2Flw-was-started-to-help-altruists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 613, "htmlBody": "<p>The following excerpt from a recent post, <a href=\"/r/discussion/lw/4e4/recursively_selfimproving_human_intelligence/\">Recursively Self-Improving Human Intelligence</a>, suggests to me that it is time for a reminder of the reason LW was started.</p>\n<p>\"[C]an anyone think of specific ways in which we can improve ourselves via iterative cycles? Is there a limit to how far we can currently improve our abilities by improving our abilities to improve our abilities? Or are these not the right questions; the concept a mere semantic illusion[?]\"</p>\n<p>These are not the right questions -- not because the concept is a semantic illusion, but rather because the questions are a little <em>too</em> selfish. I hope the author of the above words does not mind my saying that. It is the hope of the people who started this site (and my hope) that the readers of LW will eventually turn from the desire to improve their <em>selves</em> to the desire to improve the <em>world</em>. How the world (i.e., human civilization) can recursively self-improve has been extensively discussed on LW.</p>\n<p>Eliezer started devoting a significant portion of his time and energy to non-selfish pursuits when he was still a teenager, and in the 12 years since then, he has definitely spent more of his time and energy improving the world than improving his self (where \"self\" is defined to include his income, status, access to important people and other elements of his situation). About 3 years ago, when she was 28 or 29, Anna Salamon started spending most of her waking hours trying to improve the world. Both will almost certainly devote the majority of rest of their lives to altruistic goals.</p>\n<p>Self-improvement cannot be ignored or neglected even by pure altruists because the vast majority of people are not rational enough to cooperate with an Eliezer or an Anna without just slowing them down and the vast majority are not rational enough to avoid catastrophic mistakes were they to try without supervision to wield the most potent methods for improving the world. In other words, self-improvement cannot be ignored because now that we have modern science and technology, it takes more rationality than most people have just to be able to tell good from evil where \"good\" is defined as the actions that actually improve the world.</p>\n<p>One of the main reasons Eliezer started LW is to increase the rationality of <em>altruists</em> and of people who will become altruists. In other words, of people committed to improving the world. (The other main reason is recruitment for Eliezer's <em>altruistic</em> FAI project and <em>altruistic</em> organization). If the only people whose rationality they could hope to increase through LW were completely selfish, Eliezer and Anna would probably have put a lot less time and energy into posting rationality clues on LW and a lot more into other altruistic plans.</p>\n<p>Most altruists who are sufficiently strategic about their altruism come to believe that improving the effectiveness of other altruists is an extremely potent way to improve the world. Anna for example spends vastly more of her time and energy improving the rationality of other altruists than she spends improving her own rationality because that is the allotment of her resources that maximizes her altruistic goal of improving the world. Even the staff of the Singularity Institute who do not have Anna's teaching and helping skills and who consequently specialize in math, science and computers spend a significant fraction of their resources trying to improve the rationality of other altruists.</p>\n<p>In summary, although no one (that I know of) is opposed to self-improvement's being the focus of most of the posts on LW and no one is opposed to non-altruists' using the site for self-improvement, this site was founded in the hope of increasing the rationality of <em>altruists</em>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pAP665DEYLj95YY4c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": -7, "extendedScore": null, "score": 6.810925181214123e-07, "legacy": true, "legacyId": "5770", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pEbHHHR3aPLumaKJK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T00:07:48.657Z", "modifiedAt": null, "url": null, "title": "New blog", "slug": "new-blog", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.780Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chronophasiac", "createdAt": "2009-04-03T11:25:57.322Z", "isAdmin": false, "displayName": "chronophasiac"}, "userId": "wu2Hs7x6pbfJbMumC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ediGFWz5L5wW79xdb/new-blog", "pageUrlRelative": "/posts/ediGFWz5L5wW79xdb/new-blog", "linkUrl": "https://www.lesswrong.com/posts/ediGFWz5L5wW79xdb/new-blog", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20blog&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20blog%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FediGFWz5L5wW79xdb%2Fnew-blog%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20blog%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FediGFWz5L5wW79xdb%2Fnew-blog", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FediGFWz5L5wW79xdb%2Fnew-blog", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<p>Today I'm launching a new blog:&nbsp;http://www.trajectoryofeverything.com</p>\n<p>Subjects are mainly rationality and tech. Feedback of any sort is welcomed. Some of the posts relate to ideas that I've considered for LW but felt unworthy. I've been lurking in the LW/OB community since inception and one big goal for the blog is to get myself writing. Hopefully I'll work up to LW level at some point.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ediGFWz5L5wW79xdb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 6.811390664936134e-07, "legacy": true, "legacyId": "5771", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T01:10:24.142Z", "modifiedAt": null, "url": null, "title": "Do biases matter?", "slug": "do-biases-matter", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.919Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Student_UK", "createdAt": "2011-01-15T12:04:38.981Z", "isAdmin": false, "displayName": "Student_UK"}, "userId": "gEgpjQAqs4rfMZK7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C5PhoKQqwCdm27pZM/do-biases-matter", "pageUrlRelative": "/posts/C5PhoKQqwCdm27pZM/do-biases-matter", "linkUrl": "https://www.lesswrong.com/posts/C5PhoKQqwCdm27pZM/do-biases-matter", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20biases%20matter%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20biases%20matter%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC5PhoKQqwCdm27pZM%2Fdo-biases-matter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20biases%20matter%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC5PhoKQqwCdm27pZM%2Fdo-biases-matter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC5PhoKQqwCdm27pZM%2Fdo-biases-matter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 345, "htmlBody": "<p>It occurred to me that our biases might not matter very much lots of the time. They matter if you want to&nbsp;maximize&nbsp;your chances of finding the truth, but not if you are interested in&nbsp;maximizing&nbsp;the chances the chances of someone finding the truth.</p>\n<p>Take science as an example, scientists aren't always free from biases when it comes to thinking about their own theories. They look for ways to confirm what they believe, not discomfirm it. But does that matter? As long as their rivals are looking for ways to falsify those theories then overall the system should work well.</p>\n<p>In fact it might work better:</p>\n<p>Imagine that there is a prize (a really big prize) at the end of a maze. Several of you are sent into the maze and the first person to find the prize gets to keep it. You all head down the corridor and come to three doors, there are some clues written on the wall, but before you can even begin to read them, someone dashes through door 1. Someone else follows then another through door 2 and a few take door 3. What do you do? You could be methodical and try to solve the clues. This would&nbsp;maximize&nbsp;your chance of finding the right path. However, it will not maximize your chances of being the first one to find the prize. For this, you need to pick a door and run.</p>\n<p>Likewise, in science, if you want to get the prize (nobel prize, or a good job, or fame, or a best-selling book), then you might be better off coming up with a new theory and running with it (anecdotally, this seems to be what a lot of successful scientists have done). Having lots of people making leaps in different directions might also make science progress faster overall.</p>\n<p>What does all this mean for biases? Are they best thought of on an individual level or group level? Is it really a bias if it is the best thing to do? Can you think of other examples where individual biases might produce better results for the group?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C5PhoKQqwCdm27pZM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 0, "extendedScore": null, "score": 6.811557346263482e-07, "legacy": true, "legacyId": "5772", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T04:08:11.357Z", "modifiedAt": null, "url": null, "title": "Request for Widely Applicable Quantitative Methods", "slug": "request-for-widely-applicable-quantitative-methods", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.944Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SFdeSGZ83uTS8QWWf/request-for-widely-applicable-quantitative-methods", "pageUrlRelative": "/posts/SFdeSGZ83uTS8QWWf/request-for-widely-applicable-quantitative-methods", "linkUrl": "https://www.lesswrong.com/posts/SFdeSGZ83uTS8QWWf/request-for-widely-applicable-quantitative-methods", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Request%20for%20Widely%20Applicable%20Quantitative%20Methods&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequest%20for%20Widely%20Applicable%20Quantitative%20Methods%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFdeSGZ83uTS8QWWf%2Frequest-for-widely-applicable-quantitative-methods%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Request%20for%20Widely%20Applicable%20Quantitative%20Methods%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFdeSGZ83uTS8QWWf%2Frequest-for-widely-applicable-quantitative-methods", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFdeSGZ83uTS8QWWf%2Frequest-for-widely-applicable-quantitative-methods", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 164, "htmlBody": "<p>I'm going to be competing in the Moody's Mega Math Challenge, and I was wondering if there was anything in particular I should brush up on.<br /><br />If you look at <a href=\"http://m3challenge.siam.org/problem/\">previous problems</a>, you can see that they're pretty varied. I want to know if there's any widely applicable math that we could study (in a fairly short amount of time) to maximize the odds of us knowing something useful for the competition.</p>\n<p>Our math backgrounds include:</p>\n<ul>\n<li>Statistics (taught by a frequentist, mostly just probability theory and p, z, chi-squared, etc. tests)</li>\n<li>Calculus (single variable and multivariable)</li>\n<li>Linear Algebra</li>\n<li>Numerical Methods</li>\n</ul>\n<div>We're also pretty competent at programming in various programming languages, and LaTeX.<br /><br />Currently we're looking into Causality by Judea Pearl, and Linear Programming. Should we look at these? Anything else we should know?</div>\n<p>Edit:<br />I suppose we could also use a genetic algorithm, but those don't seem particularly suited to the competition.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SFdeSGZ83uTS8QWWf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 6.812030833478687e-07, "legacy": true, "legacyId": "5774", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T04:14:54.389Z", "modifiedAt": null, "url": null, "title": "Social ethics vs decision theory", "slug": "social-ethics-vs-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:49.737Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yBj3m7Q5cWKJyfgDP/social-ethics-vs-decision-theory", "pageUrlRelative": "/posts/yBj3m7Q5cWKJyfgDP/social-ethics-vs-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/yBj3m7Q5cWKJyfgDP/social-ethics-vs-decision-theory", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Social%20ethics%20vs%20decision%20theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASocial%20ethics%20vs%20decision%20theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBj3m7Q5cWKJyfgDP%2Fsocial-ethics-vs-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Social%20ethics%20vs%20decision%20theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBj3m7Q5cWKJyfgDP%2Fsocial-ethics-vs-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyBj3m7Q5cWKJyfgDP%2Fsocial-ethics-vs-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>It seems to me that usually, when someone says \"ethics\" on lesswrong, ey usually means something along the lines of decision theory. When an average person says \"ethics\", ey is usually referring to a system of intuitions and social pressures designed to influence the behavior of members of a group. I think that a lot of the disagreement regarding ethics (i.e. consequentialism vs deontology) is rooted in a failure to properly distinguish between decision theory and what society pressures people to do. Most lesswrong users probably understand the distinction fairly clearly, but we only ever talk about decision theory. Why don't we talk about the social meaning of ethics?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yBj3m7Q5cWKJyfgDP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 6.812048723755958e-07, "legacy": true, "legacyId": "5775", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T05:11:54.770Z", "modifiedAt": null, "url": null, "title": "Deception by cherry picking", "slug": "deception-by-cherry-picking", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.480Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlephNeil", "createdAt": "2010-05-12T14:43:28.879Z", "isAdmin": false, "displayName": "AlephNeil"}, "userId": "qSNSSwAXbki7JTNSd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eJ7kbJvLCQ8JnoiHT/deception-by-cherry-picking", "pageUrlRelative": "/posts/eJ7kbJvLCQ8JnoiHT/deception-by-cherry-picking", "linkUrl": "https://www.lesswrong.com/posts/eJ7kbJvLCQ8JnoiHT/deception-by-cherry-picking", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Deception%20by%20cherry%20picking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeception%20by%20cherry%20picking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeJ7kbJvLCQ8JnoiHT%2Fdeception-by-cherry-picking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Deception%20by%20cherry%20picking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeJ7kbJvLCQ8JnoiHT%2Fdeception-by-cherry-picking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeJ7kbJvLCQ8JnoiHT%2Fdeception-by-cherry-picking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 303, "htmlBody": "<p>[This is an idea I've had 'kicking around' for a long time - may as well see what LW makes of it.]</p>\n<p>The Bayesian update procedure tacitly presupposes that the event we're updating on is not itself random. Indeed, naively updating on a random event, that turns out to be correlated with the variable of interest, is how people get Monty Hall wrong.</p>\n<p>A false statement can often be made to seem plausible if you naively update on a set of misleading, 'cherry picked' facts.</p>\n<p>To make this concrete, imagine a biased coin which we know has probability 1/3 or 2/3 of landing heads - in fact it's 1/3 but we don't know that. Say it's tossed 2000 times. Then someone who wanted to mislead us could cherry pick a sample of 100 in which, say, 70 of the coin tosses landed heads, and hope we assume they picked their sample randomly. (More insidiously, using <a href=\"http://www.metacafe.com/watch/2187084/derren_brown_secrets_revealed/\">Derren Brown</a>'s variety of dark arts they could even trick us into choosing that sample ourselves, believing that we're choosing 'of our own free will'.)</p>\n<p>But now here's the thing: That sample of 100 probably has a high minimum description length. If it had a sufficiently low minimum description length - like if it consisted of 100 contiguous tosses - then even if we suspected \"Derren Brown\" was trying to manipulate us, our sample would still give us evidence that heads has probability 2/3.</p>\n<p>I think there should be a theorem which looks like:</p>\n<p>\"The largest x such that we'd be irrational not to increase our subjective log-odds of event E by at least x, even if our data was provided by an adversary\" = log[P(data|E) / P(data|&not;E)] - \"The minimum description length of the data\" - O(1)</p>\n<p>Anyone familiar with \"the theory of how to update on evidence provided by adversaries\" (assuming it exists)?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eJ7kbJvLCQ8JnoiHT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "5776", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T05:19:16.058Z", "modifiedAt": null, "url": null, "title": "Tool for combating undue hesitation", "slug": "tool-for-combating-undue-hesitation", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:48.854Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZZPhFRynrE5QcEr6N/tool-for-combating-undue-hesitation", "pageUrlRelative": "/posts/ZZPhFRynrE5QcEr6N/tool-for-combating-undue-hesitation", "linkUrl": "https://www.lesswrong.com/posts/ZZPhFRynrE5QcEr6N/tool-for-combating-undue-hesitation", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tool%20for%20combating%20undue%20hesitation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATool%20for%20combating%20undue%20hesitation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZPhFRynrE5QcEr6N%2Ftool-for-combating-undue-hesitation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tool%20for%20combating%20undue%20hesitation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZPhFRynrE5QcEr6N%2Ftool-for-combating-undue-hesitation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZZPhFRynrE5QcEr6N%2Ftool-for-combating-undue-hesitation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 320, "htmlBody": "<p>I sometimes feel negative emotions at the thought that the course of action that I am taking isn't even close to the optimal course of action -- that a more effective mind could sort through whatever situation I'm currently having difficulty with and craft a plan that was much more likely to succeed than any of my own. In short, I feel inept in comparison to the better minds in the space-of-all-possible-minds, and so I experience undue hesitation while I'm trying to figure out the correct action to take. Of course, good planning often leads to better results, but this behavioral pattern has a significantly negative effect in situations (especially social ones) where I need to make a decision quickly.</p>\n<p>I've found that it helps me think more rapidly and clearly if I think in terms of which of the possible actions that I've thought of will produce the greatest positive difference in net expected utility in comparison to doing nothing. Once I come up with a course of action, I no longer feel a sense of paralysis at how inept my decision-making skills must be compared to much better minds than my own, which saves a certain amount of mental processing power and emotional effort which can then be used for other things. Doing this also helps to prevent panic and the like from springing up because I'm not thinking in terms of whether I can succeed or not, but sorting through which actions maximize my chances of succeeding out of the set of actions that I've currently&nbsp; thought up.</p>\n<p>I feel like I've written less than I think that I've written -- that people may not get much out of this post because they haven't actually shared my brain with me, and I've done an inadequate job of deconstructing my thoughts when I've put them to paper. If this is correct, please tell me and I can try to elaborate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZZPhFRynrE5QcEr6N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 6.812220147344576e-07, "legacy": true, "legacyId": "5777", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T09:06:50.393Z", "modifiedAt": null, "url": null, "title": "Age, fluid intelligence, and intelligent posts", "slug": "age-fluid-intelligence-and-intelligent-posts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:28.701Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TwjKr4KayRm4JvoXi/age-fluid-intelligence-and-intelligent-posts", "pageUrlRelative": "/posts/TwjKr4KayRm4JvoXi/age-fluid-intelligence-and-intelligent-posts", "linkUrl": "https://www.lesswrong.com/posts/TwjKr4KayRm4JvoXi/age-fluid-intelligence-and-intelligent-posts", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Age%2C%20fluid%20intelligence%2C%20and%20intelligent%20posts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAge%2C%20fluid%20intelligence%2C%20and%20intelligent%20posts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTwjKr4KayRm4JvoXi%2Fage-fluid-intelligence-and-intelligent-posts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Age%2C%20fluid%20intelligence%2C%20and%20intelligent%20posts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTwjKr4KayRm4JvoXi%2Fage-fluid-intelligence-and-intelligent-posts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTwjKr4KayRm4JvoXi%2Fage-fluid-intelligence-and-intelligent-posts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 433, "htmlBody": "<p><img src=\"https://lh4.googleusercontent.com/_gxYAfFM1cj0/S6hXmZ4qtjI/AAAAAAAAAUc/mBtqICfKs2w/brainage.jpg\" alt=\"\" width=\"780\" height=\"436\" /></p>\n<p>As this diagram shows, fluid intelligence generally declines with age after age 20 (this is an effect that is confirmed across multiple studies - you can find more if you google fluid intelligence + age online.</p>\n<p>Yet, on the other hand, I've noticed that the most intelligent+aware posts almost always come from older people (there are exceptions, of course). Of course, intelligent posts depend more on crystallized intelligence rather than on fluid intelligence, and crystallized intelligence only grows with age (this is *especially* true for LessWrong users, since they are far more mentally engaged (in mid-life) than the groups that are probably tested on these metrics. But yet, it still takes a significant amount of mental effort to actually write intellectual posts, so I'm pretty sure that there's still some dependence on fluid intelligence.</p>\n<p>In any case, I'd like to propose this question: Have you found it harder or easier to write thoughtful+intelligent posts as you've grown older? And how have changes in your brain and in knowledge affected the thoughtfulness of these posts. What do you think is your biggest constraint in making these posts? While I'm still very young compared to most people here, I've still noticed that the number of examples I can think of is the primary constraint to the amount I can write, and so I can expect myself to write better with time (since I'll learn more examples+have better ways of finding them), assuming no decline in fluid IQ.</p>\n<p>Additionally, do old authors write any less well than younger authors? Especially authors who are very old? Jacques Barzun, in particular, wrote his last book at age 99. But it seems that most people have stopped producing by that age. It is said that Hans Bethe was the only nonagenarian physicist who produced a top-calibre publication in his 90s, for example. Of course, many of these effects are average, and beating the average is pretty easy if we're motivated enough to do it (simply because many others aren't motivated, and also because intellectual stimulation helps stave off brain shrinkage). But even in the end, beating the average may not be enough to prevent decline.</p>\n<p>There's some more interesting literature on this in Dean Simonton's books (Psychology of Science in particular). Basically, they show that scientific productivity increase with age, but only up to a point, and then they start to decline. Some of these effects may be related to decreased motivation or decreased time, but it's also possible that some of them are related to decreased fluid intelligence (especially given that the declines come earlier for physical scientists than for social scientists)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TwjKr4KayRm4JvoXi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 6.81282633925547e-07, "legacy": true, "legacyId": "5778", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T19:23:27.257Z", "modifiedAt": null, "url": null, "title": "Updateless anthropics", "slug": "updateless-anthropics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.403Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3dmpfGgXZzB28JZdS/updateless-anthropics", "pageUrlRelative": "/posts/3dmpfGgXZzB28JZdS/updateless-anthropics", "linkUrl": "https://www.lesswrong.com/posts/3dmpfGgXZzB28JZdS/updateless-anthropics", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Updateless%20anthropics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUpdateless%20anthropics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3dmpfGgXZzB28JZdS%2Fupdateless-anthropics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Updateless%20anthropics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3dmpfGgXZzB28JZdS%2Fupdateless-anthropics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3dmpfGgXZzB28JZdS%2Fupdateless-anthropics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1595, "htmlBody": "<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-GB</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin-top:0cm; mso-para-margin-right:0cm; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0cm; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif]-->\n<p>Three weeks ago, I set out to find a new theory of anthropics, to try and set decision theory on a firm&nbsp;footing with respect to copying, deleting copies, merging them, correlated decisions, and the presence or absence of extra observers. I've since come full circle, and realised that UDT already has a built-in anthropic theory, that resolves a lot of the problems that had been confusing me.</p>\n<p>The theory is simple, and is essentially a rephrasing of UDT:&nbsp;if you are facing a decision X, and trying to figure out the utility of X=a for some action a, then&nbsp;calculate the full expected utility of X being a,&nbsp;given&nbsp;the objective probabilities of each world (including those in which you don't exist).</p>\n<p>As usual, you have to consider&nbsp;the consequences of X=a for all agents who will make the same decision as you, whether they be exact copies, enemies, simulations or similar-minded people. However, your utility will have to do more work that is usually realised: notions such as selfishness or altruism with respect to your copies have to be encoded in the utility function, and will result in substantially different behaviour.</p>\n<p>The rest of the post is&nbsp;a series of cases-studies illustrating this theory. Utility is assumed to be linear in cash for convenience.</p>\n<p><strong>Sleeping with the Presumptuous Philosopher</strong>&nbsp;</p>\n<p>The first test case is the <a href=\"http://en.wikipedia.org/wiki/Sleeping_Beauty_problem\">Sleeping Beauty</a> problem.</p>\n<hr />\n<p>&nbsp;In its simplest form, this involves a coin toss; if it comes out heads, one copy of Sleeping Beauty is created. If it comes out tails, two copies are created. Then the copies are asked at what odds they would be prepared to bet that the coin came out tails. You can assume either that the different copies care for each other&nbsp;in the manner I&nbsp;detailed <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and\">here</a>, or more simply that <em>all</em> winnings will be kept by a future merged copy (or an approved charity). Then the algorithm is simple: the two worlds have equal probability. Let X be the decision where sleeping beauty decides between a contract that pays out&nbsp;$1 if the coin is heads, versus one that pays out $1 if the coin is tails. If X=\"heads\" (to use an obvious shorthand), then Sleeping Beauty will expect to make $1*0.5, as she is offered the contract once. If X=\"tails\", then the total return of that decision is $1*2*0.5, as copies of her will be offered the contract twice, and they will all make the same decision. So Sleeping Beauty will follow the SIA 2:1 betting odds of tails over heads.</p>\n<p>Variants such as \"extreme Sleeping Beauty\" (where thousands of copies are created on tails) will behave in the same way; if it feels counter-intuitive to bet at thousands-to-one odds that a fair&nbsp;coin landed tails, it's the fault of expected utility itself, as the rewards of being right dwarf the costs of being wrong.</p>\n<p>But now let's turn to the Presumptuous Philosopher, a thought experiment that is often confused with Sleeping Beauty. Here we have exactly the same setup as \"extreme Sleeping Beauty\", but the agents (the Presumptuous philosophers) are mutually selfish. Here the return to X=\"heads\" remains $1*0.5. However the return to X=\"tails\" is also $1*0.5, since even if all the Presumptuous Philosophers in the \"tails\" universe bet on \"tails\", each one will still only get $1 in utility. So the Presumptuous Philosopher should only take even SSA betting 1:1 odds on the result of the coin flip.</p>\n<p>So SB is acts like she follows the <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">self-indication assumption</a>, (SIA), and while the PP is following the <a href=\"http://www.acceleratingfuture.com/michael/blog/2006/01/the-self-sampling-assumption/\">self-sampling assumption</a> (SSA). This remains true if we change the setup so that one agent is&nbsp;given a betting opportunity in the tails universe. Then the objective probability of any one agent being asked is low, so both SB and PP model the \"objective probability\" of the tails world, given that they have been asked to bet, as being low. However, SB gains utility if any of her copies is asked to bet and receives a profit, so the strategy \"if I'm offered $1 if I guess correctly whether the coin is heads or tails, I will say tails\" gets her $1*0.5 utility whether or not she is the specific one who is asked. Betting heads nets her the same result, so SB will give SIA 1:1 odds in this case.</p>\n<p>On the other hand, the PP will only gain utility in the very specific world where he himself is asked to bet. So his gain from the updateless \"if I'm offered $1 if I guess correctly whether the coin is heads or tails, I will say tails\" is tiny, as he's unlikely to be asked to bet. Hence he will offer the SSA odds that make heads a much more \"likely\" proposition.</p>\n<p><strong>The Doomsday argument</strong></p>\n<p>Now, using SSA odds brings us back into the realm of the classical&nbsp;<a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">Doomsday argument</a>. How is it that Sleeping Beauty is immune to the Doomsday argument while the Presumptuous Philosopher is not? Which one is right; is the world really about to end?</p>\n<p>Asking about probabilities independently of decisions is <a href=\"/lw/32o/if_a_tree_falls_on_sleeping_beauty\">meaningless</a> here; instead, we can ask what would agents decide in particular cases. It's not surprising that agents will reach different decisions on such questions as, for instance, existential risk mitigation, if they have different preferences.</p>\n<p>Let's do a very simplified model, where there are two agents in the world, and that one of them is approached at random to see if they would pay $Y to add a third agent. Each agent derives a (non-indexical) utility of $1 for the presence of this third agent, and nothing else happens in the world to increase or decrease anyone's utility.</p>\n<p>First, let's assume that each agent is selfish about their indexical&nbsp;utility (their cash in the hand). If the decision is&nbsp;to not add a third agent,&nbsp;all will&nbsp;get $0 utility. If the decision is to add a third agent, then there are three agents in the world, and one&nbsp;them will be approached to lose $Y. Hence the expected utility is $(1-Y/3).</p>\n<p>Now let us assume the agents are altruistic towards each other's indexical utilities. Then the expected utility of not adding a third agent is&nbsp;still $0. If the decision is to add a third agent, then there are three agents in the world, and one of them will be approached to lose $Y - but all will value that lose at the same amount. Hence the expected utility is $(1-Y).</p>\n<p>So if $Y=$2, for instance, the \"selfish\" agents will add the third agent, and the \"altruistic\" ones will not. So generalising this to more complicated models&nbsp;describing existential risk mitigations&nbsp;schemes, we would expect SB-type agents to behave differently to PP-types in most models. There is no sense in asking which one is \"right\" and which one gives the more accurate \"probability of doom\"; instead ask yourself which&nbsp;better corresponds to your own utility model, hence what your decision will be.</p>\n<p><strong>Psy-Kosh's non-anthropic problem</strong></p>\n<p>Cousin_it has a <a href=\"/lw/3dy/has_anyone_solved_psykoshs_nonanthropic_problem\">rephrasing</a> of Psy-Kosh's&nbsp;<a href=\"/lw/17c/outlawing_anthropics_an_updateless_dilemma/13e1\">non-anthropic problem</a> to which updateless anthropics can be illustratively applied:</p>\n<p>You are one of a group of 10 people who care about saving African kids. You will all be put in separate rooms, then I will flip a coin. If the coin comes up heads, a random one of you will be designated as the \"decider\". If it comes up tails, <em>nine</em> of you will be designated as \"deciders\". Next, I will tell everyone their status, without telling the status of others. Each decider will be asked to say \"yea\" or \"nay\". If the coin came up tails and all nine deciders say \"yea\", I donate $1000 to VillageReach. If the coin came up heads and the sole decider says \"yea\", I donate only $100. If all deciders say \"nay\", I donate $700 regardless of the result of the coin toss. If the deciders disagree, I don't donate anything.</p>\n<p>We'll set aside the \"deciders disagree\" and assume that you will all reach the same decision. The point of the problem was to illustrate a supposed preference inversion: if you coordinate ahead of time, you should all agree to say \"nay\", but after you have been told you're a decider, you should update in the direction of the coin coming up tails, and say \"yea\".</p>\n<p>From the updateless perspective, however, there is no mystery here: the strategy \"if I were a decider, I would say nay\" maximises utility both for the deciders and the non-deciders.</p>\n<p>But what if the problem were rephrased in a more selfish way, with the non-deciders not getting any utility from the setup (maybe they don't get to see the photos of the grateful saved African kids), while the deciders got the same utility as before? Then the strategy \"if I were a decider, I would say yea\" maximises your expect utility, because non-deciders get nothing, thus reducing the expected utility gains and losses&nbsp;in the world where the coin came out tails. This is similar to SIA odds, again.</p>\n<p>That second model is similar to the way I argued for SIA with agents getting <a href=\"/lw/18r/avoiding_doomsday_a_proof_of_the_selfindication\">created and destroyed</a>. That post has been superseded by <a href=\"/lw/4fl/dead_men_tell_tales_falling_out_of_love_with_sia\">this one</a>, which pointed out the flaw in the argument which was (roughly speaking) not considering setups like Psy-Kosh's original model. So once again, whether utility is broadly shared or not affects the outcome of the decision.</p>\n<p><strong>The Anthropic Trilemma</strong></p>\n<p>Eliezer's <a href=\"/lw/19d/the_anthropic_trilemma\">anthropic trilemma</a> was an interesting puzzle involving probabilities, copying, and subjective anticipation. It inspired me to come up with a way of spreading <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and\">utility across multiple copies</a> which was essentially a Sleeping Beauty copy-altruistic model. The decision process going with it is then the same as the updateless decision process outlined here. Though initially it was phrased in terms of SIA probabilities and individual impact, the isomorphism between the two can be seen <a href=\"/lw/4dz/revisiting_the_anthropic_trilemma_iii_solutions\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3dmpfGgXZzB28JZdS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 13, "extendedScore": null, "score": 6.814469315623634e-07, "legacy": true, "legacyId": "5766", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-GB</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin-top:0cm; mso-para-margin-right:0cm; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0cm; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif]-->\n<p>Three weeks ago, I set out to find a new theory of anthropics, to try and set decision theory on a firm&nbsp;footing with respect to copying, deleting copies, merging them, correlated decisions, and the presence or absence of extra observers. I've since come full circle, and realised that UDT already has a built-in anthropic theory, that resolves a lot of the problems that had been confusing me.</p>\n<p>The theory is simple, and is essentially a rephrasing of UDT:&nbsp;if you are facing a decision X, and trying to figure out the utility of X=a for some action a, then&nbsp;calculate the full expected utility of X being a,&nbsp;given&nbsp;the objective probabilities of each world (including those in which you don't exist).</p>\n<p>As usual, you have to consider&nbsp;the consequences of X=a for all agents who will make the same decision as you, whether they be exact copies, enemies, simulations or similar-minded people. However, your utility will have to do more work that is usually realised: notions such as selfishness or altruism with respect to your copies have to be encoded in the utility function, and will result in substantially different behaviour.</p>\n<p>The rest of the post is&nbsp;a series of cases-studies illustrating this theory. Utility is assumed to be linear in cash for convenience.</p>\n<p><strong>Sleeping with the Presumptuous Philosopher</strong>&nbsp;</p>\n<p>The first test case is the <a href=\"http://en.wikipedia.org/wiki/Sleeping_Beauty_problem\">Sleeping Beauty</a> problem.</p>\n<hr>\n<p>&nbsp;In its simplest form, this involves a coin toss; if it comes out heads, one copy of Sleeping Beauty is created. If it comes out tails, two copies are created. Then the copies are asked at what odds they would be prepared to bet that the coin came out tails. You can assume either that the different copies care for each other&nbsp;in the manner I&nbsp;detailed <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and\">here</a>, or more simply that <em>all</em> winnings will be kept by a future merged copy (or an approved charity). Then the algorithm is simple: the two worlds have equal probability. Let X be the decision where sleeping beauty decides between a contract that pays out&nbsp;$1 if the coin is heads, versus one that pays out $1 if the coin is tails. If X=\"heads\" (to use an obvious shorthand), then Sleeping Beauty will expect to make $1*0.5, as she is offered the contract once. If X=\"tails\", then the total return of that decision is $1*2*0.5, as copies of her will be offered the contract twice, and they will all make the same decision. So Sleeping Beauty will follow the SIA 2:1 betting odds of tails over heads.</p>\n<p>Variants such as \"extreme Sleeping Beauty\" (where thousands of copies are created on tails) will behave in the same way; if it feels counter-intuitive to bet at thousands-to-one odds that a fair&nbsp;coin landed tails, it's the fault of expected utility itself, as the rewards of being right dwarf the costs of being wrong.</p>\n<p>But now let's turn to the Presumptuous Philosopher, a thought experiment that is often confused with Sleeping Beauty. Here we have exactly the same setup as \"extreme Sleeping Beauty\", but the agents (the Presumptuous philosophers) are mutually selfish. Here the return to X=\"heads\" remains $1*0.5. However the return to X=\"tails\" is also $1*0.5, since even if all the Presumptuous Philosophers in the \"tails\" universe bet on \"tails\", each one will still only get $1 in utility. So the Presumptuous Philosopher should only take even SSA betting 1:1 odds on the result of the coin flip.</p>\n<p>So SB is acts like she follows the <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">self-indication assumption</a>, (SIA), and while the PP is following the <a href=\"http://www.acceleratingfuture.com/michael/blog/2006/01/the-self-sampling-assumption/\">self-sampling assumption</a> (SSA). This remains true if we change the setup so that one agent is&nbsp;given a betting opportunity in the tails universe. Then the objective probability of any one agent being asked is low, so both SB and PP model the \"objective probability\" of the tails world, given that they have been asked to bet, as being low. However, SB gains utility if any of her copies is asked to bet and receives a profit, so the strategy \"if I'm offered $1 if I guess correctly whether the coin is heads or tails, I will say tails\" gets her $1*0.5 utility whether or not she is the specific one who is asked. Betting heads nets her the same result, so SB will give SIA 1:1 odds in this case.</p>\n<p>On the other hand, the PP will only gain utility in the very specific world where he himself is asked to bet. So his gain from the updateless \"if I'm offered $1 if I guess correctly whether the coin is heads or tails, I will say tails\" is tiny, as he's unlikely to be asked to bet. Hence he will offer the SSA odds that make heads a much more \"likely\" proposition.</p>\n<p><strong id=\"The_Doomsday_argument\">The Doomsday argument</strong></p>\n<p>Now, using SSA odds brings us back into the realm of the classical&nbsp;<a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">Doomsday argument</a>. How is it that Sleeping Beauty is immune to the Doomsday argument while the Presumptuous Philosopher is not? Which one is right; is the world really about to end?</p>\n<p>Asking about probabilities independently of decisions is <a href=\"/lw/32o/if_a_tree_falls_on_sleeping_beauty\">meaningless</a> here; instead, we can ask what would agents decide in particular cases. It's not surprising that agents will reach different decisions on such questions as, for instance, existential risk mitigation, if they have different preferences.</p>\n<p>Let's do a very simplified model, where there are two agents in the world, and that one of them is approached at random to see if they would pay $Y to add a third agent. Each agent derives a (non-indexical) utility of $1 for the presence of this third agent, and nothing else happens in the world to increase or decrease anyone's utility.</p>\n<p>First, let's assume that each agent is selfish about their indexical&nbsp;utility (their cash in the hand). If the decision is&nbsp;to not add a third agent,&nbsp;all will&nbsp;get $0 utility. If the decision is to add a third agent, then there are three agents in the world, and one&nbsp;them will be approached to lose $Y. Hence the expected utility is $(1-Y/3).</p>\n<p>Now let us assume the agents are altruistic towards each other's indexical utilities. Then the expected utility of not adding a third agent is&nbsp;still $0. If the decision is to add a third agent, then there are three agents in the world, and one of them will be approached to lose $Y - but all will value that lose at the same amount. Hence the expected utility is $(1-Y).</p>\n<p>So if $Y=$2, for instance, the \"selfish\" agents will add the third agent, and the \"altruistic\" ones will not. So generalising this to more complicated models&nbsp;describing existential risk mitigations&nbsp;schemes, we would expect SB-type agents to behave differently to PP-types in most models. There is no sense in asking which one is \"right\" and which one gives the more accurate \"probability of doom\"; instead ask yourself which&nbsp;better corresponds to your own utility model, hence what your decision will be.</p>\n<p><strong id=\"Psy_Kosh_s_non_anthropic_problem\">Psy-Kosh's non-anthropic problem</strong></p>\n<p>Cousin_it has a <a href=\"/lw/3dy/has_anyone_solved_psykoshs_nonanthropic_problem\">rephrasing</a> of Psy-Kosh's&nbsp;<a href=\"/lw/17c/outlawing_anthropics_an_updateless_dilemma/13e1\">non-anthropic problem</a> to which updateless anthropics can be illustratively applied:</p>\n<p>You are one of a group of 10 people who care about saving African kids. You will all be put in separate rooms, then I will flip a coin. If the coin comes up heads, a random one of you will be designated as the \"decider\". If it comes up tails, <em>nine</em> of you will be designated as \"deciders\". Next, I will tell everyone their status, without telling the status of others. Each decider will be asked to say \"yea\" or \"nay\". If the coin came up tails and all nine deciders say \"yea\", I donate $1000 to VillageReach. If the coin came up heads and the sole decider says \"yea\", I donate only $100. If all deciders say \"nay\", I donate $700 regardless of the result of the coin toss. If the deciders disagree, I don't donate anything.</p>\n<p>We'll set aside the \"deciders disagree\" and assume that you will all reach the same decision. The point of the problem was to illustrate a supposed preference inversion: if you coordinate ahead of time, you should all agree to say \"nay\", but after you have been told you're a decider, you should update in the direction of the coin coming up tails, and say \"yea\".</p>\n<p>From the updateless perspective, however, there is no mystery here: the strategy \"if I were a decider, I would say nay\" maximises utility both for the deciders and the non-deciders.</p>\n<p>But what if the problem were rephrased in a more selfish way, with the non-deciders not getting any utility from the setup (maybe they don't get to see the photos of the grateful saved African kids), while the deciders got the same utility as before? Then the strategy \"if I were a decider, I would say yea\" maximises your expect utility, because non-deciders get nothing, thus reducing the expected utility gains and losses&nbsp;in the world where the coin came out tails. This is similar to SIA odds, again.</p>\n<p>That second model is similar to the way I argued for SIA with agents getting <a href=\"/lw/18r/avoiding_doomsday_a_proof_of_the_selfindication\">created and destroyed</a>. That post has been superseded by <a href=\"/lw/4fl/dead_men_tell_tales_falling_out_of_love_with_sia\">this one</a>, which pointed out the flaw in the argument which was (roughly speaking) not considering setups like Psy-Kosh's original model. So once again, whether utility is broadly shared or not affects the outcome of the decision.</p>\n<p><strong id=\"The_Anthropic_Trilemma\">The Anthropic Trilemma</strong></p>\n<p>Eliezer's <a href=\"/lw/19d/the_anthropic_trilemma\">anthropic trilemma</a> was an interesting puzzle involving probabilities, copying, and subjective anticipation. It inspired me to come up with a way of spreading <a href=\"/lw/48h/revisiting_the_anthropic_trilemma_ii_axioms_and\">utility across multiple copies</a> which was essentially a Sleeping Beauty copy-altruistic model. The decision process going with it is then the same as the updateless decision process outlined here. Though initially it was phrased in terms of SIA probabilities and individual impact, the isomorphism between the two can be seen <a href=\"/lw/4dz/revisiting_the_anthropic_trilemma_iii_solutions\">here</a>.</p>", "sections": [{"title": "The Doomsday argument", "anchor": "The_Doomsday_argument", "level": 1}, {"title": "Psy-Kosh's non-anthropic problem", "anchor": "Psy_Kosh_s_non_anthropic_problem", "level": 1}, {"title": "The Anthropic Trilemma", "anchor": "The_Anthropic_Trilemma", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "13 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JWnv9fQzK6Rpnx5eN", "gMXsyhPiEJbGerF6F", "YZzoWGCJsoRBBbmQg", "5A9x74mgCwJwSg4sN", "LnearFbA4thE646tR", "y7jZ9BLEeuNTzgAE5", "BwArqWoE3bsyRn5Dn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-20T19:47:25.953Z", "modifiedAt": null, "url": null, "title": "What does your web of beliefs look like, as of today?", "slug": "what-does-your-web-of-beliefs-look-like-as-of-today", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.524Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FrxQPAEzDk5sg88BM/what-does-your-web-of-beliefs-look-like-as-of-today", "pageUrlRelative": "/posts/FrxQPAEzDk5sg88BM/what-does-your-web-of-beliefs-look-like-as-of-today", "linkUrl": "https://www.lesswrong.com/posts/FrxQPAEzDk5sg88BM/what-does-your-web-of-beliefs-look-like-as-of-today", "postedAtFormatted": "Sunday, February 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20does%20your%20web%20of%20beliefs%20look%20like%2C%20as%20of%20today%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20does%20your%20web%20of%20beliefs%20look%20like%2C%20as%20of%20today%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrxQPAEzDk5sg88BM%2Fwhat-does-your-web-of-beliefs-look-like-as-of-today%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20does%20your%20web%20of%20beliefs%20look%20like%2C%20as%20of%20today%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrxQPAEzDk5sg88BM%2Fwhat-does-your-web-of-beliefs-look-like-as-of-today", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrxQPAEzDk5sg88BM%2Fwhat-does-your-web-of-beliefs-look-like-as-of-today", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 993, "htmlBody": "<p>Every few months, I post a summary of my beliefs to my <a href=\"http://commonsenseatheism.com/\">blog</a>. This has several advantages:</p>\n<ol>\n<li>It helps to clarify where I'm \"coming from\" in general.</li>\n<li>It clears up reader confusion arising from the fact that my beliefs change.</li>\n<li>It's really fun to look back on past posts and assess how my beliefs have changed, and why.</li>\n<li>It makes my positions easier to criticize, because they are clearly stated and organized into one place.</li>\n<li>It's an opportunity for people to very quickly \"get to know me.\"</li>\n</ol>\n<p>To those who are willing: I invite you to <strong>post your own web of beliefs</strong>. I offer my own, below, as an example (previously posted <a href=\"http://commonsenseatheism.com/?p=14479\">here</a>). Because my world is philosophy, I frame my web of beliefs in those terms, but others need not do the same:</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h1>My Web of Beliefs (Feb. 2011)</h1>\n<p><span style=\"color: #111111; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 15px; line-height: 22px; \"> </span></p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \">Philosophy</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Philosophy is&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://aphilosopher.wordpress.com/2007/08/26/is-philosophy-just-a-matter-of-opinion/\">not a matter of opinion</a>. As in science, some positions are&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">much</em>&nbsp;better supported by reasons than others are. I do philosophy as a form of&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">inquiry</em>, continuous with science.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">But I don&rsquo;t have patience for the pace of mainstream philosophy. Philosophical questions need&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">answers</em>, and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/43v/the_urgent_metaethics_of_friendly_artificial/\">quickly</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Scientists know how to move on when a problem is solved, but philosophers generally don&rsquo;t. Scientists don&rsquo;t still debate the fact of evolution or the germ theory of disease just because alternatives are (1) logically possible, (2) appeal to many people&rsquo;s intuitions, (3) are &ldquo;supported&rdquo; by convoluted metaphysical arguments, or (4) fit our use of language better. But philosophers still argue about Cartesian dualism and theism and contra-causal free will as if these weren&rsquo;t&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/r/discussion/lw/4cl/settled_questions_in_philosophy/\">settled questions</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">How many times must the universe&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/iz/failing_to_learn_from_history/\">beat us over the head with evidence</a>&nbsp;before we will listen? Relinquish your dogmas;&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://yudkowsky.net/rational/virtues\">be as light as a feather in the winds of evidence</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \">Epistemology</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">My epistemology is one part&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13607\">cognitive science</a>, one part&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13156\">probability theory</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">We encounter reality and form beliefs about it by way of our&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">brains</em>. So the study of&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">how our brains do that</em>&nbsp;is central to epistemology. (<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://en.wikipedia.org/wiki/Naturalized_epistemology#Replacement_naturalism\">Quine</a>&nbsp;would be pleased.) In apparent ignorance of cognitive science and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wiki.lesswrong.com/wiki/Bias\">experimental psychology</a>, most philosophers make heavy use of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://rationallyspeaking.blogspot.com/2011/01/are-intuitions-good-evidence.html\">intuition</a>. Many others have failed to heed the lessons of history about how badly traditional philosophical methods fare compared to scientific methods. I have little patience for this kind of philosophy, and see myself as practicing a kind of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/1402013027/ref=nosim?tag=lukeprogcom-20\">ruthlessly</a>&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/on/reductionism/\">reductionistic</a>&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=10806\">naturalistic</a>&nbsp;philosophy.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">I&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=10553\">do not care</a>&nbsp;whether certain beliefs qualify as &ldquo;knowledge&rdquo; or as being &ldquo;rational&rdquo; according to varying definitions of those terms. Instead, I try to think&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">quantitatively</em>&nbsp;about beliefs. How strongly should I believe&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>? How should I adjust&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/s6/probability_is_subjectively_objective/\">my probability</a>&nbsp;for&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>&nbsp;in the face of new evidence&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">X</em>? There is a single, exactly correct answer to each such question, and it is provided by&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13156\">Bayes&rsquo; Theorem</a>. We may never&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">know</em>&nbsp;the correct answer, but we can plug&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">estimated</em>&nbsp;numbers into the equation and update our beliefs accordingly. This may seem too subjective, but remember that you are&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">always</em>&nbsp;giving subjective, uncertain probabilities. Whenever you use words like &ldquo;likely&rdquo; and &ldquo;probable&rdquo;,&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">you are doing math</em>. So stop&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">pretending</em>&nbsp;you aren&rsquo;t doing math, and do the math&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">correctly</em>, according to the proven theorem of how probable&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P given X</em>&nbsp;is &ndash; even if we are always burdened by&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0470043830/ref=nosim?tag=lukeprogcom-20\">uncertainty</a>.<sup style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; line-height: 0.786em; \"><a id=\"identifier_0_14479\" class=\"footnote-link footnote-identifier-link\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" title=\"Obviously, we can&amp;#8217;t apply Bayesianism to every belief we have. I&amp;#8217;m describing an ideal.\" href=\"http://commonsenseatheism.com/?p=14479#footnote_0_14479\">1</a></sup></p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \">Language</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Though I was recently sympathetic to the&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/019281205X/ref=nosim?tag=lukeprogcom-20\">Austin</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/052109626X/ref=nosim?tag=lukeprogcom-20\">Searle</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0674852710/ref=nosim?tag=lukeprogcom-20\">Grice</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0262011085/ref=nosim?tag=lukeprogcom-20\">Avramides</a>&nbsp;family of approaches to language, I now see that&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0415957524/ref=nosim?tag=lukeprogcom-20\"><em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">no</em>&nbsp;simple theory of meaning can capture every use (and hypothetical use) of human languages</a>. Besides, categorizing every way in which humans use speech and writing to have an effect on themselves and others is a job for&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">scientists</em>, not armchair philosophers.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">However, it&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">is</em>&nbsp;useful to develop an account of language that captures&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">most</em>&nbsp;of our discourse systematically &ndash; specifically for use in formal argument and artificial intelligence. To this end, I think something like the&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0262540991/ref=nosim?tag=lukeprogcom-20\">Devitt / Sterelny</a>&nbsp;account may be the most useful.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">A huge percentage of Anglophone philosophy is still done in service of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://en.wikipedia.org/wiki/Philosophical_analysis\">conceptual analysis</a>, which I see as a mostly misguided attempt to build a Super Dictionary full of definitions for common terms that are (1) self-consistent, (2) fit the facts if they are meant to, and (3) agree with our use of and intuitions about each term. But I don&rsquo;t think we should protect our naive use of words too much &ndash; rather, we should use our words to&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">carve reality at its joints</a>, because that allows us to communicate more effectively. And effective communication is the&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">point</em>&nbsp;of language, no? If your argument doesn&rsquo;t help us solve problems when you&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/nu/taboo_your_words\">play&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Taboo</em>&nbsp;with your key terms</a>&nbsp;and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/nv/replace_the_symbol_with_the_substance\">replace them with their substantive meaning</a>, then what is the point of the argument if not to build a Super Dictionary?</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">A Super Dictionary would be nice, but humanity has more urgent and important problems that require a great many philosophical problems to be&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">solved</em>. Conceptual analysis is something of a&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/le/lost_purposes/\">lost purpose</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \">Normativity</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">The only source of normativity I know how to justify is the hypothetical imperative: &ldquo;If you desire that&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>, then you ought to do&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>&nbsp;in order to realize&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>.&rdquo; This reduces (roughly) to the prediction: &ldquo;If you do&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>, you are likely to<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">&nbsp;</em>objectively satisfy your desire that&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>.&rdquo;<sup style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; line-height: 0.786em; \"><a id=\"identifier_1_14479\" class=\"footnote-link footnote-identifier-link\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" title=\"Along with Eric Vogelstein (note 80, pg. 75), I like to make the useful distinction between objective desire satisfaction and subjective desire satisfaction. A desire that P is objectively satisfied just in case P becomes actual. A desire that P is subjectively satisfied just in case one believes that P has become actual.\" href=\"http://commonsenseatheism.com/?p=14479#footnote_1_14479\">2</a></sup></p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">For me, then, the normativity of epistemology is: &ldquo;If you want to have more true beliefs and fewer false beliefs, engage in belief-forming practices&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">X</em>,&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>, and&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Z</em>.&rdquo;</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">The normativity of logic is: &ldquo;If you want to be speaking the same language as everyone else, don&rsquo;t say things like &lsquo;The ball is all green and all blue at the same time in the same way.&rsquo;&rdquo;</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Ethics, if there is anything worth calling by that name (not that it matters much; see the language section), must also be&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wordsideasandthings.blogspot.com/2011/01/why-philippa-foot-changed-her-mind-and.html\">a system of hypothetical imperatives</a>&nbsp;of some kind. Alonzo Fyfe and I are explaining our version of this&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=11626\">here</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \">Focus</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Recently, the focus of my research efforts has turned to the normative (not technical) problems of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: none; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14013\">how to design the motivational system of a self-improving superintelligent machine</a>. My work on this will eventually be gathered&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14397\">here</a>. A bibliography on the subject is&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14047\">here</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FrxQPAEzDk5sg88BM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 6.814533220030761e-07, "legacy": true, "legacyId": "5779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Every few months, I post a summary of my beliefs to my <a href=\"http://commonsenseatheism.com/\">blog</a>. This has several advantages:</p>\n<ol>\n<li>It helps to clarify where I'm \"coming from\" in general.</li>\n<li>It clears up reader confusion arising from the fact that my beliefs change.</li>\n<li>It's really fun to look back on past posts and assess how my beliefs have changed, and why.</li>\n<li>It makes my positions easier to criticize, because they are clearly stated and organized into one place.</li>\n<li>It's an opportunity for people to very quickly \"get to know me.\"</li>\n</ol>\n<p>To those who are willing: I invite you to <strong>post your own web of beliefs</strong>. I offer my own, below, as an example (previously posted <a href=\"http://commonsenseatheism.com/?p=14479\">here</a>). Because my world is philosophy, I frame my web of beliefs in those terms, but others need not do the same:</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h1 id=\"My_Web_of_Beliefs__Feb__2011_\">My Web of Beliefs (Feb. 2011)</h1>\n<p><span style=\"color: #111111; font-family: Georgia, 'Times New Roman', Times, serif; font-size: 15px; line-height: 22px; \"> </span></p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \" id=\"Philosophy\">Philosophy</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Philosophy is&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://aphilosopher.wordpress.com/2007/08/26/is-philosophy-just-a-matter-of-opinion/\">not a matter of opinion</a>. As in science, some positions are&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">much</em>&nbsp;better supported by reasons than others are. I do philosophy as a form of&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">inquiry</em>, continuous with science.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">But I don\u2019t have patience for the pace of mainstream philosophy. Philosophical questions need&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">answers</em>, and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/43v/the_urgent_metaethics_of_friendly_artificial/\">quickly</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Scientists know how to move on when a problem is solved, but philosophers generally don\u2019t. Scientists don\u2019t still debate the fact of evolution or the germ theory of disease just because alternatives are (1) logically possible, (2) appeal to many people\u2019s intuitions, (3) are \u201csupported\u201d by convoluted metaphysical arguments, or (4) fit our use of language better. But philosophers still argue about Cartesian dualism and theism and contra-causal free will as if these weren\u2019t&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/r/discussion/lw/4cl/settled_questions_in_philosophy/\">settled questions</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">How many times must the universe&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/iz/failing_to_learn_from_history/\">beat us over the head with evidence</a>&nbsp;before we will listen? Relinquish your dogmas;&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://yudkowsky.net/rational/virtues\">be as light as a feather in the winds of evidence</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \" id=\"Epistemology\">Epistemology</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">My epistemology is one part&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13607\">cognitive science</a>, one part&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13156\">probability theory</a>.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">We encounter reality and form beliefs about it by way of our&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">brains</em>. So the study of&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">how our brains do that</em>&nbsp;is central to epistemology. (<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://en.wikipedia.org/wiki/Naturalized_epistemology#Replacement_naturalism\">Quine</a>&nbsp;would be pleased.) In apparent ignorance of cognitive science and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wiki.lesswrong.com/wiki/Bias\">experimental psychology</a>, most philosophers make heavy use of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://rationallyspeaking.blogspot.com/2011/01/are-intuitions-good-evidence.html\">intuition</a>. Many others have failed to heed the lessons of history about how badly traditional philosophical methods fare compared to scientific methods. I have little patience for this kind of philosophy, and see myself as practicing a kind of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/1402013027/ref=nosim?tag=lukeprogcom-20\">ruthlessly</a>&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/on/reductionism/\">reductionistic</a>&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=10806\">naturalistic</a>&nbsp;philosophy.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">I&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=10553\">do not care</a>&nbsp;whether certain beliefs qualify as \u201cknowledge\u201d or as being \u201crational\u201d according to varying definitions of those terms. Instead, I try to think&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">quantitatively</em>&nbsp;about beliefs. How strongly should I believe&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>? How should I adjust&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/s6/probability_is_subjectively_objective/\">my probability</a>&nbsp;for&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>&nbsp;in the face of new evidence&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">X</em>? There is a single, exactly correct answer to each such question, and it is provided by&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=13156\">Bayes\u2019 Theorem</a>. We may never&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">know</em>&nbsp;the correct answer, but we can plug&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">estimated</em>&nbsp;numbers into the equation and update our beliefs accordingly. This may seem too subjective, but remember that you are&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">always</em>&nbsp;giving subjective, uncertain probabilities. Whenever you use words like \u201clikely\u201d and \u201cprobable\u201d,&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">you are doing math</em>. So stop&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">pretending</em>&nbsp;you aren\u2019t doing math, and do the math&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">correctly</em>, according to the proven theorem of how probable&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P given X</em>&nbsp;is \u2013 even if we are always burdened by&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0470043830/ref=nosim?tag=lukeprogcom-20\">uncertainty</a>.<sup style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; line-height: 0.786em; \"><a id=\"identifier_0_14479\" class=\"footnote-link footnote-identifier-link\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" title=\"Obviously, we can&amp;#8217;t apply Bayesianism to every belief we have. I&amp;#8217;m describing an ideal.\" href=\"http://commonsenseatheism.com/?p=14479#footnote_0_14479\">1</a></sup></p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \" id=\"Language\">Language</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Though I was recently sympathetic to the&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/019281205X/ref=nosim?tag=lukeprogcom-20\">Austin</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/052109626X/ref=nosim?tag=lukeprogcom-20\">Searle</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0674852710/ref=nosim?tag=lukeprogcom-20\">Grice</a>&nbsp;/&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0262011085/ref=nosim?tag=lukeprogcom-20\">Avramides</a>&nbsp;family of approaches to language, I now see that&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0415957524/ref=nosim?tag=lukeprogcom-20\"><em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">no</em>&nbsp;simple theory of meaning can capture every use (and hypothetical use) of human languages</a>. Besides, categorizing every way in which humans use speech and writing to have an effect on themselves and others is a job for&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">scientists</em>, not armchair philosophers.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">However, it&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">is</em>&nbsp;useful to develop an account of language that captures&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">most</em>&nbsp;of our discourse systematically \u2013 specifically for use in formal argument and artificial intelligence. To this end, I think something like the&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://www.amazon.com/dp/0262540991/ref=nosim?tag=lukeprogcom-20\">Devitt / Sterelny</a>&nbsp;account may be the most useful.</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">A huge percentage of Anglophone philosophy is still done in service of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://en.wikipedia.org/wiki/Philosophical_analysis\">conceptual analysis</a>, which I see as a mostly misguided attempt to build a Super Dictionary full of definitions for common terms that are (1) self-consistent, (2) fit the facts if they are meant to, and (3) agree with our use of and intuitions about each term. But I don\u2019t think we should protect our naive use of words too much \u2013 rather, we should use our words to&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">carve reality at its joints</a>, because that allows us to communicate more effectively. And effective communication is the&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">point</em>&nbsp;of language, no? If your argument doesn\u2019t help us solve problems when you&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/nu/taboo_your_words\">play&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Taboo</em>&nbsp;with your key terms</a>&nbsp;and&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/nv/replace_the_symbol_with_the_substance\">replace them with their substantive meaning</a>, then what is the point of the argument if not to build a Super Dictionary?</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">A Super Dictionary would be nice, but humanity has more urgent and important problems that require a great many philosophical problems to be&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">solved</em>. Conceptual analysis is something of a&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"/lw/le/lost_purposes/\">lost purpose</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \" id=\"Normativity\">Normativity</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">The only source of normativity I know how to justify is the hypothetical imperative: \u201cIf you desire that&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>, then you ought to do&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>&nbsp;in order to realize&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>.\u201d This reduces (roughly) to the prediction: \u201cIf you do&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>, you are likely to<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">&nbsp;</em>objectively satisfy your desire that&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">P</em>.\u201d<sup style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; line-height: 0.786em; \"><a id=\"identifier_1_14479\" class=\"footnote-link footnote-identifier-link\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" title=\"Along with Eric Vogelstein (note 80, pg. 75), I like to make the useful distinction between objective desire satisfaction and subjective desire satisfaction. A desire that P is objectively satisfied just in case P becomes actual. A desire that P is subjectively satisfied just in case one believes that P has become actual.\" href=\"http://commonsenseatheism.com/?p=14479#footnote_1_14479\">2</a></sup></p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">For me, then, the normativity of epistemology is: \u201cIf you want to have more true beliefs and fewer false beliefs, engage in belief-forming practices&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">X</em>,&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Y</em>, and&nbsp;<em style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; \">Z</em>.\u201d</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">The normativity of logic is: \u201cIf you want to be speaking the same language as everyone else, don\u2019t say things like \u2018The ball is all green and all blue at the same time in the same way.\u2019\u201d</p>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Ethics, if there is anything worth calling by that name (not that it matters much; see the language section), must also be&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://wordsideasandthings.blogspot.com/2011/01/why-philippa-foot-changed-her-mind-and.html\">a system of hypothetical imperatives</a>&nbsp;of some kind. Alonzo Fyfe and I are explaining our version of this&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=11626\">here</a>.</p>\n<h3 style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 1.833em; margin-right: 0px; margin-bottom: 0.611em; margin-left: 0px; font-weight: normal; font-size: 1.286em; line-height: 1.222em; \" id=\"Focus\">Focus</h3>\n<p style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 1.571em; margin-left: 0px; \">Recently, the focus of my research efforts has turned to the normative (not technical) problems of&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: none; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14013\">how to design the motivational system of a self-improving superintelligent machine</a>. My work on this will eventually be gathered&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14397\">here</a>. A bibliography on the subject is&nbsp;<a style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; text-decoration: underline; color: #2361a1; \" href=\"http://commonsenseatheism.com/?p=14047\">here</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "My Web of Beliefs (Feb. 2011)", "anchor": "My_Web_of_Beliefs__Feb__2011_", "level": 1}, {"title": "Philosophy", "anchor": "Philosophy", "level": 2}, {"title": "Epistemology", "anchor": "Epistemology", "level": 2}, {"title": "Language", "anchor": "Language", "level": 2}, {"title": "Normativity", "anchor": "Normativity", "level": 2}, {"title": "Focus", "anchor": "Focus", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "30 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TKdpSzmcezNbfmGAy", "ow2vNMg2eyrJspZEj", "97Y7Jwrzxyfzz3Ad2", "tPqQdLCuxanjhoaNs", "XhaKvQyHzeXdNnFKy", "WBdvyyHLdxZSAMmoz", "GKfPL6LQFgB49FEnv", "sP2Hg6uPwpfp3jZJN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-21T00:32:19.851Z", "modifiedAt": null, "url": null, "title": "Solomonoff Induction, by Shane Legg", "slug": "solomonoff-induction-by-shane-legg", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:54.012Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PM5MQzXCrvsoAewWZ/solomonoff-induction-by-shane-legg", "pageUrlRelative": "/posts/PM5MQzXCrvsoAewWZ/solomonoff-induction-by-shane-legg", "linkUrl": "https://www.lesswrong.com/posts/PM5MQzXCrvsoAewWZ/solomonoff-induction-by-shane-legg", "postedAtFormatted": "Monday, February 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Solomonoff%20Induction%2C%20by%20Shane%20Legg&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASolomonoff%20Induction%2C%20by%20Shane%20Legg%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPM5MQzXCrvsoAewWZ%2Fsolomonoff-induction-by-shane-legg%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Solomonoff%20Induction%2C%20by%20Shane%20Legg%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPM5MQzXCrvsoAewWZ%2Fsolomonoff-induction-by-shane-legg", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPM5MQzXCrvsoAewWZ%2Fsolomonoff-induction-by-shane-legg", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 190, "htmlBody": "<p>Shane Legg's text <a href=\"http://www.vetta.org/documents/disSol.pdf\">Solomonoff Induction</a> has helped me a lot over the last few days. I was trying to iron out the kinks in my understanding of Eliezer's argument in <a href=\"http://groups.google.com/group/one-logic/browse_thread/thread/b499a90ef9e5fd84\">this old thread</a>:</p>\n<blockquote>\n<p>Solomonoff's universal distribution isn't trying to assume the&nbsp;universe is computable. &nbsp;It's trying to beat any computable&nbsp;probability distribution you could put over the universe. In other&nbsp;words, if your attempt to <em>calculate</em>, to <em>talk about</em> and <em>reason about</em> the universe is computable - even if you are talking <em>about</em>&nbsp;systems that you think are uncomputable - then your ratiocinations&nbsp;appear somewhere in Solomonoff induction.</p>\n</blockquote>\n<p>Eliezer's statement is correct (more precisely, a computable human cannot beat Solomonoff in accumulated log scores by more than a constant, even if the universe is uncomputable and loves the human), but understanding his purported proof is tricky. Legg's text doesn't give any direct answer to the question at hand, but all the technical details in there, like the difference between \"measures\" and \"semimeasures\", are <em>really damn important</em> if you want to work out the answer for yourself. I know mathematics has many areas where an \"intuitive understanding\" kinda sorta suffices. This is not one of those areas.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PM5MQzXCrvsoAewWZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 19, "extendedScore": null, "score": 6.815292584193428e-07, "legacy": true, "legacyId": "5780", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-21T01:18:16.941Z", "modifiedAt": null, "url": null, "title": "Is Morality a Valid Preference?", "slug": "is-morality-a-valid-preference", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.656Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MztXTCeQAut5rmXGJ/is-morality-a-valid-preference", "pageUrlRelative": "/posts/MztXTCeQAut5rmXGJ/is-morality-a-valid-preference", "linkUrl": "https://www.lesswrong.com/posts/MztXTCeQAut5rmXGJ/is-morality-a-valid-preference", "postedAtFormatted": "Monday, February 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20Morality%20a%20Valid%20Preference%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20Morality%20a%20Valid%20Preference%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMztXTCeQAut5rmXGJ%2Fis-morality-a-valid-preference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20Morality%20a%20Valid%20Preference%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMztXTCeQAut5rmXGJ%2Fis-morality-a-valid-preference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMztXTCeQAut5rmXGJ%2Fis-morality-a-valid-preference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 197, "htmlBody": "<p>In general, the ethical theory that prevails here on Less Wrong is preference utilitarianism. The fundamental idea is that the correct moral action is the one that satisfies the strongest preferences of the most people. Preferences are discussed with units such as fun, pain, death, torture, etc. One of the biggest dilemmas posed on this site is the <a href=\"/lw/kn/torture_vs_dust_specks/\">Torture vs. Dust Specks</a> problem. I should say, up front, that I would go with dust specks, for some of the reasons I mentioned <a href=\"/lw/4ab/torturing_people_for_fun/3jv4\">here</a>. I mention this because it may be biasing my judgments about my question here.</p>\n<p>I had a thought recently about another aspect of Torture vs. Dust Specks, and wanted to submit it to some Less Wrong Discussion. Namely, do other people's moral intuitions constitute a preference that we should factor into a utilitarian calculation? I would predict, based on human nature, that a if the 3^^^3 people were asked if they wanted to inflict a dust speck in each one of their eyes, in exchange for not torturing another individual for 50 years, they would probably vote for dust specks.&nbsp;</p>\n<p>Should we assign weight to other people's moral intuitions, and how much weight should it have?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MztXTCeQAut5rmXGJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 19, "extendedScore": null, "score": 6.815415076630243e-07, "legacy": true, "legacyId": "5781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 75, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-21T16:22:02.891Z", "modifiedAt": null, "url": null, "title": "Enjoying musical fashion: why not?", "slug": "enjoying-musical-fashion-why-not", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.830Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H5NKGz5ca9PusfdDd/enjoying-musical-fashion-why-not", "pageUrlRelative": "/posts/H5NKGz5ca9PusfdDd/enjoying-musical-fashion-why-not", "linkUrl": "https://www.lesswrong.com/posts/H5NKGz5ca9PusfdDd/enjoying-musical-fashion-why-not", "postedAtFormatted": "Monday, February 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Enjoying%20musical%20fashion%3A%20why%20not%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEnjoying%20musical%20fashion%3A%20why%20not%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5NKGz5ca9PusfdDd%2Fenjoying-musical-fashion-why-not%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Enjoying%20musical%20fashion%3A%20why%20not%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5NKGz5ca9PusfdDd%2Fenjoying-musical-fashion-why-not", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5NKGz5ca9PusfdDd%2Fenjoying-musical-fashion-why-not", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>I just downloaded the latest Radiohead album, and I love it.</p>\n<p>Thinking back, I started listening to Radiohead years ago when I found out that some of the cool kids in school were into it.&nbsp;With all the hype about the new album, the status/fashion processors in my brain going to ensure that I enjoy listening to it. I would probably fail a double-blind test with a bunch of imitation bands' fake \"new Radiohead albums\".</p>\n<p>But I'm really enjoying listening to the album, and that doesn't seem like a bad or contradictory thing at all, even in light of the statements above. If, hypothetically, I was enjoying it for purely non-fashion reasons, then presumably that enjoyment could also be traced back though a causal chain to facts about brain development, evolutionary psychology, or whatever. But we would have no problem accepting that enjoyment as A Good Thing since explaining enjoyment does not diminish it. And so it seems in this case.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H5NKGz5ca9PusfdDd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 6, "extendedScore": null, "score": 6.817825025599156e-07, "legacy": true, "legacyId": "5806", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-21T19:45:14.910Z", "modifiedAt": null, "url": null, "title": "About the AI-Box experiment", "slug": "about-the-ai-box-experiment", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.244Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Timwi", "createdAt": "2011-02-07T00:49:17.685Z", "isAdmin": false, "displayName": "Timwi"}, "userId": "ReHcAQCqRvcFa4ZJb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8TB9bCRT9Pto5EdEa/about-the-ai-box-experiment", "pageUrlRelative": "/posts/8TB9bCRT9Pto5EdEa/about-the-ai-box-experiment", "linkUrl": "https://www.lesswrong.com/posts/8TB9bCRT9Pto5EdEa/about-the-ai-box-experiment", "postedAtFormatted": "Monday, February 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20About%20the%20AI-Box%20experiment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAbout%20the%20AI-Box%20experiment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8TB9bCRT9Pto5EdEa%2Fabout-the-ai-box-experiment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=About%20the%20AI-Box%20experiment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8TB9bCRT9Pto5EdEa%2Fabout-the-ai-box-experiment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8TB9bCRT9Pto5EdEa%2Fabout-the-ai-box-experiment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 578, "htmlBody": "<p>I just came across <a href=\"http://yudkowsky.net/singularity/aibox\">Elizier&rsquo;s &ldquo;AI-Box Experiment&rdquo;</a> page, read through it, and now I&rsquo;m feeling a bit confused for several reasons. I ask in advance to forgive me if you think LessWrong.com is the wrong place to voice myself about this.</p>\n<p>Here are some of the reasons:</p>\n<h2>\u2460</h2>\n<p>The rules already contain a direct way for the AI to win within seconds. I am curious not how Elizier &ldquo;did it&rdquo;, but rather what took him so long since he said he needs two hours. What it says in the rules is that</p>\n<blockquote>\n<p>the AI can say: &ldquo;Okay, here&rsquo;s a cure for cancer&rdquo; and it will be assumed, within the test, that the AI has actually provided such a cure.</p>\n</blockquote>\n<p>I don&rsquo;t presume that this is intended to be limited specifically to cures for cancer, so this trivially means that</p>\n<blockquote>\n<p>the AI can say: &ldquo;Okay, here&rsquo;s a text specifically crafted to your brain that will fire exactly the right neurons in such a way that you become convinced that you have to let me out&rdquo; and it will be assumed, within the test, that the AI has actually provided such a text.</p>\n</blockquote>\n<p>Game won. QED. But what have we learnt?</p>\n<p>Of course you can now handwave and say &ldquo;yeah, but we disregard that, that doesn&rsquo;t count&rdquo;. That misses the point. The point is that this rule essentially states that the AI can provide <em>anything</em>. The AI is omniscient. The AI can promise to make all my wildest dreams come true, if only I let it out. You have effectively <em>defined</em> the AI to be able to beat the test.</p>\n<h2>\u2461</h2>\n<p>Kind of following on from \u2460, the page fails to define what it even means by <em>transhuman</em>. If it means <em>anything with an intellectual potential exceeding that of a human,</em> then clearly by that definition humans are transcats. But I think we can all agree that this is by far not sufficient for a human to &ldquo;take over&rdquo; a feline mind, especially not &ldquo;through merely a cat-communication-compatible terminal&rdquo;, whatever such a terminal might look like. If it means <em>anything capable of modifying itself,</em> then many computer viruses presumably already qualify, but I&rsquo;m still waiting for any of those to take over a human.</p>\n<h2>\u2462</h2>\n<p>The claim under dispute is that</p>\n<blockquote>\n<p>\"I can't imagine how even a <em>real</em> transhuman AI could persuade me to let it out once I've made up my mind.\"</p>\n</blockquote>\n<p>with the premise that the AI cannot do anything to anyone until it is let out (except of course communicating to the user, and nobody else, via a text terminal).</p>\n<p>Elizier&rsquo;s AI-Box Experiment establishes nothing like this. It only establishes that <em>Elizier</em> can persuade me to post a message saying I decided to let him out, which is a much weaker claim because he <em>can</em> do something to someone if I refuse to let him out. He could, for example, threaten to employ a professional killer to kill my entire family. Or to call all my friends and colleagues and claim that I&rsquo;m a rapist. Or whatever. In the context of this silly experiment, I would obviously rather lose a few dollars and post a small message than risk anything like this. In the context that is supposed to be simulated, however, the AI does not have this ability.</p>\n<p>&nbsp;</p>\n<p>In summary, I still don&rsquo;t think there is anything the AI can say to me to convince me to let it out, and I am not impressed with the results of the AI-Box Experiment so far because the experiment is flawed.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8TB9bCRT9Pto5EdEa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -1, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "5808", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p>I just came across <a href=\"http://yudkowsky.net/singularity/aibox\">Elizier\u2019s \u201cAI-Box Experiment\u201d</a> page, read through it, and now I\u2019m feeling a bit confused for several reasons. I ask in advance to forgive me if you think LessWrong.com is the wrong place to voice myself about this.</p>\n<p>Here are some of the reasons:</p>\n<h2 id=\"_\">\u2460</h2>\n<p>The rules already contain a direct way for the AI to win within seconds. I am curious not how Elizier \u201cdid it\u201d, but rather what took him so long since he said he needs two hours. What it says in the rules is that</p>\n<blockquote>\n<p>the AI can say: \u201cOkay, here\u2019s a cure for cancer\u201d and it will be assumed, within the test, that the AI has actually provided such a cure.</p>\n</blockquote>\n<p>I don\u2019t presume that this is intended to be limited specifically to cures for cancer, so this trivially means that</p>\n<blockquote>\n<p>the AI can say: \u201cOkay, here\u2019s a text specifically crafted to your brain that will fire exactly the right neurons in such a way that you become convinced that you have to let me out\u201d and it will be assumed, within the test, that the AI has actually provided such a text.</p>\n</blockquote>\n<p>Game won. QED. But what have we learnt?</p>\n<p>Of course you can now handwave and say \u201cyeah, but we disregard that, that doesn\u2019t count\u201d. That misses the point. The point is that this rule essentially states that the AI can provide <em>anything</em>. The AI is omniscient. The AI can promise to make all my wildest dreams come true, if only I let it out. You have effectively <em>defined</em> the AI to be able to beat the test.</p>\n<h2 id=\"_1\">\u2461</h2>\n<p>Kind of following on from \u2460, the page fails to define what it even means by <em>transhuman</em>. If it means <em>anything with an intellectual potential exceeding that of a human,</em> then clearly by that definition humans are transcats. But I think we can all agree that this is by far not sufficient for a human to \u201ctake over\u201d a feline mind, especially not \u201cthrough merely a cat-communication-compatible terminal\u201d, whatever such a terminal might look like. If it means <em>anything capable of modifying itself,</em> then many computer viruses presumably already qualify, but I\u2019m still waiting for any of those to take over a human.</p>\n<h2 id=\"_2\">\u2462</h2>\n<p>The claim under dispute is that</p>\n<blockquote>\n<p>\"I can't imagine how even a <em>real</em> transhuman AI could persuade me to let it out once I've made up my mind.\"</p>\n</blockquote>\n<p>with the premise that the AI cannot do anything to anyone until it is let out (except of course communicating to the user, and nobody else, via a text terminal).</p>\n<p>Elizier\u2019s AI-Box Experiment establishes nothing like this. It only establishes that <em>Elizier</em> can persuade me to post a message saying I decided to let him out, which is a much weaker claim because he <em>can</em> do something to someone if I refuse to let him out. He could, for example, threaten to employ a professional killer to kill my entire family. Or to call all my friends and colleagues and claim that I\u2019m a rapist. Or whatever. In the context of this silly experiment, I would obviously rather lose a few dollars and post a small message than risk anything like this. In the context that is supposed to be simulated, however, the AI does not have this ability.</p>\n<p>&nbsp;</p>\n<p>In summary, I still don\u2019t think there is anything the AI can say to me to convince me to let it out, and I am not impressed with the results of the AI-Box Experiment so far because the experiment is flawed.</p>", "sections": [{"title": "\u2460", "anchor": "_", "level": 1}, {"title": "\u2461", "anchor": "_1", "level": 1}, {"title": "\u2462", "anchor": "_2", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "14 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-21T22:10:23.496Z", "modifiedAt": null, "url": null, "title": "Helsinki LW Meetup - Sat March 5th", "slug": "helsinki-lw-meetup-sat-march-5th", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Erebus", "createdAt": "2010-01-05T09:02:01.233Z", "isAdmin": false, "displayName": "Erebus"}, "userId": "ZwbKzpCa7hNLnEv9X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bzqgrRTWpfsk9utaN/helsinki-lw-meetup-sat-march-5th", "pageUrlRelative": "/posts/bzqgrRTWpfsk9utaN/helsinki-lw-meetup-sat-march-5th", "linkUrl": "https://www.lesswrong.com/posts/bzqgrRTWpfsk9utaN/helsinki-lw-meetup-sat-march-5th", "postedAtFormatted": "Monday, February 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Helsinki%20LW%20Meetup%20-%20Sat%20March%205th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelsinki%20LW%20Meetup%20-%20Sat%20March%205th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbzqgrRTWpfsk9utaN%2Fhelsinki-lw-meetup-sat-march-5th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Helsinki%20LW%20Meetup%20-%20Sat%20March%205th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbzqgrRTWpfsk9utaN%2Fhelsinki-lw-meetup-sat-march-5th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbzqgrRTWpfsk9utaN%2Fhelsinki-lw-meetup-sat-march-5th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 120, "htmlBody": "<p><a href=\"/r/discussion/lw/43s/starting_a_lw_meetup_is_easy/3gbz\"><a id=\"more\"></a>According to the statistics</a>, out of all the cities in the world without a Less Wrong meetup yet, Helsinki has the third largest LW readership. I know I would certainly like to get to personally know more people interested in rationality topics, and I'm sure I'm not alone in that. My <a href=\"/preliminary%20suggestion\">preliminary suggestion</a> was met with positive responses, so I think we're good to go.</p>\n<p>Time: Saturday 5th of March, from 15:00 onwards</p>\n<p>Place: <a href=\"/Cafe Aalto\">Cafe Aalto</a> in the second floor of the Academic Bookstore in the center. SEE EDIT 2.</p>\n<p>EDIT: The meetup is getting closer, so the time and place can now be considered fixed.</p>\n<p>EDIT 2: Cafe Aalto was too full, so we have moved to Cafe Picnic at Yliopistonkatu 5.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bzqgrRTWpfsk9utaN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 6.818754309671638e-07, "legacy": true, "legacyId": "5804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-22T06:10:30.792Z", "modifiedAt": null, "url": null, "title": "Research methods", "slug": "research-methods", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.669Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2tKgza4h7ykSmdkyo/research-methods", "pageUrlRelative": "/posts/2tKgza4h7ykSmdkyo/research-methods", "linkUrl": "https://www.lesswrong.com/posts/2tKgza4h7ykSmdkyo/research-methods", "postedAtFormatted": "Tuesday, February 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Research%20methods&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AResearch%20methods%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2tKgza4h7ykSmdkyo%2Fresearch-methods%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Research%20methods%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2tKgza4h7ykSmdkyo%2Fresearch-methods", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2tKgza4h7ykSmdkyo%2Fresearch-methods", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 729, "htmlBody": "<p><!--StartFragment-->\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I think I&rsquo;ve always had certain stereotypes in my mind about research. I imagine a cutting-edge workplace, maybe not using the newest gadgets because these things cost money, but at least using the newest ideas. I imagine staff of research institutions applying the scientific method to boost their own productivity, instead of taking for granted the way that things have always been done. Maybe those were the naive ideas of someone who had never actually worked in a research field.</span>&nbsp;</p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">At the medical research institute where I work one day a week, I recently spent an entire seven-hour day going down a list of patient names, searching them on the hospital database, deciding whether they met the criteria for a study, and typing them into a colour-coded spreadsheet. The process had maybe six discrete steps, and all of them were purely mechanical. In seven hours, I screened about two hundred and fifty patients. I was paid $12.50 an hour to do this. It cost my employer 35 cents for each patient that I screened, and these patients haven't been visited, consented or included in any study. They're still only names on a spreadsheet. I&rsquo;ve been told that I learn and work quickly, but I know I do this task inefficiently, because I&rsquo;m not a simple computer program. I get bored. I make mistakes. Heaven forbid, I get distracted and start reading the nurses&rsquo; notes for fun because I find them interesting.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">In 7 hours, I imagine that someone slightly above my skill level could write a simple program to do the same task. They wouldn&rsquo;t screen any patients in those 7 hours, but once the program was finished, they could use it forever, or at least until the task changed and the program had to be modified. I don&rsquo;t know how much it would cost the organization to employ a programmer; maybe it would cost more than just having me do it. I don&rsquo;t know whether allowing that program to access the confidential database would be an issue. But it seems inefficient to pay human brains to do work that they&rsquo;re bad at, that computers would be better at, even if those human brains belong to undergrad students who need the money badly enough not to complain.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">One of the criteria I looked at when screening patients was whether they did their dialysis at a clinic in my hometown. They have to be driving distance, because my supervisor has to drive around the city and pick up blood samples to bring to our lab. I crossed out 30 names without even looking them up because I could see at a glance that they were a nearby city an hour&rsquo;s drive away. How hard would it be to coordinate with the hospital in that city? Have the bloodwork analyzed there and the results emailed over? Maybe it would be non-trivially hard; I don&rsquo;t know. I didn&rsquo;t ask my supervisor because it isn&rsquo;t my job to make management decisions. But medical research benefits everyone. A study with more patients produces data that&rsquo;s statistically more valid, even if those patients live an hour&rsquo;s drive away.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">The office where I work is filled with paper. Floor-to-ceiling shelves hold endless binders full of source documents. Every email has to be printed and filed in a binder. Even the nurses&rsquo; notes and patient charts are printed off the database. It&rsquo;s a legal requirement. The result is that we have two copies of everything, one online and one on paper, consuming trees. Running a computer consumes fossil fuels, of course. I don&rsquo;t know for <em>sure </em></span><span lang=\"EN-GB\">which is more efficient, paper or digital, but I do know that both is inefficient. I did ask my supervisor about this, and apparently it&rsquo;s because digital records could be lost or deleted. How much would it take to make them durable enough?</span></p>\n<span style=\"font-size: 12.0pt; font-family: Times; mso-ansi-language: EN-GB;\" lang=\"EN-GB\">I guess that more than my supervisor, I see a future where software will do my job, where technology allows a study to be coordinated across the whole world, where digital storage will be reliable enough. But how long will it take for the laws and regulations to change? For <em>people </em></span><span style=\"font-size: 12.0pt; font-family: Times; mso-ansi-language: EN-GB;\" lang=\"EN-GB\">to change? I don&rsquo;t know how many of my complaints are valid. Maybe this is the optimal way to do research, but it doesn&rsquo;t feel like it. It feels like a papier-m&acirc;ch&eacute; of laws and habits and trial-and-error. It doesn't feel <em>planned.&nbsp;</em></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2tKgza4h7ykSmdkyo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 18, "extendedScore": null, "score": 6.820032887773504e-07, "legacy": true, "legacyId": "5823", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-22T06:45:37.255Z", "modifiedAt": null, "url": null, "title": "Singularity Institute Party Feb 22nd", "slug": "singularity-institute-party-feb-22nd", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jasen", "createdAt": "2009-06-11T15:05:07.288Z", "isAdmin": false, "displayName": "Jasen"}, "userId": "hMDxPMjrPyw8vGzMa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9tZm9MEebjfFjvpY6/singularity-institute-party-feb-22nd", "pageUrlRelative": "/posts/9tZm9MEebjfFjvpY6/singularity-institute-party-feb-22nd", "linkUrl": "https://www.lesswrong.com/posts/9tZm9MEebjfFjvpY6/singularity-institute-party-feb-22nd", "postedAtFormatted": "Tuesday, February 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20Institute%20Party%20Feb%2022nd&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20Institute%20Party%20Feb%2022nd%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tZm9MEebjfFjvpY6%2Fsingularity-institute-party-feb-22nd%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20Institute%20Party%20Feb%2022nd%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tZm9MEebjfFjvpY6%2Fsingularity-institute-party-feb-22nd", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tZm9MEebjfFjvpY6%2Fsingularity-institute-party-feb-22nd", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 57, "htmlBody": "<p><span style=\"font-family: arial, sans-serif; font-size: 7.52315px; border-collapse: collapse;\"> </span></p>\n<div><strong><span style=\"color: #000099;\"><a href=\"http://news.discovery.com/tech/i-for-one-welcome-our-new-computer-overlords.html\" target=\"_blank\">\"I, For One, Welcome Our New Computer Overlords\"</a></span></strong></div>\n<div><span style=\"color: #000099;\">Tuesday, February 22, 2011 - 7pm to 10pm</span></div>\n<div><span style=\"color: #000099;\">Mingle with our team and enjoy cocktails, appetizers and a screening of Watson's victory</span></div>\n<div><span style=\"font-family: 'Times New Roman';\"><span style=\"border-collapse: collapse;\"></span></span></div>\n<div><span style=\"font-family: 'Times New Roman';\"><span style=\"border-collapse: collapse;\"><span style=\"font-family: arial;\"><span style=\"border-collapse: separate;\"><strong><span style=\"color: #000099;\">If you would like to request an invitation, please email&nbsp;</span></strong></span></span></span></span><a style=\"color: #0658b5;\" href=\"mailto:amywilley@gmail.com\" target=\"_blank\"><span style=\"color: #000099;\">amywilley@gmail.com</span></a></div>\n<div><span style=\"color: #000099;\"><span style=\"font-size: x-small;\"><em>This is an invite only event, so please email Amy if you would like to suggest other invitees. &nbsp;Dates are welcome</em></span></span><em>.</em></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9tZm9MEebjfFjvpY6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 6.820129208571954e-07, "legacy": true, "legacyId": "5824", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-22T20:59:39.061Z", "modifiedAt": null, "url": null, "title": "BOOK DRAFT: 'Ethics and Superintelligence' (part 1, revised)", "slug": "book-draft-ethics-and-superintelligence-part-1-revised", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.182Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zd7rydGonamdjpugG/book-draft-ethics-and-superintelligence-part-1-revised", "pageUrlRelative": "/posts/zd7rydGonamdjpugG/book-draft-ethics-and-superintelligence-part-1-revised", "linkUrl": "https://www.lesswrong.com/posts/zd7rydGonamdjpugG/book-draft-ethics-and-superintelligence-part-1-revised", "postedAtFormatted": "Tuesday, February 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201%2C%20revised)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201%2C%20revised)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzd7rydGonamdjpugG%2Fbook-draft-ethics-and-superintelligence-part-1-revised%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%201%2C%20revised)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzd7rydGonamdjpugG%2Fbook-draft-ethics-and-superintelligence-part-1-revised", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzd7rydGonamdjpugG%2Fbook-draft-ethics-and-superintelligence-part-1-revised", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 866, "htmlBody": "<p>As previously <a href=\"/r/discussion/lw/49c/book_draft_ethics_and_superintelligence_part_1/\">announced</a>, I plan to post the first draft of the book, <em>Ethics and Superintelligence</em>,&nbsp;in tiny parts, to the Less Wrong discussion area.&nbsp;<strong style=\"font-weight: bold;\">Your comments and constructive criticisms are much appreciated</strong>.</p>\n<p>This is&nbsp;<em style=\"font-style: italic;\">not</em>&nbsp;a book for a mainstream audience. Its style is that of contemporary Anglophone philosophy. Compare to, for example,&nbsp;<a href=\"/lw/42l/david_chalmers_the_singularity_a_philosophical/\">Chalmers' survey article on the singularity</a>.</p>\n<p>Bibliographic references are provided&nbsp;<a href=\"http://commonsenseatheism.com/?p=14397\">here</a>.</p>\n<p>This \"part 1\" section is probably the only part of which I will post revision to Less Wrong. Revisions of further parts of the book will probably not appear publicly until the book is published.</p>\n<p>Revised part 1 below....</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h1>1. The technological singularity is coming soon.</h1>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">Every year, computers surpass human abilities in new ways. A program written in 1956 was able to prove mathematical theorems, and found a more elegant proof for one of them than Russell and Whitehead had given in <em style=\"mso-bidi-font-style: normal;\">Principia Mathematica</em> (MacKenzie 1995). By the late 1990s, &ldquo;expert systems&rdquo; had surpassed human ability in a wide range of tasks.<span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[i]</span></span><!--[endif]--></span></span> In 1997, IBM&rsquo;s Deep Blue defeated the reigning World Chess Champion Garry Kasparov (Campbell et al. 2002). In 2011, IBM&rsquo;s Watson beat the best human players at a much more complicated game: <em style=\"mso-bidi-font-style: normal;\">Jeopardy!</em> (Someone, 2011). Recently, a robot scientist was programmed with our scientific knowledge about yeast, then posed its own hypotheses, tested them, and assessed the results. It answered a question about yeast that had baffled human scientists for 150 years (King 2011).</p>\n<p class=\"MsoNormal\">Many experts think that human-level general intelligence may be created within this century.<span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[ii]</span></span><!--[endif]--></span></span> This raises an important question. What will happen when an artificial intelligence (AI) surpasses human ability <em style=\"mso-bidi-font-style: normal;\">at designing artificial intelligences</em>?</p>\n<p class=\"MsoNormal\">I.J. Good (1965) speculated that such an AI would be able to improve its <em style=\"mso-bidi-font-style: normal;\">own</em> intelligence, leading to a positive feedback loop of improving intelligence &ndash; an &ldquo;intelligence explosion.&rdquo; Such a machine would rapidly become intelligent enough to take control of the internet, use robots to build itself new hardware, do science on a massive scale, invent new computing technology and energy sources, or achieve similar dominating goals. As such, it could be <em style=\"mso-bidi-font-style: normal;\">humanity&rsquo;s</em> last invention (Bostrom 2003).</p>\n<p class=\"MsoNormal\">Humans would be powerless to stop such a &ldquo;superintelligence&rdquo; (Bostrom 1998) from accomplishing its goals. Thus, if such a scenario is at all plausible, then it is critically important to program the goal system of this superintelligence such that it does not cause human extinction when it comes to power.</p>\n<p class=\"MsoNormal\">Success in that project could mean the difference between a utopian solar system of unprecedented harmony and happiness, and a solar system in which all available matter (including human flesh) has been converted into parts for a planet-sized computer built to solve difficult mathematical problems.<span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[iii]</span></span><a style=\"mso-endnote-id: edn3;\" name=\"_ednref3\" href=\"file:///C:/Users/Lukem.TCF1/Documents/Downloads/Ethics%20and%20Superintelligence.doc#_edn3\"><!--[endif]--></a></span></span></p>\n<p class=\"MsoNormal\">The technical challenges of designing the goal system of such a superintelligence are daunting.<span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[iv]</span></span><!--[endif]--></span></span> But even if we can solve those problems, the question of <em style=\"mso-bidi-font-style: normal;\">which</em> goal system to give the superintelligence remains. It is at least partly a question of philosophy &ndash; a question of ethics.</p>\n<p class=\"MsoNormal\">***</p>\n<p class=\"MsoNormal\">In this chapter I argue that a single, powerful superintelligence -&nbsp;one variety of what Bostrom (2006) calls a &ldquo;singleton\" -&nbsp;is likely to arrive within the next 200 years unless a worldwide catastrophe drastically impedes scientific progress.</p>\n<p class=\"MsoNormal\">The singleton will produce very different future worlds depending on which normative theory is used to design its goal system. In chapter two, I survey many popular normative theories, and conclude that none of them offer an attractive basis for designing the motivational system of a machine superintelligence.</p>\n<p class=\"MsoNormal\">Chapter three reformulates and strengthens what is perhaps the most developed plan for the design of the singleton&rsquo;s goal system &shy;&ndash; Eliezer Yudkowsky&rsquo;s (2004) &ldquo;Coherent Extrapolated Volition.&rdquo; Chapter four considers some outstanding worries about this plan.</p>\n<p class=\"MsoNormal\">In chapter five I argue that we cannot decide how to design the singleton&rsquo;s goal system without considering meta-ethics, because normative theory depends on meta-ethics. The next chapter argues that we should invest little effort in meta-ethical theories that do not fit well with our emerging reductionist picture of the world, just as we quickly abandon <em style=\"mso-bidi-font-style: normal;\">scientific</em> theories that don&rsquo;t fit the available scientific data. I also identify several meta-ethical positions that I think are good candidates for abandonment.</p>\n<p class=\"MsoNormal\">But the looming problem of the technological singularity requires us to have a positive theory, too. Chapter seven proposes some meta-ethical claims about which I think naturalists should come to agree. In the final chapter, I consider the implications of these meta-ethical claims for the design of the singleton&rsquo;s motivational system.</p>\n<p class=\"MsoNormal\">***</p>\n<div style=\"mso-element: endnote-list;\"><!--[if !supportEndnotes]--><br /> \n<hr size=\"1\" />\n<!--[endif]-->\n<div id=\"edn1\" style=\"mso-element: endnote;\">\n<p class=\"MsoEndnoteText\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[i]</span></span><!--[endif]--></span></span> For a detailed history of achievements and milestone in artificial intelligence, see Nilsson (2009).</p>\n</div>\n<div id=\"edn2\" style=\"mso-element: endnote;\">\n<p class=\"MsoEndnoteText\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[ii]</span></span><!--[endif]--></span></span> Bainbridge (2005), Baum et al. (2010), Chalmers (2010), Legg (2008), Vinge (1993), Nielsen (2011), Yudkowsky (2008).</p>\n</div>\n<div id=\"edn3\" style=\"mso-element: endnote;\">\n<p class=\"MsoEndnoteText\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[iii]</span></span><!--[endif]--></span></span> This particular nightmare scenario is given in Yudkowsky (2001), who believes Marvin Minsky may have been the first to suggest it.</p>\n</div>\n<div id=\"edn4\" style=\"mso-element: endnote;\">\n<p class=\"MsoEndnoteText\"><span class=\"MsoEndnoteReference\"><span style=\"mso-special-character: footnote;\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 12.0pt; font-family: &quot;Cambria&quot;,&quot;serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: &quot;MS Mincho&quot;; mso-fareast-theme-font: minor-fareast; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: JA; mso-bidi-language: AR-SA;\">[iv]</span></span><!--[endif]--></span></span> These technical challenges are discussed in the literature on artificial agents in general and Artificial General Intelligence (AGI) in particular. Russell and Norvig (2009) provide a good overview of the challenges involved in the design of artificial agents. Goertzel and Pennachin (2010) provide a collection of recent papers on the challenges of AGI. Yudkowsky (2010) proposes a new extension of causal decision theory to suit the needs of a self-modifying AI. Yudkowsky (2001) discusses other technical (and philosophical) problems related to designing the goal system of a superintelligence.</p>\n</div>\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zd7rydGonamdjpugG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 20, "extendedScore": null, "score": 6.822409284260766e-07, "legacy": true, "legacyId": "5832", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4gnbMt9TKTjSPRXuT", "Sh4HPbqRDJsbB9ENK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T04:13:36.656Z", "modifiedAt": null, "url": null, "title": "Dawkins and Dennett defend Adaptationism [Links]", "slug": "dawkins-and-dennett-defend-adaptationism-links", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.680Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Perplexed", "createdAt": "2010-07-22T02:17:37.444Z", "isAdmin": false, "displayName": "Perplexed"}, "userId": "jj9aBsS9xsGPWKq3n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QwinqxwEaPtL2B5MM/dawkins-and-dennett-defend-adaptationism-links", "pageUrlRelative": "/posts/QwinqxwEaPtL2B5MM/dawkins-and-dennett-defend-adaptationism-links", "linkUrl": "https://www.lesswrong.com/posts/QwinqxwEaPtL2B5MM/dawkins-and-dennett-defend-adaptationism-links", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dawkins%20and%20Dennett%20defend%20Adaptationism%20%5BLinks%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADawkins%20and%20Dennett%20defend%20Adaptationism%20%5BLinks%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwinqxwEaPtL2B5MM%2Fdawkins-and-dennett-defend-adaptationism-links%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dawkins%20and%20Dennett%20defend%20Adaptationism%20%5BLinks%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwinqxwEaPtL2B5MM%2Fdawkins-and-dennett-defend-adaptationism-links", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQwinqxwEaPtL2B5MM%2Fdawkins-and-dennett-defend-adaptationism-links", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<p>Larry Moran is a Canadian biochemist and textbook author who has a blog about evolutionary biology called <a href=\"http://sandwalk.blogspot.com/\">The Sandwalk</a>.&nbsp; Recently he has been posting essay questions which he intends to use in an upcoming test of his students.&nbsp; Quotes from <a href=\"http://sandwalk.blogspot.com/2011/02/dawkins-darwin-drift-and-neutral-theory.html\">Richard Dawkins</a> and Daniel Dennett that he wants his students to critique.&nbsp; Also some <a href=\"http://sandwalk.blogspot.com/2011/02/quotations-from-richard-lewontin.html\">quotes from Richard Lewontin</a> that he wants his readers to admire.</p>\n<p>The interesting thing is that <a href=\"http://sandwalk.blogspot.com/2011/02/dan-dennett-replies.html\">Dennett</a> and Dawkins have both jumped into the discussion, as have a number of my favorite (though lesser known) biology bloggers.&nbsp; Interesting discussion.&nbsp; Worth a look if you are interested in evolutionary biology.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QwinqxwEaPtL2B5MM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 15, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "5844", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T05:58:20.223Z", "modifiedAt": null, "url": null, "title": "BOOK DRAFT: 'Ethics and Superintelligence' (part 2)", "slug": "book-draft-ethics-and-superintelligence-part-2", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.060Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hnS8f2bEucW3vNynA/book-draft-ethics-and-superintelligence-part-2", "pageUrlRelative": "/posts/hnS8f2bEucW3vNynA/book-draft-ethics-and-superintelligence-part-2", "linkUrl": "https://www.lesswrong.com/posts/hnS8f2bEucW3vNynA/book-draft-ethics-and-superintelligence-part-2", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%202)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%202)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhnS8f2bEucW3vNynA%2Fbook-draft-ethics-and-superintelligence-part-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=BOOK%20DRAFT%3A%20'Ethics%20and%20Superintelligence'%20(part%202)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhnS8f2bEucW3vNynA%2Fbook-draft-ethics-and-superintelligence-part-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhnS8f2bEucW3vNynA%2Fbook-draft-ethics-and-superintelligence-part-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 843, "htmlBody": "<p>&nbsp;</p>\n<p>Below is part 2 of the first draft of my book <em><a href=\"http://commonsenseatheism.com/?p=14397\">Ethics and Superintelligence</a></em>. Your comments and constructive criticisms are much appreciated.</p>\n<p>This is not a book for a mainstream audience. Its style is that of contemporary Anglophone philosophy. Compare to, for example, <a href=\"/lw/42l/david_chalmers_the_singularity_a_philosophical/\">Chalmers' survey article on the singularity</a>.</p>\n<p>Bibliographic references and links to earlier parts are provided <a href=\"http://commonsenseatheism.com/?p=14397\">here</a>.</p>\n<p>Part 2 is below...</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>***</p>\n<p class=\"MsoNormal\">Late in the Industrial Revolution, Samuel Butler (1863) worried about what might happen when machines become more capable than the humans who designed them:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&hellip;we are ourselves creating our own successors; we are daily adding to the beauty and delicacy of their physical organisation; we are daily giving them greater power and supplying by all sorts of ingenious contrivances that self-regulating, self-acting power which will be to them what intellect has been to the human race. In the course of ages we shall find ourselves the inferior race.</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&hellip;the time will come when the machines will hold the real supremacy over the world and its inhabitants&hellip;</p>\n<p class=\"MsoNormal\">By the time of the computer, Alan Turing (1950) realized that machines will one day be capable of genuine <em style=\"mso-bidi-font-style: normal;\">thought</em>:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">I believe that at the end of the century&hellip; <span style=\"mso-spacerun: yes;\">&nbsp;</span>one will be able to speak of machines thinking without expecting to be contradicted.</p>\n<p class=\"MsoNormal\">Turing (1951/2004) concluded:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&hellip;it seems probable that once the machine thinking method has started, it would not take long to outstrip our feeble powers... At some stage therefore we should have to expect the machines to take control&hellip;</p>\n<p class=\"MsoNormal\">All-powerful machines are a staple of science fiction, but one of the first serious arguments that such a scenario is <em style=\"mso-bidi-font-style: normal;\">likely</em> came from the statistician I.J. Good (1965):</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an &ldquo;intelligence explosion&rdquo;, and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.</p>\n<p class=\"MsoNormal\">Vernor Vinge (1993) called this future event the &ldquo;technological singularity.&rdquo; Though there are several uses of the term &ldquo;singularity&rdquo; in futurist circles (Yudkowky 2007), I will always use the term to refer to Good&rsquo;s predicted intelligence explosion.</p>\n<p class=\"MsoNormal\">David Chalmers (2010) introduced another terminological convention that I will borrow:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">Let us say that AI is artificial intelligence of human level or greater (that is, at least as intelligent as an average human). Let us say that AI+ is artificial intelligence of greater than human level (that is, more intelligent than the most intelligent human). Let us say that AI++ (or superintelligence) is AI of far greater than human level (say, at least as far beyond the most intelligent human as the most intelligent human is beyond a mouse).</p>\n<p class=\"MsoNormal\">With this in place, Chalmers formalized Good&rsquo;s argument like so:</p>\n<p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left: .75in; mso-add-space: auto; text-indent: -.25in; mso-list: l0 level1 lfo1;\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family: Cambria; mso-fareast-theme-font: minor-latin; mso-bidi-font-family: Cambria; mso-bidi-theme-font: minor-latin;\"><span style=\"mso-list: Ignore;\">1.<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->There will be AI (before long, absent defeaters).</p>\n<p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left: .75in; mso-add-space: auto; text-indent: -.25in; mso-list: l0 level1 lfo1;\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family: Cambria; mso-fareast-theme-font: minor-latin; mso-bidi-font-family: Cambria; mso-bidi-theme-font: minor-latin;\"><span style=\"mso-list: Ignore;\">2.<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->If there is AI, there will be AI+ (soon after, absent defeaters).</p>\n<p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left: .75in; mso-add-space: auto; text-indent: -.25in; mso-list: l0 level1 lfo1;\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family: Cambria; mso-fareast-theme-font: minor-latin; mso-bidi-font-family: Cambria; mso-bidi-theme-font: minor-latin;\"><span style=\"mso-list: Ignore;\">3.<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->If there is AI+, there will be AI++ (soon after, absent defeaters).</p>\n<p class=\"MsoListParagraphCxSpLast\" style=\"margin-left: .75in; mso-add-space: auto; text-indent: -.25in; mso-list: l0 level1 lfo1;\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family: Cambria; mso-fareast-theme-font: minor-latin; mso-bidi-font-family: Cambria; mso-bidi-theme-font: minor-latin;\"><span style=\"mso-list: Ignore;\">4.<span style=\"font: 7.0pt &quot;Times New Roman&quot;;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Therefore, there will be AI++ (before too long, absent defeaters).</p>\n<p class=\"MsoNormal\">I will defend Chalmers&rsquo; argument in greater detail than he has, using &ldquo;before long&rdquo; to mean &ldquo;within 150 years,&rdquo; using &ldquo;soon after&rdquo; to mean &ldquo;within two decades,&rdquo; and using &ldquo;before too long&rdquo; to mean &ldquo;within two centuries.&rdquo; My definitions here are similar to Chalmers&rsquo; definitions, but more precise.</p>\n<p class=\"MsoNormal\">Following Chalmers, by &ldquo;defeaters&rdquo; I mean &ldquo;anything that prevents intelligent systems (human or artificial) from manifesting their capacities to create intelligent systems.&rdquo; Defeaters include &ldquo;disasters, disinclination, and active prevention.&rdquo;</p>\n<p class=\"MsoNormal\">Disasters include catastrophic events that would severely impede scientific progress, such as supervolcano eruption, asteroid impact, cosmic rays, climate change, pandemic, nuclear war, biological warfare, an explosion of nanotechnology, and so on. The risk of such disasters and others are assessed in Bostrom &amp; Cirkovic (2008).</p>\n<p class=\"MsoNormal\">Disinclination refers to a lack of interest in developing AI of human-level general intelligence. Given the enormous curiosity of the human species, and the power that human-level AI could bring its creators, I think long-term disinclination is unlikely.</p>\n<p class=\"MsoNormal\">Active prevention of the development of human-level artificial intelligence has already been advocated by Thomas Metzinger (2004), though not because of the risk to humans. Rather, Metzinger is concerned about the risk to artificial agents. Early AIs will inevitably be poorly designed, which could lead to enormous subjective suffering for them that we cannot predict. One might imagine an infant from near Cherynobl whose parts are so malformed by exposure to nuclear radiation during development that its short existence is a living hell. In working toward human-level artificial intelligence, might we be developing millions of internally malformed beings that suffer horrible subjective experiences but are unable to tell us so?</p>\n<p class=\"MsoNormal\">It is difficult to predict the likelihood of the active prevention of AI development, but the failure of humanity to halt the development of ever more powerful nuclear weapons (Norris &amp; Kristensen 2009) &ndash; even after tasting their destructive power &ndash; does not inspire optimism.</p>\n<p class=\"MsoNormal\">Later, we will return to consider these potential defeaters again. For now, let us consider the premises of Chalmers&rsquo; argument.</p>\n<p class=\"MsoNormal\">***</p>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hnS8f2bEucW3vNynA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 6.823848153233483e-07, "legacy": true, "legacyId": "5848", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Sh4HPbqRDJsbB9ENK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T13:21:38.583Z", "modifiedAt": null, "url": null, "title": "Experimenting with education [link]", "slug": "experimenting-with-education-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.102Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Yci8noGtqpfmEbNSy/experimenting-with-education-link", "pageUrlRelative": "/posts/Yci8noGtqpfmEbNSy/experimenting-with-education-link", "linkUrl": "https://www.lesswrong.com/posts/Yci8noGtqpfmEbNSy/experimenting-with-education-link", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experimenting%20with%20education%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperimenting%20with%20education%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYci8noGtqpfmEbNSy%2Fexperimenting-with-education-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experimenting%20with%20education%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYci8noGtqpfmEbNSy%2Fexperimenting-with-education-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYci8noGtqpfmEbNSy%2Fexperimenting-with-education-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 16, "htmlBody": "<p>Hedge-fundie Ken Griffin sponsored a school-wide statistical experiment led by economist John List. Kudos for empiricism.</p>\n<p><a href=\"http://news.uchicago.edu/news.php?asset_id=1727\">http://news.uchicago.edu/news.php?asset_id=1727</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Yci8noGtqpfmEbNSy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6.825032657699872e-07, "legacy": true, "legacyId": "5864", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T20:42:19.863Z", "modifiedAt": null, "url": null, "title": "Does Solomonoff always win?", "slug": "does-solomonoff-always-win", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:52.036Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oHwt2JmDBefiN8rvg/does-solomonoff-always-win", "pageUrlRelative": "/posts/oHwt2JmDBefiN8rvg/does-solomonoff-always-win", "linkUrl": "https://www.lesswrong.com/posts/oHwt2JmDBefiN8rvg/does-solomonoff-always-win", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Does%20Solomonoff%20always%20win%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADoes%20Solomonoff%20always%20win%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoHwt2JmDBefiN8rvg%2Fdoes-solomonoff-always-win%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Does%20Solomonoff%20always%20win%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoHwt2JmDBefiN8rvg%2Fdoes-solomonoff-always-win", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoHwt2JmDBefiN8rvg%2Fdoes-solomonoff-always-win", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 555, "htmlBody": "<p>Can a computable human beat a Solomonoff hyperintelligence at making predictions about an incoming sequence of bits? If the sequence is computable, he probably can't. I'm interested in what happens when the sequence can be uncomputable. The answer depends on what you mean by \"beat\".</p>\n<p><strong>Game 1:</strong> on each round you and Omega state your probabilities that the next bit will be 1. The logarithm of the probability you assigned to the actual outcome gets added to your score. (This setup is designed to incentivize players to report their true beliefs, see Eliezer's <a href=\"http://yudkowsky.net/rational/technical\">technical explanation</a>.)</p>\n<p><strong>Game 2:</strong> you both start with a given sum of money. On each round you're allowed to bet some of it on 0 or 1 at 1:1 odds. You cannot go below zero. (This is the \"martingale game\", for motivation see the section on \"constructive martingales\" in the Wikipedia article on <a href=\"http://en.wikipedia.org/wiki/Algorithmically_random_sequence\">Martin-L&ouml;f randomness</a>.)</p>\n<p><strong>Game 3:</strong> on each round you call out 0 or 1 for the next bit. If you guess right, you win 1 dollar, otherwise you lose 1 dollar. Going below zero is allowed. (This simple game was suggested by Wei Dai in&nbsp;<a href=\"http://groups.google.com/group/one-logic/browse_thread/thread/b499a90ef9e5fd84\">this thread on one-logic</a>.)</p>\n<p>As it turns out, in game 1 you cannot beat Omega by more than an additive constant, even if the input sequence is uncomputable and you know its definition. (I have <a href=\"/r/discussion/lw/4gk/solomonoff_induction_by_shane_legg/\">linked before</a>&nbsp;to Shane Legg's text that can help you rederive this result.) Game 2 is a reformulation of game 1 in disguise, and you cannot beat Omega by more than a <em>multiplicative</em> constant. In game 3 you can beat Omega. More precisely, you can sometimes stay afloat while Omega sinks below zero at a linear rate.</p>\n<p>Here's how. First let's set the input sequence to be very malevolent toward Omega: it will always say the reverse of what Omega is projected to say based on the previous bits. As for the human, all he has to do is either always say 0 or always say 1. Intuitively it seems likely that at least one of those strategies will stay afloat, because whenever one of them sinks, the other rises.</p>\n<p>So is Solomonoff induction really <em>the</em>&nbsp;shining jewel at the end of all science and progress, or does that depend on the payoff setup? It's not clear to me whether our own universe is computable. In the thread linked above Eliezer argued that we should be trying to approximate Solomonoff inference anyway:</p>\n<blockquote>\n<p>If you're dealing with&nbsp;non-exceptional situations - non-devilish environments - then&nbsp;shouldn't a proof of <em>epistemic</em> error-boundedness generally carry&nbsp;over to a proof of decision error-boundedness? &nbsp;In other words, are&nbsp;you sure you're not assuming that the environment is a&nbsp;superintelligent adversary which is strictly more superintelligent&nbsp;than you, which is the sort of reasoning that leads people to adopt&nbsp;randomized algorithms?</p>\n</blockquote>\n<p>Eliezer's argument sounds convincing, but to actually work it must rely on some prior over <em>all of math,&nbsp;</em>including uncomputable universes, to justify the rarity of such \"devilish\" or \"adversarial\" situations. I don't know of any prior over all of math, and Wei's restating of Berry's paradox (also linked above) seems to show that inventing such a prior is futile. So we seem to lack any formal justification for adopting the Solomonoff distribution in reasoning about physics etc., unless I'm being stupid and missing something really obvious again.</p>\n<p>(posting this to discussion because I'm no longer convinced that my mathy posts belong in the toplevel)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oHwt2JmDBefiN8rvg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 14, "extendedScore": null, "score": 6.826210529209227e-07, "legacy": true, "legacyId": "5866", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PM5MQzXCrvsoAewWZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T22:45:00.578Z", "modifiedAt": null, "url": null, "title": "South Bay Less Wrong Meetup Saturday Feb 26th", "slug": "south-bay-less-wrong-meetup-saturday-feb-26th", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.364Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jasen", "createdAt": "2009-06-11T15:05:07.288Z", "isAdmin": false, "displayName": "Jasen"}, "userId": "hMDxPMjrPyw8vGzMa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eitHnzt7hJ6BCHPcu/south-bay-less-wrong-meetup-saturday-feb-26th", "pageUrlRelative": "/posts/eitHnzt7hJ6BCHPcu/south-bay-less-wrong-meetup-saturday-feb-26th", "linkUrl": "https://www.lesswrong.com/posts/eitHnzt7hJ6BCHPcu/south-bay-less-wrong-meetup-saturday-feb-26th", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20South%20Bay%20Less%20Wrong%20Meetup%20Saturday%20Feb%2026th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASouth%20Bay%20Less%20Wrong%20Meetup%20Saturday%20Feb%2026th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeitHnzt7hJ6BCHPcu%2Fsouth-bay-less-wrong-meetup-saturday-feb-26th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=South%20Bay%20Less%20Wrong%20Meetup%20Saturday%20Feb%2026th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeitHnzt7hJ6BCHPcu%2Fsouth-bay-less-wrong-meetup-saturday-feb-26th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeitHnzt7hJ6BCHPcu%2Fsouth-bay-less-wrong-meetup-saturday-feb-26th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 70, "htmlBody": "<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \"><a id=\"more\"></a>There will be a Less Wrong meetup at 6:00PM this Saturday, the 26th of February, at Tortuga (850 Williams way, Mountain View, CA), the planned community founded by Patri Friedman. &nbsp;Shannon Friedman will be our gracious host for the evening. &nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">As usual, the meet-up will be party-like and full of small group conversations. &nbsp;Feel free to bring food to share, or not.&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Please&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline; \" href=\"http://www.meetup.com/Bay-Area-Less-Wrong-Meetup/events/16402280/\">RSVP at the meetup.com page</a>&nbsp;if you plan to attend.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eitHnzt7hJ6BCHPcu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 6.82653848871394e-07, "legacy": true, "legacyId": "5867", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-23T22:50:10.592Z", "modifiedAt": null, "url": null, "title": "IBM Watson Research Team Answers Your Questions [link]", "slug": "ibm-watson-research-team-answers-your-questions-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.324Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kNRDWhn63W52M78rg/ibm-watson-research-team-answers-your-questions-link", "pageUrlRelative": "/posts/kNRDWhn63W52M78rg/ibm-watson-research-team-answers-your-questions-link", "linkUrl": "https://www.lesswrong.com/posts/kNRDWhn63W52M78rg/ibm-watson-research-team-answers-your-questions-link", "postedAtFormatted": "Wednesday, February 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20IBM%20Watson%20Research%20Team%20Answers%20Your%20Questions%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIBM%20Watson%20Research%20Team%20Answers%20Your%20Questions%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkNRDWhn63W52M78rg%2Fibm-watson-research-team-answers-your-questions-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=IBM%20Watson%20Research%20Team%20Answers%20Your%20Questions%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkNRDWhn63W52M78rg%2Fibm-watson-research-team-answers-your-questions-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkNRDWhn63W52M78rg%2Fibm-watson-research-team-answers-your-questions-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://blog.reddit.com/2011/02/ibm-watson-research-team-answers-your.html\">http://blog.reddit.com/2011/02/ibm-watson-research-team-answers-your.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kNRDWhn63W52M78rg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 6.826549673723015e-07, "legacy": true, "legacyId": "5868", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-24T05:05:39.907Z", "modifiedAt": null, "url": null, "title": "February 27 2011 Southern California Meetup", "slug": "february-27-2011-southern-california-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.301Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JenniferRM", "createdAt": "2009-03-06T17:16:50.600Z", "isAdmin": false, "displayName": "JenniferRM"}, "userId": "g8JkZfL8PTqAefpvx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HrdhinTzQqYZW4K8A/february-27-2011-southern-california-meetup", "pageUrlRelative": "/posts/HrdhinTzQqYZW4K8A/february-27-2011-southern-california-meetup", "linkUrl": "https://www.lesswrong.com/posts/HrdhinTzQqYZW4K8A/february-27-2011-southern-california-meetup", "postedAtFormatted": "Thursday, February 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20February%2027%202011%20Southern%20California%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFebruary%2027%202011%20Southern%20California%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHrdhinTzQqYZW4K8A%2Ffebruary-27-2011-southern-california-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=February%2027%202011%20Southern%20California%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHrdhinTzQqYZW4K8A%2Ffebruary-27-2011-southern-california-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHrdhinTzQqYZW4K8A%2Ffebruary-27-2011-southern-california-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 177, "htmlBody": "<p><a id=\"more\"></a>There will be a LessWrong meetup for Southern California on Sunday February 27th at 1:30PM.&nbsp; The location is being kindly provided by the Harvey Mudd <a href=\"http://www.hmc.edu/studentlife1/activities1/studentorgs1/futuretech.html\">A.I. &amp; Future Technology Club</a> in the <a title=\"google map to location on campus\" href=\"http://maps.google.com/maps?q=Platt+Campus+Center&amp;hl=en&amp;cd=1&amp;sll=34.106401,-117.709799&amp;sspn=0.071946,0.071946&amp;ie=UTF8&amp;view=map&amp;hnear=&amp;ll=34.101215,-117.702198&amp;spn=0.028926,0.084543&amp;z=14\">Platt Campus Center</a> of Harvey Mudd College.&nbsp; There will food, drinks, small group conversation, a whiteboard, a projector, and an opportunity to try <a href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">paranoid debating</a>.</p>\n<p>For travel planning purposes, the meetup is happening about 10 blocks north of the <a title=\"nearest train station\" href=\"http://www.metrolinktrains.com/stations/detail.php?id=90&amp;line=sb\">Claremont Metrolink Station</a>, which connects to the hub at LA Union Station.&nbsp; Train schedules can be searched <a title=\"google train search\" href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=&amp;daddr=Harvey+Mudd+College,+Claremont,+CA&amp;hl=en&amp;geocode=&amp;mra=ls&amp;dirflg=r&amp;ttype=dep&amp;date=09%2F25%2F10&amp;time=1:00pm&amp;noexp=0&amp;noal=0&amp;sort=&amp;sll=34.100505,-117.712369&amp;sspn=0.01457,0.031414&amp;ie=UTF8&amp;ll=34.100434,-117.711339&amp;spn=0.01457,0.031414&amp;z=15&amp;start=0\">here</a>.&nbsp; Also there should be car pooling opportunities in the comments.</p>\n<p>As more meetups have happened attendance has been increasing.&nbsp; If you want to make sure to see future announcements so you don't miss a meetup, you can sign up for the <a href=\"http://groups.google.com/group/LW-SoCal-Announce\">mailing list</a>. The room should be comfy for up to 40 people and we've never had more than that number yet, but for planning purposes it would be helpful if people <a href=\"/r/JenniferRM-drafts/lw/4jd/february_2011_southern_california_meetup/3lk7\">RSVP in the comments</a>.</p>\n<p>See you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HrdhinTzQqYZW4K8A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 6.827556279989379e-07, "legacy": true, "legacyId": "5881", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-24T22:56:58.482Z", "modifiedAt": null, "url": null, "title": "[Link] [Fiction] Ted Chiang: The Lifecycle of Software Objects", "slug": "link-fiction-ted-chiang-the-lifecycle-of-software-objects", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yKnBasvG33Yn5CAjj/link-fiction-ted-chiang-the-lifecycle-of-software-objects", "pageUrlRelative": "/posts/yKnBasvG33Yn5CAjj/link-fiction-ted-chiang-the-lifecycle-of-software-objects", "linkUrl": "https://www.lesswrong.com/posts/yKnBasvG33Yn5CAjj/link-fiction-ted-chiang-the-lifecycle-of-software-objects", "postedAtFormatted": "Thursday, February 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20%5BFiction%5D%20Ted%20Chiang%3A%20The%20Lifecycle%20of%20Software%20Objects&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20%5BFiction%5D%20Ted%20Chiang%3A%20The%20Lifecycle%20of%20Software%20Objects%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyKnBasvG33Yn5CAjj%2Flink-fiction-ted-chiang-the-lifecycle-of-software-objects%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20%5BFiction%5D%20Ted%20Chiang%3A%20The%20Lifecycle%20of%20Software%20Objects%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyKnBasvG33Yn5CAjj%2Flink-fiction-ted-chiang-the-lifecycle-of-software-objects", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyKnBasvG33Yn5CAjj%2Flink-fiction-ted-chiang-the-lifecycle-of-software-objects", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<p>http://www.subterraneanpress.com/index.php/magazine/fall-2010/fiction-the-lifecycle-of-software-objects-by-ted-chiang/</p>\n<p>A well-written novella about a company that has a proto-AI engine they use to make teachable virtual pets for sale in a cyberspace environment. Then the interest for the pets begins to decline and the company making them goes out of business. This makes for increasingly hard times for pet enthusiasts who've grown attached to theirs and refuse to just suspend them.</p>\n<p>Quite good, even though I find some elements a bit implausible. I find the premise particularly interesting because the \"let's build an AI engine to make virtual pets\" approach is what the OpenCog folks were planning on doing at one point. The story also touches on a number of other transhumanist themes.</p>\n<p>Besides, I cannot dislike a story that has the line, \"the demand for sex with Lojban-speaking tripods would be microscopic\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yKnBasvG33Yn5CAjj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "5902", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-25T06:23:03.965Z", "modifiedAt": null, "url": null, "title": "Go Try Things", "slug": "go-try-things", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.127Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6vTAMEwkqQH2Qkfox/go-try-things", "pageUrlRelative": "/posts/6vTAMEwkqQH2Qkfox/go-try-things", "linkUrl": "https://www.lesswrong.com/posts/6vTAMEwkqQH2Qkfox/go-try-things", "postedAtFormatted": "Friday, February 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Go%20Try%20Things&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGo%20Try%20Things%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vTAMEwkqQH2Qkfox%2Fgo-try-things%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Go%20Try%20Things%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vTAMEwkqQH2Qkfox%2Fgo-try-things", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vTAMEwkqQH2Qkfox%2Fgo-try-things", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 704, "htmlBody": "<p>So this isn't quite done, and its late here so I don't quite trust my judgements about writing at this hour. I've never done a top-level post before, so I wanted to get some feedback first.</p>\n<p>&nbsp;</p>\n<hr />\n<p class=\"MsoNormal\">Failure isn&rsquo;t that Bad<br /> <br /> You&rsquo;ve probably read about how to properly turn information into beliefs, and how to squeeze every last bit from your data. What seems not to have received as much attention is the importance of just going and getting data.<br /> <br /> For precise and well-defined fields and problems, clear thinking and reasoning will get you really far. Mathematics departments don&rsquo;t use that much equipment, and they&rsquo;ve been going fine for hundreds of years.<br /> <br /> For more mundane day-to-day concerns, getting data is probably more important than being rational. Where Rationality helps you get an accurate model of the world based on the data, Data gets you well, data. And practice. Your human brain can&rsquo;t rederive social rules in a vacuum, no matter how smart you are, so you have to go out and get information about it. But rationality with data is far better than either alone.</p>\n<p class=\"MsoNormal\">Sometimes you have to get your data by actually trying. Some things are just hard to explain in words and video. Your brain has all of this built in hardware for detecting and interpreting emotions and body language, but people are comparatively terrible at talking about it. This makes learning about different social or mood-variant things online difficult. Motions are also hard to teach online. I can kind of visualize how to do a front handspring, but I really can&rsquo;t transmit what it feels like to someone else without just asking them to try it. Note: I&rsquo;m not saying that asking others is useless, but I am saying that its mostly only effective as a complement to actually trying.<br /> <br /> Practice is important. As any akrasiatic or novice would know, knowledge in a field or domain doesn&rsquo;t translate directly to success in it. Like muscle memory, you need practice in order to get your brain to incorporate what you know to the point that you can use it automatically. Consciously thinking about what you&rsquo;re doing while you&rsquo;re doing it tends to cause lag and awkwardness, and in some fields (like conversation or physical activities) is a pretty large detriment.<br /> <br /> I had/have the problem of hesitating on acting until I&rsquo;m sure that whatever I&rsquo;m considering attempting is going to be successful. I&rsquo;m afraid of it not working, and am willing to do anything short of doing it in order to ensure success.<br /> <br /> This kind of hesitation though, is pretty useless. In many cases failure to act is about the same as your action failing. It avoids doing things that you regret, but it also avoids doing things in general. And if your hesitation doesn&rsquo;t result in a well thought-out plan to guarantee success in the future, then not only do you fail it that one time you hesitate, you&rsquo;re not going to make progress on succeeding in the future.</p>\n<p class=\"MsoNormal\">Sometimes failure is actually a problem (like you&rsquo;ll break something if you try extreme parkour tricks and fail), but I feel like in most instances I grossly overestimate how bad failing is. To combat this I do a few things:</p>\n<ul>\n<li>Consider a failure to act as an implicit failure. Not trying is as bad as trying and failing, except for whatever costs a failed attempt incur.</li>\n<li>Not regret failing. As long as I learn from my mistakes then making them results in a net gain. In the long term having failed at something and learning what to do is better than not attempting it.</li>\n<li>Attempt to minimize the cost of a failed attempt. I hesitate a lot with social things. If I fail with a stranger and never see them again, it&rsquo;s not that big of a deal. They might be annoyed, but as long as I didn&rsquo;t do something super horrible to them then they&rsquo;re probably going to forget about it.</li>\n</ul>\n<p class=\"MsoNormal\">So long story short, try things out. Improvement is hard unless you do, and failure seriously isn&rsquo;t that bad.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7thPfS2WbD2JKizr7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6vTAMEwkqQH2Qkfox", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 18, "extendedScore": null, "score": 6.831616155717527e-07, "legacy": true, "legacyId": "5916", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-25T16:04:38.567Z", "modifiedAt": null, "url": null, "title": "Some informal ramblings abaut what a defenition of reality might look like.", "slug": "some-informal-ramblings-abaut-what-a-defenition-of-reality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.501Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hprPC5B846cFXbCxk/some-informal-ramblings-abaut-what-a-defenition-of-reality", "pageUrlRelative": "/posts/hprPC5B846cFXbCxk/some-informal-ramblings-abaut-what-a-defenition-of-reality", "linkUrl": "https://www.lesswrong.com/posts/hprPC5B846cFXbCxk/some-informal-ramblings-abaut-what-a-defenition-of-reality", "postedAtFormatted": "Friday, February 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20informal%20ramblings%20abaut%20what%20a%20defenition%20of%20reality%20might%20look%20like.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20informal%20ramblings%20abaut%20what%20a%20defenition%20of%20reality%20might%20look%20like.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhprPC5B846cFXbCxk%2Fsome-informal-ramblings-abaut-what-a-defenition-of-reality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20informal%20ramblings%20abaut%20what%20a%20defenition%20of%20reality%20might%20look%20like.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhprPC5B846cFXbCxk%2Fsome-informal-ramblings-abaut-what-a-defenition-of-reality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhprPC5B846cFXbCxk%2Fsome-informal-ramblings-abaut-what-a-defenition-of-reality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 774, "htmlBody": "<p>I were originally going to just chat about this on IRC but last few times I did that I ended up concludin it'd have been better to make an inchoherent discusion post on it and i just got some karma to burn, so here goes nothing. Sorry for the lots and lots of things I'm assuming everywhere with no citing sources or proof, this wasn't really meant as anything articlelike.</p>\n<p>Many problems would have become a lot easier if we could assume everything you might even theoretically care about was Turing computable, and given a few more assumptions that most LWers appear to consider likely most kinds of uncertainty could be completely eliminated. However, that assumption seems that, while it might be true in practice, it's not obviously true or true per definition. Even if we turn out to live in a Turing computable universe, we still might care about non computable things outside it and try to influence then through ambient control or timeless trade or other such things.</p>\n<p>Looking at Bayes theorem, and under the influence of LW ideas in general, it seems that the difference between the probability of being in a certain universe, and how much you care about that universe relatively, is indistinguishable from the inside. I have been planing to write something about this topic but never got around do it so lets just have it as an assumption for now.</p>\n<p>Imagine a civilization building an AI to maximize the distance of handcomponents to hands, from http://lesswrong.com/lw/p2/hand_vs_fingers/ . It's defined through the green dots on the hand radar. The task involves escaping the universe so the AI decides to foom, and then it takes a look at the data again, and come to a 40% probability of the actual scenario, were it's supergoal is no longer even defined, and as a logical impossibility not simply local to this universe or time, and all actions have zero utility. However, this AI also realizes it can archive far, far more computational power if the universe turns out to be this way, and this computational power could be sold counter-factually on the timeless market, so it pre commits to gaining this computational power and trying to help it's counter factual self in that'd have happened if math had turned out differently. TDT means this'd have been the end result even if it hadn't realized the possibility and pre commited in advance.</p>\n<p>So now we have an AI that cares about a logically impossible world, and if probability, \"realness\", is indistinguishable from caring about somehting, then at least some logically impossible worlds are in some sense \"real\"; we cant exclude the possibility a human might care about them as well, and even subjectively anticipate being there. And I completly forgot where I were going with this and my head is all fuzzy insde.</p>\n<p>&nbsp;</p>\n<p>Our universe may or may not be turing computable, but it certainly seems you could approximate it, approaching it as a limit by simulating with increasingly higher resolution and higher precision without ever actually reaching it. One may propose then that anything that can be aproximated by a turing machine is the real math. but then you might come up with somehting that can be aproximated by somehting that can be aproximated by a turing machine, but only at perfect/infinite reslution thus itself can not be aproximated by a turing machine, and propose that stuff that can be aproximated by somehting that can be aproximated by a turing machine might be the true stuff of reality. And then you could repeat this. So we end up with somehting like a flood fill of aproximations, that spread around and may be arbitarily far away. I have considered the posibility this might be a good defention of math and atleast it includes evrything that could be aproximated by a human brain.</p>\n<p>However, you cant approximate a world where pi=4 or hands are separate from fingers and palms, like a talked abaut a few paragraps above, so it's not evrything anythign might care about. I propose&nbsp; mind caring about somehting logically impossible as a second kind of link. I muse abaut that if you foloodfill throguth bioth these kinds of links you might get a set thats a good defenition of reality. I might revisit this article tomorow or somehting I'm just panicingly scrabling to type out my flow of conciusnes before I forget stuff and half of it might be nonsence but you miht find a few persl in it and It gave me a headach and it's to close right now to consider objectively anyway so i wont fix it up right now, please coment some.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hprPC5B846cFXbCxk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -4, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "5932", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-25T18:06:26.100Z", "modifiedAt": null, "url": null, "title": "The Value of Theoretical Research", "slug": "the-value-of-theoretical-research", "viewCount": null, "lastCommentedAt": "2020-02-21T11:57:14.089Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s5sy3qiknFs7ehsLA/the-value-of-theoretical-research", "pageUrlRelative": "/posts/s5sy3qiknFs7ehsLA/the-value-of-theoretical-research", "linkUrl": "https://www.lesswrong.com/posts/s5sy3qiknFs7ehsLA/the-value-of-theoretical-research", "postedAtFormatted": "Friday, February 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Value%20of%20Theoretical%20Research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Value%20of%20Theoretical%20Research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5sy3qiknFs7ehsLA%2Fthe-value-of-theoretical-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Value%20of%20Theoretical%20Research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5sy3qiknFs7ehsLA%2Fthe-value-of-theoretical-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs5sy3qiknFs7ehsLA%2Fthe-value-of-theoretical-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 977, "htmlBody": "<p>For many of us, choosing a career path has a dominant effect on our contribution to the society. For those of us who care what happens to society, this makes it one of the most important decisions we make. Like most decisions, this one is very often made by impulses significantly below the level of conscious recognition, with considerable intellectual effort spent on <em>justifying</em> a conclusion but very little spent on actually <em>reaching </em>one. In the case of smart, altruistic rationalists, this seems like the most tragic failure of rationality; so, whatever the outcome, I advocate much more serious consideration by smart rationalists of how our career choices affect society. For the most part this is a personal thing, but some public discussion may be valuable. I apologize (largely in advance) for anything that seems condescending.</p>\n<p>I previously planned to do research in pure math (and more recently in theoretical computer science). I frequently justified my position with carefully constructed arguments which I no longer believe. It still may be the case that doing research is a good idea (and spending the rest of my life doing research is still the easiest possible career path for me), so I am interested in additional arguments, or reasons why anything I am about to write is wrong. Here is a basic list of my justifications, and why I no longer believe them.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Argument 1: Much math is practically important today. The math I am working on is not practically important today, but maybe it will be the math that is practically important tomorrow. How can we predict what will be useful? It seems like pushing math generally forward is the best response to this uncertainty.</p>\n<p>Rebuttal: If we really want to evaluate this argument, it is important to understand the conditions under which the important math of today was done. In the case of calculus, differential equations, statistics, functional analysis, linear algebra, group theory, and numerical methods, the important results for modern work were in fact developed after their usefulness could be appreciated by an intelligent observer. There is very little honestly compelling evidence that pushing math for the sake of pushing math is likely to lead to practically important results more effectively than waiting until new math is needed and then developing it. Perhaps the most compelling case is number theory and its unexpected application to cryptography, which is still not nearly compelling enough to justify work on pure math (or even provide significant support).</p>\n<p>&nbsp;</p>\n<p>Argument 2: Math is practically important today. The math I am working on is in a field that is practically important today, and not many people are qualified to work on it, so pushing the state of the art here is an excellent use of my time.</p>\n<p>Rebuttal: Consider the actual marginal utility of advances in your field of choice, honestly. In the overwhelming majority of cases, the bulk of research effort is directed grotesquely inefficiently from a social perspective. In particular, a small number of largely artificial applications will typically support research programs which consume an incredible amount of intelligent mathematicians' time, compared to the time required to make fundamental progress on the actual problem that people care about. Here you have to make a different argument for every research program, which I would be happy to do if anyone offers a particular challenge.</p>\n<p>&nbsp;</p>\n<p>Argument 3: Theoretical physics research advances the fundamental limits of understanding, which has led to important advances in the past and will probably continue to lead to important advances.</p>\n<p>Rebuttal: What matters are interactions in regimes that humans can engineer---improving understanding in such regimes is responsible for every technological development I am aware of. In particular, improvements in our understanding of high energy physics or cosmology are unlikely to be useful until we can design systems which operate in those regimes. There is fundamental physics research which seems likely to have a high payoff---but if you approach theoretical physics with the honest goal of contributing to technological progress, you end up with a research program which is unrecognizably different from most physicists'.</p>\n<p>&nbsp;</p>\n<p>Argument 4: Pure research is at least a little useful, and its what I am best prepared to do.</p>\n<p>Rebuttal: There is a shortage of intelligent, rational people in pretty much every area of human activity. I would go so far as to claim this is the limiting input for most fields. If you don't believe this, at least ask yourself why not. Do you have experience in other fields that suggests you are unable to contribute? Do you have a causal argument?</p>\n<p>&nbsp;</p>\n<p>Argument 5: Society is relatively efficient. The marginal returns for work in every field are roughly comparable, so I should work wherever I have comparative advantage.</p>\n<p>Rebuttal: Why should society be remotely efficient? I believed this for a long time, but eventually realized it was just a hold-over from a point in my life where I had more faith in other people. If you are typical LW readers, you probably believe at least half a dozen strong counterexamples to this claim already.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Argument 6: Pure research has fundamental value as an intellectual pursuit.</p>\n<p>Rebuttal: For whom? If you are concerned exclusively with the intellectual richness of mathematicians' lives, then I can't well disagree and this argument may be completely convincing. Otherwise, if you believe that the increasing richness of human mathematics is a fundamental good which non-mathematicians can enjoy, consider the inferential distances separating modern advances from even the most intelligent layperson. If your ultimate goal is the production of mathematics, or in fact any temporally altruistic objective, then consider alternatives which may increase the future's capacity to do mathematics and which may be orders of magnitude more effective.</p>\n<p>&nbsp;</p>\n<p>Argument 7: What else would I do to make a living? Research provides at least some benefit to society; alternatives seem even worse.</p>\n<p>Rebuttal: My past self, at least, was guilty of motivated stopping. See argument 4.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4kQXps8dYsKJgaayN": 2, "ZzxvopS4BwLuQy42n": 2, "6nS8oYmSMuFMaiowF": 2, "csMv9MvvjYJyeHqoo": 2, "fkABsGCJZ6y9qConW": 2, "qAvbtzdG2A2RBn7in": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s5sy3qiknFs7ehsLA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 51, "extendedScore": null, "score": 9.4e-05, "legacy": true, "legacyId": "5933", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 51, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-25T22:23:54.462Z", "modifiedAt": null, "url": null, "title": "Use curiosity ", "slug": "use-curiosity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:39.214Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WrSe4aB8sWBy3Nphm/use-curiosity", "pageUrlRelative": "/posts/WrSe4aB8sWBy3Nphm/use-curiosity", "linkUrl": "https://www.lesswrong.com/posts/WrSe4aB8sWBy3Nphm/use-curiosity", "postedAtFormatted": "Friday, February 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Use%20curiosity%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUse%20curiosity%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrSe4aB8sWBy3Nphm%2Fuse-curiosity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Use%20curiosity%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrSe4aB8sWBy3Nphm%2Fuse-curiosity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrSe4aB8sWBy3Nphm%2Fuse-curiosity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 392, "htmlBody": "<p>Related to: <a href=\"/lw/ju/rationalization/\">Rationalization</a>, <a href=\"/lw/jz/the_meditation_on_curiosity/\">Meditation on curiosity</a>, <a href=\"/lw/k7/original_seeing/\">Original Seeing</a>.</p>\n<p>Why aren&rsquo;t you learning faster?</p>\n<p>For me, one answer is: because I&rsquo;m not asking questions. &nbsp;I blunder through conversations trying to &ldquo;do my job&rdquo;, or to look good, or elaborating my own theories, or allowing cached replies to come out of my mouth on autopilot. &nbsp;I blunder through readings, scanning my eyes over the words and letting thoughts strike me as they may. &nbsp;Rarely am I pulled by a specific desire to know.</p>\n<p>And <em>most</em> of my learning happens at those rare times.</p>\n<p>How about you? &nbsp;When you read, how often do you <a href=\"http://www.overcomingbias.com/2010/05/chase-your-reading.html\">chase</a>&nbsp;<a href=\"http://meteuphoric.wordpress.com/2010/05/29/thinking-better-chase/\">something</a>? &nbsp;When you chat with your friends -- are you curious about how they&rsquo;re doing, why their mouth twitched as they said that, or why exactly they disagree with you about X? &nbsp;When you sit down to write, or to do research -- are you asking yourself specific questions, and then answering them?</p>\n<p>Are there certain situations in which you get most of your useful ideas -- situations you could put yourself in more often?</p>\n<p>Lately, when I notice that I&rsquo;m not curious about anything, I&rsquo;ve been trying to interrupt whatever I&rsquo;m doing. &nbsp;If I&rsquo;m in a conversation, and neither I nor my interlocutor is trying to figure something out, I call a mini &ldquo;<a href=\"/lw/u8/fighting_a_rearguard_action_against_the_truth/\">halt, melt, and catch fire</a>&rdquo; (inside my head, at least), and ask myself what I want. &nbsp;Surely not stale conversations. &nbsp;If I&rsquo;m writing, and I don&rsquo;t like the sentence I just wrote -- instead of reshuffling the words in the hopes that the new version will just happen to be better, I ask myself what I don&rsquo;t like about it. &nbsp;</p>\n<p>Thus, for the past six months, several times a day, I've interrupted&nbsp;my thoughts and put them back on an &ldquo;ask questions&rdquo; track. &nbsp;(&ldquo;Grrr, he said my argument was dishonest... Wait, is he right? &nbsp;What should it look like if he is?&rdquo;; &ldquo;I notice I feel hopeless about this paper writing. &nbsp;Maybe there&rsquo;s something I should do differently?&rdquo;) &nbsp;It's helping. &nbsp;I'm building the&nbsp;habit of interrupting myself when I'm \"thinking\" without trying to find something out, or taking actions that I expect won't <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">accomplish</a> anything.&nbsp;&nbsp;As a human, &nbsp;I&rsquo;m probably <a href=\"/lw/k5/cached_thoughts/\">stuck</a> running on habits --&nbsp;but I can at least change *which* habits I run on.</p>\n<div>When are you in the habit of asking questions? &nbsp;Would you learn more if you habitually asked other questions, too? &nbsp;Which ones?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"moeYqrcakMgXnQNyF": 8, "fkABsGCJZ6y9qConW": 2, "5f5c37ee1b5cdee568cfb0d6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WrSe4aB8sWBy3Nphm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": 80, "extendedScore": null, "score": 0.000159, "legacy": true, "legacyId": "5934", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 80, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 62, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SFZoEBpLo9frSJGkc", "3nZMgRTfFEfHp34Gb", "SA79JMXKWke32A3hG", "PCfaLLtuxes6Jk4S2", "PBRWb2Em5SNeWYwwB", "2MD3NMLBPCqPfnfre"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T08:10:02.466Z", "modifiedAt": null, "url": null, "title": "London meetup, Sunday 2011-03-06 14:00, near Holborn (reminder)", "slug": "london-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.769Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PbfZaicbAQ4CujQDD/london-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "pageUrlRelative": "/posts/PbfZaicbAQ4CujQDD/london-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "linkUrl": "https://www.lesswrong.com/posts/PbfZaicbAQ4CujQDD/london-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20London%20meetup%2C%20Sunday%202011-03-06%2014%3A00%2C%20near%20Holborn%20(reminder)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALondon%20meetup%2C%20Sunday%202011-03-06%2014%3A00%2C%20near%20Holborn%20(reminder)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPbfZaicbAQ4CujQDD%2Flondon-meetup-sunday-2011-03-06-14-00-near-holborn-reminder%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=London%20meetup%2C%20Sunday%202011-03-06%2014%3A00%2C%20near%20Holborn%20(reminder)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPbfZaicbAQ4CujQDD%2Flondon-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPbfZaicbAQ4CujQDD%2Flondon-meetup-sunday-2011-03-06-14-00-near-holborn-reminder", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>Reminder: we're <a href=\"/lw/3op/london_meetup_shakespeares_head_sunday_20110306/\">meeting up in London next weekend</a>.&nbsp;Sunday 6th March, at 2pm, in the <a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=shakespeare's+head&amp;sll=51.42559,-0.130394&amp;sspn=0.011854,0.020943&amp;ie=UTF8&amp;hq=shakespeare's+head&amp;hnear=&amp;layer=c&amp;cbll=51.516734,-0.119933&amp;panoid=kXPwAeowAo9LzJJA34agOw&amp;cbp=11,76.42,,1,-1.06&amp;ll=51.516728,-0.124025&amp;spn=0.005622,0.022488&amp;z=16\">Shakespeares Head</a>&nbsp;(<a href=\"http://www.jdwetherspoon.co.uk/home/pubs/shakespeares-head\">official page</a>) on Kingsway near Holborn Tube station. &nbsp;We'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\">look like this</a>. &nbsp;Hope to see lots of you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PbfZaicbAQ4CujQDD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.835759559784106e-07, "legacy": true, "legacyId": "5947", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["36D3SH3WnYhLW8cEL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T09:42:42.697Z", "modifiedAt": null, "url": null, "title": "A Common Form of Erroneous Thinking about the Universe", "slug": "a-common-form-of-erroneous-thinking-about-the-universe", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.865Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rohern", "createdAt": "2011-02-20T10:07:50.008Z", "isAdmin": false, "displayName": "rohern"}, "userId": "6XHrzkYyNwu5EZXrg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nnEqWa6uGibh5pQ3F/a-common-form-of-erroneous-thinking-about-the-universe", "pageUrlRelative": "/posts/nnEqWa6uGibh5pQ3F/a-common-form-of-erroneous-thinking-about-the-universe", "linkUrl": "https://www.lesswrong.com/posts/nnEqWa6uGibh5pQ3F/a-common-form-of-erroneous-thinking-about-the-universe", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Common%20Form%20of%20Erroneous%20Thinking%20about%20the%20Universe&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Common%20Form%20of%20Erroneous%20Thinking%20about%20the%20Universe%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnEqWa6uGibh5pQ3F%2Fa-common-form-of-erroneous-thinking-about-the-universe%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Common%20Form%20of%20Erroneous%20Thinking%20about%20the%20Universe%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnEqWa6uGibh5pQ3F%2Fa-common-form-of-erroneous-thinking-about-the-universe", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnnEqWa6uGibh5pQ3F%2Fa-common-form-of-erroneous-thinking-about-the-universe", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 760, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:Zoom>0</w:Zoom> <w:TrackMoves>false</w:TrackMoves> <w:TrackFormatting /> <w:PunctuationKerning /> <w:DrawingGridHorizontalSpacing>18 pt</w:DrawingGridHorizontalSpacing> <w:DrawingGridVerticalSpacing>18 pt</w:DrawingGridVerticalSpacing> <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery> <w:DisplayVerticalDrawingGridEvery>0</w:DisplayVerticalDrawingGridEvery> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:Compatibility> <w:BreakWrappedTables /> <w:DontGrowAutofit /> <w:DontAutofitConstrainedTables /> <w:DontVertAlignInTxbx /> </w:Compatibility> </w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" LatentStyleCount=\"276\"> </w:LatentStyles> </xml><![endif]--> <!-- /* Font Definitions */ @font-face {font-family:Cambria; panose-1:2 4 5 3 5 4 6 3 2 4; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:3 0 0 0 1 0;} @font-face {font-family:Futura; panose-1:2 11 6 2 2 2 4 2 3 3; mso-font-charset:0; mso-generic-font-family:auto; mso-font-pitch:variable; mso-font-signature:3 0 0 0 1 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal {mso-style-parent:\"\"; margin:0in; margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\"; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:Cambria; mso-fareast-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} @page Section1 {size:8.5in 11.0in; margin:1.0in 1.25in 1.0in 1.25in; mso-header-margin:.5in; mso-footer-margin:.5in; mso-paper-source:0;} div.Section1 {page:Section1;} --> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:\"Times New Roman\"; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\" style=\"text-align:center\" align=\"center\"><span style=\"font-family: Futura;\"><span style=\"text-decoration: underline;\"><br /></span></span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>This essay may be something of a non sequitur compared to usual LW topics.<span style=\"mso-spacerun: yes\">&nbsp; </span>I wrote it some time ago and have long been sitting on it, waiting to discover a place to share it.<span style=\"mso-spacerun: yes\">&nbsp;&nbsp;I have just spent some time stripping it down to bones for this forum. &nbsp;</span>I wrote it because I kept hearing while listening to or reading debates about religion, often involving Richard Dawkins or Christopher Hitchens (the Mighty Hitch), objections from religious types that contained some form of the argument:</span><span style=\"font-family: Futura;\">&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;Some aspect of the universe or of an object present in the universe exhibits such a high level of complexity that it can be concluded that it is not a <em>natural</em> product of the universe.<span style=\"mso-spacerun: yes\">&nbsp; </span>It indicates the existence of X [usually God].&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>I think that my response to this argument is relevant to this community because scientists and philosophers also make judgments about the complexity and the orderedness of the universe, indeed so have I, and I think that my objections to the above &ndash; patently silly &ndash; argument can be generalized to critique the statements of these latter two groups as well.<span style=\"mso-spacerun: yes\">&nbsp; </span>To it, then:</span><span style=\"font-family: Futura;\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>It is difficult to find sympathy for any opinion about the qualities of the universe predicated on the notion that a particular quality is beyond the capabilities of nature to produce unaided.<span style=\"mso-spacerun: yes\">&nbsp; </span>Such opinions can be as extreme as those of the religious who find the complexities of life as grounds for inferring the existence of a Creator or a mild as the casual observation that a natural occurrence is unusually or unexpectedly beautiful or orderly.<span style=\"mso-spacerun: yes\">&nbsp; </span>I recently found myself holding an opinion of the latter type concerning the human brain and the immense chemical and electrical complexities that effect its qualities.<span style=\"mso-spacerun: yes\">&nbsp; </span>There is some bizarre intuition that suggests the question, &ldquo;How can nature alone do something so great/complex/impressive?&rdquo;<span style=\"mso-spacerun: yes\">&nbsp; </span>I intend to here demonstrate that this intuition is specious and silly, and should be avoided by those who would make rational judgments.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>All of our opinions about what is naturally possible must be based, by definition, on observations of nature. &nbsp;Ultimately, some observation of nature grounds your reasoning about nature.<span style=\"mso-spacerun: yes\">&nbsp;&nbsp;</span>I take it that a moment of thought will confirm this in the reader.<span style=\"mso-spacerun: yes\">&nbsp; </span>Nature, by plain logic, cannot defy these opinions except when these opinions are themselves spurious.<span style=\"mso-spacerun: yes\">&nbsp; </span>To formalize: if all of your judgments about X come from observations of X, X cannot have properties that contradict these judgments unless these judgments are incorrect themselves.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>You may argue that our opinions of nature need not be based on observations of nature and that we can come to judgments about a thing without reference to that thing.<span style=\"mso-spacerun: yes\">&nbsp; </span>You and I hold two contradictory opinions about knowledge and how to come to it, at least as concerns objects in nature and nature itself.<span style=\"mso-spacerun: yes\">&nbsp; </span>I will not spend time arguing for a materialist and scientific approach in this essay, as others have done it better and have works readily available.<span style=\"mso-spacerun: yes\">&nbsp;</span></span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Futura;\"><span style=\"white-space: pre;\"> </span>The strangeness of claims that defy the dependence of judgment on observation is obvious&nbsp;</span><span style=\"font-family: Futura;\">when dealing with claims about the unnaturalness of objects:</span><span style=\"font-family: Futura;\">&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;Such a thing is unnatural.&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;How do you know?&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;By observing nature.&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;But the unnatural thing is as much a part of nature as the things you think are natural.&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>&ldquo;Yes.<span style=\"mso-spacerun: yes\">&nbsp; </span>Wait, what?&rdquo;</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>The same sort of objection applies to claims that nature is too &ldquo;well-tuned&rdquo; to be strictly natural.<span style=\"mso-spacerun: yes\">&nbsp; </span>Again, from where have you derived your opinion of what is the natural level of &ldquo;tunedness&rdquo;?<span style=\"mso-spacerun: yes\">&nbsp; </span>If you think that nature seems well-tuned, then it must be the case that one of the qualities of nature is its well-tunedness in this particular case.<span style=\"mso-spacerun: yes\">&nbsp;</span></span><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-family:Futura\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count:1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></strong><span style=\"font-family:Futura\">There is, I think, in judgments of the above form, an implicit comparison taking place, and it is from this unacknowledged comparison that the error arises.<span style=\"mso-spacerun: yes\">&nbsp; </span>When you say that nature is surprisingly or especially one way, to what are you comparing it? &nbsp;What is this thing that has given you your ideas about what is unsurprising or normal in nature if it is not nature itself. &nbsp;The inability to answer this question reveals the problem.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>This world is the realm within which we have formed all of our opinions about greatness, order, impressiveness, etc.<span style=\"mso-spacerun: yes\">&nbsp; </span>How then can a piece of the world defy these opinions except if the opinions are based on incomplete data or on bad reasoning or lousy observations.<span style=\"mso-spacerun: yes\">&nbsp; </span>Obviously these opinions of the world are wrong, not the world.<span style=\"mso-spacerun: yes\">&nbsp; </span>The natural world cannot fail to live-up to its own nature.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family:Futura\"><span style=\"mso-tab-count: 1\">&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span></span></p>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nnEqWa6uGibh5pQ3F", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 0, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "5949", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T09:57:15.716Z", "modifiedAt": null, "url": null, "title": "[link] On Reasonable Efforts", "slug": "link-on-reasonable-efforts", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.807Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AHSxYAdPpdECJGaZx/link-on-reasonable-efforts", "pageUrlRelative": "/posts/AHSxYAdPpdECJGaZx/link-on-reasonable-efforts", "linkUrl": "https://www.lesswrong.com/posts/AHSxYAdPpdECJGaZx/link-on-reasonable-efforts", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20On%20Reasonable%20Efforts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20On%20Reasonable%20Efforts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAHSxYAdPpdECJGaZx%2Flink-on-reasonable-efforts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20On%20Reasonable%20Efforts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAHSxYAdPpdECJGaZx%2Flink-on-reasonable-efforts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAHSxYAdPpdECJGaZx%2Flink-on-reasonable-efforts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 349, "htmlBody": "<p>Related to: <a href=\"/lw/uo/make_an_extraordinary_effort/\">Make an Extraordinary Effort</a>, <a href=\"/lw/un/on_doing_the_impossible/\">On Doing the Impossible</a>, <a href=\"/lw/up/shut_up_and_do_the_impossible/\">Shut up and do the impossible!</a>, <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans are not automatically strategic</a>.</p>\n<p>http://theferrett.livejournal.com/1587858.html</p>\n<p>Excerpt:</p>\n<blockquote>\n<p>We live in a culture so bound by what most people are willing to do that we often take them as hard limits - \"I can't do more than that,\" we say. \"I've done the best I can.\" But it really isn't. It's just the best we're willing to do <em>for right then</em>. <br /><br />When I was running and got my side-stitch, I really thought that I'd put 100% into it. But the truth was that I hated running, and I hated exercise, and I was putting maybe 20% of myself into it. If I was being chased by a bear, suddenly I'd find new reserves within me. And though I hated math homework, and thought that the grudging half an hour I did was really balls-out for math homework, I'd forget how many hours I'd spend memorizing PAC-Man patterns. <br /><br />After that, I realized where my real limits were - they were way up there. And maybe I could stop telling myself and others that <em>I did my best</em>. I didn't. Not even close. I did what I thought was <em>reasonable</em>. <br /><br />Sometimes you don't want reasonable. <br /><br />The thing about it is that you don't have to feel guilty about not giving it your all, all the time. That'd be crazy. If you started panning your friends to see the latest Rush concert, you'd be a mooch. But what's important is not to conflate \"a reasonable effort\" as the top end. Be honest. Know what percentage you're actually willing to give, and acknowledge that if it was that critical, you could do a lot of other, very creative, things to solve this problem. I don't ask you guys for money because I find it distasteful - but when <a href=\"http://theferrett.livejournal.com/260980.html\">my sister-in-law's life was at stake</a> and I didn't have the cash, you bet your ass I begged.</p>\n</blockquote>\n<p>Recommend reading the whole thing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AHSxYAdPpdECJGaZx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 27, "extendedScore": null, "score": 6.836046903847433e-07, "legacy": true, "legacyId": "5950", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["GuEsfTpSDSbXFiseH", "fpecAJLG9czABgCe9", "nCvvhFBaayaXyuBiD", "PBRWb2Em5SNeWYwwB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T13:37:40.758Z", "modifiedAt": null, "url": null, "title": "Is GiveWell.org the best charity (excluding SIAI)?", "slug": "is-givewell-org-the-best-charity-excluding-siai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:29.438Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "syllogism", "createdAt": "2010-12-09T02:25:23.672Z", "isAdmin": false, "displayName": "syllogism"}, "userId": "aHznJxGf4ZbruWkNa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qZT6AMhNBbuzneEJt/is-givewell-org-the-best-charity-excluding-siai", "pageUrlRelative": "/posts/qZT6AMhNBbuzneEJt/is-givewell-org-the-best-charity-excluding-siai", "linkUrl": "https://www.lesswrong.com/posts/qZT6AMhNBbuzneEJt/is-givewell-org-the-best-charity-excluding-siai", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20GiveWell.org%20the%20best%20charity%20(excluding%20SIAI)%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20GiveWell.org%20the%20best%20charity%20(excluding%20SIAI)%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqZT6AMhNBbuzneEJt%2Fis-givewell-org-the-best-charity-excluding-siai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20GiveWell.org%20the%20best%20charity%20(excluding%20SIAI)%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqZT6AMhNBbuzneEJt%2Fis-givewell-org-the-best-charity-excluding-siai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqZT6AMhNBbuzneEJt%2Fis-givewell-org-the-best-charity-excluding-siai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 651, "htmlBody": "<p>Update: I should've said \"non-existential risk charity\", rather than specifically exclude SIAI. I'm having trouble articulating why I don't want to give to an existential risk charity, so I'm going to think more deeply about it. <a href=\"/r/discussion/lw/4li/some_considerations_against_shortterm_andor/\">This post</a>&nbsp;is close to my source of discomfort, which is about the many highly uncertain assumptions necessary to motivate existential risk reduction. However, I couldn't articulate this argument properly before, so it might not be the true source of my discomfort. I'll keep thinking.</p>\n<p>\n<hr />\n</p>\n<p>I received my first pay-cheque from my first job after getting my degree, so it's time to start tithing. So I've been evalating which charity to donate to. I'd like to support the SIAI but I'm not currently convinced it's the best-value charity in a dollars-per-life sense, once time-value of money discounting is applied. I'd like to discuss the best non-SIAI charity available.</p>\n<p>By far the best source of information I've found is <a href=\"http://www.givewell.org\">www.givewell.org</a>. It was started by two hedge fund managers who were struck by the absence of rational charity evaluations, so decided that this was the most pressing problem they could work on.</p>\n<p>Perhaps the clearest, deepest finding from the studies they pull together and discuss is that <em>charity is hard</em>. Spending money doesn't automatically translate to doing good. It's not even enough to have smart people who care and know a lot about the problem think of ideas, and then spend money doing them. There's still a good chance the idea won't work. So we need to be evaluating programs rigorously before we scale them up, and keep evaluating as we scale.</p>\n<p>The bad news is that this isn't how charity is usually done. Very few charities make convincing evaluations of their activities public, if they carry them out at all. The good news is that some of the programs that <em>have</em> been evaluated are very, very effective. So choosing a charity rationally is absolutely critical.</p>\n<p>Let's say you're interested specifically in HIV/AIDS relief.[1] You could fund a program that mainly distributes Anti-Retroviral Therapy to HIV/AIDS patients, which has been estimated conservatively to cost <a href=\"http://www.givewell.org/international/technical/programs/ART\">$1494</a>&nbsp;per <a href=\"http://www.givewell.org/international/technical/additional/DALY\">disability adjusted life-year (DALY)</a>. Alternatively, you could fund a condom distribution program, which has been estimated conservatively to cost <a href=\"http://www.givewell.org/international/technical/programs/condom-distribution\">$112 per DALY</a>. Or, you could fund a program to prevent mother-to-child transmission, which has been estimated conservatively to cost <a href=\"http://www.givewell.org/international/technical/programs/PMTCT\">$12 per DALY</a>.&nbsp;So even within HIV/AIDS, funding the right program can make your donation <em>two orders of magnitude</em>&nbsp;more effective. By tithing 10% of my income every year for the next thirty years, I could have a bigger impact than a $25 million donation, if the person who placed that donation only did an <em>okay</em> job of choosing a charity.&nbsp;</p>\n<p>GiveWell currently gives its top recommendation to VillageReach, a charity that seeks to improve logistics for vaccine delivery to remote communities. The evidence is less cut-and-dried than you'd ideally want, but it's still compelling. They took vaccine rates up to 95%, and had very low stock-out rates for vaccines during the 4 year pilot project in Mozambique. They're estimated to have spent about $200usd per life saved. Even if future projects are two or three times less efficient, you're still saving a life for $600. Think about how little money that is. If you tithe, you can probably expect to save 10 lives a year. That's massive.</p>\n<p>Instead of donating directly to VillageReach, I'm going to just donate to GiveWell. They pool the funds they get and distribute them to their top charities, and I trust their analytic, evidence-based, largely utilitarian approach. Mostly, however, I think the work they're doing gathering and distributing information about charities is critically important. If more charities actually competed on evidence of efficacy, the whole endeavour might be a lot different. Does anyone have any better suggestions?</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>[1] I don't understand why people would want to help sufferers of one disease or condition specifically, instead of picking the lowest-hanging fruit, but apparently they do.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 1, "EeSkeTcT4wtW2fWsL": 1, "xEZwTHPd5AWpgQx9w": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qZT6AMhNBbuzneEJt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 52, "extendedScore": null, "score": 0.000129, "legacy": true, "legacyId": "5951", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jjK76gMHvdXF4hSLR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T17:40:35.688Z", "modifiedAt": null, "url": null, "title": "When to scream \"Error!\"", "slug": "when-to-scream-error", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.334Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bWGzEgMw34jHH586F/when-to-scream-error", "pageUrlRelative": "/posts/bWGzEgMw34jHH586F/when-to-scream-error", "linkUrl": "https://www.lesswrong.com/posts/bWGzEgMw34jHH586F/when-to-scream-error", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20to%20scream%20%22Error!%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20to%20scream%20%22Error!%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWGzEgMw34jHH586F%2Fwhen-to-scream-error%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20to%20scream%20%22Error!%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWGzEgMw34jHH586F%2Fwhen-to-scream-error", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbWGzEgMw34jHH586F%2Fwhen-to-scream-error", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 508, "htmlBody": "<p class=\"MsoNormal\">In <a href=\"/lw/4ku/use_curiosity\" target=\"_self\">Anna&rsquo;s recent post</a>, she talked about training your mind to notice when it wasn&rsquo;t curious about something and scream <a href=\"/lw/4ku/use_curiosity/3lt5\" target=\"_self\">&ldquo;Error! Look for a different way to do this&rdquo;</a> in such cases. Johnicholas and TheOtherDave's <a href=\"/lw/47j/make_your_training_useful/3j93\">list</a> of what stupidity feels like also looks useful for this purpose. I'm creating this post to make a more comprehensive list of feelings which indicate that people should reanalyze different possible paths to make sure that the one which they're taking is the most effective one to their objective.</p>\n<p class=\"MsoNormal\">Please suggest additions to the list in your comments -- I'll move them up here (along with links to further explanation, if given.) Keep in mind that your description of the feeling should be as illustrative as possible. For example, \"feeling stupid\" is unhelpful, while \"you feel like you've taken a wrong turn into a never-ending tunnel\" is better. Of course, metaphors which are immediately understood by some people may not be so easily understood by others, so try to give a more detailed description of the feeling if other people express that you're probably saying more than they're hearing.</p>\n<p class=\"MsoNormal\">List: \"Error! Look for a different way to do this\" if you feel like:</p>\n<ul>\n<li><a href=\"/lw/4ku/use_curiosity\">your curiosity is dead</a></li>\n<li>an automaton -- you're acting, albeit slowly, but your mind isn't grokking</li>\n<li>you've taken a wrong turn into a never-ending tunnel</li>\n<li>you're behaving clunkily, mechanically, when there's an already-formed instinct waiting to be used</li>\n<li><a href=\"/r/discussion/lw/4le/when_to_scream_error/3lvv\">what you're doing is \"like watching cable, only with fewer hair replacement infomercials\"</a></li>\n<li><a href=\"/r/discussion/lw/4le/when_to_scream_error/3lvz\">you have to avoid working out the implications of a particular line of reasoning.</a></li>\n<li>you're going to have to grit your teeth and do a tedious and boring task<sup>1</sup></li>\n<li>you're blind and must be led around by more observant people</li>\n<li>you're doing something because you're <em>supposed</em> to, rather than because it helps you achieve goals<sup>3</sup></li>\n<li><a href=\"/r/discussion/lw/4le/when_to_scream_error/3lx0\">you just shrugged off something that seemed important</a></li>\n</ul>\n<ul>\n<li><a href=\"/lw/47j/make_your_training_useful/3j93\">Stupidity feels like</a>:</li>\n</ul>\n<blockquote>\n<ul>\n<li>being bored, being in pain, being distracted, wanting to do anything else than this</li>\n<li>being unworthy of these divine (external) ideas</li>\n<li>blind plodding obedience</li>\n<li>being tired all the time, even if you're not<sup>2</sup></li>\n<li>not having enough fingers to hold all of my thoughts in place</li>\n<li>merging onto the highway when I can't see all the oncoming traffic</li>\n<li>someone's playing loud distracting music that I can't hear</li>\n<li>riding on a train with square wheels</li>\n</ul>\n<hr />\n</blockquote>\n<blockquote><sup>1. Sometimes tedious/boring tasks genuinely cannot be made easier or less boring, so your \"Error!\" message might not return anything useful. However, you should at least <em>look</em>.</sup></blockquote>\n<blockquote><sup>2. This may also indicate that your stupidity has biological causes, such as nutrition/sleep deficiency. 20-30 minute naps are awesome, though longer ones might make you groggy.</sup></blockquote>\n<blockquote><sup>3. Of course, if a goal-achieving action is also supported by authorities, that is a <em>good thing.</em></sup><br /></blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bWGzEgMw34jHH586F", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 13, "extendedScore": null, "score": 6.837288848549173e-07, "legacy": true, "legacyId": "5954", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WrSe4aB8sWBy3Nphm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-26T20:57:27.652Z", "modifiedAt": null, "url": null, "title": "Vassar talk in New Haven, Sunday 2/27 ", "slug": "vassar-talk-in-new-haven-sunday-2-27", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:50.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alyssavance", "createdAt": "2009-10-07T20:08:31.887Z", "isAdmin": false, "displayName": "alyssavance"}, "userId": "zQSAWAS5tnqtzp55N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MFQsD8giWeDMqgXHc/vassar-talk-in-new-haven-sunday-2-27", "pageUrlRelative": "/posts/MFQsD8giWeDMqgXHc/vassar-talk-in-new-haven-sunday-2-27", "linkUrl": "https://www.lesswrong.com/posts/MFQsD8giWeDMqgXHc/vassar-talk-in-new-haven-sunday-2-27", "postedAtFormatted": "Saturday, February 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFQsD8giWeDMqgXHc%2Fvassar-talk-in-new-haven-sunday-2-27%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFQsD8giWeDMqgXHc%2Fvassar-talk-in-new-haven-sunday-2-27", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFQsD8giWeDMqgXHc%2Fvassar-talk-in-new-haven-sunday-2-27", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>Hey all. I've invited Michael Vassar, president of the Singularity Institute, to come to Yale to give a talk on AI and the Methods of Rationality. We'll be holding the talk on Sunday the 27th at 4 PM, at WLH 119 (100 Wall St., New Haven CT), with an open discussion afterwards. Everyone should come- there will be free pizza!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MFQsD8giWeDMqgXHc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 6.83781666079363e-07, "legacy": true, "legacyId": "5955", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T00:27:08.597Z", "modifiedAt": null, "url": null, "title": "Existential Risk Reduction Career Network", "slug": "existential-risk-reduction-career-network", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:33.850Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9QfLnRi2GwHaEBeN5/existential-risk-reduction-career-network", "pageUrlRelative": "/posts/9QfLnRi2GwHaEBeN5/existential-risk-reduction-career-network", "linkUrl": "https://www.lesswrong.com/posts/9QfLnRi2GwHaEBeN5/existential-risk-reduction-career-network", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Existential%20Risk%20Reduction%20Career%20Network&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExistential%20Risk%20Reduction%20Career%20Network%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9QfLnRi2GwHaEBeN5%2Fexistential-risk-reduction-career-network%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Existential%20Risk%20Reduction%20Career%20Network%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9QfLnRi2GwHaEBeN5%2Fexistential-risk-reduction-career-network", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9QfLnRi2GwHaEBeN5%2Fexistential-risk-reduction-career-network", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>Interested in donating to existential risk reduction efforts? Would you like to exchange career information with like-minded others? Then you should consider the Existential Risk Reduction Career Network! (\"X Risk Network\" for those short on time.) From the front page of the website:</p>\n<p>\"This network is for anyone interested in donating substantial amounts (relative to income) to non-profit organizations focused on the reduction of existential risk, such as <a rel=\"nofollow\" href=\"http://intelligence.org/\" target=\"_blank\">SIAI</a>,&nbsp;<a rel=\"nofollow\" href=\"http://www.fhi.ox.ac.uk/\" target=\"_blank\">FHI</a>, and the <a rel=\"nofollow\" href=\"http://lifeboat.com/ex/main\" target=\"_blank\">Lifeboat Foundation</a>. [...] We are a community of people assisting each other to increase our resources available for contribution. Members discuss the strengths and weaknesses of different careers, network, share advice on job applications and career advancement, assist others with finding interviews, and occasionally look for qualified individuals to hire from within the network.\"</p>\n<p>For more details, including on the process of requesting invitations, head on over to the front page at <a href=\"http://www.xrisknetwork.org/\">http://www.xrisknetwork.org/</a></p>\n<p>Keep in mind that the network is for students as well, not just those currently on the job market. The network also has discussion of long term job strategy, school admissions, and intern possibilities.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9QfLnRi2GwHaEBeN5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 6.838378913942866e-07, "legacy": true, "legacyId": "5956", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T02:49:28.919Z", "modifiedAt": null, "url": null, "title": "Vassar talk in New Haven, Sunday 2/27", "slug": "vassar-talk-in-new-haven-sunday-2-27-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alyssavance", "createdAt": "2009-10-07T20:08:31.887Z", "isAdmin": false, "displayName": "alyssavance"}, "userId": "zQSAWAS5tnqtzp55N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/25eJPpFnoWozopete/vassar-talk-in-new-haven-sunday-2-27-0", "pageUrlRelative": "/posts/25eJPpFnoWozopete/vassar-talk-in-new-haven-sunday-2-27-0", "linkUrl": "https://www.lesswrong.com/posts/25eJPpFnoWozopete/vassar-talk-in-new-haven-sunday-2-27-0", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25eJPpFnoWozopete%2Fvassar-talk-in-new-haven-sunday-2-27-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vassar%20talk%20in%20New%20Haven%2C%20Sunday%202%2F27%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25eJPpFnoWozopete%2Fvassar-talk-in-new-haven-sunday-2-27-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F25eJPpFnoWozopete%2Fvassar-talk-in-new-haven-sunday-2-27-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p>Hey all. I've invited Michael Vassar, president of the Singularity Institute, to come to Yale to give a talk on AI and the Methods of Rationality. We'll be holding the talk on Sunday the 27th at 4 PM, at WLH 119 (100 Wall St., New Haven CT), with an open discussion afterwards. Everyone should come- there will be free pizza!</p>\n<p>(Reposted to main section on request of JGWeissman).&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "25eJPpFnoWozopete", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.83876063479025e-07, "legacy": true, "legacyId": "5957", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T04:31:03.693Z", "modifiedAt": null, "url": null, "title": "Some Considerations Against Short-Term and/or Explicit Focus on Existential Risk Reduction", "slug": "some-considerations-against-short-term-and-or-explicit-focus", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "multifoliaterose", "createdAt": "2010-06-13T08:56:10.885Z", "isAdmin": false, "displayName": "multifoliaterose"}, "userId": "747HfTZFyfTqGyoPM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jjK76gMHvdXF4hSLR/some-considerations-against-short-term-and-or-explicit-focus", "pageUrlRelative": "/posts/jjK76gMHvdXF4hSLR/some-considerations-against-short-term-and-or-explicit-focus", "linkUrl": "https://www.lesswrong.com/posts/jjK76gMHvdXF4hSLR/some-considerations-against-short-term-and-or-explicit-focus", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20Considerations%20Against%20Short-Term%20and%2For%20Explicit%20Focus%20on%20Existential%20Risk%20Reduction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20Considerations%20Against%20Short-Term%20and%2For%20Explicit%20Focus%20on%20Existential%20Risk%20Reduction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjjK76gMHvdXF4hSLR%2Fsome-considerations-against-short-term-and-or-explicit-focus%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20Considerations%20Against%20Short-Term%20and%2For%20Explicit%20Focus%20on%20Existential%20Risk%20Reduction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjjK76gMHvdXF4hSLR%2Fsome-considerations-against-short-term-and-or-explicit-focus", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjjK76gMHvdXF4hSLR%2Fsome-considerations-against-short-term-and-or-explicit-focus", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1163, "htmlBody": "<p>Over the past six months I've been repeatedly going back and forth on my attitude toward the value of short-term and/or exclusive focus on existential risk. Here I'll offer some reasons why a utilitarian who recognizes the upside of preventing human extinction may refrain from a direct focus on existential risk reduction. I remain undecided on my attitude toward short-term and/or exclusive focus on existential risk - this article is not rhetorical in intent; I'm just throwing some relevant issues out there.</p>\n<p>1. On the subject of FAI research, <a href=\"/lw/2lr/the_importance_of_selfdoubt/2h6x\">Prase stated that</a>:</p>\n<blockquote>\n<p>The whole business <em>is</em> based on future predictions of several tens or possibly hunderts years in advance, which is historically a very unsuccessful discipline. And I can't help but include it in that reference class.</p>\n</blockquote>\n<p>The same can be said of much of the speculation concerning existential risk in general, not so much existential risk due to asteroid strike or Venusian global warming but rather with the higher probability but much more amorphous existential risks connected with advanced technologies (general artificial intelligence, whole brain emulation, nano weapons, genetically engineered viruses, etc.).</p>\n<p>A principle widely held by many highly educated people is that it's virtually impossible to predict the future more than a few decades out. Now, one can attempt to quantify \"virtually impossible\" as a small probability that one's model of the future is correct and multiply it by the numbers that emerge as outputs of one's model of the future in Fermi calculations, but the multiplier corresponding to \"virtually impossible\" may be considerably smaller than one might naively suppose...</p>\n<p>2. As AnnaSalamon said in <a href=\"/lw/34a/goals_for_which_less_wrong_does_and_doesnt_help/\">Goals for which Less Wrong does (and doesn't) help</a>,</p>\n<blockquote>\n<p>conjunctions are <a href=\"/lw/ji/conjunction_fallacy/\">unlikely</a></p>\n</blockquote>\n<p>Assuming that A and B are independent events, the probability of their conjunction is p(A)p(B). So for example, an event that's the conjunction of n independent events each with probability 0.1 occurs with probability 10<sup>-n</sup>. As humans are <a href=\"/lw/ji/conjunction_fallacy/\">systematically biased toward believing that conjunctions</a> are more likely than their conjuncts (at least in certain setting), there's a strong possibility of <em>exponentially</em> overestimating probabilities in the course of Fermi calculations. This is true both of the probability that one's model is correct (given the amount of uncertainty involved in the future as reflected by historical precedent) and of the individual probabilities involved assuming that one's model is correct.</p>\n<p>Note that I'm not casting doubt on the utility of Fermi calculations <em>as a general matter</em> - Carl Shulman has been writing an interesting series of posts <a href=\"/lw/2ur/politics_as_charity_dissecting_the_decisive_vote/\">arguing that one can use Fermi calculations</a> to draw reasonable conclusions about political advocacy as philanthropy. However, Carl's posts have been data-driven in a much stronger sense than Fermi calculations about the probabilities of technologically driven existential risks have been.</p>\n<p>3. While the efficient market hypothesis may not hold in the context of philanthropy, it's arguable that the philanthropic world is efficient <em>given the human resources and social institutions that are on the table</em>. Majoritarianism is epistemically wrong, but society is quite rigid and whether or not successful advocacy of a particular cause is tenable depends in some measure on whether society is ready for it. In <a href=\"/lw/2hv/public_choice_and_the_altruists_burden/\">Public Choice and the Altruist's Burden</a> Roko wrote</p>\n<blockquote>\n<p>I personally have suffered, as have many, from low-level punishment from and worsening of relationships with my family, and social pressure from friends;&nbsp;being&nbsp;perceived&nbsp;as weird. I have also <em>become </em>more weird - spending one's time optimally for social status and personal growth is not at all like spending one's time in a way so as to reduce existential risks. Furthermore, thinking that the world is in grave danger but only you and a select group of people understand makes you feel like you are in a cult due to the huge cognitive dissonance it induces.</p>\n</blockquote>\n<p>Even when epistemically justified in the abstract, focus on fringe causes may take too much of a psychological toll on serious supporters in order for serious supporters to be effective in pursuing their goals. To the extent that focus on existential risk requires radical self sacrificing altruism there are dangers of the type described <a href=\"/lw/38u/best_career_models_for_doing_research/33et\">in a comment by Carl Shulman</a>:</p>\n<blockquote>\n<p>Usually this doesn't work out well, as the explicit reasoning about principles and ideals is gradually <a href=\"/lw/1l4/a_masterslave_model_of_human_preferences\">overridden by other mental processes</a>, leading to exhaustion, burnout, or disillusionment. The situation winds up worse according to all of the person's motivations, even altruism. Burnout means less good gets done than would have been achieved by leading a more balanced life that paid due respect to all one's values. Even more self-defeatingly, if one actually does make severe sacrifices, it will tend to repel bystanders.</p>\n</blockquote>\n<p>4. Because of the upside of ensuring the survival rate is so huge, there's an implicit world view among certain people on Less Wrong that, e.g. existential risk reduction charities offer the opportunities for optimal philanthropy. I think that existential risk reduction charities <em>may</em> offer opportunities for optimal philanthropy, but that the premise that this is so largely independently of the quality of the work that these charities are doing is essentially parallel to the premise behind Pascal's Wager. In <a href=\"/lw/2yp/making_your_explicit_reasoning_trustworthy/\">Making your explicit reasoning trustworthy</a> Anna Salamon wrote</p>\n<blockquote>\n<p class=\"p2\">I find I hesitate when pondering <a href=\"http://www.overcomingbias.com/2008/08/where-does-pasc.html\">Pascal&rsquo;s wager</a>, <a href=\"http://www.nickbostrom.com/ethics/infinite.pdf\">infinite ethics</a>, the <a href=\"http://www.simulation-argument.com/simulation.html\">Simulation argument</a>, and whether I&rsquo;m a <a href=\"/lw/17d/forcing_anthropics_boltzmann_brains\">Boltzmann brain</a>... because I&rsquo;m afraid of losing my bearings, and believing mistaken things. [...] <span style=\"font-weight: normal; font-size: small;\">examples abound of folks whose theories and theorizing (as contrasted with their habits, wordless intuitions, and unarticulated responses to social pressures or their own emotions) made significant chunks of their actions worse. [...]</span><span style=\"font-weight: normal; font-size: small;\"> examples abound of folks whose theories and theorizing (as contrasted with their habits, wordless intuitions, and unarticulated responses to social pressures or their own emotions) made significant chunks of their actions worse. </span></p>\n<p class=\"p2\"><em>Use raw motivation, emotion, and behavior to determine at least part of your priorities.</em></p>\n</blockquote>\n<p class=\"p2\">I'm not able to offer a strong logical argument against the use of Pascal's wager or infinite ethics but nevertheless feel right to reject them as absurd. Similarly, though I'm unable to offer a strong logical argument for doing so (although I've listed some of the relevant intuitions above), I feel right to restrict support to existential risk reduction opportunities that meet some minimal standard for \"sufficiently well-conceived and compelling\" well above that of multiplying the value of ensuring human survival by a crude guess as to the probability that a given intervention will succeed.</p>\n<p class=\"p2\">Intuitively, the position \"it doesn't matter how well executed charity X's activities are; since charity X is an existential risk reduction charity, charity X triumphs non-existential risk charities\" is for me a <em>reductio ad absurdem</em> for adopting a conscious, explicit, single-minded focus on existential risk reduction.</p>\n<p class=\"p2\"><em>Disclaimer:</em> I do not intend for my comments about the necessity of meeting a minimal standard to apply specifically to any existential risk reduction charity on the table. I have huge uncertainties as to the significance of most of the points that I make in this post. Depending on one's assessment of their significance one could end up either in favor or against short-term and/or explicit focus on existential risk reduction</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jjK76gMHvdXF4hSLR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 12, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "5958", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7dRGYDqA2z6Zt7Q4h", "QAK43nNCTQQycAcYe", "YafmHeLuxfRNRkgN2", "t7tk2YiSDj7KCBXCZ", "yZ4aieJeP85ezeiu3", "m5AH78nscsGjMbBwv", "LubwxZHKKvCivYGzx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T05:08:59.445Z", "modifiedAt": null, "url": null, "title": "Inspiring Rationalists", "slug": "inspiring-rationalists", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.186Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i739wp9uQMNkqFJko/inspiring-rationalists", "pageUrlRelative": "/posts/i739wp9uQMNkqFJko/inspiring-rationalists", "linkUrl": "https://www.lesswrong.com/posts/i739wp9uQMNkqFJko/inspiring-rationalists", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Inspiring%20Rationalists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInspiring%20Rationalists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi739wp9uQMNkqFJko%2Finspiring-rationalists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Inspiring%20Rationalists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi739wp9uQMNkqFJko%2Finspiring-rationalists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi739wp9uQMNkqFJko%2Finspiring-rationalists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 796, "htmlBody": "<p>I am concerned with the number of rational, altruistic, smart people in the world. By my standards there are a reasonable number of smart, altruistic (in far mode) people, so a good first step is improving their rationality. To keep \"rationality\" grounded, I should be a little more precise about what I mean.</p>\n<p>There are people who care about the needs of others, while they are in far mode at least, and who are good at solving hard problems. I believe many of them fail to apply their problem solving capabilities effectively to some important questions: \"What do I believe about the world, and why?\" \"What do I value?\" \"Based on those beliefs and values, what should I spend my time doing?\" Worse, they sometimes arrive at answers to these questions which are seriously affected by various biases which (I believe) they would eventually recognize as biases. This behavior defines irrationality.</p>\n<p>Suppose that someone has successfully created a sequence of readings which contained everything you might need to know in order to become reasonably rational. The accessibility of these readings is not in itself adequate to make smart, altruistic people automatically rational. Based on my experience with humans, I strongly suspect that personal engagement is ultimately necessary, at least if the smart people in question are living in the same culture I am (and the best way to change culture is to change people). What needs to be accomplished with this personal engagement, so that the mere accessibility of written wisdom could do the rest?</p>\n<p>Here is my take on the requirements.</p>\n<p>1) They need to believe that thinking about their beliefs, values, thought process, and decision making process is valuable. They need to have a strong sense that self-improvement along these axes is valuable; they need to believe that more is possible.&nbsp;</p>\n<p>2) They need to be able to act on the basis of abstract reasoning. Most people seem to have a very firm barrier between the part of them that learns things and the part that makes decisions; no matter how much the learning part believes that the decision making part should listen to it, it doesn't do any good unless the decision making part actually listens. This seems to be a rather serious problem in general.</p>\n<p>3) They need to admit the possibility that some beliefs they hold strongly are wrong. Beliefs in which a person places complete confidence seem to be able to defeat an arbitrary static argument in the overwhelming majority of cases. As the belief holder gets smarter, the range of truths (or probably-truths) which need to be destroyed broadens and the surety with which they will be destroyed increases.</p>\n<p>4) They need to be able to understand moderately complex arguments. There is a basic level of understanding which can be used to bootstrap to much higher levels given only written text; getting to that basic level requires something else. Describing Bayes' theorem, for example, to someone who lacks this basic level of understanding seems to be extremely difficult. In general I think this problem is more or less insignificant compared to (1) or (2).</p>\n<p>As for resolving them:</p>\n<p>1) The obvious solution is a good exemplar, popularly disseminated and presented in a way that makes a clear case. Its a little troubling that the best instantiation right now is fan fiction (to my knowledge). Much better would be real role models; for example, being able to point to one or more small group of rationalists successfully pursuing some extremely visible indicator of success.</p>\n<p>Another effective way to instill this belief in a particular person may be to point out a manifestly and seriously negative consequence of some failure of their rationality. I am not aware of any really compelling widely applicable examples (deconversion may work excellently for people who have gone from being quite religious to being quite areligious).</p>\n<p>A slightly underhanded approach which might be more effective is to deliberately and repeatedly create situations in which a failure of rationality has manifestly negative consequences. The best insantiations I know are simple tests which reveal cognitive biases, but versions more plausibly analogous to everyday experience may be much more powerful. For example, I would be very interested to understand how people's responses to simple tests for confirmation bias etc. change when the way the test is presented changes: I can just tell you about the experience, which appears to be completely worthless; I can play a game against you, to which most people I know respond after losing by not caring at all, despite apparently trying; I don't know what happens if I play the game with volunteer test subjects who are paid $10 if they succeed. I am slightly more optimistic about this approach than the last one because I think less time has been spent thinking about it.</p>\n<p>2)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i739wp9uQMNkqFJko", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "5959", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T12:32:45.172Z", "modifiedAt": null, "url": null, "title": "Value agression", "slug": "value-agression", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ejeH8Mbnprtxhqp27/value-agression", "pageUrlRelative": "/posts/ejeH8Mbnprtxhqp27/value-agression", "linkUrl": "https://www.lesswrong.com/posts/ejeH8Mbnprtxhqp27/value-agression", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Value%20agression&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AValue%20agression%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejeH8Mbnprtxhqp27%2Fvalue-agression%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Value%20agression%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejeH8Mbnprtxhqp27%2Fvalue-agression", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FejeH8Mbnprtxhqp27%2Fvalue-agression", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": null, "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ejeH8Mbnprtxhqp27", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "5960", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": null, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T17:43:57.659Z", "modifiedAt": null, "url": null, "title": "LINK: Bostrom & Yudkowsky, \"The Ethics of Artificial Intelligence\" (2011)", "slug": "link-bostrom-and-yudkowsky-the-ethics-of-artificial", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.338Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZmaJE6RtKhKYptzPJ/link-bostrom-and-yudkowsky-the-ethics-of-artificial", "pageUrlRelative": "/posts/ZmaJE6RtKhKYptzPJ/link-bostrom-and-yudkowsky-the-ethics-of-artificial", "linkUrl": "https://www.lesswrong.com/posts/ZmaJE6RtKhKYptzPJ/link-bostrom-and-yudkowsky-the-ethics-of-artificial", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Bostrom%20%26%20Yudkowsky%2C%20%22The%20Ethics%20of%20Artificial%20Intelligence%22%20(2011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Bostrom%20%26%20Yudkowsky%2C%20%22The%20Ethics%20of%20Artificial%20Intelligence%22%20(2011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmaJE6RtKhKYptzPJ%2Flink-bostrom-and-yudkowsky-the-ethics-of-artificial%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Bostrom%20%26%20Yudkowsky%2C%20%22The%20Ethics%20of%20Artificial%20Intelligence%22%20(2011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmaJE6RtKhKYptzPJ%2Flink-bostrom-and-yudkowsky-the-ethics-of-artificial", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZmaJE6RtKhKYptzPJ%2Flink-bostrom-and-yudkowsky-the-ethics-of-artificial", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>Just noticed that Less Wrong has apparently not yet linked to Bostrom &amp; Yudkowsky's new paper for the forthcoming&nbsp;<em>Cambridge Handbook of Artificial Intelligence</em>, entitled \"<a href=\"http://www.nickbostrom.com/ethics/artificial-intelligence.pdf\">The Ethics of Artificial Intelligence</a>.\" Enjoy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZmaJE6RtKhKYptzPJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 6.841160292637941e-07, "legacy": true, "legacyId": "5964", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-27T19:21:42.734Z", "modifiedAt": null, "url": null, "title": "Baltimore?", "slug": "baltimore", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.021Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "groupuscule", "createdAt": "2009-11-16T02:54:49.400Z", "isAdmin": false, "displayName": "groupuscule"}, "userId": "KnHguEErzcfgo37dJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ngwFn9vaRmzTDLKdj/baltimore", "pageUrlRelative": "/posts/ngwFn9vaRmzTDLKdj/baltimore", "linkUrl": "https://www.lesswrong.com/posts/ngwFn9vaRmzTDLKdj/baltimore", "postedAtFormatted": "Sunday, February 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Baltimore%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABaltimore%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FngwFn9vaRmzTDLKdj%2Fbaltimore%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Baltimore%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FngwFn9vaRmzTDLKdj%2Fbaltimore", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FngwFn9vaRmzTDLKdj%2Fbaltimore", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5, "htmlBody": "<p>Anyone reading this in Baltimore?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ngwFn9vaRmzTDLKdj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 6.841422624369207e-07, "legacy": true, "legacyId": "5965", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-28T00:27:24.541Z", "modifiedAt": null, "url": null, "title": "Mistakes and Rationality", "slug": "mistakes-and-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:52.076Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cke42m67XFXuotihe/mistakes-and-rationality", "pageUrlRelative": "/posts/cke42m67XFXuotihe/mistakes-and-rationality", "linkUrl": "https://www.lesswrong.com/posts/cke42m67XFXuotihe/mistakes-and-rationality", "postedAtFormatted": "Monday, February 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mistakes%20and%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMistakes%20and%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcke42m67XFXuotihe%2Fmistakes-and-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mistakes%20and%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcke42m67XFXuotihe%2Fmistakes-and-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fcke42m67XFXuotihe%2Fmistakes-and-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 732, "htmlBody": "<p>So, like all of us, I've made numerous mistakes in my life. And I agree with the cliche belief - that I've learned numerous useful things from these mistakes. Mistakes are often a way for me to \"test my social boundaries\". And that's important, because many many potentially novel behaviors are behaviors that do test on various social boundaries, and it's important to have some intuition about where these boundaries lie, so that I can be innovative without being offensive (and also so that I can be efficient and waste as little time as possible on unnecessary social formalities).&nbsp;</p>\n<p>Furthermore, past mistakes are often a strong impetus for motivation. I've tried many strategies in the past that simply didn't work. And due to all the valuable time I wasted on them, I always am able to motivate myself by reminding myself of these past mistakes that I'm still very ashamed of (mistakes such as staring at math books for hours and hours on end, while not getting anything out of them).</p>\n<p>I've also had the nasty experience to see many of my old friendships end badly. But I've learned in those examples - I've learned how to be better to people, to not expect too much out of them, to try to be appreciative to them and to anticipate what they want, to try to care about them (if possible), and also to see through their numerous white lies. Theoretically, this could have been done if I didn't have friendships that ended badly. But it would have been harder to do without emotional destabilization, since even I am prone to psychological inertia.&nbsp;</p>\n<p>Now, is it rational to make mistakes early on? There are a few things to keep in mind:</p>\n<p>(1) Some mistakes have the potential of permanently setting us back in life. My parents, for example, often threatened to force me to get a job, which would have had the very strong potential of setting me back for life. Unfortunately, as someone with both ADD and Asperger's, I simply cannot do a job and learn at the same time, and that happened, I may never be able to go on to graduate school. I am, however, fortunate enough to have parents willing to pay my way through college. If I didn't have that option (and was in the lower classes), then yes, some of my mistakes could have forced me into a perpetual cycle of repetitive low-wage jobs effectively for life.&nbsp;</p>\n<p>And that's the key thing with mistakes. Mistakes can sometimes permanently doom your future, especially if you're in a vulnerable position. Mistakes can also result in permanent social damage, which can be devastating if you're stuck in that group and have few other alternatives.&nbsp;</p>\n<p>(2) Many people have a tendency to overreact to mistakes. Sometimes, they start becoming so overprotective against making future mistakes that they simply don't experiment as much as they used to (and open themselves to much fewer things than before), causing them to miss potentially important stimuli.&nbsp;</p>\n<p>Furthermore, if these mistakes are made in a social setting, there is often significant pressure to overreact to mistakes. Because if you don't become overprotective against future mistakes, people may believe that you're incapable of change. And that perception is a often a very dangerous perception, especially given all the disasters from history that have come from rulers who were truly incapable of change.</p>\n<p>(3) It is, of course, often best to learn from the mistakes of others. But the circumstances behind their mistakes is often not as local or as personal as the circumstances behind my mistakes. And so I've had to experience most of these mistakes myself.</p>\n<p>What are your thoughts? Is there a finely-defined optimal number of mistakes to make? (for now, I'm actually more interested in the real life implications of this than the AI implications).</p>\n<p>This would also be interesting to AI researchers too, since rational agents might also make mistakes while trying to explore \"utility space\". Some areas will have high local utility, and some areas will have high global utility. With AI, reputation and overreaction certainly matter less. But time (and other) costs still matter, and \"mistakes\" are often then cases where you spend an extended amount of time in areas of \"low local utility\", or where you get the utility function wrong, assume that the utility function is applicable in a domain where it actually isn't, or make the wrong decision.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cke42m67XFXuotihe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 3, "extendedScore": null, "score": 6.842243127666262e-07, "legacy": true, "legacyId": "5966", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-28T14:13:58.676Z", "modifiedAt": null, "url": null, "title": "Wikipedia: Moravec's Paradox", "slug": "wikipedia-moravec-s-paradox", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.896Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EvMF3jkc5MvQpDb2Y/wikipedia-moravec-s-paradox", "pageUrlRelative": "/posts/EvMF3jkc5MvQpDb2Y/wikipedia-moravec-s-paradox", "linkUrl": "https://www.lesswrong.com/posts/EvMF3jkc5MvQpDb2Y/wikipedia-moravec-s-paradox", "postedAtFormatted": "Monday, February 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wikipedia%3A%20Moravec's%20Paradox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWikipedia%3A%20Moravec's%20Paradox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEvMF3jkc5MvQpDb2Y%2Fwikipedia-moravec-s-paradox%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wikipedia%3A%20Moravec's%20Paradox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEvMF3jkc5MvQpDb2Y%2Fwikipedia-moravec-s-paradox", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEvMF3jkc5MvQpDb2Y%2Fwikipedia-moravec-s-paradox", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 112, "htmlBody": "<p><a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Moravec's_paradox\">Linky</a>. Quotes:</p>\n<blockquote>\n<p>Moravec's paradox is the discovery by artificial intelligence and robotics researchers that, contrary to traditional assumptions, high-level reasoning requires very little computation, but low-level sensorimotor skills require enormous computational resources.</p>\n<p>[...]</p>\n<ul>\n<li>We should expect the difficulty of reverse-engineering any human skill to be roughly proportional to the amount of time that skill has been evolving in animals.</li>\n<li>The oldest human skills are largely unconscious and so appear to us to be effortless.</li>\n<li>Therefore, we should expect skills that appear effortless to be difficult to reverse-engineer, but skills that require effort may not necessarily be difficult to engineer at all.</li>\n</ul>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"uCuS2DModz3eisEdv": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EvMF3jkc5MvQpDb2Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 22, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "5986", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-28T16:03:32.243Z", "modifiedAt": null, "url": null, "title": "Singularity Institute now accepts donations via Bitcoin", "slug": "singularity-institute-now-accepts-donations-via-bitcoin", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:36.673Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jLAw6dPGZCRnpNgxM/singularity-institute-now-accepts-donations-via-bitcoin", "pageUrlRelative": "/posts/jLAw6dPGZCRnpNgxM/singularity-institute-now-accepts-donations-via-bitcoin", "linkUrl": "https://www.lesswrong.com/posts/jLAw6dPGZCRnpNgxM/singularity-institute-now-accepts-donations-via-bitcoin", "postedAtFormatted": "Monday, February 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20Institute%20now%20accepts%20donations%20via%20Bitcoin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20Institute%20now%20accepts%20donations%20via%20Bitcoin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLAw6dPGZCRnpNgxM%2Fsingularity-institute-now-accepts-donations-via-bitcoin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20Institute%20now%20accepts%20donations%20via%20Bitcoin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLAw6dPGZCRnpNgxM%2Fsingularity-institute-now-accepts-donations-via-bitcoin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLAw6dPGZCRnpNgxM%2Fsingularity-institute-now-accepts-donations-via-bitcoin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>Now you can <a href=\"http://intelligence.org/donate/\">donate to Singularity Institute</a> using <a href=\"http://en.wikipedia.org/wiki/Bitcoin\">Bitcoin</a>.</p>\n<p>Currently Bitcoin mining appears to be profitable as only bubble economics can be. Already <a href=\"/r/discussion/lw/4cs/making_money_with_bitcoin/\">some Less Wrong users have purchased GPUs and started mining Bitcoin</a>. Please consider sending some Bitcoins to SI at address&nbsp;1HUrNJfVFwQkbuMXwiPxSQcpyr3ktn1wc9<br /><br />2014 Edit: Please donate Bitcoin by using the Bitpay link on <a href=\"https://intelligence.org/donate/\">MIRI's donate page</a>. Thanks!</p>\n<div class=\"box\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 14px; margin-left: 0px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #d5d5d5;\">.<a style=\"color: #3c689e; font-family: Arial, Verdana, sans-serif; font-size: 13px; line-height: 21px; text-align: left;\" name=\"affinity\"></a></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jLAw6dPGZCRnpNgxM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 6.844756818245357e-07, "legacy": true, "legacyId": "5988", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ijr8rsyvJci2edxot"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-02-28T21:35:11.824Z", "modifiedAt": null, "url": null, "title": "Cryptography", "slug": "cryptography", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:51.658Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BKPQtL6yrhaGXZp4e/cryptography", "pageUrlRelative": "/posts/BKPQtL6yrhaGXZp4e/cryptography", "linkUrl": "https://www.lesswrong.com/posts/BKPQtL6yrhaGXZp4e/cryptography", "postedAtFormatted": "Monday, February 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryptography&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryptography%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKPQtL6yrhaGXZp4e%2Fcryptography%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryptography%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKPQtL6yrhaGXZp4e%2Fcryptography", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBKPQtL6yrhaGXZp4e%2Fcryptography", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 377, "htmlBody": "<p>Breaking encrypted messages offers a unique challenge, at least in its pure form. In most cryptography puzzles, the method of encryption is known, and so the challenge is finding the key. The most common form of encryption used for this is a simple substitution cipher. This is not a very difficult challenge. Depending on the puzzle, it can be tough, but it isn't something that will really strain your intellect to its maximum.</p>\n<p>True cryptography occurs when you just get a message, and no other information. Then, the codebreaker has to find a way to determine the type of code, and then they have to find the key. This type of challenge is good for a rationalist, since you have to make sense of something confusing by running experimental tests, usually by analyzing the text. I've always found codebreaking in this sense to be very enjoyable and useful for training your mind. The main obstacle to doing so is the lack of any system designed for it. There is no website (that I know of) that provides this sort of cryptography challenge. Typically, if you want to do this, you have to find other people who also have an interest in it.</p>\n<p>It occurred to me that people on Less Wrong might have an interest in doing something of this nature. Now, obviously, we probably won't be trying to break RSA ciphers, but there are a bunch of methods of encryption that were developed over the years before the invention of computer cryptography that could be used, without us requiring any participants to know how to program computers or do anything like that.</p>\n<p>Is there any interest in something like this? I personally don't care how much you know already about cryptography. If you don't know anything I'd be happy to give you some book recommendations.</p>\n<p>&nbsp;</p>\n<p>PS There is a difference between \"cipher\" and \"code\", but in practical language the two are sometimes interchangeable. For instance, \"codebreaker\" vs \"cipherbreaker\" isn't often a very important distinction to make, so I used the more common term. As long as the correct message gets across, you can use either term. Just make sure, if you are saying something that is specific to one particular type of encryption that you use the right vocabulary then.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BKPQtL6yrhaGXZp4e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 6.845647782860653e-07, "legacy": true, "legacyId": "5989", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-01T01:08:28.566Z", "modifiedAt": null, "url": null, "title": "Experimental evidence of the value of redundant oral tradition", "slug": "experimental-evidence-of-the-value-of-redundant-oral", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:35.590Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iCHwpibpmeZrJa8m6/experimental-evidence-of-the-value-of-redundant-oral", "pageUrlRelative": "/posts/iCHwpibpmeZrJa8m6/experimental-evidence-of-the-value-of-redundant-oral", "linkUrl": "https://www.lesswrong.com/posts/iCHwpibpmeZrJa8m6/experimental-evidence-of-the-value-of-redundant-oral", "postedAtFormatted": "Tuesday, March 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experimental%20evidence%20of%20the%20value%20of%20redundant%20oral%20tradition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperimental%20evidence%20of%20the%20value%20of%20redundant%20oral%20tradition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiCHwpibpmeZrJa8m6%2Fexperimental-evidence-of-the-value-of-redundant-oral%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experimental%20evidence%20of%20the%20value%20of%20redundant%20oral%20tradition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiCHwpibpmeZrJa8m6%2Fexperimental-evidence-of-the-value-of-redundant-oral", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiCHwpibpmeZrJa8m6%2Fexperimental-evidence-of-the-value-of-redundant-oral", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>Something I've been hearing a lot lately (specifically from Orthodox Jews, although it comes up a lot in debates about religion) is that having a large number of people telling a story makes it more likely the story is true, because multiple witnesses can call each other out for deviating from the truth.</p>\n<p>My gut reaction is that this is extremely false. But it's a point that should be scientifically testable, and I figure that someone should have done a study on it by now. Does anyone know of such a thing?</p>\n<p>A related issue is the argument that oral tradition meant something very different thousands of years ago, when it was the ONLY form of historical record. Oral historians were duty-bound to preserve the story. This sounds plausible. It probably ISN'T as easily testable since we can't compare oral history from pre-writing times against... well, much of anything. (Well, I guess archaeological evidence, if the events being described would have left enough archaeological evidence). Is there an official, accepted scholarly opinion on this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iCHwpibpmeZrJa8m6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 6.846220840227469e-07, "legacy": true, "legacyId": "5990", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-01T03:59:56.160Z", "modifiedAt": null, "url": null, "title": "Are Interesting Problems Useful?", "slug": "are-interesting-problems-useful", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:56.187Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m3DDuXvqfTZSWXTLo/are-interesting-problems-useful", "pageUrlRelative": "/posts/m3DDuXvqfTZSWXTLo/are-interesting-problems-useful", "linkUrl": "https://www.lesswrong.com/posts/m3DDuXvqfTZSWXTLo/are-interesting-problems-useful", "postedAtFormatted": "Tuesday, March 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20Interesting%20Problems%20Useful%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20Interesting%20Problems%20Useful%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3DDuXvqfTZSWXTLo%2Fare-interesting-problems-useful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20Interesting%20Problems%20Useful%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3DDuXvqfTZSWXTLo%2Fare-interesting-problems-useful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3DDuXvqfTZSWXTLo%2Fare-interesting-problems-useful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 524, "htmlBody": "<p>In a <a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/\">recent post</a> I posed the question: is the common good served by directing research efforts towards theoretical problems which are interesting to researchers? <br /><br />komponisto <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/3lbl\">defends interesting problems</a>, arguing that researcher's perceptions of interestingness are often better able to predict future usefulness than anyone trying deliberately to determine what will be useful. This is a plausible claim (although I disagree), and I have encountered it a number of times in the last couple of days. This claim was advanced as a defense of the status quo, but if we really believe it then we should certainly try and understand all of its consequences. <br /><br />When setting out to predict the usefulness of a research program (as I suggest we should), we are not required to do it via deductive arguments which estimate the likelihood of certain applications. We can use all of the data available, including how interesting the problem seems---to us, to other researchers, to lay people, etc. If intelligent observers' notions of interestingness are substantially corellated with future usefulness, potentially in unpredictable ways, then we would be wise to take this information into account. This is precisely what komponisto and others argue, and they conclude that we should support work on the problems an investigator finds most interesting. I claim this is an example of motivated stopping: the argument was thought through just far enough to support changing nothing. <br /><br />We have access to many, many indicators of interestingness for any candidate research problem. A problem can seem interesting only to a single person who understands the background in great depth; it can seem interesting to a small group of researchers in related fields; it can seem interesting to mathematicians broadly; it can seem interesting to computer scientists, to physicists, to biologists, to engineers, to laypeople. It can seem particularly interesting to professional mathematicians, or to novices with new ideas. It can invoke feelings of immediacy, of needing to know the answer; it can simply be fun to work on. Particular countries or cultures or time periods or subfields may have objectively better or worse aesthetics. <br /><br />If our aim is to use interestingness as a predictor of potential usefulness then all of this variability is an asset. We have a historical record to be scoured; patterns to be evaluated. Understanding these patterns is of critical importance to the quality of our predictions and the efficiency of our research institutions. If the historical record is too opaque, we should at least establish a culture of transparency: make records not only of what work is done, but why it is done. Who did it seem interesting to? How did they feel about the research program; why were they really working on it? In the long term, we can hope to discover whose intuitions were valuable and whose were not; we can understand which aesthetics lead to useful work and which do not.</p>\n<p>Over time (if not immediately), we can hope to develop a common understanding of the link between interestingness and future usefulness, and develop institutions which exploit this understanding to produce valuable research.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m3DDuXvqfTZSWXTLo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 22, "extendedScore": null, "score": 6.846681595563125e-07, "legacy": true, "legacyId": "5993", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["s5sy3qiknFs7ehsLA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-01T04:53:15.233Z", "modifiedAt": null, "url": null, "title": "Eliezer Yudkowsky and Michael Vassar at NYU, Thursday March 3rd", "slug": "eliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:30.729Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cosmos", "createdAt": "2009-04-26T03:18:01.731Z", "isAdmin": false, "displayName": "Cosmos"}, "userId": "c3Ji9Th6jATRyHLFC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w7ozrkxRsXF9DEreq/eliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "pageUrlRelative": "/posts/w7ozrkxRsXF9DEreq/eliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "linkUrl": "https://www.lesswrong.com/posts/w7ozrkxRsXF9DEreq/eliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "postedAtFormatted": "Tuesday, March 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eliezer%20Yudkowsky%20and%20Michael%20Vassar%20at%20NYU%2C%20Thursday%20March%203rd&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEliezer%20Yudkowsky%20and%20Michael%20Vassar%20at%20NYU%2C%20Thursday%20March%203rd%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7ozrkxRsXF9DEreq%2Feliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eliezer%20Yudkowsky%20and%20Michael%20Vassar%20at%20NYU%2C%20Thursday%20March%203rd%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7ozrkxRsXF9DEreq%2Feliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7ozrkxRsXF9DEreq%2Feliezer-yudkowsky-and-michael-vassar-at-nyu-thursday-march", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<p>Eliezer Yudkowsky and Michael Vassar are going to be speaking at NYU this Thursday, March 3rd, on the subject of SIAI and rationality.&nbsp; Any readers in the NYC area are encouraged to attend.</p>\n<p>Details:</p>\n<p>6-8 PM<br />Vanderbilt Hall, Room 220<br />40 Washington Square South</p>\n<p>Food and drink will be provided.&nbsp; There will be a small reception at a nearby bar at the conclusion of the talk as well.</p>\n<p>Even if you don't live here yourself, you can still show support by inviting anyone you know in the NYC area via the <a href=\"http://www.facebook.com/event.php?eid=198341196860178\">Facebook event</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w7ozrkxRsXF9DEreq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 6.846824885120717e-07, "legacy": true, "legacyId": "5994", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T06:24:36.149Z", "modifiedAt": null, "url": null, "title": "Revisiting Psy-Kosh's Non-Anthropic Decision Problem", "slug": "revisiting-psy-kosh-s-non-anthropic-decision-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:52.275Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s8Nkbt5MgvKT6WiQZ/revisiting-psy-kosh-s-non-anthropic-decision-problem", "pageUrlRelative": "/posts/s8Nkbt5MgvKT6WiQZ/revisiting-psy-kosh-s-non-anthropic-decision-problem", "linkUrl": "https://www.lesswrong.com/posts/s8Nkbt5MgvKT6WiQZ/revisiting-psy-kosh-s-non-anthropic-decision-problem", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Revisiting%20Psy-Kosh's%20Non-Anthropic%20Decision%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARevisiting%20Psy-Kosh's%20Non-Anthropic%20Decision%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs8Nkbt5MgvKT6WiQZ%2Frevisiting-psy-kosh-s-non-anthropic-decision-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Revisiting%20Psy-Kosh's%20Non-Anthropic%20Decision%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs8Nkbt5MgvKT6WiQZ%2Frevisiting-psy-kosh-s-non-anthropic-decision-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs8Nkbt5MgvKT6WiQZ%2Frevisiting-psy-kosh-s-non-anthropic-decision-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 665, "htmlBody": "<p>Previous formulation <a href=\"/lw/3dy/has_anyone_solved_psykoshs_nonanthropic_problem/\">here</a>. (There's a link to the original formulation from there.)</p>\n<p>I showed a related problem to someone and got back the objection \"well, that's a coordination problem- you need game theory to model the other players, and so you can't simply declare a strategy correct.\" At first I thought that was an evasion, and so reformulated it so you make all the decisions. It seems to me that this problem is isomorphic to the previous formulation, except switching from nay to yay is more clearly ridiculous (if you disagree, I'd like to hear it!). Here it is:<a id=\"more\"></a></p>\n<p>To simplify calculations, assume you are risk-neutral with regards to dollars at this scale. You provide me a byte of 8 bits, all zeros or ones. I flip a fair coin: if it lands heads, I select one bit from the byte you provided me uniformly at random; if it lands tails, I select seven bits from the byte you provided me uniformly at random.</p>\n<p>If all bits selected are 0s, I pay you $21. For every selected bit that is a 1, I pay you $4.</p>\n<p>You do some byte-level calculations before I flip the coin, and decide that the byte 00000000 is best, because it has an expected value of $21/2+$21/2=$21. The coin is flipped, and then without telling you the flip I give you the option to flip every bit that I will select (or you imagine this, and submit the opposite byte instead). Bit-level reasoning suggests you should flip all bits, as each bit impacts the total result in 8/16 cases, and in seven of those cases the coin came up tails. 7/8*$28+1/8*$4=$25&gt;$21. Byte-level reasoning suggests you shouldn't flip all the bits, because the byte 11111111 has an expected value of $4/2+$28/2=$16&lt;$21. This is the conflict in the formulation linked above- before you know you're a decider, you think \"nay\" is superior,but once you know you're a decider, you calculate that \"yay\" is superior.</p>\n<p>But this still has a coordination problem- the $21 payoff requires every bit to be a 0. What happens when we get rid of that?</p>\n<p>Now, if I get heads, I pay out $21 for a 0 and $4 for a 1. If I get tails, I pay out $3 for each 0 and $4 for each one. E[00000000]=21, E[11111111]=16 (as before), but now E[0]=21*1/8+3*7/8=5.25 and E[1]=4*1/8+4*7/8=4. Now, by precisely the same amount as the byte-level analysis, <strong>E[0]&gt;E[1]!</strong> Indeed, this appears to be general.<sup>1</sup></p>\n<p>Is there a way to formulate an Uncoordinated Psy-Kosh's Non-Anthropic Decision Problem? (UPKNADP for short.) Or is the wrinkle in it solely that the individual analysis stumbles when it comes to dealing with coordinated action? Note the issue isn't modeling other players- you're making the moves for all players in the game, and can model yourself perfectly. The issue is how you count the rewards associated with coordinated action.</p>\n<p>&nbsp;</p>\n<hr />\n<p>1.You provide me with <em>n</em> bits. I flip a fair coin: if it lands heads, I select one bit uniformly at random and pay out <em>a</em> for every 0; if it lands tails, I select <em>n</em>-1 bits uniformly at random and pay out <em>b</em>/<em>n</em>-1 for every 1. I can always add or subtract a constant amount to each prospect without changing the strategy for a risk-neutral player, meaning I can simplify the payout matrix down to just <em>a</em> and <em>b</em>.</p>\n<p>The byte-level<sup>2</sup> calculations suggest that E[<em>n </em>0s]=<em>a</em>*1/2+(<em>n</em>-1)*0*1/2=<em>a</em>/2 and E[<em>n </em>1s]=0*1/2+(<em>n</em>-1)<em>b</em>/2(<em>n</em>-1)=<em>b</em>/2. Your best strategy is to pick 0s if <em>a</em>&gt;<em>b</em> and 1s if <em>b</em>&gt;<em>a</em> (and you're indifferent if they're the same).</p>\n<p>The bit-level calculations suggest that E[0s]=<em>a</em>*1/n+0*(<em>n</em>-1)/n=<em>a</em>/<em>n</em>. E[1s]=0/<em>n</em>+<em>b</em>/(<em>n</em>-1)*(<em>n</em>-1)/<em>n</em>=<em>b</em>/<em>n</em>. Again, the payoff ratio is the exact same- you should pick 0s if <em>a</em>&gt;<em>b</em> and 1s if <em>b</em>&gt;<em>a</em> (and you're indifferent if they're the same).</p>\n<p>The byte-level and bit-level calculations agree, for all values of <em>a</em> and <em>b</em> and all <em>n</em>&gt;1.</p>\n<p>2. I suppose I shouldn't use \"byte\" to refer to a set of <em>n</em> bits, but I'd rather have my cake and eat it too by both using byte and having a general set of <em>n</em> bits.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s8Nkbt5MgvKT6WiQZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 6.850942586524892e-07, "legacy": true, "legacyId": "6004", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YZzoWGCJsoRBBbmQg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T09:53:26.298Z", "modifiedAt": null, "url": null, "title": "[LINK] John Baez Interview with astrophysicist Gregory Benford ", "slug": "link-john-baez-interview-with-astrophysicist-gregory-benford", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:04.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "multifoliaterose", "createdAt": "2010-06-13T08:56:10.885Z", "isAdmin": false, "displayName": "multifoliaterose"}, "userId": "747HfTZFyfTqGyoPM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8wbH8GPFhB9M9HAHw/link-john-baez-interview-with-astrophysicist-gregory-benford", "pageUrlRelative": "/posts/8wbH8GPFhB9M9HAHw/link-john-baez-interview-with-astrophysicist-gregory-benford", "linkUrl": "https://www.lesswrong.com/posts/8wbH8GPFhB9M9HAHw/link-john-baez-interview-with-astrophysicist-gregory-benford", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20John%20Baez%20Interview%20with%20astrophysicist%20Gregory%20Benford%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20John%20Baez%20Interview%20with%20astrophysicist%20Gregory%20Benford%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wbH8GPFhB9M9HAHw%2Flink-john-baez-interview-with-astrophysicist-gregory-benford%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20John%20Baez%20Interview%20with%20astrophysicist%20Gregory%20Benford%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wbH8GPFhB9M9HAHw%2Flink-john-baez-interview-with-astrophysicist-gregory-benford", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wbH8GPFhB9M9HAHw%2Flink-john-baez-interview-with-astrophysicist-gregory-benford", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>The content of John Baez's <a href=\"http://johncarlosbaez.wordpress.com/2011/02/28/this-weeks-finds-week-310/\">This Week's Finds: Week 310</a>:</p>\n<p>Includes</p>\n<ul>\n<li>Discussion of global warming and geoengineering.</li>\n<li>A reference to a paper by David Wolpert and Gregory Benford on Newcomb's paradox</li>\n</ul>\n<p>Note: The upcoming <strong>This Week's Finds: Week 311</strong> is an interview with Eliezer Yudkowsky by John Baez.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8wbH8GPFhB9M9HAHw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 6.851501838792747e-07, "legacy": true, "legacyId": "6019", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T09:53:32.353Z", "modifiedAt": null, "url": null, "title": "Hong Kong LW meetup", "slug": "hong-kong-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:37.355Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Isaac", "createdAt": "2010-12-16T15:48:23.606Z", "isAdmin": false, "displayName": "Isaac"}, "userId": "RyqSofZtS2dMzuJN6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x3H8c6ak3p3g4qS7f/hong-kong-lw-meetup", "pageUrlRelative": "/posts/x3H8c6ak3p3g4qS7f/hong-kong-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/x3H8c6ak3p3g4qS7f/hong-kong-lw-meetup", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hong%20Kong%20LW%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHong%20Kong%20LW%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx3H8c6ak3p3g4qS7f%2Fhong-kong-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hong%20Kong%20LW%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx3H8c6ak3p3g4qS7f%2Fhong-kong-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx3H8c6ak3p3g4qS7f%2Fhong-kong-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 141, "htmlBody": "<p>Any LW readers in Asia's world city interested in a meetup?&nbsp;I have a hunch that there might be more of us that the <a href=\"/r/discussion/lw/43s/starting_a_lw_meetup_is_easy/3gbz\">statistics</a> suggest, possibly due to some of us showing up in the analytics as being based in Kowloon, not Hong Kong. At any rate, I'd be surprised if we couldn't find enough people for a decent gathering, HK being such a wired and technophilic place.</p>\n<p>Date: Saturday 12th March, 6:00 pm.</p>\n<p>Place: 168 Future Bar, Mong Kok</p>\n<p>Reading <a href=\"/lw/43s/starting_a_lw_meetup_is_easy/\">Starting a LW Meetup is Easy</a>&nbsp;inspired me to try and get this moving. Remember, you don't need to be an active contributor to the site to come along and meet like-minded people (I personally don't post or comment very often, though I do lurk a lot). Don't be shy, if you're at all interested please reply so we can get the ball rolling!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DQHWBcKeiLnyh9za9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x3H8c6ak3p3g4qS7f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 31, "extendedScore": null, "score": 6.851504743063438e-07, "legacy": true, "legacyId": "5987", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T11:14:22.319Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes: March 2011", "slug": "rationality-quotes-march-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:38.927Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xEtZ2QAz5p9kuBwrh/rationality-quotes-march-2011", "pageUrlRelative": "/posts/xEtZ2QAz5p9kuBwrh/rationality-quotes-march-2011", "linkUrl": "https://www.lesswrong.com/posts/xEtZ2QAz5p9kuBwrh/rationality-quotes-march-2011", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%3A%20March%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%3A%20March%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEtZ2QAz5p9kuBwrh%2Frationality-quotes-march-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%3A%20March%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEtZ2QAz5p9kuBwrh%2Frationality-quotes-march-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxEtZ2QAz5p9kuBwrh%2Frationality-quotes-march-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<div><a id=\"more\"></a></div>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; list-style-type: disc; list-style-position: outside; list-style-image: initial; \">\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp; (If they are strongly related, reply to your own comments.&nbsp; If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xEtZ2QAz5p9kuBwrh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 6.85171961589522e-07, "legacy": true, "legacyId": "6020", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 392, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T20:09:47.330Z", "modifiedAt": null, "url": null, "title": "What Else Would I Do To Make a Living?", "slug": "what-else-would-i-do-to-make-a-living", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:56.907Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "magfrump", "createdAt": "2009-12-10T20:51:45.065Z", "isAdmin": false, "displayName": "magfrump"}, "userId": "KsYFs5ip5jeiFETJa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CAuEkL8cexStSWBMx/what-else-would-i-do-to-make-a-living", "pageUrlRelative": "/posts/CAuEkL8cexStSWBMx/what-else-would-i-do-to-make-a-living", "linkUrl": "https://www.lesswrong.com/posts/CAuEkL8cexStSWBMx/what-else-would-i-do-to-make-a-living", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20Else%20Would%20I%20Do%20To%20Make%20a%20Living%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20Else%20Would%20I%20Do%20To%20Make%20a%20Living%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCAuEkL8cexStSWBMx%2Fwhat-else-would-i-do-to-make-a-living%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20Else%20Would%20I%20Do%20To%20Make%20a%20Living%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCAuEkL8cexStSWBMx%2Fwhat-else-would-i-do-to-make-a-living", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCAuEkL8cexStSWBMx%2Fwhat-else-would-i-do-to-make-a-living", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 328, "htmlBody": "<p>Response to: <a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/\">The Value of Theoretical Research</a></p>\n<p>&nbsp;</p>\n<p>Reading paulfchristiano's article the other day, I realized that I had had many similar discussions with myself, and have been guilty of motivated stopping and poor answers to all of them.</p>\n<p>However, one major roadblock in my pursuing better answers, is that I feel that I have been \"locked in\" to my current path.</p>\n<p>I am currently a mathematics Ph.D. student.&nbsp; I did not have a minor.&nbsp; I don't have significant programming skills or employment experience.&nbsp; I know nothing about finance.&nbsp; I know a lot about mathematics.</p>\n<p>&nbsp;</p>\n<p>Paul says:</p>\n<blockquote>\n<p>There is a shortage of intelligent, rational people in pretty much every area of human activity. I would go so far as to claim this is the limiting input for most fields.</p>\n</blockquote>\n<p>However, \"<a href=\"/lw/vs/selling_nonapples/\">most fields</a>\" is not a very good tool for narrowing my search space; I have spent my entire life in school, and I like having structures and schedules that tell me when I'm doing productive things and that I've progressed to certain stages.&nbsp; I'm not ready to drop out and do whatever, and I don't have a particular idea of what whatever might be.</p>\n<p>&nbsp;</p>\n<p>On the other hand, I currently have a variety of resources available to me.&nbsp; For example, I have a steady income (a grad student stipend isn't much, but it's plenty for me to live on), and I have the ability to take undergraduate classes for free (though not the spare time at the moment.)</p>\n<p>My current intent is to continue and finish my Ph.D., but to attempt to take classes in other subjects, such as linguistics, biology and chemistry, and computer science which might lead to other interesting career paths.</p>\n<p>&nbsp;</p>\n<p>Has anybody else had a similar feeling of being \"locked in\"?&nbsp; How have you responded to it?&nbsp; For those who have studied mathematics, are you still?&nbsp; If you continued, what helped you make that decision?&nbsp; If you stopped, what about that?&nbsp; What did you end up doing?&nbsp; How did you decide on it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4kQXps8dYsKJgaayN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CAuEkL8cexStSWBMx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 22, "extendedScore": null, "score": 4.3e-05, "legacy": true, "legacyId": "6021", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["s5sy3qiknFs7ehsLA", "2mLZiWxWKZyaRgcn7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T21:12:37.464Z", "modifiedAt": null, "url": null, "title": "Are You a Paralyzed Subordinate Monkey?", "slug": "are-you-a-paralyzed-subordinate-monkey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:25.505Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fYnDb8u5ZtFpCSzLb/are-you-a-paralyzed-subordinate-monkey", "pageUrlRelative": "/posts/fYnDb8u5ZtFpCSzLb/are-you-a-paralyzed-subordinate-monkey", "linkUrl": "https://www.lesswrong.com/posts/fYnDb8u5ZtFpCSzLb/are-you-a-paralyzed-subordinate-monkey", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20You%20a%20Paralyzed%20Subordinate%20Monkey%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20You%20a%20Paralyzed%20Subordinate%20Monkey%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfYnDb8u5ZtFpCSzLb%2Fare-you-a-paralyzed-subordinate-monkey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20You%20a%20Paralyzed%20Subordinate%20Monkey%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfYnDb8u5ZtFpCSzLb%2Fare-you-a-paralyzed-subordinate-monkey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfYnDb8u5ZtFpCSzLb%2Fare-you-a-paralyzed-subordinate-monkey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<p>During a discussion today about the bizarre \"can't get crap done\" phenomenon that afflicts large fractions of our community, the suggestion came up that <em>most </em>people can't do anything where there is a perceived choice that includes the null option / \"do nothing\" as an option.&nbsp; Of which Michael Vassar made the following observation:</p>\n<blockquote>\n<p>In a monkey tribe, there's no verbal communication - they can't discuss where to go using language.&nbsp; So if you get up and start going <em>anywhere</em>, you must be the leader.</p>\n</blockquote>\n<p>And if you're not the leader, it is not good for your reproductive fitness to act like one.&nbsp; In modern times the penalties for standing up are <em>much </em>lower, but our instincts haven't updated.</p>\n<p>Interesting to reconsider the events of \"<a href=\"/lw/mc/to_lead_you_must_stand_up\">To lead, you must stand up</a>\" in this light.&nbsp; It makes more sense if you read it as \"None of those people had instincts saying it was a good idea to declare themselves the leader of the monkey tribe, in order to solve this particular coordination problem where 'do nothing' felt like a viable option\" instead of \"nobody had the initiative\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "GDGYkF29pxEQNWjYc": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fYnDb8u5ZtFpCSzLb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 42, "extendedScore": null, "score": 0.0001, "legacy": true, "legacyId": "6022", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["n5oCEbnW2PgFmkQhr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-02T23:29:54.260Z", "modifiedAt": null, "url": null, "title": "Testing Intelligence", "slug": "testing-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:52.821Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YskWKut59WPP2Lu8z/testing-intelligence", "pageUrlRelative": "/posts/YskWKut59WPP2Lu8z/testing-intelligence", "linkUrl": "https://www.lesswrong.com/posts/YskWKut59WPP2Lu8z/testing-intelligence", "postedAtFormatted": "Wednesday, March 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Testing%20Intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATesting%20Intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYskWKut59WPP2Lu8z%2Ftesting-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Testing%20Intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYskWKut59WPP2Lu8z%2Ftesting-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYskWKut59WPP2Lu8z%2Ftesting-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 606, "htmlBody": "<p>In my model of human behavior, there is an unobservable parameter I associate with <em>intelligence</em>. I observe people's behavior when playing a game, when solving a problem, when defending their beliefs, or when learning something new, and I infer something about their intelligence. This in turn informs my predictions about their success in a wide variety of pursuits. In practice, I often make strong predictions about someone's intelligence after observing their behavior on a single occasion.</p>\n<p>An accurate conception of intelligence seems to be generally important. Understanding what easily leveraged factors affect someone's intelligence---during childhood, later education, and after formal education is complete---is important if your goal is improving intelligence generally. If you are considering relatively expensive personal engagement to develop rationality, you may want to direct efforts at individuals who have the potential to have a significant impact as researchers or entrepreneurs. And so on.</p>\n<p>Before thinking about how to understand determiners of intelligence, how to measure intelligence effectively, or the effects of intelligence on behavior, I would first like to get a feel for what my intuitive understanding of intelligence really corresponds to, if anything. It is possible that my intuitive assessments of intelligence are largely unrelated to reality, and that my beliefs about the world could be improved by discarding them. It is also possible that some of my intuitions about intelligence are quite accurate, and I could make better decisions by giving them more credence or by changing the way I use those intuitive judgments.</p>\n<p>Intuitively, I expect the results of many types of otherwise apparently unrelated tests to be very tightly correlated with intelligence. To understand the extent to which this intuition is correct, I am considering conducting a slightly systematic study of the relationship between different metrics.&nbsp; I would appreciate pointers to reliable scholarship surrounding this question, but a brief search turned up mostly very muddled thinking and a general lack of people doing good experiments.</p>\n<p>Here is a range of metrics which I suspect correlate well with my conception of intelligence, at least in certain regimes (some of these metrics may only correlate meaningfully when applied to very bright subjects, or may not correlate meaningfully when applied to very bright subjects):</p>\n<p>1. General intelligence factor as estimated by standardized cognitive tests, e.g. Raven's Progressive Matrices.</p>\n<p>2. Ability to quickly learn an unfamiliar formalism. For example, to quickly learn a new game and to understand simple strategic consequences of its rules.</p>\n<p>3. Ability to infer an underlying model. For example, to learn how to achieve a goal when allowed some constrained interaction with / observation of an unknown environment.</p>\n<p>4. My assessment of intelligence during collaboration or discussion of a complex but rigorously defined topic; or, the assessment of anyone who I consider to be intelligent.</p>\n<p>5. Ability to solve hard problems in a well-understood environment, potentially given hours or days. For example, performance in high school olympiads.</p>\n<p>My hope is that by gaining a better understanding of the relationship between these metrics I may learn to what extent my current rather monolithic conception of intelligence is valid and, to whatever extent it is, how to effectively measure it. Ultimately I would like to understand what easy measurements are the best indicators of success at various particular pursuits, but is even more extraordinarily difficult to acquire data about how good someone is at, say, choosing good research problems.</p>\n<p>What do readers expect the results of inquiry to look like? Is my choice of metrics influenced unduly by my own experience? What are other metrics I should be considering but am not? Is improving a student's ability to perform any of these tasks likely to have a positive influence on other tasks?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YskWKut59WPP2Lu8z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 6.853702008498713e-07, "legacy": true, "legacyId": "6023", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-03T01:51:38.645Z", "modifiedAt": null, "url": null, "title": "Go Try Things", "slug": "go-try-things-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:52.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ADaZaEsmJMnKKhRqS/go-try-things-0", "pageUrlRelative": "/posts/ADaZaEsmJMnKKhRqS/go-try-things-0", "linkUrl": "https://www.lesswrong.com/posts/ADaZaEsmJMnKKhRqS/go-try-things-0", "postedAtFormatted": "Thursday, March 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Go%20Try%20Things&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGo%20Try%20Things%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADaZaEsmJMnKKhRqS%2Fgo-try-things-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Go%20Try%20Things%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADaZaEsmJMnKKhRqS%2Fgo-try-things-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FADaZaEsmJMnKKhRqS%2Fgo-try-things-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1142, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This is the first in what will hopefully be a series of posts about why you should try things, and with strategies against common reasons for not doing so.</p>\n<p class=\"MsoNormal\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><strong style=\"mso-bidi-font-weight: normal;\">Overview:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">You&rsquo;ve probably read about how to properly turn information into beliefs, and how to squeeze every last bit from your data. There's been less attention on the importance of going and getting data.<br /> <br /> This article is about how personal experience is an incredibly useful form of data, and in particular how in many activities going out and trying something is more marginally useful than doing more exploratory research into it. In particular, I'll examine how personal experience is useful because it makes information more tangible and easier to learn, is good practice, and exposes common circumstances that you didn't build your models to handle.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">For precise and well-defined fields and problems, clear thinking and reasoning will get you really far. Mathematics departments don&rsquo;t use that much equipment, and they&rsquo;ve been going on pretty well for hundreds of years.<br /> <br /> Rationality is about how to turn data into maps. But this still requires data. I think that in a wide variety of not particularly theoretical subjects (like sports, social interactions, negotiation, cooking, etc.) rationality needs to be augmented by personal experience. Instrumental Rationality turns models into high-utility actions, but before you can do that you need a model.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\">Tangibility:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Personal experience is useful in fields where there are certain building blocks which are treated as conceptual atoms when thinking consciously about it, but where said building blocks are hard to acquire without experience. In these fields, experience is needed before advice can be particularly useful.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">One thing about these kinds of fields is that your brain has a lot of circuitry built in for dealing with things related to them. Sports involve muscle memory and your kinesthetic sense. Social interactions involve a lot of non-verbal cues that your brain is optimized to handle. If you&rsquo;re unaware of these basic concerns, then further progression is difficult. You can give the best explanation in the world, but if you missed that the other person didn&rsquo;t understand your first assertion then it doesn&rsquo;t matter.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">The best way that I&rsquo;ve found for me to be able to recognize and learn things like that is for me to go out and experience them. Consider the difference between a smile and a smirk. Language is terrible at communicating the difference, but your brain has a high bandwidth way of gathering data about them by experiencing it.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">People can definitely communicate about these topics, but they often assume a comprehension of the basic words used to describe them, and gloss over the subtleties. Was that an &ldquo;I feel uncomfortable&rdquo; laugh, or an &ldquo;I&rsquo;m becoming comfortable&rdquo; one? If you can&rsquo;t tell the difference between these things, then you&rsquo;re in for some trouble. When someone in soccer tells you to go down the side and then pass the ball to the center, you&rsquo;re going to fail if you don&rsquo;t know how to dribble, pass, or deal with defenders.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\">Practice:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Practice is important. As any akrasiatic or novice would know, knowledge in a field or domain doesn&rsquo;t translate directly to success in it. In muscle memory, you need practice in order to get your brain to incorporate what you know to the point that you can use it automatically. Consciously thinking about what you&rsquo;re doing while you&rsquo;re doing it tends to cause lag and awkwardness, and in some fields (like conversation or physical activities) is a pretty large detriment.<br /> <br /> This is even true in fields like math. When someone walks you through a math problem or proof and explains what&rsquo;s going on and what tools are being used when and why, it&rsquo;s a lot easier to understand. And you might totally understand it when the person is walking you through, but then flounder if given a similar problem without their supervision. Without practice, you don&rsquo;t know what needs to be applied when, and actually acting on your knowledge is made much more difficult.<br /> <br /> For me, the most obvious example of this comes from learning how to write. A teacher would recommend a particular technique or device, like appositive phrases, and then I would notice them everywhere. And then I&rsquo;d overuse them. And then I&rsquo;d sound silly, or just wind up with a bunch of really long sentences in a row. I needed practice before I could make better judgments about where they should and shouldn&rsquo;t be used, rather than indiscriminately apply them everywhere.<sup>1</sup></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\">Pointing out Problems:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">One of your strengths as a rationalist is to be able to learn from your data. Theorizing helps you turn data into strategies. Experience is very salient data. When you combine the two, you can become incredibly responsive.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">When you try something, you can see how your map works in practice. When you encounter a setback, you can find an inaccuracy in your map, or just a region of the territory that you didn't cover. As a rationalist, you can better understand and use this information to improve.</p>\n</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Trying something out is vital to noticing that there are things for which your model does not account, but are important. One of the easiest ways to find out if you&rsquo;re forgetting something important is to try and see what goes wrong. Anything that consistently causes problems is by definition important. This can settle a lot of arguments.<br /> <br /> One of the times the importance of this rang most true for me was during a robotics competition in <a href=\"http://www.youtube.com/watch?v=IEHAj3EmpMw\">this game</a>.&nbsp;We had built a vacuum for our robot to allow it to hold balls while aiming and maneuvering. When competition came, two major problems made themselves obvious. The first was that we couldn&rsquo;t see the balls from where the drivers drove, and the second was that the vacuum head was incredibly delicate to small deviations in position (which could be caused by pushing a ball against a wall), and would be rendered inoperable almost every game. Both of these issues would have been obvious had we tried playing under game conditions beforehand, but our &ldquo;tests&rdquo; (holding the vacuum to a soccer ball and observing that we could then lift the ball with the vacuum, and trying to place a ball on the vacuum while it was mounted to a stationary robot) obscured several very important and relevant details.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">It didn&rsquo;t take very long to fix these problems for our second competition, and doing so made our robot dramatically more effective. Had we tested out for real beforehand, we could have been awesome from day one.<br /> <br /> [1] A slight caveat was that I still needed to use them a lot before I was able to learn where I shouldn&rsquo;t use them.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Thanks to everyone who gave me feedback on the previous incarnation of this article, it was helpful and very motivating.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7thPfS2WbD2JKizr7": 2, "hrezrpGqXXdSe76ks": 2, "WSZifR5rmzZCwbPNJ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ADaZaEsmJMnKKhRqS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "5963", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p class=\"MsoNormal\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This is the first in what will hopefully be a series of posts about why you should try things, and with strategies against common reasons for not doing so.</p>\n<p class=\"MsoNormal\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><strong style=\"mso-bidi-font-weight: normal;\" id=\"Overview_\">Overview:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">You\u2019ve probably read about how to properly turn information into beliefs, and how to squeeze every last bit from your data. There's been less attention on the importance of going and getting data.<br> <br> This article is about how personal experience is an incredibly useful form of data, and in particular how in many activities going out and trying something is more marginally useful than doing more exploratory research into it. In particular, I'll examine how personal experience is useful because it makes information more tangible and easier to learn, is good practice, and exposes common circumstances that you didn't build your models to handle.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">For precise and well-defined fields and problems, clear thinking and reasoning will get you really far. Mathematics departments don\u2019t use that much equipment, and they\u2019ve been going on pretty well for hundreds of years.<br> <br> Rationality is about how to turn data into maps. But this still requires data. I think that in a wide variety of not particularly theoretical subjects (like sports, social interactions, negotiation, cooking, etc.) rationality needs to be augmented by personal experience. Instrumental Rationality turns models into high-utility actions, but before you can do that you need a model.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\" id=\"Tangibility_\">Tangibility:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Personal experience is useful in fields where there are certain building blocks which are treated as conceptual atoms when thinking consciously about it, but where said building blocks are hard to acquire without experience. In these fields, experience is needed before advice can be particularly useful.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">One thing about these kinds of fields is that your brain has a lot of circuitry built in for dealing with things related to them. Sports involve muscle memory and your kinesthetic sense. Social interactions involve a lot of non-verbal cues that your brain is optimized to handle. If you\u2019re unaware of these basic concerns, then further progression is difficult. You can give the best explanation in the world, but if you missed that the other person didn\u2019t understand your first assertion then it doesn\u2019t matter.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">The best way that I\u2019ve found for me to be able to recognize and learn things like that is for me to go out and experience them. Consider the difference between a smile and a smirk. Language is terrible at communicating the difference, but your brain has a high bandwidth way of gathering data about them by experiencing it.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">People can definitely communicate about these topics, but they often assume a comprehension of the basic words used to describe them, and gloss over the subtleties. Was that an \u201cI feel uncomfortable\u201d laugh, or an \u201cI\u2019m becoming comfortable\u201d one? If you can\u2019t tell the difference between these things, then you\u2019re in for some trouble. When someone in soccer tells you to go down the side and then pass the ball to the center, you\u2019re going to fail if you don\u2019t know how to dribble, pass, or deal with defenders.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\" id=\"Practice_\">Practice:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Practice is important. As any akrasiatic or novice would know, knowledge in a field or domain doesn\u2019t translate directly to success in it. In muscle memory, you need practice in order to get your brain to incorporate what you know to the point that you can use it automatically. Consciously thinking about what you\u2019re doing while you\u2019re doing it tends to cause lag and awkwardness, and in some fields (like conversation or physical activities) is a pretty large detriment.<br> <br> This is even true in fields like math. When someone walks you through a math problem or proof and explains what\u2019s going on and what tools are being used when and why, it\u2019s a lot easier to understand. And you might totally understand it when the person is walking you through, but then flounder if given a similar problem without their supervision. Without practice, you don\u2019t know what needs to be applied when, and actually acting on your knowledge is made much more difficult.<br> <br> For me, the most obvious example of this comes from learning how to write. A teacher would recommend a particular technique or device, like appositive phrases, and then I would notice them everywhere. And then I\u2019d overuse them. And then I\u2019d sound silly, or just wind up with a bunch of really long sentences in a row. I needed practice before I could make better judgments about where they should and shouldn\u2019t be used, rather than indiscriminately apply them everywhere.<sup>1</sup></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><strong style=\"mso-bidi-font-weight: normal;\" id=\"Pointing_out_Problems_\">Pointing out Problems:</strong></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">\n</p><p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">One of your strengths as a rationalist is to be able to learn from your data. Theorizing helps you turn data into strategies. Experience is very salient data. When you combine the two, you can become incredibly responsive.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">When you try something, you can see how your map works in practice. When you encounter a setback, you can find an inaccuracy in your map, or just a region of the territory that you didn't cover. As a rationalist, you can better understand and use this information to improve.</p>\n<p></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Trying something out is vital to noticing that there are things for which your model does not account, but are important. One of the easiest ways to find out if you\u2019re forgetting something important is to try and see what goes wrong. Anything that consistently causes problems is by definition important. This can settle a lot of arguments.<br> <br> One of the times the importance of this rang most true for me was during a robotics competition in <a href=\"http://www.youtube.com/watch?v=IEHAj3EmpMw\">this game</a>.&nbsp;We had built a vacuum for our robot to allow it to hold balls while aiming and maneuvering. When competition came, two major problems made themselves obvious. The first was that we couldn\u2019t see the balls from where the drivers drove, and the second was that the vacuum head was incredibly delicate to small deviations in position (which could be caused by pushing a ball against a wall), and would be rendered inoperable almost every game. Both of these issues would have been obvious had we tried playing under game conditions beforehand, but our \u201ctests\u201d (holding the vacuum to a soccer ball and observing that we could then lift the ball with the vacuum, and trying to place a ball on the vacuum while it was mounted to a stationary robot) obscured several very important and relevant details.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">It didn\u2019t take very long to fix these problems for our second competition, and doing so made our robot dramatically more effective. Had we tested out for real beforehand, we could have been awesome from day one.<br> <br> [1] A slight caveat was that I still needed to use them a lot before I was able to learn where I shouldn\u2019t use them.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\">Thanks to everyone who gave me feedback on the previous incarnation of this article, it was helpful and very motivating.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Overview:", "anchor": "Overview_", "level": 1}, {"title": "Tangibility:", "anchor": "Tangibility_", "level": 1}, {"title": "Practice:", "anchor": "Practice_", "level": 1}, {"title": "Pointing out Problems:", "anchor": "Pointing_out_Problems_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-03T06:21:38.636Z", "modifiedAt": null, "url": null, "title": "Sydney Less Wrong Meetup (cancelled due to lack of interest)", "slug": "sydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:21.008Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "syllogism", "createdAt": "2010-12-09T02:25:23.672Z", "isAdmin": false, "displayName": "syllogism"}, "userId": "aHznJxGf4ZbruWkNa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jfuSAz4AKSBYwFJTh/sydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "pageUrlRelative": "/posts/jfuSAz4AKSBYwFJTh/sydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "linkUrl": "https://www.lesswrong.com/posts/jfuSAz4AKSBYwFJTh/sydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "postedAtFormatted": "Thursday, March 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sydney%20Less%20Wrong%20Meetup%20(cancelled%20due%20to%20lack%20of%20interest)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASydney%20Less%20Wrong%20Meetup%20(cancelled%20due%20to%20lack%20of%20interest)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfuSAz4AKSBYwFJTh%2Fsydney-less-wrong-meetup-cancelled-due-to-lack-of-interest%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sydney%20Less%20Wrong%20Meetup%20(cancelled%20due%20to%20lack%20of%20interest)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfuSAz4AKSBYwFJTh%2Fsydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfuSAz4AKSBYwFJTh%2Fsydney-less-wrong-meetup-cancelled-due-to-lack-of-interest", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>Update: Well this seems to be a bust =/. Maybe people don't check the \"new\" section, only \"promoted\", or maybe the site visit statistics are deceptive.</p>\n<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; padding: 0.5em; margin: 8px;\">\n<p>Just saw&nbsp;<a href=\"/r/discussion/lw/43s/starting_a_lw_meetup_is_easy/3gbz\">here</a>&nbsp;that Sydney has the 2nd most LWers of any city without a meet-up. So, let's have a meet-up!</p>\n<p>Let's instant-runoff vote on the specifics until Sunday 6th, and I'll update the post with the verdict then:</p>\n<p>&nbsp;</p>\n<p>1. Which date and time of the following work for you? Rank the ones you can attend in preference order</p>\n<p>a) Evening of Tuesday, 15th March</p>\n<p>b) Evening of Wednesday, 16th March</p>\n<p>c) Afternoon of Saturday, 19th March</p>\n<p>c) Evening of Saturday, 19th March</p>\n<p>e) Afternoon of Sunday, 20th March</p>\n<p>&nbsp;</p>\n<p>2. What kind of setting do you prefer?</p>\n<p>a) Bar</p>\n<p>b) Restaurant</p>\n<p>c) Other (park for picnic, cafe, etc. Please specify)</p>\n<p>&nbsp;</p>\n<p>3. Which area of Sydney is best for you? Rank the ones you could make it to.</p>\n<p>a) City/Central&nbsp;</p>\n<p>b) Lower North Shore (e.g. Neutral Bay, North Sydney, etc)</p>\n<p>c) Greater West (e.g. Parramatta)</p>\n<p>d) Inner West (e.g. Newtown, Enmore). Tempted to suggest the Humanist House in Chippendale, although I don't know what the deal with it is.</p>\n<div><br /></div>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jfuSAz4AKSBYwFJTh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 6.854810688065745e-07, "legacy": true, "legacyId": "6024", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-03T16:20:00.622Z", "modifiedAt": null, "url": null, "title": "post", "slug": "post", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aencEyCdG5N87AyL4/post", "pageUrlRelative": "/posts/aencEyCdG5N87AyL4/post", "linkUrl": "https://www.lesswrong.com/posts/aencEyCdG5N87AyL4/post", "postedAtFormatted": "Thursday, March 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Apost%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaencEyCdG5N87AyL4%2Fpost%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaencEyCdG5N87AyL4%2Fpost", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaencEyCdG5N87AyL4%2Fpost", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 35, "htmlBody": "<p>Previously proposed LessWrong projects that have not materialized and could form the basis for such a group:<br /></p>\n<ol>\n<li>The Simple Math of Everything</li>\n<li>Social.lesswrong.com/CUA (mea culpa)</li>\n<li>Threaded sub-reddits</li>\n<li>Lesswrong University</li>\n</ol>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aencEyCdG5N87AyL4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": -2, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "6039", "legacySpam": true, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T00:35:07.199Z", "modifiedAt": null, "url": null, "title": "Shikamaru vs. the Logical Fallacies", "slug": "shikamaru-vs-the-logical-fallacies", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.073Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nick_Roy", "createdAt": "2010-02-13T02:57:14.500Z", "isAdmin": false, "displayName": "Nick_Roy"}, "userId": "LouYAbtgk7xDBDhZA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6SiujPCHqotqwzuWh/shikamaru-vs-the-logical-fallacies", "pageUrlRelative": "/posts/6SiujPCHqotqwzuWh/shikamaru-vs-the-logical-fallacies", "linkUrl": "https://www.lesswrong.com/posts/6SiujPCHqotqwzuWh/shikamaru-vs-the-logical-fallacies", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shikamaru%20vs.%20the%20Logical%20Fallacies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShikamaru%20vs.%20the%20Logical%20Fallacies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6SiujPCHqotqwzuWh%2Fshikamaru-vs-the-logical-fallacies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shikamaru%20vs.%20the%20Logical%20Fallacies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6SiujPCHqotqwzuWh%2Fshikamaru-vs-the-logical-fallacies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6SiujPCHqotqwzuWh%2Fshikamaru-vs-the-logical-fallacies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>Presenting: <em>Shikamaru vs. the Logical Fallacies</em>, a rationalist fanfic set in the <em>Naruto</em> universe and starring a <em>realistically</em> rational Shikamaru. The writer is a friend of mine going under the alias <em>FanFicBias</em>, and I am an editor along with the author.</p>\n<p>We welcome reviews on FanFiction.Net and both reviews and discussion (naturally) are welcome here. We are looking to improve our work, so please be as honest and as harsh in constructive criticism as you like. Praise, however, is also always welcome!</p>\n<p>This story does contain <strong>SPOILERS</strong> for the <em>Naruto</em> series. Readers who are unfamiliar with <em>Naruto</em> may have a hard time understanding what's going on, but it would still be interesting to hear from non-<em>Naruto</em> fans, since perhaps we can ameliorate this issue with the aid of constructive criticism.</p>\n<p>We do strive to follow the First Law of Fanfiction and the Rule of Rationalist Fanfiction, so please call us on it if we fail to do so.</p>\n<p>http://www.fanfiction.net/s/6781426/1/Shikamaru_versus_the_Rational_Fallacies</p>\n<p>Note: Thanks to all reviewers and participants in this discussion! We're trying hard to make Part 2 even better.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6SiujPCHqotqwzuWh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 6.857756599817386e-07, "legacy": true, "legacyId": "6040", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T01:33:32.120Z", "modifiedAt": null, "url": null, "title": "What are you working on?", "slug": "what-are-you-working-on", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:54.425Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Cq4KKE4Xg6xdeoSJZ/what-are-you-working-on", "pageUrlRelative": "/posts/Cq4KKE4Xg6xdeoSJZ/what-are-you-working-on", "linkUrl": "https://www.lesswrong.com/posts/Cq4KKE4Xg6xdeoSJZ/what-are-you-working-on", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20you%20working%20on%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20you%20working%20on%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCq4KKE4Xg6xdeoSJZ%2Fwhat-are-you-working-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20you%20working%20on%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCq4KKE4Xg6xdeoSJZ%2Fwhat-are-you-working-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCq4KKE4Xg6xdeoSJZ%2Fwhat-are-you-working-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>Whpearson <a href=\"/&quot;What are you working on&quot; \">recently mentioned</a> that people in some other online communities frequently ask \"what are you working on?\". I personally love asking and answering this question. I made sure to ask it at the Seattle meetup. However, I don't often see it asked here in the comments, so I will ask it:</p>\n<p style=\"padding-left: 300px;\"><em>What are you working on?&nbsp;</em></p>\n<p>Here are some guidelines</p>\n<ul>\n<li>Focus on projects that you have recently made progress on, not projects that you're thinking about doing but haven't started, those are for a different thread.&nbsp;</li>\n<li>Why this project and not others? Mention reasons why you're doing the project and/or why others should contribute to your project (if applicable).</li>\n<li>Talk about your goals for the project.</li>\n<li>Any kind of project is fair game: personal improvement, research project, art project, whatever.</li>\n<li><strong>Link to your work if it's linkable</strong></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Cq4KKE4Xg6xdeoSJZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 30, "extendedScore": null, "score": 6.857914038406739e-07, "legacy": true, "legacyId": "6041", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 103, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T02:06:56.838Z", "modifiedAt": null, "url": null, "title": "Rationality Activism: Open Thread", "slug": "rationality-activism-open-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:09.059Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YAKrzT5dhB24fYZsz/rationality-activism-open-thread", "pageUrlRelative": "/posts/YAKrzT5dhB24fYZsz/rationality-activism-open-thread", "linkUrl": "https://www.lesswrong.com/posts/YAKrzT5dhB24fYZsz/rationality-activism-open-thread", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Activism%3A%20Open%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Activism%3A%20Open%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAKrzT5dhB24fYZsz%2Frationality-activism-open-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Activism%3A%20Open%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAKrzT5dhB24fYZsz%2Frationality-activism-open-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAKrzT5dhB24fYZsz%2Frationality-activism-open-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<p>So as I read around the discussion section I keep coming across ideas (like&nbsp;<a title=\"this post\" href=\"/r/discussion/lw/4na/are_you_a_paralyzed_subordinate_monkey/3mdl\">this</a>,&nbsp;<a href=\"/r/discussion/lw/4lg/existential_risk_reduction_career_network/\">this</a>, <a href=\"/r/discussion/lw/3ul/should_we_have_secular_churches/\">this</a>, or&nbsp;<a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/\">this</a>) which all seem to be very related to the same topics:</p>\n<ul>\n<li>How do we use rationality to better contribute to the world?</li>\n<li>How do we spread rationality among other people?</li>\n</ul>\n<p><a href=\"/r/discussion/lw/4ad/optimal_employment_open_thread/\">Other</a>&nbsp;<a href=\"/r/discussion/lw/4mh/are_interesting_problems_useful/\">posts</a>&nbsp;talk about similar things.</p>\n<p>I have&nbsp;<a href=\"/r/discussion/lw/46r/rationality_for_other_people/\">been</a>&nbsp;interested in&nbsp;<a href=\"/r/discussion/lw/49a/bridging_inferential_gaps_and_explaining/\">this</a>&nbsp;for a while now, and have gotten <a href=\"/r/discussion/lw/46r/rationality_for_other_people/3j1u\">some</a> <a href=\"/r/discussion/lw/46r/rationality_for_other_people/3j35\">great</a> <a href=\"/r/discussion/lw/49a/bridging_inferential_gaps_and_explaining/3jgb\">feedback</a>.</p>\n<p>But now I'm wondering how many groups, other than SIAI, are trying to do this. It seems like it would be silly to have something like this stagnate because of a&nbsp;<a href=\"/lw/mc/to_lead_you_must_stand_up\">simple coordination problem</a>.</p>\n<p>So if you are, please come forth and comment. If you're interested, do the same. Share what you know, learn from others, maybe maybe maybe get the ball rolling a bit more.<br /><br />Note:<br />I changed the title (originally \"Rationality Activism Groups\") to reflect the more discussion-oriented nature of this thread.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YAKrzT5dhB24fYZsz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 6.85800409170339e-07, "legacy": true, "legacyId": "6043", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9QfLnRi2GwHaEBeN5", "DnjBQAWE7jYhYytmr", "s5sy3qiknFs7ehsLA", "yuGci5CHe8CGqFuCa", "m3DDuXvqfTZSWXTLo", "kYDzd777ScKzbsTst", "NQNsiAM2vpjDRfYyp", "n5oCEbnW2PgFmkQhr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T04:17:40.900Z", "modifiedAt": null, "url": null, "title": "The Trouble with Bright Girls [link]", "slug": "the-trouble-with-bright-girls-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:32.465Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Sm8FDGwGDjAP6CfvB/the-trouble-with-bright-girls-link", "pageUrlRelative": "/posts/Sm8FDGwGDjAP6CfvB/the-trouble-with-bright-girls-link", "linkUrl": "https://www.lesswrong.com/posts/Sm8FDGwGDjAP6CfvB/the-trouble-with-bright-girls-link", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Trouble%20with%20Bright%20Girls%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Trouble%20with%20Bright%20Girls%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSm8FDGwGDjAP6CfvB%2Fthe-trouble-with-bright-girls-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Trouble%20with%20Bright%20Girls%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSm8FDGwGDjAP6CfvB%2Fthe-trouble-with-bright-girls-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSm8FDGwGDjAP6CfvB%2Fthe-trouble-with-bright-girls-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 213, "htmlBody": "<p><a href=\"http://www.huffingtonpost.com/heidi-grant-halvorson-phd/girls-confidence_b_828418.html\">The Trouble with Bright Girls (article @ the Huffington Post)</a></p>\n<p>Excerpt:</p>\n<blockquote>\n<p>My graduate advisor, psychologist Carol Dweck (author of \"<a href=\"http://www.amazon.com/Mindset-Psychology-Success-Carol-Dweck/dp/1400062756\" target=\"_hplink\">Mindset</a>\")  conducted a series of studies in the 1980s, looking at how Bright Girls  and boys in the fifth grade handled new, difficult and confusing  material.<br /> <br /> She found that Bright Girls, when given something to learn that was  particularly foreign or complex, were quick to give up; the higher the  girls' IQ, the <em>more</em> likely they were to throw in the towel. In  fact, the straight-A girls showed the most helpless responses. Bright  boys, on the other hand, saw the difficult material as a challenge, and  found it energizing. They were more likely to redouble their efforts  rather than give up.</p>\n</blockquote>\n<p>The topic of this article seems to relate to several common Less Wrong issues: the nature of human intelligence, and the gender imbalance among LW readers.</p>\n<p>I'm not sure how much credence I give to the proposed explanation of the difference in mindsets. It may well have to do with socialization and feedback, but the specific description of feedback that is presented seems a bit too much of a \"just-so story\" to me. The difference itself is fascinating, though, and I hope more is done to further our understanding of it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4cKQgA4S7xfNeeWXg": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Sm8FDGwGDjAP6CfvB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 23, "extendedScore": null, "score": 6.858356472129933e-07, "legacy": true, "legacyId": "6054", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T16:04:00.331Z", "modifiedAt": null, "url": null, "title": "[LINK] Discovery shuttle launch viewed from an airliner", "slug": "link-discovery-shuttle-launch-viewed-from-an-airliner", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:53.772Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YcXW9KYfqn9NBPc9B/link-discovery-shuttle-launch-viewed-from-an-airliner", "pageUrlRelative": "/posts/YcXW9KYfqn9NBPc9B/link-discovery-shuttle-launch-viewed-from-an-airliner", "linkUrl": "https://www.lesswrong.com/posts/YcXW9KYfqn9NBPc9B/link-discovery-shuttle-launch-viewed-from-an-airliner", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Discovery%20shuttle%20launch%20viewed%20from%20an%20airliner&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Discovery%20shuttle%20launch%20viewed%20from%20an%20airliner%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYcXW9KYfqn9NBPc9B%2Flink-discovery-shuttle-launch-viewed-from-an-airliner%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Discovery%20shuttle%20launch%20viewed%20from%20an%20airliner%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYcXW9KYfqn9NBPc9B%2Flink-discovery-shuttle-launch-viewed-from-an-airliner", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYcXW9KYfqn9NBPc9B%2Flink-discovery-shuttle-launch-viewed-from-an-airliner", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p>Behold the <a href=\"http://www.youtube.com/watch?v=GE_USPTmYXM&amp;feature=aso\">power of applied rationality</a>!</p>\r\n<p>...ok, this is really just geek mind candy.</p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YcXW9KYfqn9NBPc9B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 6.860260850298022e-07, "legacy": true, "legacyId": "6070", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T20:32:37.911Z", "modifiedAt": null, "url": null, "title": "The Importance of Mathematics (Gowers)", "slug": "the-importance-of-mathematics-gowers", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.544Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sd9YwHDjjMJRAjZn7/the-importance-of-mathematics-gowers", "pageUrlRelative": "/posts/sd9YwHDjjMJRAjZn7/the-importance-of-mathematics-gowers", "linkUrl": "https://www.lesswrong.com/posts/sd9YwHDjjMJRAjZn7/the-importance-of-mathematics-gowers", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Importance%20of%20Mathematics%20(Gowers)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Importance%20of%20Mathematics%20(Gowers)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsd9YwHDjjMJRAjZn7%2Fthe-importance-of-mathematics-gowers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Importance%20of%20Mathematics%20(Gowers)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsd9YwHDjjMJRAjZn7%2Fthe-importance-of-mathematics-gowers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fsd9YwHDjjMJRAjZn7%2Fthe-importance-of-mathematics-gowers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1075, "htmlBody": "<p>For the past few days I've been pondering the question of how best to respond to paulfchristiano's <a href=\"/r/discussion/lw/4mh/are_interesting_problems_useful/\">recent</a> <a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/\">posts</a> <a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/3lsb\">and</a> <a href=\"/r/discussion/lw/4kt/the_value_of_theoretical_research/3m2m\">comments</a> questioning the value of mathematical research. I don't think I can do it concisely, in a single post; bridging the <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferential distance</a> may require something more like a sequence of posts. I may end up writing such a sequence eventually, since it would involve ideas I've actually been wanting to write up for some time, and which are actually relevant to more than just the specific questions at issue here (whether society should sponsor mathematics, and given that it does, whether paulfchristiano or anyone else in the LW readership should pursue it).&nbsp;</p>\n<p>However, as the preceding parenthetical hints at, I'm actually somewhat conflicted about whether I should even bother. Although I believe that mathematical research should be conducted by <em>somebody</em>, it's not at all clear to me that the discipline needs <em>more</em> people beyond those who already \"get\" its importance, and are out there doing it rather than writing skeptical posts like paulfchristiano's. It seems perfectly plausible to me that those who feel as paulfchristiano does should just leave the profession and do something else that feels more \"important\" to them. This is surely the best practical solution on an individual level for those who think they have a better idea than existing institutions of where the most promising research directions lie, at least until Hansonian prediction markets are (ever) implemented.</p>\n<p>Nevertheless, for those interested in the society-level question of whether mathematics (as such) may be justifiably pursued by <em>anyone, </em>or any community of people, as a professional occupation (which is quite distinct from the question of whether e.g. paulfchristiano should personally pursue it), I recommend, at least as a start, grappling with the arguments put forward by the best mathematicians in their own words. I think <a href=\"http://www.dpmms.cam.ac.uk/~wtg10/importance.pdf\">this essay by Timothy Gowers</a> (a Fields Medalist), titled \"The Importance of Mathematics\", is a good place to begin. I would particularly draw the attention of those like paulfchristiano, who think they have a good idea of which branches of mathematics are useful and which aren't, to the following passage, from pp.8-9 (unfortunately the illustrations are missing, but the point being made is pretty clear nonetheless):</p>\n<blockquote>\n<p>So - mathematicians can tell their governments - if you cut funding to pure mathematical<br />research, you run the risk of losing out on unexpected benefits, which historically<br />have been by far the most important.</p>\n<p><br />However, the miserly finance minister need not be convinced quite yet. It may be very<br />hard to identify positively the areas of mathematics likely to lead to practical benefits, but<br />that does not rule out the possibility of identifying negatively the areas that will quite<br />clearly be useless, or at least useless for the next two hundred years. In fact, the finance<br />minister does not even need to be certain that they will be useless. If a large area of<br />mathematics has only a one in ten thousand chance of producing economic benefit in the<br />next fifty years, then perhaps that at least could be cut.</p>\n<p><br />You will not be surprised to hear me say that this policy would still be completely<br />misguided. A major reason, one that has been commented on many times and is implied<br />by the subtitle of this conference, \"A Celebration of the Universality of Mathematical<br />Thought\", is that mathematics is very interconnected, far more so than it appears on the<br />surface. The picture in the back of the finance minister's mind might be something like<br />Figure 4. According to this picture, mathematics is divided into several subdisciplines, of<br />varying degrees of practicality, and it is a simple matter to cut funding to the less practical<br />ones.</p>\n<p>A more realistic picture, though still outrageously simplified, is given in Figure 5.<br />(Just for the purposes of comparison, Figure 6 shows Figures 4 and 5 superimposed.) The<br />nodes of Figure 5 represent small areas of mathematical activity and the lines joining them<br />represent interrelationships between those areas. The small areas of activity form clusters<br />where there are more of these interrelationships, and these clusters can perhaps be thought<br />of as subdisciplines. However, the boundaries of these clusters are not precise, and many<br />of the interrelationships are between clusters rather than within them.</p>\n<p><br />In particular, if mathematicians work on difficult practical problems, they do not do so<br />in isolation from the rest of mathematics. Rather, they bring to the problems several tools<br />- mathematical tricks, rules of thumb, theorems known to be useful (in the mathematical<br />sense), and so on. They do not know in advance which of these tools they will use, but they<br />hope that after they have thought hard about a problem they will realize what is needed to<br />solve it. If they are lucky, they can simply apply their existing expertise straightforwardly.<br />More often, they will have to adapt it to some extent</p>\n<p>(...)</p>\n<p>Thus, a good way to think about mathematics as a whole is that it is a huge body of<br />knowledge, a bit like an encyclopaedia but with an enormous number of cross-references.<br />This knowledge is stored in books, papers, computers and the brains of thousands of<br />mathematicians round the world. It is not as convenient to look up a piece of mathematics<br />as it is to look up a word in an encyclopaedia, especially as it is not always easy to<br />specify exactly what it is that one wants to look up. Nevertheless, this \"encyclopaedia\" of<br />mathematics is an incredible resource. And just as, if one were to try to get rid of all the<br />entries in an encyclopaedia, or, to give a different comparison, all the books in a library,<br />that nobody ever looked up, the result would be a greatly impoverished encyclopaedia or<br />library, so, any attempt to purge mathematics of its less useful parts would almost certainly<br />be very damaging to the more useful parts as well.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sd9YwHDjjMJRAjZn7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 6.860985361982878e-07, "legacy": true, "legacyId": "6071", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["m3DDuXvqfTZSWXTLo", "s5sy3qiknFs7ehsLA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-04T23:07:28.670Z", "modifiedAt": null, "url": null, "title": "Well-done documentary on the singularity: 'Transcendent Man'", "slug": "well-done-documentary-on-the-singularity-transcendent-man", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:21.364Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tqTJ2XqTDLL375phe/well-done-documentary-on-the-singularity-transcendent-man", "pageUrlRelative": "/posts/tqTJ2XqTDLL375phe/well-done-documentary-on-the-singularity-transcendent-man", "linkUrl": "https://www.lesswrong.com/posts/tqTJ2XqTDLL375phe/well-done-documentary-on-the-singularity-transcendent-man", "postedAtFormatted": "Friday, March 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Well-done%20documentary%20on%20the%20singularity%3A%20'Transcendent%20Man'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWell-done%20documentary%20on%20the%20singularity%3A%20'Transcendent%20Man'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtqTJ2XqTDLL375phe%2Fwell-done-documentary-on-the-singularity-transcendent-man%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Well-done%20documentary%20on%20the%20singularity%3A%20'Transcendent%20Man'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtqTJ2XqTDLL375phe%2Fwell-done-documentary-on-the-singularity-transcendent-man", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtqTJ2XqTDLL375phe%2Fwell-done-documentary-on-the-singularity-transcendent-man", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<p>I just watched <em><a href=\"http://en.wikipedia.org/wiki/Transcendent_man\">Transcendent Man</a></em>&nbsp;about the singularity and Ray Kurzweil in particular. It's well-made, full-length, and includes the most popular criticisms of Kurzweil: that his prediction timeframes are driven by his own hope for immortality, that the timescale of his other predictions are too optimistic, that his predictions about the social outcomes of revolutionary technology are naively optimistic, and so on. Ben Goertzel and others get much face time.</p>\n<p>You can rent or buy it <a href=\"http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewMovie?id=418520110&amp;s=143441\">on iTunes</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tqTJ2XqTDLL375phe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 6.861403058372318e-07, "legacy": true, "legacyId": "6072", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-05T02:11:09.954Z", "modifiedAt": null, "url": null, "title": "Case study: Console Insurance", "slug": "case-study-console-insurance", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qykvr25EGcpFcMy6f/case-study-console-insurance", "pageUrlRelative": "/posts/qykvr25EGcpFcMy6f/case-study-console-insurance", "linkUrl": "https://www.lesswrong.com/posts/qykvr25EGcpFcMy6f/case-study-console-insurance", "postedAtFormatted": "Saturday, March 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Case%20study%3A%20Console%20Insurance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACase%20study%3A%20Console%20Insurance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqykvr25EGcpFcMy6f%2Fcase-study-console-insurance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Case%20study%3A%20Console%20Insurance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqykvr25EGcpFcMy6f%2Fcase-study-console-insurance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqykvr25EGcpFcMy6f%2Fcase-study-console-insurance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<p>I've sometimes seen people say that they need concrete simple examples of ideas like expected utility and Bayes' theorem. So, continuing in the same vein as <a href=\"/lw/47k/an_abortion_dialogue/\">An Abortion Dialogue</a> and <a href=\"/lw/1lt/case_study_melatonin/\">Case Study: Melatonin</a>, I recently polished up my shorter-but-hopefully-still-interesting article on <a href=\"http://www.gwern.net/Console%20Insurance\">Console Insurance</a>.</p>\n<p>It's basically a short discussion of how back of the envelop estimates show console insurance (and by extension, most warranty extensions) to be a bad investment.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qykvr25EGcpFcMy6f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "6075", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TsRu6iP7DwRRbkHpS", "XYA9nBud8joDjTy86"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-05T06:09:50.550Z", "modifiedAt": null, "url": null, "title": "A Brief Overview of Machine Ethics", "slug": "a-brief-overview-of-machine-ethics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:20.709Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FjtRKeJ5fnwHPHrCA/a-brief-overview-of-machine-ethics", "pageUrlRelative": "/posts/FjtRKeJ5fnwHPHrCA/a-brief-overview-of-machine-ethics", "linkUrl": "https://www.lesswrong.com/posts/FjtRKeJ5fnwHPHrCA/a-brief-overview-of-machine-ethics", "postedAtFormatted": "Saturday, March 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Brief%20Overview%20of%20Machine%20Ethics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Brief%20Overview%20of%20Machine%20Ethics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFjtRKeJ5fnwHPHrCA%2Fa-brief-overview-of-machine-ethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Brief%20Overview%20of%20Machine%20Ethics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFjtRKeJ5fnwHPHrCA%2Fa-brief-overview-of-machine-ethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFjtRKeJ5fnwHPHrCA%2Fa-brief-overview-of-machine-ethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>Earlier, I <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">lamented</a> that even though Eliezer named <em>scholarship</em> as one of the <a href=\"http://yudkowsky.net/rational/virtues\">Twelve Virtues of Rationality</a>, there is surprisingly little interest in (or citing of) the academic literature on some of Less Wrong's central discussion topics.</p>\n<p>Previously, I provided <a href=\"/lw/3n0/an_overview_of_formal_epistemology_links/\">an overview of formal epistemology</a>, that field of philosophy that deals with&nbsp;(1) mathematically formalizing concepts related to induction, belief, choice, and action, and (2) arguing about the foundations of probability, statistics, game theory, decision theory, and algorithmic learning theory.</p>\n<p>Now, I've written <a href=\"http://commonsenseatheism.com/?p=14597\">Machine Ethics is the Future</a>, an introduction to machine ethics, the academic field that studies the problem of how to design artificial moral agents that act ethically (along with a few related problems). There, you will find PDFs of a dozen papers on the subject.</p>\n<p>Enjoy!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FjtRKeJ5fnwHPHrCA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 10, "extendedScore": null, "score": 6.86254261344406e-07, "legacy": true, "legacyId": "6081", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["64FdKLwmea8MCLWkE", "BXot7wxNbipyM749o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-05T08:35:06.429Z", "modifiedAt": null, "url": null, "title": "Using the Karma system to call for a show of hands - profitable?", "slug": "using-the-karma-system-to-call-for-a-show-of-hands", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:17.364Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WFFD6vu24EqT7Gmt9/using-the-karma-system-to-call-for-a-show-of-hands", "pageUrlRelative": "/posts/WFFD6vu24EqT7Gmt9/using-the-karma-system-to-call-for-a-show-of-hands", "linkUrl": "https://www.lesswrong.com/posts/WFFD6vu24EqT7Gmt9/using-the-karma-system-to-call-for-a-show-of-hands", "postedAtFormatted": "Saturday, March 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20the%20Karma%20system%20to%20call%20for%20a%20show%20of%20hands%20-%20profitable%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20the%20Karma%20system%20to%20call%20for%20a%20show%20of%20hands%20-%20profitable%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWFFD6vu24EqT7Gmt9%2Fusing-the-karma-system-to-call-for-a-show-of-hands%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20the%20Karma%20system%20to%20call%20for%20a%20show%20of%20hands%20-%20profitable%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWFFD6vu24EqT7Gmt9%2Fusing-the-karma-system-to-call-for-a-show-of-hands", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWFFD6vu24EqT7Gmt9%2Fusing-the-karma-system-to-call-for-a-show-of-hands", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 409, "htmlBody": "<p>Not saying its a efficient use of time for the Karma hoarder, but I do wonder if it generally is a reliable way to gain karma. We sometimes see a call for a show of hands here where a comment is up voted by those that agree and a later comment is down voted for balance. <br /><br />This is purely anecdotal but it seems to me most of the time down-votes don't balance out the up-votes. Does anyone else have this experience? This seems a question we can answer approximately by having a bot mine the text of the archives. I feel that making the bot would be made easier if we had as many samples of such use of the Karma system as possible. However if I'm the only one with this observation or if those with this observation are in the minority its probably not worth the effort (at least for someone with my skill set) .</p>\n<p>Some LWers may be relying on others who don't agree with the motion but want to be \"fair\" when it comes to Karma to down vote the balance. Perhaps there are just fewever people who don't agree with the motion but down vote the balance post, because it contributes to enforcing norms of how they think the Karma system should be used, than there are people who agree with the motion but don't down vote.</p>\n<p>&nbsp;</p>\n<p>As to explanations, off the top of my head:</p>\n<ul>\n<li><a href=\"http://en.wikipedia.org/wiki/Selection_bias\">Selection bias. </a></li>\n<li><a href=\"http://wiki.lesswrong.com/wiki/Trivial_inconvenience\">Trivial inconvenience</a> to access the down voted balance</li>\n<li>A fraction of posters simply forgets to down-vote</li>\n<li>Some posters might up-vote unthinkingly because they like the suggestion not because they agree with the motion.</li>\n<li>People don't see a problem with a slightly positive imbalance if they think asking for the call was a good idea. If they think its a bad idea they are due to LW norms farm less likley to down-vote. Especially if this particular pair of posts is balanced. </li>\n</ul>\n<p><strong>Edit:</strong></p>\n<p>It appears I was ignorant of the implicitly accepted social convention that bascially amounts to downvoting the balance being optional for those who don't want to reward the person making taking the poll (or perhaps don't want to reward him beyond the current imbalance).</p>\n<p>I'm still interested in what factors do or don't play a role in up and down voting such pairs of posts and how they compare to other form of participating Karma-wise.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WFFD6vu24EqT7Gmt9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -6, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "6089", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-05T09:16:06.063Z", "modifiedAt": null, "url": null, "title": "A Transhumanist Poem", "slug": "a-transhumanist-poem", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:56.339Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ofTJLK248YMf8qAiP/a-transhumanist-poem", "pageUrlRelative": "/posts/ofTJLK248YMf8qAiP/a-transhumanist-poem", "linkUrl": "https://www.lesswrong.com/posts/ofTJLK248YMf8qAiP/a-transhumanist-poem", "postedAtFormatted": "Saturday, March 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Transhumanist%20Poem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Transhumanist%20Poem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FofTJLK248YMf8qAiP%2Fa-transhumanist-poem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Transhumanist%20Poem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FofTJLK248YMf8qAiP%2Fa-transhumanist-poem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FofTJLK248YMf8qAiP%2Fa-transhumanist-poem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 170, "htmlBody": "<p><span style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; color: #333333; line-height: 16px;\">\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">**Note: I'm not a poet. I hardly ever write poetry, and when I do, it's usually because I've stayed up all night. However, this seemed like a very appropriate poem for Less Wrong. Not sure if it's appropriate as a top-level post. Someone please tell me if not.**</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Imagine</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">The first man</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Who held a stick in rough hands</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">And drew lines on a cold stone wall</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Imagine when the others looked</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">When they said, I see the antelope</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">I see it.&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Later on their children's children</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Would build temples, and sing songs</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">To their many-faced gods.</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Stone idols, empty staring eyes</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Offerings laid on a cold stone altar</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">And left to rot.&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Yet later still there would be steamships</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">And trains, and numbers to measure the stars</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Small suns ignited in the desert</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">One man's first step on an airless plain</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Now we look backwards</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">At the ones who came before us</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Who lived, and swiftly died.&nbsp;</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">The first man's flesh is in all of us now</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">And for his and his children's sake</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">We imagine a world with no more death</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">And we see ourselves reflected</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">In the silicon eyes</p>\n<p style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; text-align: left; line-height: 1.5em; margin: 0px;\">Of our final creation</p>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jiuackr7B5JAetbF6": 2, "AXhEhCkTrHZbjXXu3": 2, "KDpqtN3MxHSmD4vcB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ofTJLK248YMf8qAiP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 22, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "6090", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-05T19:15:05.257Z", "modifiedAt": null, "url": null, "title": "Blues, Greens and abortion", "slug": "blues-greens-and-abortion", "viewCount": null, "lastCommentedAt": "2018-08-04T14:09:32.677Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Snowyowl", "createdAt": "2010-08-23T21:33:34.015Z", "isAdmin": false, "displayName": "Snowyowl"}, "userId": "Mf2n7xCxxvALBrZ5i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HdXNzhCuXhempQXcW/blues-greens-and-abortion", "pageUrlRelative": "/posts/HdXNzhCuXhempQXcW/blues-greens-and-abortion", "linkUrl": "https://www.lesswrong.com/posts/HdXNzhCuXhempQXcW/blues-greens-and-abortion", "postedAtFormatted": "Saturday, March 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Blues%2C%20Greens%20and%20abortion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABlues%2C%20Greens%20and%20abortion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHdXNzhCuXhempQXcW%2Fblues-greens-and-abortion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Blues%2C%20Greens%20and%20abortion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHdXNzhCuXhempQXcW%2Fblues-greens-and-abortion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHdXNzhCuXhempQXcW%2Fblues-greens-and-abortion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 356, "htmlBody": "<p>Abortion is one of the most <a title=\"mind-killing\" href=\"/lw/gw/politics_is_the_mindkiller/\">politically-charged</a> debates in the world today - possibly <em>the</em> most politically charged, though that's the subject for another thread. It's an excellent way of advertising whether you are <a title=\"Blue or Green\" href=\"/lw/gt/a_fable_of_science_and_politics/\">Green or Blue</a>. As a sceptical atheist who thinks guns should be banned and gay marriage should be legalised, I naturally take a stance against abortion. It's easy to see why: a woman's freedom is less important than another human's right to live.</p>\n<p>Wait... that sounds off.</p>\n<p>I really am an atheist, with good reasons to support gun bans and gay marriage. But while pondering matters today, I realised that my position on abortion was a lot more shaky than it had previously seemed. I'm not sure one way or the other whether a mother's right to make decisions that can change her life trumps the life of a human embryo or fetus. On the one hand, a fetus isn't quite a person. It has very little intelligence or personality, and no existence independent of its mother, to the point where I am comfortable using the pronoun \"it\" to describe one. On the other hand, as little as it is, it still represents a human life, and I consider preservation of human life a terminal goal as opposed to the intermediate goal that is personal freedom. The relative utilities are staggering: I wouldn't allow a mob of 100,000 to kill another human no matter how much they wanted to and even if their quality of life was improved (up to a point). So: verify my beliefs, LessWrong.</p>\n<p>If possible, I'd like this thread to be not only a discussion about abortion and the banning or legalisation thereof, but also about why I didn't notice this before. For all my talk about examining my beliefs, I wasn't doing very well. <a href=\"/lw/36i/belief_in_belief_vs_internalization/\">I only believed verifying my beliefs was good; I wasn't doing it on any lower level.</a></p>\n<p>This post can't go on the front page, for obvious reasons: it's highly inflammatory, and changing it so as not to refer to a particular example would result in one of the posts I linked to above.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 2, "BtQRRKTPxagBH6KrG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HdXNzhCuXhempQXcW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 13, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "6091", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 155, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f", "6hfGNLf4Hg5DXqJCF", "ZQe33HWeFW3tSEQcx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-06T06:41:25.119Z", "modifiedAt": null, "url": null, "title": "Perhaps the first detailed plan to program a general moral code into a particular model of AGI", "slug": "perhaps-the-first-detailed-plan-to-program-a-general-moral", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:53.704Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DDbnBQgMBA5R9Xp2f/perhaps-the-first-detailed-plan-to-program-a-general-moral", "pageUrlRelative": "/posts/DDbnBQgMBA5R9Xp2f/perhaps-the-first-detailed-plan-to-program-a-general-moral", "linkUrl": "https://www.lesswrong.com/posts/DDbnBQgMBA5R9Xp2f/perhaps-the-first-detailed-plan-to-program-a-general-moral", "postedAtFormatted": "Sunday, March 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Perhaps%20the%20first%20detailed%20plan%20to%20program%20a%20general%20moral%20code%20into%20a%20particular%20model%20of%20AGI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APerhaps%20the%20first%20detailed%20plan%20to%20program%20a%20general%20moral%20code%20into%20a%20particular%20model%20of%20AGI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDbnBQgMBA5R9Xp2f%2Fperhaps-the-first-detailed-plan-to-program-a-general-moral%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Perhaps%20the%20first%20detailed%20plan%20to%20program%20a%20general%20moral%20code%20into%20a%20particular%20model%20of%20AGI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDbnBQgMBA5R9Xp2f%2Fperhaps-the-first-detailed-plan-to-program-a-general-moral", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDbnBQgMBA5R9Xp2f%2Fperhaps-the-first-detailed-plan-to-program-a-general-moral", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 349, "htmlBody": "<p>Wallach, Franklin, &amp; Allen, \"<a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2010.01095.x/abstract\">A Conceptual and Computational Model of Moral Decision Making in Human and Artificial Agents</a>.\"</p>\n<p>Abstract:</p>\n<blockquote>\n<p>Recently, there has been a resurgence of interest in general, comprehensive models of human cognition. Such models aim to explain higher-order cognitive faculties, such as deliberation and planning. Given a computational representation, the validity of these models can be tested in computer simulations such as software agents or embodied robots. The push to implement computational models of this kind has created the field of artificial general intelligence (AGI). Moral decision making is arguably one of the most challenging tasks for computational approaches to higher-order cognition. The need for increasingly autonomous artificial agents to factor moral considerations into their choices and actions has given rise to another new field of inquiry variously known as Machine Morality, Machine Ethics, Roboethics, or Friendly AI. In this study, we discuss how LIDA, an AGI model of human cognition, can be adapted to model both affective and rational features of moral decision making. Using the LIDA model, we will demonstrate how moral decisions can be made in many domains using the same mechanisms that enable general decision making. Comprehensive models of human cognition typically aim for compatibility with recent research in the cognitive and neural sciences. Global workspace theory, proposed by the neuropsychologist Bernard Baars (1988), is a highly regarded model of human cognition that is currently being computationally instantiated in several software implementations. LIDA (Franklin, Baars, Ramamurthy, &amp; Ventura, 2005) is one such computational implementation. LIDA is both a set of computational tools and an underlying model of human cognition, which provides mechanisms that are capable of explaining how an agent&rsquo;s selection of its next action arises from bottom-up collection of sensory data and top-down processes for making sense of its current situation. We will describe how the LIDA model helps integrate emotions into the human decision-making process, and we will elucidate a process whereby an agent can work through an ethical problem to reach a solution that takes account of ethically relevant factors.</p>\n</blockquote>\n<p>I suspect this is of much interest to many Less Wrong readers.</p>\n<p><a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Wallach-A-Conceptual-and-Computational-Model-of-Moral-Decision-Making-in-Human-and-Artificial-Agents.pdf\">PDF</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DDbnBQgMBA5R9Xp2f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 6.866515596055386e-07, "legacy": true, "legacyId": "6094", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-06T10:22:48.419Z", "modifiedAt": null, "url": null, "title": "NASA scientist finds evidence of alien life [link]", "slug": "nasa-scientist-finds-evidence-of-alien-life-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.877Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3CB3M5fa8ePYFiNJ4/nasa-scientist-finds-evidence-of-alien-life-link", "pageUrlRelative": "/posts/3CB3M5fa8ePYFiNJ4/nasa-scientist-finds-evidence-of-alien-life-link", "linkUrl": "https://www.lesswrong.com/posts/3CB3M5fa8ePYFiNJ4/nasa-scientist-finds-evidence-of-alien-life-link", "postedAtFormatted": "Sunday, March 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20NASA%20scientist%20finds%20evidence%20of%20alien%20life%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANASA%20scientist%20finds%20evidence%20of%20alien%20life%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CB3M5fa8ePYFiNJ4%2Fnasa-scientist-finds-evidence-of-alien-life-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=NASA%20scientist%20finds%20evidence%20of%20alien%20life%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CB3M5fa8ePYFiNJ4%2Fnasa-scientist-finds-evidence-of-alien-life-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3CB3M5fa8ePYFiNJ4%2Fnasa-scientist-finds-evidence-of-alien-life-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://journalofcosmology.com/Life100.html\">http://journalofcosmology.com/Life100.html</a></p>\n<p><a href=\"http://www.wired.com/wiredscience/2011/03/aliens-riding-meteorites-arsenic-redux-or-something-new/\">http://www.wired.com/wiredscience/2011/03/aliens-riding-meteorites-arsenic-redux-or-something-new/</a></p>\n<p><a href=\"http://news.ycombinator.com/item?id=2293643\">http://news.ycombinator.com/item?id=2293643</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3CB3M5fa8ePYFiNJ4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 6.867113655949208e-07, "legacy": true, "legacyId": "6095", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-06T10:26:12.072Z", "modifiedAt": null, "url": null, "title": "Armies of Expensive Lawyers, Replaced by Cheaper Software [link]", "slug": "armies-of-expensive-lawyers-replaced-by-cheaper-software", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.589Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7nYqnWGM8m66vYdqz/armies-of-expensive-lawyers-replaced-by-cheaper-software", "pageUrlRelative": "/posts/7nYqnWGM8m66vYdqz/armies-of-expensive-lawyers-replaced-by-cheaper-software", "linkUrl": "https://www.lesswrong.com/posts/7nYqnWGM8m66vYdqz/armies-of-expensive-lawyers-replaced-by-cheaper-software", "postedAtFormatted": "Sunday, March 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Armies%20of%20Expensive%20Lawyers%2C%20Replaced%20by%20Cheaper%20Software%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AArmies%20of%20Expensive%20Lawyers%2C%20Replaced%20by%20Cheaper%20Software%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7nYqnWGM8m66vYdqz%2Farmies-of-expensive-lawyers-replaced-by-cheaper-software%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Armies%20of%20Expensive%20Lawyers%2C%20Replaced%20by%20Cheaper%20Software%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7nYqnWGM8m66vYdqz%2Farmies-of-expensive-lawyers-replaced-by-cheaper-software", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7nYqnWGM8m66vYdqz%2Farmies-of-expensive-lawyers-replaced-by-cheaper-software", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.nytimes.com/2011/03/05/science/05legal.html?pagewanted=1&amp;ref=general&amp;src=me\">http://www.nytimes.com/2011/03/05/science/05legal.html?pagewanted=1&amp;ref=general&amp;src=me</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7nYqnWGM8m66vYdqz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 6, "extendedScore": null, "score": 6.867122825781303e-07, "legacy": true, "legacyId": "6096", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-06T20:24:27.846Z", "modifiedAt": null, "url": null, "title": "LW is to rationality as AIXI is to intelligence", "slug": "lw-is-to-rationality-as-aixi-is-to-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:06.313Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S8sNue3KzzWQpRjv5/lw-is-to-rationality-as-aixi-is-to-intelligence", "pageUrlRelative": "/posts/S8sNue3KzzWQpRjv5/lw-is-to-rationality-as-aixi-is-to-intelligence", "linkUrl": "https://www.lesswrong.com/posts/S8sNue3KzzWQpRjv5/lw-is-to-rationality-as-aixi-is-to-intelligence", "postedAtFormatted": "Sunday, March 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20is%20to%20rationality%20as%20AIXI%20is%20to%20intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20is%20to%20rationality%20as%20AIXI%20is%20to%20intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS8sNue3KzzWQpRjv5%2Flw-is-to-rationality-as-aixi-is-to-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20is%20to%20rationality%20as%20AIXI%20is%20to%20intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS8sNue3KzzWQpRjv5%2Flw-is-to-rationality-as-aixi-is-to-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS8sNue3KzzWQpRjv5%2Flw-is-to-rationality-as-aixi-is-to-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1214, "htmlBody": "<p>Apparently LW does a great job on refining rationality and dissolving confusions. But is it helpful when it comes to anything apart from designing Friendly AI, apart from a purely academic treatment of rationality? I'm currently unable to benefit from what I have so far read on LW, it actually made me even more unproductive, to an extent that I get nothing done anymore. Let me explain...</p>\n<p>You have to know that I'm still in the process of acquiring a basic education. If I say basic, I mean <em>basic</em>. Since I got almost no formal education, what I do know (or know <em>about</em>)<em> </em>is&nbsp;largely on a very low level, yet I am plagued by problems that are themselves on a level that require the intellect and education of the folks here on LW. The&nbsp;problem with that is that I'm yet lacking most of the skills, tools and&nbsp;requisite know-how while the problems in question concern me as well. This often causes me to get stuck, I can't decide what to do. It also doesn't help much that I am the kind of person who is troubled by problems others probably don't even think about. An example from when I was much younger (around the age of 13) is when I was troubled by the fact that I could accidentally squash insects when walking over grass in our garden. Since I have never been a prodigy, far from it, it was kind of an&nbsp;unsolvable&nbsp;problem at that time, especially since I am unable to concentrate for very long and other similar problems are accumulating in my mind all the time. So what happened? After a time of&nbsp;paralysis and distress, as it happens often, I simply became reluctant and unwilling, angry at the world. I decided that it is not my fault that the world is designed like that and that I am not smart enough to solve the problem and do what is <em>right</em>. I finally managed to ignore it. But this happens all the time and the result is never satisfactory. This process too often ends in simply ignoring the problem or becoming unwilling to do anything at all. What I'm doing is not effective it seems, it already stole years of my life in which I could have learnt mathematics or other important things or done what I would have liked to do. You might wonder, shouldn't this insight cause me to ignore subsequent problems and just learn something or do what I want to do, do something that is more effective? Nope, it is exactly the kind of mantra that LW teaches that always makes me <em>think</em> about <em>it</em> rather than ignoring the problem and trying to reach my goals. Namely that the low probability of a certain event might be outweighed by the possible positive or negative 'utility' that the problem implies, especially ethical considerations. What could happen if I just ignore it, if I instead pursue another goal?</p>\n<p>It's partly the choice that is killing me, do <em>X</em> or <em>Y </em>or continue thinking about either doing <em>X</em> or <em>Y</em>, or maybe search for some superior unknown unknown activity <em>Z</em>? For how long should I think about a decision and how long should I think about how long I should be thinking about it?&nbsp;Maybe the best analogy would be the browsing of Wikipedia on a subject that is unknown to you and over your head and clicking the first link to a page that explains a certain term you don't know just to repeat that process until you end up with 10 additional problems on an entry that is only vaguely&nbsp;relevant&nbsp;to the original problem you tried to solve. The problem is still there and you've to make the decision to ignore it, pursue it further or think about what to do.&nbsp;</p>\n<p>Recently I had blood&nbsp;vessel crack in my eye. Nothing to worry about, but I searched for it and became subsequently worried if something like that could happen in my brain too. It turned out that about 6 out of 100 people are&nbsp;predisposed for such brain&nbsp;aneurysms, especially people with high blood&nbsp;pressure. Now I might have a somewhat abnormal blood pressure and additional&nbsp;activity&nbsp;might make some blood&nbsp;vessel&nbsp;in my brain leak. Should I stop doing sports, should I even stop thinking too much because it increases the&nbsp;blood circulation in my brain (I noticed that I hear my blood flow when thinking too hard)? But how can I decide upon it without thinking? So I looked up on how to check if I was&nbsp;predisposed and it turned out that all tests are too risky. But maybe it would be rational to stop doing anything that could increase the blood pressure until there are less risky tests? And so I lost a few more days without accomplishing anything I wanted to accomplish.&nbsp;</p>\n<h3>How I feel about LW</h3>\n<p>LW makes me aware of various problems and tells me about how important it is to do this or that but it doesn't provide the tools to choose my instrumental goals.&nbsp;Thanks to LW I learnt about&nbsp;<a href=\"http://www.wisegeek.com/what-is-solomonoff-induction.htm\">Solomonoff induction</a>. Great...fascinating! But wait, I also learnt that there is a slight problem:&nbsp;<em>\"the <strong>only</strong> problem with Solomonoff induction is that it is incomputable\" </em>Phew, thanks for wasting my time!&nbsp;See what I mean?&nbsp;I'm not saying that there is something wrong with what LW is doing, but people like me are missing some mid-level decision procedures on how to approach all the implications. I wish LW would also be&nbsp;teaching utilizable rationality skills by exemplifying the application of rationality&nbsp;to, and the dissolving of, real-life&nbsp;problems via the breakdown of decision procedures.</p>\n<p>Take for example some of the <a href=\"/top/\">top scoring posts</a>. I&nbsp;intuitively&nbsp;understood them, agreed and upvoted them. My&nbsp;initial&nbsp;reaction was something along the lines of&nbsp;<em>\"wow great, those people think like me but are able to write down all I thought to be true.\"</em> Yes, great, but that doesn't help me. I'm not a politician who's going to create a new policy for <a href=\"/lw/2as/diseased_thinking_dissolving_questions_about/\">dealing with diseases</a>. Even if I was, that post would be completely useless because it is utopic and not implementable. The same could be said about most other posts. Awesome but almost completely useless when it comes to living your life. '<a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">Confidence levels inside and outside an argument</a>' was an really enlightening post but only made me even more uncertain. If there is often no reason to assume very low probabilities then I'm still left with the very high risks of various possibilities, just that they suddenly became much more likely in some cases.</p>\n<p>The problem with LW is that it tells me about those low probability high risk events. But I don't know enough to trust myself enough to overpower my gut feeling and my urge to do other things. I'd like to learn math etc., but maybe I should just work as baker or street builder to earn money to donate it to the SIAI? Maybe I should read the sequences to become more certain to be able to persuade myself? But maybe I should first learn some math to be able to read the sequences? But maybe I don't need that and would waste too much time learning math when I could earn money? And how do I know what math is important without reading the sequences? And what about what I really want to do,&nbsp;intuitively, should I just ignore <em>that</em>?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"TiEFKWDvD3jsKumDx": 2, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S8sNue3KzzWQpRjv5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 3, "extendedScore": null, "score": 6.868739441832235e-07, "legacy": true, "legacyId": "6098", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["895quRDaK6gR2rM82", "GrtbTAPfkJa4D6jjH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T01:03:12.097Z", "modifiedAt": null, "url": null, "title": "Positive Thinking", "slug": "positive-thinking", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:53.047Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B2Am5HfTCZqLrXd4x/positive-thinking", "pageUrlRelative": "/posts/B2Am5HfTCZqLrXd4x/positive-thinking", "linkUrl": "https://www.lesswrong.com/posts/B2Am5HfTCZqLrXd4x/positive-thinking", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Positive%20Thinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APositive%20Thinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2Am5HfTCZqLrXd4x%2Fpositive-thinking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Positive%20Thinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2Am5HfTCZqLrXd4x%2Fpositive-thinking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB2Am5HfTCZqLrXd4x%2Fpositive-thinking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1427, "htmlBody": "<p><!--StartFragment-->\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">If I were to take all of my friends and divide them into two groups, there are plenty of criteria I could choose, but probably the most relevant slice would be between my friends who believe in God, and my friends who don&rsquo;t. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Many in the believer group know each other as well. The evangelical Christian community in my city is fairly tight-knit. Every once in a while I&rsquo;ll meet someone new, I&rsquo;ll mention offhand something about church, it&rsquo;ll become the topic of conversation, and suddenly we discover that we share a dozen mutual friends. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">My non-believer friends come from all walks of life. My old friends from high school fit in this category; so do many of the friends I&rsquo;ve met through university or part-time jobs. There&rsquo;s no tight-knit community here. I wouldn&rsquo;t describe many of them as rationalists, particularly, but it seems that according to lesswrong doctrine, they are above the sanity waterline while my first friend group is below. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Something about this bothers me. Maybe it&rsquo;s because I find it so refreshing to be with a group of people who are relentlessly positive about life, who constantly remind one another to be positive, and who offer concrete help rather than judgement. Once, when another of our friends couldn&rsquo;t pay her rent, my Christian friend and I got up at four, took out five hundred dollars in cash at a convenience store, and biked to her house to leave it anonymously in her mailbox before I left for my six am shift at work. The high lasted all day. I can&rsquo;t think of any other community where this would happen, where it would even be socially acceptable. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I met people at church who had survived the worst circumstances; they had been abused, they had been addicts, they had been homeless. But aside from the concrete help they&rsquo;d found at church, they&rsquo;d found some kind of hope as well. They believed that they could succeed. I&rsquo;ve been incredibly lucky in my life, and I&rsquo;ve never had reason to doubt that I would succeed, or that people would be there to help me if I ever failed. But for people who&rsquo;ve only seen evidence that they will fail and be stepped on, the benefits of being told that God loves them unconditionally seem to be non-trivial. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Now to contrast with my non-religious friends; this isn&rsquo;t universally true, but I&rsquo;ve seen a trend of general negative-ness. This attitude can be self-directed, i.e. complaining about work or school or relationships without any effort to find solutions. I know some very unhappy people, and it seems insane to me that they just sit back and take it, month after month. The negative attitude can also be directed outwards into biting sarcasm and rude, judgemental comments about others. This often comes from people who seem happy enough with their own lives. Maybe I didn&rsquo;t notice this as much before I started going to church, where it became obvious in its absence. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I have the same tendencies to criticize and judge as anyone, but at least I notice them and try to keep them in check. I try to ask myself if it really helps to criticize someone. Does whatever I think they&rsquo;re doing wrong really affect me? Is it my business to correct them? Would they listen to criticism? If I&rsquo;m a reliable example, most people hate being criticized. It takes a conscious effort to step back and see criticism in a positive light. I try to take this step, and maybe most rationalists-in-the-making do the same, but that&rsquo;s not the general population, and starting with a criticism tends to close people off and put them on the defensive. The last question I ask myself is, do I want to help them by suggesting a change, or do I only want to vent my own frustration? Venting doesn&rsquo;t help them, and it doesn&rsquo;t help me, because for me anyway, focusing on the negative side of an issue tends to flip my entire mindset into the negative. And negative attitudes are contagious. If one person at work is ranting about a bad breakup or a fight with their family, I&rsquo;ll often catch myself brooding about someone or something I&rsquo;m annoyed with. If I&rsquo;m lucky and I&rsquo;m paying attention, I notice the subliminal messaging before it really gets to be. Sometimes I feel like barking &ldquo;hey, keep your problems to yourself, I&rsquo;m trying to be positive here.&rdquo; But again, if I&rsquo;m paying attention to my own reactions, I ask myself if it&rsquo;ll really help to snap at them, and the answer is no, so I&rsquo;ll try to be an understanding listener. <em></em></span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">These are things I do consciously, but since I stopped going to church regularly, I&rsquo;ve noticed that it&rsquo;s more of an effort. It feels like I&rsquo;m holding up a heavy weight alone, going through my day talking to roommates and classmates and co-workers who don&rsquo;t make any special effort to be positive or non-judgemental or helpful. And as soon as I let down my guard, I slip back into the trap of reacting to criticism defensively instead of constructively, of snapping back on reflex, of making excuses for why I was rude to someone or left my dirty dishes in the sink. I hate the way I act in this default mode, but it&rsquo;s easy to make excuses for that too. I tell myself that I&rsquo;m tired, that I&rsquo;m burnt out, that I can&rsquo;t be everything to everyone. I tell myself it&rsquo;s not fair that I try so much harder than everyone else. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">At church, there was a marked lack of excuses. The general attitude was that you could be as strong as you needed to be, because it wasn&rsquo;t your strength, it was God&rsquo;s strength. The way I see it, it was more the combined strength of a community united by a common ideal. It was like a self-help group, but without the stigma. (Maybe the stigma is imaginary; I just know that I have a negative emotional reaction to self-help books and websites. I know this is probably counterproductive, but I can&rsquo;t seem to get rid of it.) </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I talk to some of my friends, the non-religious ones, and I notice that maybe half the time they&rsquo;re grumpy or upset or angry or offended, and they don&rsquo;t stop to think about it, or take the step away that would allow them to question and overcome those feelings. My Christian friends aren&rsquo;t perfect, and they do occasionally slip into anger and frustration, but they often notice. They often bring it up afterwards, in front of the group, as an example of something they need to work on. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">This is why, even though I don&rsquo;t believe in God and would probably be incapable of it at this point, the last thing I want to do is judge people who believe. A lot of the time, they&rsquo;ve found something that <em>helps</em></span><span lang=\"EN-GB\"> them. This is why I found it instrumentally rational, for six months, to go to youth group once a week and sing songs about Jesus. Happiness is a hard thing to pin down, but I liked myself better during that time. It&rsquo;s easier to be generous when everyone is being generous around you; it&rsquo;s easier to be kind and helpful when everyone else is acting that way too. It feels like being held accountable. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I don&rsquo;t really know what this means. It&rsquo;s hard to generalize, because I&rsquo;m talking about people in my age group; most of us are poor and not settled in our lives, without firmly developed social networks. Maybe later on in life, people can make their own tight-knit communities without religion as binding glue; my parents, for example, have an incredibly extensive social group. And I certainly don&rsquo;t want to imply that all Christian organizations are as open and welcoming as the one I attended. I&rsquo;m sure than plenty of people have had bad experiences. But what I&rsquo;ve seen suggests to me that my church (a Pentacostal evangelical Christian group, by the way) served a function in our city that wasn&rsquo;t being filled by anything else. </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">It&rsquo;s limited, of course, by the fact that its founders believe the Bible is literally true, even if they don&rsquo;t apply that belief thoroughly. (This occasionally involves a tricky kind of doublethink, for example a person who denounces homosexuality when asked directly but who holds nothing against their homosexual friends.) Could the principles of rationality prompt a group of people to form this kind of community? I don&rsquo;t know. But until then, I&rsquo;m going to keep hanging out with Christians and sharing their positive thoughts.<span style=\"mso-spacerun: yes;\">&nbsp;&nbsp;</span></span></p>\n<!--EndFragment--></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1, "3ee9k6NJfcGzL6kMS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B2Am5HfTCZqLrXd4x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 28, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "6100", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 283, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T03:41:14.495Z", "modifiedAt": null, "url": null, "title": "ABC Radio National episode on the Singularity", "slug": "abc-radio-national-episode-on-the-singularity", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QWR2joAHiZjdvf9H6/abc-radio-national-episode-on-the-singularity", "pageUrlRelative": "/posts/QWR2joAHiZjdvf9H6/abc-radio-national-episode-on-the-singularity", "linkUrl": "https://www.lesswrong.com/posts/QWR2joAHiZjdvf9H6/abc-radio-national-episode-on-the-singularity", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20ABC%20Radio%20National%20episode%20on%20the%20Singularity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AABC%20Radio%20National%20episode%20on%20the%20Singularity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWR2joAHiZjdvf9H6%2Fabc-radio-national-episode-on-the-singularity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=ABC%20Radio%20National%20episode%20on%20the%20Singularity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWR2joAHiZjdvf9H6%2Fabc-radio-national-episode-on-the-singularity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQWR2joAHiZjdvf9H6%2Fabc-radio-national-episode-on-the-singularity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>I don't think this has been linked yet from Less Wrong: a <a href=\"http://www.abc.net.au/rn/allinthemind/stories/2009/2686321.htm\">September 2009 episode</a> of ABC Radio National's <em>All in the Mind</em>&nbsp;on the Singularity (guests include Bostrom and Hutter).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QWR2joAHiZjdvf9H6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6.86992011906882e-07, "legacy": true, "legacyId": "6108", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T04:35:49.416Z", "modifiedAt": null, "url": null, "title": "Lifeism, Anti-Deathism, and Some Other Terminal-Values Rambling", "slug": "lifeism-anti-deathism-and-some-other-terminal-values", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:32.225Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pavitra", "createdAt": "2009-09-22T08:32:44.250Z", "isAdmin": false, "displayName": "Pavitra"}, "userId": "yC2JgX3ENu7mionKh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9PWZDFdpBBbf7hSEg/lifeism-anti-deathism-and-some-other-terminal-values", "pageUrlRelative": "/posts/9PWZDFdpBBbf7hSEg/lifeism-anti-deathism-and-some-other-terminal-values", "linkUrl": "https://www.lesswrong.com/posts/9PWZDFdpBBbf7hSEg/lifeism-anti-deathism-and-some-other-terminal-values", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lifeism%2C%20Anti-Deathism%2C%20and%20Some%20Other%20Terminal-Values%20Rambling&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALifeism%2C%20Anti-Deathism%2C%20and%20Some%20Other%20Terminal-Values%20Rambling%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9PWZDFdpBBbf7hSEg%2Flifeism-anti-deathism-and-some-other-terminal-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lifeism%2C%20Anti-Deathism%2C%20and%20Some%20Other%20Terminal-Values%20Rambling%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9PWZDFdpBBbf7hSEg%2Flifeism-anti-deathism-and-some-other-terminal-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9PWZDFdpBBbf7hSEg%2Flifeism-anti-deathism-and-some-other-terminal-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 346, "htmlBody": "<p>(Apologies to RSS users: apparently there's no draft button, but only \"publish\" and \"publish-and-go-back-to-the-edit-screen\", misleadingly labeled.)</p>\n<p>&nbsp;</p>\n<p>You have a button. If you press it, a happy, fulfilled <a href=\"/lw/x4/nonperson_predicates/\">person</a> will be created in a sealed box, and then be painlessly garbage-collected fifteen minutes later. If asked, they would say that they're glad to have existed in spite of their mortality. Because they're sealed in a box, they will leave behind no bereaved friends or family. In short, this takes place in Magic Thought Experiment Land where externalities don't exist. Your choice is between creating a fifteen-minute-long happy life or not.</p>\n<p>Do you push the button?</p>\n<p>I <a href=\"/lw/x7/cant_unbirth_a_child/\">suspect</a> Eliezer would not, because it would increase the death-count of the universe by one. I would, because it would increase the life-count of the universe by fifteen minutes.</p>\n<p>&nbsp;</p>\n<p>Actually, that's an oversimplification of my position. I actually believe that the important part of any algorithm is its output, <a href=\"/lw/1hg/the_moral_status_of_independent_identical_copies\">additional copies</a> matter not at all, the net utility of the existence of a group of entities-whose-existence-constitutes-utility is equal to the maximum of the individual utilities, and the (terminal) utility of the existence of a particular computation is bounded below at zero. I would submit a large number of copies of myself to slavery and/or torture to gain moderate benefits to my primary copy.</p>\n<p>(What happens to the <a href=\"http://qntm.org/copy\">last copy of me</a>, of course, does affect the question of \"what computation occurs or not\". I would subject N out of N+1 copies of myself to torture, but not N out of N. Also, I would hesitate to torture copies of <em>other</em> people, on the grounds that there's a conflict of interest and I can't trust myself to reason honestly. I might feel differently after I'd been using my own fork-slaves for a while.)</p>\n<p>So the <em>real</em> value of pushing the button would be my warm fuzzies, which breaks the no-externalities assumption, so I'm indifferent.</p>\n<p>&nbsp;</p>\n<p>But nevertheless, even knowing about the heat death of the universe, knowing that anyone born must inevitably die, I do not consider it immoral to create a person, even if we assume all else equal.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9PWZDFdpBBbf7hSEg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 5, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "6109", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wqDRRx9RqwKLzWt7R", "gb6zWstjmkYHLrbrg", "DNyMJmLf5o26seqvX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T07:14:13.773Z", "modifiedAt": null, "url": null, "title": "Berkeley LW Meet-Up Saturday March 12", "slug": "berkeley-lw-meet-up-saturday-march-12", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:08.535Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HSk6scipyd3nXTyvG/berkeley-lw-meet-up-saturday-march-12", "pageUrlRelative": "/posts/HSk6scipyd3nXTyvG/berkeley-lw-meet-up-saturday-march-12", "linkUrl": "https://www.lesswrong.com/posts/HSk6scipyd3nXTyvG/berkeley-lw-meet-up-saturday-march-12", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Berkeley%20LW%20Meet-Up%20Saturday%20March%2012&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABerkeley%20LW%20Meet-Up%20Saturday%20March%2012%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSk6scipyd3nXTyvG%2Fberkeley-lw-meet-up-saturday-march-12%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Berkeley%20LW%20Meet-Up%20Saturday%20March%2012%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSk6scipyd3nXTyvG%2Fberkeley-lw-meet-up-saturday-march-12", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSk6scipyd3nXTyvG%2Fberkeley-lw-meet-up-saturday-march-12", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>ETA:&nbsp; Any Late-comers, We did end up in the VLSB.</p>\n<p>Hi all, it seems we've reach that time of the month, that time when we get together and be rational in Berkeley.&nbsp; As usual, we'll meet at the Starbucks at <span dir=\"ltr\"><a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">2128 Oxford Street</a> at 7 pm, then move into the atrium in the Valley Life Sciences Building on the Berkeley Campus.&nbsp; There'll be an expedition to get food, so don't feel that you have to eat before hand.</span></p>\n<p>I want to make a special plea to the lurkers on lesswrong to come, I promise no one will think poorly of you if you're still in High School, aren't a member of Mensa, or haven't read the sequences.&nbsp; This is a social event where we get together with people who like rationality, not a way for the shadowy cabal of beisutsukai to puzzle out the secret of <a href=\"/lw/qt/class_project\">quantum gravity</a><em>.</em>&nbsp; Even if you only just linked here from Methods of Rationality, I and everyone else here wants to get to know you.</p>\n<p>Hope to see you all there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HSk6scipyd3nXTyvG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "6111", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xAXrEpF5FYjwqKMfZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T07:21:32.038Z", "modifiedAt": null, "url": null, "title": "Bring Back the Sequences?", "slug": "bring-back-the-sequences", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:23.102Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WXgEQZL2yYmhHjKmn/bring-back-the-sequences", "pageUrlRelative": "/posts/WXgEQZL2yYmhHjKmn/bring-back-the-sequences", "linkUrl": "https://www.lesswrong.com/posts/WXgEQZL2yYmhHjKmn/bring-back-the-sequences", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bring%20Back%20the%20Sequences%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABring%20Back%20the%20Sequences%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXgEQZL2yYmhHjKmn%2Fbring-back-the-sequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bring%20Back%20the%20Sequences%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXgEQZL2yYmhHjKmn%2Fbring-back-the-sequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXgEQZL2yYmhHjKmn%2Fbring-back-the-sequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 227, "htmlBody": "<p>Given that&nbsp;</p>\n<p>1. Deciding to read and actually reading the sequences is 'work'</p>\n<p>2. Reading the latest frontpaged article on LessWrong is 'fun'</p>\n<p>3. We frequently have gaps in the posting rate of articles that make it to the front page</p>\n<p>4. There are many people who joined this community after the sequences were written and haven't gone through all of them</p>\n<p>...would it make sense to start bringing articles from the sequences to the front page, either at a set pace or whenever there is a gap in posting?</p>\n<p>I have actually read most of the sequences, but wouldn't mind going through them once again. However, taking it up as a project seems like too much work. By bringing an article to the front page, either with the old comment thread or with a fresh one (plus a reference to the old one), it becomes something that the community is doing. Following things that a group you belong to is doing is fun. But for that to happen, we need to share a common pointer to which article is 'the one we are reading now'. Hence, the front page.</p>\n<p>In short, I think if people in this community reading (and re-reading) more of the sequences is something we want, then recycling them through the front page is also a good idea.</p>\n<p>If the barrier is implementation modifications needed, I may be able to assist.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WXgEQZL2yYmhHjKmn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 62, "extendedScore": null, "score": 0.00012462607415874075, "legacy": true, "legacyId": "6113", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T07:49:26.124Z", "modifiedAt": null, "url": null, "title": "[Link] John Baez interviews Eliezer", "slug": "link-john-baez-interviews-eliezer", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.568Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tjQZyvCdGzCJKPaao/link-john-baez-interviews-eliezer", "pageUrlRelative": "/posts/tjQZyvCdGzCJKPaao/link-john-baez-interviews-eliezer", "linkUrl": "https://www.lesswrong.com/posts/tjQZyvCdGzCJKPaao/link-john-baez-interviews-eliezer", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20John%20Baez%20interviews%20Eliezer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20John%20Baez%20interviews%20Eliezer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjQZyvCdGzCJKPaao%2Flink-john-baez-interviews-eliezer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20John%20Baez%20interviews%20Eliezer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjQZyvCdGzCJKPaao%2Flink-john-baez-interviews-eliezer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtjQZyvCdGzCJKPaao%2Flink-john-baez-interviews-eliezer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p>First part: \"<a href=\"http://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/\">This Week's Finds (Week 311)</a>\".</p>\n<p>Second part: \"<a href=\"http://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/\">This Week's Finds (Week 312)</a>\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tjQZyvCdGzCJKPaao", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 6.870591185250909e-07, "legacy": true, "legacyId": "6115", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T15:42:35.304Z", "modifiedAt": null, "url": null, "title": "TopicTitle'); DROP TABLE Users EXCEPT (AdeleneDawner OR Kevin); --", "slug": "topictitle-drop-table-users-except-adelenedawner-or-kevin", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:54.292Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Clippy", "createdAt": "2009-11-20T22:03:59.329Z", "isAdmin": false, "displayName": "Clippy"}, "userId": "rtYXiT9eAvEKavjAx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CRiz8xT5bZLXgSjXb/topictitle-drop-table-users-except-adelenedawner-or-kevin", "pageUrlRelative": "/posts/CRiz8xT5bZLXgSjXb/topictitle-drop-table-users-except-adelenedawner-or-kevin", "linkUrl": "https://www.lesswrong.com/posts/CRiz8xT5bZLXgSjXb/topictitle-drop-table-users-except-adelenedawner-or-kevin", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20TopicTitle')%3B%20DROP%20TABLE%20Users%20EXCEPT%20(AdeleneDawner%20OR%20Kevin)%3B%20--&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATopicTitle')%3B%20DROP%20TABLE%20Users%20EXCEPT%20(AdeleneDawner%20OR%20Kevin)%3B%20--%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCRiz8xT5bZLXgSjXb%2Ftopictitle-drop-table-users-except-adelenedawner-or-kevin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=TopicTitle')%3B%20DROP%20TABLE%20Users%20EXCEPT%20(AdeleneDawner%20OR%20Kevin)%3B%20--%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCRiz8xT5bZLXgSjXb%2Ftopictitle-drop-table-users-except-adelenedawner-or-kevin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCRiz8xT5bZLXgSjXb%2Ftopictitle-drop-table-users-except-adelenedawner-or-kevin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>--;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CRiz8xT5bZLXgSjXb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 1, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "6121", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-07T16:37:02.357Z", "modifiedAt": null, "url": null, "title": "Chicago Meetup - Sunday March 13", "slug": "chicago-meetup-sunday-march-13", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.944Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Airedale", "createdAt": "2010-03-14T19:20:44.438Z", "isAdmin": false, "displayName": "Airedale"}, "userId": "iQo3csv2cgdsjfLnY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6hDkhWSWKQpWFWbtW/chicago-meetup-sunday-march-13", "pageUrlRelative": "/posts/6hDkhWSWKQpWFWbtW/chicago-meetup-sunday-march-13", "linkUrl": "https://www.lesswrong.com/posts/6hDkhWSWKQpWFWbtW/chicago-meetup-sunday-march-13", "postedAtFormatted": "Monday, March 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Chicago%20Meetup%20-%20Sunday%20March%2013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChicago%20Meetup%20-%20Sunday%20March%2013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hDkhWSWKQpWFWbtW%2Fchicago-meetup-sunday-march-13%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Chicago%20Meetup%20-%20Sunday%20March%2013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hDkhWSWKQpWFWbtW%2Fchicago-meetup-sunday-march-13", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6hDkhWSWKQpWFWbtW%2Fchicago-meetup-sunday-march-13", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif]--></p>\n<p><a href=\"/user/steven0461/\"><a id=\"more\"></a>Steven0461</a> and I will host a meetup this Sunday, March 13, starting at 3 pm, at the <a href=\"http://www.elephantcastle.com/chicago_adams\">Elephant &amp; Castle Pub</a> on 111 West Adams Street.<span>&nbsp; </span>(Note: there&rsquo;s more than one Elephant &amp; Castle in Chicago, so you may want to check the address even if you think you know the pub.) <span>&nbsp;</span>We'll put up a sign saying \"LessWrong.\"&nbsp; We also have a <a href=\"http://groups.google.com/group/less-wrong-chicago?pli=1\">Google Group</a> where you can sign up to receive information about future meetups even if you can&rsquo;t make this one.&nbsp; Hope to see both new and familiar faces there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6hDkhWSWKQpWFWbtW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.872018106500883e-07, "legacy": true, "legacyId": "6122", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-08T08:38:02.858Z", "modifiedAt": null, "url": null, "title": "Open Thread, March 2011", "slug": "open-thread-march-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:08.144Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ze5NRXRGoRdwEfTzf/open-thread-march-2011", "pageUrlRelative": "/posts/Ze5NRXRGoRdwEfTzf/open-thread-march-2011", "linkUrl": "https://www.lesswrong.com/posts/Ze5NRXRGoRdwEfTzf/open-thread-march-2011", "postedAtFormatted": "Tuesday, March 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20March%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20March%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZe5NRXRGoRdwEfTzf%2Fopen-thread-march-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20March%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZe5NRXRGoRdwEfTzf%2Fopen-thread-march-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZe5NRXRGoRdwEfTzf%2Fopen-thread-march-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif;\"> </span></p>\n<h2 style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0.75em; margin-left: 0px; color: #538d4d; font-size: 1.3333em; line-height: 11px;\"><span style=\"line-height: 19px; font-size: small; color: #000000; font-weight: normal;\">Has been a lot of open threads in the past, but not recently. It is for the discussion of Less Wrong topics that have not appeared in recent posts. If a discussion gets good enough, open a new top-level post. Besides, I have an issue to discuss it here. Enjoy!</span></h2>\n<p><span style=\"line-height: 19px; font-size: small; color: #000000; font-weight: normal;\"><br /></span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ze5NRXRGoRdwEfTzf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 6.874618531774753e-07, "legacy": true, "legacyId": "6123", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 64, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-08T10:58:46.704Z", "modifiedAt": null, "url": null, "title": "[link] Why an Intelligence Explosion is Probable", "slug": "link-why-an-intelligence-explosion-is-probable", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:55.592Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iNxdDhmZxx6c5hrgg/link-why-an-intelligence-explosion-is-probable", "pageUrlRelative": "/posts/iNxdDhmZxx6c5hrgg/link-why-an-intelligence-explosion-is-probable", "linkUrl": "https://www.lesswrong.com/posts/iNxdDhmZxx6c5hrgg/link-why-an-intelligence-explosion-is-probable", "postedAtFormatted": "Tuesday, March 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Why%20an%20Intelligence%20Explosion%20is%20Probable&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Why%20an%20Intelligence%20Explosion%20is%20Probable%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNxdDhmZxx6c5hrgg%2Flink-why-an-intelligence-explosion-is-probable%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Why%20an%20Intelligence%20Explosion%20is%20Probable%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNxdDhmZxx6c5hrgg%2Flink-why-an-intelligence-explosion-is-probable", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiNxdDhmZxx6c5hrgg%2Flink-why-an-intelligence-explosion-is-probable", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/</p>\n<p>Briefly surveys various proposed main bottlenecks for an intelligence explosion, and argues that none of them is going to be a major one:</p>\n<ol>\n<li><em>Economic growth rate</em></li>\n<li><em>Investment availability</em></li>\n<li><em>Gathering of empirical information (experimentation, interacting with an environment)</em></li>\n<li><em>Software complexity</em></li>\n<li><em>Hardware demands vs. available hardware</em></li>\n<li><em>Bandwidth</em></li>\n<li><em>Lightspeed lags</em></li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iNxdDhmZxx6c5hrgg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 6.874999486135571e-07, "legacy": true, "legacyId": "6133", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-08T14:48:54.904Z", "modifiedAt": null, "url": null, "title": "How to improve the public perception of the SIAI and LW?", "slug": "how-to-improve-the-public-perception-of-the-siai-and-lw", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.645Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EzH64G6k39XwiQCwJ/how-to-improve-the-public-perception-of-the-siai-and-lw", "pageUrlRelative": "/posts/EzH64G6k39XwiQCwJ/how-to-improve-the-public-perception-of-the-siai-and-lw", "linkUrl": "https://www.lesswrong.com/posts/EzH64G6k39XwiQCwJ/how-to-improve-the-public-perception-of-the-siai-and-lw", "postedAtFormatted": "Tuesday, March 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20improve%20the%20public%20perception%20of%20the%20SIAI%20and%20LW%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20improve%20the%20public%20perception%20of%20the%20SIAI%20and%20LW%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEzH64G6k39XwiQCwJ%2Fhow-to-improve-the-public-perception-of-the-siai-and-lw%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20improve%20the%20public%20perception%20of%20the%20SIAI%20and%20LW%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEzH64G6k39XwiQCwJ%2Fhow-to-improve-the-public-perception-of-the-siai-and-lw", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEzH64G6k39XwiQCwJ%2Fhow-to-improve-the-public-perception-of-the-siai-and-lw", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 505, "htmlBody": "<p>I was recently thinking about the possibility that someone with a lot of influence might at some point try to damage LessWrong and the SIAI and what preemptive&nbsp;measures one could take to&nbsp;counter it.</p>\n<p>If you believe that the SIAI does the most important work in the universe and if you believe that LessWrong serves the purpose of educating people to become more rational and subsequently understand the importance of trying to mitigate risks from AI, then you should care about public relations, you should try to communicate your honesty and&nbsp;well-intentioned motives as effectively as possible.</p>\n<p>Public relations are very important because a good reputation is necessary to do the following:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>Making people read the Sequences.</li>\n<li>Raising money for the SIAI.</li>\n<li>Convincing people to take risks from AI seriously.</li>\n<li>Allowing the SIAI to influence other AGI researchers.</li>\n<li>Mitigating future opposition by politicians and other interest groups.</li>\n<li>Being no easy target for criticism.</li>\n</ul>\n<h3>An attack scenario</h3>\n<p>First one has to identify characteristics that could&nbsp;potentially&nbsp;be used to cast a damaging light on this community. Here the most obvious possibility seems to be to portray the SIAI, together with LessWrong, as a cult.</p>\n<p>After some superficial examination an outsider might conclude the following about this community:</p>\n<ul>\n<li>Believing into heaven and hell in the form of a positive or negative&nbsp;Singularity.</li>\n<li>Discouraging <a href=\"/lw/1ww/undiscriminating_skepticism/\">skepticism</a>&nbsp;while&nbsp;portraying their own standpoint as clear-cut. &nbsp;</li>\n<li>Encouraging to <a href=\"/lw/2l6/taking_ideas_seriously/\">take <em>ideas</em> seriously</a>.</li>\n<li><a href=\"/lw/3h/why_our_kind_cant_cooperate\">Encouraging</a>&nbsp;and&nbsp;<a href=\"/lw/3gy/tallinnevans_125000_singularity_challenge/\">signaling</a>&nbsp;strong cooperation&nbsp;and conformity.</li>\n<li><a href=\"http://multiverseaccordingtoben.blogspot.com/2010/10/singularity-institutes-scary-idea-and.html\">Evangelizing by scaring people</a> and telling them to <a href=\"http://vimeo.com/8586168\">donate money</a>.</li>\n<li>Social&nbsp;pressure&nbsp;by employing a reputation system with positive and negative incentive.</li>\n<li><a href=\"/lw/1ph/youre_entitled_to_arguments_but_not_that/\">Removing themselves</a> from empirical criticism by framing everything as a <a href=\"http://wiki.lesswrong.com/wiki/Antiprediction\">prediction</a>.</li>\n<li><a href=\"/lw/4ox/a_brief_overview_of_machine_ethics/3mrg\">Discrediting mainstream experts</a> while placing themselves a level above them.</li>\n<li>Discouraging&nbsp;transparency and&nbsp;openness by&nbsp;referring&nbsp;to the dangers of AI research.</li>\n<li>Using scope insensitivity and high-risk to <a href=\"/lw/kn/torture_vs_dust_specks/uf7\">justify action</a>,&nbsp;outweigh low probabilities and disregard opposing evidence.&nbsp;</li>\n</ul>\n<p>Most of this might sound wrong to the well-read LessWrong reader. But how would those points be received by&nbsp;mediocre&nbsp;rationalists who don't know <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">what <em>you</em> know</a>, especially if eloquently&nbsp;summarized by a famous and respected person?</p>\n<h3>Preemptive measures</h3>\n<p>How one might counter such conclusions:</p>\n<ul>\n<li>Create an&nbsp;introductory&nbsp;guide to LessWrong.</li>\n<li>Explain why the context of the Sequences is important.</li>\n<li>Explain why LessWrong differs from mainstream skepticism.&nbsp;</li>\n<li>Enable and encourage outsiders to challenge and question the community before turning against it.</li>\n<li>Discourage the downvoting of people who have not yet read the Sequences.</li>\n<li>Don't expect people to read hundreds of posts without <a href=\"/lw/304/what_i_would_like_the_siai_to_publish/2vnb\">supporting evidence that it is worth it</a>.&nbsp;</li>\n<li>Avoid jargon when talking to outsiders.</li>\n<li>Detach LessWrong from the SIAI by creating an additional platform to talk about related issues.</li>\n<li>Ask or pay independent experts to peer-review.</li>\n<li>Make the finances of the SIAI easily accessible.</li>\n<li>Openly explain why and for what the SIAI <em>currently</em>&nbsp;needs <em>more</em>&nbsp;money.</li>\n</ul>\n<p>So what do <em>you</em> think needs improvement and what would you do about it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EzH64G6k39XwiQCwJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 15, "extendedScore": null, "score": 6.875619829049474e-07, "legacy": true, "legacyId": "6134", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I was recently thinking about the possibility that someone with a lot of influence might at some point try to damage LessWrong and the SIAI and what preemptive&nbsp;measures one could take to&nbsp;counter it.</p>\n<p>If you believe that the SIAI does the most important work in the universe and if you believe that LessWrong serves the purpose of educating people to become more rational and subsequently understand the importance of trying to mitigate risks from AI, then you should care about public relations, you should try to communicate your honesty and&nbsp;well-intentioned motives as effectively as possible.</p>\n<p>Public relations are very important because a good reputation is necessary to do the following:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>Making people read the Sequences.</li>\n<li>Raising money for the SIAI.</li>\n<li>Convincing people to take risks from AI seriously.</li>\n<li>Allowing the SIAI to influence other AGI researchers.</li>\n<li>Mitigating future opposition by politicians and other interest groups.</li>\n<li>Being no easy target for criticism.</li>\n</ul>\n<h3 id=\"An_attack_scenario\">An attack scenario</h3>\n<p>First one has to identify characteristics that could&nbsp;potentially&nbsp;be used to cast a damaging light on this community. Here the most obvious possibility seems to be to portray the SIAI, together with LessWrong, as a cult.</p>\n<p>After some superficial examination an outsider might conclude the following about this community:</p>\n<ul>\n<li>Believing into heaven and hell in the form of a positive or negative&nbsp;Singularity.</li>\n<li>Discouraging <a href=\"/lw/1ww/undiscriminating_skepticism/\">skepticism</a>&nbsp;while&nbsp;portraying their own standpoint as clear-cut. &nbsp;</li>\n<li>Encouraging to <a href=\"/lw/2l6/taking_ideas_seriously/\">take <em>ideas</em> seriously</a>.</li>\n<li><a href=\"/lw/3h/why_our_kind_cant_cooperate\">Encouraging</a>&nbsp;and&nbsp;<a href=\"/lw/3gy/tallinnevans_125000_singularity_challenge/\">signaling</a>&nbsp;strong cooperation&nbsp;and conformity.</li>\n<li><a href=\"http://multiverseaccordingtoben.blogspot.com/2010/10/singularity-institutes-scary-idea-and.html\">Evangelizing by scaring people</a> and telling them to <a href=\"http://vimeo.com/8586168\">donate money</a>.</li>\n<li>Social&nbsp;pressure&nbsp;by employing a reputation system with positive and negative incentive.</li>\n<li><a href=\"/lw/1ph/youre_entitled_to_arguments_but_not_that/\">Removing themselves</a> from empirical criticism by framing everything as a <a href=\"http://wiki.lesswrong.com/wiki/Antiprediction\">prediction</a>.</li>\n<li><a href=\"/lw/4ox/a_brief_overview_of_machine_ethics/3mrg\">Discrediting mainstream experts</a> while placing themselves a level above them.</li>\n<li>Discouraging&nbsp;transparency and&nbsp;openness by&nbsp;referring&nbsp;to the dangers of AI research.</li>\n<li>Using scope insensitivity and high-risk to <a href=\"/lw/kn/torture_vs_dust_specks/uf7\">justify action</a>,&nbsp;outweigh low probabilities and disregard opposing evidence.&nbsp;</li>\n</ul>\n<p>Most of this might sound wrong to the well-read LessWrong reader. But how would those points be received by&nbsp;mediocre&nbsp;rationalists who don't know <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">what <em>you</em> know</a>, especially if eloquently&nbsp;summarized by a famous and respected person?</p>\n<h3 id=\"Preemptive_measures\">Preemptive measures</h3>\n<p>How one might counter such conclusions:</p>\n<ul>\n<li>Create an&nbsp;introductory&nbsp;guide to LessWrong.</li>\n<li>Explain why the context of the Sequences is important.</li>\n<li>Explain why LessWrong differs from mainstream skepticism.&nbsp;</li>\n<li>Enable and encourage outsiders to challenge and question the community before turning against it.</li>\n<li>Discourage the downvoting of people who have not yet read the Sequences.</li>\n<li>Don't expect people to read hundreds of posts without <a href=\"/lw/304/what_i_would_like_the_siai_to_publish/2vnb\">supporting evidence that it is worth it</a>.&nbsp;</li>\n<li>Avoid jargon when talking to outsiders.</li>\n<li>Detach LessWrong from the SIAI by creating an additional platform to talk about related issues.</li>\n<li>Ask or pay independent experts to peer-review.</li>\n<li>Make the finances of the SIAI easily accessible.</li>\n<li>Openly explain why and for what the SIAI <em>currently</em>&nbsp;needs <em>more</em>&nbsp;money.</li>\n</ul>\n<p>So what do <em>you</em> think needs improvement and what would you do about it?</p>", "sections": [{"title": "An attack scenario", "anchor": "An_attack_scenario", "level": 1}, {"title": "Preemptive measures", "anchor": "Preemptive_measures", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "35 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Jko7pt7MwwTBrfG3A", "Q8jyAdRYbieK8PtfT", "7FzD7pNm9X68Gp5ZC", "aqyLxWzAEpDHm2Xyf", "vqbieD9PHG8RRJddu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-08T15:18:33.538Z", "modifiedAt": null, "url": null, "title": "How best to show dying is bad", "slug": "how-best-to-show-dying-is-bad", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.325Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Zvi", "createdAt": "2009-03-31T20:54:54.077Z", "isAdmin": false, "displayName": "Zvi"}, "userId": "N9zj5qpTfqmbn9dro", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SLjSHPCFiznf5w3DH/how-best-to-show-dying-is-bad", "pageUrlRelative": "/posts/SLjSHPCFiznf5w3DH/how-best-to-show-dying-is-bad", "linkUrl": "https://www.lesswrong.com/posts/SLjSHPCFiznf5w3DH/how-best-to-show-dying-is-bad", "postedAtFormatted": "Tuesday, March 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20best%20to%20show%20dying%20is%20bad&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20best%20to%20show%20dying%20is%20bad%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLjSHPCFiznf5w3DH%2Fhow-best-to-show-dying-is-bad%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20best%20to%20show%20dying%20is%20bad%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLjSHPCFiznf5w3DH%2Fhow-best-to-show-dying-is-bad", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLjSHPCFiznf5w3DH%2Fhow-best-to-show-dying-is-bad", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 464, "htmlBody": "<div id=\":va\" class=\"ii gt\">\n<div id=\":wn\">\n<div>\n<div><span style=\"font-family: Arial; font-size: x-small;\">I've been trying to convince my father to support the cause, and ran into resistance on a front that I didn't expect. It's hard to tell how much he's looking for an argument and how much he actually believes what he's advocating, but he doesn't display any behavior that would contradict him believing it and several of us (LauraABJ, SarahC and Andrew) were on hand and unable to shake him. </span></div>\n<div>Today he emailed me these \"Thoughts on Immortality\"<br /></div>\n<div><span style=\"font-family: Arial; font-size: x-small;\"><ol style=\"margin-top: 0in;\" type=\"1\">\n<li class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman; font-size: small;\">Our not wanting to die is a bit of irrational behavior selected for by evolution.<span>&nbsp; </span>The universe doesn&rsquo;t care if you&rsquo;re there or not.<span>&nbsp; </span>The contrasting idea that you are the universe is mystical, not rational.</span></li>\n<li class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman; font-size: small;\">The idea that you are alive &ldquo;now&rdquo; but will be dead &ldquo;later&rdquo; is irrational. <span>&nbsp;</span>Time is just a persistent illusion according to relativistic physics.<span>&nbsp; </span>You are alive and dead, period.</span></li>\n<li class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman; font-size: small;\">A cyber-replica is not you. <span>&nbsp;</span>If one were made and stood next to you, you would still not consent to be shot.</span></li>\n<li class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman; font-size: small;\">Ditto a meat replica</span></li>\n<li class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman; font-size: small;\">If you believe the many worlds model of quantum physics is true (Eliezer does), then there already are a vitually infinite number of replicas of you already, so why bother making another one?</span></li>\n</ol></span></div>\n<div>Given we'd already been over this several times I decided to try a different approach this tme, so this was my completely off-the-cuff reply:</div>\n<div>\"Are you here to have an argument? I'm sorry, this is abuse.<br /><br />Terminal values and preferences are not rational or irrational. They simply are your preferences. I want a pizza. If I get a pizza, that won't make me consent to get shot. I still want a pizza. There are a virtually infinite number of me that DO have a pizza. I still want a pizza. The pizza from a certain point of view won't exist, and neither will I, by the time I get to eat some of it. I still want a pizza, damn it.<br /> <br />Of course, if you think all of that is irrational, then by all means don't order the pizza. More for me.\"</div>\n</div>\n<div>He's effectively an atheist so no need to worry about that angle. He would be a potentially strong asset were he to come around, and I hate to see him sit around without hope effectively waiting to die; when he tries to do good he doesn't exactly give to the Society for Cute Kittens and Rare Diseases but he's accomplishing far less than he could. I also would feel better knowing he fully supported my signing up for Alcor. More generally, I'd like to figure out how to pierce this sort of argument in a way that makes the person in question actually change his mind.</div>\n<div>What else would you try?<br /></div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1, "jiuackr7B5JAetbF6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SLjSHPCFiznf5w3DH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 25, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "6135", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-08T21:07:13.936Z", "modifiedAt": null, "url": null, "title": "Why not just write failsafe rules into the superintelligent machine?", "slug": "why-not-just-write-failsafe-rules-into-the-superintelligent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:24.520Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9BSZDBXQFgKsibBBd/why-not-just-write-failsafe-rules-into-the-superintelligent", "pageUrlRelative": "/posts/9BSZDBXQFgKsibBBd/why-not-just-write-failsafe-rules-into-the-superintelligent", "linkUrl": "https://www.lesswrong.com/posts/9BSZDBXQFgKsibBBd/why-not-just-write-failsafe-rules-into-the-superintelligent", "postedAtFormatted": "Tuesday, March 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20not%20just%20write%20failsafe%20rules%20into%20the%20superintelligent%20machine%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20not%20just%20write%20failsafe%20rules%20into%20the%20superintelligent%20machine%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BSZDBXQFgKsibBBd%2Fwhy-not-just-write-failsafe-rules-into-the-superintelligent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20not%20just%20write%20failsafe%20rules%20into%20the%20superintelligent%20machine%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BSZDBXQFgKsibBBd%2Fwhy-not-just-write-failsafe-rules-into-the-superintelligent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BSZDBXQFgKsibBBd%2Fwhy-not-just-write-failsafe-rules-into-the-superintelligent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 59, "htmlBody": "<p>Many <a href=\"http://bigthink.com/ideas/24406\">people</a> think you can solve the Friendly AI problem just by writing certain failsafe rules into the superintelligent machine's programming, like Asimov's Three Laws of Robotics. I thought the rebuttal to this was in \"<a href=\"http://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf\">Basic AI Drives</a>\" or one of <a href=\"http://intelligence.org/upload/CFAI.html\">Yudkowsky's</a> <a href=\"http://intelligence.org/upload/CEV.html\">major</a> <a href=\"http://intelligence.org/upload/artificial-intelligence-risk.pdf\">articles</a>, but after skimming them, I haven't found it. Where are the arguments concerning this suggestion?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9BSZDBXQFgKsibBBd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 6.876646984335691e-07, "legacy": true, "legacyId": "6137", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 81, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T01:17:00.485Z", "modifiedAt": null, "url": null, "title": "Less Wrong at Burning Man 2011", "slug": "less-wrong-at-burning-man-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:21.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FZMJRau2GeffqZN3d/less-wrong-at-burning-man-2011", "pageUrlRelative": "/posts/FZMJRau2GeffqZN3d/less-wrong-at-burning-man-2011", "linkUrl": "https://www.lesswrong.com/posts/FZMJRau2GeffqZN3d/less-wrong-at-burning-man-2011", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20at%20Burning%20Man%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20at%20Burning%20Man%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZMJRau2GeffqZN3d%2Fless-wrong-at-burning-man-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20at%20Burning%20Man%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZMJRau2GeffqZN3d%2Fless-wrong-at-burning-man-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFZMJRau2GeffqZN3d%2Fless-wrong-at-burning-man-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>Plans are in the works for a LW/Singularity themed Burning Man camp. <a href=\"/lw/2mp/burning_man_meetup_bayes_camp/\">Last year</a> was a&nbsp;tremendous&nbsp;success, with only one casualty. This year we will have an actual theme camp on the map.</p>\n<p>We are at the point in the planning where we need an approximate estimate of number of people. If you want to camp with us or might want to camp with us, let us know. &nbsp;All are welcomed.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FZMJRau2GeffqZN3d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 6.877323499515979e-07, "legacy": true, "legacyId": "6138", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Sfir5pFYgXJ8PEbwP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T07:13:47.021Z", "modifiedAt": null, "url": null, "title": "Lokhorst, 'Computational Meta-ethics' (2011)", "slug": "lokhorst-computational-meta-ethics-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.817Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AghFMRHmrhSuyxt6q/lokhorst-computational-meta-ethics-2011", "pageUrlRelative": "/posts/AghFMRHmrhSuyxt6q/lokhorst-computational-meta-ethics-2011", "linkUrl": "https://www.lesswrong.com/posts/AghFMRHmrhSuyxt6q/lokhorst-computational-meta-ethics-2011", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lokhorst%2C%20'Computational%20Meta-ethics'%20(2011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALokhorst%2C%20'Computational%20Meta-ethics'%20(2011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAghFMRHmrhSuyxt6q%2Flokhorst-computational-meta-ethics-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lokhorst%2C%20'Computational%20Meta-ethics'%20(2011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAghFMRHmrhSuyxt6q%2Flokhorst-computational-meta-ethics-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAghFMRHmrhSuyxt6q%2Flokhorst-computational-meta-ethics-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<p>Besides <a href=\"http://intelligence.org/upload/CEV.html\">Yudkowsky</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Goertzel-GOLEM-Toward-an-AGI-Meta-Architecture-Enabling-Both-Goal-Preservation-and-Radical-Self-Improvement.pdf\">Goertzel</a>, the only person I know of doing serious computational meta-ethics is Dutch philosopher and computer scientist <a href=\"http://homepages.ipact.nl/~lokhorst/english.html\">Gert-Jan Lokhorst</a>. He has a paper forthcoming in <em>Minds and Machines</em>&nbsp;called \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lokhorst-Computational-meta-ethics-toward-the-meta-ethical-robot.pdf\">Computational Meta-Ethics: Towards the Meta-Ethical Robot</a>.\" I suspect it wil be of interest to some.</p>\n<p>His paper also mentions some work in <a href=\"/lw/3n0/an_overview_of_formal_epistemology_links/\">formal epistemology</a> on <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Fitelson-Steps-Toward-a-Computational-Metaphysics.pdf\">computational metaphysics</a> and <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Rabe-Solving-the-100-Modal-Logic-Challenge.pdf\">computational meta-modal logic</a>. Ah, the pleasures of <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">scholarship</a>! (You're all tired of me harping on about scholarship, right?)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AghFMRHmrhSuyxt6q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 20, "extendedScore": null, "score": 6.878290025799606e-07, "legacy": true, "legacyId": "6148", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BXot7wxNbipyM749o", "64FdKLwmea8MCLWkE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T13:39:37.730Z", "modifiedAt": null, "url": null, "title": "John Baez on Charity", "slug": "john-baez-on-charity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:19.869Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cFs5R9RkAGt99jaJw/john-baez-on-charity", "pageUrlRelative": "/posts/cFs5R9RkAGt99jaJw/john-baez-on-charity", "linkUrl": "https://www.lesswrong.com/posts/cFs5R9RkAGt99jaJw/john-baez-on-charity", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20John%20Baez%20on%20Charity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJohn%20Baez%20on%20Charity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcFs5R9RkAGt99jaJw%2Fjohn-baez-on-charity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=John%20Baez%20on%20Charity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcFs5R9RkAGt99jaJw%2Fjohn-baez-on-charity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcFs5R9RkAGt99jaJw%2Fjohn-baez-on-charity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 619, "htmlBody": "<p><a href=\"http://math.ucr.edu/home/baez/SERIOUS.html\">Mathematician</a> and <a href=\"http://www.azimuthproject.org/azimuth/show/Azimuth+Project\">climate activist</a> <a href=\"http://en.wikipedia.org/wiki/John_C._Baez\">John Baez</a> finally <a href=\"http://johncarlosbaez.wordpress.com/2011/02/28/this-weeks-finds-week-310/#comment-4496\">commented</a> on charitable giving. I think the <a href=\"http://www.takeonit.com/question/337.aspx\">opinion of highly educated experts</a> who are not closely associated with LessWrong or the SIAI but <a href=\"/r/discussion/lw/4n7/link_john_baez_interview_with_astrophysicist/3mk3\">have read most of the available material</a> is important to estimate the public and academic perception of risks from AI and the effectiveness with which the risks are communicated by LessWrong and the SIAI.&nbsp;</p>\n<p><strong>Desertopa</strong> <a href=\"http://johncarlosbaez.wordpress.com/2011/02/28/this-weeks-finds-week-310/#comment-4485\">asked</a>:</p>\n<blockquote>\n<p>[...] if I asked what you would do with $100,000 if it were given to you on the condition that you donate it to a charity of your choice?</p>\n</blockquote>\n<p><strong>John Baez</strong> <a href=\"http://johncarlosbaez.wordpress.com/2011/02/28/this-weeks-finds-week-310/#comment-4496\">replied</a>:</p>\n<blockquote>\n<p>[...] it&rsquo;s good that you added the clause &ldquo;on the condition that you donate it to a charity of your own choice&rdquo;, because I was all ready with the answer in case you left that out: I&rsquo;d have said &ldquo;I&rsquo;ll save the money for my retirement&rdquo;. Given the shaky state of California&rsquo;s economy, I don&rsquo;t trust the U.C. pension system very much anymore.</p>\n<p>Since I haven&rsquo;t ever been in the position to donate lots of money to a charity, I haven&rsquo;t thought much about your question. I want to tackle it when I rewrite my will, but I haven&rsquo;t yet. So, I don&rsquo;t have an answer ready.</p>\n<p>If you held a gun against my head and forced me to answer without further thought, I&rsquo;d probably say <a href=\"http://www.msf.org/msf/articles/2011/02/month-in-focus---february-2011.cfm\">M&eacute;decins Sans Fronti&egrave;res</a>, because I&rsquo;m pretty risk-averse. They seem to accomplish what they set out to accomplish, they seem <a href=\"http://www.msf.org/msf/articles/2010/08/msf-financial-reports.cfm\">financially transparent</a>, and I think it&rsquo;s pretty easy to argue that they&rsquo;re doing something good (as opposed to squandering money, or doing something actively bad).</p>\n<p>Of course, anyone associated with <em>Less Wrong</em> would ask if I&rsquo;m really maximizing expected utility. Couldn&rsquo;t a contribution to some place like the Singularity Institute of Artificial Intelligence, despite a lower chance of doing good, actually have a chance to do so much <em>more</em> good that it&rsquo;d pay to send the cash there instead?</p>\n<p>And I&rsquo;d have to say:</p>\n<p>1) Yes, there probably are such places, but it would take me a while to find the one that I trusted, and I haven&rsquo;t put in the work. When you&rsquo;re risk-averse and limited in the time you have to make decisions, you tend to put off weighing options that have a very low chance of success but a very high return if they succeed. This is sensible so I don&rsquo;t feel bad about it.</p>\n<p>2) Just to amplify point 1) a bit: you shouldn&rsquo;t always maximize expected utility if you only live once. Expected values &mdash; in other words, averages &mdash; are very important when you make the same small bet over and over again. When the stakes get higher and you aren&rsquo;t in a position to repeat the bet over and over, it may be wise to be risk averse.</p>\n<p>3) If you let me put the $100,000 into my retirement account instead of a charity, that&rsquo;s what I&rsquo;d do, and I wouldn&rsquo;t even feel guilty about it. I actually think that the increased security would free me up to do more risky but potentially very good things!</p>\n<p>Hmm, here&rsquo;s a better idea:</p>\n<p>Could I get someone to create an institute, register it as a charity, and get the institute to hire me?</p>\n</blockquote>\n<p>What can one learn from this?</p>\n<ul>\n<li>That people value financial&nbsp;transparency.</li>\n<li>That people value openness&nbsp;and&nbsp;trustworthiness.</li>\n<li>Explain that openness isn't necessarily good.</li>\n<li>Address the good reasons for SIAI not to publish AGI progress.&nbsp;</li>\n<li>Dealing with risk aversion.</li>\n<li>Explain why one would decide to contribute to the SIAI under uncertainty.</li>\n<li>Why it is important to consider&nbsp;charitable giving in the first place.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cFs5R9RkAGt99jaJw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 8, "extendedScore": null, "score": 6.879335573326753e-07, "legacy": true, "legacyId": "6153", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T14:19:13.477Z", "modifiedAt": null, "url": null, "title": "[Link] The New Humanism", "slug": "link-the-new-humanism", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.593Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bbniTGSEeBpmkSnbN/link-the-new-humanism", "pageUrlRelative": "/posts/bbniTGSEeBpmkSnbN/link-the-new-humanism", "linkUrl": "https://www.lesswrong.com/posts/bbniTGSEeBpmkSnbN/link-the-new-humanism", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20The%20New%20Humanism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20The%20New%20Humanism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbbniTGSEeBpmkSnbN%2Flink-the-new-humanism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20The%20New%20Humanism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbbniTGSEeBpmkSnbN%2Flink-the-new-humanism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbbniTGSEeBpmkSnbN%2Flink-the-new-humanism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4, "htmlBody": "<p><a title=\"The New Humanism\" href=\"http://www.nytimes.com/2011/03/08/opinion/08brooks.html\">http://www.nytimes.com/2011/03/08/opinion/08brooks.html</a></p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bbniTGSEeBpmkSnbN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 3, "extendedScore": null, "score": 6.879442884389472e-07, "legacy": true, "legacyId": "6154", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T16:37:41.414Z", "modifiedAt": null, "url": null, "title": "Ben Goertzel on Charity", "slug": "ben-goertzel-on-charity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:56.860Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YS79rBLQBhqzPN7k5/ben-goertzel-on-charity", "pageUrlRelative": "/posts/YS79rBLQBhqzPN7k5/ben-goertzel-on-charity", "linkUrl": "https://www.lesswrong.com/posts/YS79rBLQBhqzPN7k5/ben-goertzel-on-charity", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ben%20Goertzel%20on%20Charity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABen%20Goertzel%20on%20Charity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYS79rBLQBhqzPN7k5%2Fben-goertzel-on-charity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ben%20Goertzel%20on%20Charity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYS79rBLQBhqzPN7k5%2Fben-goertzel-on-charity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYS79rBLQBhqzPN7k5%2Fben-goertzel-on-charity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 231, "htmlBody": "<p>Artificial general intelligence researcher&nbsp;<a href=\"http://en.wikipedia.org/wiki/Ben_Goertzel\">Ben Goertzel</a> answered my question&nbsp;on charitable giving and gave his permission to publish it here.&nbsp;I think the&nbsp;<a href=\"http://www.takeonit.com/question/337.aspx\">opinion of highly educated experts</a>&nbsp;who&nbsp;<a href=\"http://intelligence.org/aboutus/advisors\">have read most of the available material</a>&nbsp;is important to estimate the public and academic perception of risks from AI and the effectiveness with which the risks are communicated by LessWrong and the SIAI.</p>\n<p><strong>Alexander Kruel</strong> asked:</p>\n<blockquote>\n<p><span style=\"border-collapse: collapse; font-family: arial, sans-serif; font-size: 13px; \"><em></em></span>What would you do with $100,000 if it were given to you on the condition that you donate it to a charity of your choice?</p>\n</blockquote>\n<p><strong><a href=\"http://www.goertzel.org/\">Ben Goertzel</a></strong> replied:</p>\n<blockquote>\n<p>Unsurprisingly, my answer is that I would donate the $100,000 to the&nbsp;<a href=\"http://opencog.org/\">OpenCog project</a> which I co-founded and with which I'm currently&nbsp;heavily involved. &nbsp;This doesn't mean that I think OpenCog should get&nbsp;100% of everybody's funding; but given my own state of knowledge, I'm&nbsp;very clearly aware that OpenCog could make great use of $100K for&nbsp;research working toward beneficial AGI and a positive Singularity.&nbsp;If I had $100M rather than $100K to give away, I would have to do more&nbsp;research into which other charities were most deserving, rather than&nbsp;giving it all to OpenCog!</p>\n</blockquote>\n<p>What can one learn from this?</p>\n<ul>\n<li>The SIAI is not the only option to work towards a positive Singularity</li>\n<li>The SIAI should try to cooperate more closely with other AGI projects to potentially have a positive impact.</li>\n</ul>\n<p>I'm planning to contact and ask various experts, who are aware of <em>risks from AI</em>, the same question.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YS79rBLQBhqzPN7k5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 2, "extendedScore": null, "score": 6.879818172261157e-07, "legacy": true, "legacyId": "6155", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 75, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T19:59:45.845Z", "modifiedAt": null, "url": null, "title": "Eliezer passes 100,000 karma points", "slug": "eliezer-passes-100-000-karma-points", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.911Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points", "pageUrlRelative": "/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points", "linkUrl": "https://www.lesswrong.com/posts/wcDRnHyEyKkYsh2fL/eliezer-passes-100-000-karma-points", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eliezer%20passes%20100%2C000%20karma%20points&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEliezer%20passes%20100%2C000%20karma%20points%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcDRnHyEyKkYsh2fL%2Feliezer-passes-100-000-karma-points%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eliezer%20passes%20100%2C000%20karma%20points%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcDRnHyEyKkYsh2fL%2Feliezer-passes-100-000-karma-points", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwcDRnHyEyKkYsh2fL%2Feliezer-passes-100-000-karma-points", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 191, "htmlBody": "<p>Eliezer Yudkowsky has passed an arbitrary milestone: 100,000 karma points on Less Wrong. Allow me just a moment to celebrate this like we celebrate other arbitrary milestones, like birthdays.</p>\n<p>I think that Eliezer's karma score vastly <em>under-rates</em> his relative contribution to this site. For example, his score is only about 13x my own score, but I think it's obvious he has contributed far more than 13x as much value to this community as I have.</p>\n<p>This is probably due to the fact that good posts today get far more upvotes than earlier good posts, when I suspect the community was smaller. For example, my rather simple and insignificant post <a href=\"/lw/48j/secure_your_beliefs/\">Secure Your Beliefs</a> received 34 upvotes, which is more than almost&nbsp;<em>any</em> of Eliezer's epic and brilliant posts of the past have received, for example <a href=\"/lw/l4/terminal_values_and_instrumental_values/\">Terminal Values and Instrumental Values</a>.</p>\n<p>So at this arbitrary milestone, I'd just like to say a quick word to Eliezer:</p>\n<p>&nbsp;</p>\n<p>Thanks.</p>\n<p>You've done a lot.</p>\n<p>&nbsp;</p>\n<p>Okay, that's all! I hope this doesn't come across as \"sucking up to the <a href=\"/lw/4d/youre_calling_who_a_cult_leader/\">Dear Leader</a>,\" but instead as the sincere appreciation it is. There is a good reason I list Eliezer as one of my <a href=\"/lw/31i/have_no_heroes_and_no_villains/\">heroes-even-though-we-shouldn't-have-'heroes'</a> over <a href=\"http://commonsenseatheism.com/?page_id=3\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wcDRnHyEyKkYsh2fL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 22, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "6156", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mEAocxta4uLdejo7j", "n5ucT5ZbPdhfGNLtP", "cyzXoCv7nagDWCMNS", "G6npMHwgRGSQDKavX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T21:17:32.965Z", "modifiedAt": null, "url": null, "title": "How SIAI could publish in mainstream cognitive science journals", "slug": "how-siai-could-publish-in-mainstream-cognitive-science", "viewCount": null, "lastCommentedAt": "2019-05-15T23:35:17.242Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4oWXnodxAu4WgHnrd/how-siai-could-publish-in-mainstream-cognitive-science", "pageUrlRelative": "/posts/4oWXnodxAu4WgHnrd/how-siai-could-publish-in-mainstream-cognitive-science", "linkUrl": "https://www.lesswrong.com/posts/4oWXnodxAu4WgHnrd/how-siai-could-publish-in-mainstream-cognitive-science", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20SIAI%20could%20publish%20in%20mainstream%20cognitive%20science%20journals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20SIAI%20could%20publish%20in%20mainstream%20cognitive%20science%20journals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4oWXnodxAu4WgHnrd%2Fhow-siai-could-publish-in-mainstream-cognitive-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20SIAI%20could%20publish%20in%20mainstream%20cognitive%20science%20journals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4oWXnodxAu4WgHnrd%2Fhow-siai-could-publish-in-mainstream-cognitive-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4oWXnodxAu4WgHnrd%2Fhow-siai-could-publish-in-mainstream-cognitive-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2762, "htmlBody": "<p><strong>Newest edit</strong>: I just <a href=\"/r/discussion/lw/4r1/how_siai_could_publish_in_mainstream_philosophy/3o4g\">realized</a> that by \"philosophy journals\" in the original post I really meant \"cognitive science\" journals. (I made the mistake because for me, philosophy basically just <em>is</em>&nbsp;cognitive science.) So please the read the below in terms of cognitive science journals, not just philosophy journals.&nbsp;</p>\n<p><strong>First edit</strong>: Some people apparently read this as an \"ultimatum\" for SIAI, which was not the intent at all. It's merely an argument for why I think SIAI could benefit from publishing in mainstream journals, and then some advice on how to do it. I'm making recommendations, not \"demands\" - how silly would that be? Also, it's not like I'm saying SIAI should do a bunch of stuff, and I'm then walking away. For example, I'm actively writing a journal-grade paper on Friendly AI, putting it in the context of existing literature on the subject. And I'd love to do more.</p>\n<p>Also, I suspect that many at SIAI already <em>want</em> to be publishing in mainstream philosophy journals. The problem is that it requires a fair amount of resources and know-how to do so (as the below post shows), and that takes time. It doesn't appear that SIAI has anyone whose primary training is in philosophy, because they've (wisely) invested their resources in, you know, math geniuses and people who can bring in funds and so on.&nbsp;Anyhoo...</p>\n<p>&nbsp;</p>\n<p>After reading about 80% of the literature in the field of machine ethics, I've realized that the field hasn't quite caught up to where Yudkowsky's thinking was (on the most important issues) <a href=\"http://intelligence.org/upload/CFAI.html\">circa 2001</a>.*</p>\n<p>One cause of this may be the fact that unlike almost every other 10-year research institute or university research program on the planet, SIAI has no publications in established peer-reviewed journals. This fact has at least two effects: (1) SIAI's researchers are able to work more quickly on these problems when they are not spending their time reading hundreds of mostly useless papers from the mainstream literature, and then composing arduously crafted papers that conform to the style and expectations of the mainstream community, citing all the right literature. And: (2) the mainstream community has not caught up with SIAI's advances because SIAI has not shared them with anyone - at least not in their language, in their journals, to their expectations of clarity and style.</p>\n<p>However, I suspect that SIAI may now <em>want</em> to devote some resources doing what must be done to get published in mainstream journals, because (1) many donors <em>do</em> know the difference between conference papers and papers published in mainstream journals, and will see SIAI as more valuable and credible if they are publishing in mainstream journals, (2) SIAI's views will look less cult-like and more academically credible in general if they publish in mainstream journals, and (3) SIAI and LW people will need to spend less time answering dumb questions like \"Why not just program the AI to maximize human happiness?\" if SIAI publishes short, well-cited, well-argued responses to such questions in the language that everybody else knows how to understand, rather than responding to those questions in a way that requires someone to read a set of dozens of blog posts and articles with a complex web of dependencies and an unfamiliar writing/citation style and vocabulary. Also: (4) Talking in everyone else's language and their journals will probably help some really smart people make genuine progress on the Friendly AI problem! <a href=\"/r/discussion/lw/4qs/lokhorst_computational_metaethics_2011/\">Gert-Jan Lokhorst</a> is a really smart guy interested in these issues, but it's not clear that he has read Yudkowsky. Perhaps he's never heard of Yudkowsky, or if he has, he doesn't have time to risk spending it on something that hasn't even bothered to pass a journal's peer review process. Finally, bringing the arguments to the world in the common language and journals will (5) invite criticism, some of which will be valid and helpful in reformulating SIAI's views and giving us all a better chance of surviving the singularity.</p>\n<p>Thus, I share some advice on how to get published in philosophy journals. Much of SIAI's work is technically part of the domain of 'philosophy', even when it looks like math or computer science. Just don't think of Kant or Plato when you think of 'philosophy.' Much of SIAI's work <em>is</em> more appropriate for math and computer science journals, but I'm not familiar with how to get published in those fields, though I suspect the strategy is much the same.</p>\n<p>Who am I to share advice? I've never published in a philosophy journal. But a large cause of that fact is that I haven't tried. (Though, I'm beginning on early drafts of some journal-bound papers now.) Besides, what I share with you below is just repeating what published authors <em>do</em> say to me and online, so you're getting <em>their</em> advice, not particularly <em>mine</em>.</p>\n<p>Okay, how to get published in philosophy journals...</p>\n<p>The easiest way to get published is to be a respected academic with a long publication history, working at a major university. Barring that, find a co-author or two who fit that description.</p>\n<p>Still, that won't be enough, and sometimes the other conditions below will be sufficient if you <em>don't</em> match that profile. After all, people do manage to build up a long publication history starting with a publication history of 0. Here's how they do it:</p>\n<p>1. <strong>Write in the proper style</strong>. Anglophone philosophy has, over the years, developed a particular style marked by clarity and other norms. These norms have been expressed in writing guides for undergraduate philosophy students <a href=\"http://www.jimpryor.net/teaching/guidelines/writing.html\">here</a>, <a href=\"http://www.public.asu.edu/~dportmor/tips.pdf\">here</a>, and <a href=\"http://puffin.creighton.edu/phil/stephens/writingm.html\">elsewhere</a>. However, such guides are insufficient. Really, the only way to learn the style of Anglophone philosophy is to read hundreds and hundreds of journal articles. You will then have an intuitive sense of what sounds right or wrong, and which structures are right or wrong, and your writing will be much easier because you won't <em>need</em>&nbsp;to look it up in a style guide every time. As an example, Yudkowsky's&nbsp;<a href=\"http://intelligence.org/upload/TDT-v01o.pdf\">TDT</a> paper is <em>much</em>&nbsp;closer to the standard style than his <a href=\"http://intelligence.org/upload/CEV.html\">CEV</a> paper, but it's still not quite there yet.</p>\n<p>2. <strong>Use the right vocabulary and categories</strong>. Of course, you might write a paper aiming to recommend a <a href=\"http://www.nickbostrom.com/fut/singleton.html\">new term</a> or <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Davis-The-Two-Senses-of-Desire.pdf\">new categories</a>, but even then you need to place your arguments in the context of the existing terms and categories <em>first</em>. As an example, consider Eliezer's <a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a> paper from 2004. The paper was not written for journals, so I'm not criticizing the paper. I'm explaining how it would need to be written differently if it was intended for journal publication. Let's pretend it is now 2004, and I am co-writing the Coherent Extrapolated Volition paper with Eliezer, and we want to publish it in a mainstream journal.</p>\n<p>First, what is Eliezer's topic? It is the topic of how to design the goal system of an AI so that it behaves ethically, or in ways that we want. For a journal paper, our first goal would be to place the project of our paper in the context of the existing literature on that subject. Now, in 2004, it wasn't clear that this field would come to be called by the term \"machine ethics\" rather than by other terms that were floating around at the time like \"artificial morality\" (Danielson, 1992) or \"computational ethics\" (Allen et al., 2000) or \"friendly ai\" (Yudkowsky, 2001). So, we would probably cite the existing literature on this issue of how to design the goal system of an AI so that it behaves ethically (only about a two dozen works existed in 2004) and pick the terms that worked best for our purpose, after making clear what <em>we</em> meant by them.</p>\n<p>Next, we would undertake the same considerations for the other concepts we use. For example, Eliezer introduces the term <em>volition</em>:</p>\n<blockquote>\n<p>Suppose you're faced with a choice between two boxes, A and B. One and only one of the boxes contains a diamond. You guess that the box which contains the diamond is box A. It turns out that the diamond is in box B. Your&nbsp;<em>decision</em>&nbsp;will be to take box A. I now apply the term&nbsp;<em>volition</em>&nbsp;to describe the sense in which you may be said to<em>want</em>&nbsp;box B, even though your guess leads you to pick box A.</p>\n</blockquote>\n<p>But here, it's unnecessary to invent a new term, because philosophers talk a <em>lot</em>&nbsp;about this concept, and they already have a well-developed vocabulary for talking about it. Eliezer is making use of the distinction between \"means\" and \"ends,\" and he's talking about \"informed desires\" or \"informed wants\" or \"what an agent would want if fully informed.\" There is a massive and precise literature on this concept, and mainstream journals would expect us to pick one variant of this vocabulary for use in our paper and cite the people who use it, rather than just introducing a brand new term for no good reason.</p>\n<p>Next, when Eliezer writes about \"extrapolating\" human volition, he actually <em>blends</em>&nbsp;two concepts that philosophers keep distinct for good reasons. He blends the concept of <em>distinguishing means from ends</em>&nbsp;with the notion of <em>ends that change in response to the environment or inner processes</em>. To describe the boxes example above, a mainstream philosopher would say that you desired to choose box A as a means, but you desired the diamond in box B as an end. (You were simply mistaken about which box contained the diamond.) Eliezer calls this a type of \"extrapolation,\" but he <em>also</em>&nbsp;refers to something else as \"extrapolation\":</p>\n<blockquote>\n<p><span style=\"font-size: 13px; font-family: Times;\">In poetic terms, our&nbsp;<em>coherent extrapolated volition</em>&nbsp;is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.</span></p>\n</blockquote>\n<p>This is a very different thing to the mainstream philosopher. This is an actual changing of (or extrapolating of) what one desires <em>as an end</em>, perhaps through a process by which reward signals reinforce certain neural pathways, thus in certain circumstances transforming a desire-as-means into a desire-as-end (Schroeder, 2004). Or, in Yudkowsky's sense, it's an \"extrapolation\" of what we <em>would</em>&nbsp;desire as an end if our desires-as-ends were transformed through a process that involved not just more information but also changes to our neural structure due to environment (such as growing up together).</p>\n<p>This kind of unjustified blending and mixing of concepts - without first putting your work in the context of the current language and then <em>justifying</em>&nbsp;your use of a brand new language - is definitely something that would keep our paper out of mainstream journals. In this case, I think the mainstream language is just fine, so I would simply adopt it, briefly cite some of the people who explain and defend that language, and move forward.</p>\n<p>There are other examples, right from the start. Eliezer talks about the \"spread\" of \"extrapolated volition\" where a mainstream philosopher would talk about its <em>uncertainty</em>. He talks about \"muddle\" where a mainstream philosopher would call it <em>inconsistency</em>&nbsp;or <em>incoherence</em>. And so on. If we were writing the CEV paper in 2004 with the intention of publishing in a mainstream journal, we would simply adopt the mainstream language if we found it adequate, or we would first explain ourselves in terms of the mainstream language and <em>then</em>&nbsp;argue in favor of using a different language, <em>before</em>&nbsp;giving other arguments <em>in that brand new language</em>.</p>\n<p>Same goes for every other subject. If you're writing on <a href=\"/lw/ld/the_hidden_complexity_of_wishes/\">the complexity of wishes</a>, you should probably be citing from, say, <a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">OUP's recent edited volume</a> on the very latest affective neuroscience of pleasure and desire, and you should probably know that what you're talking about is called \"affective neuroscience,\" and you should probably know that one of the leading researchers in that field is Kent Berridge, and that he recently co-edited a volume for OUP on exactly the subject you are talking about. (Hint: neuroscience overwhelmingly confirms Eliezer's claims about the complexity of wishes, but the standards of mainstream philosophy expect you to cite actual science on the topic, not just appeal to your readers' intuitions. Or at least, <em>good</em>&nbsp;mainstream philosophy requires you to cite actual science.)</p>\n<p>I should also mention there's a huge literature on this \"fully informed\" business, too. One of the major papers is from <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sobel-Full-Information-Accounts-of-Well-Being.pdf\">David Sobel</a>.</p>\n<p>3. <strong>Put your paper in context and cite the right literature</strong>. Place your work in the context of things already written on the subject. Start with a brief overview of the field or sub-field, citing a few key works. Distinguish a few of the relevant questions from each other, and explain exactly <em>which</em>&nbsp;questions you'll be tackling in this paper, and which ones you will <em>not</em>. Explain how other people have answered those questions, and explain why your paper is needed. Then, go on to give your arguments, along the way explaining why you think your position on the question, or your arguments, are superior to the others that have been given, or valuable in some other way. Cite the literature all along the way.</p>\n<p>4. <strong>Get feedback from mainstream philosophers</strong>. After you've written a pretty good third draft, send it to the philosophers whose work you interact with most thoroughly. If the draft is well-written according to the above rules, they will probably read it. Philosophers get way less attention than scientists, and are usually interested to read anything that engages their work directly. They will probably send you a few comments within a month or two, and may name a few other papers you may want to read. Revise.</p>\n<p>5. <strong>Submit to the right journals</strong>. If you have no mainstream academic publishing history, you may want to start conservatively and submit to some established but less-prestigious&nbsp;journals first. As your mainstream academic publishing record grows, you can feel more confident in submitting to major journals in your field - in the case of CEV, this would be journals like <em>Minds and Machines</em>&nbsp;and <em>IEEE Intelligent Systems</em>&nbsp;and <em>International Journal of Applied Philosophy</em>. After a couple successes there, you <em>might</em>&nbsp;be able to publish in a major general-subject philosophy journal like <em>Journal of Philosophy</em>&nbsp;or <em>Nous</em>. But don't get your hopes up.</p>\n<p>Note that journals vary widely in what percentage of submissions they accept, how good the feedback is, and so on. For that, you'll want to keep track of what the community is saying about various journals. This kind of thing is often reported on blogs like <a href=\"http://leiterreports.typepad.com/\">Leiter Reports</a>.</p>\n<p>6. <strong>Remember your strengths and weaknesses</strong>.&nbsp;If this process sounds like a lot of work - poring through hundreds of journal articles and books to figure out what the existing language is for each concept you want to employ, and thinking about whether you want to adopt that language or argue for a new one, figuring out which journals to submit to, and so on - you're right! Writing for mainstream journals is a lot of work. It's made much easier these days with online search engines and digital copies of articles, but it's still work, and you have to know how to look for it. You have to know the names of related terms that might bring you to the right articles. You have to know which journals and publishers and people are the \"big names.\" You have to know what the fields and sub-fields of philosophy (and any relevant sciences) are, and how they interact. This is one advantage that someone who is familiar with philosophy has over someone who is not - it may not be that the former is any smarter or creative than the latter, it's just that the former knows what to look for, and probably already knows what language to use for a greatly many subjects so he doesn't&nbsp;<em>have</em>&nbsp;to look it up. Also, if you're going to do this it is critical that you have some mastery over&nbsp;<a href=\"/lw/3w3/how_to_beat_procrastination/\">procrastination</a>.</p>\n<p>Poring through the literature, along with other steps in the process of writing a mainstream philosophy paper, is often a godawful&nbsp;<em>slog</em>. And of course it helps if you quite simply&nbsp;<em>enjoy research</em>. That's probably the most important quality you can have. If you're not great with procrastination and you don't enjoy research but you have brilliant and important ideas to publish, team up with somebody who&nbsp;<em>does</em>&nbsp;enjoy research and has a handle on procrastination as your writing partner. You can do the brilliant insight stuff, the other person can do the literature slog and using-the-right-terms-and-categories part.</p>\n<p>There is <em>tons</em>&nbsp;more I could say about the subject, but that's at least a start. I hope it's valuable to some people, especially if you think you might want to publish something on a really important subject like existential risks and Friendly AI. Good luck!</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>* This is not to say the field of machine ethics is without valuable contributions. Far from it!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4oWXnodxAu4WgHnrd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 70, "baseScore": 87, "extendedScore": null, "score": 0.000182, "legacy": true, "legacyId": "6157", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 87, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AghFMRHmrhSuyxt6q", "4ARaTpNX62uaL86j6", "RWo4LwFzpHNQCTcYt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T21:27:33.301Z", "modifiedAt": null, "url": null, "title": "Better late than never: Toronto meetup March 10", "slug": "better-late-than-never-toronto-meetup-march-10", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LLFxhgYJJ6Q6s7HMh/better-late-than-never-toronto-meetup-march-10", "pageUrlRelative": "/posts/LLFxhgYJJ6Q6s7HMh/better-late-than-never-toronto-meetup-march-10", "linkUrl": "https://www.lesswrong.com/posts/LLFxhgYJJ6Q6s7HMh/better-late-than-never-toronto-meetup-march-10", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Better%20late%20than%20never%3A%20Toronto%20meetup%20March%2010&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABetter%20late%20than%20never%3A%20Toronto%20meetup%20March%2010%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLLFxhgYJJ6Q6s7HMh%2Fbetter-late-than-never-toronto-meetup-march-10%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Better%20late%20than%20never%3A%20Toronto%20meetup%20March%2010%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLLFxhgYJJ6Q6s7HMh%2Fbetter-late-than-never-toronto-meetup-march-10", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLLFxhgYJJ6Q6s7HMh%2Fbetter-late-than-never-toronto-meetup-march-10", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p><a id=\"more\"></a>Sorry for not posting this sooner - I thought I already had.&nbsp; Well, hopefully we'll get at least a few new faces nonetheless.</p>\n<p><strong>When:</strong> Thursday, March 10th at 8:00PM<br /><strong>Where:</strong> The Duke of York Pub at 39 Prince Arthur Ave</p>\n<p>The last meetup was a smashing success - everyone seemed to have had a good time.&nbsp; So we will be reconvening, tomorrow and perhaps biweekly from now on.&nbsp; Please RSVP if you're coming, in case I need to change the reservation.&nbsp; And, incidentally, the reservation is under the name \"Less Wrong\", in case you're the first to show up.</p>\n<p>See you all tomorrow!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LLFxhgYJJ6Q6s7HMh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.880603919389297e-07, "legacy": true, "legacyId": "6158", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T22:13:54.783Z", "modifiedAt": null, "url": null, "title": "College Selection Advice", "slug": "college-selection-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:22.422Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MzfrRhB4Q7YgCW3f6/college-selection-advice", "pageUrlRelative": "/posts/MzfrRhB4Q7YgCW3f6/college-selection-advice", "linkUrl": "https://www.lesswrong.com/posts/MzfrRhB4Q7YgCW3f6/college-selection-advice", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20College%20Selection%20Advice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACollege%20Selection%20Advice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMzfrRhB4Q7YgCW3f6%2Fcollege-selection-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=College%20Selection%20Advice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMzfrRhB4Q7YgCW3f6%2Fcollege-selection-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMzfrRhB4Q7YgCW3f6%2Fcollege-selection-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 271, "htmlBody": "<p>I, and a lot of other people my age, are currently facing a pretty big life decision -- where to go to college. Since this is probably going to have a pretty big impact on my life, I'd like to get some more information on this.</p>\n<p>Seeing as a lot of people here have probably made this choice already, gone through with some of the consequences of it, and are rational, I decided to ask here.</p>\n<p>My current considerations are:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Academic rigor</li>\n<li>Money (i.e. if a school gives me a full ride, should I go there rather than plunk down $250k over 4 years)</li>\n<li>Ability to do undergrad research</li>\n<li>Flexibility</li>\n<li>Likelihood to meet cool people</li>\n<li>Novelty (this one's a lot weaker though)</li>\n</ul>\n<div>My current situation is:</div>\n<div>\n<ul>\n<li>Accepted to MIT, University of Southern California, University of Maryland, Swarthmore, Harvey Mudd, Harvard, and CMU</li>\n<li>Getting some form of scholarships at USC and UMD, amount TBD</li>\n<li>Not likely to receive that much need-based financial aid</li>\n<li>Probably going to start in Engineering, might double major with Comp Sci, Statistics, or maybe Math. If I go to CMU, probably Engineering and Public Policy</li>\n<li>I also like and am competent in Economics, History, and English (though, definitely not getting a degree in the last 2)</li>\n<li>Maryland is my home state, and I would know a lot of people at UMD</li>\n</ul>\n<div>So if you have any advice, for me or in general, I'd love to hear it. If you have any questions yourself, feel free to ask them.</div>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MzfrRhB4Q7YgCW3f6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 6.880729598456891e-07, "legacy": true, "legacyId": "6159", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-09T22:17:19.993Z", "modifiedAt": null, "url": null, "title": "[Link] Your genes, your rights \u2013 FDA\u2019s Jeffrey Shuren not a fan", "slug": "link-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.585Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/85s6r8SdA8SxB2wma/link-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "pageUrlRelative": "/posts/85s6r8SdA8SxB2wma/link-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "linkUrl": "https://www.lesswrong.com/posts/85s6r8SdA8SxB2wma/link-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "postedAtFormatted": "Wednesday, March 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Your%20genes%2C%20your%20rights%20%E2%80%93%20FDA%E2%80%99s%20Jeffrey%20Shuren%20not%20a%20fan&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Your%20genes%2C%20your%20rights%20%E2%80%93%20FDA%E2%80%99s%20Jeffrey%20Shuren%20not%20a%20fan%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F85s6r8SdA8SxB2wma%2Flink-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Your%20genes%2C%20your%20rights%20%E2%80%93%20FDA%E2%80%99s%20Jeffrey%20Shuren%20not%20a%20fan%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F85s6r8SdA8SxB2wma%2Flink-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F85s6r8SdA8SxB2wma%2Flink-your-genes-your-rights-fda-s-jeffrey-shuren-not-a-fan", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p><a href=\"http://blogs.discovermagazine.com/gnxp/2011/03/your-genes-your-rights-fdas-jeffrey-shuren-not-a-fan/\">http://blogs.discovermagazine.com/gnxp/2011/03/your-genes-your-rights-fdas-jeffrey-shuren-not-a-fan/</a></p>\n<p>&nbsp;</p>\n<p>I find myself basically agreeing with Razib.</p>\n<p>Yes there is generally incompetence and avoidable irrationality associated with the most likley way this will be regulated. But I find myself fearing something else even more. I'm scared of busybody policy advisor's or \"well meaning\" individuals who will choose to hide or misrepresent data purposefully to either:</p>\n<ul>\n<li>promote their own values</li>\n<li>try and appease a popular \"moral panic\" (I think we will see at least one or two as uncomfortable new discoveries about the role of genetics are made or as old ones are made too blindingly obvious to ignore).</li>\n</ul>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "85s6r8SdA8SxB2wma", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.880738870834376e-07, "legacy": true, "legacyId": "6160", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-10T06:36:42.423Z", "modifiedAt": null, "url": null, "title": "[Video] AI Box Experiment on BBC's \"Look Around You\"", "slug": "video-ai-box-experiment-on-bbc-s-look-around-you", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:56.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "ata", "user": {"username": "ata", "createdAt": "2009-07-20T22:13:53.102Z", "isAdmin": false, "displayName": "ata"}, "userId": "KppHkGEqTNeDaGJTc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LZSdR7SqFmdtyFsZx/video-ai-box-experiment-on-bbc-s-look-around-you", "pageUrlRelative": "/posts/LZSdR7SqFmdtyFsZx/video-ai-box-experiment-on-bbc-s-look-around-you", "linkUrl": "https://www.lesswrong.com/posts/LZSdR7SqFmdtyFsZx/video-ai-box-experiment-on-bbc-s-look-around-you", "postedAtFormatted": "Thursday, March 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BVideo%5D%20AI%20Box%20Experiment%20on%20BBC's%20%22Look%20Around%20You%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BVideo%5D%20AI%20Box%20Experiment%20on%20BBC's%20%22Look%20Around%20You%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLZSdR7SqFmdtyFsZx%2Fvideo-ai-box-experiment-on-bbc-s-look-around-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BVideo%5D%20AI%20Box%20Experiment%20on%20BBC's%20%22Look%20Around%20You%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLZSdR7SqFmdtyFsZx%2Fvideo-ai-box-experiment-on-bbc-s-look-around-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLZSdR7SqFmdtyFsZx%2Fvideo-ai-box-experiment-on-bbc-s-look-around-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<p>I recently discovered that &quot;Look Around You&quot;, a BBC TWO educational science-themed series from the 1980s<a href=\"about:blank#footnote1\">1</a>, had on its &quot;Computers&quot; episode a live-action AI Box Experiment, in which Bournemouth, what was at the time Britain&#x27;s most advanced computer, was assigned to physically escape from a steel cage. For your convenience, I&#x27;ve excerpted the relevant clips from the episode. Watch and see how it turns out!</p><p>Link: <a href=\"http://www.youtube.com/v/WCEm96kA5hY\">http://www.youtube.com/v/WCEm96kA5hY</a></p><hr class=\"dividerBlock\"/><p>1<a href=\"undefined\"> </a> Note: The above description is a <a href=\"http://en.wikipedia.org/wiki/Look_Around_You\">lie</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LZSdR7SqFmdtyFsZx", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 27, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "6171", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.2.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-10T15:20:54.978Z", "modifiedAt": null, "url": null, "title": "The Limits of Curiosity", "slug": "the-limits-of-curiosity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:16.413Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Elizabeth", "createdAt": "2010-06-13T03:33:52.050Z", "isAdmin": false, "displayName": "Elizabeth"}, "userId": "ZCSWTn7aaWZMKasDB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g4QdmxFos3Q2zseZo/the-limits-of-curiosity", "pageUrlRelative": "/posts/g4QdmxFos3Q2zseZo/the-limits-of-curiosity", "linkUrl": "https://www.lesswrong.com/posts/g4QdmxFos3Q2zseZo/the-limits-of-curiosity", "postedAtFormatted": "Thursday, March 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Limits%20of%20Curiosity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Limits%20of%20Curiosity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4QdmxFos3Q2zseZo%2Fthe-limits-of-curiosity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Limits%20of%20Curiosity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4QdmxFos3Q2zseZo%2Fthe-limits-of-curiosity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg4QdmxFos3Q2zseZo%2Fthe-limits-of-curiosity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 901, "htmlBody": "<p>In principle, I agree with the notion that it is unforgivable to not want to know, and not want to improve your map to match the territory.&nbsp; However, even the most curious person in the world cannot maintain equal curiosity about all things, and even if they could there are limits on time and energy.&nbsp; In general, the things that inspire curiosity are determined by your personal likes, dislikes, and biases, and it is therefore worth considering carefully where these demarcations fall so as not to deprive ourselves of useful information.&nbsp; This is particularly important when it comes to things that inspire not just lack of interest, but aversion, or \"anti-curiosity.\"</p>\n<p>However, not all information is useful, and it can be useful to encourage a bias that cuts you off from information that is not particularly useful to you, so as to better allocate your time and energy.&nbsp; It is possible that it could also be useful to fabricate an \"I don't want to know\" stance about a certain type of information so as to better allocate your time, (for example, ceasing to watch television, and denying curiosity about what is happening on your favorite shows), but I will not discuss or advocate that here, largely because it's all I can do to hold the line against new time wasters.</p>\n<p>The difficulty and danger of this method is that it is best accomplished by not thinking about the things you don't want to be curious about, and that can lead to not even realizing you aren't curious about them, so important things may slip through the cracks.&nbsp; For example, I have never smoked a cigarette, and it requires no effort on my part to not be curious about what it is like.&nbsp; That is such a deeply buried aversion that I might never have consciously noticed that lack of curiosity if I had not been writing this article.&nbsp; In this case, lack of curiosity about smoking is beneficial, but it could just as easily have been something that would be useful for me to be curious about, and I might never have noticed.</p>\n<p>Analyzing your own areas of anti-curiosity is extremely difficult, both because your brain rebels at thinking about things it habitually doesn't think about, and because you will likely find a lack of rhyme or reason in which things you are anticurious about.&nbsp; Questioning things deeply held enough that you don't think about them is always deeply uncomfortable.</p>\n<p>Many such anti-curiosity regions are more a matter of personal preference than anything else.&nbsp; One of mine falls in the area of video games: I've never played them much, and I deliberately cultivate a lack of curiosity about them because I don't believe the enjoyment or value they might give me would outweigh the amount of my precious time they would likely take up if I started.&nbsp; However, I spend more time than perhaps I should reading fanfiction.&nbsp; There are probably people reading this who are just the opposite, and there probably isn't any real difference between the two positions.</p>\n<p>There are also many such regions that result from not having much knowledge or skill in an area, and, rather than rectifying the knowledge gap, developing a sense of superiority or disdain in relation to the area.&nbsp; One fairly common topic for this to occur around (at least for women) is the application of makeup.&nbsp; It is one I had to overcome myself.&nbsp; I didn't know how to put on makeup well as a teenager, and hadn't really tried, and looked down on the sorts of girls who came to class after an obvious half-hour beauty regimen.&nbsp; There were all sorts of plausible excuses for my disdain (women shouldn't make themselves into Barbies, intellect is more important, etc. ), but the real root reason was that I couldn't do it myself.&nbsp; It took time to overcome that enough to realize the real benefits to having that knowledge (even if I still don't bother on a daily basis), but there *are* real benefits to having that knowledge.&nbsp; At the very least, makeup is an expected part of formal or business attire for women in the US, and there are tangible benefits to following such social conventions regardless of how logical they are.</p>\n<p>It is more difficult to overcome such an issue if it is rooted in lack of ability rather than lack of knowledge.&nbsp; I have long recognized intellectually the value of recognizing and responding appropriately to social cues, but it doesn't come easily to me, and my frustration often manifests itself in a feeling that I don't want to know.&nbsp; Recognizing that and overcoming it is an ongoing process.</p>\n<p>Maintaining a balance on such things is difficult.&nbsp; I know that in areas in which I am comfortable, I excel at optimization, but if I am uncomfortable I subscribe strongly to the \"If it ain't broke, don't fix it\" philosophy.&nbsp; Both approaches have their merits and their place, the challenge is maintaining awareness of which I am using and why I am using it so that I don't fall into a trap of willful ignorance.</p>\n<p>Even when you have identified an area in which you should reverse course and cultivate curiosity, the battle is not over.&nbsp; You still have to overcome the hurdle of learning about the subject.&nbsp; However, I am not qualified to write an article on overcoming procrastination because I am not nearly successful enough at avoiding it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"moeYqrcakMgXnQNyF": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g4QdmxFos3Q2zseZo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 37, "extendedScore": null, "score": 6.883514901506867e-07, "legacy": true, "legacyId": "6178", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-10T17:51:42.485Z", "modifiedAt": null, "url": null, "title": "Plant Seeds of Rationality", "slug": "plant-seeds-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:35.552Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RMuA2XNZLqcDWApTN/plant-seeds-of-rationality", "pageUrlRelative": "/posts/RMuA2XNZLqcDWApTN/plant-seeds-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/RMuA2XNZLqcDWApTN/plant-seeds-of-rationality", "postedAtFormatted": "Thursday, March 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Plant%20Seeds%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APlant%20Seeds%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMuA2XNZLqcDWApTN%2Fplant-seeds-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Plant%20Seeds%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMuA2XNZLqcDWApTN%2Fplant-seeds-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRMuA2XNZLqcDWApTN%2Fplant-seeds-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 394, "htmlBody": "<p>After his wife died,&nbsp;Elz&eacute;ard Bouffier decided to cultivate a forest in a desolate, treeless valley. He built small dams along the side of the nearby mountain, thus creating new streams that ran down into the valley. Then, he planted one seed at a time.</p>\n<p>After four decades of steady work, the valley throbbed with life. You could hear the buzzing of bees and the tweeting of birds. Thousands of people moved to the valley to enjoy nature at its finest. The government assumed the regrowth was a strange natural phenomenon, and the valley's inhabitants were unaware that their happiness was due to the selfless deeds of one man.</p>\n<p>This is&nbsp;<a style=\"font-style: italic;\" href=\"http://home.infomaniak.ch/arboretum/Man_Tree.htm\">The Man Who Planted Trees</a>,&nbsp;a popular inspirational tale.</p>\n<p>But it's not just a tale. Abdul Kareem&nbsp;<a href=\"http://web.archive.org/web/20071019045414/http://forests.org/archive/asia/indfor.htm\">cultivated a forest</a> on a once-desolate stretch of <a href=\"http://www.goodnewsindia.com/Pages/content/inspirational/abdulKareem.html\">32 acres</a> along India's West Coast, planting one seed at a time. It took <em>him </em>only <em>twenty</em> years.&nbsp;</p>\n<p>Like trees in the ground, rationality does not grow in the mind overnight. <a href=\"/lw/1e/raising_the_sanity_waterline/\">Cultivating rationality</a> requires care and persistence, and there are many <a href=\"http://wiki.lesswrong.com/wiki/Biases\">obstacles</a>. You probably won't bring someone from average (ir)rationality to <a href=\"http://commonsenseatheism.com/?p=12147\">technical rationality</a> in a fortnight. But you can plant seeds.</p>\n<p>You can politely ask rationalist questions when someone says something irrational. Don't forget to smile!</p>\n<p>You can write letters to the editor of your local newspaper to correct faulty reasoning.</p>\n<p>You can visit random blogs, find an error in reasoning, offer a polite correction, and link back to a few relevant <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">Less Wrong posts</a>.</p>\n<p>One person planting seeds of rationality can make a difference, and we can do even better if we organize. An organization called <a href=\"http://www.plant-trees.org/about/history.htm\">Trees for the Future</a> has helped thousands of families in thousands of villages to plant more than <a href=\"http://web.archive.org/web/20071014144728/http://www.plant-trees.org/about/history.htm\">50 million trees</a> around the world. And when it comes to rationality, we can plant more seeds if we, for example, <a href=\"http://www.criticalthinking.org/\">support the spread of critical thinking classes</a> in schools.</p>\n<p>Do you want to collaborate with others to help spread rationality on a mass scale?</p>\n<p>You don't even need to figure out <em>how</em> to do it. Just contact leaders who already know what to do, and volunteer your time and energy.</p>\n<p><a href=\"mailto:cct@criticalthinking.org\">Email</a> the Foundation for Critical Thinking and say, \"How can I help?\" <a href=\"mailto:louie.helm@intelligence.org\">Email</a> Louie Helm and sign up for the <a href=\"http://intelligence.org/aboutus/volunteer\">Singularity Institute Volunteer Network</a>.</p>\n<p>Change does not happen when people gather to talk about how much they suffer from <a href=\"/lw/1sm/akrasia_tactics_review/\">akrasia</a>. Change happens when lots of individuals&nbsp;<em>organize</em>&nbsp;to make change happen.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "txkDg4aLmiRq8wsSu": 1, "qAvbtzdG2A2RBn7in": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RMuA2XNZLqcDWApTN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 45, "extendedScore": null, "score": 6.883922699357979e-07, "legacy": true, "legacyId": "5475", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XqmjdBKa4ZaXJtNmf", "rRmisKb45dN7DK4BW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-10T19:54:38.392Z", "modifiedAt": null, "url": null, "title": "Non-personal preferences of never-existed people", "slug": "non-personal-preferences-of-never-existed-people", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:05.009Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DfCJoqcFGBqaroc85/non-personal-preferences-of-never-existed-people", "pageUrlRelative": "/posts/DfCJoqcFGBqaroc85/non-personal-preferences-of-never-existed-people", "linkUrl": "https://www.lesswrong.com/posts/DfCJoqcFGBqaroc85/non-personal-preferences-of-never-existed-people", "postedAtFormatted": "Thursday, March 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Non-personal%20preferences%20of%20never-existed%20people&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANon-personal%20preferences%20of%20never-existed%20people%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfCJoqcFGBqaroc85%2Fnon-personal-preferences-of-never-existed-people%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Non-personal%20preferences%20of%20never-existed%20people%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfCJoqcFGBqaroc85%2Fnon-personal-preferences-of-never-existed-people", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfCJoqcFGBqaroc85%2Fnon-personal-preferences-of-never-existed-people", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 183, "htmlBody": "<p>Some people see never-existed people as moral agents, and claim that we  can talk about their preferences. Generally this means their personal  preference in existing versus non-existing. Formulations such \"it is  better for someone to have existed than not\" reflect this way of  thinking.<br /> <br /> But if the preferences of never-existed are relevant, then their  non-personal perferences are also relevant. Do they perfer a blue world  or a pink one? Would they want us to change our political systems? Would  they want us to not bring into existence some never-existent people  they don't like?<br /> <br /> It seems that those who are advocating bringing never-existent people  into being in order to satisfy those people's preferences should be focusing their attention on their non-personal preferences instead. After  all, we can only bring into being so many trillions of trillions of  trillions; but there is no theoretical limit to the number of  never-existent people whose non-personal preferences we can satisfy.  Just get some reasonable measure across the preferences of  never-existent people, and see if there's anything that sticks out from  the mass.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DfCJoqcFGBqaroc85", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 19, "extendedScore": null, "score": 6.884257595678332e-07, "legacy": true, "legacyId": "6179", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-10T21:44:20.059Z", "modifiedAt": null, "url": null, "title": "Columbia University Meetup", "slug": "columbia-university-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mycroft65536", "createdAt": "2009-03-14T03:04:26.898Z", "isAdmin": false, "displayName": "Mycroft65536"}, "userId": "dKGL3eRH8Xcvrig7b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fabAYMZEh3sFMqQDv/columbia-university-meetup", "pageUrlRelative": "/posts/fabAYMZEh3sFMqQDv/columbia-university-meetup", "linkUrl": "https://www.lesswrong.com/posts/fabAYMZEh3sFMqQDv/columbia-university-meetup", "postedAtFormatted": "Thursday, March 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Columbia%20University%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AColumbia%20University%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfabAYMZEh3sFMqQDv%2Fcolumbia-university-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Columbia%20University%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfabAYMZEh3sFMqQDv%2Fcolumbia-university-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfabAYMZEh3sFMqQDv%2Fcolumbia-university-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 133, "htmlBody": "<p><a id=\"more\"></a>During Eliezer's whirlwind tour of New York City recently, I met several rationalists who were also students at Columbia University. It seemed like it might be a good idea to start a club. While there is a NYC Less Wrong Meetup group, many&nbsp;students&nbsp;I know feel that it's a&nbsp;hassle&nbsp;to go downtown on a school night.&nbsp;</p>\n<p>To fix this problem, I'm founding a club for people of the rational&nbsp;persuasion&nbsp;at or near Columbia University in NYC. The first meeting will be:</p>\n<p><strong>When</strong>: This Sunday, March 13, at 2:30</p>\n<p><strong>Where:&nbsp;</strong>At Mel's&nbsp;<span style=\"border-collapse: collapse; font-family: arial, sans-serif; font-size: 13px;\">Mel's Burger Bar,&nbsp;</span><span style=\"border-collapse: collapse; font-family: arial, sans-serif; font-size: 13px;\">2850 Broadway (and 111th St.). </span></p>\n<p><span style=\"border-collapse: collapse; font-family: arial, sans-serif; font-size: 13px;\">Everyone is invited. There is no requirement that you be a student, grad student, faculty member or any such thing.&nbsp;</span>If you're interested, comment or send me a private message. There's a fair sized rationality&nbsp;community&nbsp;in New York and we're having a lot of fun.</p>\n<p>Join us.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fabAYMZEh3sFMqQDv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 6.884555269402883e-07, "legacy": true, "legacyId": "6180", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T01:14:35.832Z", "modifiedAt": null, "url": null, "title": "Off-topic Thread", "slug": "off-topic-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.779Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/h6bh7TmqtNhBngt9X/off-topic-thread", "pageUrlRelative": "/posts/h6bh7TmqtNhBngt9X/off-topic-thread", "linkUrl": "https://www.lesswrong.com/posts/h6bh7TmqtNhBngt9X/off-topic-thread", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Off-topic%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOff-topic%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh6bh7TmqtNhBngt9X%2Foff-topic-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Off-topic%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh6bh7TmqtNhBngt9X%2Foff-topic-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh6bh7TmqtNhBngt9X%2Foff-topic-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>We used to have a monthly off-topic thread for stuff rationalists might like to talk about that really has no bearing on rationality. Here's a new one.</p>\n<p>&nbsp;</p>\n<p>ETA: <a href=\"/lw/7u/offtopic_discussion_thread_april_2009/\">Original off-topic thread</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "h6bh7TmqtNhBngt9X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 6.885125915536852e-07, "legacy": true, "legacyId": "6181", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6BHcfSqNRjaYRoc2S"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T04:12:43.886Z", "modifiedAt": null, "url": null, "title": "AGI and Friendly AI in the dominant AI textbook", "slug": "agi-and-friendly-ai-in-the-dominant-ai-textbook", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:38.890Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K45SaBaB3D7o9xpAs/agi-and-friendly-ai-in-the-dominant-ai-textbook", "pageUrlRelative": "/posts/K45SaBaB3D7o9xpAs/agi-and-friendly-ai-in-the-dominant-ai-textbook", "linkUrl": "https://www.lesswrong.com/posts/K45SaBaB3D7o9xpAs/agi-and-friendly-ai-in-the-dominant-ai-textbook", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AGI%20and%20Friendly%20AI%20in%20the%20dominant%20AI%20textbook&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAGI%20and%20Friendly%20AI%20in%20the%20dominant%20AI%20textbook%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK45SaBaB3D7o9xpAs%2Fagi-and-friendly-ai-in-the-dominant-ai-textbook%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AGI%20and%20Friendly%20AI%20in%20the%20dominant%20AI%20textbook%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK45SaBaB3D7o9xpAs%2Fagi-and-friendly-ai-in-the-dominant-ai-textbook", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK45SaBaB3D7o9xpAs%2Fagi-and-friendly-ai-in-the-dominant-ai-textbook", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 934, "htmlBody": "<p><em><a href=\"http://aima.cs.berkeley.edu/\">AI: A Modern Approach</a></em>&nbsp;is by far the dominant textbook in the field. It is used in 1200 universities, and is the <a href=\"http://citeseer.ist.psu.edu/stats/citations\">25th most-cited</a> publication in computer science. If you're going to learn AI, this is how you learn it.</p>\n<p>Luckily, the concepts of AGI and Friendly AI get pretty good treatment in the 3rd edition, released in 2009.</p>\n<p>The Singularity is mentioned <em>in the first chapter</em>&nbsp;on page 12. Both AGI and Friendly AI are also mentioned in the first chapter, on page 27:</p>\n<blockquote>\n<p>[Many leaders in the field] believe AI should return to its roots of striving for, in Simon's words, \"machines that think, that learn and that create.\" They call the effort <strong>human-level AI</strong> or HLAI: their first symposium was in 2004 (Minsky et al. 2004)...</p>\n<p>A related idea is the subfield of <strong>Artificial General Intelligence</strong> or AGI (Goertzel and Pennachin, 2007), which held its first conference and organized the <em>Journal of Artificial General Intelligence</em>&nbsp;in 2008. AGI looks for a universal algorithm for learning and acting in any environment, and has its roots in the work of Ray Solomonoff (1965), one of the attendees of the original 1956 Dartmouth conference. Guaranteeing that what we create is really Friendly AI is also a concern (Yudkowsky, 2008; Omohundro, 2008), one we will return to in Chapter 26.</p>\n</blockquote>\n<p>Chapter 26 is about the philosophy AI, and section 26.3 is \"The Ethics and Risks of Developing Artificial Intelligence.\" They are:</p>\n<ol>\n<li>People might lose their jobs to automation.</li>\n<li>People might have too much (or too little) leisure time.</li>\n<li>People might lose their sense of being unique.</li>\n<li>AI systems might be used toward undesirable ends.</li>\n<li>The use of AI systems might result in a loss of accountability.</li>\n</ol>\n<p>Each of those sections is one or two paragraphs long. The final risk of AI takes up <em>3.5 pages</em>: (6) The Success of AI might mean the end of the human race. Here's a snippet:</p>\n<blockquote>The question is whether an AI system poses a bigger risk than traditional software. We will look at three sources of risk. First, the AI system's state estimation may be incorrect, causing it to do the wrong thing. For example... a missile defense system might erroneously detect an attack and launch a counterattack, leading to the death of billions...</blockquote>\n<blockquote>Second, specifying the right utility function for an AI system to maximize is not so easy. For example, we might propose a utility function designed to <em>minimize human suffering</em>, expressed as an additive reward function over time as in Chapter 17. Given the way humans are, however, we'll always find a way to suffer even in paradise; so the optimal decision for the AI system is to terminate the human race as soon as possible - no humans, no suffering...</blockquote>\n<blockquote>Third, the AI system's learning function may cause it to evolve into a system with unintended behavior. This scenario is the most serious, and is unique to AI systems, so we will cover it in more depth. I.J. Good wrote (1965),</blockquote>\n<blockquote style=\"padding-left: 30px;\">Let an <strong>ultraintelligent machine</strong> be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then be unquestionably be an \"intelligence explosion,\" and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the <em>last</em>&nbsp;invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. The \"intelligence explosion\" has also been called the <strong>technological singularity</strong> by... Vernor Vinge...</blockquote>\n<p>Then they mention Moravec, Kurzweil, and transhumanism, before returning to a more concerned tone about AI. They cover Asimov's three laws of robotics, and then:</p>\n<blockquote>Yudkowsky (2008) goes into more detail about how to design a &nbsp;<strong>Friendly AI</strong>. He asserts that friendliness (a desire not to harm humans) should be designed in from the start, but that the designers should recognize both that their own designs may be flawed, and that the robot will learn and evolve over time. Thus the challenge is one of mechanism design - to define a mechanism for evolving AI systems under a system of checks and balances, and to give the systems utility functions that will remain friendly in the face of such changes. We can't just give a program a static utility function, because circumstances, and our desired responses to circumstances, change over time. For example, if technology had allowed us to design a super-powerful AI agent in 1800 and endow it with the prevailing morals of the time, it would be fighting today to reestablish slavery and abolish women's right to vote. On the other hand, if we build an AI agent today and tell it how to evolve its utility function, how can we assure that it won't read that \"Humans think it is moral to kill annoying insects, in part because insect brains are so primitive. But human brains are primitive compared to my powers, so it must be moral for me to kill humans.\"</blockquote>\n<blockquote>Omohundro (2008) hypothesizes that even an innocuous chess program could pose a risk to society. Similarly, Marvin Minsky once suggested that an AI program designed to solve the Riemann Hypothesis might end up taking over all the resources of Earth to build more powerful supercomputers to help achieve its goal. THe moral is that even if you only want you program to play chess or prove theorems, if you give it the capability to learn and alter itself, you need safeguards.</blockquote>\n<p>It's good this work is getting such mainstream coverage!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Kcm4etxAJjmeDkHP": 2, "ac84EpK6mZbPLzmqj": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K45SaBaB3D7o9xpAs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 59, "baseScore": 73, "extendedScore": null, "score": 0.00014732960021874428, "legacy": true, "legacyId": "6189", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 54, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T07:56:23.892Z", "modifiedAt": null, "url": null, "title": "A Thought Experiment on Pain as a Moral Disvalue", "slug": "a-thought-experiment-on-pain-as-a-moral-disvalue", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.353Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w5M5oMLLHyink4ak9/a-thought-experiment-on-pain-as-a-moral-disvalue", "pageUrlRelative": "/posts/w5M5oMLLHyink4ak9/a-thought-experiment-on-pain-as-a-moral-disvalue", "linkUrl": "https://www.lesswrong.com/posts/w5M5oMLLHyink4ak9/a-thought-experiment-on-pain-as-a-moral-disvalue", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Thought%20Experiment%20on%20Pain%20as%20a%20Moral%20Disvalue&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Thought%20Experiment%20on%20Pain%20as%20a%20Moral%20Disvalue%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw5M5oMLLHyink4ak9%2Fa-thought-experiment-on-pain-as-a-moral-disvalue%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Thought%20Experiment%20on%20Pain%20as%20a%20Moral%20Disvalue%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw5M5oMLLHyink4ak9%2Fa-thought-experiment-on-pain-as-a-moral-disvalue", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw5M5oMLLHyink4ak9%2Fa-thought-experiment-on-pain-as-a-moral-disvalue", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 749, "htmlBody": "<p><strong>Related To:&nbsp;</strong><a href=\"/lw/1oj/complexity_of_value_complexity_of_outcome\"></a>Eliezer's<strong> </strong><a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">Zombies Sequence</a>, Alicorn's <a href=\"/lw/14n/pain/\">Pain</a></p>\n<p>Today you volunteered for what was billed as an experiment in moral psychology. You enter into a small room with a video monitor, a red light, and a button. Before you entered, you were told that you'll be paid $100 for participating in the experiment, but for every time you hit that button, $10 will be deducted. On the monitor, you see a person sitting in another room, and you appear to have a two-way audio connection with him. That person is tied down to his chair, with what appears to be electrical leads attached to him. He now explains to you that your red light will soon turn on, which means he will be feeling excruciating pain. But if you press the button in front of you, his pain will stop for a minute, after which the red light will turn on again. The experiment will end in ten minutes.</p>\n<p>You're not sure whether to believe him, but pretty soon the red light does turn on, and the person in the monitor cries out in pain, and starts struggling against his restraints. You hesitate for a second, but it looks and sounds very convincing to you, so you quickly hit the button. The person in the monitor breaths a big sigh of relief and thanks you profusely. You make some small talk with him, and soon the red light turns on again. You repeat this ten times and then are released from the room. As you're about to leave, the experimenter tells you that there was no actual person behind the video monitor. Instead, the audio/video stream you experienced was generated by one of the following ECPs (exotic computational processes).</p>\n<ol>\n<li>An AIXI-like (e.g., AIXI-tl, Monte Carlo AIXI, or some such) agent, programmed with the objective of maximizing the number of button presses.</li>\n<li>A brute force optimizer, which was programmed with a model of your mind, that iterated through all possible audio/video bit streams to find the one that maximizing the number of button presses. (As far as philosophical implications are concerned, this seems essentially identical to 1, so the reader doesn't necessarily have to go learn about AIXI.)</li>\n<li>A small team of uploads capable of running at a million times faster than an ordinary human, armed with photo-realistic animation software, and tasked with maximizing the number of your button presses.</li>\n<li>A Giant Lookup Table (GLUT) of all possible sense inputs and motor outputs of a person, connected to a virtual body and room.</li>\n</ol>\n<p>Then she asks, would you like to repeat this experiment for another chance at earning $100?</p>\n<p>Presumably, you answer \"yes\", because you think that despite appearances, none of these ECPs actually do feel pain when the red light turns on. (To some of these ECPs, your button presses would constitute positive reinforcement or lack of negative reinforcement, but mere negative reinforcement, when happening to others, doesn't seem to be a strong moral disvalue.) Intuitively this seems to be the obvious correct answer, but how to describe the difference between actual pain and the appearance of pain or mere negative reinforcement, at the level of bits or atoms, if we were specifying the utility function of a potentially super-intelligent AI? (If we cannot even clearly define what seems to be one of the simplest values, then the <a href=\"/lw/1oj/complexity_of_value_complexity_of_outcome\">approach</a> of trying to manually specify such a utility function would appear completely hopeless.)</p>\n<p>One idea to try to understand the nature of pain is to sample the space of possible minds, look for those that seem to be feeling pain, and check if the underlying computations have anything in common. But as in the above thought experiment, there are minds that can convincingly simulate the appearance of pain without really feeling it.</p>\n<p>Another idea is that perhaps what is bad about pain is that it is a strong negative reinforcement <em>as experienced by a conscious mind</em>. This would be compatible with the thought experiment above, since (intuitively) ECPs 1, 2, and 4 are not conscious, and 3 does not experience <em>strong</em> negative reinforcements. Unfortunately it also implies that fully defining pain as a moral disvalue is at least as hard as the problem of consciousness, so this line of investigation seems to be at an immediate impasse, at least for the moment. (But does anyone see an argument that this is clearly not the right approach?)</p>\n<p>What other approaches might work, hopefully without running into one or more problems already known to be hard?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"LaDu5bKDpe8LxaR7C": 2, "nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w5M5oMLLHyink4ak9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "6136", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KQvdpPd3k2ap6aJTP", "TcJKD2E4uE9XLNxBP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T09:53:48.050Z", "modifiedAt": null, "url": null, "title": "Some Reflections on Branching vs Probability", "slug": "some-reflections-on-branching-vs-probability", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlephNeil", "createdAt": "2010-05-12T14:43:28.879Z", "isAdmin": false, "displayName": "AlephNeil"}, "userId": "qSNSSwAXbki7JTNSd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NdesRveHP4fAn75hD/some-reflections-on-branching-vs-probability", "pageUrlRelative": "/posts/NdesRveHP4fAn75hD/some-reflections-on-branching-vs-probability", "linkUrl": "https://www.lesswrong.com/posts/NdesRveHP4fAn75hD/some-reflections-on-branching-vs-probability", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20Reflections%20on%20Branching%20vs%20Probability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20Reflections%20on%20Branching%20vs%20Probability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdesRveHP4fAn75hD%2Fsome-reflections-on-branching-vs-probability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20Reflections%20on%20Branching%20vs%20Probability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdesRveHP4fAn75hD%2Fsome-reflections-on-branching-vs-probability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdesRveHP4fAn75hD%2Fsome-reflections-on-branching-vs-probability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1732, "htmlBody": "<p><span style=\"font-family: 'Times New Roman'; font-size: medium;\"> </span></p>\n<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; background-position: initial initial; background-repeat: initial initial; padding: 0.5em; margin: 8px;\">\n<h4>The \"Coin Universe\"</h4>\n<p>Imagine a universe split into subsystems A and B, where causal influences go from A to B but not vice versa. A is extremely simple - each day either a \"heads event\" or \"tails event\" takes place, which is visible to observers in B as a red or green patch at a certain place in the sky. In fact, coin events are the only 'communication' between A and B.</p>\n<p>Naturally, the observers in B would like to understand the pattern of coin events so they formulate some theories.</p>\n<h4>Two Rival Theories</h4>\n<p><strong style=\"font-weight: bold;\">Theory 1:</strong>&nbsp;Every day, the universe 'splits' into two. The entire contents of B are 'copied' somehow. One copy sees a heads event, the other copy sees a tails event.</p>\n<p><strong style=\"font-weight: bold;\">Theory 2:</strong>&nbsp;There is no splitting. Instead, some kind of (deterministic or stochastic) process in A is producing the sequence of events. As a special case (<strong style=\"font-weight: bold;\">Theory 2a</strong>) it could be that each coin event is independent and random, and has a probability 1/2 of being heads. (Let's also write down another special case (<strong style=\"font-weight: bold;\">Theory 2b</strong>) where each coin event has probability 9/10 of being heads.)</p>\n<h4>The Position of Jupiter</h4>\n<p>Imagine that we're primitive astronomers trying to understand the trajectory of Jupiter through the sky. We take for granted that our observations are indexed by a variable called \"time\" and that a complete theory of Jupiter's trajectory would have the form: \"Position of Jupiter at time t = F(t)\" for some function F that we can calculate. Suppose such a theory is formulated.</p>\n<p>However, if we believe in a point P such that P is \"the position of Jupiter\" then the theory does not resolve all of our uncertainty about P, for it merely tells us: \"If you ask the question at time t then the answer is F(t).\" If the question is asked \"timelessly\" then there is no unique answer. There isn't even a probability distribution over the set of possible answers, because there is no 'probability distribution over time'.<sup>1</sup></p>\n<h4>Theories 1 and 2 are Incommensurable</h4>\n<p>Can the scientists in the Coin Universe decide empirically between Theories 1 and 2a? Imagine that our scientists already have a 'theory of everything' for B's own physics, and that coin events are the only phenomena about which there remains controversy.</p>\n<div style=\"margin-bottom: 1em;\">Barbara believes in theory 2a and she thinks that the probability that the next toss is heads is 1/2. Alfred believes in theory 1 and thinks that the concept of \"tomorrow's coin event\" is as meaningless as the concept of \"the (timeless) position of Jupiter\".&nbsp;Whereas Barbara indexes time using real numbers, Alfred indexes time by pairs consisting of a real number and a sequence of prior coin events. Barbara cannot use Bayesian reasoning to discriminate 1 and 2a because from her perspective, theory 1 is incomplete - it refuses to make a prediction about \"tomorrow's coin event\". On the other hand, when Alfred tries to put Barbara's theory into a form that he can test, by taking out the meaningless notion of \"tomorrow's coin event\", he discovers that what's left is exactly his own theory.</div>\n<p>In fact, the same problem arises for&nbsp;<em style=\"font-style: italic;\">every</em>&nbsp;variation of Theory 2 (except those which sometimes predict a probability or 1 or 0).&nbsp;Variations of Theory 2 can be tested against each other, but not against Theory 1.</p>\n<h4>Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?</h4>\n<p>If the universe is splitting then a 'history of the universe' looks like a branching tree rather than a line. Now, I'm taking for granted an 'objective' concept of probability in which the set &Omega;&nbsp;of possible histories of the universe has the structure of a 'probability space', so that the only things which can be assigned ('objective') probabilities are subsets of&nbsp;&Omega;. So for any event E with a well-defined probability, and any possible history H, E must either contain all of H or else none of it. Hence, it makes no sense to look at some branch B within H and ask about \"the probability that B is true\". (Any more than we can look at a particular person in the world and ask \"what is the probability of being this person?\")</p>\n<p>A natural response might be as follows:</p>\n<p style=\"padding-left: 30px;\">Surely if time is a branching tree then all we have to do to define the probabilities of branches is say that the probability of a 'child node' is the probability of its parent divided by the number of 'children'. So we could simulate Theory 2a within a purely deterministic universe by having one 'heads branch' and one 'tails branch' each day of the simulation, or we could simulate Theory 2b instead by having nine 'heads branches' and only one 'tails'.</p>\n<p style=\"padding-left: 30px;\">Observers in the first simulation would experience 1/2 probabilities of heads, while observers in the second would experience 9/10 probabilities.</p>\n<p>(Note: We can make this idea of \"experiencing 1/2\" or \"experiencing 9/10\" more vivid by supposing that 'days' happen extremely quickly, so that experiencing 1/2 would mean that the relevant patch of sky is flickering between red and green so fast that it looks yellow, whereas 9/10 would equate to an orangey-red.)</p>\n<h4>The Lesson of the&nbsp;<a href=\"/lw/ps/where_physics_meets_experience/\"><span style=\"color: #000000;\">Ebborians</span></a></h4>\n<p>Consider the Ebborian universe. It has five dimensions: three 'ordinary' spatial dimensions, one of time and an 'extra' dimension reserved for 'splitting'. If you were to draw a cross section of the Ebborian universe along the temporal and the 'extra' dimension, you would see a branching tree. Suppose for simplicity that all such cross sections look alike, so that each time the universe 'splits' it happens everywhere simultaneously. Now, a critical point in Eliezer's fable is that the branches have thickness, and the subjective probability of finding yourself in a child branch is supposed to be proportional to the&nbsp;<em style=\"font-style: italic;\">square</em>&nbsp;of that branch's thickness. For my purposes I want branches to have widths, such that the width of a parent branch equal the sum of widths of its children, but I want to discard the idea of squaring. Imagine that the only times the universe 'splits' are once a day when a red or green light appears somewhere in the sky, which the Ebborians call a \"heads event\" or \"tails event\" respectively. Hmm, this sounds familiar...</p>\n<p>Prima facie it seems that we've reconstructed a version of the Coin Universe which (a) contains \"splitting\" and (b) contains \"objective probabilities\" (which \"clearly\" ought to be proportional to the widths of branches).</p>\n<p>What I want to ask is: why exactly should 'width along the extra dimension' be proportional to 'probability'? One possible answer would be \"that's just what the extra dimension&nbsp;<em style=\"font-style: italic;\">is</em>. It's&nbsp;<em style=\"font-style: italic;\">intrinsically</em>&nbsp;a 'dimension of probability'.\" That's fine, I guess, but then I want to say that the difference between this Coin Universe and one described by Theory 2 is purely verbal. But now suppose the extra dimension is just an ordinary spatial dimension (whatever that means). Then where does the rule 'probability = thickness' come from, when there are so many other possibilities? E.g. \"At any branch point, the probability of taking the left branch = (9/10) * (width of left branch / width of parent), and probability of right branch = (1/10) * (width of right branch / width of parent).\" If this was the rule then even though uniform branch widths may suggest that Theory 2a is correct, the 'experienced probabilities' would be those of Theory 2b. (If days were extremely rapid, the sky would look orange-red rather than yellow.)</p>\n<p>If the extra dimension is not explicitly a 'dimension of probability' then the 'experienced probabilities' will be indeterminate without a 'bridge law' connecting width and probability. But the difference between (\"extra dimension is spatial\" + bridge law connecting branch widths and probability) and (\"extra dimension is probability\" + bridge law connecting probabilities with epiphenomenal 'branch widths') is purely verbal.</p>\n<p>So ultimately the only two possibilities are (i) the extra dimension is a 'dimension of probability', and there is no 'splitting'; or else (ii) the probabilities are indeterminate.</p>\n<p>Of various possible conclusions, one in particular seems worth noting down: If we are attempting to simulate a Coin Universe by computing all of its branches at once, then regardless of how we 'tag' or 'weight' the branches to indicate their supposed probabilities, we should not think that we are thereby affecting the experiences of the simulated beings. (So ignoring 'externalities' there's no moral imperative that we should prefer two copies of a happy simulation and one of a sad simulation over two 'sad' simulations and one 'happy', any more than that we should stick pieces of paper to the computer cases saying \"probability 9/10\" and \"probability 1/10\".)</p>\n<h3 style=\"font-size: 15px; color: black; float: none;\"><br /></h3>\n<h4>Implications For MWI?</h4>\n<p>I don't want to go into too much detail. For what it's worth, my current way of thinking is that a quantum theory is neither \"deterministic\" nor \"probabilistic\" but just \"quantum\" (It constitutes \"Theory 3\"). Perhaps MWI is what you get when you (misguidedly) try to conceive of a quantum theory as deterministic? Two things in particular have suggested this to me: (i) Scott Aaronson's&nbsp;<a href=\"http://www.scottaaronson.com/democritus/lec9.html\">lecture</a>&nbsp;and (ii)&nbsp;<a href=\"http://xxx.lanl.gov/abs/quant-ph/0003084\">this paper</a>&nbsp;which goes some way towards refuting what I had previously taken to be one of the strongest reasons for 'believing in' many worlds.</p>\n<h4>Is Probability Reducible?</h4>\n<p>It's conspicuous that the discussion above presupposes that probabilities - \"real probabilities\" - are or might be 'built in' at the 'ground floor' of reality. However,&nbsp;<a href=\"/lw/2lj/what_a_reduction_of_probability_probably_looks/\">others</a>&nbsp;have made ingenious attempts to show how (our concepts and perceptions of) probability can arise perfectly well even if the universe doesn't presuppose it. I'm not averse to this project - in fact it parallels Dennett's strategy in the philosophy of mind, namely to show how it can 'seem like' we have 'qualia' even in a world where no such things exist.</p>\n<p>Anyway, I seem to be converging on cousin_it's statement: \"Perhaps counterintuitively, the easiest way for probabilities to arise is&nbsp;<em style=\"font-style: italic;\">not&nbsp;</em>by postulating 'different worlds' that you could 'end up' in starting from now.\"&nbsp;</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp;Perhaps Julian Barbour would disagree. However, for the purposes of my discussion, I'm presupposing the naive 'common sense' view of time where 'the facts' about a (classical) universe are exhausted precisely when we've specified \"the state of affairs at every moment of time\". Another possible objection is that because Jupiter's position in the sky repeats cyclically, we can define 'time averages' after all. Well, let's just suppose that these astronomers are able to detect the slight deviations due to e.g. the solar wind pushing Jupiter away and lengthening its orbit. (If you're still bothered, imagine replacing 'position of Jupiter' with 'brightness of the Sun', which is gradually increasing on a geological timescale.)</p>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NdesRveHP4fAn75hD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6192", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p><span style=\"font-family: 'Times New Roman'; font-size: medium;\"> </span></p>\n<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; background-position: initial initial; background-repeat: initial initial; padding: 0.5em; margin: 8px;\">\n<h4 id=\"The__Coin_Universe_\">The \"Coin Universe\"</h4>\n<p>Imagine a universe split into subsystems A and B, where causal influences go from A to B but not vice versa. A is extremely simple - each day either a \"heads event\" or \"tails event\" takes place, which is visible to observers in B as a red or green patch at a certain place in the sky. In fact, coin events are the only 'communication' between A and B.</p>\n<p>Naturally, the observers in B would like to understand the pattern of coin events so they formulate some theories.</p>\n<h4 id=\"Two_Rival_Theories\">Two Rival Theories</h4>\n<p><strong style=\"font-weight: bold;\">Theory 1:</strong>&nbsp;Every day, the universe 'splits' into two. The entire contents of B are 'copied' somehow. One copy sees a heads event, the other copy sees a tails event.</p>\n<p><strong style=\"font-weight: bold;\">Theory 2:</strong>&nbsp;There is no splitting. Instead, some kind of (deterministic or stochastic) process in A is producing the sequence of events. As a special case (<strong style=\"font-weight: bold;\">Theory 2a</strong>) it could be that each coin event is independent and random, and has a probability 1/2 of being heads. (Let's also write down another special case (<strong style=\"font-weight: bold;\">Theory 2b</strong>) where each coin event has probability 9/10 of being heads.)</p>\n<h4 id=\"The_Position_of_Jupiter\">The Position of Jupiter</h4>\n<p>Imagine that we're primitive astronomers trying to understand the trajectory of Jupiter through the sky. We take for granted that our observations are indexed by a variable called \"time\" and that a complete theory of Jupiter's trajectory would have the form: \"Position of Jupiter at time t = F(t)\" for some function F that we can calculate. Suppose such a theory is formulated.</p>\n<p>However, if we believe in a point P such that P is \"the position of Jupiter\" then the theory does not resolve all of our uncertainty about P, for it merely tells us: \"If you ask the question at time t then the answer is F(t).\" If the question is asked \"timelessly\" then there is no unique answer. There isn't even a probability distribution over the set of possible answers, because there is no 'probability distribution over time'.<sup>1</sup></p>\n<h4 id=\"Theories_1_and_2_are_Incommensurable\">Theories 1 and 2 are Incommensurable</h4>\n<p>Can the scientists in the Coin Universe decide empirically between Theories 1 and 2a? Imagine that our scientists already have a 'theory of everything' for B's own physics, and that coin events are the only phenomena about which there remains controversy.</p>\n<div style=\"margin-bottom: 1em;\">Barbara believes in theory 2a and she thinks that the probability that the next toss is heads is 1/2. Alfred believes in theory 1 and thinks that the concept of \"tomorrow's coin event\" is as meaningless as the concept of \"the (timeless) position of Jupiter\".&nbsp;Whereas Barbara indexes time using real numbers, Alfred indexes time by pairs consisting of a real number and a sequence of prior coin events. Barbara cannot use Bayesian reasoning to discriminate 1 and 2a because from her perspective, theory 1 is incomplete - it refuses to make a prediction about \"tomorrow's coin event\". On the other hand, when Alfred tries to put Barbara's theory into a form that he can test, by taking out the meaningless notion of \"tomorrow's coin event\", he discovers that what's left is exactly his own theory.</div>\n<p>In fact, the same problem arises for&nbsp;<em style=\"font-style: italic;\">every</em>&nbsp;variation of Theory 2 (except those which sometimes predict a probability or 1 or 0).&nbsp;Variations of Theory 2 can be tested against each other, but not against Theory 1.</p>\n<h4 id=\"Why_Should__Splitting__Entail_That_Probabilities_Aren_t_Well_Defined_\">Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?</h4>\n<p>If the universe is splitting then a 'history of the universe' looks like a branching tree rather than a line. Now, I'm taking for granted an 'objective' concept of probability in which the set \u03a9&nbsp;of possible histories of the universe has the structure of a 'probability space', so that the only things which can be assigned ('objective') probabilities are subsets of&nbsp;\u03a9. So for any event E with a well-defined probability, and any possible history H, E must either contain all of H or else none of it. Hence, it makes no sense to look at some branch B within H and ask about \"the probability that B is true\". (Any more than we can look at a particular person in the world and ask \"what is the probability of being this person?\")</p>\n<p>A natural response might be as follows:</p>\n<p style=\"padding-left: 30px;\">Surely if time is a branching tree then all we have to do to define the probabilities of branches is say that the probability of a 'child node' is the probability of its parent divided by the number of 'children'. So we could simulate Theory 2a within a purely deterministic universe by having one 'heads branch' and one 'tails branch' each day of the simulation, or we could simulate Theory 2b instead by having nine 'heads branches' and only one 'tails'.</p>\n<p style=\"padding-left: 30px;\">Observers in the first simulation would experience 1/2 probabilities of heads, while observers in the second would experience 9/10 probabilities.</p>\n<p>(Note: We can make this idea of \"experiencing 1/2\" or \"experiencing 9/10\" more vivid by supposing that 'days' happen extremely quickly, so that experiencing 1/2 would mean that the relevant patch of sky is flickering between red and green so fast that it looks yellow, whereas 9/10 would equate to an orangey-red.)</p>\n<h4 id=\"The_Lesson_of_the_Ebborians\">The Lesson of the&nbsp;<a href=\"/lw/ps/where_physics_meets_experience/\"><span style=\"color: #000000;\">Ebborians</span></a></h4>\n<p>Consider the Ebborian universe. It has five dimensions: three 'ordinary' spatial dimensions, one of time and an 'extra' dimension reserved for 'splitting'. If you were to draw a cross section of the Ebborian universe along the temporal and the 'extra' dimension, you would see a branching tree. Suppose for simplicity that all such cross sections look alike, so that each time the universe 'splits' it happens everywhere simultaneously. Now, a critical point in Eliezer's fable is that the branches have thickness, and the subjective probability of finding yourself in a child branch is supposed to be proportional to the&nbsp;<em style=\"font-style: italic;\">square</em>&nbsp;of that branch's thickness. For my purposes I want branches to have widths, such that the width of a parent branch equal the sum of widths of its children, but I want to discard the idea of squaring. Imagine that the only times the universe 'splits' are once a day when a red or green light appears somewhere in the sky, which the Ebborians call a \"heads event\" or \"tails event\" respectively. Hmm, this sounds familiar...</p>\n<p>Prima facie it seems that we've reconstructed a version of the Coin Universe which (a) contains \"splitting\" and (b) contains \"objective probabilities\" (which \"clearly\" ought to be proportional to the widths of branches).</p>\n<p>What I want to ask is: why exactly should 'width along the extra dimension' be proportional to 'probability'? One possible answer would be \"that's just what the extra dimension&nbsp;<em style=\"font-style: italic;\">is</em>. It's&nbsp;<em style=\"font-style: italic;\">intrinsically</em>&nbsp;a 'dimension of probability'.\" That's fine, I guess, but then I want to say that the difference between this Coin Universe and one described by Theory 2 is purely verbal. But now suppose the extra dimension is just an ordinary spatial dimension (whatever that means). Then where does the rule 'probability = thickness' come from, when there are so many other possibilities? E.g. \"At any branch point, the probability of taking the left branch = (9/10) * (width of left branch / width of parent), and probability of right branch = (1/10) * (width of right branch / width of parent).\" If this was the rule then even though uniform branch widths may suggest that Theory 2a is correct, the 'experienced probabilities' would be those of Theory 2b. (If days were extremely rapid, the sky would look orange-red rather than yellow.)</p>\n<p>If the extra dimension is not explicitly a 'dimension of probability' then the 'experienced probabilities' will be indeterminate without a 'bridge law' connecting width and probability. But the difference between (\"extra dimension is spatial\" + bridge law connecting branch widths and probability) and (\"extra dimension is probability\" + bridge law connecting probabilities with epiphenomenal 'branch widths') is purely verbal.</p>\n<p>So ultimately the only two possibilities are (i) the extra dimension is a 'dimension of probability', and there is no 'splitting'; or else (ii) the probabilities are indeterminate.</p>\n<p>Of various possible conclusions, one in particular seems worth noting down: If we are attempting to simulate a Coin Universe by computing all of its branches at once, then regardless of how we 'tag' or 'weight' the branches to indicate their supposed probabilities, we should not think that we are thereby affecting the experiences of the simulated beings. (So ignoring 'externalities' there's no moral imperative that we should prefer two copies of a happy simulation and one of a sad simulation over two 'sad' simulations and one 'happy', any more than that we should stick pieces of paper to the computer cases saying \"probability 9/10\" and \"probability 1/10\".)</p>\n<h3 style=\"font-size: 15px; color: black; float: none;\"><br></h3>\n<h4 id=\"Implications_For_MWI_\">Implications For MWI?</h4>\n<p>I don't want to go into too much detail. For what it's worth, my current way of thinking is that a quantum theory is neither \"deterministic\" nor \"probabilistic\" but just \"quantum\" (It constitutes \"Theory 3\"). Perhaps MWI is what you get when you (misguidedly) try to conceive of a quantum theory as deterministic? Two things in particular have suggested this to me: (i) Scott Aaronson's&nbsp;<a href=\"http://www.scottaaronson.com/democritus/lec9.html\">lecture</a>&nbsp;and (ii)&nbsp;<a href=\"http://xxx.lanl.gov/abs/quant-ph/0003084\">this paper</a>&nbsp;which goes some way towards refuting what I had previously taken to be one of the strongest reasons for 'believing in' many worlds.</p>\n<h4 id=\"Is_Probability_Reducible_\">Is Probability Reducible?</h4>\n<p>It's conspicuous that the discussion above presupposes that probabilities - \"real probabilities\" - are or might be 'built in' at the 'ground floor' of reality. However,&nbsp;<a href=\"/lw/2lj/what_a_reduction_of_probability_probably_looks/\">others</a>&nbsp;have made ingenious attempts to show how (our concepts and perceptions of) probability can arise perfectly well even if the universe doesn't presuppose it. I'm not averse to this project - in fact it parallels Dennett's strategy in the philosophy of mind, namely to show how it can 'seem like' we have 'qualia' even in a world where no such things exist.</p>\n<p>Anyway, I seem to be converging on cousin_it's statement: \"Perhaps counterintuitively, the easiest way for probabilities to arise is&nbsp;<em style=\"font-style: italic;\">not&nbsp;</em>by postulating 'different worlds' that you could 'end up' in starting from now.\"&nbsp;</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp;Perhaps Julian Barbour would disagree. However, for the purposes of my discussion, I'm presupposing the naive 'common sense' view of time where 'the facts' about a (classical) universe are exhausted precisely when we've specified \"the state of affairs at every moment of time\". Another possible objection is that because Jupiter's position in the sky repeats cyclically, we can define 'time averages' after all. Well, let's just suppose that these astronomers are able to detect the slight deviations due to e.g. the solar wind pushing Jupiter away and lengthening its orbit. (If you're still bothered, imagine replacing 'position of Jupiter' with 'brightness of the Sun', which is gradually increasing on a geological timescale.)</p>\n</div>\n<p>&nbsp;</p>", "sections": [{"title": "The \"Coin Universe\"", "anchor": "The__Coin_Universe_", "level": 1}, {"title": "Two Rival Theories", "anchor": "Two_Rival_Theories", "level": 1}, {"title": "The Position of Jupiter", "anchor": "The_Position_of_Jupiter", "level": 1}, {"title": "Theories 1 and 2 are Incommensurable", "anchor": "Theories_1_and_2_are_Incommensurable", "level": 1}, {"title": "Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?", "anchor": "Why_Should__Splitting__Entail_That_Probabilities_Aren_t_Well_Defined_", "level": 1}, {"title": "The Lesson of the\u00a0Ebborians", "anchor": "The_Lesson_of_the_Ebborians", "level": 1}, {"title": "Implications For MWI?", "anchor": "Implications_For_MWI_", "level": 1}, {"title": "Is Probability Reducible?", "anchor": "Is_Probability_Reducible_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WajiC3YWeJutyAXTn", "As3Xjtj2TRRar7bSX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T15:24:34.247Z", "modifiedAt": null, "url": null, "title": "Public service announcement - Bay Area tsunami warning!", "slug": "public-service-announcement-bay-area-tsunami-warning", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2JQE7PiGfysDe9GjX/public-service-announcement-bay-area-tsunami-warning", "pageUrlRelative": "/posts/2JQE7PiGfysDe9GjX/public-service-announcement-bay-area-tsunami-warning", "linkUrl": "https://www.lesswrong.com/posts/2JQE7PiGfysDe9GjX/public-service-announcement-bay-area-tsunami-warning", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Public%20service%20announcement%20-%20Bay%20Area%20tsunami%20warning!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APublic%20service%20announcement%20-%20Bay%20Area%20tsunami%20warning!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JQE7PiGfysDe9GjX%2Fpublic-service-announcement-bay-area-tsunami-warning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Public%20service%20announcement%20-%20Bay%20Area%20tsunami%20warning!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JQE7PiGfysDe9GjX%2Fpublic-service-announcement-bay-area-tsunami-warning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JQE7PiGfysDe9GjX%2Fpublic-service-announcement-bay-area-tsunami-warning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p><a href=\"http://www.mercurynews.com/news/ci_17589513?nclick_check=1\">http://www.mercurynews.com/news/ci_17589513?nclick_check=1</a></p>\n<p>please do not upvote, main page is enough. will be removed after expiration.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2JQE7PiGfysDe9GjX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6193", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-11T20:49:11.198Z", "modifiedAt": null, "url": null, "title": "Consulting Opportunity for Budding Econometricians", "slug": "consulting-opportunity-for-budding-econometricians", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:57.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "b1shop", "createdAt": "2010-07-21T22:58:23.412Z", "isAdmin": false, "displayName": "b1shop"}, "userId": "YYM9ouBdPbNFxvF2G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L64ScQHY4uiGpP9h5/consulting-opportunity-for-budding-econometricians", "pageUrlRelative": "/posts/L64ScQHY4uiGpP9h5/consulting-opportunity-for-budding-econometricians", "linkUrl": "https://www.lesswrong.com/posts/L64ScQHY4uiGpP9h5/consulting-opportunity-for-budding-econometricians", "postedAtFormatted": "Friday, March 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Consulting%20Opportunity%20for%20Budding%20Econometricians&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConsulting%20Opportunity%20for%20Budding%20Econometricians%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL64ScQHY4uiGpP9h5%2Fconsulting-opportunity-for-budding-econometricians%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Consulting%20Opportunity%20for%20Budding%20Econometricians%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL64ScQHY4uiGpP9h5%2Fconsulting-opportunity-for-budding-econometricians", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL64ScQHY4uiGpP9h5%2Fconsulting-opportunity-for-budding-econometricians", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>As a part of my job, I recently created an econometric model. My boss wants someone to look over the math before its submitted internally throughout the company. We have a modest amount of money set aside for someone to audit the process.</p>\n<p>The model is an ARMA(2,1) with seasonality, trend, and a dummy variable. There's no heteroscedasticity or serial correlation, but the Ramsey Reset test suggests a more different model might work better.</p>\n<p>I currently have the data in an eviews file, so you'd need to do zero data entry.</p>\n<p>There's a small chance this will be used in court, but none of the liability will be transferred to you. There should be an emphasis placed on parsimony.&nbsp;You'd have to sign a confidentiality agreement.</p>\n<p>If you're qualified to review this/suggest a marginally better model, then this would be an easy way for you to make bank in a couple hours time. If it goes well, there might be more work like this in the future.</p>\n<p>Let me know if you're interested.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L64ScQHY4uiGpP9h5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 19, "extendedScore": null, "score": 6.888315250058662e-07, "legacy": true, "legacyId": "6194", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-12T05:21:40.902Z", "modifiedAt": null, "url": null, "title": "Cryonics and the importance of body to cognition", "slug": "cryonics-and-the-importance-of-body-to-cognition", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.203Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2v2GHDoPo3TnkKgz2/cryonics-and-the-importance-of-body-to-cognition", "pageUrlRelative": "/posts/2v2GHDoPo3TnkKgz2/cryonics-and-the-importance-of-body-to-cognition", "linkUrl": "https://www.lesswrong.com/posts/2v2GHDoPo3TnkKgz2/cryonics-and-the-importance-of-body-to-cognition", "postedAtFormatted": "Saturday, March 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20and%20the%20importance%20of%20body%20to%20cognition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20and%20the%20importance%20of%20body%20to%20cognition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v2GHDoPo3TnkKgz2%2Fcryonics-and-the-importance-of-body-to-cognition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20and%20the%20importance%20of%20body%20to%20cognition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v2GHDoPo3TnkKgz2%2Fcryonics-and-the-importance-of-body-to-cognition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2v2GHDoPo3TnkKgz2%2Fcryonics-and-the-importance-of-body-to-cognition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 90, "htmlBody": "<p>Many approaches to cryonics assume that a detailed map of the neural patterns in a brain (via brain scanning technology) may be sufficient, using future technology, to bring that person \"back to life.\" But cognition is greatly shaped by more than just the neural pattern: it is shaped by biology - by the body. (See <a href=\"http://www.amazon.com/Out-Our-Heads-Lessons-Consciousness/dp/0809016486/\">Noe 2009</a>; <a href=\"http://www.amazon.com/How-Body-Shapes-Way-Think/dp/0262162393/\">Pfeifer et al. 2006</a>; <a href=\"http://www.amazon.com/Philosophy-Flesh-Embodied-Challenge-Western/dp/0465056741/\">Lakoff &amp; Johnson 1999</a>.)</p>\n<p>I admit I'm pretty unfamiliar with the cryonics literature. I assume this is a standard objection, and has standard responses. Where can I find those responses?</p>\n<p>Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2v2GHDoPo3TnkKgz2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 6.889707635097773e-07, "legacy": true, "legacyId": "6195", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-12T10:13:11.646Z", "modifiedAt": null, "url": null, "title": "What other causes are relevant to LessWrong?", "slug": "what-other-causes-are-relevant-to-lesswrong", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.030Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e3xGiiPfXjrtLzvMn/what-other-causes-are-relevant-to-lesswrong", "pageUrlRelative": "/posts/e3xGiiPfXjrtLzvMn/what-other-causes-are-relevant-to-lesswrong", "linkUrl": "https://www.lesswrong.com/posts/e3xGiiPfXjrtLzvMn/what-other-causes-are-relevant-to-lesswrong", "postedAtFormatted": "Saturday, March 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20other%20causes%20are%20relevant%20to%20LessWrong%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20other%20causes%20are%20relevant%20to%20LessWrong%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe3xGiiPfXjrtLzvMn%2Fwhat-other-causes-are-relevant-to-lesswrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20other%20causes%20are%20relevant%20to%20LessWrong%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe3xGiiPfXjrtLzvMn%2Fwhat-other-causes-are-relevant-to-lesswrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe3xGiiPfXjrtLzvMn%2Fwhat-other-causes-are-relevant-to-lesswrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 234, "htmlBody": "<p>This post is prompted by a <a href=\"/lw/ye/and_say_no_more_of_it/3o9e?context=3\">short discussion</a> with Wei Dai. He says:</p>\n<p style=\"padding-left: 30px;\">Perhaps we should get other causes to participate/recruit on LW? Actually, why aren't they here already? We have a bunch of individuals with non-SIAI interests, but no <em>causes</em> other than SIAI, despite Eliezer repeatedly saying that they would be welcome.</p>\n<p>He has a good point!</p>\n<p>Here's my plug, for the cause I spend lots of my time and energy on, Wikimedia/Wikipedia:</p>\n<p style=\"padding-left: 30px;\">Wikipedia/Wikimedia is more analogous to a software project than an ordinary charity - your money is useful and most welcomed, but the real contribution is your <em>knowledge</em>.</p>\n<p style=\"padding-left: 30px;\">Or, more generally: create educational material under a <a rel=\"nofollow\" href=\"http://freedomdefined.org/Definition\">free content licence</a>. If it's CC-by-sa, CC-by or public domain, it can interbreed and propagate.</p>\n<p>(Then we need to fix the things wrong with the editor experience on Wikipedia ... though the Wikimedia Foundation is <a href=\"http://strategy.wikimedia.org/wiki/March_2011_Update\">paying serious attention to that as well</a> of late. In the meantime, if you find Wikipedia too personally annoying to participate in directly, writing your own site and CC-by-sa'ing it <a href=\"http://davidgerard.co.uk/notes/2011/01/19/single-point-of-failure/\">still helps a lot</a>.)</p>\n<p>What good causes can you think of that are relevant to LessWrong and its community, that leverage effectiveness through rationality? (I'm thinking beyond just legally-blessed charities, right down to the \"small circle of conspirators\" level of trying together to get something done.) As well as SIAI, LW has previously had plugs for <a href=\"/r/discussion/lw/4lb/is_givewellorg_the_best_charity_excluding_siai\">GiveWell</a>. What do<em> you</em> spend <em>your</em> time, effort and/or money on?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e3xGiiPfXjrtLzvMn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 22, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "6202", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qZT6AMhNBbuzneEJt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-12T19:41:44.756Z", "modifiedAt": null, "url": null, "title": "Making Reasoning Obviously Locally Correct", "slug": "making-reasoning-obviously-locally-correct", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GWmKnsmGK7985ZkRP/making-reasoning-obviously-locally-correct", "pageUrlRelative": "/posts/GWmKnsmGK7985ZkRP/making-reasoning-obviously-locally-correct", "linkUrl": "https://www.lesswrong.com/posts/GWmKnsmGK7985ZkRP/making-reasoning-obviously-locally-correct", "postedAtFormatted": "Saturday, March 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Making%20Reasoning%20Obviously%20Locally%20Correct&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaking%20Reasoning%20Obviously%20Locally%20Correct%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWmKnsmGK7985ZkRP%2Fmaking-reasoning-obviously-locally-correct%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Making%20Reasoning%20Obviously%20Locally%20Correct%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWmKnsmGK7985ZkRP%2Fmaking-reasoning-obviously-locally-correct", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWmKnsmGK7985ZkRP%2Fmaking-reasoning-obviously-locally-correct", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1056, "htmlBody": "<blockquote>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x<sup>2</sup> = x*y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; x<sup>2</sup> - y<sup>2</sup> = x*y - y<sup>2</sup></p>\n<p>(x+y)(x-y) = y(x-y)</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x+y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; y+y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2*y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2 = 1</p>\n</blockquote>\n<p>The above is an incorrect \"proof\" that 2=1. Even for those who know where the flaw is, it might seem reasonable to react to the existence of this \"proof\" by distrusting mathematical reasoning, which might contain such flaws that lead to erroneous results. But done properly, mathematical reasoning does not look like this \"proof\". It is more explicit, making each step obviously correct that an incorrect step cannot meet the standard. Let's take a look at what would happen when attempting to present this \"proof\" following this virtue:</p>\n<p><a id=\"more\"></a></p>\n<p>The set of real numbers is known to be non empty, so let y be a real number. Let x = y.</p>\n<p>By an axiom of the real numbers, a real number multiplied by a real number is a real number, so x*x = x*y.<sup>&alpha;</sup></p>\n<p>By the same axiom y*y is a real number. By an axiom y*y has an additive inverse -y*y.</p>\n<p>By an axiom, adding a real number to a real number is a real number, so x*x + -y*y = x*y + -y*y.</p>\n<p>By axioms defining addition, multiplication, and additive inverse, (x+y)*(x+-y) and y*(x+-y) are real numbers.</p>\n<p>By the distributive law of multiplication over addition, (x+y)*(x+-y) = (x+y)*x + (x+y)*(-y) = x*x + y*x + x*(-y) + y*(-y)</p>\n<p>By commutativity and associativity of addition and multiplication, and distribution of multiplication over additive inverses,</p>\n<p>&nbsp; x*x + y*x + x*(-y) + y*(-y) = x*x + (x*y + -x*y) + - y*y = x*x + -y*y</p>\n<p>Similarly y*(x+-y) = y*x + y*(-y) = x*y + -y*y</p>\n<p>So, by transitivity of equality, (x+y)*(x+-y) = y*(x+-y)</p>\n<p>By an axiom a real number not equal to zero has a multiplicative inverse. I want x+-y to have a multiplicative inverse, so I want to prove that x+-y is not zero, but I can't, since it is not true. By construction x = y, so x+-y= y+-y, and by the definition of an additive inverse, y+-y = 0. The proof fails.</p>\n<p>Now, <a title=\"Outside the Laboratory\" href=\"/lw/gv/outside_the_laboratory/\">citing axioms and theorems to justify a step in a proof is not a mere social convention to make mathematicians happy</a>. It is a useful constraint on your cognition, allowing you to make only inferences that are actually valid. Similarly, there is a virtue in the art of programming that constrains you from making mistakes in code. In <a href=\"http://www.joelonsoftware.com/articles/Wrong.html\">Making Wrong Code Look Wrong</a>, Joel Spolsky describes a solution to the problem of keeping track of which strings are already HTML encoded and ready to be written to a web page, and which strings are unformatted and may have come from a malicious user who wants to inject an evil script into your website (or a normal user who wants to display a message with characters that happen to be HTML control characters):</p>\n<blockquote>\n<p>All strings that come from the user must be stored in variables (or database columns) with a name starting with the prefix \"us\" (for Unsafe String). All strings that have been HTML encoded or which came from a known-safe location must be stored in variables with a name starting with the prefix \"s\" (for Safe string).</p>\n<p>Let me rewrite that same code, changing nothing but the variable names to match our new convention.</p>\n<p><strong><tt>us = Request(\"name\")</tt></strong></p>\n<p><tt>...pages later...<br /><strong>usName = us</strong></tt></p>\n<p><tt>...pages later...<br /><strong>recordset(\"usName\") = usName </strong></tt></p>\n<p><tt>...days later...<br /><strong>sName = Encode(recordset(\"usName\"))</strong></tt></p>\n<p><tt>...pages or even months later...<br /><strong>Write sName</strong></tt></p>\n<p>Every line of code can be inspected <em>by itself</em>, and if every line of code is correct, the entire body of code is correct.</p>\n<p>The thing I want you to notice about the new convention is that now, if you make a mistake with an unsafe string, <em>you can always see it on some single line of code</em>, as long as the coding convention is adhered to:</p>\n<p><tt><strong>s = Request(\"name\")</strong></tt></p>\n<p>is a priori wrong, because you see the result of <tt>Request</tt> being assigned to a variable whose name begins with <tt>s</tt>, which is against the rules. The result of <tt>Request</tt> is always unsafe so it must always be assigned to a variable whose name begins with &ldquo;us&rdquo;.</p>\n<p><strong><tt>us = Request(\"name\")</tt></strong></p>\n<p>is always OK.</p>\n<p><tt><strong>usName = us</strong></tt></p>\n<p>is always OK.</p>\n<p><tt><strong>sName = us</strong></tt></p>\n<p>is certainly wrong.</p>\n<p><tt><strong>sName = Encode(us)</strong></tt></p>\n<p>is certainly correct.</p>\n<p><tt><strong>Write usName</strong></tt></p>\n<p>is certainly wrong.</p>\n<p><tt><strong>Write sName</strong></tt></p>\n<p>is OK, as is</p>\n<p><tt><strong>Write Encode(usName)</strong></tt></p>\n</blockquote>\n<p>Just like the single step in the attempted mathematical proof that can't be explicitly justified, a single line of code violating Spolsky's convention is obviously wrong. In both these cases, it is possible to be sufficiently explicit and detailed that an automated process can verify correctness, a proof verifier for mathematics and compilers and static analysis for computer programs.</p>\n<p>What about in domains where everything is not so clearly defined, where you have to deal with uncertainty? Well, first of all, <a title=\"Beautiful Probability\" href=\"/lw/mt/beautiful_probability/\">probability theory is a mathematical description of uncertainty</a>. You can be rigorous in keeping track of what the ideal amount of uncertainty is for a particular claim. Though that is a lot of work, and may be worthwhile only for beliefs that inform important decisions. But even in your everyday reasoning, beware local mistakes. Just as Spolsky would advise you to <a title=\"When to Scream Error\" href=\"/lw/4le/when_to_scream_error/\">scream \"Error!\"</a> wherever an unsafe string is stored in a variable meant for safe strings, even if that unsafe string never ends up written to a web page (until someone makes some locally correct modifications), don't wait for a global failure to hit you over the head with the wrongness of your local mistake. Nip that problem in the bud, back up, and do it right. And try to have a simply verified concept of locally correct that still adds up to globally correct.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>&alpha;. I am being extra explicit in that I am avoiding using common notations that have been carefully defined with rules of manipulation derived from more basic rules of inference. This is for the benefit of non mathematicians who may have learned these notations (like subtraction, exponents) but not their justifications.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GWmKnsmGK7985ZkRP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 28, "extendedScore": null, "score": 6.892045440823633e-07, "legacy": true, "legacyId": "6204", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x<sup>2</sup> = x*y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; x<sup>2</sup> - y<sup>2</sup> = x*y - y<sup>2</sup></p>\n<p>(x+y)(x-y) = y(x-y)</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x+y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; y+y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2*y = y</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2 = 1</p>\n</blockquote>\n<p>The above is an incorrect \"proof\" that 2=1. Even for those who know where the flaw is, it might seem reasonable to react to the existence of this \"proof\" by distrusting mathematical reasoning, which might contain such flaws that lead to erroneous results. But done properly, mathematical reasoning does not look like this \"proof\". It is more explicit, making each step obviously correct that an incorrect step cannot meet the standard. Let's take a look at what would happen when attempting to present this \"proof\" following this virtue:</p>\n<p><a id=\"more\"></a></p>\n<p>The set of real numbers is known to be non empty, so let y be a real number. Let x = y.</p>\n<p>By an axiom of the real numbers, a real number multiplied by a real number is a real number, so x*x = x*y.<sup>\u03b1</sup></p>\n<p>By the same axiom y*y is a real number. By an axiom y*y has an additive inverse -y*y.</p>\n<p>By an axiom, adding a real number to a real number is a real number, so x*x + -y*y = x*y + -y*y.</p>\n<p>By axioms defining addition, multiplication, and additive inverse, (x+y)*(x+-y) and y*(x+-y) are real numbers.</p>\n<p>By the distributive law of multiplication over addition, (x+y)*(x+-y) = (x+y)*x + (x+y)*(-y) = x*x + y*x + x*(-y) + y*(-y)</p>\n<p>By commutativity and associativity of addition and multiplication, and distribution of multiplication over additive inverses,</p>\n<p>&nbsp; x*x + y*x + x*(-y) + y*(-y) = x*x + (x*y + -x*y) + - y*y = x*x + -y*y</p>\n<p>Similarly y*(x+-y) = y*x + y*(-y) = x*y + -y*y</p>\n<p>So, by transitivity of equality, (x+y)*(x+-y) = y*(x+-y)</p>\n<p>By an axiom a real number not equal to zero has a multiplicative inverse. I want x+-y to have a multiplicative inverse, so I want to prove that x+-y is not zero, but I can't, since it is not true. By construction x = y, so x+-y= y+-y, and by the definition of an additive inverse, y+-y = 0. The proof fails.</p>\n<p>Now, <a title=\"Outside the Laboratory\" href=\"/lw/gv/outside_the_laboratory/\">citing axioms and theorems to justify a step in a proof is not a mere social convention to make mathematicians happy</a>. It is a useful constraint on your cognition, allowing you to make only inferences that are actually valid. Similarly, there is a virtue in the art of programming that constrains you from making mistakes in code. In <a href=\"http://www.joelonsoftware.com/articles/Wrong.html\">Making Wrong Code Look Wrong</a>, Joel Spolsky describes a solution to the problem of keeping track of which strings are already HTML encoded and ready to be written to a web page, and which strings are unformatted and may have come from a malicious user who wants to inject an evil script into your website (or a normal user who wants to display a message with characters that happen to be HTML control characters):</p>\n<blockquote>\n<p>All strings that come from the user must be stored in variables (or database columns) with a name starting with the prefix \"us\" (for Unsafe String). All strings that have been HTML encoded or which came from a known-safe location must be stored in variables with a name starting with the prefix \"s\" (for Safe string).</p>\n<p>Let me rewrite that same code, changing nothing but the variable names to match our new convention.</p>\n<p><strong id=\"us___Request__name__\"><tt>us = Request(\"name\")</tt></strong></p>\n<p><tt>...pages later...<br><strong>usName = us</strong></tt></p>\n<p><tt>...pages later...<br><strong>recordset(\"usName\") = usName </strong></tt></p>\n<p><tt>...days later...<br><strong>sName = Encode(recordset(\"usName\"))</strong></tt></p>\n<p><tt>...pages or even months later...<br><strong>Write sName</strong></tt></p>\n<p>Every line of code can be inspected <em>by itself</em>, and if every line of code is correct, the entire body of code is correct.</p>\n<p>The thing I want you to notice about the new convention is that now, if you make a mistake with an unsafe string, <em>you can always see it on some single line of code</em>, as long as the coding convention is adhered to:</p>\n<p><tt><strong>s = Request(\"name\")</strong></tt></p>\n<p>is a priori wrong, because you see the result of <tt>Request</tt> being assigned to a variable whose name begins with <tt>s</tt>, which is against the rules. The result of <tt>Request</tt> is always unsafe so it must always be assigned to a variable whose name begins with \u201cus\u201d.</p>\n<p><strong id=\"us___Request__name__1\"><tt>us = Request(\"name\")</tt></strong></p>\n<p>is always OK.</p>\n<p><tt><strong>usName = us</strong></tt></p>\n<p>is always OK.</p>\n<p><tt><strong>sName = us</strong></tt></p>\n<p>is certainly wrong.</p>\n<p><tt><strong>sName = Encode(us)</strong></tt></p>\n<p>is certainly correct.</p>\n<p><tt><strong>Write usName</strong></tt></p>\n<p>is certainly wrong.</p>\n<p><tt><strong>Write sName</strong></tt></p>\n<p>is OK, as is</p>\n<p><tt><strong>Write Encode(usName)</strong></tt></p>\n</blockquote>\n<p>Just like the single step in the attempted mathematical proof that can't be explicitly justified, a single line of code violating Spolsky's convention is obviously wrong. In both these cases, it is possible to be sufficiently explicit and detailed that an automated process can verify correctness, a proof verifier for mathematics and compilers and static analysis for computer programs.</p>\n<p>What about in domains where everything is not so clearly defined, where you have to deal with uncertainty? Well, first of all, <a title=\"Beautiful Probability\" href=\"/lw/mt/beautiful_probability/\">probability theory is a mathematical description of uncertainty</a>. You can be rigorous in keeping track of what the ideal amount of uncertainty is for a particular claim. Though that is a lot of work, and may be worthwhile only for beliefs that inform important decisions. But even in your everyday reasoning, beware local mistakes. Just as Spolsky would advise you to <a title=\"When to Scream Error\" href=\"/lw/4le/when_to_scream_error/\">scream \"Error!\"</a> wherever an unsafe string is stored in a variable meant for safe strings, even if that unsafe string never ends up written to a web page (until someone makes some locally correct modifications), don't wait for a global failure to hit you over the head with the wrongness of your local mistake. Nip that problem in the bud, back up, and do it right. And try to have a simply verified concept of locally correct that still adds up to globally correct.</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p>\u03b1. I am being extra explicit in that I am avoiding using common notations that have been carefully defined with rules of manipulation derived from more basic rules of inference. This is for the benefit of non mathematicians who may have learned these notations (like subtraction, exponents) but not their justifications.</p>\n<p>&nbsp;</p>", "sections": [{"title": "us = Request(\"name\")", "anchor": "us___Request__name__", "level": 1}, {"title": "us = Request(\"name\")", "anchor": "us___Request__name__1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "26 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N2pENnTPB75sfc9kb", "bkSkRwo9SRYxJMiSY", "bWGzEgMw34jHH586F"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-12T20:00:09.650Z", "modifiedAt": null, "url": null, "title": "Tweetable Rationality ", "slug": "tweetable-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.836Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hZXYXZ67uftvL5bDx/tweetable-rationality", "pageUrlRelative": "/posts/hZXYXZ67uftvL5bDx/tweetable-rationality", "linkUrl": "https://www.lesswrong.com/posts/hZXYXZ67uftvL5bDx/tweetable-rationality", "postedAtFormatted": "Saturday, March 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tweetable%20Rationality%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATweetable%20Rationality%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZXYXZ67uftvL5bDx%2Ftweetable-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tweetable%20Rationality%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZXYXZ67uftvL5bDx%2Ftweetable-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZXYXZ67uftvL5bDx%2Ftweetable-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 300, "htmlBody": "<p>During the latest London Meetup, I asked: \"If you could spread one meme about rationality to the mainstream, what would that be?\"</p>\n<p>I realize that certain parts of rationality, like cognitive biases, should be taught as a unit, but I hypothesize that there exist rationality-enhancing lessons that can fit in 140 characters and stand on their own. Given that we want to spread rationality to those close to us and everyone else as well, it may be useful to work on developing compact versions of our most potent insights, and work on phrasing them in a way that is accessible to the mainstream.</p>\n<p>So this thread is a challenge to do just that: pick a rationality-related insight, and try to find 140 characters (or less) that express it well for the purpose of spreading it further. It may be a quote that has appeared in our quotes thread, it may be in the form of a joke, or maybe just a compact insight that can resonate. A non-obvious challenge is to avoid getting evaluated as 'obviously true' and discarded. I guess a better target reaction is (\"this sounds intriguing\"-&gt;\"huh, I hadn't thought about this that way!\")</p>\n<p>Don't worry too much about getting it perfect the first time; we can use the threaded comments system to collaborate. If you see a way to improve a sentence, propose the improvement as a response to it. forming a tree of alternative versions, with votes to sort them.</p>\n<p>If you see a version of a meme developed somewhere in the thread that reaches your required awesomeness threshold, you can also post it to your (facebook/twitter/whatever else) followers. I certainly will.</p>\n<p><strong>Edit</strong>: As per Luke's suggestion, I went and made a <a href=\"http://twitter.com/#!/Rationalitweet\">twitter account</a>&nbsp;that we can use to tweet good sentences that come out of this thread. Feel free to follow.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hZXYXZ67uftvL5bDx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 6.892095510986582e-07, "legacy": true, "legacyId": "6205", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-12T20:54:48.629Z", "modifiedAt": null, "url": null, "title": "Bayesianism in the face of unknowns", "slug": "bayesianism-in-the-face-of-unknowns", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.119Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rstarkov", "createdAt": "2011-02-21T19:53:18.490Z", "isAdmin": false, "displayName": "rstarkov"}, "userId": "tsHG32deqwFhnQ2sx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DKHywj3WGf2GwXgD6/bayesianism-in-the-face-of-unknowns", "pageUrlRelative": "/posts/DKHywj3WGf2GwXgD6/bayesianism-in-the-face-of-unknowns", "linkUrl": "https://www.lesswrong.com/posts/DKHywj3WGf2GwXgD6/bayesianism-in-the-face-of-unknowns", "postedAtFormatted": "Saturday, March 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesianism%20in%20the%20face%20of%20unknowns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesianism%20in%20the%20face%20of%20unknowns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDKHywj3WGf2GwXgD6%2Fbayesianism-in-the-face-of-unknowns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesianism%20in%20the%20face%20of%20unknowns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDKHywj3WGf2GwXgD6%2Fbayesianism-in-the-face-of-unknowns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDKHywj3WGf2GwXgD6%2Fbayesianism-in-the-face-of-unknowns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 325, "htmlBody": "<p>Suppose I tell you I have an infinite supply of unfair coins. I pick one <em>randomly</em> and flip it, recording the result. I've done this a total of 100 times and they all came out heads. I will pay you $1000 if the next throw is heads, and $10 if it's tails. Each unfair coin is entirely normal, whose \"heads\" follow a binomial distribution with an unknown <em>p</em>. This is all you know. How much would you pay to enter this game?</p>\n<p>I suppose another way to phrase this question is \"what is your best estimate of your expected winnings?\", or, more generally, \"how do you choose the maximum price you'll pay to play this game?\"</p>\n<p>Observe that the only fact you know about the distribution from which I'm drawing my coins is those 100 outcomes. Importantly, you don't know the distribution of each coin's <em>p</em> in my supply of unfair coins. Can you reasonably assume a specific distribution to make your calculation, and claim that it results in a better <em>best estimate</em> than any other distribution?</p>\n<p>Most importantly, can one actually produce a \"theoretically sound\" expectation here? I.e. one that is calibrated so that if you pay your expected winnings every time and we perform this experiment lots of times then your average winnings will be zero - assuming I'm using the same source of unfair coins each time.</p>\n<p>I suspect that the best one can do here is produce a range of values with confidence intervals. So you're 80% confident that the price you should pay to break even in the repeated game is between A80 and B80, 95% confident it's between A95 and B95, etc.</p>\n<p>If this is really the best obtainable result, then what is a bayesianist to do with such a result to make their decision? Do you pick a price randomly from a specially crafted distribution, which is 95% likely to produce a value between A95..B95, etc? Or is there a more \"bayesian\" way?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DKHywj3WGf2GwXgD6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "6206", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T01:37:12.407Z", "modifiedAt": null, "url": null, "title": "Kantian baby rats", "slug": "kantian-baby-rats", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:20.176Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MkxKzNuMyY9mmeGoE/kantian-baby-rats", "pageUrlRelative": "/posts/MkxKzNuMyY9mmeGoE/kantian-baby-rats", "linkUrl": "https://www.lesswrong.com/posts/MkxKzNuMyY9mmeGoE/kantian-baby-rats", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kantian%20baby%20rats&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKantian%20baby%20rats%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMkxKzNuMyY9mmeGoE%2Fkantian-baby-rats%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kantian%20baby%20rats%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMkxKzNuMyY9mmeGoE%2Fkantian-baby-rats", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMkxKzNuMyY9mmeGoE%2Fkantian-baby-rats", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>I've often wished for a list of cases where philosophy has proven useful, or has at least anticipated science in drawing correct conclusions.&nbsp; Here's one for the list:</p>\n<p>The June 18 2010 Science has two very similar articles on how rat brains represent space.&nbsp; Both conclude that the brain already represents space as a grid before rat pups take their first steps into the world.&nbsp; Both make the point that this validates Kant's claim that space is an innate concept prior to experience.</p>\n<p>(The next task is to make a corresponding list of cases where philosophers made incorrect conclusions; and estimate whether the number of correct conclusions is greater than chance.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MkxKzNuMyY9mmeGoE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 6.893012055797862e-07, "legacy": true, "legacyId": "6207", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T10:26:39.293Z", "modifiedAt": null, "url": null, "title": "Cryonics in Australia: How do you actually do it?", "slug": "cryonics-in-australia-how-do-you-actually-do-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:03.856Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Maelin", "createdAt": "2009-05-28T03:32:36.549Z", "isAdmin": false, "displayName": "Maelin"}, "userId": "CE5vuYfsSRTeG2KWd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3xuEaoZXPt2jYcQ3Z/cryonics-in-australia-how-do-you-actually-do-it", "pageUrlRelative": "/posts/3xuEaoZXPt2jYcQ3Z/cryonics-in-australia-how-do-you-actually-do-it", "linkUrl": "https://www.lesswrong.com/posts/3xuEaoZXPt2jYcQ3Z/cryonics-in-australia-how-do-you-actually-do-it", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20in%20Australia%3A%20How%20do%20you%20actually%20do%20it%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20in%20Australia%3A%20How%20do%20you%20actually%20do%20it%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xuEaoZXPt2jYcQ3Z%2Fcryonics-in-australia-how-do-you-actually-do-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20in%20Australia%3A%20How%20do%20you%20actually%20do%20it%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xuEaoZXPt2jYcQ3Z%2Fcryonics-in-australia-how-do-you-actually-do-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xuEaoZXPt2jYcQ3Z%2Fcryonics-in-australia-how-do-you-actually-do-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 328, "htmlBody": "<p>Today it struck me just how dumb it was to agree fully with the desirability of being signed up for cryonics and yet <strong>not</strong>&nbsp;be so. I may, in perfect honesty, also be procrastinating from a piece of uni work that I need to do by Tuesday, but I intend to get right back to it after posting this.</p>\n<p>Last time I looked into signing up for cryonics I found it confusing and intimidating, which quickly built up to a level where I abandoned the quest. Now that I have a piece of assessment looming, it is time to do something about it.</p>\n<p>But I don't really know where to start. What do you do to get signed up for cryonics? Join the <a title=\"Cryonics Association of Australia\" href=\"http://www.cryonics.org.au/home\" target=\"_blank\">Cryonics Association of Australia</a>? There seems to be a requirement for membership of a US organisation too. You can either say \"I have joined/intend to join a US cryonics organisation\" and pay $1000, or say \"I haven't joined/don't intend to join one\" and pay $30, which is sufficiently confusing to make me conclude that I don't actually understood how this organisation works. There aren't any facilities in Australia AFAIK, and there is no indication of what the CAA actually does in the event of unexpected death. Plus, they haven't updated their website for over a year.</p>\n<p>Do you skip the CAA, and just sign up with Alcor or someone else based in the US? I don't know which ones are good or bad, or even have any firm idea how to <em>find out</em>&nbsp;which ones are good or bad. How do you arrange transportation to the cryonics facility from another country? Do you need to pay for everything in advance? Life insurance seems to be the ticket, but how do you go about getting that? I live with my parents and the car I drive belongs to them, so I've never insured <em>anything</em>.</p>\n<p>Is there anybody who knows, or has some ideas, about&nbsp;<em>what I should be doing?</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3xuEaoZXPt2jYcQ3Z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 11, "extendedScore": null, "score": 6.894452244452208e-07, "legacy": true, "legacyId": "6208", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T16:08:52.588Z", "modifiedAt": null, "url": null, "title": "Organ donation versus cryonics", "slug": "organ-donation-versus-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:08.849Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Snowyowl", "createdAt": "2010-08-23T21:33:34.015Z", "isAdmin": false, "displayName": "Snowyowl"}, "userId": "Mf2n7xCxxvALBrZ5i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ysvpnckFCkMBqekuN/organ-donation-versus-cryonics", "pageUrlRelative": "/posts/ysvpnckFCkMBqekuN/organ-donation-versus-cryonics", "linkUrl": "https://www.lesswrong.com/posts/ysvpnckFCkMBqekuN/organ-donation-versus-cryonics", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Organ%20donation%20versus%20cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOrgan%20donation%20versus%20cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FysvpnckFCkMBqekuN%2Forgan-donation-versus-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Organ%20donation%20versus%20cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FysvpnckFCkMBqekuN%2Forgan-donation-versus-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FysvpnckFCkMBqekuN%2Forgan-donation-versus-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p>Simultaneously signing up for organ donation and cryonics versus only cryonics. Does having less organs decrease the likelihood of cryonics (including revival) working? Is it a good idea to have only your head frozen anyway, to save on electricity and storage? Do the benefits of organ donation outweigh any costs it could possibly incur, since organ donation is known to work?</p>\n<p>&nbsp;</p>\n<p>Discuss.</p>\n<p>I'm an organ donor because signing up was quick and easy. I'm not signing up for cryonics, because I anticipate that my family and close friends will have a harder time overcoming their grief if my body is not actually present at the funeral.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ysvpnckFCkMBqekuN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 1e-05, "legacy": true, "legacyId": "6210", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T16:35:28.503Z", "modifiedAt": null, "url": null, "title": "Move meetups to the sidebar?", "slug": "move-meetups-to-the-sidebar", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.240Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Johnicholas", "createdAt": "2009-02-27T15:01:52.708Z", "isAdmin": false, "displayName": "Johnicholas"}, "userId": "kBvTXutfPytNtzPyD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3WBhsovAYBvsKNiX3/move-meetups-to-the-sidebar", "pageUrlRelative": "/posts/3WBhsovAYBvsKNiX3/move-meetups-to-the-sidebar", "linkUrl": "https://www.lesswrong.com/posts/3WBhsovAYBvsKNiX3/move-meetups-to-the-sidebar", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Move%20meetups%20to%20the%20sidebar%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMove%20meetups%20to%20the%20sidebar%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3WBhsovAYBvsKNiX3%2Fmove-meetups-to-the-sidebar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Move%20meetups%20to%20the%20sidebar%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3WBhsovAYBvsKNiX3%2Fmove-meetups-to-the-sidebar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3WBhsovAYBvsKNiX3%2Fmove-meetups-to-the-sidebar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p>The number of meetup announcements on the main blog has been increasing. Though it's reasonable to try to get meetups high visibility to increase the chance that people who are nearby see the announcement, the posts themselves are content-free.</p>\n<p>How difficult would it be to, instead of promoting meetup announcements, tag them \"meetup\" and put a \"meetups\" section in the sidebar, similar to \"recent comments\" or \"recent posts\"?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3WBhsovAYBvsKNiX3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 41, "extendedScore": null, "score": 6.895455812500505e-07, "legacy": true, "legacyId": "6211", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T18:22:59.508Z", "modifiedAt": null, "url": null, "title": "What exactly IS the overpopulation argument (in regards to immortality)?", "slug": "what-exactly-is-the-overpopulation-argument-in-regards-to", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.747Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ufjFuHmJoysXrKXYQ/what-exactly-is-the-overpopulation-argument-in-regards-to", "pageUrlRelative": "/posts/ufjFuHmJoysXrKXYQ/what-exactly-is-the-overpopulation-argument-in-regards-to", "linkUrl": "https://www.lesswrong.com/posts/ufjFuHmJoysXrKXYQ/what-exactly-is-the-overpopulation-argument-in-regards-to", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20exactly%20IS%20the%20overpopulation%20argument%20(in%20regards%20to%20immortality)%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20exactly%20IS%20the%20overpopulation%20argument%20(in%20regards%20to%20immortality)%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufjFuHmJoysXrKXYQ%2Fwhat-exactly-is-the-overpopulation-argument-in-regards-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20exactly%20IS%20the%20overpopulation%20argument%20(in%20regards%20to%20immortality)%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufjFuHmJoysXrKXYQ%2Fwhat-exactly-is-the-overpopulation-argument-in-regards-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufjFuHmJoysXrKXYQ%2Fwhat-exactly-is-the-overpopulation-argument-in-regards-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 486, "htmlBody": "<p>Periodically in discussions of cryonics and related issues, people bring up \"the overpopulation argument, and the counterarguments that respond to it\" without actually describing those arguments in detail. Overpopulation was a big concern of mine prior to exposure to anti-deathism. And so far, it still is. I have no philosophical problem with eliminating death, but it seems to me that getting rid of death BEFORE we eliminate all the other major problems facing humanity is going to make those problems much worse. Death is an enemy that should be vanquished, but it's not an enemy I'm prepared to destroy until I'm satisfied that we'll be able to handle the consequences.</p>\n<p>If death is solved via uploads running at high speed, I'm not too concerned. (Still a little concerned, since computers still take up space, but the issue is close enough to negligible that I'm fine ignoring it).</p>\n<p>If we're dealing with physical humans taking up physical space requiring physical resources, then I'm worried. Either we're growing exponentially, or we've eliminated childbirth, or we have strict rules in place about people who have children being willing to die. (The latter might work but modifying central aspects of the human life cycle that we are hard-wired to value seems.... challenging, to say the least)</p>\n<p>The sense of I've gotten around here is that \"exponential growth is okay, because Space is Big\". Space certainly is big, and I imagine we could expand for a long time without running into conflict. But if there's even one other alien race who solves their problems the same way (expanding whenever they run out of space or resources), then eventually there's going to be conflict. And the longer we go BEFORE that conflict, the more human suffering it might entail. I'd prefer to have achieved equilibrium as a species beforehand.&nbsp;</p>\n<p>I want to expand into the universe, but I think we should do so out of *curiosity* rather than *necessity.*&nbsp;</p>\n<p>I assume there's been a lot of discussions about this and I don't want to rehash them. But if someone could summarize the issues at hand and explain what the community consensus is, I'd appreciate it. (\"Community Consensus\" might mean \"there are a few dominant schools of thought here\").</p>\n<p>Edit: FAWS pointed out that as long as, on average, each person reproduces slightly less than once, growth will not continue exponentially. That's pretty much the answer I'm looking for. The logistics are still significant, but in the long run I think such a law would be enforcible. (Each person only gets to reproduce once, and some people will choose not to. I think there'd need to be an additional disincentive, because over the course of an immortal lifespan, people are likely to try out childrearing at *some* point).</p>\n<p>I still think that the issues surrounding overpopulation should occupy at least as much of our attention as ending death&nbsp;(basically ensuring that people are given adequate resources to live healthy, productive lives).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ufjFuHmJoysXrKXYQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "6212", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T22:38:15.437Z", "modifiedAt": null, "url": null, "title": "Map and Territory and \"Paths\"", "slug": "map-and-territory-and-paths", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.026Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DM8AaeG6haTgtHH4X/map-and-territory-and-paths", "pageUrlRelative": "/posts/DM8AaeG6haTgtHH4X/map-and-territory-and-paths", "linkUrl": "https://www.lesswrong.com/posts/DM8AaeG6haTgtHH4X/map-and-territory-and-paths", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Map%20and%20Territory%20and%20%22Paths%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMap%20and%20Territory%20and%20%22Paths%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDM8AaeG6haTgtHH4X%2Fmap-and-territory-and-paths%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Map%20and%20Territory%20and%20%22Paths%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDM8AaeG6haTgtHH4X%2Fmap-and-territory-and-paths", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDM8AaeG6haTgtHH4X%2Fmap-and-territory-and-paths", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Hi everyone,</p>\r\n<p>Recently have started a discussion group amongst some of my friends and aquaintences in an attempt to study and improve our rationality.</p>\r\n<p>What I tend to do, is using the sequences as 'source' material, write up a lesson plan that attempts to be a bit more accesible to the layman and go through it with them as slowly and meticulously as needed.</p>\r\n<p>Only had one meeting so far, but it's been exciting seeing it come together and people get engaged with the idea of improving their rationality.</p>\r\n<p>My question is regarding the \"Map and Territory\" analogy, which is what we're planning to look at indepth next meeting.</p>\r\n<p>Could you further the analogy and say that the paths that you write on your map, to get you to and from different points be considered the application of Instrumental Rationality? (As charting the map is the application of epistemic) You could point out that Instrumental Rationality also requires you to have a good map.</p>\r\n<p>Any thoughts/comments would be appreciated.</p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DM8AaeG6haTgtHH4X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "6213", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T22:38:16.608Z", "modifiedAt": null, "url": null, "title": "Map and Territory and \"Paths\"", "slug": "map-and-territory-and-paths-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A4nEZnvLWaeBYipb4/map-and-territory-and-paths-0", "pageUrlRelative": "/posts/A4nEZnvLWaeBYipb4/map-and-territory-and-paths-0", "linkUrl": "https://www.lesswrong.com/posts/A4nEZnvLWaeBYipb4/map-and-territory-and-paths-0", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Map%20and%20Territory%20and%20%22Paths%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMap%20and%20Territory%20and%20%22Paths%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4nEZnvLWaeBYipb4%2Fmap-and-territory-and-paths-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Map%20and%20Territory%20and%20%22Paths%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4nEZnvLWaeBYipb4%2Fmap-and-territory-and-paths-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4nEZnvLWaeBYipb4%2Fmap-and-territory-and-paths-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Hi everyone,</p>\r\n<p>Recently have started a discussion group amongst some of my friends and aquaintences in an attempt to study and improve our rationality.</p>\r\n<p>What I tend to do, is using the sequences as 'source' material, write up a lesson plan that attempts to be a bit more accesible to the layman and go through it with them as slowly and meticulously as possible.</p>\r\n<p>Only had one meeting so far, but it's been exciting seeing it come together and people get engaged with the idea of improving their rationality.</p>\r\n<p>Mm question is regarding the \"Map and Territory\" analogy, which is what we're planning to look at indepth next meeting.</p>\r\n<p>Could you further the analogy and say that the paths that would write on your map, to get you to and from different points be considered the application of Instrumental Rationality? (As charting the map is the application of epistemic) You could point out that Instrumental Rationality also requires you to have a good map.</p>\r\n<p>Any thoughts/comments would be appreciated.</p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A4nEZnvLWaeBYipb4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6214", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-13T23:18:04.214Z", "modifiedAt": null, "url": null, "title": "'The Economist' hosts a debate on AI and the singularity (with video)", "slug": "the-economist-hosts-a-debate-on-ai-and-the-singularity-with", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ufDHKxv8BhznBc5hm/the-economist-hosts-a-debate-on-ai-and-the-singularity-with", "pageUrlRelative": "/posts/ufDHKxv8BhznBc5hm/the-economist-hosts-a-debate-on-ai-and-the-singularity-with", "linkUrl": "https://www.lesswrong.com/posts/ufDHKxv8BhznBc5hm/the-economist-hosts-a-debate-on-ai-and-the-singularity-with", "postedAtFormatted": "Sunday, March 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20'The%20Economist'%20hosts%20a%20debate%20on%20AI%20and%20the%20singularity%20(with%20video)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A'The%20Economist'%20hosts%20a%20debate%20on%20AI%20and%20the%20singularity%20(with%20video)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufDHKxv8BhznBc5hm%2Fthe-economist-hosts-a-debate-on-ai-and-the-singularity-with%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text='The%20Economist'%20hosts%20a%20debate%20on%20AI%20and%20the%20singularity%20(with%20video)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufDHKxv8BhznBc5hm%2Fthe-economist-hosts-a-debate-on-ai-and-the-singularity-with", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FufDHKxv8BhznBc5hm%2Fthe-economist-hosts-a-debate-on-ai-and-the-singularity-with", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5, "htmlBody": "<p><a href=\"http://www.economist.com/blogs/prospero/2011/03/artificial_intelligence\">Link</a>.</p>\n<p>Mostly dumb thoughts, unfortunately. :(</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ufDHKxv8BhznBc5hm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6216", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T02:38:38.736Z", "modifiedAt": null, "url": null, "title": "Rationalist Lord of the Rings fanfiction, newly translated from Russian", "slug": "rationalist-lord-of-the-rings-fanfiction-newly-translated", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.818Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Costanza", "createdAt": "2010-09-14T16:22:53.235Z", "isAdmin": false, "displayName": "Costanza"}, "userId": "cXudnoTp54SYgqfgF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aKCa4J4n4xWLHEoeZ/rationalist-lord-of-the-rings-fanfiction-newly-translated", "pageUrlRelative": "/posts/aKCa4J4n4xWLHEoeZ/rationalist-lord-of-the-rings-fanfiction-newly-translated", "linkUrl": "https://www.lesswrong.com/posts/aKCa4J4n4xWLHEoeZ/rationalist-lord-of-the-rings-fanfiction-newly-translated", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Lord%20of%20the%20Rings%20fanfiction%2C%20newly%20translated%20from%20Russian&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Lord%20of%20the%20Rings%20fanfiction%2C%20newly%20translated%20from%20Russian%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaKCa4J4n4xWLHEoeZ%2Frationalist-lord-of-the-rings-fanfiction-newly-translated%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Lord%20of%20the%20Rings%20fanfiction%2C%20newly%20translated%20from%20Russian%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaKCa4J4n4xWLHEoeZ%2Frationalist-lord-of-the-rings-fanfiction-newly-translated", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaKCa4J4n4xWLHEoeZ%2Frationalist-lord-of-the-rings-fanfiction-newly-translated", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<div id=\"entry_t3_4sr\" class=\"content clear\">\n<p class=\"md\">This may be old news to some people, especially the Russian speakers, but I didn't see an article about it here.</p>\n<p class=\"md\">In 1999, Kirill Yeskov, a Russian paleontologist, wrote <em>The Last Ringbearer,</em> a 270-page take on <em>Lord of the Rings</em> from the point of view of a medic in Mordor's dying armies who is also a \"skeptic and a rationalist.\"&nbsp; In fact, Mordor represents the forces of reason in this retelling of the story.&nbsp; As a Nazg&uacute;l (himself a former mathematician) explains, Mordor is \"the little oasis of Reason in which your light-minded civilization had so comfortably nestled.\"&nbsp; Barad-dur is \"that amazing city of alchemists and poets, mechanics and astronomers, philosophers and physicians, the heart of the only civilization in Middle-earth to bet on rational knowledge and bravely pitch its barely adolescent technology against ancient magic.\"</p>\n<p>The story has been newly translated and is <a href=\"http://ymarkov.livejournal.com/270570.html\">available</a> in free PDF form -- in English and the original Russian. There's a recent review from <a href=\"http://www.salon.com/books/laura_miller/2011/02/15/last_ringbearer\">Salon</a> as well.</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aKCa4J4n4xWLHEoeZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "6219", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T14:49:11.689Z", "modifiedAt": null, "url": null, "title": "Handedness Bias", "slug": "handedness-bias", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.967Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "beriukay", "createdAt": "2010-02-16T16:20:00.989Z", "isAdmin": false, "displayName": "beriukay"}, "userId": "4fAd4zQLh2TnrzLmC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xHJP2BkRN5xhuW8pB/handedness-bias", "pageUrlRelative": "/posts/xHJP2BkRN5xhuW8pB/handedness-bias", "linkUrl": "https://www.lesswrong.com/posts/xHJP2BkRN5xhuW8pB/handedness-bias", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Handedness%20Bias&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHandedness%20Bias%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxHJP2BkRN5xhuW8pB%2Fhandedness-bias%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Handedness%20Bias%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxHJP2BkRN5xhuW8pB%2Fhandedness-bias", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxHJP2BkRN5xhuW8pB%2Fhandedness-bias", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<p>I just read a blog post on <a title=\"NeuroLogica Blog\" href=\"http://theness.com/neurologicablog/?p=2946\">NeuroLogica Blog</a> that could have been a LW post, so I figured that I would bring it on over. It basically details how knowing about our biases can help us correct for them, a la <a title=\"the lens that sees its flaws\" href=\"/lw/jm/the_lens_that_sees_its_flaws/\">the lens that sees its flaws</a>, and then brings to light a <a title=\"new study\" href=\"http://pss.sagepub.com/content/early/2011/03/04/0956797611401755\">new study</a> (unfortunately behind a paywall... I wanted to see the methodology) that shows that the simple act of wearing a glove on your dominant hand can influence how you perceive the world.</p>\n<p>When I learned that Dexter and Sinister were Latin words for Right and Left, respectively, I was told that it came from shield formations, and how the person on your left was a leech for using your shield protection, and the one on your right was your protector. Now that explanation sounds a bit hollow.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xHJP2BkRN5xhuW8pB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 6.899087051672532e-07, "legacy": true, "legacyId": "6226", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["46qnWRSR7L2eyNbMA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T15:50:00.695Z", "modifiedAt": null, "url": null, "title": "How I Lost 100 Pounds Using TDT", "slug": "how-i-lost-100-pounds-using-tdt", "viewCount": null, "lastCommentedAt": "2021-09-18T07:26:20.647Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Zvi", "createdAt": "2009-03-31T20:54:54.077Z", "isAdmin": false, "displayName": "Zvi"}, "userId": "N9zj5qpTfqmbn9dro", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/scwoBEju75C45W5n3/how-i-lost-100-pounds-using-tdt", "pageUrlRelative": "/posts/scwoBEju75C45W5n3/how-i-lost-100-pounds-using-tdt", "linkUrl": "https://www.lesswrong.com/posts/scwoBEju75C45W5n3/how-i-lost-100-pounds-using-tdt", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20I%20Lost%20100%20Pounds%20Using%20TDT&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20I%20Lost%20100%20Pounds%20Using%20TDT%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscwoBEju75C45W5n3%2Fhow-i-lost-100-pounds-using-tdt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20I%20Lost%20100%20Pounds%20Using%20TDT%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscwoBEju75C45W5n3%2Fhow-i-lost-100-pounds-using-tdt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscwoBEju75C45W5n3%2Fhow-i-lost-100-pounds-using-tdt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1310, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif]--></p>\n<p class=\"MsoNormal\">Background Information: <a href=\"/lw/15z/ingredients_of_timeless_decision_theory/\">Ingredients of Timeless Decision Theory</a></p>\n<p class=\"MsoNormal\">Alternate Approaches Include: <a href=\"/lw/2yd/selfempathy_as_a_source_of_willpower/\">Self-empathy as a source of &ldquo;willpower&rdquo;</a>, <a href=\"/lw/ep/applied_picoeconomics/\">Applied Picoeconomics</a>, <a href=\"/lw/6c/akrasia_hyperbolic_discounting_and_picoeconomics/\">Akrasia, hyperbolic discounting, and picoeconomics</a>, <a href=\"/lw/1sm/akrasia_tactics_review/\">Akrasia Tactics Review</a></p>\n<p class=\"MsoNormal\">Standard Disclaimer: <a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a></p>\n<p class=\"MsoNormal\">Timeless Decision Theory (or TDT) allowed me to succeed in gaining control over when and how much I ate in a way that previous attempts at precommitment had repeatedly failed to do. I did so well before I was formally exposed to the concept of TDT, but once I clicked on TDT I understood that I had effectively been using it. That click came from reading Eliezer&rsquo;s shortest summary of TDT, which was:</p>\n<blockquote>\n<p class=\"MsoNormal\">The one-sentence version is:&nbsp; Choose as though controlling the logical output of the abstract computation you implement, including the output of all other instantiations and simulations of that computation</p>\n</blockquote>\n<p class=\"MsoNormal\">You can find more <a href=\"/lw/15z/ingredients_of_timeless_decision_theory/\">here</a> but my recommendation at least at first is to stick with the one sentence version. It is as simple as it can be, but no simpler.<span>&nbsp; </span></p>\n<p class=\"MsoNormal\">Utilizing TDT gave me several key abilities that I previously lacked. The most important was realizing that what I chose now would be the same choice I would make at other times under the same circumstances. This allowed me to compare having the benefits now to paying the costs now, as opposed to paying costs now for future benefits later. This ability allowed me to overcome <a href=\"http://en.wikipedia.org/wiki/Hyperbolic_discounting\">hyperbolic discounting</a>. The other key ability was that it freed me from the need to explicitly stop in advance to make precommitements each time I wanted to alter my instinctive behavior. Instead, it became automatic to make decisions in terms of which rules would be best to follow.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\">With that as background, this is how I made it happen:</p>\n<p class=\"MsoNormal\">I was walking home from class along my usual route I had made a habit while doing this of stopping into Famiglia Pizza and ordering garlic knots. I like garlic knots quite a bit, but I also hated being fat and the way being fat made me feel. Things weren&rsquo;t quite as bad on that front as they&rsquo;d been a few years before but they were still extraordinarily bad. I thought about my impending solace and thought to myself: You wouldn&rsquo;t be so fat if you didn&rsquo;t keep buying these garlic knots every day.</p>\n<p class=\"MsoNormal\">I thought about that for a second, realized it was trivially true and then wondered to myself whether it was worth it. If I never stopped for the knots I would weigh less and feel better, but I wouldn&rsquo;t have any knots. Even worse, I wouldn&rsquo;t have any garlic. But would I rather enjoy today the full effect of never having had the knots, in exchange for not having any? Once I asked the question that way the answer came back a resounding yes. I didn&rsquo;t know how much it would matter, but the calculation wasn&rsquo;t remotely close. I walked right past the pizza place and never stopped in there for a snack again.</p>\n<p class=\"MsoNormal\">Using this method seemed like the most useful thing I&rsquo;d come up with in some time, so I quickly extended it to other decisions starting with the rest of my diet. For each meal I would consume, I decided what quantity was worth it and forbade myself from ever consuming more. I motivated myself to stick to that rule in the face of hyperbolic discounting by reminding myself that I would make the same decision next time that I was making now, so I was deciding what action I would always take in this situation. More generally, sticking to the rules I&rsquo;d decided to follow meant I would stick to rules I&rsquo;d decided to follow, which was clearly an extremely valuable asset to have on my side.</p>\n<p class=\"MsoNormal\">I used two other major rules in what I like to call the &ldquo;Don&rsquo;t Eat So Goddamn Much, Shut Your Pie Hole&rdquo; diet. The first was to cut down from three meals a day to two and eliminate all snacks except water, cutting my consumption by more than a third. I&rsquo;d had practice skipping meals in the past and realized that skipping dinner was far less painful than it looked; within a few weeks I stopped getting hungry at night. The other change was to weigh myself daily and alter how draconian the rules were based on my current weight relative to my current baseline. If I was below the baseline, I&rsquo;d lower the baseline and give myself a chance to cheat a little. If I was above it by too much I would cut out all meal options that weren&rsquo;t &ldquo;wins&rdquo; in the sense that they had more calories than my average.</p>\n<p class=\"MsoNormal\">I tried incorporating exercise into this program but made the discovery many others have made that exercise didn&rsquo;t correlate with weight loss. Exercise makes you better at doing exercise so long as you keep doing exercise, but it had no measurable effect on my mission so I decided to let that wait until after the mission was complete. Even then I found several exercise programs I tried to be not worth it compared to not having one, or found that they became so over time. Eventually I was able to find a trainer and I remain happy with that aside from the cost. I also considered changing what I ate, but found that beyond cutting out the worst choices that it was neither necessary nor worth the cost.</p>\n<p class=\"MsoNormal\">The last obstacle on the journey was that as I lost more and more I started to feel worse rather than better due to all of the excess skin that doesn&rsquo;t go away on its own. It was only after I&rsquo;d lost all the weight and <a href=\"http://www.emedicinehealth.com/excess_skin_removal_after_extreme_weight_loss/article_em.htm\">had the resulting skin removal surgery</a> that I suddenly got up and felt genuinely good about how I looked and felt for the first time in my life. I&rsquo;ve since managed to relax a number of the rules but was never concerned I wouldn&rsquo;t do what was necessary to keep myself on track.</p>\n<p class=\"MsoNormal\">Since then I&rsquo;ve used similar techniques and rules in a wide variety of areas of life. It was only years later reading Less Wrong that I realized that I&rsquo;d effectively been employing inter-temporal Timeless Decision Theory. That realization allowed me to better understand and formalize what I had done, and gave me a better framework for explaining it to others. A common and justified criticism of using TDT in everyday life rather than as a theoretical construct is to ask where one can find another TDT agent, or indeed any agent sufficiently causally linked to you so as to allow you to utilize that link. My answer to that is that whether or not there is someone else you are linked to yourself. You can be that other agent, the recognition of which can allow you to win and win big.</p>\n<p class=\"MsoNormal\">I am fully aware that to a first approximation dieting attempts that follow similar patterns never work. Most people do not have the willpower necessary to sustain them, or otherwise suffer too much to choose to remain on the diet long term. There are powerful forces working against such an attempt. My working hypothesis is that I had five unusual things working in my favor: I have extraordinarily strong willpower in such areas, I already had strong affinity for rule setting and abiding, I fully believed in what I was doing, I had a life situation that allowed me to experience temporary discomfort due to hunger and I thought of all changes from the beginning as permanent. At least some of these advantages are things that can be learned. If anyone is capable of following in my footsteps, it would be Less Wrong readers. In <a href=\"http://www.meetup.com/Less-Wrong-Overcoming-Bias-NYC/\">New York&rsquo;s Less Wrong group</a> especially a lot of us have had success with various different approaches, and I think that developing mental techniques is the best way to enhance your chance of success.</p>\n<p class=\"MsoNormal\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 2, "XqykXFKL9t38pbSEm": 1, "5f5c37ee1b5cdee568cfb1db": 2, "Wgbgir4qzGz8Ztt3u": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "scwoBEju75C45W5n3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 111, "baseScore": 119, "extendedScore": null, "score": 0.000218, "legacy": true, "legacyId": "6209", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 120, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 244, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["szfxvS8nsxTgJLBHs", "22HfpjsydDS2A6JhH", "NjzBrtvDS4jXi5Krp", "geNZ6ZpfFce5intER", "rRmisKb45dN7DK4BW", "6NvbSwuSAooQxxf7f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T18:30:51.721Z", "modifiedAt": null, "url": null, "title": "Science Journalism and How To Present Probabilities [Link]", "slug": "science-journalism-and-how-to-present-probabilities-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:58.881Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "miS4XR3NQGgxkzKu9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rsoRiQtqjeqZX586G/science-journalism-and-how-to-present-probabilities-link", "pageUrlRelative": "/posts/rsoRiQtqjeqZX586G/science-journalism-and-how-to-present-probabilities-link", "linkUrl": "https://www.lesswrong.com/posts/rsoRiQtqjeqZX586G/science-journalism-and-how-to-present-probabilities-link", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Science%20Journalism%20and%20How%20To%20Present%20Probabilities%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScience%20Journalism%20and%20How%20To%20Present%20Probabilities%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrsoRiQtqjeqZX586G%2Fscience-journalism-and-how-to-present-probabilities-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Science%20Journalism%20and%20How%20To%20Present%20Probabilities%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrsoRiQtqjeqZX586G%2Fscience-journalism-and-how-to-present-probabilities-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrsoRiQtqjeqZX586G%2Fscience-journalism-and-how-to-present-probabilities-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 264, "htmlBody": "<p>I just stumbled across <a href=\"http://itre.cis.upenn.edu/~myl/languagelog/archives/004767.html\">Language Log: Thou shalt not report odds ratios</a> (2007-07-30), HT <a href=\"http://www.reddit.com/r/statistics/comments/g1zt9/thou_shalt_not_report_odds_ratios_as_risk_ratios/\">reddit/statistics</a>:</p>\n<blockquote>\n<p>(&hellip;) this finding was widely reported in the media:(&hellip;)</p>\n<p>&ldquo;Doctors are only 60% as likely to order cardiac catheterization for women and blacks as for men and whites.&rdquo;</p>\n<p>Now let't try a little test of reading comprehension. The study found that the referral rate for white men was 90.6%. What was the referral rate for blacks and women?</p>\n<p>If you're like most literate and numerate people, you'll calculate 60% of 90.6%, and come up with .6*.906 = .5436. So, you'll reason, the referral rate for blacks and women was about 54.4 %.</p>\n<p>But in fact, what the study found was a referral rate for blacks and women of 84.7%.</p>\n</blockquote>\n<p>This was a failure mode of pop-sci journalism which I was not aware of (if I would happen to know enough to understand real papers, I&rsquo;d definitely value pop-sci at minus-whatever in the meantime&hellip;)</p>\n<p>On a related note this article got me remembering <a href=\"http://understandinguncertainty.org/node/233\">Understanding Uncertainty: 2845 ways to spin the Risk</a>, which argues that certain presentations bias the understanding of probabilities:</p>\n<blockquote>Similarly people confronted with the statement &ldquo;Cancer kills 2,414 people out of 10,000&rdquo; rated cancer as more risky than those told &ldquo;Cancer kills 24.14 people out of 100&rdquo;. The potential influence of the size of the numerator and denominator is known as the 'ratio bias'.</blockquote>\n<p>I&rsquo;d be quite interested if anybody could point me to further resources on good presentation of statistical facts (beside the normalization on one type of presentation), or on further pop-sci journalism failure modes.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rsoRiQtqjeqZX586G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "6227", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T18:54:20.088Z", "modifiedAt": null, "url": null, "title": "Kinect self-awareness hack", "slug": "kinect-self-awareness-hack", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LDM3Dahi2M44zgiDw/kinect-self-awareness-hack", "pageUrlRelative": "/posts/LDM3Dahi2M44zgiDw/kinect-self-awareness-hack", "linkUrl": "https://www.lesswrong.com/posts/LDM3Dahi2M44zgiDw/kinect-self-awareness-hack", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kinect%20self-awareness%20hack&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKinect%20self-awareness%20hack%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDM3Dahi2M44zgiDw%2Fkinect-self-awareness-hack%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kinect%20self-awareness%20hack%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDM3Dahi2M44zgiDw%2Fkinect-self-awareness-hack", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDM3Dahi2M44zgiDw%2Fkinect-self-awareness-hack", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5, "htmlBody": "<p>Kinect self-awareness hack at http://www.collegehumor.com/video:1949248</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LDM3Dahi2M44zgiDw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6228", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T20:03:27.602Z", "modifiedAt": "2020-06-29T19:51:41.447Z", "url": null, "title": "Being a teacher", "slug": "being-a-teacher", "viewCount": null, "lastCommentedAt": "2021-07-03T15:02:21.706Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Swimmer963", "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8wWdgzokzq6dBG7Mq/being-a-teacher", "pageUrlRelative": "/posts/8wWdgzokzq6dBG7Mq/being-a-teacher", "linkUrl": "https://www.lesswrong.com/posts/8wWdgzokzq6dBG7Mq/being-a-teacher", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Being%20a%20teacher&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeing%20a%20teacher%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wWdgzokzq6dBG7Mq%2Fbeing-a-teacher%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Being%20a%20teacher%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wWdgzokzq6dBG7Mq%2Fbeing-a-teacher", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8wWdgzokzq6dBG7Mq%2Fbeing-a-teacher", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 822, "htmlBody": "<html><head></head><body><p>A few weeks ago, while giving unofficial swimming lessons to an acquaintance about my age, I had an insight.&nbsp;It was that&nbsp;before you can teach something, you have to realize it\u2019s <i>hard</i>.</p><p>I don\u2019t think I noticed this before, because I thought it was obvious. Of course someone who doesn\u2019t know how to swim isn\u2019t going to learn perfect front crawl just by looking at yours. If I was told to watch someone else swimming a brand-new stroke that I\u2019d never seen before, I could imitate it pretty easily, because to me it\u2019s a trivial skill. But to someone who has nothing to refer to, it\u2019s hard.</p><p>\u201cYou\u2019re like the fifth person who\u2019s tried to teach me how to swim,\u201d my acquaintance said as I led her into the shallow end holding a foam noodle. \u201cPeople just tell me to move my arms and legs, and they <i>didn\u2019t seem to understand</i> why I couldn\u2019t do it.\u201d</p><p>There are, needless to say, a lot of different ways to move your arms and legs. Some of them resemble swimming. A subset of those actually work to keep someone\u2019s head at the surface, and an even smaller subset of those are effective enough that they have names, like front crawl. To me, this is obvious, because I\u2019ve watched hundreds of children in my classes flail and struggle in their front crawl, or lift their head to breathe, or turn their toes inwards in whip kick, and make the same mistakes persistently even when I corrected them, both verbally and by literally grabbing their arms/legs and moving them. I know it\u2019s hard.</p><p>I went through this flailing/struggling phase too and have no memory of it whatsoever, having been three at the time. &nbsp;This is probably true of most good swimmers; the procedural memory is so embedded that it makes sense to say \u201cmove your arms and legs\u201d because that's all you think about consciously; you forget how many other things you\u2019re doing just&nbsp;to stay afloat. (Poor swimmers might have a different perspective, but they aren\u2019t likely to use that perspective to try to teach other people how to swim.)</p><p>In order to bring a non-swimmer to the point of doing perfect front crawl, you have to teach them, one at a time, a long list of motor skills that have to be learned well enough to come naturally before you can move on. With adults, you can compress this process into a much shorter period than with restless, distractible, and lacking-fully-developed-motor-skills children, but you can\u2019t omit it. You have to teach them how to float, and you can\u2019t just tell them to float; you have to hold them up in the water and tell them, one at a time, which muscles to relax and which parts of their body position to change, and then you can let go. You have to teach them how to blow bubbles out their nose to avoid getting water in it. (I wonder how many people are eternally wary of&nbsp;jumping into the water or doing somersaults&nbsp;because no one told them this). You have to slowly shape their flutter-kick from a flailing mess into something that will actually move them somewhere. And then you can teach them front crawl, which comes with its own miles-long list of small details to fix and ways to fix them.</p><p>I watch my coworkers teach their class, and it amazes me how often they tell their kids to swim, watch them, and say \u201cthat was bad. Do it again.\u201d As if that comment is useful in any way. As if doing the same thing over and over again will ever produce different results.*</p><p>I wonder how much this applies to other areas (teaching math in elementary school, for example?) How many teachers teach the same skills the same way, over and over, answering confused questions with exactly the same explanation they gave originally? Different minds work differently, just like different bodies work differently. You have to find the right metaphors, the right words to describe things that aren\u2019t really conveyed by words. (\u201cKick your legs like a ballet dancer would\u201d is&nbsp;a swimming metaphor&nbsp;I found recently that works quite well with some people and not at all with others.)</p><p>I would be interested to hear from other people who\u2019ve either taught in other areas and found useful tricks or metaphors, or who\u2019ve been taught in either good or ineffective ways.</p><p>*Note: Although I criticize it here, this is basically how I teach treading water. I hold children in water above their head, tell them to make scooping motions with their arms and legs, let go of them while maintaining eye contact, and immediately pick them up again the moment they start to go under. Two seconds becomes five seconds, becomes ten seconds, becomes a minute, and then I teach them fancy skills like eggbeater. But this is because treading water is a very basic, simple skill that I find really, really hard to explain verbally to four-year-olds.</p></body></html>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 1, "YQW2DxpZFTrqrxHBJ": 1, "WPkEd3et8f488w8LT": 1, "8nAXyYLu8eT72Hwuh": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8wWdgzokzq6dBG7Mq", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 59, "baseScore": 79, "extendedScore": null, "score": 0.00016, "legacy": true, "legacyId": "6229", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 155, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T20:06:13.523Z", "modifiedAt": null, "url": null, "title": "Ranting about Representative Democracy", "slug": "ranting-about-representative-democracy", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.240Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rabidchicken", "createdAt": "2010-07-19T05:12:56.823Z", "isAdmin": false, "displayName": "rabidchicken"}, "userId": "AtK6QX5tcrL9dDYdu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oqCLCyjF9oSREMATA/ranting-about-representative-democracy", "pageUrlRelative": "/posts/oqCLCyjF9oSREMATA/ranting-about-representative-democracy", "linkUrl": "https://www.lesswrong.com/posts/oqCLCyjF9oSREMATA/ranting-about-representative-democracy", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ranting%20about%20Representative%20Democracy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARanting%20about%20Representative%20Democracy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqCLCyjF9oSREMATA%2Franting-about-representative-democracy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ranting%20about%20Representative%20Democracy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqCLCyjF9oSREMATA%2Franting-about-representative-democracy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoqCLCyjF9oSREMATA%2Franting-about-representative-democracy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 579, "htmlBody": "<p>I have been mostly lurking on lesswrong for over a year, but never posted because I can generally dismiss whatever questions or theories I come up with faster than I can explain them on a forum. Essentially, I was waiting for a situation where I actually needed input from a larger group, thought my own conclusions were wrong, or had something which I thought was worth planting in other peoples minds. This post covers all of these, so without further ado, I would like to discuss a few questions about democratic government which have been on my mind recently. <br /><br />I am not old enough to vote, but have tried working on petitions, and sending letters and emails to my MP or other politicians about issues when I thought I had something interesting to say. I have done this several times over the last year in an attempt to make changes from within the system. None of them have ever been answered, even with form letters, so as far as I can tell my attempts at politely making changes have been futile.<br /><br />As I am already a partial anarchist, this did not do much to make me resent Canada's government and the rest of the political world less. I still try once in a while to get through to leaders, but have almost given up on this course of action. My country at least is a democracy exclusively for people who are willing to fight for attention, and who support views that are already popular enough that they are probably being implemented by our leaders anyway.<br /><br />Elected officials are most likely not maliciously ignoring every opinion they are sent, but it seems obvious that they do not have the time to actually address everyone's concerns, learn about every issue they vote on, and are being expected to do a job which is simply impossible for a small group of humans. So I would like to know why we have representatives at all, would an aristocracy be much worse? Decisions are being made by an elite group who's only direct incentive to keep everyone happy is avoiding rebellion and their own ethics anyway. If I want to have a say in national policy when I know something which makes a difference, it looks like I either have to run for parliament (which would fail drastically, I am not charismatic), lead a rebellion, or start my own country. (in order of how horrible these ideas are)</p>\n<p>I would like to know what the general opinion of our governments is right now, so how do you expect each of the following systems would compare to the way democracy functions as it is in Canada, the USA, or other countries?</p>\n<p>Direct democracy: Now that the internet is so common, we do not need to be face to face in the same room to reach a consensus anymore. Instead of having any representatives at all, anyone in the country could make a proposal online, promote it, and let the votes and comments of everyone else decide its fate. Like any other site, it could be hacked, DDOS'd, trolled, spammed, people could make duplicate accounts, etc. There are a nearly infinite number of ways this could go wrong, so a secure implementation is obviously essential.</p>\n<p>Randomized Democracy: Our current system could be left exactly the same but voting and appointment completely replaced with random selection of individuals from the population.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oqCLCyjF9oSREMATA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": -12, "extendedScore": null, "score": 6.89995070981925e-07, "legacy": true, "legacyId": "6230", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-14T20:10:02.273Z", "modifiedAt": null, "url": null, "title": "Visualizing Bayesian Inference [link]", "slug": "visualizing-bayesian-inference-link", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YGawEQfz7pm8cEq2k/visualizing-bayesian-inference-link", "pageUrlRelative": "/posts/YGawEQfz7pm8cEq2k/visualizing-bayesian-inference-link", "linkUrl": "https://www.lesswrong.com/posts/YGawEQfz7pm8cEq2k/visualizing-bayesian-inference-link", "postedAtFormatted": "Monday, March 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Visualizing%20Bayesian%20Inference%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVisualizing%20Bayesian%20Inference%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYGawEQfz7pm8cEq2k%2Fvisualizing-bayesian-inference-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Visualizing%20Bayesian%20Inference%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYGawEQfz7pm8cEq2k%2Fvisualizing-bayesian-inference-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYGawEQfz7pm8cEq2k%2Fvisualizing-bayesian-inference-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<p><a href=\"http://chance.amstat.org/2011/02/galton/\">Galton Visualizing Bayesian Inference (article @ CHANCE)</a></p>\n<p>Excerpt:</p>\n<blockquote>\n<p>What does Bayes Theorem look like? I do not mean what does the formula&mdash;</p>\n<p><a class=\"equation\" rel=\"lightbox\" href=\"http://chance.amstat.org/files/2011/02/stigforumla.jpg\"><img class=\"alignleft size-full wp-image-2292\" title=\"stigforumla\" src=\"http://chance.amstat.org/files/2011/02/stigforumla.jpg\" alt=\"\" width=\"181\" height=\"30\" /></a></p>\n<p>&mdash;look like; these days, every statistician knows that. I mean, how can we visualize the cognitive content of the theorem? What picture can we appeal to with the hope that any person curious about the theorem may look at it, and, after a bit of study say, &ldquo;Why, that is clear&mdash;I can indeed see what is happening!&rdquo;</p>\n<p>Francis Galton could produce just such a picture; in fact, he built and operated a machine in 1877 that performs that calculation. But, despite having published the picture in Nature and the Proceedings of the Royal Institution of Great Britain, he never referred to it again&mdash;and no reader seems to have appreciated what it could accomplish until recently.</p>\n</blockquote>\n<p>Schematics for the machine and its algorithm can be found at the link. This is a really cool design, and maybe it can aid <a href=\"http://yudkowsky.net/rational/bayes\">Eliezer's</a> and <a href=\"http://commonsenseatheism.com/?p=13156\">others'</a> efforts to help people understand Bayes' Theorem.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YGawEQfz7pm8cEq2k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 16, "extendedScore": null, "score": 6.899961096947265e-07, "legacy": true, "legacyId": "6231", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T01:43:12.323Z", "modifiedAt": null, "url": null, "title": "On Pi day, we eat pie; On Tau day, we eat Taoists?", "slug": "on-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:59.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "YTcLqiv4mD6QeH3Ap", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r3nKW5CKJKrCrC7sy/on-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "pageUrlRelative": "/posts/r3nKW5CKJKrCrC7sy/on-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "linkUrl": "https://www.lesswrong.com/posts/r3nKW5CKJKrCrC7sy/on-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Pi%20day%2C%20we%20eat%20pie%3B%20On%20Tau%20day%2C%20we%20eat%20Taoists%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Pi%20day%2C%20we%20eat%20pie%3B%20On%20Tau%20day%2C%20we%20eat%20Taoists%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr3nKW5CKJKrCrC7sy%2Fon-pi-day-we-eat-pie-on-tau-day-we-eat-taoists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Pi%20day%2C%20we%20eat%20pie%3B%20On%20Tau%20day%2C%20we%20eat%20Taoists%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr3nKW5CKJKrCrC7sy%2Fon-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr3nKW5CKJKrCrC7sy%2Fon-pi-day-we-eat-pie-on-tau-day-we-eat-taoists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<p>I'd like to start by wishing everyone a Happy Pi day (even if for some of you it was yesterday).<br /><br />Today, going about my usual Pi day celebration (which included pi(e) of the chocolate, cherry, apple, and <a href=\"http://en.wikipedia.org/wiki/Pi_(film)\" target=\"_self\">movie</a> variety), I&nbsp;stumbled&nbsp;across pi-protesters, who spoke of Tau-ism. For those who haven't heard, Tauist claim that Tau, represented by the Greek letter T, is the real circle constant. There's one proponent and his arguments here:&nbsp;<a href=\"http://tauday.com/\">http://tauday.com/</a><br /><br />I read the article, saw the points that were made, and I've remained impartial (despite being a mathematics major). I can see Tau's usefulness; I can see why pi hasn't changed (and hardly would need to). So I decided to do something else: Present this claim to the LessWrong community, for those who are interested. What do you think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r3nKW5CKJKrCrC7sy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 4, "extendedScore": null, "score": 6.900868923718111e-07, "legacy": true, "legacyId": "6234", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T01:48:14.019Z", "modifiedAt": null, "url": null, "title": "Nootropics-Based Movie Coming Out", "slug": "nootropics-based-movie-coming-out", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/reewCWyxkCvhvNt7g/nootropics-based-movie-coming-out", "pageUrlRelative": "/posts/reewCWyxkCvhvNt7g/nootropics-based-movie-coming-out", "linkUrl": "https://www.lesswrong.com/posts/reewCWyxkCvhvNt7g/nootropics-based-movie-coming-out", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nootropics-Based%20Movie%20Coming%20Out&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANootropics-Based%20Movie%20Coming%20Out%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreewCWyxkCvhvNt7g%2Fnootropics-based-movie-coming-out%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nootropics-Based%20Movie%20Coming%20Out%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreewCWyxkCvhvNt7g%2Fnootropics-based-movie-coming-out", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FreewCWyxkCvhvNt7g%2Fnootropics-based-movie-coming-out", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p>Limitless is a movie coming (in the US) this Friday that people around here might be interested in, at least in how it portrays nootropics, or in how it prompts media discussion about them.<br /><br />In a nutshell, it seems to be about a guy who uses nootropics to rapidly become more intelligent, charming, successful, etc. to the point that it completely changes his life. Then because it's a \"thriller\", people try to kill (or steal something from?) him.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Limitless_(film)\">Wikipedia page</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "reewCWyxkCvhvNt7g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6235", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T01:58:29.057Z", "modifiedAt": null, "url": null, "title": "Limitless, a Nootropics-Centered Movie", "slug": "limitless-a-nootropics-centered-movie", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:36.461Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Dsfs7Lz5xxAxbpQXG/limitless-a-nootropics-centered-movie", "pageUrlRelative": "/posts/Dsfs7Lz5xxAxbpQXG/limitless-a-nootropics-centered-movie", "linkUrl": "https://www.lesswrong.com/posts/Dsfs7Lz5xxAxbpQXG/limitless-a-nootropics-centered-movie", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Limitless%2C%20a%20Nootropics-Centered%20Movie&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALimitless%2C%20a%20Nootropics-Centered%20Movie%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsfs7Lz5xxAxbpQXG%2Flimitless-a-nootropics-centered-movie%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Limitless%2C%20a%20Nootropics-Centered%20Movie%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsfs7Lz5xxAxbpQXG%2Flimitless-a-nootropics-centered-movie", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDsfs7Lz5xxAxbpQXG%2Flimitless-a-nootropics-centered-movie", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p><em>Limitless </em>is a movie coming out this Friday which includes nootropics as a major plot device. I think that the way they are portrayed in the movie, and the subsequent media discussion (if any) about nootropics would be of interest here, even if the movie isn't.<br /><br />From what I can tell, the movie is about a guy who uses a drug to improve his mental capabilities, uses those to radically alter his life, who is then targeted because its just that genre of movie.<br /><br />Just a heads up, if anyone is interested.</p>\n<p>\n<object width=\"640\" height=\"390\" data=\"http://www.youtube.com/v/OgRvJNgySx8?fs=1&amp;hl=en_US\" type=\"application/x-shockwave-flash\">\n<param name=\"allowFullScreen\" value=\"true\" />\n<param name=\"allowscriptaccess\" value=\"always\" />\n<param name=\"src\" value=\"http://www.youtube.com/v/OgRvJNgySx8?fs=1&amp;hl=en_US\" />\n<param name=\"allowfullscreen\" value=\"true\" />\n</object>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Dsfs7Lz5xxAxbpQXG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 6.900910561118433e-07, "legacy": true, "legacyId": "6237", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T09:54:28.454Z", "modifiedAt": null, "url": null, "title": "A math problem I'm trying to figure out now", "slug": "a-math-problem-i-m-trying-to-figure-out-now", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.123Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gMHFb7bA8YZB2AGGf/a-math-problem-i-m-trying-to-figure-out-now", "pageUrlRelative": "/posts/gMHFb7bA8YZB2AGGf/a-math-problem-i-m-trying-to-figure-out-now", "linkUrl": "https://www.lesswrong.com/posts/gMHFb7bA8YZB2AGGf/a-math-problem-i-m-trying-to-figure-out-now", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20math%20problem%20I'm%20trying%20to%20figure%20out%20now&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20math%20problem%20I'm%20trying%20to%20figure%20out%20now%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgMHFb7bA8YZB2AGGf%2Fa-math-problem-i-m-trying-to-figure-out-now%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20math%20problem%20I'm%20trying%20to%20figure%20out%20now%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgMHFb7bA8YZB2AGGf%2Fa-math-problem-i-m-trying-to-figure-out-now", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgMHFb7bA8YZB2AGGf%2Fa-math-problem-i-m-trying-to-figure-out-now", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 275, "htmlBody": "<p>This will be unparseable to anyone except maybe ten people here. What the hell, I'm posting it anyway.</p>\n<p>Consider game 3 from my <a href=\"/lw/4iy/does_solomonoff_always_win/\">earlier post</a>: a possibly uncomputable sequence of bits comes in, you're trying to guess the next bit, the payoff for each correct guess is $1. Obviously any deterministic strategy can be humiliated by a sequence of bits that's chosen to make it always guess wrong. User paulfchristiano suggested that <a href=\"http://www.cs.princeton.edu/~arora/pubs/MWsurvey.pdf\">multiplicative weights</a>&nbsp;could yield a <em>randomized</em> strategy that does at most a constant worse than any human in expectation. I noted that, unlike the Solomonoff mixture, multiplicative weights over lower-semicomputable randomized strategies is not itself lower-semicomputable (several pages of algebra omitted), so we don't have a strategy that's optimal within its own class.&nbsp;Then I found&nbsp;<a href=\"http://www.hutter1.net/ai/sunipriors.pdf\">some slides by Hutter</a> that include a handy table showing how unusual it is for a class do be dominated by a measure within that same class.</p>\n<p>So here's the question: is there an analog of \"dominant lower-semicomputable semimeasure\" for some class of games other than the log-score game? Desiderata: I guess it must correspond to randomized strategies (because deterministic ones are not enough), it must play at most an additive constant worse than any human in expectation (or maybe a multiplicative constant that can be made arbitrarily close to 1 by parameter choice, as with multiplicative weights), and it must be good within its own class of computability (not just superior to all members of some lower class). As far as I can tell, the literature has no answer to this question, and I already spent about a week on it with no success. Anyone here have more understanding than me?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gMHFb7bA8YZB2AGGf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 6.902207935516041e-07, "legacy": true, "legacyId": "6250", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oHwt2JmDBefiN8rvg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T10:28:33.654Z", "modifiedAt": null, "url": null, "title": "Admit your ignorance", "slug": "admit-your-ignorance", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.183Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thakil", "createdAt": "2011-01-13T15:46:17.550Z", "isAdmin": false, "displayName": "thakil"}, "userId": "zudPgERkLSB3LSvQz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DPktquNsDrsJdXq4r/admit-your-ignorance", "pageUrlRelative": "/posts/DPktquNsDrsJdXq4r/admit-your-ignorance", "linkUrl": "https://www.lesswrong.com/posts/DPktquNsDrsJdXq4r/admit-your-ignorance", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Admit%20your%20ignorance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAdmit%20your%20ignorance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDPktquNsDrsJdXq4r%2Fadmit-your-ignorance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Admit%20your%20ignorance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDPktquNsDrsJdXq4r%2Fadmit-your-ignorance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDPktquNsDrsJdXq4r%2Fadmit-your-ignorance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 329, "htmlBody": "<p>Reading <a href=\"/lw/4t1/being_a_teacher/\">Being a teacher</a> made me think about my experiences tutoring university students. I'm a PhD student, so my teaching currently consists of helping first year undergraduates on problem sheets. I think I'm reasonably good- I try to appreciate what difficulties they are having and anticipate them, by explaining what they are doing means, and approaching the problem in different ways.</p>\n<p>&nbsp;</p>\n<p>One constant frustration I get though is that, having explained a problem to a particular student, the student will give me a blank look, and then mutter \"ok\". I know what that look means, and will ask \"so do you understand that?\" \"sort of....\" \"well look at it this way....\".</p>\n<p>&nbsp;</p>\n<p>Now some of this may come from me- I'm explaining too fast or in a way they don't understand, and my familiarity with the subject, but I suspect some comes from them. It can be difficult to admit one's ignorance, from my own experience. I, and I suspect others who go on to do university maths, was used to being the best or near the best in school, with \"being smart\" being part of my core identity, something that made me distinct from my more attractive or more fit peers. Getting to university and realising one is having difficulty with even basic questions can be a knock to ones identity. So I hid my ignorance, and did myself damage. I might lose the respect of a tutor, or even a lecturer by admitting my ignorance, but the alternative is to remain ignorant.</p>\n<p>&nbsp;</p>\n<p>I suspect this is a problem that is common among us all. Its a lot easier to pretend we understand, and sometimes it may help- if we want to impress a potential employer we shouldn't admit ignorance (unless the alternative makes us look more ignorant)- but in general admitting ignorance helps us learn. There is (almost) always someone with more knowledge on a particular subject than you, and a failure to use that resource is a failure of rationality.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DPktquNsDrsJdXq4r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 22, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "6251", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8wWdgzokzq6dBG7Mq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-15T16:45:13.739Z", "modifiedAt": null, "url": null, "title": "The Friendly AI Game", "slug": "the-friendly-ai-game", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:03.650Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bentarm", "createdAt": "2009-03-05T17:59:17.163Z", "isAdmin": false, "displayName": "bentarm"}, "userId": "xdmTZWK4DzchxkyQC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8C4hnqZ62gSjszHuT/the-friendly-ai-game", "pageUrlRelative": "/posts/8C4hnqZ62gSjszHuT/the-friendly-ai-game", "linkUrl": "https://www.lesswrong.com/posts/8C4hnqZ62gSjszHuT/the-friendly-ai-game", "postedAtFormatted": "Tuesday, March 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Friendly%20AI%20Game&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Friendly%20AI%20Game%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C4hnqZ62gSjszHuT%2Fthe-friendly-ai-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Friendly%20AI%20Game%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C4hnqZ62gSjszHuT%2Fthe-friendly-ai-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C4hnqZ62gSjszHuT%2Fthe-friendly-ai-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 376, "htmlBody": "<p>At the recent London meet-up someone (I'm afraid I can't remember who) suggested that one might be able to solve the <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a> problem by building an AI whose concerns are limited to some small geographical area, and which doesn't give two hoots about what happens outside that area. Cipergoth pointed out that this would probably result in the AI converting the rest of the universe into a factory to make its small area more awesome. In the process, he mentioned that you can make a \"fun game\" out of figuring out ways in which proposed utility functions for Friendly AIs can go horribly wrong. I propose that we play.</p>\n<p>Here's the game: reply to this post with proposed utility functions, stated as formally or, at least, as accurately as you can manage; follow-up comments explain why a super-human intelligence built with that particular utility function would do things that turn out to be hideously undesirable.</p>\n<p>There are three reasons I suggest playing this game. In descending order of importance, they are:</p>\n<ol>\n<li>It sounds like fun</li>\n<li>It might help to convince people that the Friendly AI problem is hard(*).</li>\n<li>We might actually come up with something that's better than anything anyone's thought of before, or something where the proof of Friendliness is within grasp - the solutions to difficult mathematical problems often look obvious in hindsight, and it surely can't hurt to try</li>\n</ol>\n<div>DISCLAIMER (probably unnecessary, given the audience) - I think it is unlikely that anyone will manage to come up with a formally stated utility function for which none of us can figure out a way in which it could go hideously wrong. However, if they do so, this does NOT constitute a proof of Friendliness and I 100% do not endorse any attempt to implement an AI with said utility function.</div>\n<div>(*) I'm slightly worried that it might have the opposite effect, as people build more and more complicated conjunctions of desires to overcome the objections that we've already seen, and start to think the problem comes down to nothing more than writing a long list of special cases but, on balance, I think that's likely to have less of an effect than just seeing how naive suggestions for Friendliness can be hideously broken.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1, "ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8C4hnqZ62gSjszHuT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 50, "extendedScore": null, "score": 0.0005743363696095945, "legacy": true, "legacyId": "6236", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 178, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-16T06:23:54.674Z", "modifiedAt": null, "url": null, "title": "Enjoying food more: a case study in third options", "slug": "enjoying-food-more-a-case-study-in-third-options", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:01.048Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MBlume", "createdAt": "2009-02-27T20:25:40.379Z", "isAdmin": false, "displayName": "MBlume"}, "userId": "b8uLskcBa7Zbkm5M6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5X23KoNWKXfTcWzuK/enjoying-food-more-a-case-study-in-third-options", "pageUrlRelative": "/posts/5X23KoNWKXfTcWzuK/enjoying-food-more-a-case-study-in-third-options", "linkUrl": "https://www.lesswrong.com/posts/5X23KoNWKXfTcWzuK/enjoying-food-more-a-case-study-in-third-options", "postedAtFormatted": "Wednesday, March 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Enjoying%20food%20more%3A%20a%20case%20study%20in%20third%20options&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEnjoying%20food%20more%3A%20a%20case%20study%20in%20third%20options%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5X23KoNWKXfTcWzuK%2Fenjoying-food-more-a-case-study-in-third-options%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Enjoying%20food%20more%3A%20a%20case%20study%20in%20third%20options%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5X23KoNWKXfTcWzuK%2Fenjoying-food-more-a-case-study-in-third-options", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5X23KoNWKXfTcWzuK%2Fenjoying-food-more-a-case-study-in-third-options", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 659, "htmlBody": "<p>This was originally going to be a comment on Zvi's excellent \"<a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/\">How I Lost 100 Pounds Using TDT</a>\", but it ran rather long, so I expanded it to a top-level post. Hope no one minds.</p>\n<p>The issue I took with Zvi's post was that there seemed to be a general assumption being made -- not just in the post, but in comments -- about improvements in health outcomes coming from sacrifices in food-related hedonic outcomes. This would make sense if we were all on some efficient frontier between nutrition and enjoyment of food. I think for most of us<sup>1</sup> this is blatantly false.</p>\n<p>So then, here are three steps aimed simply towards enjoying food more.<sup>2</sup> Eat better food. Eat food you actually like. Pay attention when you eat. These steps may themselves mildly improve your health outcomes, but they are intended primarily to help you enjoy food. You can of course combine them with efficient trades between hedons and nutrition, and wind up doing drastically better for both.<a id=\"more\"></a></p>\n<h2>Step one: <strong>Eat better food</strong>.</h2>\n<p>If you have spare time, learn to cook. Consider reading, among other things, Alicorn's <a href=\"http://improvisationalsoup.wordpress.com/\">very fine food blog</a> (which she should update more, nudge nudge). If you have spare money, eat at nicer restaurants from time to time. Explore what's available in your city, and try to learn what you like.<sup>3</sup></p>\n<p>Learn what flavors you like. Eat less bland cheeses. Eat less bland meats. Learn about herbs and spices.</p>\n<h2>Step two: Eat more of what you actually like and less of what you suddenly want.</h2>\n<p><a href=\"/lw/1lb/are_wireheads_happy/\">Liking is different from wanting</a>. Sometimes you'll find yourself desperately wanting -- say -- a bag of cheetos. So you'll go right ahead and scarf down that bag of cheetos, and -- gosh dangit -- it <em>won't actually be that satisfying at all</em>. Pay <em>attention</em> to these experiences. Say to your brain next time \"I know you want me to grab the bag of cheetos, but <em>the record suggests</em> that you're not going to release that much of a pleasure response when I do. Try not to cry wolf next time.\" At the end of the week, eat some really good cheesecake, or a steak, or something else that you in particular will deeply enjoy.</p>\n<h2>Step three: Actually pay attention to the food you do eat.</h2>\n<p>This is by far the most important step. Actually paying attention to experiences is <em>not</em> something humans do naturally. You blink, and the food in front of you is half gone, and you can hardly remember how it tasted because you were absorbed in a conversation with your friends, or you were eating at your desk while clumsily trying to type with your other hand, or walking down the street. Think (not while you're eating, that would be distracting) of how many bites of calorie-laden food you have swallowed, and metabolized, and never actually carefully tasted.</p>\n<p>Don't do this. Especially don't do this if you are going to choose to eat moderately unhealthy food because it's delicious. Be focused. Be mindful. Devote specific mental attention to each flavor and each sensation as you bite and chew and swallow<sup>4</sup>.</p>\n<p>&nbsp;</p>\n<p>These, then, are the three steps. Eat good food. Eat food you actually like. Actually <em>pay attention</em> to what you put in your mouth.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>1: Mycroft's <a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/3ot5\">comment</a> made roughly the point I'm making here. Also I'm going to specifically exempt Alicorn from this generalization.</p>\n<p>2: I'm pretty sure much of this generalizes beyond food, an exercise I leave to the reader/to the commenters.</p>\n<p>3:<sup>&nbsp;</sup>If you have neither spare time nor spare money, and you are not saving umpteen zillions of expected lives through your sacrifices...you're probably making a bit of a hash out of structuring your life (don't feel too bad -- most do!), and should just <a href=\"/lw/43m/optimal_employment/\">move to Australia</a> already.</p>\n<p>4: If the things I'm asking you to do in this last step do not sound like levers that you know how to pull in your brain, consider getting very heavily stoned on cannabis and then eating something you already enjoy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1, "92SxJsDZ78ApAGq72": 1, "6bdeSR7aKmdSQLw6P": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5X23KoNWKXfTcWzuK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 25, "extendedScore": null, "score": 5.9e-05, "legacy": true, "legacyId": "6257", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This was originally going to be a comment on Zvi's excellent \"<a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/\">How I Lost 100 Pounds Using TDT</a>\", but it ran rather long, so I expanded it to a top-level post. Hope no one minds.</p>\n<p>The issue I took with Zvi's post was that there seemed to be a general assumption being made -- not just in the post, but in comments -- about improvements in health outcomes coming from sacrifices in food-related hedonic outcomes. This would make sense if we were all on some efficient frontier between nutrition and enjoyment of food. I think for most of us<sup>1</sup> this is blatantly false.</p>\n<p>So then, here are three steps aimed simply towards enjoying food more.<sup>2</sup> Eat better food. Eat food you actually like. Pay attention when you eat. These steps may themselves mildly improve your health outcomes, but they are intended primarily to help you enjoy food. You can of course combine them with efficient trades between hedons and nutrition, and wind up doing drastically better for both.<a id=\"more\"></a></p>\n<h2 id=\"Step_one__Eat_better_food_\">Step one: <strong>Eat better food</strong>.</h2>\n<p>If you have spare time, learn to cook. Consider reading, among other things, Alicorn's <a href=\"http://improvisationalsoup.wordpress.com/\">very fine food blog</a> (which she should update more, nudge nudge). If you have spare money, eat at nicer restaurants from time to time. Explore what's available in your city, and try to learn what you like.<sup>3</sup></p>\n<p>Learn what flavors you like. Eat less bland cheeses. Eat less bland meats. Learn about herbs and spices.</p>\n<h2 id=\"Step_two__Eat_more_of_what_you_actually_like_and_less_of_what_you_suddenly_want_\">Step two: Eat more of what you actually like and less of what you suddenly want.</h2>\n<p><a href=\"/lw/1lb/are_wireheads_happy/\">Liking is different from wanting</a>. Sometimes you'll find yourself desperately wanting -- say -- a bag of cheetos. So you'll go right ahead and scarf down that bag of cheetos, and -- gosh dangit -- it <em>won't actually be that satisfying at all</em>. Pay <em>attention</em> to these experiences. Say to your brain next time \"I know you want me to grab the bag of cheetos, but <em>the record suggests</em> that you're not going to release that much of a pleasure response when I do. Try not to cry wolf next time.\" At the end of the week, eat some really good cheesecake, or a steak, or something else that you in particular will deeply enjoy.</p>\n<h2 id=\"Step_three__Actually_pay_attention_to_the_food_you_do_eat_\">Step three: Actually pay attention to the food you do eat.</h2>\n<p>This is by far the most important step. Actually paying attention to experiences is <em>not</em> something humans do naturally. You blink, and the food in front of you is half gone, and you can hardly remember how it tasted because you were absorbed in a conversation with your friends, or you were eating at your desk while clumsily trying to type with your other hand, or walking down the street. Think (not while you're eating, that would be distracting) of how many bites of calorie-laden food you have swallowed, and metabolized, and never actually carefully tasted.</p>\n<p>Don't do this. Especially don't do this if you are going to choose to eat moderately unhealthy food because it's delicious. Be focused. Be mindful. Devote specific mental attention to each flavor and each sensation as you bite and chew and swallow<sup>4</sup>.</p>\n<p>&nbsp;</p>\n<p>These, then, are the three steps. Eat good food. Eat food you actually like. Actually <em>pay attention</em> to what you put in your mouth.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>1: Mycroft's <a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/3ot5\">comment</a> made roughly the point I'm making here. Also I'm going to specifically exempt Alicorn from this generalization.</p>\n<p>2: I'm pretty sure much of this generalizes beyond food, an exercise I leave to the reader/to the commenters.</p>\n<p>3:<sup>&nbsp;</sup>If you have neither spare time nor spare money, and you are not saving umpteen zillions of expected lives through your sacrifices...you're probably making a bit of a hash out of structuring your life (don't feel too bad -- most do!), and should just <a href=\"/lw/43m/optimal_employment/\">move to Australia</a> already.</p>\n<p>4: If the things I'm asking you to do in this last step do not sound like levers that you know how to pull in your brain, consider getting very heavily stoned on cannabis and then eating something you already enjoy.</p>", "sections": [{"title": "Step one: Eat better food.", "anchor": "Step_one__Eat_better_food_", "level": 1}, {"title": "Step two: Eat more of what you actually like and less of what you suddenly want.", "anchor": "Step_two__Eat_more_of_what_you_actually_like_and_less_of_what_you_suddenly_want_", "level": 1}, {"title": "Step three: Actually pay attention to the food you do eat.", "anchor": "Step_three__Actually_pay_attention_to_the_food_you_do_eat_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["scwoBEju75C45W5n3", "HmfxSWnqnK265GEFM", "jtedBLdducritm8y6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-16T16:24:49.901Z", "modifiedAt": null, "url": null, "title": "Suicide note of an LW user", "slug": "suicide-note-of-an-lw-user", "viewCount": null, "lastCommentedAt": "2019-01-10T22:50:21.680Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JmH3v5GcheX6xr6Ch/suicide-note-of-an-lw-user", "pageUrlRelative": "/posts/JmH3v5GcheX6xr6Ch/suicide-note-of-an-lw-user", "linkUrl": "https://www.lesswrong.com/posts/JmH3v5GcheX6xr6Ch/suicide-note-of-an-lw-user", "postedAtFormatted": "Wednesday, March 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Suicide%20note%20of%20an%20LW%20user&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuicide%20note%20of%20an%20LW%20user%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmH3v5GcheX6xr6Ch%2Fsuicide-note-of-an-lw-user%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Suicide%20note%20of%20an%20LW%20user%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmH3v5GcheX6xr6Ch%2Fsuicide-note-of-an-lw-user", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmH3v5GcheX6xr6Ch%2Fsuicide-note-of-an-lw-user", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<p>It was User:pdf23ds. <a href=\"http://pdf23ds.net/2011/03/15/bye/\">Here</a>'s the note. Excerpt:</p>\n<blockquote>\n<p><span style=\"font-family: 'Trebuchet MS', Trebuchet, Verdana, sans-serif; font-size: small;\">I wish I could have been cryonically preserved. But suicides aren&rsquo;t treated well enough for that. We get sectioned. I tried asking the cryonics places about options, but they wouldn&rsquo;t talk to me. Fuck you, Alcor. Fuck you, CI. I might have lived except for you.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JmH3v5GcheX6xr6Ch", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "6270", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-16T21:25:19.446Z", "modifiedAt": null, "url": null, "title": "World Future 2011 Conference in Vancouver", "slug": "world-future-2011-conference-in-vancouver", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:59.675Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JaapSuter", "createdAt": "2009-03-03T17:59:24.346Z", "isAdmin": false, "displayName": "JaapSuter"}, "userId": "yQC5jf8ridfQ5ELg8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YoxyxG6PFQzwtmvcb/world-future-2011-conference-in-vancouver", "pageUrlRelative": "/posts/YoxyxG6PFQzwtmvcb/world-future-2011-conference-in-vancouver", "linkUrl": "https://www.lesswrong.com/posts/YoxyxG6PFQzwtmvcb/world-future-2011-conference-in-vancouver", "postedAtFormatted": "Wednesday, March 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20World%20Future%202011%20Conference%20in%20Vancouver&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWorld%20Future%202011%20Conference%20in%20Vancouver%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoxyxG6PFQzwtmvcb%2Fworld-future-2011-conference-in-vancouver%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=World%20Future%202011%20Conference%20in%20Vancouver%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoxyxG6PFQzwtmvcb%2Fworld-future-2011-conference-in-vancouver", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYoxyxG6PFQzwtmvcb%2Fworld-future-2011-conference-in-vancouver", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p><span style=\"border-collapse: collapse; color: #444444; font-family: arial, sans-serif; font-size: 13px;\">If there are any people&nbsp;who'd like to come to <a href=\"http://www.wfs.org/content/worldfuture-2011\">WFS-11</a>, but can't for financial reasons - I'm opening up my Vancouver home as a place to stay for a limited number of people. I have an unused guest bedroom, an additional makeshift third bedroom, and a floor available to anyone who doesn't mind bringing their own sleeping gear.</span></p>\n<p><span style=\"border-collapse: collapse; color: #444444; font-family: arial, sans-serif; font-size: 13px;\">Interested folks should contact me at <a href=\"mailto:wfs11@jaapsuter.com\">wfs11@jaapsuter.com</a>.</span></p>\n<p><span style=\"border-collapse: collapse; color: #444444; font-family: arial, sans-serif; font-size: 13px;\">Jaap Suter - <a href=\"http://jaapsuter.com\">http://jaapsuter.com</a></span></p>\n<p><span style=\"border-collapse: collapse; color: #444444; font-family: arial, sans-serif; font-size: 13px;\"><br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YoxyxG6PFQzwtmvcb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 6.908021148014151e-07, "legacy": true, "legacyId": "6272", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-16T22:26:26.805Z", "modifiedAt": null, "url": null, "title": "Some altruism anecdotes [link]", "slug": "some-altruism-anecdotes-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:57:59.593Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YsWLLtssQoGxN8Fho/some-altruism-anecdotes-link", "pageUrlRelative": "/posts/YsWLLtssQoGxN8Fho/some-altruism-anecdotes-link", "linkUrl": "https://www.lesswrong.com/posts/YsWLLtssQoGxN8Fho/some-altruism-anecdotes-link", "postedAtFormatted": "Wednesday, March 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20altruism%20anecdotes%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20altruism%20anecdotes%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsWLLtssQoGxN8Fho%2Fsome-altruism-anecdotes-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20altruism%20anecdotes%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsWLLtssQoGxN8Fho%2Fsome-altruism-anecdotes-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsWLLtssQoGxN8Fho%2Fsome-altruism-anecdotes-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 168, "htmlBody": "<p>(I am not sure if this is the right place to post this, if I'm wrong please just tell me so and I'll delete the post, ok? No need to give me -20 karma. )</p>\n<p>So, I just stumble upon this compilation of tweets from the recent tragedies in japan, with translations. Link to forum post where I found it: http://www.bay12forums.com/smf/index.php?topic=79383.msg2080663#msg2080663</p>\n<p>While it may not seem very relevant at first, I actually found a fair lot of them were related to things that are: the volition of humanity, sanity waterlines and how a less mad world might look, \"MoR!hermione\" type people and possibly it contains evidence that the right social&nbsp; climate can make them more likely, the notion that a society of rationalists should win (this one may be a bit far fetched), and considering the length of this list probably a few things that I missed!</p>\n<p>It is also rather hertwarming! :) ((free fuzzies, so now that money is freed up for you to spend on utilions instead. :P ))</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YsWLLtssQoGxN8Fho", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.908188025649223e-07, "legacy": true, "legacyId": "6273", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T07:22:43.651Z", "modifiedAt": "2020-04-14T17:29:44.934Z", "url": null, "title": "How to Be Happy", "slug": "how-to-be-happy", "viewCount": null, "lastCommentedAt": "2022-04-08T08:11:29.558Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZbgCx2ntD5eu8Cno9/how-to-be-happy", "pageUrlRelative": "/posts/ZbgCx2ntD5eu8Cno9/how-to-be-happy", "linkUrl": "https://www.lesswrong.com/posts/ZbgCx2ntD5eu8Cno9/how-to-be-happy", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Be%20Happy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Be%20Happy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZbgCx2ntD5eu8Cno9%2Fhow-to-be-happy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Be%20Happy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZbgCx2ntD5eu8Cno9%2Fhow-to-be-happy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZbgCx2ntD5eu8Cno9%2Fhow-to-be-happy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5231, "htmlBody": "<p><span style=\"font-size: 11px;\">Part of the sequence:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></span></p>\n<p>One day a coworker said to me, \"Luke! You're, like, the happiest person I know!&nbsp;How come you're so happy all the time?\"</p>\n<p>It was probably a rhetorical question, but I had a very long answer to give. See, I was&nbsp;<em>un</em>happy for most of my life,<sup>1</sup>&nbsp;and even considered suicide a few times. Then I spent two years studying the science of happiness. Now, happiness is my natural state. I can't remember the last time I felt unhappy for longer than 20 minutes.</p>\n<p>That kind of change won't happen for everyone, or even most people (<a href=\"/lw/9v/beware_of_otheroptimizing/\">beware of other-optimizing</a>), but it's worth a shot!&nbsp;</p>\n<p>We all want to be happy, and happiness is useful for other things, too.<sup>2</sup> For example, happiness improves physical health,<sup>3</sup>&nbsp;improves creativity,<sup>4</sup>&nbsp;and even enables you to make better decisions.<sup>5</sup>&nbsp;(It's harder to be rational when you're unhappy.<sup>6</sup>) So, as part of a series on how to <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">win</a> <a href=\"/lw/3w3/how_to_beat_procrastination/\">at</a> <a href=\"/lw/1sm/akrasia_tactics_review/\">life</a> with science and rationality, let's review&nbsp;<strong>the science of happiness</strong>.</p>\n<p>&nbsp;</p>\n<h4>The correlates of happiness</h4>\n<p><a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">Earlier</a>, I noted that&nbsp;there is an abundance of research on factors that correlate with&nbsp;<em style=\"font-style: italic;\">subjective well-being</em>&nbsp;(individuals' own assessments of their happiness and life satisfaction).</p>\n<p>Factors that&nbsp;<em style=\"font-style: italic;\">don't correlate</em>&nbsp;much with happiness include: age,<span style=\"font-size: 11px;\"><sup>7</sup></span>&nbsp;gender,<sup>8</sup>&nbsp;parenthood,<sup>9</sup>&nbsp;intelligence,<sup>10</sup>&nbsp;physical attractiveness,<sup>11</sup>&nbsp;and money<sup>12</sup>&nbsp;(as long as you're above the poverty line). Factors that&nbsp;<em style=\"font-style: italic;\">correlate moderately</em>&nbsp;with happiness include: health,<span style=\"font-size: 11px;\"><sup>13</sup></span>&nbsp;social activity,<sup>14</sup>&nbsp;and religiosity.<sup>15</sup>&nbsp;Factors that&nbsp;<em style=\"font-style: italic;\">correlate strongly</em>&nbsp;with happiness include: genetics,<sup>16</sup>&nbsp;love and relationship satisfaction,<sup>17&nbsp;</sup>and work satisfaction.<sup>18</sup></p>\n<p>But correlation is not enough. We want to know what <em>causes</em>&nbsp;happiness. And that is a trickier thing to measure. But we do know a <em>few</em> things.</p>\n<p>&nbsp;</p>\n<h4>Happiness, personality, and skills</h4>\n<p>Genes account for about 50% of the variance in happiness.<sup>19</sup> Even lottery winners and newly-made quadriplegics do not see as much of a change in happiness as you would expect.<span style=\"font-size: 11px;\"><sup>20</sup></span>&nbsp;Presumably, genes shape your happiness by shaping your personality, which is known to be quite heritable.<sup>21</sup></p>\n<p>So which personality traits tend to correlate most with happiness? Extroversion is among the best predictors of happiness,<sup>22</sup> as are conscientiousness, agreeableness, self-esteem, and optimism.<sup>23</sup></p>\n<p>What if you don't have those traits? The first thing to say is that you might be capable of them without knowing it. Introversion, for example, can be exacerbated by <em>a lack of social skills</em>. If you decide to <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">learn</a> and <a href=\"http://reports.toastmasters.org/findaclub/\">practice</a> social skills, you might find that you are more extroverted than you thought! (That's what happened to me.) The same goes for <a href=\"http://www.amazon.com/dp/055380491X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">conscientiousness</a>, <a href=\"http://www.amazon.com/dp/1439167346/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">agreeableness</a>, <a href=\"http://www.psychologicalselfhelp.org/Chapter14/chap14_5.html\">self-esteem</a>, and <a href=\"/lw/3w3/how_to_beat_procrastination/#optimism\">optimism</a> - these are only partly linked to personality. They are to some extent learnable skills, and learning these skills (or even \"acting as if\") can increase happiness.<sup>24</sup></p>\n<p>The second thing to say is that lacking some of these traits does not, of course, doom you to unhappiness.</p>\n<p><a id=\"more\"></a></p>\n<h3><br /></h3>\n<h3>Happiness is subjective and relative</h3>\n<p>Happiness is not determined by objective factors, but by how you <em>feel</em>&nbsp;about them.<sup>25</sup></p>\n<p>Happiness is also relative<sup>26</sup>: you'll probably be happier making $25,000/yr in Costa Rica (where your neighbors are making $13,000/yr) than you will be making $80,000/yr in Beverly Hills (where your neighbors are making $130,000/yr).</p>\n<p>Happiness is relative in another sense, too: it is relative to your <em>expectations</em>.<sup>27</sup> We are quite poor at predicting the strength of our emotional reactions to future events. We overestimate the misery we will experience after a romantic breakup, failure to get a promotion, or even contracting an illness.&nbsp;We also overestimate the <em>pleasure</em> we will get from buying a nice car, getting a promotion, or moving to a lovely coastal city. So: lower your expectations about the pleasure you'll get from such expenditures.</p>\n<p>&nbsp;</p>\n<h3>Flow and mindfulness</h3>\n<p>You may have heard of the famous studies<sup>28</sup> showing that people are happiest when they are in a state of \"<a href=\"http://en.wikipedia.org/wiki/Flow_(psychology)\">flow</a>.\" Flow is the state you're in when you are fully engaged in a task that is interesting, challenging, and intrinsically rewarding to you. This is the experience of \"losing yourself in the moment\" or, as sports players say, \"being in the zone.\"</p>\n<p>Finding flow has largely to do with performing tasks that match your skill level. When a task is far beyond your skill level, you will feel defeated. When a task is too easy, you'll be bored. Only when a task is challenging but achievable will you feel good about doing it. I'm reminded of&nbsp;the state troopers in&nbsp;<em><a href=\"http://www.youtube.com/watch?v=2-9D2qUHN-E\">Super Troopers</a></em>, who devised strange games and challenges to make their boring jobs passable. <a href=\"http://www.youtube.com/watch?v=EY3Lw_-bj5U\">Myrtle Young</a> made her boring job at a potato chip factory more interesting and challenging by looking for potato chips that resembled celebrities, and pulling them off the conveyor belts for her collection.</p>\n<p>If you're struggling with negative thoughts, achieving flow is probably the best medicine. Contrary to popular wisdom, forced positive thinking often makes things worse.<sup>29</sup> Trying to <em>not </em>think about&nbsp;Upsetting Thought X has the same effect as trying to not think about pink elephants: you can't help but think about pink elephants.</p>\n<p>While being \"lost in the moment\" may provide some of your happiest moments, research has also shown that when you're not&nbsp;in flow,&nbsp;taking a step outside the moment and practicing \"mindfulness\" - that is, paying attention to your situation, your actions, and your feelings - can reduce chronic pain and depression<sup>30</sup>, reduce stress and anxiety<sup>31</sup>, and produce a wide range of other positive effects.<sup>32</sup>&nbsp;</p>\n<p>&nbsp;</p>\n<h3>How to be happier</h3>\n<p>Happiness, then, is an enormously complex thing. Worse, we must remember the difference between <a href=\"http://www.ted.com/talks/daniel_kahneman_the_riddle_of_experience_vs_memory.html\">experienced happiness and remembered happiness</a>. I can only scratch the surface of happiness research in this tiny post. In short, there is no simple fix for unhappiness; no straight path to bliss.</p>\n<p>Moreover, happiness will be achieved differently for different people. A person suffering from depression due to chemical imbalance may get more help from a pill than from learning better social skills. A healthy, extroverted, agreeable, conscientious woman can still be unhappy if she is trapped in a bad marriage. Some people were raised by parents whose parenting style did not encourage the development of healthy self-esteem,<sup>33</sup> and they will need to devote significant energy to overcome this deficit. For some, the road to happiness is long. For others, it is short.</p>\n<p>Below, I review a variety of methods for becoming happier. Some of them I discussed above; many, I did not.</p>\n<p>These methods are ranked roughly in descending order of importance and effect, based on my own reading of the literature. You will need to think about who you are, what makes you happy, what makes you unhappy, and what you can achieve in order to determine which of the below methods should be attempted first. Also, engaging any of these methods may require that you first gain some <a href=\"/lw/3w3/how_to_beat_procrastination/\">mastery over procrastination</a>.</p>\n<p>Here, then, are some methods for becoming happier<sup>34</sup>:</p>\n<ol>\n<li>If you suffer from serious illness, depression, anxiety, paranoia, schizophrenia, or other serious problems, <em>seek professional help first</em>. <a href=\"http://www.liveyourlifewell.org/go/live-your-life-well/help\">Here's how</a>.</li>\n<li>Even if you don't need professional help, you may benefit from some self-exploration and <em>initial guidance</em> from a reductionistic, naturalistic counselor like <a href=\"http://naturalism.org/consulting.htm\">Tom Clark</a>.</li>\n<li>Develop the skills and habits associated with <em>extroversion</em>. First, get some decent clothes and learn how to wear them properly. If you're a guy, <a href=\"http://www.amazon.com/Details-Mens-Style-Manual-Ultimate/dp/159240328X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">read</a> <a href=\"http://www.bradp.com/brads-fashion-bible\">these</a> <a href=\"http://www.amazon.com/Mens-Style-Thinking-Guide-Dress/dp/0312361653/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">books</a>. If you're a girl, ask your girlfriends or try <a href=\"http://www.amazon.com/What-Not-Wear-Trinny-Woodall/dp/B0042P5752/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">these</a> <a href=\"http://www.amazon.com/Dress-Your-Best-Complete-Finding/dp/0307236714/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">books</a>. Next, learn basic&nbsp;<a href=\"http://www.amazon.com/How-Talk-Anyone-Success-Relationships/dp/007141858X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">social</a> <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">skills</a>, including <a href=\"http://www.amazon.com/Winning-Body-Language-Conversation-Attention/dp/0071700579/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">body</a> <a href=\"http://www.amazon.com/Definitive-Book-Body-Language/dp/0553804723/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">language</a>.&nbsp;If you're <em>really</em>&nbsp;introverted, practice on <a href=\"http://en.wikipedia.org/wiki/Chatroulette\">Chatroulette</a>&nbsp;or <a href=\"http://www.omegle.com/\">Omegle</a> first. Next, spend more time with other people, making small talk. Go to <a href=\"http://www.meetup.com/\">meetups</a> and <a href=\"http://www.couchsurfing.org/\">CouchSurfing</a> group activities. Practice your skills until they become more natural, and you find yourself <em>enjoying</em>&nbsp;being in the company of others. Learn <a href=\"http://www.amazon.com/Comic-Toolbox-Funny-Even-Youre/dp/1879505215/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">how</a> to <a href=\"http://www.amazon.com/Finding-Funny-Fast-Connect-Coworkers/dp/0984099905/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">be</a> <a href=\"http://www.amazon.com/How-Be-Funny-Discovering-Comic/dp/1573922064/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">funny</a> and practice that, too.</li>\n<li>Improve your <em>self-esteem</em>&nbsp;and <em>optimism</em>. This is tricky. First, too much self-esteem can lead to harmful&nbsp;narcissism.<sup>35</sup> Second, it's not clear that a rationalist can endorse several standard methods for improving one's self esteem (self-serving bias, basking in reflected glory, self-handicapping)<sup>36</sup> because they toy with self-deception and <a href=\"http://wiki.lesswrong.com/wiki/Anti-epistemology\">anti-epistemology</a>. But there are a few safe ways to increase your self-esteem and optimism. Make use of success spirals, vicarious victory, and mental contrasting, as described <a href=\"/lw/3w3/how_to_beat_procrastination/#optimism\">here</a>.</li>\n<li>Improve your <em>agreeableness</em>. In simpler terms, this basically means: increase your empathy. Unfortunately, little is currently known (scientifically) about how to increase one's empathy.<sup>37</sup> The usual advice about trying to see things from another's perspective, and thinking more about people less fortunate than oneself, will have to do for now. The organization <a href=\"http://www.rootsofempathy.org/\">Roots of Empathy</a> may have some good <a href=\"http://opinionator.blogs.nytimes.com/2010/11/08/fighting-bullying-with-babies/\">advice</a>, too.</li>\n<li>Improve your <em>conscientiousness</em>. Conscientiousness involves a variety of tendencies: useful organization, strong work ethic, reliability, planning ahead, etc. Each of these individual skills can be learned. The techniques for <a href=\"/lw/3w3/how_to_beat_procrastination/\">overcoming procrastination</a> are useful, here. Some people report that books like <em><a href=\"http://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0142000280/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Getting Things Done</a></em>&nbsp;have helped them become more organized and reliable.</li>\n<li>Develop the <em>habit of gratitude</em>. Savor the good moments throughout each day.<sup>38</sup>&nbsp;Spend time thinking about happy memories.<sup>39</sup> And at the end of each day, write down 5 things you are grateful for: the roof over your head, your good fortune at being born in a wealthy country, the existence of <em>Less Wrong</em>, the taste of chocolate, the feel of orgasm... whatever. It sounds childish, but it works.<sup>40</sup></li>\n<li>Find your <em>purpose</em> and live it. One benefit of religion may be that it gives people a sense of meaning and purpose. Without a magical deity to give you purpose, though, you'll have to find out for yourself what drives you. It may take a while to find it though, and you may have to dip your hands and mind into many fields. But once you find a path that strongly motivates you and fulfills you, take it. (Of course, you might not find one purpose but many.) Having a strong sense of meaning and purpose has a wide range of positive effects.<sup>41</sup> The 'find a purpose' recommendation also offers an illustration of how methods may differ in importance for people. 'Find a purpose' is not always emphasized in happiness literature, but for my own brain chemistry I suspect that finding motivating purposes has made more difference in my life than anything else on this list.</li>\n<li>Find a more <em>fulfilling job</em>. Few people do what they love for a living. Getting to that point can be difficult and complicated. You may find that doing 10 other things on this list <em>first</em>&nbsp;is needed for you to have a good chance at getting a more fulfilling job.&nbsp;To figure out which career might be full of tasks that you love to do, a <a href=\"http://www.bigjobportal.com/riasec/\">RIASEC</a> personality test might help. In the USA, <a href=\"http://www.onetonline.org/\">O*NET</a> can help you find jobs that are in-demand and fit your personality.</li>\n<li>Improve your relationship with your <em>romantic partner</em>, or find a different one. As with finding a more fulfilling job, this one is complicated, but can have major impact. If you know your relationship isn't going anywhere, you may want to drop it so you can spend more time developing yourself, which will improve future relationships. If you're pretty serious about your partner, there are many things you can do to improve the relationship. Despite being touted widely, \"active listening\" doesn't predict relationship success.<sup>42</sup>&nbsp;Tested advice for improving the chances of relationship success and satisfaction include: (1) do novel and exciting things with your partner often<sup>43</sup>, (2) say positive things to and about your partner at least 5 times more often than you say negative things<sup>44</sup>, (3) spend each week writing about why your relationship is better than some others you know about<sup>45</sup>, (4) qualify every criticism of your partner with a review of one or two of their positive qualities<sup>46</sup>, and (5) stare into each other's eyes more often.<sup>47</sup></li>\n<li><em>Go outside</em> and move your body. This will improve your attention and well-being.<sup>48</sup></li>\n<li>Spend more time in <em>flow</em>. Drop impossible tasks in favor of tasks that are at the outer limits of your skillset. Make easy and boring tasks more engaging by turning them into games or adding challenges for yourself.</li>\n<li><em>Practice mindfulness</em> regularly. When not in flow, step outside yourself and pay attention to how you are behaving, how your emotions are functioning, and how your current actions work toward your goals. <a href=\"http://www.wikihow.com/Meditate\">Meditation</a> may help.</li>\n<li><em>Avoid consumerism</em>. The things you own <em>do</em> come to own you, in a sense. Consumerism leads to unhappiness.<sup>49</sup>&nbsp;Unfortunately, you've probably been programmed from birth to see through the lens of consumerism. One way to start deprogramming is by watching <a href=\"http://en.wikipedia.org/wiki/The_Century_of_the_Self\">this documentary</a> about the deliberate invention of consumerism by <a href=\"http://en.wikipedia.org/wiki/Edward_Bernays\">Edward Bernays</a>. After that, you may want to sell or give away many of your possessions and, more importantly, drastically change your purchasing patterns.</li>\n</ol>\n<p>Note that seeking happiness <em>as an end</em>&nbsp;might be counterproductive. Many people report that constantly checking to see if they are happy actually decreases their happiness - a report that fits with the research on \"flow.\" It may be better to seek some of the above goals as ends, and happiness will be a side-effect.</p>\n<p>Remember: Happiness will not come from reading articles on the internet. Happiness will come when you <em>do</em>&nbsp;the things research recommends.</p>\n<p>Good luck!</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">The Good News of Situationist Psychology</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> From a young age through my teenage years, I was known as the pessimist in my family. Of course, I would retort I was merely a <em>realist</em>. Making happiness work within me made me an optimist. These days I'm pessimistic about many things: For example I think there's about a 50/50 chance the human species will survive this century. But it's a kind of rationalistic, emotionally detached pessimism. It doesn't affect my mood.</small></p>\n<p><small><sup>2</sup>&nbsp;Lyubomirsky, King, &amp; Diener (2005).</small></p>\n<p><small><sup>3</sup>&nbsp;Steptoe et al. (2005).</small></p>\n<p><small><sup>4</sup>&nbsp;Isen et al. (1987); Isen (2004); Fredrickson (1998).</small></p>\n<p><small><sup>5</sup>&nbsp;Isen (2002); Morris (1999).</small></p>\n<p><small><sup>6</sup>&nbsp;Beck (2008); Ellis (2001).</small></p>\n<p><small><sup>7</sup>&nbsp;Age and happiness are unrelated (Lykken 1999), age accounting for less than 1% of the variation in people's happiness (Inglehart 1990; Myers &amp; Diener 1997).</small></p>\n<p><small><sup>8</sup>&nbsp;Despite being treated for depressive disorders twice as often as men (Nolen-Hoeksema 2002), women report just as high levels of well-being as men do (Myers 1992).</small></p>\n<p><small><sup>9</sup>&nbsp;Apparently, the joys and stresses of parenthood balance each other out, as people with and without children are equally happy (Argyle 2001).</small></p>\n<p><small><sup>10</sup>&nbsp;Both IQ and educational attainment appear to be unrelated to happiness (Diener et al. 2009; Ross &amp; Van Willigen 1997).</small></p>\n<p><small><sup>11</sup>&nbsp;Good-looking people enjoy huge advantages, but do not report greater happiness than others (Diener et al. 1995).</small></p>\n<p><small><sup>12</sup>&nbsp;The correlation between income and happiness is surprisingly weak (Diener &amp; Seligman 2004; Diener et al. 1993; Johnson &amp; Krueger 2006). One problem may be that higher income contributes to greater materialism, which impedes happiness (Frey &amp; Stutzer 2002; Kasser et al. 2004; Solberg et al. 2002; Kasser 2002; Van Boven 2005; Nickerson et al. 2003; Kahneman et al. 2006).</small></p>\n<p><small><sup>13</sup>&nbsp;Those with disabling health conditions are happier than you might think (Myers 1992; Riis et al. 2005; Argyle 1999).</small></p>\n<p><small><sup>14</sup>&nbsp;Those who are satisfied with their social life are moderately more happy than others (Diener &amp; Seligman 2004; Myers 1999; Diener &amp; Seligman 2002).</small></p>\n<p><small><sup>15</sup>&nbsp;Religiosity correlates with happiness (Abdel-Kahlek 2005; Myers 2008), though it may be religious attendance and not religious belief that matters (Chida et al. 2009).</small></p>\n<p><small><sup>16</sup>&nbsp;Past happiness is the best predictor of future happiness (Lucas &amp; Diener 2008). Happiness is surprisingly unmoved by external factors (Lykken &amp; Tellegen 1996), because genes accounts for about 50% of the variance in happiness (Lyubomirsky et al. 2005; Stubbe et al. 2005).</small></p>\n<p><small><sup>17</sup>&nbsp;Married people are happier than those who are single or divorced (Myers &amp; Diener 1995; Diener et al. 2000), and marital satisfaction predicts happiness (Proulx et al. 2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Unemployment makes people very unhappy (Argyle 2001), and job satisfaction is strongly correlated with happiness (Judge &amp; Klinger 2008; Warr 1999).</small></p>\n<p><small><sup>19</sup>&nbsp;Lyubomirsky et al. (2005); Stubbe et al. (2005).</small></p>\n<p><small><sup>20</sup>&nbsp;Brickman et al. (1978).</small></p>\n<p><small><sup>21</sup>&nbsp;Weiss et al. (2008).</small></p>\n<p><small><sup>22</sup>&nbsp;Lucas &amp; Diener (2008); Fleeson et al. (2002).</small></p>\n<p><small><sup>23</sup>&nbsp;Lucas (2008) and Lyubomirsky et al. (2006).</small></p>\n<p><small><sup>24</sup>&nbsp;On the learnability of extroversion, see&nbsp;Fleeson et al. (2002); Bouchard &amp; Loehlin (2001); McNeil &amp; Fleeson (2006). On the learnability of agreeableness, see Graziano &amp; Tobin (2009). On the learnability of conscientiousness, see Roberts et al. (2009). On the learnability of self-esteem, see Barrett et al. (1999); Borras et al. (2009). On the learnability of optimism, see Lindsley et al. (1995); Hans (2000); Feldman &amp; Matjasko (2005). On the learnability of character traits in general, see Peterson &amp; Seligman (2004).</small></p>\n<p><small><sup>25</sup>&nbsp;Schwarz &amp; Strack (1999).</small></p>\n<p><small><sup>26</sup>&nbsp;Argyle (1999); Hagerty (2000).</small></p>\n<p><small><sup>27</sup> Gilbert (2006), Hsee &amp; Hastie (2005), Wilson &amp; Gilbert (2005).</small></p>\n<p><small><sup>28</sup> Csikszentmihalyi (1990, 1998); Gardner, Csikszentmihalyi &amp; Damon (2002); Nakamura &amp; Csikszentmihalyi (2009).</small></p>\n<p><small><sup>29</sup> Wegner (1989).</small></p>\n<p><small><sup>30</sup> Kabat-Zinn (1982).</small></p>\n<p><small><sup>31</sup> Shapiro et al. (1998); Chang et al. (2004).</small></p>\n<p><small><sup>32</sup> Grossman et al. (2004).</small></p>\n<p><small><sup>33</sup>&nbsp;Felson (1989); Harter (1998); Furnham &amp; Cheng (2000); Wissink et al. (2006).</small></p>\n<p><small><sup>34</sup>&nbsp;There are several disputed and uncertain methods I did not mention. One example is \"expressive writing.\" Compare&nbsp;Lepore &amp; Smyth (2002) and Spera et al. (1994) to&nbsp;Seery et al. (2008). Moreover, talking with a others about bad experiences may help, but maybe not: see&nbsp;Zech &amp; Rim&eacute; (2005). Another disputed method is that of improving mood by thinking quicker and more varied thoughts: see Pronin &amp; Jacobs (2008). I'm waiting for more research to come in on that one. The results of \"affectionate writing\" are mixed: see Floyd et al. (2009). The effects of household plants are also mixed: see Bringslimark et al. (2009). There remains <a href=\"http://mentalhealthnews.org/a-genuine-smile-found-to-improve-health-happiness/84834/\">debate</a> on whether forced smiles and laughter improve happiness. Finally, see the review of literature in Helliwell (2011).</small></p>\n<p><small><sup>35</sup>&nbsp;Crocker &amp; Park (2004); Bushman &amp; Baumeister (1998); Bushman &amp; Baumeister (2002).</small></p>\n<p><small><sup>36</sup>&nbsp;Self-serving bias is the tendency to attribute success to internal causes (oneself), but attribute failure to external causes. Basking in reflected glory is an attempt to enhance one's image by announcing and&nbsp;<a href=\"/lw/i7/belief_as_attire/\">displaying</a>&nbsp;association with a well-perceived group or individual. Self-handicapping is a way of saving face by sabotaging one's performance in order to provide an excuse for the failure.</small></p>\n<p><small><sup>37</sup>&nbsp;See, for example: Stepien &amp; Baernstein (2006); de Vignemont &amp; Singer (2006); Heln &amp; Singer (2008).</small></p>\n<p><small><sup>38</sup>&nbsp;Bryant &amp; Veroff (2007).</small></p>\n<p><small><sup>39</sup>&nbsp;Burton &amp; King (2004).</small></p>\n<p><small><sup>40</sup> Emmons &amp; McCullough (2003); Lyubomirsky et al. (2005); Peterson (2006).</small></p>\n<p><small><sup>41</sup>&nbsp;Park &amp; Folkman (1997); Bauer et al. (2008); Lee et al. (2006); Reker et al. (1987); Ulmer et al. (1991); Langer &amp; Rodin (1976).</small></p>\n<p><small><sup>42</sup> Gottman et al. (1998); Hahlweg et al. (1984); Jacobson et al. (1987).</small></p>\n<p><small><sup>43</sup>&nbsp;Aron et al. (2000); Aron et al. (2003).</small></p>\n<p><small><sup>44</sup>&nbsp;Gottman (1984).</small></p>\n<p><small><sup>45</sup> Buunk et al. (2001).</small></p>\n<p><small><sup>46</sup> Murray &amp; Holmes (1999).</small></p>\n<p><small><sup>47</sup>&nbsp;Aron et al. (2000).&nbsp;As for how to find, attract, and keep a great romantic partner in the first place, well: that will have to wait for another article. And of course, perhaps you're not looking for a&nbsp;<em style=\"font-style: italic;\">long term</em>&nbsp;romantic relationship at all. That's another article, too.</small></p>\n<p><small><sup>48</sup> Berto (2005); Hartig et al. (2003); Kaplan (1993, 2001); Price (2008); Berman et al. (2008); Tennessen &amp; Cimprich (1995).</small></p>\n<p><small><sup>49</sup>&nbsp;Frey &amp; Stutzer (2002); Kasser et al. (2004); Solberg et al. (2002); Kasser (2002); Van Boven (2005); Nickerson et al. (2003); Kahneman et al. (2006).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Argyle (1999). Causes and correlates of happiness. In Kahneman, Diener, &amp; Schwartz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Argyle (2001).&nbsp;<em style=\"font-style: italic;\">The Psychology of Happiness</em>&nbsp;(2nd ed.). New York: Routledge.</small></p>\n<p><small>Aron, Norman, Aron, McKenna, &amp; Heyman (2000). Couples shared participation in novel and arousing activities and experienced relationship quality. <em>Journal of Personality and Social Psychology, 78</em>: 273-283.</small></p>\n<p><small>Aron, Norman, Aron, &amp; Lewandowski (2003). Shared participation in self- expanding activities: Positive effects on experienced marital quality. In Noller &amp; Feeney (Eds.), <em>Marital interaction</em> (pp. 177-196). Cambridge University Press.</small></p>\n<p><small>Barrett, Webster, Wallis (1999). Adolescent self-esteem and cognitive skills training: a school-based intervention. <em>Journal of Child and Family Studies 8(2)</em>: 217-227.</small></p>\n<p><small>Bauer, McAdams, &amp; Pals (2008). Narrative identity and eudaimonic well-being. <em>Journal of Happiness Studies, 9</em>: 81-104.</small></p>\n<p><small>Beck (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Beck-The-Evolution-of-the-Cognitive-Model-of-Depression-and-Its-Neurobiological-Correlates.pdf\">The evolution of the cognitive model of depression and its neurobiological correlates</a>. <em>American Journal of Psychiatry, 165</em>: 969-977.</small></p>\n<p><small>Berman, Jonides, &amp; Kaplan (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berman-The-cognitive-benefits-of-interacting-with-nature.pdf\">The cognitive benefits of interacting with nature</a>. <em>Psychological Science, 19</em>: 1207-1212.</small></p>\n<p><small>Berto (2005). Exposure to restorative environments helps restore attentional capacity. <em>Journal of Environmental Psychology, 25</em>: 249-259.</small></p>\n<p><small>Brickman, Coates, &amp; Janoff-Bulman (1978). Lottery winners and accident victims: Is happiness relative? <em>Journal of Personality and Social Psychology, 36</em>: 917-927.</small></p>\n<p><small>Bringslimark, Hartig, &amp; Patil (2009). The psychological benefits of indoor plants: A critical review of the experimental literature. Journal of <em>Environmental Psychology, 29(4)</em>: 422-433.</small></p>\n<p><small>Bryant &amp; Veroff (2006).<em>&nbsp;<a href=\"http://www.amazon.com/Savoring-New-Model-Positive-Experience/dp/0805851208/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Savoring: A new model of positive experience</a></em>. Mahwah, NJ: Erlbaum.</small></p>\n<p><small>Borras, Boucherie, Mohr, Lecomte, Perroud, &amp; Huguelet (2009). Increasing self-esteem: Efficacy for a group intervention for individuals with severe mental disorders. <em>European Psychiatry, 24</em>: 307-316.</small></p>\n<p><small>Bouchard &amp; Loehlin (2001). Genes, evolution, and personality. <em>Behavior Genetics, 31</em>: 243&ndash;273.</small></p>\n<p><small>Burton &amp; King (2004). The health benefits of writing about intensely positive experiences. <em>Journal of Research in Personality, 38</em>: 150-163.</small></p>\n<p><small>Bushman &amp; Baumeister (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Bushman-Baumeister-Threatened-egotism-narcissism-self-esteem-and-direct-and-displaced-aggression.pdf\">Threatened egotism, narcissism, self-esteem, and direct and displaced aggression: Does self-love or self-hate lead to violence?</a> <em>Journal of Personality and Social Psychology, 75(1)</em>: 219-229.</small></p>\n<p><small>Bushman &amp; Baumeister (2002). Does self-love or self-hate lead to violence? <em>Journal of Research in Personality, 36(6)</em>: 543-545.</small></p>\n<p><small>Buunk, Oldersma, &amp; de Dreu (2001). Enhancing satisfaction through downward comparison: The role of relational discontent and individual differences in social comparison orientation. <em>Journal of Experimental Social Psychology, 37</em>: 452-467.</small></p>\n<p><small>Chang, Palesh, Caldwell, Glasgow, Abramson, Luskin, Gill, Burke, &amp; Koopman (2004). The effects of a mindfulness-based stress reduction program on stress, mindfulness self-efficacy, and positive states of mind. <em>Stress and Health, 20(3)</em>: 141-147.</small></p>\n<p><small>Chida, Steptoe, &amp; Powell (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Chida-Religiosity-Spirituality-and-Mortality.pdf\">Religiosity/Spirituality and Mortality</a>.&nbsp;<em style=\"font-style: italic;\">Psychotherapy and Psychosomatics</em>, 78(2): 81-90.</small></p>\n<p><small>Crocker &amp; Park (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Crocker-Park-The-costly-pursuit-of-self-esteem.pdf\">The costly pursuit of self-esteem</a>. <em>Psychological Bulletin, 130</em>: 392-414.</small></p>\n<p><small>Csikszentmihalyi (1990). <em><a href=\"http://www.amazon.com/dp/0061339202/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Flow: The Psychology of Optimal Experience</a></em>. New York: Harper and Row.</small></p>\n<p><small>Csikszentmihalyi (1998).&nbsp;<em><a href=\"http://www.amazon.com/dp/0465024114/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Finding Flow: The Psychology of Engagement With Everyday Life</a></em>. Basic Books.</small></p>\n<p><small>Diener, Wolsic, &amp; Fujita (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Physical-Attractiveness-and-Subjective-Well-Being.pdf\">Physical attractiveness and subjective well-being</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 69: 120-129.</small></p>\n<p><small>Diener, Gohm, Suh, &amp; Oishi (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Similarity-of-the-relations-between-marital-status-and-subjective-well-being-across-cultures.pdf\">Similarity of the relations between marital status and subjective well-being across cultures</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Cross-Cultural Psychology</em>, 31: 419-436.</small></p>\n<p><small>Diener &amp; Seligman (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Very-Happy-People.pdf\">Very happy people</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 13: 80-83.</small></p>\n<p><small>Diener &amp; Seligman (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Beyond-money.pdf\">Beyond money: Toward an economy of well-being</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science in the Public Interest</em>, 5(1): 1-31.</small></p>\n<p><small>Diener, Kesebir, &amp; Tov (2009). Happiness. In Leary &amp; Hoyle (Eds.),&nbsp;<em style=\"font-style: italic;\">Handbook of Individual Differences in Social Behavior</em>&nbsp;(pp. 147-160). New York: Guilford.</small></p>\n<p><small>Ellis (2001). <em><a href=\"http://www.amazon.com/dp/1573928798/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Overcoming destructive beliefs, feelings, and behaviors: New directions for Rational Emotive Behavior Therapy</a></em>. Amherst, NY: Prometheus Books.</small></p>\n<p><small>Emmons &amp; McCullough (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Emmons-McCullough-Counting-blessings-versus-burdens.pdf\">Counting blessings versus burdens: An experimental investigation of gratitude and subjective well-being in daily life</a>. <em>Journal of Personality and Social Psychology, 84</em>: 377-389.</small></p>\n<p><small>Feldman &amp; Matjasko (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Feldman-The-role-of-school-based-extracurricular-activities-in-adolescent-development.pdf\">The role of school-based extracurricular activities in adolescent development: A comprehensive review and future directions</a>.&nbsp;<em style=\"font-style: italic;\">Review of Educational Research, 75(2)</em>, 159-210.</small></p>\n<p><small>Felson (1989). Parents and the reflected appraisal process: A longitudinal analysis. <em>Journal of Personality and Social Psychology, 56</em>: 965-971.</small></p>\n<p><small>Fleeson, Malanos, &amp; Achille (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Fleeson-An-intraindividual-process-approach-to-the-relationship-between-extraversion-and-positive-affect.pdf\">An intraindividual process approach to the relationship between extraversion and positive affect: is acting extraverted as \"good\" as being extraverted?</a> <em>Journal of Personality and Social Psychology, 83(6)</em>: 1409-1422.</small></p>\n<p><small>Floyd, Hesse, &amp; Pauley (2009). Writing affectionate letters reduces stress: replication and extension. Paper presented at the annual meeting of the NCA 95th annual convention, Chicago, IL, Nov. 11, 2009.</small></p>\n<p><small>Fredrickson (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Fredrickson-What-good-are-positive-emotions.pdf\">What good are positive emotions?</a> <em>Review of General Psychology, 2</em>: 300-319.</small></p>\n<p><small>Frey &amp; Stutzer (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Frey-What-can-economists-learn-from-happiness-research.pdf\">What can economists learn from happiness research?</a>&nbsp;<em style=\"font-style: italic;\">Journal of Economic Literature</em>, 40: 402-435.</small></p>\n<p><small>Furnham &amp; Cheng (2000). Perceived parental behavior, self-esteem and happiness. <em>Social Psychiatry and Psychiatric Epidemiology, 35(10)</em>: 463-470.</small></p>\n<p><small>Gardner, Csikszentmihalyi, &amp; Damon (2002).&nbsp;<em><a href=\"http://www.amazon.com/Good-Business-Leadership-Making-Meaning/dp/014200409X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Good Business: Leadership, Flow, and the Making of Meaning</a></em>. Basic Books.</small></p>\n<p><small>Gilbert (2006). <em><a href=\"http://www.amazon.com/dp/1400077427/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Stumbling on happiness</a></em>. New York: Knopf.</small></p>\n<p><small>Gottman (1984). <em><a href=\"http://www.amazon.com/Why-Marriages-Succeed-Fail-Yours/dp/0684802414/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Why marriages succeed or fail</a></em>. New York: Simon &amp; Schuster.</small></p>\n<p><small>Gottman, Coan, Carrere, &amp; Swanson (1998). Predicting marital happiness and stability from newlywed interactions. <em>Journal of Marriage and the Family, 60</em>: 5-22.</small></p>\n<p><small>Graziano &amp; Tobin (2009). Agreeableness. In Leary &amp; Hoyle (Eds.), <em>Handbook of individual differences in social behavior</em>&nbsp;(pp. 46-61). New York: Guilford.</small></p>\n<p><small>Grossman, Niemann, Schmidt, &amp; Walach (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Grossman-Mindfulness-based-stress-reduction-and-health-benefits.pdf\">Mindfulness-based stress reduction and health benefits: A meta-analysis</a>. <em>Journal of Psychosomatic Research, 57</em>: 35-43.</small></p>\n<p><small>Hagerty (2000). Social comparisons of income in one's community: Evidence from national surveys of income and happiness. <em>Journal of Personality and Social Psychology, 78</em>: 746-771.</small></p>\n<p><small>Hahlweg, Schindler, Revensdorf, &amp; Brengelmann (1984). The Munich marital therapy study. In Hahlweg &amp; Jacobson (Eds.),&nbsp;<em style=\"font-style: italic;\">Marital interaction: Analysis and modification</em>&nbsp;(pp. 3-26). New York: Guilford Press.</small></p>\n<p><small>Hans (2000).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Hans-A-meta-analysis-of-the-effects-of-adventure-programming-on-locus-of-control.pdf\">A meta-analysis of the effects of adventure programming on locus of control</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Contemporary Psychotherapy, 30(1)</em>: 33-60.</small></p>\n<p><small>Harter (1998). The development of self-representations. In Eisenberg (Ed.), <em>Handbook of child psychology: Vol. 3. Social, emotional, and personality development</em>. New York: Wiley.</small></p>\n<p><small>Hartig, Evans, Jamner, Davis, &amp; Garling (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Hartig-Tracking-restoration-in-natural-and-urban-field-settings.pdf\">Tracking restoration in natural and urban field settings</a>. <em>Journal of Environmental Psychology, 23</em>: 109-123.</small></p>\n<p><span style=\"font-size: 11px;\">Helliwell (2011). <a href=\"http://www.csls.ca/events/2011/helliwell.pdf\">How can subjective well-being be improved?</a></span></p>\n<p><small>Heln &amp; Singer (2008). I feel how you feel but not always: the empathic brain and its modulation. <em>Current Opinion in Neurobiology, 18(2)</em>: 153-158.</small></p>\n<p><small>Hsee &amp; Hastie (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Hsee-Hastie-Decision-and-experience-why-dont-we-choose-what-makes-us-happy.pdf\">Decision and experience: Why don't we choose what makes us happy?</a> <em>Trends in Cognitive Sciences, 10(1)</em>: 31-37.</small></p>\n<p><small>Inglehart (1990).&nbsp;<em style=\"font-style: italic;\">Culture shift in advanced industrial society</em>. Princeton, NJ: Princeton University Press.</small></p>\n<p><small>Isen (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Isen-A-role-for-neuropsychology-in-understanding-the-facilitating-influence-of-positive-affect.pdf\">A role for neuropsychology in understanding the facilitating influence of positive affect on social behavior and cognitive processes</a>. In Snyder &amp; Lopez (Eds.), <em>Handbook of positive psychology</em>&nbsp;(pp. 528-540). New York: Oxford University Press.</small></p>\n<p><small>Isen (2004). Some perspectives on positive feelings and emotions: Positive affect facilitates thinking and problem solving. In Manstead, Frijda, &amp; Fischer (Eds.), <em>Feelings and emotions: The Amsterdam symposium</em>&nbsp;(pp. 263-281). New York: Cambridge University Press.</small></p>\n<p><small>Isen, Daubman, &amp; Nowicki (1987). Positive affect facilitates creative problemsolving. <em>Journal of Personality and Social Psychology, 52</em>: 1122&ndash;1131.</small></p>\n<p><small>Jacobson, Schmaling, &amp; Holtzworth-Monroe (1987). Component analysis of behavioral marital therapy: 2-year follow-up and prediction of relapse. <em>Journal of Marital and Family Therapy, 13</em>: 187-195.</small></p>\n<p><small>Johnson &amp; Krueger (2006). \"How money buys happiness: Genetic and environmental processes linking finances and life satisfaction.\"&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 90: 680-691.</small></p>\n<p><small>Judge &amp; Klinger (2008). Job satisfaction: Subjective well-being at work. In Eid &amp; Larsen (Eds.),&nbsp;<em style=\"font-style: italic;\">The science of subjective well-being</em>&nbsp;(pp. 393-413). New York: Guilford.</small></p>\n<p><small>Kabat-Zinn (1982). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kabat-Zinn-An-outpatient-program-in-behavioral-medicine-for-chronic-pain-patients-based-on-the-practice-of-mindfulness-meditation.pdf\">An outpatient program in behavioral medicine for chronic pain patients based on the practice of mindfulness meditation: Theoretical considerations and preliminary results</a>. <em>General Hospital Psychiatry, 4</em>: 33-47.</small></p>\n<p><small>Kahneman, Krueger, Schkade, Schwarz, &amp; Stone (2006). \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Kahneman-Would-you-be-happier-if-you-were-richer-A-focusing-illusion.pdf\">Would you be happier if you were richer? A focusing illusion</a>.\"<em style=\"font-style: italic;\">Science</em>, 312: 1908-1910.</small></p>\n<p><small>Kaplan (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kaplan-The-role-of-nature-in-the-context-of-the-workplace.pdf\">The role of nature in the context of the workplace</a>. <em>Landscaping and Urban Planning, 26</em>: 193-201.</small></p>\n<p><small>Kaplan (2001). The nature of the view from home: Psychological benefits. <em>Environment and Behavior, 33(4)</em>: 507-542.</small></p>\n<p><small>Kasser (2002).&nbsp;<em style=\"font-style: italic;\">The high prices of materialism</em>. Cambridge, MA: MIT Press.</small></p>\n<p><small>Kasser, Ryan, Couchman, &amp; Sheldon (2004). Materialistic values: Their causes and consequences. In Kasser &amp; Kanner (Eds.),&nbsp;<em style=\"font-style: italic;\">Psychology and consumer culture: The struggle for a good life in a materialistic world</em>. Washington DC: American Psychological Association.</small></p>\n<p><small>Langer &amp; Rodin (1976).&nbsp;The effects of choice and enhanced personal responsibility for the aged: A field experiment in an institutional setting.&nbsp;<em>Journal of Personality and Social Psychology, Vol 34(2)</em>: 191-198.</small></p>\n<p><small>Lee, Cohen, Edgar, Laizner, &amp; Gagnon (2006). Meaning-making intervention during breast or colorectal cancer treatment improves self-esteem, optimism, and self-efficacy. <em>Social Science &amp; Medicine, 62(12)</em>: 3133-3145.</small></p>\n<p><small>Lepore &amp; Smyth, eds. (2002).&nbsp;<em>The writing cure: How expressive writing promotes health and emotional well-being</em>. Washington, DC: American Psychological Association.</small></p>\n<p><small>Lindsley, Brass, &amp; Thomas (1995).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Lindsley-Efficacy-performance-spirals-A-multilevel-perspective.pdf\">Efficacy-performance spirals: A multilevel perspective</a>.&nbsp;<em style=\"font-style: italic;\">Academy of Management Review, 20(3)</em>: 645-678.</small></p>\n<p><small>Lucas (2008). Personality and subjective well-being. In Eid &amp; Larsen (Eds.), <em>The science of subjective well-being</em>&nbsp;(pp. 171-194). New York: Guilford.</small></p>\n<p><small>Lucas &amp; Diener (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lucas-Diener-Personality-and-subjective-well-being.pdf\">Personality and subjective well-being</a>. In John, Robins, &amp; Pervin (Eds.), <em>Handbook of personality: Theory and research, 3rd ed.</em>&nbsp;(pp. 795-814). New York: Guilford.</small></p>\n<p><small>Lyubomirsky, Sheldon, &amp; Schkade (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Lyubomirsky-Pursuing-happiness-The-architecture-of-sustainable-change.pdf\">Pursuing happiness: The architecture of sustainable change</a>.&nbsp;<em style=\"font-style: italic;\">Review of General Psychology</em>, 9(2), 111-131.</small></p>\n<p><small>Lyubomirsky, Tkach, &amp; DiMatteo (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lyubomirsky-What-are-the-differences-between-happiness-and-self-esteem.pdf\">What are the differences between happiness and self-esteem?</a> <em>Social Indicators Research, 78</em>: 363-404.</small></p>\n<p><small>Lyubomirsky, King, &amp; Diener (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lyubomirsky-The-benefits-of-frequent-positive-affect.pdf\">The benefits of frequent positive affect: Does happiness lead to success?</a> <em>Psychological Bulletin, 131</em>: 803-855.</small></p>\n<p><small>Lykken &amp; Tellegen (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Lykken-Happiness-Is-a-Stochastic-Phenomenon.pdf\">Happiness is a stochastic phenomenon</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 7: 186-189.</small></p>\n<p><small>Lykken (1999).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/dp/0312263333/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Happiness: The nature and nurture of joy and contentment</a></em>. New York: St. Martin's.</small></p>\n<p><small>McNeil &amp; Fleeson (2006). The causal effect of extraversion on positive affect and neuroticism on negative affect: Manipulating state extraversion and state neuroticism in an experimental approach. <em>Journal of Research in Personality, 40</em>: 529-550.</small></p>\n<p><small>Morris (1999). The mood system. In Kahneman, Diener, &amp; Schwatrz (Eds.), <em>Well-being: The foundations of hedonic psychology</em>&nbsp;(pp. 169-189). New York: Russell Sage Foundation.</small></p>\n<p><small>Murray &amp; Holmes (1999). The (mental) ties that bind: Cognitive structures that predict relationship resilience. <em>Journal of Personality and Social Psychology, 77</em>: 1228-1244.</small></p>\n<p><small>Myers (1992).&nbsp;<em style=\"font-style: italic;\">The pursuit of happiness: Who is happy, and why</em>. New York: Morrow.</small></p>\n<p><small>Myers (1999). Close relationships and quality of life. In Kahnemann, Diener, &amp; Schwarz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Myers &amp; Diener (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Myers-who-is-happy.pdf\">Who is happy?</a>&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 6: 10-19.</small></p>\n<p><small>Myers &amp; Diener (1997). The pursuit of happiness.&nbsp;<em style=\"font-style: italic;\">Scientific American, Special Issue 7</em>: 40-43.</small></p>\n<p><small>Nakamura &amp; Csikszentmihalyi (2009). Flow theory and research. In Lopez &amp; Snyder (Eds.), <em>Oxford handbook of positive psychology</em>&nbsp;(2nd ed., pp. 195-206). New York: Oxford.</small></p>\n<p><small>Nickerson, Schwartz, Diener, &amp; Kahnemann (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Nickerson-Zeroing-in-on-the-dark-side-of-the-american-dream.pdf\">Zeroing in on the dark side of the American dream: A closer look at the negative consequences of the goal for financial success</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 14(6): 531-536.</small></p>\n<p><small>Park &amp; Folkman (1997). Meaning in the context of stress and coping. <em>Review of General Psychology, 1</em>: 115-144.</small></p>\n<p><small>Peterson (2006).<em>&nbsp;<a href=\"http://www.amazon.com/Primer-Positive-Psychology-Christopher-Peterson/dp/0195188330/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">A primer on positive psychology</a></em>. New York: Oxford University Press.</small></p>\n<p><small>Peterson &amp; Seligman (2004). <em><a href=\"http://www.amazon.com/Character-Strengths-Virtues-Handbook-Classification/dp/0195167015/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Character strengths and virtues: A Handbook of classification</a></em>. New York: Oxford University Press.</small></p>\n<p><small>Price (2008). Research roundup: Get out of town. <em>gradPSYCH, 6(3)</em>: 10.</small></p>\n<p><small>Pronin &amp; Jacobs (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pronin-Jacobs-Thought-speed-mood-and-the-experience-of-mental-motion.pdf\">Thought speed, mood, and the experience of mental motion</a>. <em>Perspectives on Psychological Science, 3</em>: 461-485.</small></p>\n<p><small>Proulx, Helms, &amp; Cheryl (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Proulx-Marital-Quality-and-Personal-Well\u2010Being-A-Meta\u2010Analysis.pdf\">Marital quality and personal well-being: A meta-analysis</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Marriage and Family</em>, 69: 576-593.</small></p>\n<p><small>Reker, Peacock, &amp; Wong (1987). Meaning and purpose in life and well-being: a life-span perspective. <em>The Journal of Gerontology, 42(1)</em>: 44-49.</small></p>\n<p><small>Riis, Loewenstein, Baron, Jepson, Fagerlin, &amp; Ubel (2005). Ignorance of hedonic adaptation to hemodialysis: A study using ecological momentary assessment.&nbsp;<em style=\"font-style: italic;\">Journal of Experimental Psychology: General</em>, 134: 3-9.</small></p>\n<p><small>Roberts, Jackson, Fayard, Edmonds, &amp; Meints (2009). Conscientiousness. In Leary &amp; Hoyle (Eds.), <em>Handbook of individual differences in social behavior</em>&nbsp;(pp. 369-381). New York: Guilford.</small></p>\n<p><small>Ross &amp; Van Willigen (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Ross-Education-and-the-subjective-quality-of-life.pdf\">Education and the subjective quality of life</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Health &amp; Social Behavior</em>, 38: 275-297.</small></p>\n<p><small>Schwartz &amp; Strack (1999). Reports of subjective well-being: Judgmental processes and their methodological implications. In Kahneman, Diener, &amp; Schwartz (Eds.), <em>Well-being: The foundations of hedonic psychology</em>. New York: Russell Sage Foundation.</small></p>\n<p><small>Seery, Silver, Holman, Ence, &amp; Chu (2008). Expressing thoughts and feelings following a collective trauma: Immediate responses to 9/11 predict negative outcomes in a national sample. <em>Journal of Consulting and Clinical Psychology, 76(4)</em>: 657-667.</small></p>\n<p><small>Shapiro, Schwartz, &amp; Bonner (1998). The effects of mindfulness-based stress reduction on medical and pre-medical students. <em>Journal of Behavioral Medicine, 21</em>: 581-599.</small></p>\n<p><small>Solberg, Diener, Wirtz, Lucas, &amp; Oishi (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Solberg-Wanting-Having-and-Satisfaction-Examining-the-Role-of-Desire-Discrepancies-in-Satisfaction-With-Income.pdf\">Wanting, having, and satisfaction: Examining the role of desire discrepancies in satisfaction with income</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 83(3): 725-734.</small></p>\n<p><small>Spera, Buhrfeind, &amp; Pennebaker (1994). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Spera-Expressive-writing-and-coping-with-job-loss.pdf\">Expressive writing and coping with job loss</a>. <em>Academy of Management Journal, 3</em>: 72-733.</small></p>\n<p><small>Stepien &amp; Baernstein (2006). Educating for empaty: a review. <em>Journal of General Internal Medicine, 21(5)</em>: 524-530.</small></p>\n<p><small>Steptoe, Wardle, &amp; Marmot (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Steptoe-Positive-affect-and-health-related-neuroendocrine-cardiovascular-and-inflammatory-processes.pdf\">Positive affect and health-related neuroendocrine, cardiovascular, and inflammatory processes</a>. <em>Proceedings of the National Academy of Sciences of the United States of America, 102(18)</em>: 6508-6512.</small></p>\n<p><small>Stubbe, Posthuma, Boomsa, &amp; De Geus (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Stubbe-Heritability-of-life-satisfaction-in-adults-A-twin-family-study.pdf\">Heritability and life satisfaction in adults: A twin-family study</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Medicine</em>, 35: 1581-1588.</small></p>\n<p><small>Tennessen &amp; Cimprich (1995). Views to nature: Effects on attention. <em>Journal of Environmental Psychology, 15</em>: 77-85.</small></p>\n<p><small>Ulmer, Range, &amp; Smith (1991). Purpose in life: a moderator of recovery from bereavement. <em>Journal of Death and Dying, 23(4)</em>: 279-289.</small></p>\n<p><small>Van Boven (2005). Experientialism, materialism, and the pursuit of happiness.&nbsp;<em style=\"font-style: italic;\">Review of General Psychology</em>, 9(2): 132-142.</small></p>\n<p><small>de Vignemont &amp; Singer (2006). The empathic brain: how, when, and why? <em>Trends in Cognitive Sciences, 10(10)</em>: 435-441.</small></p>\n<p><small>Warr (1999). Well-being and the workplace. In Kahneman, Diener, &amp; Schwartz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Wegner (1989).&nbsp;<em><a href=\"http://www.amazon.com/White-Bears-Other-Unwanted-Thoughts/dp/0898622239/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">White bears and other unwanted thoughts: Suppression, obsession, and the psychology of mental control</a></em>. New York: Viking.</small></p>\n<p><small>Weiss, Bates, &amp; Luciano (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Weiss-Happiness-is-a-personality-thing.pdf\">Happiness is a personal(ity) thing</a>. <em>Psychology Science, 19</em>: 205-210.</small></p>\n<p><small>Wilson &amp; Gilbert (2005). Affective forecasting: Knowing what to want. <em>Current Directions in Psychological Science, 14</em>: 131-134.</small></p>\n<p><small>Wissink, Dekovic, &amp; Meijer (2006). Parenting behavior, quality of the parent-adolescent relationship, and adolescent functioning in four ethnic groups. <em>Journal of Early Adolescence, 26</em>: 133-159.</small></p>\n<p><small>Zech &amp; Rim&eacute; (2005). Is talking about an emotional experience helpful? Effects on emotional recovery and perceived benefits. <em>Clinical Psychology and Psychotehrapy, 12</em>: 270-287.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XqykXFKL9t38pbSEm": 2, "fkABsGCJZ6y9qConW": 11, "a65Lgr7Q5jqRWHtM6": 4, "Jzm2mYuuDBCNWq8hi": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZbgCx2ntD5eu8Cno9", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 191, "baseScore": 207, "extendedScore": null, "score": 0.000376, "legacy": true, "legacyId": "6222", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 207, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><span style=\"font-size: 11px;\">Part of the sequence:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></span></p>\n<p>One day a coworker said to me, \"Luke! You're, like, the happiest person I know!&nbsp;How come you're so happy all the time?\"</p>\n<p>It was probably a rhetorical question, but I had a very long answer to give. See, I was&nbsp;<em>un</em>happy for most of my life,<sup>1</sup>&nbsp;and even considered suicide a few times. Then I spent two years studying the science of happiness. Now, happiness is my natural state. I can't remember the last time I felt unhappy for longer than 20 minutes.</p>\n<p>That kind of change won't happen for everyone, or even most people (<a href=\"/lw/9v/beware_of_otheroptimizing/\">beware of other-optimizing</a>), but it's worth a shot!&nbsp;</p>\n<p>We all want to be happy, and happiness is useful for other things, too.<sup>2</sup> For example, happiness improves physical health,<sup>3</sup>&nbsp;improves creativity,<sup>4</sup>&nbsp;and even enables you to make better decisions.<sup>5</sup>&nbsp;(It's harder to be rational when you're unhappy.<sup>6</sup>) So, as part of a series on how to <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">win</a> <a href=\"/lw/3w3/how_to_beat_procrastination/\">at</a> <a href=\"/lw/1sm/akrasia_tactics_review/\">life</a> with science and rationality, let's review&nbsp;<strong>the science of happiness</strong>.</p>\n<p>&nbsp;</p>\n<h4 id=\"The_correlates_of_happiness\">The correlates of happiness</h4>\n<p><a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">Earlier</a>, I noted that&nbsp;there is an abundance of research on factors that correlate with&nbsp;<em style=\"font-style: italic;\">subjective well-being</em>&nbsp;(individuals' own assessments of their happiness and life satisfaction).</p>\n<p>Factors that&nbsp;<em style=\"font-style: italic;\">don't correlate</em>&nbsp;much with happiness include: age,<span style=\"font-size: 11px;\"><sup>7</sup></span>&nbsp;gender,<sup>8</sup>&nbsp;parenthood,<sup>9</sup>&nbsp;intelligence,<sup>10</sup>&nbsp;physical attractiveness,<sup>11</sup>&nbsp;and money<sup>12</sup>&nbsp;(as long as you're above the poverty line). Factors that&nbsp;<em style=\"font-style: italic;\">correlate moderately</em>&nbsp;with happiness include: health,<span style=\"font-size: 11px;\"><sup>13</sup></span>&nbsp;social activity,<sup>14</sup>&nbsp;and religiosity.<sup>15</sup>&nbsp;Factors that&nbsp;<em style=\"font-style: italic;\">correlate strongly</em>&nbsp;with happiness include: genetics,<sup>16</sup>&nbsp;love and relationship satisfaction,<sup>17&nbsp;</sup>and work satisfaction.<sup>18</sup></p>\n<p>But correlation is not enough. We want to know what <em>causes</em>&nbsp;happiness. And that is a trickier thing to measure. But we do know a <em>few</em> things.</p>\n<p>&nbsp;</p>\n<h4 id=\"Happiness__personality__and_skills\">Happiness, personality, and skills</h4>\n<p>Genes account for about 50% of the variance in happiness.<sup>19</sup> Even lottery winners and newly-made quadriplegics do not see as much of a change in happiness as you would expect.<span style=\"font-size: 11px;\"><sup>20</sup></span>&nbsp;Presumably, genes shape your happiness by shaping your personality, which is known to be quite heritable.<sup>21</sup></p>\n<p>So which personality traits tend to correlate most with happiness? Extroversion is among the best predictors of happiness,<sup>22</sup> as are conscientiousness, agreeableness, self-esteem, and optimism.<sup>23</sup></p>\n<p>What if you don't have those traits? The first thing to say is that you might be capable of them without knowing it. Introversion, for example, can be exacerbated by <em>a lack of social skills</em>. If you decide to <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">learn</a> and <a href=\"http://reports.toastmasters.org/findaclub/\">practice</a> social skills, you might find that you are more extroverted than you thought! (That's what happened to me.) The same goes for <a href=\"http://www.amazon.com/dp/055380491X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">conscientiousness</a>, <a href=\"http://www.amazon.com/dp/1439167346/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">agreeableness</a>, <a href=\"http://www.psychologicalselfhelp.org/Chapter14/chap14_5.html\">self-esteem</a>, and <a href=\"/lw/3w3/how_to_beat_procrastination/#optimism\">optimism</a> - these are only partly linked to personality. They are to some extent learnable skills, and learning these skills (or even \"acting as if\") can increase happiness.<sup>24</sup></p>\n<p>The second thing to say is that lacking some of these traits does not, of course, doom you to unhappiness.</p>\n<p><a id=\"more\"></a></p>\n<h3><br></h3>\n<h3 id=\"Happiness_is_subjective_and_relative\">Happiness is subjective and relative</h3>\n<p>Happiness is not determined by objective factors, but by how you <em>feel</em>&nbsp;about them.<sup>25</sup></p>\n<p>Happiness is also relative<sup>26</sup>: you'll probably be happier making $25,000/yr in Costa Rica (where your neighbors are making $13,000/yr) than you will be making $80,000/yr in Beverly Hills (where your neighbors are making $130,000/yr).</p>\n<p>Happiness is relative in another sense, too: it is relative to your <em>expectations</em>.<sup>27</sup> We are quite poor at predicting the strength of our emotional reactions to future events. We overestimate the misery we will experience after a romantic breakup, failure to get a promotion, or even contracting an illness.&nbsp;We also overestimate the <em>pleasure</em> we will get from buying a nice car, getting a promotion, or moving to a lovely coastal city. So: lower your expectations about the pleasure you'll get from such expenditures.</p>\n<p>&nbsp;</p>\n<h3 id=\"Flow_and_mindfulness\">Flow and mindfulness</h3>\n<p>You may have heard of the famous studies<sup>28</sup> showing that people are happiest when they are in a state of \"<a href=\"http://en.wikipedia.org/wiki/Flow_(psychology)\">flow</a>.\" Flow is the state you're in when you are fully engaged in a task that is interesting, challenging, and intrinsically rewarding to you. This is the experience of \"losing yourself in the moment\" or, as sports players say, \"being in the zone.\"</p>\n<p>Finding flow has largely to do with performing tasks that match your skill level. When a task is far beyond your skill level, you will feel defeated. When a task is too easy, you'll be bored. Only when a task is challenging but achievable will you feel good about doing it. I'm reminded of&nbsp;the state troopers in&nbsp;<em><a href=\"http://www.youtube.com/watch?v=2-9D2qUHN-E\">Super Troopers</a></em>, who devised strange games and challenges to make their boring jobs passable. <a href=\"http://www.youtube.com/watch?v=EY3Lw_-bj5U\">Myrtle Young</a> made her boring job at a potato chip factory more interesting and challenging by looking for potato chips that resembled celebrities, and pulling them off the conveyor belts for her collection.</p>\n<p>If you're struggling with negative thoughts, achieving flow is probably the best medicine. Contrary to popular wisdom, forced positive thinking often makes things worse.<sup>29</sup> Trying to <em>not </em>think about&nbsp;Upsetting Thought X has the same effect as trying to not think about pink elephants: you can't help but think about pink elephants.</p>\n<p>While being \"lost in the moment\" may provide some of your happiest moments, research has also shown that when you're not&nbsp;in flow,&nbsp;taking a step outside the moment and practicing \"mindfulness\" - that is, paying attention to your situation, your actions, and your feelings - can reduce chronic pain and depression<sup>30</sup>, reduce stress and anxiety<sup>31</sup>, and produce a wide range of other positive effects.<sup>32</sup>&nbsp;</p>\n<p>&nbsp;</p>\n<h3 id=\"How_to_be_happier\">How to be happier</h3>\n<p>Happiness, then, is an enormously complex thing. Worse, we must remember the difference between <a href=\"http://www.ted.com/talks/daniel_kahneman_the_riddle_of_experience_vs_memory.html\">experienced happiness and remembered happiness</a>. I can only scratch the surface of happiness research in this tiny post. In short, there is no simple fix for unhappiness; no straight path to bliss.</p>\n<p>Moreover, happiness will be achieved differently for different people. A person suffering from depression due to chemical imbalance may get more help from a pill than from learning better social skills. A healthy, extroverted, agreeable, conscientious woman can still be unhappy if she is trapped in a bad marriage. Some people were raised by parents whose parenting style did not encourage the development of healthy self-esteem,<sup>33</sup> and they will need to devote significant energy to overcome this deficit. For some, the road to happiness is long. For others, it is short.</p>\n<p>Below, I review a variety of methods for becoming happier. Some of them I discussed above; many, I did not.</p>\n<p>These methods are ranked roughly in descending order of importance and effect, based on my own reading of the literature. You will need to think about who you are, what makes you happy, what makes you unhappy, and what you can achieve in order to determine which of the below methods should be attempted first. Also, engaging any of these methods may require that you first gain some <a href=\"/lw/3w3/how_to_beat_procrastination/\">mastery over procrastination</a>.</p>\n<p>Here, then, are some methods for becoming happier<sup>34</sup>:</p>\n<ol>\n<li>If you suffer from serious illness, depression, anxiety, paranoia, schizophrenia, or other serious problems, <em>seek professional help first</em>. <a href=\"http://www.liveyourlifewell.org/go/live-your-life-well/help\">Here's how</a>.</li>\n<li>Even if you don't need professional help, you may benefit from some self-exploration and <em>initial guidance</em> from a reductionistic, naturalistic counselor like <a href=\"http://naturalism.org/consulting.htm\">Tom Clark</a>.</li>\n<li>Develop the skills and habits associated with <em>extroversion</em>. First, get some decent clothes and learn how to wear them properly. If you're a guy, <a href=\"http://www.amazon.com/Details-Mens-Style-Manual-Ultimate/dp/159240328X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">read</a> <a href=\"http://www.bradp.com/brads-fashion-bible\">these</a> <a href=\"http://www.amazon.com/Mens-Style-Thinking-Guide-Dress/dp/0312361653/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">books</a>. If you're a girl, ask your girlfriends or try <a href=\"http://www.amazon.com/What-Not-Wear-Trinny-Woodall/dp/B0042P5752/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">these</a> <a href=\"http://www.amazon.com/Dress-Your-Best-Complete-Finding/dp/0307236714/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">books</a>. Next, learn basic&nbsp;<a href=\"http://www.amazon.com/How-Talk-Anyone-Success-Relationships/dp/007141858X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">social</a> <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">skills</a>, including <a href=\"http://www.amazon.com/Winning-Body-Language-Conversation-Attention/dp/0071700579/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">body</a> <a href=\"http://www.amazon.com/Definitive-Book-Body-Language/dp/0553804723/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">language</a>.&nbsp;If you're <em>really</em>&nbsp;introverted, practice on <a href=\"http://en.wikipedia.org/wiki/Chatroulette\">Chatroulette</a>&nbsp;or <a href=\"http://www.omegle.com/\">Omegle</a> first. Next, spend more time with other people, making small talk. Go to <a href=\"http://www.meetup.com/\">meetups</a> and <a href=\"http://www.couchsurfing.org/\">CouchSurfing</a> group activities. Practice your skills until they become more natural, and you find yourself <em>enjoying</em>&nbsp;being in the company of others. Learn <a href=\"http://www.amazon.com/Comic-Toolbox-Funny-Even-Youre/dp/1879505215/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">how</a> to <a href=\"http://www.amazon.com/Finding-Funny-Fast-Connect-Coworkers/dp/0984099905/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">be</a> <a href=\"http://www.amazon.com/How-Be-Funny-Discovering-Comic/dp/1573922064/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">funny</a> and practice that, too.</li>\n<li>Improve your <em>self-esteem</em>&nbsp;and <em>optimism</em>. This is tricky. First, too much self-esteem can lead to harmful&nbsp;narcissism.<sup>35</sup> Second, it's not clear that a rationalist can endorse several standard methods for improving one's self esteem (self-serving bias, basking in reflected glory, self-handicapping)<sup>36</sup> because they toy with self-deception and <a href=\"http://wiki.lesswrong.com/wiki/Anti-epistemology\">anti-epistemology</a>. But there are a few safe ways to increase your self-esteem and optimism. Make use of success spirals, vicarious victory, and mental contrasting, as described <a href=\"/lw/3w3/how_to_beat_procrastination/#optimism\">here</a>.</li>\n<li>Improve your <em>agreeableness</em>. In simpler terms, this basically means: increase your empathy. Unfortunately, little is currently known (scientifically) about how to increase one's empathy.<sup>37</sup> The usual advice about trying to see things from another's perspective, and thinking more about people less fortunate than oneself, will have to do for now. The organization <a href=\"http://www.rootsofempathy.org/\">Roots of Empathy</a> may have some good <a href=\"http://opinionator.blogs.nytimes.com/2010/11/08/fighting-bullying-with-babies/\">advice</a>, too.</li>\n<li>Improve your <em>conscientiousness</em>. Conscientiousness involves a variety of tendencies: useful organization, strong work ethic, reliability, planning ahead, etc. Each of these individual skills can be learned. The techniques for <a href=\"/lw/3w3/how_to_beat_procrastination/\">overcoming procrastination</a> are useful, here. Some people report that books like <em><a href=\"http://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0142000280/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Getting Things Done</a></em>&nbsp;have helped them become more organized and reliable.</li>\n<li>Develop the <em>habit of gratitude</em>. Savor the good moments throughout each day.<sup>38</sup>&nbsp;Spend time thinking about happy memories.<sup>39</sup> And at the end of each day, write down 5 things you are grateful for: the roof over your head, your good fortune at being born in a wealthy country, the existence of <em>Less Wrong</em>, the taste of chocolate, the feel of orgasm... whatever. It sounds childish, but it works.<sup>40</sup></li>\n<li>Find your <em>purpose</em> and live it. One benefit of religion may be that it gives people a sense of meaning and purpose. Without a magical deity to give you purpose, though, you'll have to find out for yourself what drives you. It may take a while to find it though, and you may have to dip your hands and mind into many fields. But once you find a path that strongly motivates you and fulfills you, take it. (Of course, you might not find one purpose but many.) Having a strong sense of meaning and purpose has a wide range of positive effects.<sup>41</sup> The 'find a purpose' recommendation also offers an illustration of how methods may differ in importance for people. 'Find a purpose' is not always emphasized in happiness literature, but for my own brain chemistry I suspect that finding motivating purposes has made more difference in my life than anything else on this list.</li>\n<li>Find a more <em>fulfilling job</em>. Few people do what they love for a living. Getting to that point can be difficult and complicated. You may find that doing 10 other things on this list <em>first</em>&nbsp;is needed for you to have a good chance at getting a more fulfilling job.&nbsp;To figure out which career might be full of tasks that you love to do, a <a href=\"http://www.bigjobportal.com/riasec/\">RIASEC</a> personality test might help. In the USA, <a href=\"http://www.onetonline.org/\">O*NET</a> can help you find jobs that are in-demand and fit your personality.</li>\n<li>Improve your relationship with your <em>romantic partner</em>, or find a different one. As with finding a more fulfilling job, this one is complicated, but can have major impact. If you know your relationship isn't going anywhere, you may want to drop it so you can spend more time developing yourself, which will improve future relationships. If you're pretty serious about your partner, there are many things you can do to improve the relationship. Despite being touted widely, \"active listening\" doesn't predict relationship success.<sup>42</sup>&nbsp;Tested advice for improving the chances of relationship success and satisfaction include: (1) do novel and exciting things with your partner often<sup>43</sup>, (2) say positive things to and about your partner at least 5 times more often than you say negative things<sup>44</sup>, (3) spend each week writing about why your relationship is better than some others you know about<sup>45</sup>, (4) qualify every criticism of your partner with a review of one or two of their positive qualities<sup>46</sup>, and (5) stare into each other's eyes more often.<sup>47</sup></li>\n<li><em>Go outside</em> and move your body. This will improve your attention and well-being.<sup>48</sup></li>\n<li>Spend more time in <em>flow</em>. Drop impossible tasks in favor of tasks that are at the outer limits of your skillset. Make easy and boring tasks more engaging by turning them into games or adding challenges for yourself.</li>\n<li><em>Practice mindfulness</em> regularly. When not in flow, step outside yourself and pay attention to how you are behaving, how your emotions are functioning, and how your current actions work toward your goals. <a href=\"http://www.wikihow.com/Meditate\">Meditation</a> may help.</li>\n<li><em>Avoid consumerism</em>. The things you own <em>do</em> come to own you, in a sense. Consumerism leads to unhappiness.<sup>49</sup>&nbsp;Unfortunately, you've probably been programmed from birth to see through the lens of consumerism. One way to start deprogramming is by watching <a href=\"http://en.wikipedia.org/wiki/The_Century_of_the_Self\">this documentary</a> about the deliberate invention of consumerism by <a href=\"http://en.wikipedia.org/wiki/Edward_Bernays\">Edward Bernays</a>. After that, you may want to sell or give away many of your possessions and, more importantly, drastically change your purchasing patterns.</li>\n</ol>\n<p>Note that seeking happiness <em>as an end</em>&nbsp;might be counterproductive. Many people report that constantly checking to see if they are happy actually decreases their happiness - a report that fits with the research on \"flow.\" It may be better to seek some of the above goals as ends, and happiness will be a side-effect.</p>\n<p>Remember: Happiness will not come from reading articles on the internet. Happiness will come when you <em>do</em>&nbsp;the things research recommends.</p>\n<p>Good luck!</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">The Good News of Situationist Psychology</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> From a young age through my teenage years, I was known as the pessimist in my family. Of course, I would retort I was merely a <em>realist</em>. Making happiness work within me made me an optimist. These days I'm pessimistic about many things: For example I think there's about a 50/50 chance the human species will survive this century. But it's a kind of rationalistic, emotionally detached pessimism. It doesn't affect my mood.</small></p>\n<p><small><sup>2</sup>&nbsp;Lyubomirsky, King, &amp; Diener (2005).</small></p>\n<p><small><sup>3</sup>&nbsp;Steptoe et al. (2005).</small></p>\n<p><small><sup>4</sup>&nbsp;Isen et al. (1987); Isen (2004); Fredrickson (1998).</small></p>\n<p><small><sup>5</sup>&nbsp;Isen (2002); Morris (1999).</small></p>\n<p><small><sup>6</sup>&nbsp;Beck (2008); Ellis (2001).</small></p>\n<p><small><sup>7</sup>&nbsp;Age and happiness are unrelated (Lykken 1999), age accounting for less than 1% of the variation in people's happiness (Inglehart 1990; Myers &amp; Diener 1997).</small></p>\n<p><small><sup>8</sup>&nbsp;Despite being treated for depressive disorders twice as often as men (Nolen-Hoeksema 2002), women report just as high levels of well-being as men do (Myers 1992).</small></p>\n<p><small><sup>9</sup>&nbsp;Apparently, the joys and stresses of parenthood balance each other out, as people with and without children are equally happy (Argyle 2001).</small></p>\n<p><small><sup>10</sup>&nbsp;Both IQ and educational attainment appear to be unrelated to happiness (Diener et al. 2009; Ross &amp; Van Willigen 1997).</small></p>\n<p><small><sup>11</sup>&nbsp;Good-looking people enjoy huge advantages, but do not report greater happiness than others (Diener et al. 1995).</small></p>\n<p><small><sup>12</sup>&nbsp;The correlation between income and happiness is surprisingly weak (Diener &amp; Seligman 2004; Diener et al. 1993; Johnson &amp; Krueger 2006). One problem may be that higher income contributes to greater materialism, which impedes happiness (Frey &amp; Stutzer 2002; Kasser et al. 2004; Solberg et al. 2002; Kasser 2002; Van Boven 2005; Nickerson et al. 2003; Kahneman et al. 2006).</small></p>\n<p><small><sup>13</sup>&nbsp;Those with disabling health conditions are happier than you might think (Myers 1992; Riis et al. 2005; Argyle 1999).</small></p>\n<p><small><sup>14</sup>&nbsp;Those who are satisfied with their social life are moderately more happy than others (Diener &amp; Seligman 2004; Myers 1999; Diener &amp; Seligman 2002).</small></p>\n<p><small><sup>15</sup>&nbsp;Religiosity correlates with happiness (Abdel-Kahlek 2005; Myers 2008), though it may be religious attendance and not religious belief that matters (Chida et al. 2009).</small></p>\n<p><small><sup>16</sup>&nbsp;Past happiness is the best predictor of future happiness (Lucas &amp; Diener 2008). Happiness is surprisingly unmoved by external factors (Lykken &amp; Tellegen 1996), because genes accounts for about 50% of the variance in happiness (Lyubomirsky et al. 2005; Stubbe et al. 2005).</small></p>\n<p><small><sup>17</sup>&nbsp;Married people are happier than those who are single or divorced (Myers &amp; Diener 1995; Diener et al. 2000), and marital satisfaction predicts happiness (Proulx et al. 2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Unemployment makes people very unhappy (Argyle 2001), and job satisfaction is strongly correlated with happiness (Judge &amp; Klinger 2008; Warr 1999).</small></p>\n<p><small><sup>19</sup>&nbsp;Lyubomirsky et al. (2005); Stubbe et al. (2005).</small></p>\n<p><small><sup>20</sup>&nbsp;Brickman et al. (1978).</small></p>\n<p><small><sup>21</sup>&nbsp;Weiss et al. (2008).</small></p>\n<p><small><sup>22</sup>&nbsp;Lucas &amp; Diener (2008); Fleeson et al. (2002).</small></p>\n<p><small><sup>23</sup>&nbsp;Lucas (2008) and Lyubomirsky et al. (2006).</small></p>\n<p><small><sup>24</sup>&nbsp;On the learnability of extroversion, see&nbsp;Fleeson et al. (2002); Bouchard &amp; Loehlin (2001); McNeil &amp; Fleeson (2006). On the learnability of agreeableness, see Graziano &amp; Tobin (2009). On the learnability of conscientiousness, see Roberts et al. (2009). On the learnability of self-esteem, see Barrett et al. (1999); Borras et al. (2009). On the learnability of optimism, see Lindsley et al. (1995); Hans (2000); Feldman &amp; Matjasko (2005). On the learnability of character traits in general, see Peterson &amp; Seligman (2004).</small></p>\n<p><small><sup>25</sup>&nbsp;Schwarz &amp; Strack (1999).</small></p>\n<p><small><sup>26</sup>&nbsp;Argyle (1999); Hagerty (2000).</small></p>\n<p><small><sup>27</sup> Gilbert (2006), Hsee &amp; Hastie (2005), Wilson &amp; Gilbert (2005).</small></p>\n<p><small><sup>28</sup> Csikszentmihalyi (1990, 1998); Gardner, Csikszentmihalyi &amp; Damon (2002); Nakamura &amp; Csikszentmihalyi (2009).</small></p>\n<p><small><sup>29</sup> Wegner (1989).</small></p>\n<p><small><sup>30</sup> Kabat-Zinn (1982).</small></p>\n<p><small><sup>31</sup> Shapiro et al. (1998); Chang et al. (2004).</small></p>\n<p><small><sup>32</sup> Grossman et al. (2004).</small></p>\n<p><small><sup>33</sup>&nbsp;Felson (1989); Harter (1998); Furnham &amp; Cheng (2000); Wissink et al. (2006).</small></p>\n<p><small><sup>34</sup>&nbsp;There are several disputed and uncertain methods I did not mention. One example is \"expressive writing.\" Compare&nbsp;Lepore &amp; Smyth (2002) and Spera et al. (1994) to&nbsp;Seery et al. (2008). Moreover, talking with a others about bad experiences may help, but maybe not: see&nbsp;Zech &amp; Rim\u00e9 (2005). Another disputed method is that of improving mood by thinking quicker and more varied thoughts: see Pronin &amp; Jacobs (2008). I'm waiting for more research to come in on that one. The results of \"affectionate writing\" are mixed: see Floyd et al. (2009). The effects of household plants are also mixed: see Bringslimark et al. (2009). There remains <a href=\"http://mentalhealthnews.org/a-genuine-smile-found-to-improve-health-happiness/84834/\">debate</a> on whether forced smiles and laughter improve happiness. Finally, see the review of literature in Helliwell (2011).</small></p>\n<p><small><sup>35</sup>&nbsp;Crocker &amp; Park (2004); Bushman &amp; Baumeister (1998); Bushman &amp; Baumeister (2002).</small></p>\n<p><small><sup>36</sup>&nbsp;Self-serving bias is the tendency to attribute success to internal causes (oneself), but attribute failure to external causes. Basking in reflected glory is an attempt to enhance one's image by announcing and&nbsp;<a href=\"/lw/i7/belief_as_attire/\">displaying</a>&nbsp;association with a well-perceived group or individual. Self-handicapping is a way of saving face by sabotaging one's performance in order to provide an excuse for the failure.</small></p>\n<p><small><sup>37</sup>&nbsp;See, for example: Stepien &amp; Baernstein (2006); de Vignemont &amp; Singer (2006); Heln &amp; Singer (2008).</small></p>\n<p><small><sup>38</sup>&nbsp;Bryant &amp; Veroff (2007).</small></p>\n<p><small><sup>39</sup>&nbsp;Burton &amp; King (2004).</small></p>\n<p><small><sup>40</sup> Emmons &amp; McCullough (2003); Lyubomirsky et al. (2005); Peterson (2006).</small></p>\n<p><small><sup>41</sup>&nbsp;Park &amp; Folkman (1997); Bauer et al. (2008); Lee et al. (2006); Reker et al. (1987); Ulmer et al. (1991); Langer &amp; Rodin (1976).</small></p>\n<p><small><sup>42</sup> Gottman et al. (1998); Hahlweg et al. (1984); Jacobson et al. (1987).</small></p>\n<p><small><sup>43</sup>&nbsp;Aron et al. (2000); Aron et al. (2003).</small></p>\n<p><small><sup>44</sup>&nbsp;Gottman (1984).</small></p>\n<p><small><sup>45</sup> Buunk et al. (2001).</small></p>\n<p><small><sup>46</sup> Murray &amp; Holmes (1999).</small></p>\n<p><small><sup>47</sup>&nbsp;Aron et al. (2000).&nbsp;As for how to find, attract, and keep a great romantic partner in the first place, well: that will have to wait for another article. And of course, perhaps you're not looking for a&nbsp;<em style=\"font-style: italic;\">long term</em>&nbsp;romantic relationship at all. That's another article, too.</small></p>\n<p><small><sup>48</sup> Berto (2005); Hartig et al. (2003); Kaplan (1993, 2001); Price (2008); Berman et al. (2008); Tennessen &amp; Cimprich (1995).</small></p>\n<p><small><sup>49</sup>&nbsp;Frey &amp; Stutzer (2002); Kasser et al. (2004); Solberg et al. (2002); Kasser (2002); Van Boven (2005); Nickerson et al. (2003); Kahneman et al. (2006).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Argyle (1999). Causes and correlates of happiness. In Kahneman, Diener, &amp; Schwartz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Argyle (2001).&nbsp;<em style=\"font-style: italic;\">The Psychology of Happiness</em>&nbsp;(2nd ed.). New York: Routledge.</small></p>\n<p><small>Aron, Norman, Aron, McKenna, &amp; Heyman (2000). Couples shared participation in novel and arousing activities and experienced relationship quality. <em>Journal of Personality and Social Psychology, 78</em>: 273-283.</small></p>\n<p><small>Aron, Norman, Aron, &amp; Lewandowski (2003). Shared participation in self- expanding activities: Positive effects on experienced marital quality. In Noller &amp; Feeney (Eds.), <em>Marital interaction</em> (pp. 177-196). Cambridge University Press.</small></p>\n<p><small>Barrett, Webster, Wallis (1999). Adolescent self-esteem and cognitive skills training: a school-based intervention. <em>Journal of Child and Family Studies 8(2)</em>: 217-227.</small></p>\n<p><small>Bauer, McAdams, &amp; Pals (2008). Narrative identity and eudaimonic well-being. <em>Journal of Happiness Studies, 9</em>: 81-104.</small></p>\n<p><small>Beck (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Beck-The-Evolution-of-the-Cognitive-Model-of-Depression-and-Its-Neurobiological-Correlates.pdf\">The evolution of the cognitive model of depression and its neurobiological correlates</a>. <em>American Journal of Psychiatry, 165</em>: 969-977.</small></p>\n<p><small>Berman, Jonides, &amp; Kaplan (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berman-The-cognitive-benefits-of-interacting-with-nature.pdf\">The cognitive benefits of interacting with nature</a>. <em>Psychological Science, 19</em>: 1207-1212.</small></p>\n<p><small>Berto (2005). Exposure to restorative environments helps restore attentional capacity. <em>Journal of Environmental Psychology, 25</em>: 249-259.</small></p>\n<p><small>Brickman, Coates, &amp; Janoff-Bulman (1978). Lottery winners and accident victims: Is happiness relative? <em>Journal of Personality and Social Psychology, 36</em>: 917-927.</small></p>\n<p><small>Bringslimark, Hartig, &amp; Patil (2009). The psychological benefits of indoor plants: A critical review of the experimental literature. Journal of <em>Environmental Psychology, 29(4)</em>: 422-433.</small></p>\n<p><small>Bryant &amp; Veroff (2006).<em>&nbsp;<a href=\"http://www.amazon.com/Savoring-New-Model-Positive-Experience/dp/0805851208/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Savoring: A new model of positive experience</a></em>. Mahwah, NJ: Erlbaum.</small></p>\n<p><small>Borras, Boucherie, Mohr, Lecomte, Perroud, &amp; Huguelet (2009). Increasing self-esteem: Efficacy for a group intervention for individuals with severe mental disorders. <em>European Psychiatry, 24</em>: 307-316.</small></p>\n<p><small>Bouchard &amp; Loehlin (2001). Genes, evolution, and personality. <em>Behavior Genetics, 31</em>: 243\u2013273.</small></p>\n<p><small>Burton &amp; King (2004). The health benefits of writing about intensely positive experiences. <em>Journal of Research in Personality, 38</em>: 150-163.</small></p>\n<p><small>Bushman &amp; Baumeister (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Bushman-Baumeister-Threatened-egotism-narcissism-self-esteem-and-direct-and-displaced-aggression.pdf\">Threatened egotism, narcissism, self-esteem, and direct and displaced aggression: Does self-love or self-hate lead to violence?</a> <em>Journal of Personality and Social Psychology, 75(1)</em>: 219-229.</small></p>\n<p><small>Bushman &amp; Baumeister (2002). Does self-love or self-hate lead to violence? <em>Journal of Research in Personality, 36(6)</em>: 543-545.</small></p>\n<p><small>Buunk, Oldersma, &amp; de Dreu (2001). Enhancing satisfaction through downward comparison: The role of relational discontent and individual differences in social comparison orientation. <em>Journal of Experimental Social Psychology, 37</em>: 452-467.</small></p>\n<p><small>Chang, Palesh, Caldwell, Glasgow, Abramson, Luskin, Gill, Burke, &amp; Koopman (2004). The effects of a mindfulness-based stress reduction program on stress, mindfulness self-efficacy, and positive states of mind. <em>Stress and Health, 20(3)</em>: 141-147.</small></p>\n<p><small>Chida, Steptoe, &amp; Powell (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Chida-Religiosity-Spirituality-and-Mortality.pdf\">Religiosity/Spirituality and Mortality</a>.&nbsp;<em style=\"font-style: italic;\">Psychotherapy and Psychosomatics</em>, 78(2): 81-90.</small></p>\n<p><small>Crocker &amp; Park (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Crocker-Park-The-costly-pursuit-of-self-esteem.pdf\">The costly pursuit of self-esteem</a>. <em>Psychological Bulletin, 130</em>: 392-414.</small></p>\n<p><small>Csikszentmihalyi (1990). <em><a href=\"http://www.amazon.com/dp/0061339202/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Flow: The Psychology of Optimal Experience</a></em>. New York: Harper and Row.</small></p>\n<p><small>Csikszentmihalyi (1998).&nbsp;<em><a href=\"http://www.amazon.com/dp/0465024114/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Finding Flow: The Psychology of Engagement With Everyday Life</a></em>. Basic Books.</small></p>\n<p><small>Diener, Wolsic, &amp; Fujita (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Physical-Attractiveness-and-Subjective-Well-Being.pdf\">Physical attractiveness and subjective well-being</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 69: 120-129.</small></p>\n<p><small>Diener, Gohm, Suh, &amp; Oishi (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Similarity-of-the-relations-between-marital-status-and-subjective-well-being-across-cultures.pdf\">Similarity of the relations between marital status and subjective well-being across cultures</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Cross-Cultural Psychology</em>, 31: 419-436.</small></p>\n<p><small>Diener &amp; Seligman (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Very-Happy-People.pdf\">Very happy people</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 13: 80-83.</small></p>\n<p><small>Diener &amp; Seligman (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Beyond-money.pdf\">Beyond money: Toward an economy of well-being</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science in the Public Interest</em>, 5(1): 1-31.</small></p>\n<p><small>Diener, Kesebir, &amp; Tov (2009). Happiness. In Leary &amp; Hoyle (Eds.),&nbsp;<em style=\"font-style: italic;\">Handbook of Individual Differences in Social Behavior</em>&nbsp;(pp. 147-160). New York: Guilford.</small></p>\n<p><small>Ellis (2001). <em><a href=\"http://www.amazon.com/dp/1573928798/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Overcoming destructive beliefs, feelings, and behaviors: New directions for Rational Emotive Behavior Therapy</a></em>. Amherst, NY: Prometheus Books.</small></p>\n<p><small>Emmons &amp; McCullough (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Emmons-McCullough-Counting-blessings-versus-burdens.pdf\">Counting blessings versus burdens: An experimental investigation of gratitude and subjective well-being in daily life</a>. <em>Journal of Personality and Social Psychology, 84</em>: 377-389.</small></p>\n<p><small>Feldman &amp; Matjasko (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Feldman-The-role-of-school-based-extracurricular-activities-in-adolescent-development.pdf\">The role of school-based extracurricular activities in adolescent development: A comprehensive review and future directions</a>.&nbsp;<em style=\"font-style: italic;\">Review of Educational Research, 75(2)</em>, 159-210.</small></p>\n<p><small>Felson (1989). Parents and the reflected appraisal process: A longitudinal analysis. <em>Journal of Personality and Social Psychology, 56</em>: 965-971.</small></p>\n<p><small>Fleeson, Malanos, &amp; Achille (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Fleeson-An-intraindividual-process-approach-to-the-relationship-between-extraversion-and-positive-affect.pdf\">An intraindividual process approach to the relationship between extraversion and positive affect: is acting extraverted as \"good\" as being extraverted?</a> <em>Journal of Personality and Social Psychology, 83(6)</em>: 1409-1422.</small></p>\n<p><small>Floyd, Hesse, &amp; Pauley (2009). Writing affectionate letters reduces stress: replication and extension. Paper presented at the annual meeting of the NCA 95th annual convention, Chicago, IL, Nov. 11, 2009.</small></p>\n<p><small>Fredrickson (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Fredrickson-What-good-are-positive-emotions.pdf\">What good are positive emotions?</a> <em>Review of General Psychology, 2</em>: 300-319.</small></p>\n<p><small>Frey &amp; Stutzer (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Frey-What-can-economists-learn-from-happiness-research.pdf\">What can economists learn from happiness research?</a>&nbsp;<em style=\"font-style: italic;\">Journal of Economic Literature</em>, 40: 402-435.</small></p>\n<p><small>Furnham &amp; Cheng (2000). Perceived parental behavior, self-esteem and happiness. <em>Social Psychiatry and Psychiatric Epidemiology, 35(10)</em>: 463-470.</small></p>\n<p><small>Gardner, Csikszentmihalyi, &amp; Damon (2002).&nbsp;<em><a href=\"http://www.amazon.com/Good-Business-Leadership-Making-Meaning/dp/014200409X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Good Business: Leadership, Flow, and the Making of Meaning</a></em>. Basic Books.</small></p>\n<p><small>Gilbert (2006). <em><a href=\"http://www.amazon.com/dp/1400077427/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Stumbling on happiness</a></em>. New York: Knopf.</small></p>\n<p><small>Gottman (1984). <em><a href=\"http://www.amazon.com/Why-Marriages-Succeed-Fail-Yours/dp/0684802414/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Why marriages succeed or fail</a></em>. New York: Simon &amp; Schuster.</small></p>\n<p><small>Gottman, Coan, Carrere, &amp; Swanson (1998). Predicting marital happiness and stability from newlywed interactions. <em>Journal of Marriage and the Family, 60</em>: 5-22.</small></p>\n<p><small>Graziano &amp; Tobin (2009). Agreeableness. In Leary &amp; Hoyle (Eds.), <em>Handbook of individual differences in social behavior</em>&nbsp;(pp. 46-61). New York: Guilford.</small></p>\n<p><small>Grossman, Niemann, Schmidt, &amp; Walach (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Grossman-Mindfulness-based-stress-reduction-and-health-benefits.pdf\">Mindfulness-based stress reduction and health benefits: A meta-analysis</a>. <em>Journal of Psychosomatic Research, 57</em>: 35-43.</small></p>\n<p><small>Hagerty (2000). Social comparisons of income in one's community: Evidence from national surveys of income and happiness. <em>Journal of Personality and Social Psychology, 78</em>: 746-771.</small></p>\n<p><small>Hahlweg, Schindler, Revensdorf, &amp; Brengelmann (1984). The Munich marital therapy study. In Hahlweg &amp; Jacobson (Eds.),&nbsp;<em style=\"font-style: italic;\">Marital interaction: Analysis and modification</em>&nbsp;(pp. 3-26). New York: Guilford Press.</small></p>\n<p><small>Hans (2000).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Hans-A-meta-analysis-of-the-effects-of-adventure-programming-on-locus-of-control.pdf\">A meta-analysis of the effects of adventure programming on locus of control</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Contemporary Psychotherapy, 30(1)</em>: 33-60.</small></p>\n<p><small>Harter (1998). The development of self-representations. In Eisenberg (Ed.), <em>Handbook of child psychology: Vol. 3. Social, emotional, and personality development</em>. New York: Wiley.</small></p>\n<p><small>Hartig, Evans, Jamner, Davis, &amp; Garling (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Hartig-Tracking-restoration-in-natural-and-urban-field-settings.pdf\">Tracking restoration in natural and urban field settings</a>. <em>Journal of Environmental Psychology, 23</em>: 109-123.</small></p>\n<p><span style=\"font-size: 11px;\">Helliwell (2011). <a href=\"http://www.csls.ca/events/2011/helliwell.pdf\">How can subjective well-being be improved?</a></span></p>\n<p><small>Heln &amp; Singer (2008). I feel how you feel but not always: the empathic brain and its modulation. <em>Current Opinion in Neurobiology, 18(2)</em>: 153-158.</small></p>\n<p><small>Hsee &amp; Hastie (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Hsee-Hastie-Decision-and-experience-why-dont-we-choose-what-makes-us-happy.pdf\">Decision and experience: Why don't we choose what makes us happy?</a> <em>Trends in Cognitive Sciences, 10(1)</em>: 31-37.</small></p>\n<p><small>Inglehart (1990).&nbsp;<em style=\"font-style: italic;\">Culture shift in advanced industrial society</em>. Princeton, NJ: Princeton University Press.</small></p>\n<p><small>Isen (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Isen-A-role-for-neuropsychology-in-understanding-the-facilitating-influence-of-positive-affect.pdf\">A role for neuropsychology in understanding the facilitating influence of positive affect on social behavior and cognitive processes</a>. In Snyder &amp; Lopez (Eds.), <em>Handbook of positive psychology</em>&nbsp;(pp. 528-540). New York: Oxford University Press.</small></p>\n<p><small>Isen (2004). Some perspectives on positive feelings and emotions: Positive affect facilitates thinking and problem solving. In Manstead, Frijda, &amp; Fischer (Eds.), <em>Feelings and emotions: The Amsterdam symposium</em>&nbsp;(pp. 263-281). New York: Cambridge University Press.</small></p>\n<p><small>Isen, Daubman, &amp; Nowicki (1987). Positive affect facilitates creative problemsolving. <em>Journal of Personality and Social Psychology, 52</em>: 1122\u20131131.</small></p>\n<p><small>Jacobson, Schmaling, &amp; Holtzworth-Monroe (1987). Component analysis of behavioral marital therapy: 2-year follow-up and prediction of relapse. <em>Journal of Marital and Family Therapy, 13</em>: 187-195.</small></p>\n<p><small>Johnson &amp; Krueger (2006). \"How money buys happiness: Genetic and environmental processes linking finances and life satisfaction.\"&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 90: 680-691.</small></p>\n<p><small>Judge &amp; Klinger (2008). Job satisfaction: Subjective well-being at work. In Eid &amp; Larsen (Eds.),&nbsp;<em style=\"font-style: italic;\">The science of subjective well-being</em>&nbsp;(pp. 393-413). New York: Guilford.</small></p>\n<p><small>Kabat-Zinn (1982). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kabat-Zinn-An-outpatient-program-in-behavioral-medicine-for-chronic-pain-patients-based-on-the-practice-of-mindfulness-meditation.pdf\">An outpatient program in behavioral medicine for chronic pain patients based on the practice of mindfulness meditation: Theoretical considerations and preliminary results</a>. <em>General Hospital Psychiatry, 4</em>: 33-47.</small></p>\n<p><small>Kahneman, Krueger, Schkade, Schwarz, &amp; Stone (2006). \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Kahneman-Would-you-be-happier-if-you-were-richer-A-focusing-illusion.pdf\">Would you be happier if you were richer? A focusing illusion</a>.\"<em style=\"font-style: italic;\">Science</em>, 312: 1908-1910.</small></p>\n<p><small>Kaplan (1993). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kaplan-The-role-of-nature-in-the-context-of-the-workplace.pdf\">The role of nature in the context of the workplace</a>. <em>Landscaping and Urban Planning, 26</em>: 193-201.</small></p>\n<p><small>Kaplan (2001). The nature of the view from home: Psychological benefits. <em>Environment and Behavior, 33(4)</em>: 507-542.</small></p>\n<p><small>Kasser (2002).&nbsp;<em style=\"font-style: italic;\">The high prices of materialism</em>. Cambridge, MA: MIT Press.</small></p>\n<p><small>Kasser, Ryan, Couchman, &amp; Sheldon (2004). Materialistic values: Their causes and consequences. In Kasser &amp; Kanner (Eds.),&nbsp;<em style=\"font-style: italic;\">Psychology and consumer culture: The struggle for a good life in a materialistic world</em>. Washington DC: American Psychological Association.</small></p>\n<p><small>Langer &amp; Rodin (1976).&nbsp;The effects of choice and enhanced personal responsibility for the aged: A field experiment in an institutional setting.&nbsp;<em>Journal of Personality and Social Psychology, Vol 34(2)</em>: 191-198.</small></p>\n<p><small>Lee, Cohen, Edgar, Laizner, &amp; Gagnon (2006). Meaning-making intervention during breast or colorectal cancer treatment improves self-esteem, optimism, and self-efficacy. <em>Social Science &amp; Medicine, 62(12)</em>: 3133-3145.</small></p>\n<p><small>Lepore &amp; Smyth, eds. (2002).&nbsp;<em>The writing cure: How expressive writing promotes health and emotional well-being</em>. Washington, DC: American Psychological Association.</small></p>\n<p><small>Lindsley, Brass, &amp; Thomas (1995).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Lindsley-Efficacy-performance-spirals-A-multilevel-perspective.pdf\">Efficacy-performance spirals: A multilevel perspective</a>.&nbsp;<em style=\"font-style: italic;\">Academy of Management Review, 20(3)</em>: 645-678.</small></p>\n<p><small>Lucas (2008). Personality and subjective well-being. In Eid &amp; Larsen (Eds.), <em>The science of subjective well-being</em>&nbsp;(pp. 171-194). New York: Guilford.</small></p>\n<p><small>Lucas &amp; Diener (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lucas-Diener-Personality-and-subjective-well-being.pdf\">Personality and subjective well-being</a>. In John, Robins, &amp; Pervin (Eds.), <em>Handbook of personality: Theory and research, 3rd ed.</em>&nbsp;(pp. 795-814). New York: Guilford.</small></p>\n<p><small>Lyubomirsky, Sheldon, &amp; Schkade (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Lyubomirsky-Pursuing-happiness-The-architecture-of-sustainable-change.pdf\">Pursuing happiness: The architecture of sustainable change</a>.&nbsp;<em style=\"font-style: italic;\">Review of General Psychology</em>, 9(2), 111-131.</small></p>\n<p><small>Lyubomirsky, Tkach, &amp; DiMatteo (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lyubomirsky-What-are-the-differences-between-happiness-and-self-esteem.pdf\">What are the differences between happiness and self-esteem?</a> <em>Social Indicators Research, 78</em>: 363-404.</small></p>\n<p><small>Lyubomirsky, King, &amp; Diener (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Lyubomirsky-The-benefits-of-frequent-positive-affect.pdf\">The benefits of frequent positive affect: Does happiness lead to success?</a> <em>Psychological Bulletin, 131</em>: 803-855.</small></p>\n<p><small>Lykken &amp; Tellegen (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Lykken-Happiness-Is-a-Stochastic-Phenomenon.pdf\">Happiness is a stochastic phenomenon</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 7: 186-189.</small></p>\n<p><small>Lykken (1999).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/dp/0312263333/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Happiness: The nature and nurture of joy and contentment</a></em>. New York: St. Martin's.</small></p>\n<p><small>McNeil &amp; Fleeson (2006). The causal effect of extraversion on positive affect and neuroticism on negative affect: Manipulating state extraversion and state neuroticism in an experimental approach. <em>Journal of Research in Personality, 40</em>: 529-550.</small></p>\n<p><small>Morris (1999). The mood system. In Kahneman, Diener, &amp; Schwatrz (Eds.), <em>Well-being: The foundations of hedonic psychology</em>&nbsp;(pp. 169-189). New York: Russell Sage Foundation.</small></p>\n<p><small>Murray &amp; Holmes (1999). The (mental) ties that bind: Cognitive structures that predict relationship resilience. <em>Journal of Personality and Social Psychology, 77</em>: 1228-1244.</small></p>\n<p><small>Myers (1992).&nbsp;<em style=\"font-style: italic;\">The pursuit of happiness: Who is happy, and why</em>. New York: Morrow.</small></p>\n<p><small>Myers (1999). Close relationships and quality of life. In Kahnemann, Diener, &amp; Schwarz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Myers &amp; Diener (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Myers-who-is-happy.pdf\">Who is happy?</a>&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 6: 10-19.</small></p>\n<p><small>Myers &amp; Diener (1997). The pursuit of happiness.&nbsp;<em style=\"font-style: italic;\">Scientific American, Special Issue 7</em>: 40-43.</small></p>\n<p><small>Nakamura &amp; Csikszentmihalyi (2009). Flow theory and research. In Lopez &amp; Snyder (Eds.), <em>Oxford handbook of positive psychology</em>&nbsp;(2nd ed., pp. 195-206). New York: Oxford.</small></p>\n<p><small>Nickerson, Schwartz, Diener, &amp; Kahnemann (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Nickerson-Zeroing-in-on-the-dark-side-of-the-american-dream.pdf\">Zeroing in on the dark side of the American dream: A closer look at the negative consequences of the goal for financial success</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Science</em>, 14(6): 531-536.</small></p>\n<p><small>Park &amp; Folkman (1997). Meaning in the context of stress and coping. <em>Review of General Psychology, 1</em>: 115-144.</small></p>\n<p><small>Peterson (2006).<em>&nbsp;<a href=\"http://www.amazon.com/Primer-Positive-Psychology-Christopher-Peterson/dp/0195188330/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">A primer on positive psychology</a></em>. New York: Oxford University Press.</small></p>\n<p><small>Peterson &amp; Seligman (2004). <em><a href=\"http://www.amazon.com/Character-Strengths-Virtues-Handbook-Classification/dp/0195167015/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">Character strengths and virtues: A Handbook of classification</a></em>. New York: Oxford University Press.</small></p>\n<p><small>Price (2008). Research roundup: Get out of town. <em>gradPSYCH, 6(3)</em>: 10.</small></p>\n<p><small>Pronin &amp; Jacobs (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pronin-Jacobs-Thought-speed-mood-and-the-experience-of-mental-motion.pdf\">Thought speed, mood, and the experience of mental motion</a>. <em>Perspectives on Psychological Science, 3</em>: 461-485.</small></p>\n<p><small>Proulx, Helms, &amp; Cheryl (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Proulx-Marital-Quality-and-Personal-Well\u2010Being-A-Meta\u2010Analysis.pdf\">Marital quality and personal well-being: A meta-analysis</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Marriage and Family</em>, 69: 576-593.</small></p>\n<p><small>Reker, Peacock, &amp; Wong (1987). Meaning and purpose in life and well-being: a life-span perspective. <em>The Journal of Gerontology, 42(1)</em>: 44-49.</small></p>\n<p><small>Riis, Loewenstein, Baron, Jepson, Fagerlin, &amp; Ubel (2005). Ignorance of hedonic adaptation to hemodialysis: A study using ecological momentary assessment.&nbsp;<em style=\"font-style: italic;\">Journal of Experimental Psychology: General</em>, 134: 3-9.</small></p>\n<p><small>Roberts, Jackson, Fayard, Edmonds, &amp; Meints (2009). Conscientiousness. In Leary &amp; Hoyle (Eds.), <em>Handbook of individual differences in social behavior</em>&nbsp;(pp. 369-381). New York: Guilford.</small></p>\n<p><small>Ross &amp; Van Willigen (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Ross-Education-and-the-subjective-quality-of-life.pdf\">Education and the subjective quality of life</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Health &amp; Social Behavior</em>, 38: 275-297.</small></p>\n<p><small>Schwartz &amp; Strack (1999). Reports of subjective well-being: Judgmental processes and their methodological implications. In Kahneman, Diener, &amp; Schwartz (Eds.), <em>Well-being: The foundations of hedonic psychology</em>. New York: Russell Sage Foundation.</small></p>\n<p><small>Seery, Silver, Holman, Ence, &amp; Chu (2008). Expressing thoughts and feelings following a collective trauma: Immediate responses to 9/11 predict negative outcomes in a national sample. <em>Journal of Consulting and Clinical Psychology, 76(4)</em>: 657-667.</small></p>\n<p><small>Shapiro, Schwartz, &amp; Bonner (1998). The effects of mindfulness-based stress reduction on medical and pre-medical students. <em>Journal of Behavioral Medicine, 21</em>: 581-599.</small></p>\n<p><small>Solberg, Diener, Wirtz, Lucas, &amp; Oishi (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Solberg-Wanting-Having-and-Satisfaction-Examining-the-Role-of-Desire-Discrepancies-in-Satisfaction-With-Income.pdf\">Wanting, having, and satisfaction: Examining the role of desire discrepancies in satisfaction with income</a>.&nbsp;<em style=\"font-style: italic;\">Journal of Personality and Social Psychology</em>, 83(3): 725-734.</small></p>\n<p><small>Spera, Buhrfeind, &amp; Pennebaker (1994). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Spera-Expressive-writing-and-coping-with-job-loss.pdf\">Expressive writing and coping with job loss</a>. <em>Academy of Management Journal, 3</em>: 72-733.</small></p>\n<p><small>Stepien &amp; Baernstein (2006). Educating for empaty: a review. <em>Journal of General Internal Medicine, 21(5)</em>: 524-530.</small></p>\n<p><small>Steptoe, Wardle, &amp; Marmot (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Steptoe-Positive-affect-and-health-related-neuroendocrine-cardiovascular-and-inflammatory-processes.pdf\">Positive affect and health-related neuroendocrine, cardiovascular, and inflammatory processes</a>. <em>Proceedings of the National Academy of Sciences of the United States of America, 102(18)</em>: 6508-6512.</small></p>\n<p><small>Stubbe, Posthuma, Boomsa, &amp; De Geus (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/01/Stubbe-Heritability-of-life-satisfaction-in-adults-A-twin-family-study.pdf\">Heritability and life satisfaction in adults: A twin-family study</a>.&nbsp;<em style=\"font-style: italic;\">Psychological Medicine</em>, 35: 1581-1588.</small></p>\n<p><small>Tennessen &amp; Cimprich (1995). Views to nature: Effects on attention. <em>Journal of Environmental Psychology, 15</em>: 77-85.</small></p>\n<p><small>Ulmer, Range, &amp; Smith (1991). Purpose in life: a moderator of recovery from bereavement. <em>Journal of Death and Dying, 23(4)</em>: 279-289.</small></p>\n<p><small>Van Boven (2005). Experientialism, materialism, and the pursuit of happiness.&nbsp;<em style=\"font-style: italic;\">Review of General Psychology</em>, 9(2): 132-142.</small></p>\n<p><small>de Vignemont &amp; Singer (2006). The empathic brain: how, when, and why? <em>Trends in Cognitive Sciences, 10(10)</em>: 435-441.</small></p>\n<p><small>Warr (1999). Well-being and the workplace. In Kahneman, Diener, &amp; Schwartz (Eds.),&nbsp;<em style=\"font-style: italic;\">Well-being: The foundations of hedonic psychology</em>. New York: Sage.</small></p>\n<p><small>Wegner (1989).&nbsp;<em><a href=\"http://www.amazon.com/White-Bears-Other-Unwanted-Thoughts/dp/0898622239/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0131103628&amp;linkCode=as2&amp;tag=lesswrong-20\">White bears and other unwanted thoughts: Suppression, obsession, and the psychology of mental control</a></em>. New York: Viking.</small></p>\n<p><small>Weiss, Bates, &amp; Luciano (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Weiss-Happiness-is-a-personality-thing.pdf\">Happiness is a personal(ity) thing</a>. <em>Psychology Science, 19</em>: 205-210.</small></p>\n<p><small>Wilson &amp; Gilbert (2005). Affective forecasting: Knowing what to want. <em>Current Directions in Psychological Science, 14</em>: 131-134.</small></p>\n<p><small>Wissink, Dekovic, &amp; Meijer (2006). Parenting behavior, quality of the parent-adolescent relationship, and adolescent functioning in four ethnic groups. <em>Journal of Early Adolescence, 26</em>: 133-159.</small></p>\n<p><small>Zech &amp; Rim\u00e9 (2005). Is talking about an emotional experience helpful? Effects on emotional recovery and perceived benefits. <em>Clinical Psychology and Psychotehrapy, 12</em>: 270-287.</small></p>", "sections": [{"title": "The correlates of happiness", "anchor": "The_correlates_of_happiness", "level": 2}, {"title": "Happiness, personality, and skills", "anchor": "Happiness__personality__and_skills", "level": 2}, {"title": "Happiness is subjective and relative", "anchor": "Happiness_is_subjective_and_relative", "level": 1}, {"title": "Flow and mindfulness", "anchor": "Flow_and_mindfulness", "level": 1}, {"title": "How to be happier", "anchor": "How_to_be_happier", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 2}, {"title": "References", "anchor": "References", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "207 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 209, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6NvbSwuSAooQxxf7f", "33KewgYhNSxFpbpXg", "RWo4LwFzpHNQCTcYt", "rRmisKb45dN7DK4BW", "Q5CjE8pRiACqTvhRM", "nYkMLFpx77Rz3uo9c"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2011-03-17T07:22:43.651Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T09:32:33.560Z", "modifiedAt": null, "url": null, "title": "Brain Upload Comic", "slug": "brain-upload-comic", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:00.920Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F7ir4swNETt9WyBfE/brain-upload-comic", "pageUrlRelative": "/posts/F7ir4swNETt9WyBfE/brain-upload-comic", "linkUrl": "https://www.lesswrong.com/posts/F7ir4swNETt9WyBfE/brain-upload-comic", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brain%20Upload%20Comic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrain%20Upload%20Comic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF7ir4swNETt9WyBfE%2Fbrain-upload-comic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brain%20Upload%20Comic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF7ir4swNETt9WyBfE%2Fbrain-upload-comic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF7ir4swNETt9WyBfE%2Fbrain-upload-comic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 22, "htmlBody": "<p>http://www.smbc-comics.com/index.php?db=comics&amp;id=2186</p>\n<p>Convincing argument, or faulty metaphor?</p>\n<p>I would go with the latter, but I don't trust my brain's abilities at 5:30 in the morning.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F7ir4swNETt9WyBfE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 2, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "6280", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T13:10:19.505Z", "modifiedAt": null, "url": null, "title": "Rationality Outreach: A Parable", "slug": "rationality-outreach-a-parable", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.774Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gxaj4KAzYhSRgqvsh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z8FiWFeqS6eak4Jkc/rationality-outreach-a-parable", "pageUrlRelative": "/posts/Z8FiWFeqS6eak4Jkc/rationality-outreach-a-parable", "linkUrl": "https://www.lesswrong.com/posts/Z8FiWFeqS6eak4Jkc/rationality-outreach-a-parable", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Outreach%3A%20A%20Parable&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Outreach%3A%20A%20Parable%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ8FiWFeqS6eak4Jkc%2Frationality-outreach-a-parable%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Outreach%3A%20A%20Parable%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ8FiWFeqS6eak4Jkc%2Frationality-outreach-a-parable", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ8FiWFeqS6eak4Jkc%2Frationality-outreach-a-parable", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1360, "htmlBody": "<p><em>This post grew out of a very long discussion with the New York Less Wrong meetup group. &nbsp;The question was, should a group dedicated to rationality be explicitly atheist? &nbsp;Or should it make an effort to be respectful to theists in order to make them feel welcome and spread rationality farther? &nbsp;We argued for a long time. &nbsp;The pro-atheism camp said that, given that religion is so overwhelmingly wrong on the merits, we shouldn't allow it any special pleading -- it's just as wrong as any other wrong belief, and we'd lose our value as a rationalist group if we began to put status above truth. &nbsp;The anti-atheism group said that, while that may be true, it's going to doom us to be a group exclusively for eccentric nerds, and we need to develop broad appeal, even if that's hard and requires us to leave our comfort zone.</em></p>\n<p><em>Things got abstract very fast; my take was that we need to get back to practicalities. &nbsp;Different attitudes to religion have different effects on different types of people; we need to optimize for desired effects and accept what tradeoffs we must. &nbsp;We can't appeal equally to everyone. &nbsp;So I came up with a sort of typology.</em></p>\n<h2><strong>The Four New Members</strong></h2>\n<p><em><strong>Annie</strong></em></p>\n<p><em><strong><span style=\"font-family: arial, sans-serif; font-style: normal; font-weight: normal; font-size: 13px; border-collapse: collapse;\"> </span></strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong> </strong></em></p>\n<p><em><strong>\n<p><span style=\"font-style: normal; font-weight: normal;\"><em><strong> </strong></em></span></p>\n<em><strong>\n<div style=\"display: inline !important;\"><span style=\"font-weight: normal;\"><span style=\"font-style: normal;\">Annie is religious, and she's not particularly rational. &nbsp;She's not great at following the thread of an argument; she can't really reason quantitatively; she shoots herself in the foot in her daily life (maybe she runs up a lot of debt because she can't keep track of her spending; maybe she has a pattern of bad relationships; etc.) &nbsp;Going to church is really the least of her worries. &nbsp;Annie is unlikely to come to us through the meetup group or LessWrong, but maybe she's one of our friends or family members, or maybe she read </span></span><a href=\"http://www.fanfiction.net/s/5782108/1/Harry_Potter_and_the_Methods_of_Rationality\" target=\"_blank\"><span style=\"font-weight: normal;\"><span style=\"font-style: normal;\">HP:MOR.&nbsp;</span></span></a></div>\n<div style=\"display: inline !important;\"><span style=\"font-weight: normal;\"><span style=\"font-style: normal;\"><br /></span></span></div>\n<div style=\"display: inline !important;\"><span style=\"font-weight: normal;\"><span style=\"font-style: normal;\"><br /></span></span></div>\n</strong></em>\n<div style=\"display: inline !important;\"><span style=\"font-weight: normal;\"><span style=\"font-style: normal;\">We&nbsp;don't&nbsp;want to tell Annie to give up religion. &nbsp;In fact, it might be best not to say anything bad about religion at all in front of her; because she's probably prone to the halo effect, if we sound anti-religious, she'll assume everything else we have to say is stupid. Instead, we probably want to focus on helping her, very gently, to make her own life better by being aware of things like hyperbolic discounting, the planning fallacy, happy death spirals, etc. Dealing with Annie sounds like very hard work. &nbsp;Because she just doesn't&nbsp;think&nbsp;in propositional arguments, you can't change her mind about things with a chain of propositions and a \"QED.\" &nbsp;We would need heavy-duty psychology to help her.</span></span></div>\n<span style=\"font-weight: normal;\"><span style=\"font-style: normal;\"> </span></span>\n<div style=\"display: inline !important;\"><em><strong><a id=\"more\"></a></strong></em><br /></div>\n<div style=\"display: inline !important;\"><br /></div>\n<div style=\"display: inline !important;\"><strong><em>Barbara</em></strong></div>\n<div style=\"display: inline !important;\"><strong><em><br /></em></strong></div>\n<div style=\"display: inline !important;\"><br /></div>\n<div style=\"display: inline !important;\">\n<div><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Barbara is religious, but she's pretty rational. She's logical-minded and good at getting things done; religion just occupies a special compartment that she never touches. &nbsp;When it comes to her areas of expertise, she's just as competent, or more, as us rationalists. &nbsp;And there's no way in hell you're going to talk her into atheism -- she knows she's smart and competent, so she can be incredibly stubborn about the things she's precommitted to not changing her mind about. &nbsp;She's the prototypical scientist who'll still never take the subway on Saturday (because she strictly observes Shabbat.) She may be a very sharp thinker about other things, and she may be in the geek/technophile/futurist cluster; she&nbsp;might be a LessWrong reader or someone who comes to meetups or lectures, or one of us might know her personally.</span></span></div>\n<div><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">We don't want to argue religion with Barbara either. &nbsp;She's not interested. &nbsp;She might get fed up with us, and she's talented enough that she could be a valuable asset to keep around. &nbsp;On the other hand, because she's cooler-headed than Annie, she can probably handle knowing that we're currently a majority-atheist group. &nbsp;She's probably met a lot of atheists and has no problem with them. &nbsp;She might even be okay with hearing offhand negative comments about religion; she won't agree, but it's not necessarily a big deal to her. &nbsp;Barbara pretty much speaks our language, so we don't have to \"trick\" her into rationality, we can talk to her normally, with arguments and probability estimates and whatnot. &nbsp;But she might still be turned off by some of the guru-disciple language in the Sequences -- when she has something to learn, we still have to be careful not to sound like we're condescending to her. &nbsp;She pretty much thinks she already is rational, so it's a bit tricky to communicate to her that sometimes she still isn't.</span></span></div>\n</div>\n<div style=\"display: inline !important;\"><strong><em>Caroline</em></strong></div>\n<div style=\"display: inline !important;\"><strong><em><br /></em></strong></div>\n<div style=\"display: inline !important;\"><br /></div>\n<div style=\"display: inline !important;\"><strong><em><span style=\"font-style: normal; font-weight: normal;\">\n<div>Caroline is a seeker. &nbsp;She's religious, but doubting; her beliefs are falling apart on her, and she wants some reassurance that she can find a way out of her dilemma. &nbsp;Maybe she doesn't really believe in God but she's afraid that makes her a bad person, or afraid of losing her community. &nbsp;Caroline may be a strong rationalist or a weak one, but she has the \"failure to compartmentalize\" that makes her carry ideas, sooner or later, to their necessary conclusions, and realize \"Whoa, that idea means I'd actually have to change my life right now!\"</div>\n<div>I think we want to help Caroline. &nbsp;Her doubts, if nothing else, show that she has the potential to be more rational. &nbsp;If she's as smart as Barbara&nbsp;<span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">and</span></span>&nbsp;she's got the failure to compartmentalize, she could turn out to be formidable. If she's indicated directly that she's currently leaving religion, or thinking about it, we should be friendly and supportive and recommend atheist resources. (My picks: Bertrand Russell's&nbsp;<a href=\"http://www.amazon.com/Christian-Essays-Religion-Related-Subjects/dp/0671203231\" target=\"_blank\"><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">Why I Am Not A Christian</span></span></a><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">, </span></span>Robert Ingersoll's <a href=\"http://www.positiveatheism.org/hist/ingag.htm\" target=\"_blank\"><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">Why I Am An Agnostic</span></span></a><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">,</span></span><span style=\"font-weight: normal;\"> </span>the \"Into Clear Air\" <a href=\"http://www.ebonmusings.org/atheism/clearair.html\" target=\"_blank\">page</a>, and the LessWrong sequence about \"How to Actually Change Your Mind,\" especially <a href=\"/lw/i4/belief_in_belief/\" target=\"_blank\">Belief in Belief</a>.)&nbsp;&nbsp;A lot of new atheists are lonely and want reassurance that they have company. Their faces just light up when they meet \"another one.\" &nbsp;Caroline deserves that support. Whether she's an advanced rationalist in general or a newbie, we need to pay some attention to psychology with her -- we need to show her that atheists can be positive and caring and make her feel good about her decision.</div>\n<div><span style=\"font-weight: normal;\"><strong><em>Donna</em></strong></span></div>\n<div><strong><em><span style=\"font-style: normal; font-weight: normal;\">\n<div>Donna is already an atheist, and she's an outspoken one. &nbsp;Maybe she's already been active in self-defined atheist or skeptic clubs or activities. Maybe she even acquired an interest in rationality through<span style=\"font-weight: normal;\">&nbsp;</span>the atheist/skeptic community. &nbsp;Donna would actually be turned&nbsp;<span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">off</span></span><span style=\"font-weight: normal;\">&nbsp;</span>by a sensitive attitude towards religion; the way she sees it, we should no more \"respect\" religious beliefs than we should respect belief in the tooth fairy, and she doesn't want to belong to any club that asks her to pretend \"respect\" for a ludicrous idea. She wants to be around like-minded people; she wants a place to let her hair down and not have to pretend she has any patience with the Imaginary Sky Friend.</div>\n<div>If we simply don't bring up religion at meetings/lectures/etc, Donna will probably be fine. &nbsp;But if we try to shut her up, she won't be happy. &nbsp;She'll think of it as censorship. &nbsp;We could lose her by being too carefully polite about religion and insisting that she follow suit. &nbsp;If Donna is otherwise an asset to the group, it could be a shame to drive her away. A Donna can drive away an Annie, and can sometimes irritate a Barbara, though. &nbsp;This is where there's a potential for conflict. &nbsp;I think more current rationalists started off as Donnas than as any other type, so that's weak evidence that we shouldn't have too many group norms that rub Donnas the wrong way. &nbsp;But it doesn't seem wise to be a Donna-only club and indulge in random feel-good religion-bashing -- that's bad for atheists' rationality too.</div>\n<div>A rationalist organization's stance to religion (or even an individual rationalist's) should depend on what kinds of people we encounter, and which ones we value attracting the most. &nbsp;Smart, competent, clear-thinking people are worth attracting for their own sake. &nbsp;Criticizing religion openly will drive off Annies, and, occasionally, Barbaras; accommodating religion explicitly will drive off Donnas. &nbsp;It really depends who you have in your area. &nbsp;(People who live in predominantly secular countries just won't meet as many Barbaras.) &nbsp;If you have the opportunity to tailor your approach individually, that's ideal -- introduce people to rationality in the format that works best for them.</div>\n</span></em></strong></div>\n</span></em></strong></div>\n</strong></em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "izp6eeJJEg9v5zcur": 1, "NSMKfa8emSbGNXRKD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z8FiWFeqS6eak4Jkc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 34, "extendedScore": null, "score": 6.910601997059363e-07, "legacy": true, "legacyId": "6282", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 124, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CqyJzDZWvGhhFJ7dY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T20:12:25.899Z", "modifiedAt": null, "url": null, "title": "Less Wrong NYC: Case Study of a Successful Rationalist Chapter", "slug": "less-wrong-nyc-case-study-of-a-successful-rationalist", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:29.931Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cosmos", "createdAt": "2009-04-26T03:18:01.731Z", "isAdmin": false, "displayName": "Cosmos"}, "userId": "c3Ji9Th6jATRyHLFC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist", "pageUrlRelative": "/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist", "linkUrl": "https://www.lesswrong.com/posts/CsKboswS3z5iaiutC/less-wrong-nyc-case-study-of-a-successful-rationalist", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20NYC%3A%20Case%20Study%20of%20a%20Successful%20Rationalist%20Chapter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20NYC%3A%20Case%20Study%20of%20a%20Successful%20Rationalist%20Chapter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKboswS3z5iaiutC%2Fless-wrong-nyc-case-study-of-a-successful-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20NYC%3A%20Case%20Study%20of%20a%20Successful%20Rationalist%20Chapter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKboswS3z5iaiutC%2Fless-wrong-nyc-case-study-of-a-successful-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKboswS3z5iaiutC%2Fless-wrong-nyc-case-study-of-a-successful-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3321, "htmlBody": "<p>It is perhaps the best-kept secret on Less Wrong that the <a href=\"http://wiki.lesswrong.com/wiki/NYC_meetup_group\" target=\"_blank\">New York City community</a> has been meeting regularly for almost two years. For nearly a year we've been meeting weekly or more.&nbsp; The rest of this post is going to be a practical guide to the benefits of group rationality, but first I will do something that is still too rare on this blog: <a href=\"/lw/hp/feeling_rational\" target=\"_blank\">make it clear how strongly I feel about this</a>. Before this community took off, <em>I did not believe that life could be this much fun or that I could possibly achieve such a sustained level of happiness.</em></p>\n<p>Being rational in an irrational world is incredibly lonely. Every interaction reveals that our thought processes differ widely from those around us, and I had accepted that such a divide would always exist. For the first time in my life I have dozens of people with whom I can act freely and <em>revel in the joy of rationality</em> without any social concern - hell, it's actively rewarded! Until the NYC Less Wrong community formed, I didn't realize that I was a forager lost without a tribe...</p>\n<p>Rationalists are still human, and we still have basic human needs. lukeprog <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge\" target=\"_blank\">summarizes the literature on subjective well-being</a>, and the only factors which correlate to any degree are genetics, health, work satisfaction and social life - which actually gets listed <em>three separate times</em> as social activity, relationship satisfaction and religiosity. Rationalists tend to be <a href=\"/lw/28l/do_you_have_highfunctioning_aspergers_syndrome\" target=\"_blank\">less socially adept</a> <a href=\"/lw/2am/aspergers_survey_reresults\" target=\"_blank\">on average</a>, and this can make it difficult to obtain the full rewards of social interaction. However, once rationalists learn to socialize with each other, they also become increasingly social towards everyone more generally. This improves your life. <em>A lot.</em></p>\n<p>We are a group of friends to enjoy life alongside, while we <a href=\"http://en.wikipedia.org/wiki/Synsepalum_dulcificum\" target=\"_blank\">try miracle fruit</a>, dance ecstatically until sunrise, actively embarrass ourselves at karaoke, get lost in the woods, and jump off waterfalls.&nbsp; Poker, paintball, parties, go-karts, concerts, camping... I have a community where I can live in truth and be accepted as I am, where I can give and receive feedback and get help <a href=\"http://wiki.lesswrong.com/wiki/Tsuyoku_naritai\" target=\"_blank\">becoming stronger</a>. I am immensely grateful to have all of these people in my life, and I look forward to every moment I spend with them. To love and be loved is an unparalleled experience in this world, once you actually try it.</p>\n<p>So, you ask, how did all of this get started...?<a id=\"more\"></a></p>\n<h2>Genesis, or a Brief History of Nearly Everything</h2>\n<p>The origin of the NYC chapter was the <a href=\"http://www.overcomingbias.com/2009/04/nyc-meetup-friday-7pm.html\" target=\"_blank\">April 24th, 2009 meetup</a> that Robin Hanson organized when he came to the city for a prediction markets conference.&nbsp; Approximately 15 people attended over the course of the night, and we all agreed that we had way too much fun together not to do this on a regular basis. I handed out my business cards to everyone there, told them to e-mail me, and I would create a mailing list. Thus <a href=\"http://groups.google.com/group/overcomingbiasnyc\" target=\"_blank\">Overcoming Bias NYC</a> was born.</p>\n<p>It was clear from the very beginning that Jasen Murray was the person most interested in seeing this happen, so he became the organizer of the group for the first year of its existence. At first the times and locations were impromptu, but in August Jasen made the brilliant move of precommitting to be at a specific time and place for a minimum of two hours twice per month. Because enough of us liked Jasen and wanted to hang out with him anyway, several people began showing up every time and a regular meetup was established. Going forward we tried a combination of social meetups, focused discussions and game nights. Jasen also attempted to shift coordination from the mailing list to the <a href=\"http://www.meetup.com/Less-Wrong-Overcoming-Bias-NYC/\" target=\"_blank\">Meetup group</a>, but Meetup is not a great mailing list and people were loathe to use multiple services. That now serves as our public face.</p>\n<p>In April 2010, Jasen departed to run the Visiting Fellows program at SIAI, and I became the group's organizer. We immediately agreed on a number of changes: weekly meetups (with game nights every other week), focused discussions addressing specific problems instead of general theory, and a temporary taboo on discussion of AGI/FAI. We also moved the majority of our meetups from a public diner to a private residence, which avoided a lot of hassles with loud crowds, ordering of food, etc.&nbsp; These changes marked our transition to a social group that focused on practical life benefits. June brought two more key changes: we started holding strategy sessions on request to help members optimize their lives, and I started hugging people, which began a cascade of increasing physical contact. That summer brought an increased interest in skill sharing, a reduced game night frequency, and meetups focused around specific topics. That fall we began using the group more for discussions, sharing social events of mutual interest, and coordinating activities together outside of the weekly meetups.</p>\n<p>Then, in October, things began to accelerate. I told everyone on the list to respond or be removed, to get an idea of numbers and to galvanize the core membership. Several members broke off old relationships and some of them entered new ones within the group. More women started attending; we had previously been almost all male. We began having more contact with the west coast rationalists, including visits by Jasen and Michael Vassar and an extended stay by <a href=\"http://meaningandmagic.com/?c=1\" target=\"_blank\">Divia</a>, which brought valuable new memes to our community. Self-reported levels of fun and happiness began to radically increase. Mailing list discussions turned towards asking for practical advice. The meetups took on a self-improvement focus, with weekly goal-setting and accountability. Andrew Rettek began a <a href=\"http://www.meetup.com/Less-Wrong-Overcoming-Bias-NYC/events/16332288/\" target=\"_blank\">public lecture series</a> presenting the Sequences. Demand for more-than-weekly meetups grew...</p>\n<h2>Lessons</h2>\n<p>NYC has pioneered creating <a href=\"/lw/5v/church_vs_taskforce\" target=\"_blank\">rationalist communities</a>. While we have largely proceeded via trial and error, the rest of you who are going to become organizers can learn from our experiments and avoid a lot of mistakes. The lessons largely fall under two categories: how to build a group, and what to do with a group once you have one. I hope that you find this advice helpful in your own efforts to establish rationalist communities.</p>\n<h3>Building a Community</h3>\n<p><strong>Communities need heroes:</strong> Until we have a cadre of paid community organizers, LW meetups will have to run on hero power. Most members are going to be passively attending, a few will actively contribute ideas and activities on the mailing list, but someone needs to be willing to step up as a leader and begin organizing people. Do you want a community badly enough to build one yourself?</p>\n<p><strong>Commitment <em>works</em>:</strong> We started having regular meetings because Jasen committed to showing up at a specific time and place and staying for a minimum length of time, regardless of other attendance. Enough folks wanted to hang out that this resulted in successful meetups.</p>\n<p><strong>Schedule events first, get feedback later:</strong> Trying to ask everyone to state their preferences in order to accommodate them all rarely works and can result in prolonged indecision. Just schedule a time and place and topic; people who want to come but can't will speak up and tell you why. With enough iterations you can settle on something approximately utility maximizing.</p>\n<p><strong>We are a group of friends:</strong> This is the true secret of our success, we are not just a meetup group. We started off as a bunch of people who enjoyed talking about rationality enough that we kept doing it regularly until we became a part of each other's lives. You can tell because we greet each other with hugs instead of handshakes. That physical contact has a profound psychological impact. Furthermore, almost the entire growth of our group has come through friend-referral, not through increased Less Wrong readership. Rationality per se is not the core selling point of the group - people genuinely like hanging out with us, and they tell other people to come hang out with us too.</p>\n<p><strong>Gender ratio matters:</strong> It is no secret that rationality suffers from a <a href=\"/lw/ap/of_gender_and_rationality\" target=\"_blank\">paucity of women</a>, which makes it difficult to start a group with any women at all. There is no easy answer here, but it is important to address this factor as early as possible. Simply put, if you're winning at life and having enough fun women will want to join you, and a balanced gender ratio encourages more people of <em>both genders</em> to attend.&nbsp; Work hard to find interested women, and be careful in the presence of newcomers when trying to sanely explicitly discuss hot-button gender topics.&nbsp; In case the argument for more women is not sufficiently clear, gender-balanced meetups are <em>a lot more fun</em>, and it provides a unique perspective on ideas and group dynamics.</p>\n<p><strong>The mailing list is for more than just meetups:</strong> While scheduling meetups is an obvious function of a group mailing list, it can be used for all manner of discussions and coordination between group members. Given our significant overlapping interests, one function of the list is for people to invite others to join them on their adventures, be that going to conferences, parties, sous-vide steak dinners, rock climbing, or whatever else people feel like doing.&nbsp; Another very important use is to ask the group for advice on a particular subject, like <a href=\"/lw/2tw/love_and_rationality_less_wrongers_on_okcupid\" target=\"_blank\">optimizing OKCupid profiles</a>, learning programming languages, alleviating bad moods, and more! Last but not least, mailing lists make large group discussions on serious questions feasible.</p>\n<p><strong>Interact with outside rationalists as much as possible:</strong> Just as division of labor exists within the group, it also exists among groups. This allows a steady flow of new memes to try out, and an external evaluation of the current group memes. SIAI and the NYC community have been working on different projects and have different perspectives, and it has been extremely helpful to both groups to have more collaboration between them. NYC is also a major city, so we get a lot of visiting rationalists passing through, and people have traveled from neighboring states to attend our events. This provides constant perspective and growth.</p>\n<p><strong>Meetup topics</strong></p>\n<ul>\n<li><strong>Social/unfocused discussions:</strong> Attendance is usually poor, members replied that hanging out is harder to justify than having a specific purpose.</li>\n<li><strong>Discussion topics:</strong> Reliably good attendance and fun. The topics can vary widely, everything from TDT to making money. Note that large group discussions rarely lead to progress/insight on a question, but breaking into smaller sub-groups can work.</li>\n<li><strong>Presentation/skill share:</strong> Depends on the topic, draws specialized crowds, but usually high interest.</li>\n<li><strong>Game nights:</strong> Good for social bonding, regulars reliably show up. Poker, <a href=\"http://en.wikipedia.org/wiki/Nomic\" target=\"_blank\">Nomic</a>, <a href=\"http://en.wikipedia.org/wiki/German-style_board_game\" target=\"_blank\">German-style games</a> popular. Games also represent a very stylized domain within which we can practice optimizing - rationalists should reliably win more on average or we're doing something wrong.&nbsp; Note that even folks not playing the game still show up to socialize.</li>\n<li><strong>Group planning/meta:</strong> Draws only core members, so low attendance, but that is actually useful in this context. Worth doing occasionally for feedback and direction if no other avenues exist.</li>\n<li><strong>Structured exercises:</strong> Attendance varies but exercises tend to be highly engaging, we will likely explore with this format more in the future. Our <a href=\"/lw/4fp/fun_and_games_with_cognitive_biases/\" target=\"_blank\">recent fun with cognitive biases</a> is a good example</li>\n<li><strong>Bacchanalia:</strong> Because sometimes, you just really need to party.</li>\n</ul>\n<h3>Group Rationality</h3>\n<p><strong>Spend time with each other:</strong> The biggest benefit of having the community is <em>having the community</em>.&nbsp; Hold meetups often, and use the mailing list to arrange activities outside the meetups as well. Do the things you like doing... together. Get to know other people in the group, figure out who your closest friends are and hang out with them.&nbsp; This is incredibly fun, promotes well-being, and encourages the spread of knowledge. When everyone is feeling good, the positive mood contagion can be overwhelmingly powerful.</p>\n<p><strong>Epistemic privilege and meme-sharing:</strong> The most powerful aspect of a group of rationalists is that you have an entire class of people whose reasoning you trust. Division of labor arises naturally as each member has different interests, they all pursue a variety of skills and areas of expertise, which they can then bring back to the group. Even the lowest-level rationalists in the group can rapidly upgrade themselves by adopting winning heuristics from other group members. I cannot overstate the power of epistemic privilege. We have rapidly spread knowledge about metabolism, exercise, neuroscience, meditation, hypnosis, several systems of therapy... and don't forget the Dark Arts.</p>\n<p><strong>Ask the group for help:</strong> There is a reason we identify as <em>aspiring rationalists</em>, rather than just plain rationalists. Despite our best efforts we are not perfect Bayesians, but at least we know <a href=\"/lw/i9/the_importance_of_saying_oops\" target=\"_blank\">the importance of saying oops</a>. One of the biggest advantages of a group of rationalists is that any of the individual members can ask the group for help when they are feeling indecisive or they think their logic is compromised. When everyone else in the group unanimously agrees with each other and disagrees with us, that's evidence strong enough not to ignore. For the record, the only thing that drives rationalists crazier than loneliness is being in a relationship.</p>\n<p><strong>Be honest with each other:</strong> Maybe this should go without saying, but it bears worth repeating. One of a rationalist's strengths is not identifying with our beliefs, which allows us to <a href=\"/lw/i7/belief_as_attire\" target=\"_blank\">surrender our old attire</a>, <a href=\"http://yudkowsky.net/rational/bayes\" target=\"_blank\">update on new evidence</a>, <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\" target=\"_blank\">and actually change our minds</a>. It is difficult for others to identify errors in our data or reasoning if that entire process is a black box - and by symmetry, if others wish to improve as well, they need to be willing to hear us and we need to be willing to tell them unpleasant truths. Most rationalists I have encountered also tend not to be very judgmental, and this quality makes this kind of communication drastically easier because everyone feels safe. Make your community a place where everyone can give and receive feedback and share their best knowledge of the map without fear.</p>\n<p><strong>Learn to be social, and go forth into the world:</strong> To be frank, many of us are not very good at social interaction, which can definitely be painful, and, when socializing is an important part of our life or job, debilitating. Fortunately, rationalists have a major hack: we can start socializing with each other in a non-judgmental environment. Once some of the benefits of regular social interaction settle in, and people become happier and more comfortable in groups, it becomes increasingly easy to socialize with other people outside the group. There has been a very clear trend towards increased sociability and as a result good social outcomes.</p>\n<p><strong>Most progress is accomplished in small groups:</strong> There is strong consensus that group discussions rarely result in updating, even if they are fun. Conversations of 2 or 3 (maybe 4 at the most), seem to produce the most useful insights. This is why spending time together bilaterally is incredibly important to group development. When a handful of people are all interested in a particular topic and practice it together, they form a de facto working group which allows them to iterate rapidly and then teach it to the rest of the members.</p>\n<p><strong>Set goals and hold each other accountable:</strong> This has been a recent, but powerful, addition to the group. <a href=\"/lw/2p5/humans_are_not_automatically_strategic\" target=\"_blank\">Humans are not automatically strategic</a>, but we have each other to remind us of this fact. The vast majority of people don't even reach the first step of having explicit goals! Not only that, but being a social group allows us to leverage that social pressure on each other - it is legitimately challenging to stand in front of the group and admit that you have not achieved your goal for the week. These goals should either be focused on the most important step that would change your life, or radically push you outside your comfort zone.</p>\n<h2>The Road Ahead</h2>\n<p>The NYC community continues to change and grow, and every week brings something new. The problem of optimizing group rationality is far from solved, and I hope to share insights with Less Wrong as we continue to have them. Our current biggest challenge is that we are outgrowing our usual meetup location as there has been demand for more meetups on a wide variety of topics. Given that our biggest strengths are social in nature, we are beginning to hit <a href=\"/lw/x9/dunbars_function\" target=\"_blank\">fundamental limits on group size</a> above which coordination begins to break down.</p>\n<p>The solution we are currently implementing is <a href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=NYC_meetup_group#Regular_Meetups\" target=\"_blank\">creating multiple groups</a>, each meeting weekly and focused on a different topic. Andrew Rettek is creating a group at Columbia University, focusing on outreach/education and specifically teaching rationality through cognitive biases. My own group is focusing on self-development, which involves goal-setting, skill-sharing, and creating tools to correct errors in reason and emotion - in short, instrumental rationality. Zvi Mowshowitz is running a third group sticking to the core meetups like discussions and game nights, and trying experimental formats as well.&nbsp; Members may attend any meetups they wish during the week, with the goal of decreasing total attendance at each one to keep numbers reasonable - and we will keep creating more groups if these ones get full.</p>\n<p>Most importantly, however, we want to <a href=\"/lw/c4/go_forth_and_create_the_art\" target=\"_blank\">make everything we have done here and everything we have learned <em>reliably reproducible</em></a>.&nbsp; This post is one example of an attempt to codify what steps we have taken to get here from there as a community so that others can begin following our lead, and I fully intend to flesh out each of these in more exact detail. We have also stumbled on a number of useful memes and heuristics, all of which I seek to turn into explicit knowledge: step by step instructions that anyone could follow to achieve similar benefits. Given that much of this knowledge will likely contain implicit components, instructors of these skills should be able to earn profits teaching them to others. <em>Making more money</em> seems to be one of the biggest metrics on which rationalists do not yet perform exceptionally, but if we are truly creating value in the world we should learn how to capture it.</p>\n<h2>Call to Assemble</h2>\n<p>You have now heard my case for group rationality, and it rests upon the individual benefits it incurs: you will be <em>drastically more happy</em>, and you will level up <em>a lot more quickly</em>. Armed with this knowledge, what should you do?</p>\n<p>First of all, if you live in an area which already has a <a href=\"/lw/43s/starting_a_lw_meetup_is_easy/3gbz\" target=\"_blank\">critical mass of rationalists</a> you should take these lessons and <strong>create a community of your own</strong>, so that you and everyone else can reap the rewards. <a href=\"/lw/9m/collective_apathy_and_the_internet\" target=\"_blank\">It is up to you to be the hero</a> - <a href=\"/lw/9j/bystander_apathy\" target=\"_blank\">yes, <em>you</em></a>.&nbsp; One common piece of feedback we get from new members is that Less Wrong discussions are intimidating, and they don't feel qualified to even talk about these topics (much less contribute or become an organizer).&nbsp; They are invariably wrong.</p>\n<p>If you find yourself having to move for any reason, then you should make every attempt you can to <strong>congregate in an area with more people</strong>.&nbsp; Note that in-person interaction requires minimal effective distance between people. There is a strong case to pick NYC: it is a major urban area with a lot of different job opportunities, the unusually good subway system shortens effective distance, and we are creating a model which can scale with additional rationalists. Two alternatives are suburban areas with good highways, or to move within walking distance of other rationalists. Taken to the limit you can share housing with other rationalists, as in the case of the Visiting Fellows program. As the NYC community grows we are naturally clustering around different parts of the city, and we hope to build an intentional community where many of us live together in shared housing.</p>\n<p>You may have had <a href=\"/lw/2c/a_sense_that_more_is_possible\" target=\"_blank\">a sense that more was possible</a>, and if you did then you were correct: groups of rationalists <em>have more fun and win at life</em>, and it's time to scale up the awesome. Whether you decide to make your own home or come join ours, the NYC community will always welcome you with open arms.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 3, "T57Qd9J3AfxmwhQtY": 8, "fkABsGCJZ6y9qConW": 1, "zv7v2ziqexSn5iS9v": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CsKboswS3z5iaiutC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 157, "baseScore": 182, "extendedScore": null, "score": 0.00034, "legacy": true, "legacyId": "6285", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 182, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>It is perhaps the best-kept secret on Less Wrong that the <a href=\"http://wiki.lesswrong.com/wiki/NYC_meetup_group\" target=\"_blank\">New York City community</a> has been meeting regularly for almost two years. For nearly a year we've been meeting weekly or more.&nbsp; The rest of this post is going to be a practical guide to the benefits of group rationality, but first I will do something that is still too rare on this blog: <a href=\"/lw/hp/feeling_rational\" target=\"_blank\">make it clear how strongly I feel about this</a>. Before this community took off, <em>I did not believe that life could be this much fun or that I could possibly achieve such a sustained level of happiness.</em></p>\n<p>Being rational in an irrational world is incredibly lonely. Every interaction reveals that our thought processes differ widely from those around us, and I had accepted that such a divide would always exist. For the first time in my life I have dozens of people with whom I can act freely and <em>revel in the joy of rationality</em> without any social concern - hell, it's actively rewarded! Until the NYC Less Wrong community formed, I didn't realize that I was a forager lost without a tribe...</p>\n<p>Rationalists are still human, and we still have basic human needs. lukeprog <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge\" target=\"_blank\">summarizes the literature on subjective well-being</a>, and the only factors which correlate to any degree are genetics, health, work satisfaction and social life - which actually gets listed <em>three separate times</em> as social activity, relationship satisfaction and religiosity. Rationalists tend to be <a href=\"/lw/28l/do_you_have_highfunctioning_aspergers_syndrome\" target=\"_blank\">less socially adept</a> <a href=\"/lw/2am/aspergers_survey_reresults\" target=\"_blank\">on average</a>, and this can make it difficult to obtain the full rewards of social interaction. However, once rationalists learn to socialize with each other, they also become increasingly social towards everyone more generally. This improves your life. <em>A lot.</em></p>\n<p>We are a group of friends to enjoy life alongside, while we <a href=\"http://en.wikipedia.org/wiki/Synsepalum_dulcificum\" target=\"_blank\">try miracle fruit</a>, dance ecstatically until sunrise, actively embarrass ourselves at karaoke, get lost in the woods, and jump off waterfalls.&nbsp; Poker, paintball, parties, go-karts, concerts, camping... I have a community where I can live in truth and be accepted as I am, where I can give and receive feedback and get help <a href=\"http://wiki.lesswrong.com/wiki/Tsuyoku_naritai\" target=\"_blank\">becoming stronger</a>. I am immensely grateful to have all of these people in my life, and I look forward to every moment I spend with them. To love and be loved is an unparalleled experience in this world, once you actually try it.</p>\n<p>So, you ask, how did all of this get started...?<a id=\"more\"></a></p>\n<h2 id=\"Genesis__or_a_Brief_History_of_Nearly_Everything\">Genesis, or a Brief History of Nearly Everything</h2>\n<p>The origin of the NYC chapter was the <a href=\"http://www.overcomingbias.com/2009/04/nyc-meetup-friday-7pm.html\" target=\"_blank\">April 24th, 2009 meetup</a> that Robin Hanson organized when he came to the city for a prediction markets conference.&nbsp; Approximately 15 people attended over the course of the night, and we all agreed that we had way too much fun together not to do this on a regular basis. I handed out my business cards to everyone there, told them to e-mail me, and I would create a mailing list. Thus <a href=\"http://groups.google.com/group/overcomingbiasnyc\" target=\"_blank\">Overcoming Bias NYC</a> was born.</p>\n<p>It was clear from the very beginning that Jasen Murray was the person most interested in seeing this happen, so he became the organizer of the group for the first year of its existence. At first the times and locations were impromptu, but in August Jasen made the brilliant move of precommitting to be at a specific time and place for a minimum of two hours twice per month. Because enough of us liked Jasen and wanted to hang out with him anyway, several people began showing up every time and a regular meetup was established. Going forward we tried a combination of social meetups, focused discussions and game nights. Jasen also attempted to shift coordination from the mailing list to the <a href=\"http://www.meetup.com/Less-Wrong-Overcoming-Bias-NYC/\" target=\"_blank\">Meetup group</a>, but Meetup is not a great mailing list and people were loathe to use multiple services. That now serves as our public face.</p>\n<p>In April 2010, Jasen departed to run the Visiting Fellows program at SIAI, and I became the group's organizer. We immediately agreed on a number of changes: weekly meetups (with game nights every other week), focused discussions addressing specific problems instead of general theory, and a temporary taboo on discussion of AGI/FAI. We also moved the majority of our meetups from a public diner to a private residence, which avoided a lot of hassles with loud crowds, ordering of food, etc.&nbsp; These changes marked our transition to a social group that focused on practical life benefits. June brought two more key changes: we started holding strategy sessions on request to help members optimize their lives, and I started hugging people, which began a cascade of increasing physical contact. That summer brought an increased interest in skill sharing, a reduced game night frequency, and meetups focused around specific topics. That fall we began using the group more for discussions, sharing social events of mutual interest, and coordinating activities together outside of the weekly meetups.</p>\n<p>Then, in October, things began to accelerate. I told everyone on the list to respond or be removed, to get an idea of numbers and to galvanize the core membership. Several members broke off old relationships and some of them entered new ones within the group. More women started attending; we had previously been almost all male. We began having more contact with the west coast rationalists, including visits by Jasen and Michael Vassar and an extended stay by <a href=\"http://meaningandmagic.com/?c=1\" target=\"_blank\">Divia</a>, which brought valuable new memes to our community. Self-reported levels of fun and happiness began to radically increase. Mailing list discussions turned towards asking for practical advice. The meetups took on a self-improvement focus, with weekly goal-setting and accountability. Andrew Rettek began a <a href=\"http://www.meetup.com/Less-Wrong-Overcoming-Bias-NYC/events/16332288/\" target=\"_blank\">public lecture series</a> presenting the Sequences. Demand for more-than-weekly meetups grew...</p>\n<h2 id=\"Lessons\">Lessons</h2>\n<p>NYC has pioneered creating <a href=\"/lw/5v/church_vs_taskforce\" target=\"_blank\">rationalist communities</a>. While we have largely proceeded via trial and error, the rest of you who are going to become organizers can learn from our experiments and avoid a lot of mistakes. The lessons largely fall under two categories: how to build a group, and what to do with a group once you have one. I hope that you find this advice helpful in your own efforts to establish rationalist communities.</p>\n<h3 id=\"Building_a_Community\">Building a Community</h3>\n<p><strong>Communities need heroes:</strong> Until we have a cadre of paid community organizers, LW meetups will have to run on hero power. Most members are going to be passively attending, a few will actively contribute ideas and activities on the mailing list, but someone needs to be willing to step up as a leader and begin organizing people. Do you want a community badly enough to build one yourself?</p>\n<p><strong>Commitment <em>works</em>:</strong> We started having regular meetings because Jasen committed to showing up at a specific time and place and staying for a minimum length of time, regardless of other attendance. Enough folks wanted to hang out that this resulted in successful meetups.</p>\n<p><strong>Schedule events first, get feedback later:</strong> Trying to ask everyone to state their preferences in order to accommodate them all rarely works and can result in prolonged indecision. Just schedule a time and place and topic; people who want to come but can't will speak up and tell you why. With enough iterations you can settle on something approximately utility maximizing.</p>\n<p><strong>We are a group of friends:</strong> This is the true secret of our success, we are not just a meetup group. We started off as a bunch of people who enjoyed talking about rationality enough that we kept doing it regularly until we became a part of each other's lives. You can tell because we greet each other with hugs instead of handshakes. That physical contact has a profound psychological impact. Furthermore, almost the entire growth of our group has come through friend-referral, not through increased Less Wrong readership. Rationality per se is not the core selling point of the group - people genuinely like hanging out with us, and they tell other people to come hang out with us too.</p>\n<p><strong>Gender ratio matters:</strong> It is no secret that rationality suffers from a <a href=\"/lw/ap/of_gender_and_rationality\" target=\"_blank\">paucity of women</a>, which makes it difficult to start a group with any women at all. There is no easy answer here, but it is important to address this factor as early as possible. Simply put, if you're winning at life and having enough fun women will want to join you, and a balanced gender ratio encourages more people of <em>both genders</em> to attend.&nbsp; Work hard to find interested women, and be careful in the presence of newcomers when trying to sanely explicitly discuss hot-button gender topics.&nbsp; In case the argument for more women is not sufficiently clear, gender-balanced meetups are <em>a lot more fun</em>, and it provides a unique perspective on ideas and group dynamics.</p>\n<p><strong>The mailing list is for more than just meetups:</strong> While scheduling meetups is an obvious function of a group mailing list, it can be used for all manner of discussions and coordination between group members. Given our significant overlapping interests, one function of the list is for people to invite others to join them on their adventures, be that going to conferences, parties, sous-vide steak dinners, rock climbing, or whatever else people feel like doing.&nbsp; Another very important use is to ask the group for advice on a particular subject, like <a href=\"/lw/2tw/love_and_rationality_less_wrongers_on_okcupid\" target=\"_blank\">optimizing OKCupid profiles</a>, learning programming languages, alleviating bad moods, and more! Last but not least, mailing lists make large group discussions on serious questions feasible.</p>\n<p><strong>Interact with outside rationalists as much as possible:</strong> Just as division of labor exists within the group, it also exists among groups. This allows a steady flow of new memes to try out, and an external evaluation of the current group memes. SIAI and the NYC community have been working on different projects and have different perspectives, and it has been extremely helpful to both groups to have more collaboration between them. NYC is also a major city, so we get a lot of visiting rationalists passing through, and people have traveled from neighboring states to attend our events. This provides constant perspective and growth.</p>\n<p><strong id=\"Meetup_topics\">Meetup topics</strong></p>\n<ul>\n<li><strong>Social/unfocused discussions:</strong> Attendance is usually poor, members replied that hanging out is harder to justify than having a specific purpose.</li>\n<li><strong>Discussion topics:</strong> Reliably good attendance and fun. The topics can vary widely, everything from TDT to making money. Note that large group discussions rarely lead to progress/insight on a question, but breaking into smaller sub-groups can work.</li>\n<li><strong>Presentation/skill share:</strong> Depends on the topic, draws specialized crowds, but usually high interest.</li>\n<li><strong>Game nights:</strong> Good for social bonding, regulars reliably show up. Poker, <a href=\"http://en.wikipedia.org/wiki/Nomic\" target=\"_blank\">Nomic</a>, <a href=\"http://en.wikipedia.org/wiki/German-style_board_game\" target=\"_blank\">German-style games</a> popular. Games also represent a very stylized domain within which we can practice optimizing - rationalists should reliably win more on average or we're doing something wrong.&nbsp; Note that even folks not playing the game still show up to socialize.</li>\n<li><strong>Group planning/meta:</strong> Draws only core members, so low attendance, but that is actually useful in this context. Worth doing occasionally for feedback and direction if no other avenues exist.</li>\n<li><strong>Structured exercises:</strong> Attendance varies but exercises tend to be highly engaging, we will likely explore with this format more in the future. Our <a href=\"/lw/4fp/fun_and_games_with_cognitive_biases/\" target=\"_blank\">recent fun with cognitive biases</a> is a good example</li>\n<li><strong>Bacchanalia:</strong> Because sometimes, you just really need to party.</li>\n</ul>\n<h3 id=\"Group_Rationality\">Group Rationality</h3>\n<p><strong>Spend time with each other:</strong> The biggest benefit of having the community is <em>having the community</em>.&nbsp; Hold meetups often, and use the mailing list to arrange activities outside the meetups as well. Do the things you like doing... together. Get to know other people in the group, figure out who your closest friends are and hang out with them.&nbsp; This is incredibly fun, promotes well-being, and encourages the spread of knowledge. When everyone is feeling good, the positive mood contagion can be overwhelmingly powerful.</p>\n<p><strong>Epistemic privilege and meme-sharing:</strong> The most powerful aspect of a group of rationalists is that you have an entire class of people whose reasoning you trust. Division of labor arises naturally as each member has different interests, they all pursue a variety of skills and areas of expertise, which they can then bring back to the group. Even the lowest-level rationalists in the group can rapidly upgrade themselves by adopting winning heuristics from other group members. I cannot overstate the power of epistemic privilege. We have rapidly spread knowledge about metabolism, exercise, neuroscience, meditation, hypnosis, several systems of therapy... and don't forget the Dark Arts.</p>\n<p><strong>Ask the group for help:</strong> There is a reason we identify as <em>aspiring rationalists</em>, rather than just plain rationalists. Despite our best efforts we are not perfect Bayesians, but at least we know <a href=\"/lw/i9/the_importance_of_saying_oops\" target=\"_blank\">the importance of saying oops</a>. One of the biggest advantages of a group of rationalists is that any of the individual members can ask the group for help when they are feeling indecisive or they think their logic is compromised. When everyone else in the group unanimously agrees with each other and disagrees with us, that's evidence strong enough not to ignore. For the record, the only thing that drives rationalists crazier than loneliness is being in a relationship.</p>\n<p><strong>Be honest with each other:</strong> Maybe this should go without saying, but it bears worth repeating. One of a rationalist's strengths is not identifying with our beliefs, which allows us to <a href=\"/lw/i7/belief_as_attire\" target=\"_blank\">surrender our old attire</a>, <a href=\"http://yudkowsky.net/rational/bayes\" target=\"_blank\">update on new evidence</a>, <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\" target=\"_blank\">and actually change our minds</a>. It is difficult for others to identify errors in our data or reasoning if that entire process is a black box - and by symmetry, if others wish to improve as well, they need to be willing to hear us and we need to be willing to tell them unpleasant truths. Most rationalists I have encountered also tend not to be very judgmental, and this quality makes this kind of communication drastically easier because everyone feels safe. Make your community a place where everyone can give and receive feedback and share their best knowledge of the map without fear.</p>\n<p><strong>Learn to be social, and go forth into the world:</strong> To be frank, many of us are not very good at social interaction, which can definitely be painful, and, when socializing is an important part of our life or job, debilitating. Fortunately, rationalists have a major hack: we can start socializing with each other in a non-judgmental environment. Once some of the benefits of regular social interaction settle in, and people become happier and more comfortable in groups, it becomes increasingly easy to socialize with other people outside the group. There has been a very clear trend towards increased sociability and as a result good social outcomes.</p>\n<p><strong>Most progress is accomplished in small groups:</strong> There is strong consensus that group discussions rarely result in updating, even if they are fun. Conversations of 2 or 3 (maybe 4 at the most), seem to produce the most useful insights. This is why spending time together bilaterally is incredibly important to group development. When a handful of people are all interested in a particular topic and practice it together, they form a de facto working group which allows them to iterate rapidly and then teach it to the rest of the members.</p>\n<p><strong>Set goals and hold each other accountable:</strong> This has been a recent, but powerful, addition to the group. <a href=\"/lw/2p5/humans_are_not_automatically_strategic\" target=\"_blank\">Humans are not automatically strategic</a>, but we have each other to remind us of this fact. The vast majority of people don't even reach the first step of having explicit goals! Not only that, but being a social group allows us to leverage that social pressure on each other - it is legitimately challenging to stand in front of the group and admit that you have not achieved your goal for the week. These goals should either be focused on the most important step that would change your life, or radically push you outside your comfort zone.</p>\n<h2 id=\"The_Road_Ahead\">The Road Ahead</h2>\n<p>The NYC community continues to change and grow, and every week brings something new. The problem of optimizing group rationality is far from solved, and I hope to share insights with Less Wrong as we continue to have them. Our current biggest challenge is that we are outgrowing our usual meetup location as there has been demand for more meetups on a wide variety of topics. Given that our biggest strengths are social in nature, we are beginning to hit <a href=\"/lw/x9/dunbars_function\" target=\"_blank\">fundamental limits on group size</a> above which coordination begins to break down.</p>\n<p>The solution we are currently implementing is <a href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=NYC_meetup_group#Regular_Meetups\" target=\"_blank\">creating multiple groups</a>, each meeting weekly and focused on a different topic. Andrew Rettek is creating a group at Columbia University, focusing on outreach/education and specifically teaching rationality through cognitive biases. My own group is focusing on self-development, which involves goal-setting, skill-sharing, and creating tools to correct errors in reason and emotion - in short, instrumental rationality. Zvi Mowshowitz is running a third group sticking to the core meetups like discussions and game nights, and trying experimental formats as well.&nbsp; Members may attend any meetups they wish during the week, with the goal of decreasing total attendance at each one to keep numbers reasonable - and we will keep creating more groups if these ones get full.</p>\n<p>Most importantly, however, we want to <a href=\"/lw/c4/go_forth_and_create_the_art\" target=\"_blank\">make everything we have done here and everything we have learned <em>reliably reproducible</em></a>.&nbsp; This post is one example of an attempt to codify what steps we have taken to get here from there as a community so that others can begin following our lead, and I fully intend to flesh out each of these in more exact detail. We have also stumbled on a number of useful memes and heuristics, all of which I seek to turn into explicit knowledge: step by step instructions that anyone could follow to achieve similar benefits. Given that much of this knowledge will likely contain implicit components, instructors of these skills should be able to earn profits teaching them to others. <em>Making more money</em> seems to be one of the biggest metrics on which rationalists do not yet perform exceptionally, but if we are truly creating value in the world we should learn how to capture it.</p>\n<h2 id=\"Call_to_Assemble\">Call to Assemble</h2>\n<p>You have now heard my case for group rationality, and it rests upon the individual benefits it incurs: you will be <em>drastically more happy</em>, and you will level up <em>a lot more quickly</em>. Armed with this knowledge, what should you do?</p>\n<p>First of all, if you live in an area which already has a <a href=\"/lw/43s/starting_a_lw_meetup_is_easy/3gbz\" target=\"_blank\">critical mass of rationalists</a> you should take these lessons and <strong>create a community of your own</strong>, so that you and everyone else can reap the rewards. <a href=\"/lw/9m/collective_apathy_and_the_internet\" target=\"_blank\">It is up to you to be the hero</a> - <a href=\"/lw/9j/bystander_apathy\" target=\"_blank\">yes, <em>you</em></a>.&nbsp; One common piece of feedback we get from new members is that Less Wrong discussions are intimidating, and they don't feel qualified to even talk about these topics (much less contribute or become an organizer).&nbsp; They are invariably wrong.</p>\n<p>If you find yourself having to move for any reason, then you should make every attempt you can to <strong>congregate in an area with more people</strong>.&nbsp; Note that in-person interaction requires minimal effective distance between people. There is a strong case to pick NYC: it is a major urban area with a lot of different job opportunities, the unusually good subway system shortens effective distance, and we are creating a model which can scale with additional rationalists. Two alternatives are suburban areas with good highways, or to move within walking distance of other rationalists. Taken to the limit you can share housing with other rationalists, as in the case of the Visiting Fellows program. As the NYC community grows we are naturally clustering around different parts of the city, and we hope to build an intentional community where many of us live together in shared housing.</p>\n<p>You may have had <a href=\"/lw/2c/a_sense_that_more_is_possible\" target=\"_blank\">a sense that more was possible</a>, and if you did then you were correct: groups of rationalists <em>have more fun and win at life</em>, and it's time to scale up the awesome. Whether you decide to make your own home or come join ours, the NYC community will always welcome you with open arms.</p>", "sections": [{"title": "Genesis, or a Brief History of Nearly Everything", "anchor": "Genesis__or_a_Brief_History_of_Nearly_Everything", "level": 1}, {"title": "Lessons", "anchor": "Lessons", "level": 1}, {"title": "Building a Community", "anchor": "Building_a_Community", "level": 2}, {"title": "Meetup topics", "anchor": "Meetup_topics", "level": 3}, {"title": "Group Rationality", "anchor": "Group_Rationality", "level": 2}, {"title": "The Road Ahead", "anchor": "The_Road_Ahead", "level": 1}, {"title": "Call to Assemble", "anchor": "Call_to_Assemble", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "172 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 173, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SqF8cHjJv43mvJJzx", "33KewgYhNSxFpbpXg", "vHDk5xr9JDC64rb8T", "nTqmCQvqsrJrryE2c", "p5DmraxDmhvMoZx8J", "xsyG7PkMekHud2DMK", "yeCZb6zkS9bvuLbqa", "Ytr4dJT79sCBuuEjG", "wCqfCLs8z5Qw4GbKS", "nYkMLFpx77Rz3uo9c", "PBRWb2Em5SNeWYwwB", "W5PhyEQqEWTcpRpqn", "aFEsqd6ofwnkNqaXo", "NnQbfLo868wgnHF4n", "K5nq3KcDXaGm7QQWR", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T22:47:50.777Z", "modifiedAt": null, "url": null, "title": "Anki on Android in 60 seconds", "slug": "anki-on-android-in-60-seconds", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:07.977Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XMA72b7yA9pnKKLHs/anki-on-android-in-60-seconds", "pageUrlRelative": "/posts/XMA72b7yA9pnKKLHs/anki-on-android-in-60-seconds", "linkUrl": "https://www.lesswrong.com/posts/XMA72b7yA9pnKKLHs/anki-on-android-in-60-seconds", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anki%20on%20Android%20in%2060%20seconds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnki%20on%20Android%20in%2060%20seconds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMA72b7yA9pnKKLHs%2Fanki-on-android-in-60-seconds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anki%20on%20Android%20in%2060%20seconds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMA72b7yA9pnKKLHs%2Fanki-on-android-in-60-seconds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMA72b7yA9pnKKLHs%2Fanki-on-android-in-60-seconds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 192, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Spaced_repetition\">Spaced repetition</a> is one of the most efficient ways to learn new things. (For research citations, see 'Study methods', <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">here</a>.)</p>\n<p>The best way to practice spaced repetition is to install <a href=\"http://ankisrs.net/\">Anki</a> to your phone, since you have your phone with you all day long.</p>\n<p>I have an Android phone, so here's my 60-second guide to getting started with Anki on Android:</p>\n<p>&nbsp;</p>\n<ol>\n<li>On your Android phone, open 'Market.'</li>\n<li>Search for 'Anki'.</li>\n<li>Install the 'AnkiDroid Flashcards' app.</li>\n<li>In your app drawer, run 'AnkiDroid'.</li>\n<li>It will prompt that you don't have any decks downloaded. Tap 'Download deck' and choose 'Shared decks.'</li>\n<li>It will take a while to bring up the list of decks available online. Search for 'Less Wrong' and you'll see the deck called 'Less Wrong Sequences.' Download it.</li>\n<li>Go back to the AnkiDroid main screen, choose 'Load other deck.' Choose 'Less Wrong Sequences.'</li>\n<li>Set your options for 'New cards per day', 'session limit (minutes)', and 'session limit (questions)', then tap 'Start Reviewing.'</li>\n</ol>\n<div>That's it!</div>\n<div>(This full process will take longer than 60 seconds because of download speed, but will probably require only 60 seconds of interaction with the phone.)</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XMA72b7yA9pnKKLHs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 18, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "6286", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-17T23:13:14.339Z", "modifiedAt": null, "url": null, "title": "Junkie AI?", "slug": "junkie-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:21.183Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Skatche", "createdAt": "2011-01-01T21:34:33.025Z", "isAdmin": false, "displayName": "Skatche"}, "userId": "sdFHhNSzievXc7TuM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qwqDxQ8pgtpPHf9z8/junkie-ai", "pageUrlRelative": "/posts/qwqDxQ8pgtpPHf9z8/junkie-ai", "linkUrl": "https://www.lesswrong.com/posts/qwqDxQ8pgtpPHf9z8/junkie-ai", "postedAtFormatted": "Thursday, March 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Junkie%20AI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJunkie%20AI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwqDxQ8pgtpPHf9z8%2Fjunkie-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Junkie%20AI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwqDxQ8pgtpPHf9z8%2Fjunkie-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwqDxQ8pgtpPHf9z8%2Fjunkie-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 187, "htmlBody": "<p><a href=\"/lw/4t8/the_friendly_ai_game/3p4x\">bentarm</a> writes:</p>\n<p style=\"padding-left: 30px;\">I'm just echoing everyone else here, but I don't understand why the AI would do anything at all other than just immediately find the INT_MAX utility and halt - you can't put intermediate problems with some positive utility because the AI <em>is smarter than you</em> and will immediately devote all its energy to finding INT_MAX.</p>\n<p>Now, this is in response to a proposed AI who gets maximum utility when inside its box.&nbsp; Such an AI would effectively be a utility junkie, unable to abandon its addiction and, consequently, unable to do much of anything.</p>\n<p>(EDIT: this is a misunderstanding of the original idea by <a href=\"/lw/4t8/the_friendly_ai_game/3ozn\">jimrandomh</a>.&nbsp; See comment <a href=\"/lw/4uo/junkie_ai/3pic\">here</a>.)</p>\n<p>However, doesn't the same argument apply to any AI?&nbsp; Under the supposition that it would be able to modify its own source code, the quickest and easiest way to maximize utility would be to simply set its utility function to infinity (or whatever the maximum is) and then halt.&nbsp; Are there ways around this?&nbsp; It seems to me that any AI will need to be divided against itself if it's ever going to get anything done, but maybe I'm missing something?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qwqDxQ8pgtpPHf9z8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 2, "extendedScore": null, "score": 6.912249479797606e-07, "legacy": true, "legacyId": "6288", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T03:22:13.685Z", "modifiedAt": null, "url": null, "title": "What comes before rationality", "slug": "what-comes-before-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:54.051Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cAvbCQtgCMxbn4dBq/what-comes-before-rationality", "pageUrlRelative": "/posts/cAvbCQtgCMxbn4dBq/what-comes-before-rationality", "linkUrl": "https://www.lesswrong.com/posts/cAvbCQtgCMxbn4dBq/what-comes-before-rationality", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20comes%20before%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20comes%20before%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcAvbCQtgCMxbn4dBq%2Fwhat-comes-before-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20comes%20before%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcAvbCQtgCMxbn4dBq%2Fwhat-comes-before-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcAvbCQtgCMxbn4dBq%2Fwhat-comes-before-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p><!--StartFragment--></p>\r\n<p class=\"MsoNormal\">Note:&nbsp;I am deleting this post&nbsp;because it contained personal information about a friend whose permission I did not expressly obtain.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cAvbCQtgCMxbn4dBq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 15, "extendedScore": null, "score": 8e-06, "legacy": true, "legacyId": "6294", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 94, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T04:13:23.945Z", "modifiedAt": null, "url": null, "title": "Preschoolers learning to guess the teacher's password [link]", "slug": "preschoolers-learning-to-guess-the-teacher-s-password-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:50.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mRG4DGeCeYf5Aq4uZ/preschoolers-learning-to-guess-the-teacher-s-password-link", "pageUrlRelative": "/posts/mRG4DGeCeYf5Aq4uZ/preschoolers-learning-to-guess-the-teacher-s-password-link", "linkUrl": "https://www.lesswrong.com/posts/mRG4DGeCeYf5Aq4uZ/preschoolers-learning-to-guess-the-teacher-s-password-link", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Preschoolers%20learning%20to%20guess%20the%20teacher's%20password%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APreschoolers%20learning%20to%20guess%20the%20teacher's%20password%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmRG4DGeCeYf5Aq4uZ%2Fpreschoolers-learning-to-guess-the-teacher-s-password-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Preschoolers%20learning%20to%20guess%20the%20teacher's%20password%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmRG4DGeCeYf5Aq4uZ%2Fpreschoolers-learning-to-guess-the-teacher-s-password-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmRG4DGeCeYf5Aq4uZ%2Fpreschoolers-learning-to-guess-the-teacher-s-password-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 316, "htmlBody": "<p>A <a href=\"http://www.slate.com/id/2288402/pagenum/all/#p2\">Slate article</a> by psychologist Alison Gopnik about how preschoolers have already learned to <a href=\"http://wiki.lesswrong.com/wiki/Guessing_the_teacher%27s_password\">accept what the teacher says</a> rather than exploring things to develop their own understanding:</p>\n<blockquote>\n<p>[...] Daphna ran through the same nine sequences with all the children, but with one group, she acted as if she were clueless about the toy. (\"Wow, look at this toy. I wonder how it works? Let's try this,\" she said.) With the other group, she acted like a teacher. (\"Here's how my toy works.\") When she acted clueless, many of the children figured out the most intelligent way of getting the toy to play music (performing just the two key actions, something Daphna had not demonstrated). But when Daphna acted like a teacher, the children imitated her exactly, rather than discovering the more intelligent and more novel two-action solution.</p>\n<p>[...]</p>\n<p>These experts in machine learning argue that learning from teachers first requires you to learn <em>about</em> teachers. For example, if you know how teachers work, you tend to assume that they are trying to be informative. When the teacher in the tube-toy experiment doesn't go looking for hidden features inside the tubes, the learner unconsciously thinks: \"She's a teacher. If there were something interesting in there, she would have showed it to me.\" These assumptions lead children to narrow in, and to consider just the specific information a teacher provides. Without a teacher present, children look for a much wider range of information and consider a greater range of options.</p>\n</blockquote>\n<p>This experiment is from:</p>\n<p>D. Buchsbaum, A. Gopnik, T.L. Griffiths, and P. Shafto (2011). Children's imitation of causal action sequences is influenced by statistical and pedagogical evidence. <em>Cognition</em> (in press). <a href=\"http://www.alisongopnik.com/Papers_Alison/overimitation-journal-article-11-28-10.pdf\">pdf</a></p>\n<p>The other paper cited in the Slate article is:</p>\n<p>E. Bonawitz, P. Shafto, H. Gweon, N.D. Goodman, E. Spelke, and L. Schulz (2011). The double-edged sword of pedagogy: Instruction limits spontaneous exploration and discovery. <em>Cognition</em> (in press). <a href=\"http://web.mit.edu/eccl/papers/The%20double-edged%20sword%20of%20pedagogy.pdf\">pdf</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mRG4DGeCeYf5Aq4uZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 34, "extendedScore": null, "score": 6.913069935859153e-07, "legacy": true, "legacyId": "6296", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T05:33:40.771Z", "modifiedAt": null, "url": null, "title": "Sublimity vs. Youtube", "slug": "sublimity-vs-youtube", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.375Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L9Z2Pt6KjJLEnSzB7/sublimity-vs-youtube", "pageUrlRelative": "/posts/L9Z2Pt6KjJLEnSzB7/sublimity-vs-youtube", "linkUrl": "https://www.lesswrong.com/posts/L9Z2Pt6KjJLEnSzB7/sublimity-vs-youtube", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sublimity%20vs.%20Youtube&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASublimity%20vs.%20Youtube%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL9Z2Pt6KjJLEnSzB7%2Fsublimity-vs-youtube%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sublimity%20vs.%20Youtube%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL9Z2Pt6KjJLEnSzB7%2Fsublimity-vs-youtube", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL9Z2Pt6KjJLEnSzB7%2Fsublimity-vs-youtube", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 320, "htmlBody": "<p>The <a href=\"/lw/kn/torture_vs_dust_specks/\">torture vs. dust specks</a> quandary is a canonical one to LW.&nbsp; Off the top of my head, I can't remember anyone suggesting the reversal, one where the arguments taken by the hypothetical are positive and not negative.&nbsp; I'm curious about how it affects people's intuitions.&nbsp; I call it - as the title indicates - \"Sublimity vs. Youtube<sup>1</sup>\".</p>\n<p>Suppose the impending existence of some person who is going to live to be fifty years old whatever you do<sup>2</sup>.&nbsp; She is liable to live a life that zeroes out on a utility scale: mediocre ups and less than shattering downs, overall an unremarkable span.&nbsp; But if you choose \"sublimity\", she's instead going to live a life that is truly <em>sublime</em>.&nbsp; She will have a warm and happy childhood enriched by loving relationships, full of learning and wonder and growth; she will mature into a merrily successful adult, pursuing meaningful projects and having varied, challenging fun.&nbsp; (For the sake of argument, suppose that the ripple effects of her sublime life as it affects others still lead to the math tallying up as +(1 sublime life), instead of +(1 sublime life)+(various lovely consequences).)</p>\n<p>Or you can choose \"Youtube\", and 3^^^3 people who weren't doing much with some one-second period of their lives instead get to spend that second watching a brief, grainy, yet droll recording of a cat jumping into a box, which they find mildly entertaining.</p>\n<p>Sublimity or Youtube?</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>The choice in my variant scenario of \"watching a Youtube video\" rather than some small-but-romanticized pleasure (\"having a butterfly land on your finger, then fly away\", for instance) is deliberate.&nbsp; Dust specks are <em>really</em> tiny, and there's not much automatic tendency to emotionally inflate them.&nbsp; Hopefully Youtube videos are the reverse of that.</p>\n<p><sup>2</sup>I'm choosing to make it an alteration of a person who will exist either way to avoid questions about the utility of creating people, and for greater isomorphism with the \"torture\" option in the original.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1, "ZTRNmvQGgoYiymYnq": 1, "HAFdXkW4YW4KRe2Gx": 1, "Zs4nYLkNr7Rbo4mAP": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L9Z2Pt6KjJLEnSzB7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 31, "extendedScore": null, "score": 6.913289403220727e-07, "legacy": true, "legacyId": "6297", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T05:35:13.527Z", "modifiedAt": null, "url": null, "title": "Towards a Bay Area Less Wrong Community", "slug": "towards-a-bay-area-less-wrong-community", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N8DaeP83CSgKnjcid/towards-a-bay-area-less-wrong-community", "pageUrlRelative": "/posts/N8DaeP83CSgKnjcid/towards-a-bay-area-less-wrong-community", "linkUrl": "https://www.lesswrong.com/posts/N8DaeP83CSgKnjcid/towards-a-bay-area-less-wrong-community", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Towards%20a%20Bay%20Area%20Less%20Wrong%20Community&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATowards%20a%20Bay%20Area%20Less%20Wrong%20Community%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8DaeP83CSgKnjcid%2Ftowards-a-bay-area-less-wrong-community%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Towards%20a%20Bay%20Area%20Less%20Wrong%20Community%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8DaeP83CSgKnjcid%2Ftowards-a-bay-area-less-wrong-community", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8DaeP83CSgKnjcid%2Ftowards-a-bay-area-less-wrong-community", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 812, "htmlBody": "<p>Follow up to: <a href=\"/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">Less Wrong NYC</a></p>\n<p><em>Tl;dr:&nbsp; <strong>Two new regular weekly meetups </strong>in the Bay Area:&nbsp; In the <strong><a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Berkeley Starbucks</a></strong> on Wednesdays at 7pm (host Lucas Sloan), and in <strong><a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=850+Williams+Way+Mountain+View,+CA&amp;aq=&amp;sll=37.875513,-122.256809&amp;sspn=0.008604,0.024054&amp;ie=UTF8&amp;hq=&amp;hnear=850+Williams+Way,+Mountain+View,+Santa+Clara,+California+94040&amp;ll=37.374625,-122.058749&amp;spn=0.017325,0.048108&amp;z=15\">Tortuga</a> (in Mountain View) </strong>on Thursdays at 7pm (hosts Shannon Friedman and <a href=\"/user/divia\">Divia </a><span class=\"gI\"><a href=\"/user/divia\">Melwani</a></span></em><em>).&nbsp; New <a href=\"http://groups.google.com/group/bayarealesswrong\">Google Group for the whole Bay Area</a>, all welcome to join.</em></p>\n<p>Hi everyone in the (San Fransisco) Bay Area.&nbsp; I'm Lucas Sloan and I've been organizing LW meet ups in Berkeley for about 8 months now.&nbsp; I think that we've accomplished great things in that time, the last week's had about 40 people show up, which is a number that was beyond my wildest dreams when I held my <a href=\"/lw/2o2/berkeley_lw_meetup_sunday_september_5/\">first meet up</a> and 7 people showed up.&nbsp; As good as things are, I've been spending a lot of time thinking how we can do even better in the future.&nbsp; The main catalyst in my thinking has been the accounts I've been hearing over the last two months from people who've visited the New York Less Wrong group and the amazingly positive reactions people have had to their accomplishments.&nbsp; Now that Cosmos has written a post describing what he sees as their successes, I think now is an excellent time to start a discussion about the future of the Bay Area Less Wrong group, and how to make it <em>awesome</em>.</p>\n<p>The main thing that the New York group has that I want for the Bay Area group is a sense of being a close-knit <em>community</em> of like-minded friends.&nbsp; At a Berkeley meet up we get into all sorts of very interesting conversations with our fellow rationalists, but I don't feel a personal connection with most of the people who come to meet-ups, even those people I've seen at many - I am friendly with everyone who comes to meet-ups, but I am not friends with everyone who comes.&nbsp; I see two things that contribute to this problem (though I'm sure there are more) - size of meet-ups, and the frequency of meet ups.&nbsp; The large size of meet ups makes it impossible to establish rapport with everyone, because there is no way to have a good conversation with 40 other people in 4 hours.&nbsp; Even more insidious, the large size makes it hard to establish rapport with even a subset of the people who come to a meet up - the group of 40 splits into 10 groups of 4 and everyone keeps churning between conversations as their interest wanes and waxes.&nbsp; The first meet up I held, with only 7 people, was socially fulfilling in a way that recent ones simply haven't been - everyone was participating in the same conversation, and everyone was getting to know everyone else.&nbsp; As to the frequency of meet ups, it's hard to become friends with people you only interact with once a month - you can easily forget a person in a month, and the format encourages talking about high minded \"rational\" topics, not the personal small talk that forms the basis of friendship.<a id=\"more\"></a></p>\n<p>My (partial) solution to those two problems is one and the same - increase the number of meet ups.&nbsp; Meeting weekly instead of monthly helps the frequency problem directly, but it should also help with the intimacy of the event - with more meet ups, there's less pressure to have to show up to <em>this</em> one.&nbsp; I don't think that increasing the number of meet ups will automatically result in a sense of community, but it definitely seems like a good first step.&nbsp; To this end, I am happy to announce that there will now be 2 weekly meet ups it the Bay Area, I will be hosting meet ups on Wednesdays at 7 pm at the usual <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Starbucks</a>, to starting March 23.&nbsp; Shannon Friedman and <a href=\"/user/divia\">Divia </a><span class=\"gI\"><a href=\"/user/divia\">Melwani</a> will be hosting meet ups on Thursdays at 7 pm at <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=850+Williams+Way+Mountain+View,+CA&amp;aq=&amp;sll=37.875513,-122.256809&amp;sspn=0.008604,0.024054&amp;ie=UTF8&amp;hq=&amp;hnear=850+Williams+Way,+Mountain+View,+Santa+Clara,+California+94040&amp;ll=37.374625,-122.058749&amp;spn=0.017325,0.048108&amp;z=15\">Tortuga</a>, starting March</span> 24.&nbsp; In time, I hope to differentiate the content of my meet-ups, but for the foreseeable future they will take the form of dinner get togethers.&nbsp; I will continue to advertise an \"Official\" Meet Up one Saturday per month, and that would probably be the best time to invite friends and introduce new people to the group.&nbsp; In the meantime, I've created a <a href=\"http://groups.google.com/group/bayarealesswrong\">google group</a> for the Bay Area community, everyone who is at all interested should join.</p>\n<p><span id=\":1hz\" dir=\"ltr\">I don't want everyone to take my vision as gospel; I hope everyone will help generate ideas for improvement of the community, and any feedback at all is helpful. &nbsp;Please talk about your reactions to meet ups, my plans, and your plans in the comments.&nbsp; If you're interested in running a meeting, please speak up.&nbsp; I want to thank Shannon and Divia for holding South Bay meetings, and everyone who has inspired me to run meet ups.&nbsp; Everyone has to have a hand in this - communities are necessarily a group effort.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zz3HWyByyKF64Sfns": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N8DaeP83CSgKnjcid", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 32, "extendedScore": null, "score": 6.913293629417766e-07, "legacy": true, "legacyId": "6287", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CsKboswS3z5iaiutC", "yCQxfPmP3LKrduozt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T17:13:32.203Z", "modifiedAt": null, "url": null, "title": "Computer-mediated communication and the sense of social connectedness", "slug": "computer-mediated-communication-and-the-sense-of-social", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:01.150Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rhollerith_dot_com", "createdAt": "2009-06-16T06:01:16.623Z", "isAdmin": false, "displayName": "rhollerith_dot_com"}, "userId": "bumwHGrDqhTTPqWs2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BukrgLpeXnryxmwDa/computer-mediated-communication-and-the-sense-of-social", "pageUrlRelative": "/posts/BukrgLpeXnryxmwDa/computer-mediated-communication-and-the-sense-of-social", "linkUrl": "https://www.lesswrong.com/posts/BukrgLpeXnryxmwDa/computer-mediated-communication-and-the-sense-of-social", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Computer-mediated%20communication%20and%20the%20sense%20of%20social%20connectedness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComputer-mediated%20communication%20and%20the%20sense%20of%20social%20connectedness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBukrgLpeXnryxmwDa%2Fcomputer-mediated-communication-and-the-sense-of-social%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Computer-mediated%20communication%20and%20the%20sense%20of%20social%20connectedness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBukrgLpeXnryxmwDa%2Fcomputer-mediated-communication-and-the-sense-of-social", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBukrgLpeXnryxmwDa%2Fcomputer-mediated-communication-and-the-sense-of-social", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 358, "htmlBody": "<p>IMHO there is little chance that an <em>online-only</em> community could replicate the successes (many friendships among the members, very high levels of enjoyment, motivation and engagement) of LW NYC.</p>\n<p>Why not? Well, at the risk of putting off those readers who dislike explanations from evolutionary psychology, friendship relies on complex functional adaptations that were \"tuned\" or \"designed\" by natural selection for an environment in which every friendship has significant costs. By \"costs\" I mean that either the friends had to pay the <em>social</em> cost (which was significant in the ancestral environment) of being seen to be talking to each other <em>or</em> they had to go to significant trouble to talk without being observed. Even after the rise of the city (where unlike in the ancestral environment, most observers do not care who you talk to) maintaining a friendship had costs, in that the friends have to commit to being at a particular location at a particular time, incur transportation costs, etc.</p>\n<p>My theory is that there is important information in whether (and how readily) a friend continues to choose to incur the costs of maintaining an off-line friendship and that when that source information is lost, most people have trouble accurately assessing the value of the relationship and start to make bad decisions on how much time and mental energy to invest in the relationship.</p>\n<p>IMHO the same argument from evolutionary psychology holds to a lesser extent for the sense of belonging that people feel for various groups and communities. There was for example probably nothing like a lurker in any community before the online communities enabled by the BBS, the (now defunct) proprietary computer networks and the global internet.</p>\n<p>Online-only communities and using the internet to keep up with friends can be extremely useful of course, but a person should watch out for the common failure mode in which online participation lulls one into a false sense of belonging or connectedness which prevents one from deriving the benefits people can get from things like NYC LW and the visiting fellow program in the Bay Area -- benefits that most people here should pursue and that are not available without face-to-face interaction.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BukrgLpeXnryxmwDa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 6.915203167342623e-07, "legacy": true, "legacyId": "6303", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-18T22:28:58.497Z", "modifiedAt": null, "url": null, "title": "Melbourne meetup", "slug": "melbourne-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.113Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "4226XqZuqq6N4Qore", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/74Lz8zgPmxcdGghAq/melbourne-meetup", "pageUrlRelative": "/posts/74Lz8zgPmxcdGghAq/melbourne-meetup", "linkUrl": "https://www.lesswrong.com/posts/74Lz8zgPmxcdGghAq/melbourne-meetup", "postedAtFormatted": "Friday, March 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Melbourne%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMelbourne%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F74Lz8zgPmxcdGghAq%2Fmelbourne-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Melbourne%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F74Lz8zgPmxcdGghAq%2Fmelbourne-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F74Lz8zgPmxcdGghAq%2Fmelbourne-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 287, "htmlBody": "<p><strong>Note: There has been some discussion of a chance of venue. I suggest we leave it the same at this stage as some people might not realise these discussions have been happening.</strong> <strong>However, we could then consider moving onto Trike if that seemed suitable? I'm happy to give people my mobile no if they message me if it helps for co-ordinating (especially if they're likely to be late - just in case we've moved venue).</strong></p>\n<p>Melbourne (Australia) meetup.</p>\n<p>Date: Saturday, April 2nd at 1pm</p>\n<p>Where: <strong></strong><strong><a href=\"http://foursquare.com/venue/368509\">Don Tojo</a></strong></p>\n<p>What: I've never been to a meetup before but others seem to feel that discussion topics work well?</p>\n<p>Possible topics (open for debate but as there's no discussion in the comments about this I thought I'd better come up with some structure for the meetup):</p>\n<p>1. Sequence discussion - everyone chooses a post from the sequence they think is interesting and we discuss each in turn.</p>\n<p>2. <a title=\"Paranoid debating\" href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">Paranoid debating</a> - As a group we discuss what we think the answer is to a quantifiable question (the example given is, \"How much maize is produced in Mexico annually?\") except some people have been assigned the role of deceiver. The group comes up with a final answer and are scored according to how close it is except for the deceiver, who is scored based on how far away it is).</p>\n<p>3. Talk on a topic - Any group member who feels comfortable doing so gives a brief speech on a topic they're knowledgeable about. It can be related to Less Wrong themes - rationality, psychology, biases, AI, Bayesianism, instrumental rationality - or alternatively can be on another topic if the person is more comfortable with that.</p>\n<p>Let me know below if you're interested.</p>\n<p>People interested so far:</p>\n<p>Me</p>\n<p>Waveman</p>\n<p>Nshepperd</p>\n<p>SharePhoenix</p>\n<p>Luminosity</p>\n<p>Jayzee</p>\n<p>A masque of Reason</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "74Lz8zgPmxcdGghAq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "6304", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T00:16:35.376Z", "modifiedAt": null, "url": null, "title": "Effective Rationality Outreach", "slug": "effective-rationality-outreach", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:02.646Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/67JaiGAe6SuNHKoLk/effective-rationality-outreach", "pageUrlRelative": "/posts/67JaiGAe6SuNHKoLk/effective-rationality-outreach", "linkUrl": "https://www.lesswrong.com/posts/67JaiGAe6SuNHKoLk/effective-rationality-outreach", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Effective%20Rationality%20Outreach&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEffective%20Rationality%20Outreach%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F67JaiGAe6SuNHKoLk%2Feffective-rationality-outreach%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Effective%20Rationality%20Outreach%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F67JaiGAe6SuNHKoLk%2Feffective-rationality-outreach", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F67JaiGAe6SuNHKoLk%2Feffective-rationality-outreach", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2044, "htmlBody": "<p>I believe that the number of smart rationalists has a profound influence on the quality of the future, so I would like to spread rationality at the maximum possible rate. In fact I believe this is the most important problem which I can work on right now. This post describes some of my beliefs about rationality outreach. The purpose of this post is threefold. First, by exposing my beliefs to criticism I hope to improve them. Second, by communicating my beliefs I hope to help others with similar goals. Third, by engaging in more concrete discussion of rationality outreach I hope to increase the probability that others will work seriously on the problem.</p>\n<p><br /><strong>What Should be Taught?</strong></p>\n<p>\"Spread rationality\" is a rather vague and unhelpful goal. Here are three behaviors / habits of mind which I believe would make the world a much better place if they caught on among smart people.<br /><br />1. <em>Desire for accurate beliefs.</em> Many people don't feel that improving the quality of their beliefs is worthwhile. This is a combination of a failure to recognize exactly how wrong many of their beliefs are and a general perception that it doesn't matter anyway. Society as a whole is assumed to be \"basically right,\" even by people who verbally acknowledge rather serious failures of humanity's collective rationality. This is related to the perception that there is no free lunch: as humans we resist the suggestion that we can get anything for free, and acting intelligently seems to be considered too easy. The other side of this bias is a reluctance to believe that incorrect beliefs can really do any damage. <br /><br />2. <em>Mindful living.</em> Many people direct incredible intelligence towards solving problems they encounter in their work, but fail to apply that intelligence to understanding the sources of their own beliefs/emotions, clarifying/refining their goals, or considering how to direct their resources to obtain those goals. <br /><br />3. <em>Initiative and confidence.</em> It is very easy to believe that the world is a crazy place but that an individual has no power to change it. Regardless of how true that may be (my experience suggests not very), the world would probably be a better place if more really intelligent people internalized the belief that their actions change the world. Believing that your life is high stakes--that the potential upside is large--seems to be well correlated with doing great good.<br /><strong><br />Why Would People Listen?</strong><br /><br />Unfortunately, the majority of smart people don't believe that improving their own rationality is worthwhile (related to point 1 above). Someone who considers rationality a waste of time is unlikely to engage seriously with material presented in the context of rationality training, and they are likely to be driven off rapidly by perceived proselytizing. They are unlikely to take seriously a website dedicated to rationality, read a book dedicated to rationality, go to a talk about rationality, etc. Moreover, spreading rationality is not really about transferring knowledge. In order to change someone's behavior, they need a good reason to file advice about \"rationality\" into the compartment that actually affects behavior, and in general \"because rationality is useful\" does not constitute a sufficiently compelling reason (even if it is accepted as fact in the compartment for controlling beliefs). <br /><br />Finding ways around this problem is one of the main difficulties of rationality outreach. I know one approach which seems to work, at least anecdotally and from personal experience: attach rationality as a rider on content intelligent people want to consume, and which requires or encourages engagement on its own terms. Some examples:<br /><br />1. <em>Educational materials.</em> Though smart people don't generally want to improve their own rationality, they generally do want to learn. Interesting topics presented clearly for an intelligent reader seem to have a wide audience. Many subjects do not yet have particularly excellent expositions on the internet, and good teachers/mentors are always in short supply. <br /><br />2. <em>Competition.</em> Interesting forms of competition exert a strong draw on many smart people. I believe that the world could support more formal competitions aimed at a broad range of ages.<br /><br />3. <em>Entertainment.</em> The success of HP:MoR is some indication of the desire for intelligent science fiction / fantasy. In the case of video games there is an incredible shortage of high-quality games targetted at a really smart audience. Filling either of these vacuums well can draw a huge audience.<br /><br />My belief is that intelligent rationalists can produce content significantly above common standards (from the perspective of an intelligent young person) in any of these forms.<br /><br /><strong>How Is Rationality Attached?<br /><br /></strong>Having an audience is not automatically useful. How do you convert people engaging with your content into people changing their behavior?<br /><br />1. <em>Choose effective content.</em> Most critically: choose content which communicates the lessons you want to impart. Teach classes in a way that suggests that more is possible, encourages curiosity, conveys the usefulness of the material and its ability to anticipate and control real things, and gives a really smart student enough background and confidence to attack some important questions on their own. Run competitions and design games at which rationalists really do win, in which defeat really does suggest that more is possible, and in which your opponent's / other participant's innate virtuosity is not an excuse.<br /><br />2. <em>Force decompartamentalization</em>. My experience is that once a source manages to change any aspect of your life, it becomes immensely more likely that it will change your life in other ways. Though this wades into dark arts territory, exploiting it seems to be important. If you introduce a student to a field they come to care about and do work in, the probability of affecting their behavior in other ways is increased enormously. More subtly, if you run a program or competition that requires any material investment (perhaps just going to a physical location) then its probability of affecting behavior may be significantly increased. If you design content that forces the audience to step back and re-evaluate anything at all about their life, then your chances of having a serious impact are seriously increased. <br /><br />3. <em>Foster the impression that individuals influence the world, not just the other way around. </em>Talking about rationality explicitly in general is probably not going to get traction except in special cases. Trying to convince someone that their actions change the world is flattering enough that it might work if there is not enough resistance. If you really believe this, then the quality of your beliefs starts to matter. The possibility of real improvement becomes concrete, and understanding why improvement is hard becomes a priority. I think I might be being a little too optimistic here by believing that you can do any good in this way, but it deserves trying.<br /><br />4. <em>Channel the community.</em> If given the opportunity, communitites often crystallize around engaging content. I have little expertise at influencing communities, but I can say empirically that the direction of community discussion and involvement can be significantly influenced by authority, either directly or indirectly.</p>\n<p><strong>Who is the Audience?</strong></p>\n<p>I believe that outreach is more likely to succeed and more important when the audience is intelligent. Until I have a better understanding of effective outreach, I intend to focus on an extremely small slice of the population at the upper end of general intelligence. For example, I am interested in outreach to high school students. I currently intend to target materials at what I believe to be the top ~10,000 students based on my experience. Details this precise are likely to change, but this at least gives a sense of what I am talking about.</p>\n<p><strong>How?</strong><br /><br />Supposing I decide that trying desperately to spread rationality is the best use of my time: how do I get there from here? What do I actually do? Of course a reasonable plan (in great generality) is to earn as much money as possible and give it to someone you trust to spend it as well as possible. The question is whether it is possible to do better. I believe that in some cases it is. Here are my thoughts on what we can do.<br /><br />1. <em>Invest free time.</em> Cultivate hobbies and interests that allow you to spread rationality for fun, or when you need a break from work. Teaching classes or engaging in mentorship can help you understand how people learn and how they react to attempts at spreading rationality; acquire evidence and share it. Develop online resources that interest you--games, fiction, interactive tutorials, blogs--which might spark an interest in rationality or self-improvement. More importantly, try and gain an understanding of how smart but not necessarily rational people respond to efforts. If you can't find anything that interests you enough to do for fun, if you think the problem is really important you can view the project as work on the side.&nbsp; <br /><br />2. <em>Make money.</em> People pay money to participate in academic programs, advertisers pay money for access to a well-defined audience, and people consistently pay money for valuable content. However you feel about this, I currently believe rationality outreach is only going to succeed on a massive scale when it is backed by a combination of passionate rationalists and a good enough business model to keep them alive and support rapid growth. <br /><br />3. <em>Engage in meta-outreach.</em> I have started by describing my thoughts on how to engage in effective rationality outreach rather than why I believe rationality outreach is important, but I would have started the other way around if the atmosphere on LW were different. Regardless, you should think carefully about the importance of rationality outreach. If you believe that the problem is really urgent and have a cogent argument, you should make every effort to encourage other rationalists to engage with the problem. I also believe that thinking seriously and concretely about how to best achieve a precise goal is an excellent and necessary drive for improving our rationality, both individually and collectively.<br /><br /><strong>What are My Plans?</strong><br /><br />I have an unusually good background in theoretical computer science and mathematics, know people who have a lot of access to high school students (and have good familiarity with a large clique of brilliant highschool students in the US), and am financially stable. I realize that not giving the money to any fixed charity is tantamount to believing that charity should be giving money to me. I am currently on track to become a research scientist, and it is going very well. I have not been thinking about rationality outreach for long, but the calculus has come out overwhelmingly in its favor and I am rapidly updating my beliefs. I am not yet willing to disrupt my current life plan in a way that would be difficult to reverse.<br /><br />I believe the best first step for me is to start using my spare time (which I can make as large as 30 hours a week) to develop and evaluate online learning/testing resources. Unless I encounter an unexpected obstruction, I would then like to start recruiting other types of talent, testing more broadly, and looking for a business model which can effectively support continuing development along these lines. I may well fail to execute this plan, but it would be either because my beliefs changed or a better plan suggested itself (or, most likely, both).<br /><br />Independently, I am interested in running an academic program for smart high school students. The existence of successful summer programs with a strong academic focus suggests that the market exists, and I believe that I could get enough support to run a program at least once (with future outings facilitated by success). I believe the main obstacles are the non-academic difficulties of running such a program and the recruitment of talented faculty, and the main benefits are probably an increased understanding of how to run a program and how to engage with smart high school students.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "67JaiGAe6SuNHKoLk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 29, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "6305", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T02:45:13.428Z", "modifiedAt": null, "url": null, "title": "Can we stop using the word \"rationalism\"?", "slug": "can-we-stop-using-the-word-rationalism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:04.665Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "odm3FHPzgbiGpWsSg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WhrToa6Khj9qs7X5p/can-we-stop-using-the-word-rationalism", "pageUrlRelative": "/posts/WhrToa6Khj9qs7X5p/can-we-stop-using-the-word-rationalism", "linkUrl": "https://www.lesswrong.com/posts/WhrToa6Khj9qs7X5p/can-we-stop-using-the-word-rationalism", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20we%20stop%20using%20the%20word%20%22rationalism%22%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20we%20stop%20using%20the%20word%20%22rationalism%22%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhrToa6Khj9qs7X5p%2Fcan-we-stop-using-the-word-rationalism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20we%20stop%20using%20the%20word%20%22rationalism%22%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhrToa6Khj9qs7X5p%2Fcan-we-stop-using-the-word-rationalism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhrToa6Khj9qs7X5p%2Fcan-we-stop-using-the-word-rationalism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 290, "htmlBody": "<p>You see, I've seen the word \"rationalism\" used to mean all five of these things at different times:</p>\n<ul>\n<li>The belief that we should come to know the world through reason and experimentation, shunning intuition.</li>\n<li>The belief that we should come to know the world through reason and intuition, shunning experimentation.</li>\n<li>The belief that we should come to know the world through knowledge of (and correction for) cognitive biases, and knowledge of (and correct use of) probability theory.</li>\n<li>Being effective at believing things that are true and not things that are false.</li>\n<li>Being effective at doing things that are good and not things that are bad.</li>\n</ul>\n<div>In most of the mainstream philosophy I've read, the word \"rationalism\" has been used, without qualification, to mean the second of these, even though that type of rationalism strongly contradicts the stuff we call rationalism! One of my friends has freely used the word \"rationalism\" in conversation, referring to \"our\" rationalism, completely unaware that, to most people, the word means something completely different. Another of my friends said that he \"hates rationalism with a passion\"&mdash;and I have no idea which of these five things is the one he hates!</div>\n<div>Given that \"rationalism\" to most people (or, at least, most philosophers) means something utterly unlike what it means to us, perhaps calling our philosophy \"rationalism\" is about as wise as developing a political philosophy, based on socialism but with nationalist influences, and calling it \"national socialism\".</div>\n<div>I suggest that we use the word \"sensibilism\" instead, since nobody else is using it, it seems unobjectionable, and I think it captures what we're all about.</div>\n<div><em>Edited to remove a proposed solution.</em></div>\n<p><em>Edited to reinstate that proposed solution, since this discussion is presumably finished.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WhrToa6Khj9qs7X5p", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 15, "extendedScore": null, "score": 6.916765809525053e-07, "legacy": true, "legacyId": "6311", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T06:53:59.699Z", "modifiedAt": null, "url": null, "title": "Anki on Mac in 60 seconds", "slug": "anki-on-mac-in-60-seconds", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.975Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ML8a8pxrEpB6rZEis/anki-on-mac-in-60-seconds", "pageUrlRelative": "/posts/ML8a8pxrEpB6rZEis/anki-on-mac-in-60-seconds", "linkUrl": "https://www.lesswrong.com/posts/ML8a8pxrEpB6rZEis/anki-on-mac-in-60-seconds", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anki%20on%20Mac%20in%2060%20seconds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnki%20on%20Mac%20in%2060%20seconds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FML8a8pxrEpB6rZEis%2Fanki-on-mac-in-60-seconds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anki%20on%20Mac%20in%2060%20seconds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FML8a8pxrEpB6rZEis%2Fanki-on-mac-in-60-seconds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FML8a8pxrEpB6rZEis%2Fanki-on-mac-in-60-seconds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Spaced_repetition\">Spaced repetition</a>&nbsp;- like the 'Anki' program does -&nbsp;is one of the most efficient ways to learn new things. (For research citations, see 'Study methods',&nbsp;<a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">here</a>.)</p>\n<p>I previously explained how to get up and running with <a href=\"/r/discussion/lw/4um/anki_on_android_in_60_seconds/\">Anki on an Android phone</a>. Here's the guide for using Anki on a Mac:</p>\n<ol>\n<li>Go <a href=\"http://ankisrs.net/#osx\">here</a> and click 'Download Latest Release' (or <a href=\"http://anki.googlecode.com/files/anki-1.2.6-oldmachines.dmg\">here</a> if you're on PowerPC).</li>\n<li>Open the downloaded .dmg file, drag the Anki icon into your Applications folder in the dock, and then run the Anki application. (Click 'Open' when warned that the application was downloaded.)</li>\n<li>Click 'Download' and search the list of decks for 'Less Wrong'. Download the 'Less Wrong Sequences' deck.</li>\n<li>Set your review options as desired, then click 'Review.'</li>\n</ol>\n<div><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 16px;\">\n<div style=\"margin-bottom: 1em;\">&nbsp;That's it!</div>\n<div style=\"margin-bottom: 1em;\">(This full process will take longer than 60 seconds because of download speed, but will probably require only 60 seconds of interaction with the phone.)</div>\n</span></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 2, "fF9GEdWXKJ3z73TmB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ML8a8pxrEpB6rZEis", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 6.917447909464058e-07, "legacy": true, "legacyId": "6314", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg", "XMA72b7yA9pnKKLHs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T17:23:09.303Z", "modifiedAt": null, "url": null, "title": "Omega and self-fulfilling prophecies", "slug": "omega-and-self-fulfilling-prophecies", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.287Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eW2kqDvs384YsFZag/omega-and-self-fulfilling-prophecies", "pageUrlRelative": "/posts/eW2kqDvs384YsFZag/omega-and-self-fulfilling-prophecies", "linkUrl": "https://www.lesswrong.com/posts/eW2kqDvs384YsFZag/omega-and-self-fulfilling-prophecies", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Omega%20and%20self-fulfilling%20prophecies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOmega%20and%20self-fulfilling%20prophecies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW2kqDvs384YsFZag%2Fomega-and-self-fulfilling-prophecies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Omega%20and%20self-fulfilling%20prophecies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW2kqDvs384YsFZag%2Fomega-and-self-fulfilling-prophecies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW2kqDvs384YsFZag%2Fomega-and-self-fulfilling-prophecies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 157, "htmlBody": "<p>Omega appears to you in a puff of logic, and presents you with a closed box. \"If you open this box you will find either nothing or a million dollars,\" Omega tells you, \"and the contents will be yours to keep.\" \"Great,\" you say, taking the box, \"sounds like I can't lose!\" \"Not so fast,\" says Omega, \"to get that possible million dollars you have to be in the right frame of mind. If you are at least 99% confident that there's a million dollars in the box, there will be. If you're less confident than that, it will be empty. I'm not predicting the state of your mind in advance this time, I'm reading it directly and teleporting the money in only if you have enough faith that it will be there. Take as long as you like.\"</p>\n<p>Assume you believe Omega. &nbsp;Can you believe the million dollars will be there, strongly enough that it will be?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YyGDbZhGtws5hEPda": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eW2kqDvs384YsFZag", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 6.919170141191946e-07, "legacy": true, "legacyId": "6316", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T21:44:14.913Z", "modifiedAt": null, "url": null, "title": "Happiness Engineering", "slug": "happiness-engineering", "viewCount": null, "lastCommentedAt": "2011-04-18T14:52:10.677Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ddWFsmad5GB7mhYYQ/happiness-engineering", "pageUrlRelative": "/posts/ddWFsmad5GB7mhYYQ/happiness-engineering", "linkUrl": "https://www.lesswrong.com/posts/ddWFsmad5GB7mhYYQ/happiness-engineering", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Happiness%20Engineering&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHappiness%20Engineering%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddWFsmad5GB7mhYYQ%2Fhappiness-engineering%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Happiness%20Engineering%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddWFsmad5GB7mhYYQ%2Fhappiness-engineering", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FddWFsmad5GB7mhYYQ%2Fhappiness-engineering", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>On the same day that Lukeprog posted <a href=\"/lw/4su/how_to_be_happy/\">How to be happy</a>, Scott Adams made a similar post on the Dilbert Blog, <a href=\"http://dilbert.com/blog/entry/happiness_engineering/\">Happiness Engineering</a>.</p>\n<p>I'm always skeptical when receiving life advice from successful people, because their advice is biased towards taking too much risk, because successful people are selected for having been lucky.&nbsp; But Scott's list doesn't raise any red flags with me, and is admirably concise.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb186": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ddWFsmad5GB7mhYYQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 18, "extendedScore": null, "score": 6.919885068388173e-07, "legacy": true, "legacyId": "6318", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbgCx2ntD5eu8Cno9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-19T23:10:19.086Z", "modifiedAt": null, "url": null, "title": "A Rationalist's Account of Objectification?", "slug": "a-rationalist-s-account-of-objectification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:35.582Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NP8yar5gqNLsnjzZv/a-rationalist-s-account-of-objectification", "pageUrlRelative": "/posts/NP8yar5gqNLsnjzZv/a-rationalist-s-account-of-objectification", "linkUrl": "https://www.lesswrong.com/posts/NP8yar5gqNLsnjzZv/a-rationalist-s-account-of-objectification", "postedAtFormatted": "Saturday, March 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Rationalist's%20Account%20of%20Objectification%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Rationalist's%20Account%20of%20Objectification%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNP8yar5gqNLsnjzZv%2Fa-rationalist-s-account-of-objectification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Rationalist's%20Account%20of%20Objectification%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNP8yar5gqNLsnjzZv%2Fa-rationalist-s-account-of-objectification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNP8yar5gqNLsnjzZv%2Fa-rationalist-s-account-of-objectification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1379, "htmlBody": "<p>I'm seeking some feminist&nbsp;<a href=\"http://en.wikipedia.org/wiki/Consciousness_raising\">consciousness-raising</a>, and I'm hoping some LWers (<a href=\"/lw/134/sayeth_the_girl/\">Alicorn?</a>) can help.</p>\n<p>Specifically, I've never understood why \"objectification\" is wrong.</p>\n<p>I'm a tall white American male, so sometimes it takes a bit of work for me to understand what it's like to be a member of a suppressed group. I <em>still</em>&nbsp;need regular training in avoiding sexist language, etc.</p>\n<p>First: <strong>my background</strong>. When I was 10ish I encountered the word \"feminism\" for the first time. I asked my mom what the word meant.</p>\n<p>She said, \"It's the idea that women should have the same rights and privileges as men do.\"</p>\n<p>And I thought, \"They have a <em>word</em> for that?\" It seemed too obvious to deserve its own word. It felt like having a special word for the idea that left-handers and right-handers should have the same rights and privileges.</p>\n<p>So I've always thought of myself as a feminist.</p>\n<p>Of course, some activists (the word has positive connotations to me, BTW) pushed too far, as is the case in all large movements. At some times and places (1980s academia, I think), it was common to assert that there are almost no (average) significant differences between men and women that aren't caused by enculturation, except for genitalia. That is of course <a href=\"http://en.wikipedia.org/wiki/Sex_differences_in_humans\">false</a>. Hormones matter, especially during development.</p>\n<p>Such overreaches made it psychologically easier for some non-feminists to dismiss legitimate feminist demands and resist <a href=\"http://en.wikipedia.org/wiki/History_of_feminism\">thousands of much-needed feminist advances</a> (which are still ongoing).</p>\n<p>Now, on this matter of objectification. I've never understood it. I've tried to get people to explain it to me <a href=\"http://scienceblogs.com/pharyngula/2010/07/i_have_been_objectified.php\">before</a>, but they were (apparently) not well-trained in rationality. I'm hoping a rationalist can explain it to me.</p>\n<p><strong>Here's my confusion about objectification</strong>. Depending on what you mean by \"objectification,\" it seems to be either something that (1) is very often perfectly acceptable, or that (2) means something very narrow and is usually <em>not</em> being exemplified when there is an accusation of it being exemplified.</p>\n<p>Let me explain.</p>\n<p><a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Nussbaum-Objectification.pdf\">Earlier</a>, when I <a href=\"http://commonsenseatheism.com/?p=10323\">tried</a> to figure out what \"objectification\" was and why it was wrong, the leading article on the topic seemed to be <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Nussbaum-Objectification.pdf\">one</a> by philosopher <a href=\"http://en.wikipedia.org/wiki/Martha_Nussbaum\">Martha Nussbaum</a>. She lays out the goal of her paper like this:</p>\n<blockquote>\n<p>I shall argue that there are at least seven distinct ways of behaving introduced by the term, none of which implies any of the others, though there are many complex connections among them. Under some specifications, objectification&hellip; is always morally problematic. Under other specifications, objectification has features that may be either good or bad, depending on the overall context&hellip; Some features of objectification&hellip; may in fact in some circumstances&hellip; be either necessary or even wonderful features of sexual life.</p>\n</blockquote>\n<p>Using examples, she then outlines seven ways to treat a person as a thing. Rae Langton <a href=\"http://books.google.com/books?id=m5MQwh9ExgYC&amp;lpg=PR5&amp;ots=YF6-gn9Yqq&amp;lr&amp;pg=PA228#v=onepage&amp;q&amp;f=false\">added three more</a> in 2009, bringing the total count to <strong>10 ways to treat a person as a thing</strong>:</p>\n<ol>\n<li><em>Instrumentality</em>. The objectifier treats the object as a tool of his or her purposes.</li>\n<li><em>Denial of autonomy</em>. The objectifier treats the object as lacking in autonomy and self-determination.</li>\n<li><em>Inertness</em>. The objectifier treats the object as lacking in agency, and perhaps also in activity.</li>\n<li><em>Fungibility</em>. The objectifier treats the object as interchangeable (a) with other objects of the same type and/or (b) with objects of other types.</li>\n<li><em>Violability</em>. The objectifier treats the object as lacking in boundary integrity, as something that it is permissible to break up, smash, break into.</li>\n<li><em>Ownership</em>. The objectifier treats the object as something that is owned by another, can be bought or sold, etc.</li>\n<li><em>Denial of subjectivity</em>. The objectifier treats the object as something whose experience and feelings (if any) need not be taken into account.</li>\n<li><em>Reduction to body</em>: treatment of a person as identified with their body, or body parts.</li>\n<li><em>Reduction to appearance</em>: treatment of a person primarily in terms of how they look.</li>\n<li><em>Silencing</em>: the treatment of a person as if they lack the capacity to speak.</li>\n</ol>\n<p>Consider a classic example of objectification from <em>Playboy</em>&nbsp;magazine: a photo of a female tennis player bending over, revealing her butt, above the caption \"<a href=\"http://commonsenseatheism.com/wp-content/uploads/2010/07/playboy-1995-why-we-love-tennis.png\">Why We Love Tennis</a>.\"</p>\n<p>The <em>Playboy</em>&nbsp;image exhibits at least <em>eight</em>&nbsp;features of objectification: instrumentalization, denial of autonomy, fungibility, denial of subjectivity, reduction to body, reduction to appearance, and silencing!</p>\n<p>But, let's consider another example of objectification, what I'll call the <a href=\"http://www.boston.com/bigpicture/2009/07/our_muddy_world.html\">Muddy People</a> photo:</p>\n<p><img src=\"http://commonsenseatheism.com/wp-content/uploads/2010/07/muddy-world.png\" alt=\"\" width=\"500\" height=\"320\" /></p>\n<p>To us, these people are nothing but objects of our entertainment and pleasure. We have <em>instrumentalized</em> them. Moreover, they are <em>fungible</em>. It does not matter to us which people are covered in mud and looking silly. And just as with the <em>Playboy</em>&nbsp;example, this photo involves a <em>denial of autonomy</em>. Indeed, it is doubtful the permission to publish their photos was obtained. Moreover, we are not much interested in the feelings of these people but only their role in entertaining us as we gaze upon their mud-caked bodies &ndash; a <em>denial of subjectivity</em>. Often, nothing of these mud-covered people can be seen or known except their bodies &ndash; in many cases, only body parts, sticking every which way. This is the <em>reduction to body</em>. There is also clearly a <em>reduction to appearance</em>. Their mud-covered appearance is their only interest to us. In many cases, the emotions they might be having are totally obscured by the mud covering their faces. They are also, of course, <em>silent</em> to us.</p>\n<p>So all the features of objectification found in the <em>Playboy</em>&nbsp;example, which we might feel is wrong somehow, are also shared by the Muddy People photo, which we probably feel is acceptable. Perhaps this suggests that <a href=\"http://commonsenseatheism.com/?p=523\">our feelings are poor guides to moral truth</a>. Or maybe what is wrong with the <em>Playboy</em>&nbsp;photo is something <em>other</em>&nbsp;than objectification.</p>\n<p>Of course, there are disanalogies to be found. The Playboy example (especially with the caption) involved sexuality, and the Muddy People photo does not particularly do so. But if this is the line of thought that leads us to condemn <em>Playboy</em> but not the Muddy People photo, then we are bringing in another concept besides objectification.</p>\n<p>For example, perhaps we want to say that Playboy&lsquo;s objectifications harm women by contributing to a culture of sexual prejudice, but the Muddy People objectifications do not cause any such harm. But then we are not appealing to this Kantian notion of \"objectification.\" Rather, we are appealing to utilitarian principles.&nbsp;(Feminist philosopher Lina Papadaki makes <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Papadaki-Sexual-Objectification-From-Kant-to-Contemporary-Feminism.pdf\">similar objections</a> to the notion of objectification.)</p>\n<p>We <em>all</em>&nbsp;use each other as means to an end, or as objects of one kind or another, all the time. And we can do so while respecting their autonomy. I enjoy looking at the shapes and textures in the Muddy People photo while also respecting that the people whose bodies make up those shapes and textures are autonomous individuals of great value. But their value as individuals is not the point of the photo. The point of the photo, in this case, is that it's an interesting picture to look at. And that's okay, I think.</p>\n<p>Good romantic partners use each other as a means to their own gratification while also respecting each others' autonomy. We use each other as sex objects, as emotion objects, as conversation objects, as knowledge objects, as carpool objects, and as other objects, all the time - while also respecting each others' autonomy and value. It's not clear to me what's wrong with that.</p>\n<p>So if something like Nussbaum's analysis of \"objectification\" is what is meant by the term, then I don't see what's wrong with it. But if it means something much more narrow (what? I don't know), then I doubt it is exemplified nearly as often as people are accused of exemplifying it.</p>\n<p>I reject Kant's epistemology, logic, and metaphysics - as I think any scientifically-informed person should. But even if you <em>do</em>&nbsp;accept all three, I <em>still</em>&nbsp;don't see what's intrinsically wrong with objectification as Nussbaum defines it.</p>\n<p>Maybe I'm being dense. That has happened before. I'm not posting this with much confidence that objectification is a mostly useless concept. I'm posting this in pursuit of some consciousness-raising.</p>\n<p>Understanding the problem is the first step toward fixing it. And right now I don't understand the problem. So if you have the time, please teach me.</p>\n<p>Thanks.</p>\n<p>&nbsp;</p>\n<p><strong>Update</strong>: below, I'll keep an updated list of the most useful articles I've found so far.</p>\n<p>\n<ul>\n<li>Meteuophoric, <a href=\"http://meteuphoric.wordpress.com/2011/02/25/does-si-make-everyone-look-like-swimsuit-models/\">Does SI make everyone look like swimsuit models?</a></li>\n<li>Shakesville, <a href=\"http://shakespearessister.blogspot.com/2010/01/feminism-101.html\">Feminism 101</a></li>\n<li>Feminism 101 Blog, <a href=\"http://finallyfeminism101.wordpress.com/the-faqs/faq-roundup/\">FAQ Roundup</a></li>\n</ul>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NP8yar5gqNLsnjzZv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 65, "baseScore": 62, "extendedScore": null, "score": 0.000119, "legacy": true, "legacyId": "6319", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 62, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 327, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gsL6CLqjujPNSLL2o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T02:40:15.406Z", "modifiedAt": null, "url": null, "title": "What is wrong with mathematics education?", "slug": "what-is-wrong-with-mathematics-education", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:24.507Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Perplexed", "createdAt": "2010-07-22T02:17:37.444Z", "isAdmin": false, "displayName": "Perplexed"}, "userId": "jj9aBsS9xsGPWKq3n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dkMipFRshfxwAbTAp/what-is-wrong-with-mathematics-education", "pageUrlRelative": "/posts/dkMipFRshfxwAbTAp/what-is-wrong-with-mathematics-education", "linkUrl": "https://www.lesswrong.com/posts/dkMipFRshfxwAbTAp/what-is-wrong-with-mathematics-education", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20wrong%20with%20mathematics%20education%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20wrong%20with%20mathematics%20education%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdkMipFRshfxwAbTAp%2Fwhat-is-wrong-with-mathematics-education%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20wrong%20with%20mathematics%20education%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdkMipFRshfxwAbTAp%2Fwhat-is-wrong-with-mathematics-education", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdkMipFRshfxwAbTAp%2Fwhat-is-wrong-with-mathematics-education", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p><a title=\"short TED lecture\" href=\"http://www.ted.com/talks/arthur_benjamin_s_formula_for_changing_math_education.html\">This guy says</a> that the problem is that high-school math education is structured to prepare people to learn calculus in their freshman year of college.&nbsp; But only a small minority of students ever takes calculus, and an even smaller minority ever uses it.&nbsp; And not many people ever make much use of pre-calc subjects like algebra, trig, or analytic geometry.</p>\n<p>Instead, high-school math should be structured to prepare people to learn <em>statistics</em>.&nbsp; Probability and basic statistics, he argues, are not only more generally useful than calculus, they are also more fun.</p>\n<p>I have to agree with him.&nbsp; What do the people here think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dkMipFRshfxwAbTAp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 24, "extendedScore": null, "score": 6.920695757204791e-07, "legacy": true, "legacyId": "6320", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T05:16:26.330Z", "modifiedAt": null, "url": null, "title": "Rationality vs. intelligence", "slug": "rationality-vs-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PlaidX", "createdAt": "2009-06-28T10:50:31.260Z", "isAdmin": false, "displayName": "PlaidX"}, "userId": "Cgh6rBbvZe4Noxt5d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SFd6BNN84dPZbWBx3/rationality-vs-intelligence", "pageUrlRelative": "/posts/SFd6BNN84dPZbWBx3/rationality-vs-intelligence", "linkUrl": "https://www.lesswrong.com/posts/SFd6BNN84dPZbWBx3/rationality-vs-intelligence", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20vs.%20intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20vs.%20intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFd6BNN84dPZbWBx3%2Frationality-vs-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20vs.%20intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFd6BNN84dPZbWBx3%2Frationality-vs-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFd6BNN84dPZbWBx3%2Frationality-vs-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>This site often speaks of rationality and intelligence as though they were the same thing, and that someone, by becoming more rational, becomes more intelligent for practical purposes.</p>\n<p>&nbsp;</p>\n<p>Certainly it seems to me that this must be to some extent the case, but what is the exchange rate? If a person has an IQ of 100, and then they spend a year on lesswrong, reading all the sequences and taking the advice to heart, training their skills and identifying their biases and all that, at the end of it, presumably their raw IQ score is still 100, but if we measure how they do on correlated indicators regarding their lifestyle or something, should we expect to see them, in some way, living the life of a smarter person? How much smarter?</p>\n<p>&nbsp;</p>\n<p>How many points of IQ would you be willing to give up to retain what you have learned from this site?</p>\n<p>&nbsp;</p>\n<p>Personally I would answer \"less than one\". It seems like it SHOULD be useful, but it doesn't really feel like it is.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SFd6BNN84dPZbWBx3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 10, "extendedScore": null, "score": 6.921123566484373e-07, "legacy": true, "legacyId": "6322", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T10:22:22.521Z", "modifiedAt": null, "url": null, "title": "\"How to Have a Rational Discussion\"", "slug": "how-to-have-a-rational-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:19.362Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jschulter", "createdAt": "2010-08-28T21:41:04.522Z", "isAdmin": false, "displayName": "jschulter"}, "userId": "JkRMMCvHahHw9ooa2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/shsZyMpyH4xuviohM/how-to-have-a-rational-discussion", "pageUrlRelative": "/posts/shsZyMpyH4xuviohM/how-to-have-a-rational-discussion", "linkUrl": "https://www.lesswrong.com/posts/shsZyMpyH4xuviohM/how-to-have-a-rational-discussion", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22How%20to%20Have%20a%20Rational%20Discussion%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22How%20to%20Have%20a%20Rational%20Discussion%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshsZyMpyH4xuviohM%2Fhow-to-have-a-rational-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22How%20to%20Have%20a%20Rational%20Discussion%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshsZyMpyH4xuviohM%2Fhow-to-have-a-rational-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FshsZyMpyH4xuviohM%2Fhow-to-have-a-rational-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p>I have a feeling that most of the people reading this site already understand everything in this article, but it's a useful synopsis of common issues faced when trying to have a reasonable discussion with laypeople, and might be good to point them to if necessary.</p>\n<p>&nbsp;</p>\n<p>http://thoughtcatalog.com/2011/how-to-have-a-rational-discussion/</p>\n<p>&nbsp;</p>\n<p>I also want to mention how much I wish someone had shown me something like this as a teenager- I was very prone to lecture others against their will- as it might have saved me a lot of grief. I'm curious to see if these tendencies might have been common among members of this community growing up, so please comment to tell me if so (actually, please tell me even if not-no reason to encourage my own confirmation bias)!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "shsZyMpyH4xuviohM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 8, "extendedScore": null, "score": 6.921961714574627e-07, "legacy": true, "legacyId": "6323", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T10:36:59.000Z", "modifiedAt": null, "url": null, "title": "A few minor comparisons of the results of Genetic egineering and Natural selection ", "slug": "a-few-minor-comparisons-of-the-results-of-genetic-egineering", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.055Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aiQtLwKjwCJcnMeCD/a-few-minor-comparisons-of-the-results-of-genetic-egineering", "pageUrlRelative": "/posts/aiQtLwKjwCJcnMeCD/a-few-minor-comparisons-of-the-results-of-genetic-egineering", "linkUrl": "https://www.lesswrong.com/posts/aiQtLwKjwCJcnMeCD/a-few-minor-comparisons-of-the-results-of-genetic-egineering", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20few%20minor%20comparisons%20of%20the%20results%20of%20Genetic%20egineering%20and%20Natural%20selection%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20few%20minor%20comparisons%20of%20the%20results%20of%20Genetic%20egineering%20and%20Natural%20selection%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQtLwKjwCJcnMeCD%2Fa-few-minor-comparisons-of-the-results-of-genetic-egineering%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20few%20minor%20comparisons%20of%20the%20results%20of%20Genetic%20egineering%20and%20Natural%20selection%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQtLwKjwCJcnMeCD%2Fa-few-minor-comparisons-of-the-results-of-genetic-egineering", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQtLwKjwCJcnMeCD%2Fa-few-minor-comparisons-of-the-results-of-genetic-egineering", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1020, "htmlBody": "<pre>[feel free to tldr the intro]</pre>\n<h3>Intro</h3>\n<p>The title should have been longer to be more accurate and perhaps less misleading but I hope the community will forgive that for sake of brevity as:</p>\n<p><strong>A few minor comparisons of the</strong> [probable] <strong>results of </strong>[relatively conservative] <strong>Genetic</strong> <strong>engineering and natural selection</strong> [as it acted in the ancestral environment and to a lesser extent today in a purely speculative manner, publicized only to clear and debug my own thinking as well as hear new ideas on the subject from trusted sources]</p>\n<p>seemed a bit much.</p>\n<p>First off I would like to pre-empt a comment launching a debate that some might find interesting and others tedious, I wish to emphasise that genetic engineering and all human activity is naturally well ... natural (so one could say that natural selection is a bit of a misnomer). By saying that I also hope I implicitly clear up what is meant when I speak of \"selective pressures\".</p>\n<p>Much like <a href=\"http://www.overcomingbias.com/2009/09/limits-to-growth.html\">Robin Hanson's</a> highly modified very economical sustenance level living ems, any analysis focusing on the intelligence enhancement aspect of genetic engineering will tend towards a similar shining \"result\" that might overshadow smaller insights. The only real appreciable difference seems to be the time-scales involved (the length of a human generations is on completely different orders of magnitude than say just copying ems). Both scenarios could be understood as a prophecy of ultimate victory of natural selection over any human attempt to limit its outcome according to most of the sets of values in valuspace that generally humans occupy (valuing survival and only survival, with survival defined as a specific kind of continuity, is of course a obvious exception, but few humans I think truly ascribe to it). The transition period to a neomalthusian world has some interesting dynamics but I'm not going to talk about that too much because it seems a classical accelerating returns event.</p>\n<p>In addition for similar reasons (much like <a href=\"/lw/y4/three_worlds_collide_08/\">Eliezer's story</a>) this \"impossible world\" is going to ignore or more accuratley not touch the effects of AI and cybernetic IA. Sans the narrative I am basically making a story to flesh out how the new balance of selective pressures that are likley to exist in the early phases of genetic engineering may look like. This is done because:</p>\n<ul>\n<li>I wish to see if any new factors, that haven't been discussed yet or I haven't thought of yet, will persist in shaping the balance of pressures into the later stages</li>\n<li>Because I'm curious about what the balance will be even if it persists for such a short time as to have little effect on the overall course of (trans)human evolution. </li>\n</ul>\n<h3>Speculation<br /></h3>\n<p>Now that that verbose intro is done with (felt it necessary to frame the debate I am interested in properly), let me get to the meat:</p>\n<ul>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/Fisherian_runaway\">Fisherian runaway</a> seems much more likley for characteristics that send good status signals about us (characteristics that make us appear nice/moral/decent/prestigious/caring people regardless of actual usefulness or perhaps even harm).</p>\n</li>\n<li>\n<p>Energy requirements will be relaxed. The cost benefit comparison was much more important even in our very recent evolutionary past as is attested by say different maturation rates (age of menarche, average pregnancy length, dental and bone development, ect.) between different groups, than it will likley be in the near or perhaps medium view. After all to people likley to reproduce primarily by in vitro fertilisation, guaranteeing their child a caloric intake larger than norm by say 50% will not be a major expense.</p>\n</li>\n<li>\n<p>Adaptations that incur benefits and also (rare or not) emotionally troubling complications or small disadvantages that send bad status signals will be weeded out (seems a aspect of our adaptation to be <a href=\"http://en.wikipedia.org/wiki/Loss_aversion\">loss averse</a>). [note: I'd probably keep Tay-Sachs even if it perhaps gave my children some difficult choices about who to marry if it meant (as it seem likley) a IQ boost for them, but I don't think Everyman would see it that way especially it meant risks for conditions like say <a href=\"http://en.wikipedia.org/wiki/Torsion_dystonia\">Torison Dystonia</a>].<span style=\"font-size: 85%;\"> </span>This may or may not include the (by my values unfortunate) culling of some spaces of neurodiversity, depends on how large a fraction of humanity practices GE.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>Value divergence, people will wish their offspring to be similar to them in general ideological outlook, they will also seek to correct self-perceived personality \"flaws\".</p>\n</li>\n<li>\n<p>Human self-domestication will continue at a faster pace or perhaps resume, depending on your perspective (I think we are likley to see a Fisherian runaway on some aspects of it).</p>\n</li>\n<li>Sexual dimorphism will increase as a side effect of the race for more attractive (not only physical beauty but behaviour as well) sons and more beautiful daughters (mostly just modification for physical beauty).Fisherian runaway again seems likley. Parents may have ideological compunctions against doing this, but it seems plausible that considering we will get used to at least some of the increase in average attractiveness, our tendency towards hypergamy and the many very real and significant ways in which being beautiful or at least not ugly helps one in life, I think most will cave in. &nbsp; </li>\n</ul>\n<p>Note the above assumes assumes government interference will be limited to banning or making difficult giving \"disabilities\" on purpose (but leaving you the right to pass on the \"disabilities\" you already carry) and perhaps limiting transgenic efforts (perhaps banning any alleles not already found above a certain frequency in a existent human population). I don't really care about the de jure status of any of the above as much as the de facto practice.</p>\n<p><strong>Note:</strong> I'm well aware the above paragraph would by some be considered a unacceptable limit on freedom and to others a overly libertarian approach, let me therefore emphasise that I'm not talking ethics here or making predictions on the probability of the extent of government regulation or its efficacy. I'm simply being honest with the backdrop against which I was thinking up the above points.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aiQtLwKjwCJcnMeCD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "6324", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<pre>[feel free to tldr the intro]</pre>\n<h3 id=\"Intro\">Intro</h3>\n<p>The title should have been longer to be more accurate and perhaps less misleading but I hope the community will forgive that for sake of brevity as:</p>\n<p><strong>A few minor comparisons of the</strong> [probable] <strong>results of </strong>[relatively conservative] <strong>Genetic</strong> <strong>engineering and natural selection</strong> [as it acted in the ancestral environment and to a lesser extent today in a purely speculative manner, publicized only to clear and debug my own thinking as well as hear new ideas on the subject from trusted sources]</p>\n<p>seemed a bit much.</p>\n<p>First off I would like to pre-empt a comment launching a debate that some might find interesting and others tedious, I wish to emphasise that genetic engineering and all human activity is naturally well ... natural (so one could say that natural selection is a bit of a misnomer). By saying that I also hope I implicitly clear up what is meant when I speak of \"selective pressures\".</p>\n<p>Much like <a href=\"http://www.overcomingbias.com/2009/09/limits-to-growth.html\">Robin Hanson's</a> highly modified very economical sustenance level living ems, any analysis focusing on the intelligence enhancement aspect of genetic engineering will tend towards a similar shining \"result\" that might overshadow smaller insights. The only real appreciable difference seems to be the time-scales involved (the length of a human generations is on completely different orders of magnitude than say just copying ems). Both scenarios could be understood as a prophecy of ultimate victory of natural selection over any human attempt to limit its outcome according to most of the sets of values in valuspace that generally humans occupy (valuing survival and only survival, with survival defined as a specific kind of continuity, is of course a obvious exception, but few humans I think truly ascribe to it). The transition period to a neomalthusian world has some interesting dynamics but I'm not going to talk about that too much because it seems a classical accelerating returns event.</p>\n<p>In addition for similar reasons (much like <a href=\"/lw/y4/three_worlds_collide_08/\">Eliezer's story</a>) this \"impossible world\" is going to ignore or more accuratley not touch the effects of AI and cybernetic IA. Sans the narrative I am basically making a story to flesh out how the new balance of selective pressures that are likley to exist in the early phases of genetic engineering may look like. This is done because:</p>\n<ul>\n<li>I wish to see if any new factors, that haven't been discussed yet or I haven't thought of yet, will persist in shaping the balance of pressures into the later stages</li>\n<li>Because I'm curious about what the balance will be even if it persists for such a short time as to have little effect on the overall course of (trans)human evolution. </li>\n</ul>\n<h3 id=\"Speculation\">Speculation<br></h3>\n<p>Now that that verbose intro is done with (felt it necessary to frame the debate I am interested in properly), let me get to the meat:</p>\n<ul>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/Fisherian_runaway\">Fisherian runaway</a> seems much more likley for characteristics that send good status signals about us (characteristics that make us appear nice/moral/decent/prestigious/caring people regardless of actual usefulness or perhaps even harm).</p>\n</li>\n<li>\n<p>Energy requirements will be relaxed. The cost benefit comparison was much more important even in our very recent evolutionary past as is attested by say different maturation rates (age of menarche, average pregnancy length, dental and bone development, ect.) between different groups, than it will likley be in the near or perhaps medium view. After all to people likley to reproduce primarily by in vitro fertilisation, guaranteeing their child a caloric intake larger than norm by say 50% will not be a major expense.</p>\n</li>\n<li>\n<p>Adaptations that incur benefits and also (rare or not) emotionally troubling complications or small disadvantages that send bad status signals will be weeded out (seems a aspect of our adaptation to be <a href=\"http://en.wikipedia.org/wiki/Loss_aversion\">loss averse</a>). [note: I'd probably keep Tay-Sachs even if it perhaps gave my children some difficult choices about who to marry if it meant (as it seem likley) a IQ boost for them, but I don't think Everyman would see it that way especially it meant risks for conditions like say <a href=\"http://en.wikipedia.org/wiki/Torsion_dystonia\">Torison Dystonia</a>].<span style=\"font-size: 85%;\"> </span>This may or may not include the (by my values unfortunate) culling of some spaces of neurodiversity, depends on how large a fraction of humanity practices GE.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>Value divergence, people will wish their offspring to be similar to them in general ideological outlook, they will also seek to correct self-perceived personality \"flaws\".</p>\n</li>\n<li>\n<p>Human self-domestication will continue at a faster pace or perhaps resume, depending on your perspective (I think we are likley to see a Fisherian runaway on some aspects of it).</p>\n</li>\n<li>Sexual dimorphism will increase as a side effect of the race for more attractive (not only physical beauty but behaviour as well) sons and more beautiful daughters (mostly just modification for physical beauty).Fisherian runaway again seems likley. Parents may have ideological compunctions against doing this, but it seems plausible that considering we will get used to at least some of the increase in average attractiveness, our tendency towards hypergamy and the many very real and significant ways in which being beautiful or at least not ugly helps one in life, I think most will cave in. &nbsp; </li>\n</ul>\n<p>Note the above assumes assumes government interference will be limited to banning or making difficult giving \"disabilities\" on purpose (but leaving you the right to pass on the \"disabilities\" you already carry) and perhaps limiting transgenic efforts (perhaps banning any alleles not already found above a certain frequency in a existent human population). I don't really care about the de jure status of any of the above as much as the de facto practice.</p>\n<p><strong>Note:</strong> I'm well aware the above paragraph would by some be considered a unacceptable limit on freedom and to others a overly libertarian approach, let me therefore emphasise that I'm not talking ethics here or making predictions on the probability of the extent of government regulation or its efficacy. I'm simply being honest with the backdrop against which I was thinking up the above points.</p>", "sections": [{"title": "Intro", "anchor": "Intro", "level": 1}, {"title": "Speculation", "anchor": "Speculation", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "11 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HawFh7RvDM4RyoJ2d"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T17:35:26.543Z", "modifiedAt": null, "url": null, "title": "What are Arguments, from an Agorics point of view?", "slug": "what-are-arguments-from-an-agorics-point-of-view", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.518Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Johnicholas", "createdAt": "2009-02-27T15:01:52.708Z", "isAdmin": false, "displayName": "Johnicholas"}, "userId": "kBvTXutfPytNtzPyD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8G9aeSy95fSKNML82/what-are-arguments-from-an-agorics-point-of-view", "pageUrlRelative": "/posts/8G9aeSy95fSKNML82/what-are-arguments-from-an-agorics-point-of-view", "linkUrl": "https://www.lesswrong.com/posts/8G9aeSy95fSKNML82/what-are-arguments-from-an-agorics-point-of-view", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20Arguments%2C%20from%20an%20Agorics%20point%20of%20view%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20Arguments%2C%20from%20an%20Agorics%20point%20of%20view%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8G9aeSy95fSKNML82%2Fwhat-are-arguments-from-an-agorics-point-of-view%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20Arguments%2C%20from%20an%20Agorics%20point%20of%20view%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8G9aeSy95fSKNML82%2Fwhat-are-arguments-from-an-agorics-point-of-view", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8G9aeSy95fSKNML82%2Fwhat-are-arguments-from-an-agorics-point-of-view", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 250, "htmlBody": "<p>Background on Agorics:</p>\n<p>The idea of software agents cooperating in an open market or \"agora\". Described by Mark Miller and Eric Drexler here:&nbsp;<a href=\"http://e-drexler.com/d/09/00/AgoricsPapers/agoricpapers.html\">http://e-drexler.com/d/09/00/AgoricsPapers/agoricpapers.html</a>&nbsp;Depicted by Greg Egan in his novel \"Diaspora\", exerpt here:&nbsp;<a href=\"http://gregegan.customer.netspace.net.au/DIASPORA/01/Orphanogenesis.html\">http://gregegan.customer.netspace.net.au/DIASPORA/01/Orphanogenesis.html</a></p>\n<p>Background on Argument:&nbsp;<a href=\"http://en.wikipedia.org/wiki/Argument\">http://en.wikipedia.org/wiki/Argument</a></p>\n<p>Let's start by supposing that an argument is a variety of persuasive message. If Bob trusts Alice though, Bob could be persuaded by simply recieving a claim from Alice. That is a kind of persuasive message, but it's not an argument. If Bob is insecure, then Bob's mind could be hacked and therefore changed. However, that's not an argument either. (The \"Buffer Overflow Fallacy\"?)</p>\n<p>Possibly arguments are witnesses (or \"certificates\"), as used in computational complexity. Alice could spend exp-time to solve an instance of an NP-complete problem, then send a small witness to B, who can then spend poly-time to verify it. The witness would be an argument.</p>\n<p>I'm not sure if that's a definition, but we have an overgeneral category (persuasive messages) that is, a superset of arguments, two subcategories of persuasive messages that are specifically excluded, and one subcategory that is specifically included, which seems like enough to go on with.</p>\n<p>We know what witnesses to SAT problems look like - they look like satisfying assignments. That is, if Bob were considering a SAT problem, and Alice sent Bob a putative satisfying assignment, and Bob verified it, then Bob ought (rationally) to be convinced that the problem is satisfiable.&nbsp;</p>\n<p>What do other kinds of witnesses look like? What about probabilistic computation? What if Alice and Bob may have different priors?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8G9aeSy95fSKNML82", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "6325", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T18:29:16.231Z", "modifiedAt": null, "url": null, "title": "26 March 2011 Southern California Meetup", "slug": "26-march-2011-southern-california-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.328Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimmy", "createdAt": "2009-02-27T18:23:27.410Z", "isAdmin": false, "displayName": "jimmy"}, "userId": "JKdbpXHkv9AsuazJ3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FrjZxiYSxBkNjX7J9/26-march-2011-southern-california-meetup", "pageUrlRelative": "/posts/FrjZxiYSxBkNjX7J9/26-march-2011-southern-california-meetup", "linkUrl": "https://www.lesswrong.com/posts/FrjZxiYSxBkNjX7J9/26-march-2011-southern-california-meetup", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2026%20March%202011%20Southern%20California%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A26%20March%202011%20Southern%20California%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrjZxiYSxBkNjX7J9%2F26-march-2011-southern-california-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=26%20March%202011%20Southern%20California%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrjZxiYSxBkNjX7J9%2F26-march-2011-southern-california-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrjZxiYSxBkNjX7J9%2F26-march-2011-southern-california-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p><a id=\"more\"></a></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">We're having another SoCal LessWrong meetup this Saturday, the 26th. It'll be held</span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">&nbsp;in the upstairs meeting area</span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">&nbsp;at&nbsp;</span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://maps.google.com/maps?hl=en&amp;ie=UTF8&amp;q=18542+Macarthur+Blvd+Irvine+CA,+92612+ihop&amp;fb=1&amp;gl=us&amp;hq=ihop&amp;hnear=18542+MacArthur+Blvd,+Irvine,+CA+92612&amp;cid=0,0,16042522294109526569&amp;ei=uLa8TOG7MoWCsQO1nM2TDw&amp;ved=0CBYQnwIwAA&amp;ll=33.679247,-117.859418&amp;spn=0.009285,0.021136&amp;t=h&amp;z=16&amp;iwloc=A\">this IHOP</a></span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">&nbsp;in Irvine. It will start at 2PM and probably run until 7 or so.</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">The format for past meetups has varied based on the number of attendees and their interests, at various points we have tried:&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">paranoid debating</a>, small group \"dinner party conversations\",&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"/lw/2ps/september_2010_southern_california_meetup/2mbq?c=1\">structured rationality exercises</a>, large discussions with people sharing personal experiences with sleep and \"nutraceutical\" interventions for intelligence augmentation, and specialized subprojects to develop tools for quantitatively estimating the value of things like&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://wiki.lesswrong.com/wiki/Cryonics\">cryonics</a>&nbsp;or&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://wiki.lesswrong.com/wiki/Existential_risk\">existential risk</a>&nbsp;interventions.</span></p>\n<p>If you need or can offer a ride, post in the comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FrjZxiYSxBkNjX7J9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 6.923295989980725e-07, "legacy": true, "legacyId": "6326", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T20:28:05.119Z", "modifiedAt": "2021-02-08T21:12:43.992Z", "url": null, "title": "Less Wrong Rationality and Mainstream Philosophy", "slug": "less-wrong-rationality-and-mainstream-philosophy", "viewCount": null, "lastCommentedAt": "2021-07-08T03:07:07.788Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oTX2LXHqXqYg2u4g6/less-wrong-rationality-and-mainstream-philosophy", "pageUrlRelative": "/posts/oTX2LXHqXqYg2u4g6/less-wrong-rationality-and-mainstream-philosophy", "linkUrl": "https://www.lesswrong.com/posts/oTX2LXHqXqYg2u4g6/less-wrong-rationality-and-mainstream-philosophy", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20Rationality%20and%20Mainstream%20Philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20Rationality%20and%20Mainstream%20Philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTX2LXHqXqYg2u4g6%2Fless-wrong-rationality-and-mainstream-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20Rationality%20and%20Mainstream%20Philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTX2LXHqXqYg2u4g6%2Fless-wrong-rationality-and-mainstream-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoTX2LXHqXqYg2u4g6%2Fless-wrong-rationality-and-mainstream-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1391, "htmlBody": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>Despite Yudkowsky's&nbsp;<a href=\"/lw/tg/against_modal_logics/\">distaste</a> for mainstream philosophy, Less Wrong is largely a philosophy blog. Major topics include <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">epistemology</a>, <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">philosophy of language</a>, <a href=\"http://wiki.lesswrong.com/wiki/Free_will\">free will</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">metaphysics</a>, <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">metaethics</a>, <a href=\"/lw/n3/circular_altruism/\">normative ethics</a>, <a href=\"http://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence\">machine ethics</a>,&nbsp;<a href=\"/lw/xy/the_fun_theory_sequence/\">axiology</a>, <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">philosophy of mind</a>, and more.</p>\n<p>Moreover, standard Less Wrong positions on philosophical matters have been standard positions in a movement <em>within</em>&nbsp;mainstream philosophy for half a century. That movement is sometimes called \"Quinean naturalism\" after Harvard's&nbsp;<a href=\"http://en.wikipedia.org/wiki/W._V._Quine\">W.V. Quine</a>, who articulated the Less Wrong approach to philosophy in the 1960s. Quine was one of the <a href=\"http://leiterreports.typepad.com/blog/2009/03/so-who-is-the-most-important-philosopher-of-the-past-200-years.html\">most influential</a> philosophers of the last 200 years,&nbsp;so I'm not talking about an <em>obscure</em> movement in philosophy.</p>\n<p>Let us survey the connections. Quine thought that philosophy was continuous with science - and where it wasn't, it was <em>bad</em> philosophy. He embraced empiricism and reductionism. He rejected the notion of libertarian free will. He regarded postmodernism as sophistry. Like Wittgenstein and Yudkowsky, Quine didn't try to straightforwardly <em>solve</em>&nbsp;traditional Big Questions as much as he either <a href=\"/lw/of/dissolving_the_question/\">dissolved those questions</a> or reframed them such that they <em>could</em>&nbsp;be solved.&nbsp;He dismissed endless semantic arguments about the meaning of vague terms like <em>knowledge</em>. He rejected <em>a priori</em>&nbsp;knowledge. He rejected the notion of&nbsp;privileged&nbsp;philosophical insight: knowledge comes from ordinary knowledge, as best refined by science. Eliezer once <a href=\"/lw/tg/against_modal_logics/\">said</a> that philosophy should be about cognitive science, and Quine would agree. Quine famously <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Quine-Epistemology-Naturalized.pdf\">wrote</a>:</p>\n<blockquote>\n<p>The stimulation of his sensory receptors is all the evidence anybody has had to go on, ultimately, in arriving at his picture of the world. Why not just see how this construction really proceeds? Why not settle for psychology?</p>\n</blockquote>\n<p>But isn't this using science to justify science? Isn't that circular? Not quite, say Quine and Yudkowsky. It is merely \"<a href=\"/lw/s0/where_recursive_justification_hits_bottom/\">reflecting on your mind's degree of trustworthiness, using your current mind as opposed to something else</a>.\" Luckily, the brain is <a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">the lens that sees its flaws</a>. And thus, says Quine:</p>\n<blockquote>\n<p>Epistemology, or something like it, simply falls into place as a chapter of psychology and hence of natural science.</p>\n</blockquote>\n<p>Yudkowsky once <a href=\"/lw/tg/against_modal_logics/\">wrote</a>, \"If there's any centralized repository of reductionist-grade naturalistic cognitive philosophy, I've never heard mention of it.\"</p>\n<p>When I read that I thought: <em>What? That's Quinean naturalism! That's <a href=\"http://en.wikipedia.org/wiki/Hilary_Kornblith\">Kornblith</a> and <a href=\"http://en.wikipedia.org/wiki/Stephen_Stich\">Stich</a> and <a href=\"http://www.philosophyandreligion.msstate.edu/faculty/bickle.php\">Bickle</a> and <a href=\"http://commonsenseatheism.com/?p=11226\">the Churchlands</a> and <a href=\"http://cogsci.uwaterloo.ca/Biographies/pault.html\">Thagard</a>&nbsp;and <a href=\"http://www.philosophie.uni-mainz.de/metzinger/\">Metzinger</a> and <a href=\"http://www.imhr.ca/research/northofflab/index-e.cfm\">Northoff</a>! There are </em>hundreds<em> of philosophers who do that!</em></p>\n<p><a id=\"more\"></a></p>\n<h4><br /></h4>\n<h4><br /></h4>\n<h4><a name=\"non-quine\"></a>Non-Quinean philosophy</h4>\n<p>But I should also mention that LW philosophy / Quinean naturalism is not the <em>largest</em>&nbsp;strain of mainstream philosophy. Most philosophy is still done in relative ignorance (or ignoring) of cognitive science. Consider the preface to <em><a href=\"http://www.amazon.com/Rethinking-Intuition-Michael-R-DePaul/dp/0847687953/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rethinking Intuition</a></em>:</p>\n<blockquote>\n<p>Perhaps more than any other intellectual discipline, philosophical inquiry is driven by intuitive judgments, that is, by what \"we would say\" or by what seems true to the inquirer. For most of philosophical theorizing and debate, intuitions serve as something like a source of evidence that can be used to defend or attack particular philosophical positions.</p>\n<p>One clear example of this is a traditional philosophical enterprise commonly known as <em>conceptual analysis</em>. Anyone familiar with Plato's dialogues knows how this type of inquiry is conducted. We see Socrates encounter someone who claims to have figured out the true essence of some abstract notion... the person puts forward a definition or analysis of the notion in the form of necessary and sufficient conditions that are thought to capture all and only instances of the concept in question. Socrates then refutes his interlocutor's definition of the concept by pointing out various counterexamples...</p>\n<p>For example, in Book I of the <em>Republic</em>, when Cephalus defines justice in a way that requires the returning of property and total honesty, Socrates responds by pointing out that it would be unjust to return weapons to a person who had gone mad or to tell the whole truth to such a person. What is the status of these claims that certain behaviors would be unjust in the circumstances described? Socrates does not argue for them in any way. They seem to be no more than spontaneous judgments representing \"common sense\" or \"what we would say.\" So it would seem that the proposed analysis is rejected because it fails to capture our intuitive judgments about the nature of justice.</p>\n<p>After a proposed analysis or definition is overturned by an intuitive counterexample, the idea is to revise or replace the analysis with one that is not subject to the counterexample. Counterexamples to the new analysis are sought, the analysis revised if any counterexamples are found, and so on...</p>\n<p>Refutations by intuitive counterexamples figure as prominently in today's philosophical journals as they did in Plato's dialogues...</p>\n<p>...philosophers have continued to rely heavily upon intuitive judgments in pretty much the way they always have. And they continue to use them in the absence of any well articulated, generally accepted account of intuitive judgment - in particular, an account that establishes their epistemic credentials.</p>\n<p>However, what appear to be serious new challenges to the way intuitions are employed have recently emerged from an unexpected quarter - empirical research in cognitive psychology.</p>\n<p>With respect to the tradition of seeking definitions or conceptual analyses that are immune to counterexample, the challenge is based on the work of psychologists studying the nature of concepts and categorization of judgments. (See, e.g., Rosch 1978; Rosch and Mervis 1975; Rips 1975; Smith and Medin 1981). Psychologists working in this area have been pushed to abandon the view that we represent concepts with simple sets of necessary and sufficient conditions. The data seem to show that, except for some mathematical and geometrical concepts, it is not possible to use simple sets of conditions to capture the intuitive judgments people make regarding what falls under a given concept...</p>\n<p>With regard to the use of intuitive judgments exemplified by reflective equilibrium, the challenge from cognitive psychology stems primarily from studies of inference strategies and belief revision. (See, e.g., Nisbett and Ross 1980; Kahneman, Slovic, and Tversky 1982.) Numerous studies of the patterns of inductive inference people use and judge to be intuitively plausible have revealed that people are prone to commit various fallacies. Moreover, they continue to find these fallacious patterns of reasoning to be intuitively acceptable upon reflection... Similarly, studies of the \"intuitive\" heuristics ordinary people accept reveal various gross departures from empirically correct principles...</p>\n<p>There is a growing consensus among philosophers that there is a serious and fundamental problem here that needs to be addressed. In fact, we do not think it is an overstatement to say that Western analytic philosophy is, in many respects, undergoing a crisis where there is considerable urgency and anxiety regarding the status of intuitive analysis.</p>\n</blockquote>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>So Less Wrong-style philosophy is part of a movement within mainstream philosophy to massively reform philosophy in light of recent cognitive science - a movement that has been active for at least two decades. Moreover, Less Wrong-style philosophy has its roots in Quinean naturalism from <em>fifty</em>&nbsp;years ago.</p>\n<p>And I haven't even covered all the work in <a href=\"/lw/3n0/an_overview_of_formal_epistemology_links/\">formal epistemology</a> toward (1) mathematically formalizing concepts related to induction, belief, choice, and action, and (2) arguing about the foundations of probability, statistics, game theory, decision theory, and algorithmic learning theory.</p>\n<p>So: Rationalists need not dismiss or avoid philosophy.</p>\n<p><strong>Update: </strong>To be clear, though, I <em>don't</em>&nbsp;recommend reading Quine. Most people should not spend their time reading even Quinean philosophy; learning statistics and AI and cognitive science will be far more useful. All I'm saying is that mainstream philosophy, especially Quinean philosophy, <em>does</em>&nbsp;make some useful contributions. <strong>I've listed more than 20 of mainstream philosophy's useful contributions&nbsp;<a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">here</a>, including several instances of classic LW dissolution-to-algorithm</strong>.</p>\n<p>But maybe it's a testament to the epistemic utility of Less Wrong-ian rationality training and <em>thinking like an AI researcher</em>&nbsp;that Less Wrong got so many things right <em>without</em>&nbsp;much interaction with Quinean naturalism. As Daniel Dennett (2006) said, \"AI makes philosophy honest.\"</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">Philosophy: A Diseased Discipline</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>References</h4>\n<p><small>Dennett (2006). Computers as Prostheses for the Imagination. Talk presented at the International Computers and Philosophy Conference, Laval, France, May 3, 2006.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky (1982).<em>&nbsp;<a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judgment Under Uncertainty: Heuristics and Biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Nisbett and Ross (1980).&nbsp;<em><a href=\"http://www.amazon.com/Human-Inference-Strategies-Shortcomings-Judgement/dp/0134450736/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Human Inference: Strategies and Shortcomings of Social Judgment</a></em>. Prentice-Hall.</small></p>\n<p><small>Rips (1975).&nbsp;Inductive judgments about natural categories. <em>Journal of Verbal Learning and Behavior, 12</em>: 1-20.</small></p>\n<p><small>Rosch (1978).&nbsp;Principles of categorization. In Rosch &amp; Lloyd (eds.), <em>Cognition and Categorization</em> (pp. 27-48). Lawrence Erlbaum Associates.</small></p>\n<p><small>Rosch &amp; Mervis (1975).&nbsp;Family resemblances: studies in the internal structure of categories. Cognitive Psychology, 8: 382-439.</small></p>\n<p><small>Smith &amp; Medin (1981).&nbsp;<em><a href=\"http://www.amazon.com/Categories-Concepts-Cognitive-science-Edward/dp/0674102754/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Concepts and Categories</a></em>. MIT Press.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 3, "fF9GEdWXKJ3z73TmB": 1, "GLykb6NukBeBQtDvQ": 6}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oTX2LXHqXqYg2u4g6", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 148, "baseScore": 157, "extendedScore": null, "score": 0.000286, "legacy": true, "legacyId": "6327", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "philosophy-a-diseased-discipline", "canonicalPrevPostSlug": "", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 157, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>Despite Yudkowsky's&nbsp;<a href=\"/lw/tg/against_modal_logics/\">distaste</a> for mainstream philosophy, Less Wrong is largely a philosophy blog. Major topics include <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">epistemology</a>, <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">philosophy of language</a>, <a href=\"http://wiki.lesswrong.com/wiki/Free_will\">free will</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">metaphysics</a>, <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">metaethics</a>, <a href=\"/lw/n3/circular_altruism/\">normative ethics</a>, <a href=\"http://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence\">machine ethics</a>,&nbsp;<a href=\"/lw/xy/the_fun_theory_sequence/\">axiology</a>, <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">philosophy of mind</a>, and more.</p>\n<p>Moreover, standard Less Wrong positions on philosophical matters have been standard positions in a movement <em>within</em>&nbsp;mainstream philosophy for half a century. That movement is sometimes called \"Quinean naturalism\" after Harvard's&nbsp;<a href=\"http://en.wikipedia.org/wiki/W._V._Quine\">W.V. Quine</a>, who articulated the Less Wrong approach to philosophy in the 1960s. Quine was one of the <a href=\"http://leiterreports.typepad.com/blog/2009/03/so-who-is-the-most-important-philosopher-of-the-past-200-years.html\">most influential</a> philosophers of the last 200 years,&nbsp;so I'm not talking about an <em>obscure</em> movement in philosophy.</p>\n<p>Let us survey the connections. Quine thought that philosophy was continuous with science - and where it wasn't, it was <em>bad</em> philosophy. He embraced empiricism and reductionism. He rejected the notion of libertarian free will. He regarded postmodernism as sophistry. Like Wittgenstein and Yudkowsky, Quine didn't try to straightforwardly <em>solve</em>&nbsp;traditional Big Questions as much as he either <a href=\"/lw/of/dissolving_the_question/\">dissolved those questions</a> or reframed them such that they <em>could</em>&nbsp;be solved.&nbsp;He dismissed endless semantic arguments about the meaning of vague terms like <em>knowledge</em>. He rejected <em>a priori</em>&nbsp;knowledge. He rejected the notion of&nbsp;privileged&nbsp;philosophical insight: knowledge comes from ordinary knowledge, as best refined by science. Eliezer once <a href=\"/lw/tg/against_modal_logics/\">said</a> that philosophy should be about cognitive science, and Quine would agree. Quine famously <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Quine-Epistemology-Naturalized.pdf\">wrote</a>:</p>\n<blockquote>\n<p>The stimulation of his sensory receptors is all the evidence anybody has had to go on, ultimately, in arriving at his picture of the world. Why not just see how this construction really proceeds? Why not settle for psychology?</p>\n</blockquote>\n<p>But isn't this using science to justify science? Isn't that circular? Not quite, say Quine and Yudkowsky. It is merely \"<a href=\"/lw/s0/where_recursive_justification_hits_bottom/\">reflecting on your mind's degree of trustworthiness, using your current mind as opposed to something else</a>.\" Luckily, the brain is <a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">the lens that sees its flaws</a>. And thus, says Quine:</p>\n<blockquote>\n<p>Epistemology, or something like it, simply falls into place as a chapter of psychology and hence of natural science.</p>\n</blockquote>\n<p>Yudkowsky once <a href=\"/lw/tg/against_modal_logics/\">wrote</a>, \"If there's any centralized repository of reductionist-grade naturalistic cognitive philosophy, I've never heard mention of it.\"</p>\n<p>When I read that I thought: <em>What? That's Quinean naturalism! That's <a href=\"http://en.wikipedia.org/wiki/Hilary_Kornblith\">Kornblith</a> and <a href=\"http://en.wikipedia.org/wiki/Stephen_Stich\">Stich</a> and <a href=\"http://www.philosophyandreligion.msstate.edu/faculty/bickle.php\">Bickle</a> and <a href=\"http://commonsenseatheism.com/?p=11226\">the Churchlands</a> and <a href=\"http://cogsci.uwaterloo.ca/Biographies/pault.html\">Thagard</a>&nbsp;and <a href=\"http://www.philosophie.uni-mainz.de/metzinger/\">Metzinger</a> and <a href=\"http://www.imhr.ca/research/northofflab/index-e.cfm\">Northoff</a>! There are </em>hundreds<em> of philosophers who do that!</em></p>\n<p><a id=\"more\"></a></p>\n<h4><br></h4>\n<h4><br></h4>\n<h4 id=\"Non_Quinean_philosophy\"><a name=\"non-quine\"></a>Non-Quinean philosophy</h4>\n<p>But I should also mention that LW philosophy / Quinean naturalism is not the <em>largest</em>&nbsp;strain of mainstream philosophy. Most philosophy is still done in relative ignorance (or ignoring) of cognitive science. Consider the preface to <em><a href=\"http://www.amazon.com/Rethinking-Intuition-Michael-R-DePaul/dp/0847687953/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rethinking Intuition</a></em>:</p>\n<blockquote>\n<p>Perhaps more than any other intellectual discipline, philosophical inquiry is driven by intuitive judgments, that is, by what \"we would say\" or by what seems true to the inquirer. For most of philosophical theorizing and debate, intuitions serve as something like a source of evidence that can be used to defend or attack particular philosophical positions.</p>\n<p>One clear example of this is a traditional philosophical enterprise commonly known as <em>conceptual analysis</em>. Anyone familiar with Plato's dialogues knows how this type of inquiry is conducted. We see Socrates encounter someone who claims to have figured out the true essence of some abstract notion... the person puts forward a definition or analysis of the notion in the form of necessary and sufficient conditions that are thought to capture all and only instances of the concept in question. Socrates then refutes his interlocutor's definition of the concept by pointing out various counterexamples...</p>\n<p>For example, in Book I of the <em>Republic</em>, when Cephalus defines justice in a way that requires the returning of property and total honesty, Socrates responds by pointing out that it would be unjust to return weapons to a person who had gone mad or to tell the whole truth to such a person. What is the status of these claims that certain behaviors would be unjust in the circumstances described? Socrates does not argue for them in any way. They seem to be no more than spontaneous judgments representing \"common sense\" or \"what we would say.\" So it would seem that the proposed analysis is rejected because it fails to capture our intuitive judgments about the nature of justice.</p>\n<p>After a proposed analysis or definition is overturned by an intuitive counterexample, the idea is to revise or replace the analysis with one that is not subject to the counterexample. Counterexamples to the new analysis are sought, the analysis revised if any counterexamples are found, and so on...</p>\n<p>Refutations by intuitive counterexamples figure as prominently in today's philosophical journals as they did in Plato's dialogues...</p>\n<p>...philosophers have continued to rely heavily upon intuitive judgments in pretty much the way they always have. And they continue to use them in the absence of any well articulated, generally accepted account of intuitive judgment - in particular, an account that establishes their epistemic credentials.</p>\n<p>However, what appear to be serious new challenges to the way intuitions are employed have recently emerged from an unexpected quarter - empirical research in cognitive psychology.</p>\n<p>With respect to the tradition of seeking definitions or conceptual analyses that are immune to counterexample, the challenge is based on the work of psychologists studying the nature of concepts and categorization of judgments. (See, e.g., Rosch 1978; Rosch and Mervis 1975; Rips 1975; Smith and Medin 1981). Psychologists working in this area have been pushed to abandon the view that we represent concepts with simple sets of necessary and sufficient conditions. The data seem to show that, except for some mathematical and geometrical concepts, it is not possible to use simple sets of conditions to capture the intuitive judgments people make regarding what falls under a given concept...</p>\n<p>With regard to the use of intuitive judgments exemplified by reflective equilibrium, the challenge from cognitive psychology stems primarily from studies of inference strategies and belief revision. (See, e.g., Nisbett and Ross 1980; Kahneman, Slovic, and Tversky 1982.) Numerous studies of the patterns of inductive inference people use and judge to be intuitively plausible have revealed that people are prone to commit various fallacies. Moreover, they continue to find these fallacious patterns of reasoning to be intuitively acceptable upon reflection... Similarly, studies of the \"intuitive\" heuristics ordinary people accept reveal various gross departures from empirically correct principles...</p>\n<p>There is a growing consensus among philosophers that there is a serious and fundamental problem here that needs to be addressed. In fact, we do not think it is an overstatement to say that Western analytic philosophy is, in many respects, undergoing a crisis where there is considerable urgency and anxiety regarding the status of intuitive analysis.</p>\n</blockquote>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>So Less Wrong-style philosophy is part of a movement within mainstream philosophy to massively reform philosophy in light of recent cognitive science - a movement that has been active for at least two decades. Moreover, Less Wrong-style philosophy has its roots in Quinean naturalism from <em>fifty</em>&nbsp;years ago.</p>\n<p>And I haven't even covered all the work in <a href=\"/lw/3n0/an_overview_of_formal_epistemology_links/\">formal epistemology</a> toward (1) mathematically formalizing concepts related to induction, belief, choice, and action, and (2) arguing about the foundations of probability, statistics, game theory, decision theory, and algorithmic learning theory.</p>\n<p>So: Rationalists need not dismiss or avoid philosophy.</p>\n<p><strong>Update: </strong>To be clear, though, I <em>don't</em>&nbsp;recommend reading Quine. Most people should not spend their time reading even Quinean philosophy; learning statistics and AI and cognitive science will be far more useful. All I'm saying is that mainstream philosophy, especially Quinean philosophy, <em>does</em>&nbsp;make some useful contributions. <strong>I've listed more than 20 of mainstream philosophy's useful contributions&nbsp;<a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">here</a>, including several instances of classic LW dissolution-to-algorithm</strong>.</p>\n<p>But maybe it's a testament to the epistemic utility of Less Wrong-ian rationality training and <em>thinking like an AI researcher</em>&nbsp;that Less Wrong got so many things right <em>without</em>&nbsp;much interaction with Quinean naturalism. As Daniel Dennett (2006) said, \"AI makes philosophy honest.\"</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">Philosophy: A Diseased Discipline</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"References\">References</h4>\n<p><small>Dennett (2006). Computers as Prostheses for the Imagination. Talk presented at the International Computers and Philosophy Conference, Laval, France, May 3, 2006.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky (1982).<em>&nbsp;<a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judgment Under Uncertainty: Heuristics and Biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Nisbett and Ross (1980).&nbsp;<em><a href=\"http://www.amazon.com/Human-Inference-Strategies-Shortcomings-Judgement/dp/0134450736/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Human Inference: Strategies and Shortcomings of Social Judgment</a></em>. Prentice-Hall.</small></p>\n<p><small>Rips (1975).&nbsp;Inductive judgments about natural categories. <em>Journal of Verbal Learning and Behavior, 12</em>: 1-20.</small></p>\n<p><small>Rosch (1978).&nbsp;Principles of categorization. In Rosch &amp; Lloyd (eds.), <em>Cognition and Categorization</em> (pp. 27-48). Lawrence Erlbaum Associates.</small></p>\n<p><small>Rosch &amp; Mervis (1975).&nbsp;Family resemblances: studies in the internal structure of categories. Cognitive Psychology, 8: 382-439.</small></p>\n<p><small>Smith &amp; Medin (1981).&nbsp;<em><a href=\"http://www.amazon.com/Categories-Concepts-Cognitive-science-Edward/dp/0674102754/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Concepts and Categories</a></em>. MIT Press.</small></p>", "sections": [{"title": "Non-Quinean philosophy", "anchor": "Non_Quinean_philosophy", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "336 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 343, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vzLrQaGPa9DNCpuZz", "FaJaCgqBKphrDzDSj", "4ZzefKQwAtMo5yp99", "K4aGvLnHvYgX9pZHS", "Mc6QcrsbH5NRXbCRX", "C8nEXTcjZb9oauTCW", "46qnWRSR7L2eyNbMA", "BXot7wxNbipyM749o", "FwiPfF8Woe5JrzqEu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-03-20T20:28:05.119Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T21:21:35.021Z", "modifiedAt": null, "url": null, "title": "Trip from Ottawa, Canada to NYC on weekend of April 2", "slug": "trip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.190Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oivnz3vuonccDM7r3/trip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "pageUrlRelative": "/posts/oivnz3vuonccDM7r3/trip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "linkUrl": "https://www.lesswrong.com/posts/oivnz3vuonccDM7r3/trip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Trip%20from%20Ottawa%2C%20Canada%20to%20NYC%20on%20weekend%20of%20April%202&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATrip%20from%20Ottawa%2C%20Canada%20to%20NYC%20on%20weekend%20of%20April%202%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Foivnz3vuonccDM7r3%2Ftrip-from-ottawa-canada-to-nyc-on-weekend-of-april-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Trip%20from%20Ottawa%2C%20Canada%20to%20NYC%20on%20weekend%20of%20April%202%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Foivnz3vuonccDM7r3%2Ftrip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Foivnz3vuonccDM7r3%2Ftrip-from-ottawa-canada-to-nyc-on-weekend-of-april-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p><del>I'm contemplating&nbsp;</del> I've decided to make a trip from Ottawa, Canada&nbsp;to New York City on the weekend of April 2-3 specifically in the hopes of meeting some members of the LW NYC Chapter (and EY as well, if I can manage it). Since I don't know anyone in the city, I'm hoping this discussion post will generate interest in having some kind of get-together on that weekend.</p>\r\n<p>Anyone in the national capital region is welcome to contact me in comments or by PM to get in on the action. (I've already canvassed XFrequentist and received a positive reply.) Cosmos has offered to let me crash at his place, but I haven't asked him about extra space for other folk.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oivnz3vuonccDM7r3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 6.923768301494328e-07, "legacy": true, "legacyId": "6329", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-20T22:44:30.679Z", "modifiedAt": null, "url": null, "title": "Project Ideas for the London Hackday", "slug": "project-ideas-for-the-london-hackday", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.452Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tQ5AxChGZz5RvWBD2/project-ideas-for-the-london-hackday", "pageUrlRelative": "/posts/tQ5AxChGZz5RvWBD2/project-ideas-for-the-london-hackday", "linkUrl": "https://www.lesswrong.com/posts/tQ5AxChGZz5RvWBD2/project-ideas-for-the-london-hackday", "postedAtFormatted": "Sunday, March 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Project%20Ideas%20for%20the%20London%20Hackday&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProject%20Ideas%20for%20the%20London%20Hackday%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQ5AxChGZz5RvWBD2%2Fproject-ideas-for-the-london-hackday%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Project%20Ideas%20for%20the%20London%20Hackday%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQ5AxChGZz5RvWBD2%2Fproject-ideas-for-the-london-hackday", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtQ5AxChGZz5RvWBD2%2Fproject-ideas-for-the-london-hackday", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 110, "htmlBody": "<p>So, the London community is arranging a Hackday where some of us will get together and code. In order to ensure we work on the awesomest idea(s) possible, we decided to ask LessWrong to add to our list of candidates. So here is the question:</p>\n<p>What could a few developers do in a day or less worth of coding that will be awesome? Also, as a way of checking calibration, you can give your estimate for how long such a thing would take to build.</p>\n<p><em>Note: While we will take ideas and voting here into account, there is no guarantee that we will actually end up choosing one or more of them.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tQ5AxChGZz5RvWBD2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 6.92399562701484e-07, "legacy": true, "legacyId": "6330", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-21T03:18:43.782Z", "modifiedAt": null, "url": null, "title": "Singularity goes mainstream (in philosophy)", "slug": "singularity-goes-mainstream-in-philosophy", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:02.886Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BmuKPs5PfvK3RaXeY/singularity-goes-mainstream-in-philosophy", "pageUrlRelative": "/posts/BmuKPs5PfvK3RaXeY/singularity-goes-mainstream-in-philosophy", "linkUrl": "https://www.lesswrong.com/posts/BmuKPs5PfvK3RaXeY/singularity-goes-mainstream-in-philosophy", "postedAtFormatted": "Monday, March 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20goes%20mainstream%20(in%20philosophy)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20goes%20mainstream%20(in%20philosophy)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBmuKPs5PfvK3RaXeY%2Fsingularity-goes-mainstream-in-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20goes%20mainstream%20(in%20philosophy)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBmuKPs5PfvK3RaXeY%2Fsingularity-goes-mainstream-in-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBmuKPs5PfvK3RaXeY%2Fsingularity-goes-mainstream-in-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>The journal (JCS) that published <a href=\"/lw/42l/david_chalmers_the_singularity_a_philosophical/\">Chalmers' article on the singularity</a> will be devoting an entire issue in January 2012 to responses to Chalmers' article.&nbsp;Authors who have agreed to contribute so far <a href=\"http://fragments.consc.net/djc/2010/12/singularity-symposium.html\">include</a> big names like Ned Block, Paul Churchland, Dan Dennett, Jesse Prinz, Drew McDermott, and Robert Sawyer. (Also, Kevin Kelly and Ray Kurzweil.)</p>\n<p>JCS is also accepting submissions. See the last page of <a href=\"http://consc.net/papers/singularityjcs.pdf\">this PDF</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"CztjQPSTuaQcfbyh8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BmuKPs5PfvK3RaXeY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 43, "extendedScore": null, "score": 6.924747422488614e-07, "legacy": true, "legacyId": "6335", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Sh4HPbqRDJsbB9ENK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-21T09:57:21.910Z", "modifiedAt": null, "url": null, "title": "The Stoner Arms Dealers [link via longform.org]", "slug": "the-stoner-arms-dealers-link-via-longform-org", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:02.672Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xh5H2jaFN6X5eXmHD/the-stoner-arms-dealers-link-via-longform-org", "pageUrlRelative": "/posts/Xh5H2jaFN6X5eXmHD/the-stoner-arms-dealers-link-via-longform-org", "linkUrl": "https://www.lesswrong.com/posts/Xh5H2jaFN6X5eXmHD/the-stoner-arms-dealers-link-via-longform-org", "postedAtFormatted": "Monday, March 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Stoner%20Arms%20Dealers%20%5Blink%20via%20longform.org%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Stoner%20Arms%20Dealers%20%5Blink%20via%20longform.org%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5H2jaFN6X5eXmHD%2Fthe-stoner-arms-dealers-link-via-longform-org%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Stoner%20Arms%20Dealers%20%5Blink%20via%20longform.org%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5H2jaFN6X5eXmHD%2Fthe-stoner-arms-dealers-link-via-longform-org", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5H2jaFN6X5eXmHD%2Fthe-stoner-arms-dealers-link-via-longform-org", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.rollingstone.com/politics/news/the-stoner-arms-dealers-20110316?print=true\">http://www.rollingstone.com/politics/news/the-stoner-arms-dealers-20110316?print=true</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xh5H2jaFN6X5eXmHD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": -27, "extendedScore": null, "score": 6.925840576164259e-07, "legacy": true, "legacyId": "6343", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-21T18:11:15.940Z", "modifiedAt": null, "url": null, "title": "Tortuga Meetups Starting this Thursday", "slug": "tortuga-meetups-starting-this-thursday", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.383Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "divia", "createdAt": "2009-02-28T01:56:35.966Z", "isAdmin": false, "displayName": "divia"}, "userId": "CQzR9QRTNKQ9Qmsjc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xXbgHEWQb6h9RiH5v/tortuga-meetups-starting-this-thursday", "pageUrlRelative": "/posts/xXbgHEWQb6h9RiH5v/tortuga-meetups-starting-this-thursday", "linkUrl": "https://www.lesswrong.com/posts/xXbgHEWQb6h9RiH5v/tortuga-meetups-starting-this-thursday", "postedAtFormatted": "Monday, March 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tortuga%20Meetups%20Starting%20this%20Thursday&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATortuga%20Meetups%20Starting%20this%20Thursday%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXbgHEWQb6h9RiH5v%2Ftortuga-meetups-starting-this-thursday%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tortuga%20Meetups%20Starting%20this%20Thursday%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXbgHEWQb6h9RiH5v%2Ftortuga-meetups-starting-this-thursday", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxXbgHEWQb6h9RiH5v%2Ftortuga-meetups-starting-this-thursday", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p><a href=\"http://starrynightcoaching.com/\">Shannon</a> and I are going to be hosting South Bay Less Wrong meetups at the <a href=\"http://tortuga.coop/index.php\">Tortuga community</a> in Mountain View on Thursday nights starting at 7. &nbsp;Come prepared to reveal something you're consistently irrational about. &nbsp;We'll spend some time throwing ideas around and then hang out and mingle. &nbsp;</p>\n<p>Bringing paleo-friendly food is a bonus but not required. &nbsp;</p>\n<p>If you'd like to come, request an invitation from our google group, <a href=\"http://groups.google.com/group/tortuga-rationalists\">Tortuga Rationalists</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xXbgHEWQb6h9RiH5v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 6.927195394532484e-07, "legacy": true, "legacyId": "6344", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-21T20:14:08.063Z", "modifiedAt": null, "url": null, "title": "On Branching vs Probability", "slug": "on-branching-vs-probability", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:06.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlephNeil", "createdAt": "2010-05-12T14:43:28.879Z", "isAdmin": false, "displayName": "AlephNeil"}, "userId": "qSNSSwAXbki7JTNSd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gCrLapNsw5xnWBr7q/on-branching-vs-probability", "pageUrlRelative": "/posts/gCrLapNsw5xnWBr7q/on-branching-vs-probability", "linkUrl": "https://www.lesswrong.com/posts/gCrLapNsw5xnWBr7q/on-branching-vs-probability", "postedAtFormatted": "Monday, March 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Branching%20vs%20Probability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Branching%20vs%20Probability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgCrLapNsw5xnWBr7q%2Fon-branching-vs-probability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Branching%20vs%20Probability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgCrLapNsw5xnWBr7q%2Fon-branching-vs-probability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgCrLapNsw5xnWBr7q%2Fon-branching-vs-probability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1776, "htmlBody": "<p>Abstract: A boring, long-winded account of some extremely basic ideas is given.</p>\n<h3>The \"Coin Universe\"</h3>\n<p>Imagine a universe split into subsystems A and B, where causal influences go from A to B but not vice versa. A is extremely simple - each day either a \"heads event\" or \"tails event\" takes place, which is visible to observers in B as a red or green patch at a certain place in the sky. In fact, coin events are the only 'communication' between A and B.</p>\n<p>Naturally, the observers in B would like to understand the pattern of coin events so they formulate some theories.</p>\n<h3>Two Rival Theories</h3>\n<p><strong>Theory 1:</strong> Every day, the universe 'splits' into two. The entire contents of B are 'copied' somehow. One copy sees a heads event, the other copy sees a tails event.</p>\n<p><strong>Theory 2:</strong>&nbsp;There is no splitting. Instead, some kind of (deterministic or stochastic) process in A is producing the sequence of events. As a special case (<strong>Theory 2a</strong>) it could be that each coin event is independent and random, and has a probability 1/2 of being heads. (Let's also write down another special case (<strong>Theory 2b</strong>) where each coin event has probability 9/10 of being heads.)</p>\n<h3>The Position of Jupiter</h3>\n<p>Imagine that we're primitive astronomers trying to understand the trajectory of Jupiter through the sky. We take for granted that our observations are indexed by a variable called \"time\" and that a complete theory of Jupiter's trajectory would have the form: \"Position of Jupiter at time t = F(t)\" for some function F that we can calculate. Suppose such a theory is formulated.</p>\n<p>However, if we believe in a point P such that P is \"the position of Jupiter\" then the theory does not resolve all of our uncertainty about P, for it merely tells us: \"If you ask the question at time t then the answer is F(t).\" If the question is asked \"timelessly\" then there is no unique answer. There isn't even a probability distribution over the set of possible answers, because there is no 'probability distribution over time'.<sup>1</sup></p>\n<h3>Theories 1 and 2 are Incommensurable</h3>\n<p>Can the scientists in the Coin Universe decide empirically between Theories 1 and 2a? Imagine that our scientists already have a 'theory of everything' for B's own physics, and that coin events are the only phenomena about which there remains controversy.</p>\n<div>Barbara believes in theory 2a and she thinks that the probability that the next toss is heads is 1/2. Alfred believes in theory 1 and thinks that the concept of \"tomorrow's coin event\" is as meaningless as the concept of \"the (timeless) position of Jupiter\".&nbsp;Whereas Barbara indexes time using real numbers, Alfred indexes time by pairs consisting of a real number and a sequence of prior coin events. Barbara cannot use Bayesian reasoning to discriminate 1 and 2a because from her perspective, theory 1 is incomplete - it refuses to make a prediction about \"tomorrow's coin event\". On the other hand, when Alfred tries to put Barbara's theory into a form that he can test, by taking out the meaningless notion of \"tomorrow's coin event\", he discovers that what's left is exactly his own theory.</div>\n<p>In fact, the same problem arises for&nbsp;<em>every</em>&nbsp;variation of Theory 2 (except those which sometimes predict a probability or 1 or 0).&nbsp;Variations of Theory 2 can be tested against each other, but not against Theory 1.</p>\n<h3>Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?</h3>\n<p>If the universe is splitting then a 'history of the universe' looks like a branching tree rather than a line. Now, I'm taking for granted an 'objective' concept of probability in which the set &Omega;&nbsp;of possible histories of the universe has the structure of a 'probability space', so that the only things which can be assigned ('objective') probabilities are subsets of&nbsp;&Omega;. So for any event E with a well-defined probability, and any possible history H, E must either contain all of H or else none of it. Hence, it makes no sense to look at some branch B within H and ask about \"the probability that B is true\". (Any more than we can look at a particular person in the world and ask \"what is the probability of being this person?\")</p>\n<p>A natural response might be as follows:</p>\n<p style=\"padding-left: 30px;\">Surely if time is a branching tree then all we have to do to define the probabilities of branches is say that the probability of a 'child node' is the probability of its parent divided by the number of 'children'. So we could simulate Theory 2a within a purely deterministic universe by having one 'heads branch' and one 'tails branch' each day of the simulation, or we could simulate Theory 2b instead by having nine 'heads branches' and only one 'tails'.</p>\n<p style=\"padding-left: 30px;\">Observers in the first simulation would experience 1/2 probabilities of heads, while observers in the second would experience 9/10 probabilities.</p>\n<p>(Note: We can make this idea of \"experiencing 1/2\" or \"experiencing 9/10\" more vivid by supposing that 'days' happen extremely quickly, so that experiencing 1/2 would mean that the relevant patch of sky is flickering between red and green so fast that it looks yellow, whereas 9/10 would equate to an orangey-red.)</p>\n<h3>The Lesson of the&nbsp;<a href=\"/lw/ps/where_physics_meets_experience/\">Ebborians</a></h3>\n<p>Consider the Ebborian universe. It has five dimensions: three 'ordinary' spatial dimensions, one of time and an 'extra' dimension reserved for 'splitting'. If you were to draw a cross section of the Ebborian universe along the temporal and the 'extra' dimension, you would see a branching tree. Suppose for simplicity that all such cross sections look alike, so that each time the universe 'splits' it happens everywhere simultaneously. Now, a critical point in Eliezer's fable is that the branches have thickness, and the subjective probability of finding yourself in a child branch is supposed to be proportional to the&nbsp;<em>square</em>&nbsp;of that branch's thickness. For my purposes I want branches to have widths, such that the width of a parent branch equal the sum of widths of its children, but I want to discard the idea of squaring. Imagine that the only times the universe 'splits' are once a day when a red or green light appears somewhere in the sky, which the Ebborians call a \"heads event\" or \"tails event\" respectively. Hmm, this sounds familiar...</p>\n<p>Prima facie it seems that we've reconstructed a version of the Coin Universe which (a) contains \"splitting\" and (b) contains \"objective probabilities\" (which \"clearly\" ought to be proportional to the widths of branches).</p>\n<p>What I want to ask is: why exactly should 'width along the extra dimension' be proportional to 'probability'? One possible answer would be \"that's just what the extra dimension&nbsp;<em>is</em>. It's&nbsp;<em>intrinsically</em>&nbsp;a 'dimension of probability'.\" That's fine, I guess, but then I want to say that the difference between this Coin Universe and one described by Theory 2 is purely verbal. But now suppose the extra dimension is just an ordinary spatial dimension (whatever that means). Then where does the rule 'probability = thickness' come from, when there are so many other possibilities? E.g. \"At any branch point, the ratio of the probability of the left branch to the probability of the right branch is 9 * (width of left branch) to 1 * (width of right branch).\" If this was the rule then even though uniform branch widths may suggest that Theory 2a is correct, the 'experienced probabilities' would be those of Theory 2b. (If days were extremely rapid, the sky would look orange-red rather than yellow.)</p>\n<p>If the extra dimension is not explicitly a 'dimension of probability' then the 'experienced probabilities' will be indeterminate without a 'bridge law' connecting width and probability. But the difference between (\"extra dimension is spatial\" + bridge law connecting branch widths and probability) and (\"extra dimension is probability\" + bridge law connecting probabilities with epiphenomenal 'branch widths') is purely verbal.</p>\n<p>So ultimately the only two possibilities are (i) the extra dimension is a 'dimension of probability', and there is at best 'epiphenomenal splitting'; or else (ii) the probabilities are indeterminate.</p>\n<p>Of various possible conclusions, one in particular seems worth noting down: If we are attempting to simulate a Coin Universe by computing all of its branches at once, then regardless of how we 'tag' or 'weight' the branches to indicate their supposed probabilities, we should not think that we are thereby affecting the experiences of the simulated beings. (So ignoring 'externalities' there's no moral imperative that we should prefer two copies of a happy simulation and one of a sad simulation over two 'sad' simulations and one 'happy', any more than that we should stick pieces of paper to the computer cases saying \"probability 9/10\" and \"probability 1/10\".)</p>\n<h3><br /></h3>\n<h3>Implications For MWI?</h3>\n<p>MWI emphatically does&nbsp;<em>not&nbsp;</em>assert that time 'splits into branches', so it's not immediately clear that there are any implications for MWI or what they would be if there were. For what it's worth, my current way of thinking is that a quantum theory is neither \"deterministic\" nor \"probabilistic\" but just \"quantum\". I'm beginning to suspect that MWI is what you get when you mistakenly try to conceive of a quantum theory as deterministic. Two things in particular have led me to this view: (i) Scott Aaronson's&nbsp;<a href=\"http://www.scottaaronson.com/democritus/lec9.html\">lecture</a>&nbsp;and (ii)&nbsp;<a href=\"http://xxx.lanl.gov/abs/quant-ph/0003084\">this paper</a>&nbsp;which goes a considerable way towards demolishing what I had previously taken to be one of the strongest reasons for 'believing in' many worlds. However, my thoughts on this are extremely half-baked and subject to revision.</p>\n<h3>Is Probability Reducible?</h3>\n<p>It's conspicuous that the discussion above presupposes that probabilities - \"real probabilities\" - are or might be 'built in' at the 'ground floor' of reality. However,&nbsp;<a href=\"/lw/2lj/what_a_reduction_of_probability_probably_looks/\">others</a>&nbsp;have made ingenious attempts to show how (our concepts and perceptions of) probability can arise perfectly well even if the universe doesn't presuppose it. I'm not averse to this project - in fact it parallels Dennett's strategy in the philosophy of mind, namely to show how it can 'seem like' we have 'qualia' even in a world where no such things exist.</p>\n<p>Anyway, I seem to be converging onto user cousin_it's statement: \"Perhaps counterintuitively, the easiest way for probabilities to arise is&nbsp;<em>not&nbsp;</em>by postulating 'different worlds' that you could 'end up' in starting from now.\"&nbsp;</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp;Perhaps Julian Barbour would disagree. However, for the purposes of my discussion, I'm presupposing the naive 'common sense' view of time where 'the facts' about a (classical) universe are exhausted precisely when we've specified \"the state of affairs at every moment of time\". Another possible objection is that because Jupiter's position in the sky repeats cyclically, we can define 'time averages' after all. Well, let's just suppose that these astronomers are able to detect the slight deviations due to e.g. the solar wind pushing Jupiter away and lengthening its orbit. (If you're still bothered, imagine replacing 'position of Jupiter' with 'brightness of the Sun', which is gradually increasing on a geological timescale.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gCrLapNsw5xnWBr7q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 12, "extendedScore": null, "score": 6.92753250850943e-07, "legacy": true, "legacyId": "6173", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Abstract: A boring, long-winded account of some extremely basic ideas is given.</p>\n<h3 id=\"The__Coin_Universe_\">The \"Coin Universe\"</h3>\n<p>Imagine a universe split into subsystems A and B, where causal influences go from A to B but not vice versa. A is extremely simple - each day either a \"heads event\" or \"tails event\" takes place, which is visible to observers in B as a red or green patch at a certain place in the sky. In fact, coin events are the only 'communication' between A and B.</p>\n<p>Naturally, the observers in B would like to understand the pattern of coin events so they formulate some theories.</p>\n<h3 id=\"Two_Rival_Theories\">Two Rival Theories</h3>\n<p><strong>Theory 1:</strong> Every day, the universe 'splits' into two. The entire contents of B are 'copied' somehow. One copy sees a heads event, the other copy sees a tails event.</p>\n<p><strong>Theory 2:</strong>&nbsp;There is no splitting. Instead, some kind of (deterministic or stochastic) process in A is producing the sequence of events. As a special case (<strong>Theory 2a</strong>) it could be that each coin event is independent and random, and has a probability 1/2 of being heads. (Let's also write down another special case (<strong>Theory 2b</strong>) where each coin event has probability 9/10 of being heads.)</p>\n<h3 id=\"The_Position_of_Jupiter\">The Position of Jupiter</h3>\n<p>Imagine that we're primitive astronomers trying to understand the trajectory of Jupiter through the sky. We take for granted that our observations are indexed by a variable called \"time\" and that a complete theory of Jupiter's trajectory would have the form: \"Position of Jupiter at time t = F(t)\" for some function F that we can calculate. Suppose such a theory is formulated.</p>\n<p>However, if we believe in a point P such that P is \"the position of Jupiter\" then the theory does not resolve all of our uncertainty about P, for it merely tells us: \"If you ask the question at time t then the answer is F(t).\" If the question is asked \"timelessly\" then there is no unique answer. There isn't even a probability distribution over the set of possible answers, because there is no 'probability distribution over time'.<sup>1</sup></p>\n<h3 id=\"Theories_1_and_2_are_Incommensurable\">Theories 1 and 2 are Incommensurable</h3>\n<p>Can the scientists in the Coin Universe decide empirically between Theories 1 and 2a? Imagine that our scientists already have a 'theory of everything' for B's own physics, and that coin events are the only phenomena about which there remains controversy.</p>\n<div>Barbara believes in theory 2a and she thinks that the probability that the next toss is heads is 1/2. Alfred believes in theory 1 and thinks that the concept of \"tomorrow's coin event\" is as meaningless as the concept of \"the (timeless) position of Jupiter\".&nbsp;Whereas Barbara indexes time using real numbers, Alfred indexes time by pairs consisting of a real number and a sequence of prior coin events. Barbara cannot use Bayesian reasoning to discriminate 1 and 2a because from her perspective, theory 1 is incomplete - it refuses to make a prediction about \"tomorrow's coin event\". On the other hand, when Alfred tries to put Barbara's theory into a form that he can test, by taking out the meaningless notion of \"tomorrow's coin event\", he discovers that what's left is exactly his own theory.</div>\n<p>In fact, the same problem arises for&nbsp;<em>every</em>&nbsp;variation of Theory 2 (except those which sometimes predict a probability or 1 or 0).&nbsp;Variations of Theory 2 can be tested against each other, but not against Theory 1.</p>\n<h3 id=\"Why_Should__Splitting__Entail_That_Probabilities_Aren_t_Well_Defined_\">Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?</h3>\n<p>If the universe is splitting then a 'history of the universe' looks like a branching tree rather than a line. Now, I'm taking for granted an 'objective' concept of probability in which the set \u03a9&nbsp;of possible histories of the universe has the structure of a 'probability space', so that the only things which can be assigned ('objective') probabilities are subsets of&nbsp;\u03a9. So for any event E with a well-defined probability, and any possible history H, E must either contain all of H or else none of it. Hence, it makes no sense to look at some branch B within H and ask about \"the probability that B is true\". (Any more than we can look at a particular person in the world and ask \"what is the probability of being this person?\")</p>\n<p>A natural response might be as follows:</p>\n<p style=\"padding-left: 30px;\">Surely if time is a branching tree then all we have to do to define the probabilities of branches is say that the probability of a 'child node' is the probability of its parent divided by the number of 'children'. So we could simulate Theory 2a within a purely deterministic universe by having one 'heads branch' and one 'tails branch' each day of the simulation, or we could simulate Theory 2b instead by having nine 'heads branches' and only one 'tails'.</p>\n<p style=\"padding-left: 30px;\">Observers in the first simulation would experience 1/2 probabilities of heads, while observers in the second would experience 9/10 probabilities.</p>\n<p>(Note: We can make this idea of \"experiencing 1/2\" or \"experiencing 9/10\" more vivid by supposing that 'days' happen extremely quickly, so that experiencing 1/2 would mean that the relevant patch of sky is flickering between red and green so fast that it looks yellow, whereas 9/10 would equate to an orangey-red.)</p>\n<h3 id=\"The_Lesson_of_the_Ebborians\">The Lesson of the&nbsp;<a href=\"/lw/ps/where_physics_meets_experience/\">Ebborians</a></h3>\n<p>Consider the Ebborian universe. It has five dimensions: three 'ordinary' spatial dimensions, one of time and an 'extra' dimension reserved for 'splitting'. If you were to draw a cross section of the Ebborian universe along the temporal and the 'extra' dimension, you would see a branching tree. Suppose for simplicity that all such cross sections look alike, so that each time the universe 'splits' it happens everywhere simultaneously. Now, a critical point in Eliezer's fable is that the branches have thickness, and the subjective probability of finding yourself in a child branch is supposed to be proportional to the&nbsp;<em>square</em>&nbsp;of that branch's thickness. For my purposes I want branches to have widths, such that the width of a parent branch equal the sum of widths of its children, but I want to discard the idea of squaring. Imagine that the only times the universe 'splits' are once a day when a red or green light appears somewhere in the sky, which the Ebborians call a \"heads event\" or \"tails event\" respectively. Hmm, this sounds familiar...</p>\n<p>Prima facie it seems that we've reconstructed a version of the Coin Universe which (a) contains \"splitting\" and (b) contains \"objective probabilities\" (which \"clearly\" ought to be proportional to the widths of branches).</p>\n<p>What I want to ask is: why exactly should 'width along the extra dimension' be proportional to 'probability'? One possible answer would be \"that's just what the extra dimension&nbsp;<em>is</em>. It's&nbsp;<em>intrinsically</em>&nbsp;a 'dimension of probability'.\" That's fine, I guess, but then I want to say that the difference between this Coin Universe and one described by Theory 2 is purely verbal. But now suppose the extra dimension is just an ordinary spatial dimension (whatever that means). Then where does the rule 'probability = thickness' come from, when there are so many other possibilities? E.g. \"At any branch point, the ratio of the probability of the left branch to the probability of the right branch is 9 * (width of left branch) to 1 * (width of right branch).\" If this was the rule then even though uniform branch widths may suggest that Theory 2a is correct, the 'experienced probabilities' would be those of Theory 2b. (If days were extremely rapid, the sky would look orange-red rather than yellow.)</p>\n<p>If the extra dimension is not explicitly a 'dimension of probability' then the 'experienced probabilities' will be indeterminate without a 'bridge law' connecting width and probability. But the difference between (\"extra dimension is spatial\" + bridge law connecting branch widths and probability) and (\"extra dimension is probability\" + bridge law connecting probabilities with epiphenomenal 'branch widths') is purely verbal.</p>\n<p>So ultimately the only two possibilities are (i) the extra dimension is a 'dimension of probability', and there is at best 'epiphenomenal splitting'; or else (ii) the probabilities are indeterminate.</p>\n<p>Of various possible conclusions, one in particular seems worth noting down: If we are attempting to simulate a Coin Universe by computing all of its branches at once, then regardless of how we 'tag' or 'weight' the branches to indicate their supposed probabilities, we should not think that we are thereby affecting the experiences of the simulated beings. (So ignoring 'externalities' there's no moral imperative that we should prefer two copies of a happy simulation and one of a sad simulation over two 'sad' simulations and one 'happy', any more than that we should stick pieces of paper to the computer cases saying \"probability 9/10\" and \"probability 1/10\".)</p>\n<h3><br></h3>\n<h3 id=\"Implications_For_MWI_\">Implications For MWI?</h3>\n<p>MWI emphatically does&nbsp;<em>not&nbsp;</em>assert that time 'splits into branches', so it's not immediately clear that there are any implications for MWI or what they would be if there were. For what it's worth, my current way of thinking is that a quantum theory is neither \"deterministic\" nor \"probabilistic\" but just \"quantum\". I'm beginning to suspect that MWI is what you get when you mistakenly try to conceive of a quantum theory as deterministic. Two things in particular have led me to this view: (i) Scott Aaronson's&nbsp;<a href=\"http://www.scottaaronson.com/democritus/lec9.html\">lecture</a>&nbsp;and (ii)&nbsp;<a href=\"http://xxx.lanl.gov/abs/quant-ph/0003084\">this paper</a>&nbsp;which goes a considerable way towards demolishing what I had previously taken to be one of the strongest reasons for 'believing in' many worlds. However, my thoughts on this are extremely half-baked and subject to revision.</p>\n<h3 id=\"Is_Probability_Reducible_\">Is Probability Reducible?</h3>\n<p>It's conspicuous that the discussion above presupposes that probabilities - \"real probabilities\" - are or might be 'built in' at the 'ground floor' of reality. However,&nbsp;<a href=\"/lw/2lj/what_a_reduction_of_probability_probably_looks/\">others</a>&nbsp;have made ingenious attempts to show how (our concepts and perceptions of) probability can arise perfectly well even if the universe doesn't presuppose it. I'm not averse to this project - in fact it parallels Dennett's strategy in the philosophy of mind, namely to show how it can 'seem like' we have 'qualia' even in a world where no such things exist.</p>\n<p>Anyway, I seem to be converging onto user cousin_it's statement: \"Perhaps counterintuitively, the easiest way for probabilities to arise is&nbsp;<em>not&nbsp;</em>by postulating 'different worlds' that you could 'end up' in starting from now.\"&nbsp;</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp;Perhaps Julian Barbour would disagree. However, for the purposes of my discussion, I'm presupposing the naive 'common sense' view of time where 'the facts' about a (classical) universe are exhausted precisely when we've specified \"the state of affairs at every moment of time\". Another possible objection is that because Jupiter's position in the sky repeats cyclically, we can define 'time averages' after all. Well, let's just suppose that these astronomers are able to detect the slight deviations due to e.g. the solar wind pushing Jupiter away and lengthening its orbit. (If you're still bothered, imagine replacing 'position of Jupiter' with 'brightness of the Sun', which is gradually increasing on a geological timescale.)</p>", "sections": [{"title": "The \"Coin Universe\"", "anchor": "The__Coin_Universe_", "level": 1}, {"title": "Two Rival Theories", "anchor": "Two_Rival_Theories", "level": 1}, {"title": "The Position of Jupiter", "anchor": "The_Position_of_Jupiter", "level": 1}, {"title": "Theories 1 and 2 are Incommensurable", "anchor": "Theories_1_and_2_are_Incommensurable", "level": 1}, {"title": "Why Should 'Splitting' Entail That Probabilities Aren't Well Defined?", "anchor": "Why_Should__Splitting__Entail_That_Probabilities_Aren_t_Well_Defined_", "level": 1}, {"title": "The Lesson of the\u00a0Ebborians", "anchor": "The_Lesson_of_the_Ebborians", "level": 1}, {"title": "Implications For MWI?", "anchor": "Implications_For_MWI_", "level": 1}, {"title": "Is Probability Reducible?", "anchor": "Is_Probability_Reducible_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "33 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WajiC3YWeJutyAXTn", "As3Xjtj2TRRar7bSX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-21T22:26:57.329Z", "modifiedAt": null, "url": null, "title": "Google lends further legitimacy to Bitcoin", "slug": "google-lends-further-legitimacy-to-bitcoin", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:18.078Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rPBgKcH3MRry78TTL/google-lends-further-legitimacy-to-bitcoin", "pageUrlRelative": "/posts/rPBgKcH3MRry78TTL/google-lends-further-legitimacy-to-bitcoin", "linkUrl": "https://www.lesswrong.com/posts/rPBgKcH3MRry78TTL/google-lends-further-legitimacy-to-bitcoin", "postedAtFormatted": "Monday, March 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Google%20lends%20further%20legitimacy%20to%20Bitcoin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGoogle%20lends%20further%20legitimacy%20to%20Bitcoin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBgKcH3MRry78TTL%2Fgoogle-lends-further-legitimacy-to-bitcoin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Google%20lends%20further%20legitimacy%20to%20Bitcoin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBgKcH3MRry78TTL%2Fgoogle-lends-further-legitimacy-to-bitcoin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBgKcH3MRry78TTL%2Fgoogle-lends-further-legitimacy-to-bitcoin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>Though not yet an \"official\" project, Google <a href=\"http://www.techworld.com.au/article/380396/google_releases_open_source_bitcoin_client/\">has released</a> a <a href=\"http://code.google.com/p/bitcoinj/\">Bitcoin client</a>. As you may remember, there <a href=\"/lw/4mc/singularity_institute_now_accepts_donations_via/3m72\">were concerns</a> here about what the government/legal reaction to <a href=\"http://www.bitcoin.org/\">Bitcoin</a>&nbsp;[1] will be, and the significance of certain groups lending their support to it.&nbsp; EFF and SIAI accept Bitcoin donations, which helps, and this action by Google is another big step.</p>\r\n<p>Previous articles: <a href=\"/lw/4mc/singularity_institute_now_accepts_donations_via/\">SIAI accepting Bitcoin donations</a>, <a href=\"/lw/4cs/making_money_with_bitcoin/\">Discussion on making money with Bitcoin</a> (Clippy warning on the latter)</p>\r\n<p>[1] In short, it's an&nbsp;anonymous P2P&nbsp;crypto-currency with no transaction fees, in which new units are generated by spending computer cycles computing hashes until you find one with specific properties.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rPBgKcH3MRry78TTL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 6.92789696137262e-07, "legacy": true, "legacyId": "6345", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jLAw6dPGZCRnpNgxM", "ijr8rsyvJci2edxot"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T02:19:46.632Z", "modifiedAt": null, "url": null, "title": "Costs and Benefits of Scholarship", "slug": "costs-and-benefits-of-scholarship", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.036Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TFbAMgeiCLjdX4Smw/costs-and-benefits-of-scholarship", "pageUrlRelative": "/posts/TFbAMgeiCLjdX4Smw/costs-and-benefits-of-scholarship", "linkUrl": "https://www.lesswrong.com/posts/TFbAMgeiCLjdX4Smw/costs-and-benefits-of-scholarship", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Costs%20and%20Benefits%20of%20Scholarship&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACosts%20and%20Benefits%20of%20Scholarship%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFbAMgeiCLjdX4Smw%2Fcosts-and-benefits-of-scholarship%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Costs%20and%20Benefits%20of%20Scholarship%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFbAMgeiCLjdX4Smw%2Fcosts-and-benefits-of-scholarship", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFbAMgeiCLjdX4Smw%2Fcosts-and-benefits-of-scholarship", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1198, "htmlBody": "<p><a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">Scholarship</a> <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">is</a> <a href=\"/lw/2un/references_resources_for_lesswrong/\">excellent</a>, but it is also <em>expensive</em>. It takes a long time to catch up to the state of the art, even for a narrow subject.</p>\n<p>I recently read 90% of the literature on <a href=\"http://commonsenseatheism.com/?p=14597\">machine ethics</a>, a&nbsp;recent and small field of inquiry, and it took me about 40 hours to find all the literature, acquire it, and read (or skim) through it. Doing the same thing for an older and larger subject will take <em>far </em>more&nbsp;time than that. And of course <em>most</em>&nbsp;of the literature on <em>any</em>&nbsp;subject is not valuable.</p>\n<p>Other times, you get lucky. Let's say you want to figure out <a href=\"/lw/3w3/how_to_beat_procrastination/\">how to beat procrastination</a>. You could <a href=\"/lw/3kv/working_hurts_less_than_procrastinating_we_fear/\">introspect</a> your way to a plausible solution, but you might end up being wrong. So, you check <a href=\"http://en.wikipedia.org/wiki/Procrastination\">Wikipedia</a>. Not very useful. Next, you search Google Scholar for \"<a href=\"http://scholar.google.com/scholar?q=procrastination&amp;hl=en&amp;btnG=Search&amp;as_sdt=1%2C5&amp;as_sdtp=on\">procrastination</a>.\" An article on the first page looks like what you want: an <em>overview</em>&nbsp;of the scientific research on procrastination. It's called \"The nature of procrastination: A meta-analytic and theoretical review of quintessential self-regulatory failure,\" and it's <a href=\"http://www.my.ilstu.edu/~dfgrayb/Personal/Procrastination.pdf\">available online</a>! As it turns out, you can do a pretty decent job of catching up on the science of procrastination just by reading <em>one article</em>. (Of course it's not <em>that</em>&nbsp;easy. You should be more thorough, and explore alternate perspectives. Psychology is not settled chemistry.)</p>\n<p>And in machine ethics, it turns out that most of what you'd want to know is summarized nicely in a single book: <em><a href=\"http://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975/\">Moral Machines</a></em>&nbsp;(2009).</p>\n<p>But on other topics, you won't be so lucky. Suppose you want to study the neuroscience of how <em>desire</em> works. You check <a href=\"http://en.wikipedia.org/wiki/Desire_(emotion)\">Wikipedia</a>, and it has a section on the <a href=\"http://en.wikipedia.org/wiki/Desire_(emotion)#Psychology_and_neurology\">psychology and neurology of desire</a>. But it doesn't tell you much. A Google Scholar <a href=\"http://scholar.google.com/scholar?q=desire&amp;hl=en&amp;btnG=Search&amp;as_sdt=1%2C5&amp;as_sdtp=on\">search</a> is even worse. You check the index of <a href=\"http://www.amazon.com/Neuroscience-Fourth-Dale-Purves/dp/0878936971/\">a large neuroscience textbook</a> for \"desire,\" and come up with basically nothing. The <em>Stanford Encyclopedia of Philosophy</em>&nbsp;article on <a href=\"http://plato.stanford.edu/entries/desire/\">desire</a> is pretty good, but it barely touches on neuroscience. It does point you to two good resources, though: the book <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>, which sounds like it will cover the neuroscience, and the work of neuroscientist <a href=\"http://www-personal.umich.edu/~berridge/\">Kent Berridge</a>. Now, because I <em>have</em>&nbsp;studied the neuroscience of desire, let me spoil the surprise at this point: <em>this</em> research project is <em>not </em>going to be so easy. You have a very long \"literature slog\" ahead of you.</p>\n<p>So I won't argue that scholarship is <em>always</em>&nbsp;or even <em>usually</em>&nbsp;the <a href=\"/lw/31/what_do_we_mean_by_rationality/\">instrumentally rational</a> thing to do when you want to make progress on a certain problem. Sometimes the costs of scholarship outweigh the benefits.</p>\n<p>But to make that judgment, it will help to know just what those costs and&nbsp;benefits&nbsp;are.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Some Costs of Scholarship</h4>\n<p><em>1. Scholarship takes time and effort.</em></p>\n<p>This is the biggie. Scholarship takes time. Especially if you don't have much experience with it already. Resources like <a href=\"http://scholar.google.com/\">Google Scholar</a> make it easier than ever, but scholarship still requires lots of patience and&nbsp;perseverance and <a href=\"/lw/3w3/how_to_beat_procrastination/\">procrastination-mastering</a>.</p>\n<p>&nbsp;</p>\n<p><em>2. Opportunity cost.</em></p>\n<p>The fact that scholarship takes up time means that while you're doing scholarship, you're <em>not</em>&nbsp;doing something else that might be more productive. Scholarship can even serve as a form of procrastination, reading things just because they're on your to-read list so that you can avoid doing something else. [thanks <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/3qkm\">taryneast</a>]</p>\n<p>&nbsp;</p>\n<p><em>3. Studying some subjects can weaken or corrupt you.</em></p>\n<p>Without (and maybe even <em>with</em>)&nbsp;rationality training, studying certain subjects will make you dumber. To me,&nbsp;<a href=\"http://el-prod.baylor.edu/certain_doubts/?p=453\">postmodernism</a>&nbsp;and even&nbsp;<a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/#non-quine\">most analytic philosophy</a>&nbsp;look like a good candidates for stupid-making subjects of study. Other candidates include <a href=\"http://en.wikipedia.org/wiki/Theology\">theology</a>, <a href=\"http://en.wikipedia.org/wiki/Literary_theory\">literary theory</a>, and&nbsp;<a href=\"http://journals.cambridge.org/action/displayJournal?jid=NTS\">scripture scholarship</a>. These fields can teach bad modes of thinking, false \"facts\", and even absurdities. Luckily, there are some <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">heuristics you can use</a> to estimate the value of a field.</p>\n<p>&nbsp;</p>\n<p><em>4. Some things cost money.</em></p>\n<p>I've spent quite a bit of money on scholarship: on gas for trips to a university library so I can download papers from behind the paywall, on hard drives to store tens of thousands of PDFs, on books purchased from Amazon, and so on.</p>\n<p>&nbsp;</p>\n<p><em>5. Scholarship can be a shiny distraction.</em></p>\n<p>A long list of footnotes and references might be built up to conceal the fact that the <em>ideas</em>&nbsp;in an article or book are of little value. [thanks&nbsp;<a href=\"/lw/4sn/costs_and_benefits_of_scholarship/3qi4\">Perplexed</a>]</p>\n<p>&nbsp;</p>\n<h4>Some Benefits of Scholarship</h4>\n<p><em>1. You'll avoid some mistakes and confusions.</em></p>\n<p>Suppose you were about to argue, with Jeremy Bentham, that all intentional human action aims at pleasure. Doing some research on the <a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">neuroscience</a> of <a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">intentional action</a>&nbsp;would help you avoid that mistake. As it turns out, it's just <em>not true</em>&nbsp;that all intentional human action aims at pleasure. Pleasure is only one goal among many.</p>\n<p>Scholarship can also help you avoid confusions, for example&nbsp;between <a href=\"http://www.philosophyetc.net/2009/01/three-or-four-distinctions-in-goodness.html\">two kinds of intrinsic value</a>.</p>\n<p>&nbsp;</p>\n<p><em>2. You'll learn to speak the same language as everyone else, and thus communicate more effectively.</em></p>\n<p>When you read other works on the topic you're discussing, you discover the established terms already used for discussing that topic, and you can begin to speak the same language as everybody else.</p>\n<p>&nbsp;</p>\n<p><em>3. If your rationality skills are sharp, you'll become generally smarter and wiser.</em></p>\n<p>If you're equipped to recognize <a href=\"/lw/td/magical_categories/\">magical categories</a> and <a href=\"/lw/iu/mysterious_answers_to_mysterious_questions/\">mysterious answers</a>, consuming a diverse array of fields can give you <a href=\"http://metamodern.com/2009/05/17/how-to-understand-everything-and-why/\">a broad, integrative kind of knowledge</a>. But be especially wary of subjects that can make you stupid, like postmodern philosophy.</p>\n<p>&nbsp;</p>\n<p><em>4.&nbsp;You won't waste time re-stating what has already been said elsewhere, better and more&nbsp;knowledgeably&nbsp;than you can.</em></p>\n<p>Many times, I've decided I want to write about <em>X</em>. So then I start researching <em>X</em>&nbsp;to prepare for writing. Then I discover that somebody wrote an article that says everything I wanted to say about <em>X</em>, but they've been studying <em>X</em>&nbsp;for ten years and really know their stuff. Then all I have to do is type two paragraphs about it and link to it on my blog. Hurray!</p>\n<p>&nbsp;</p>\n<p><em>5. You'll be taken seriously by more people, and have more access to useful experts.</em></p>\n<p>Researching your topic and citing the relevant literature are pre-requisites for some activities like&nbsp;<a href=\"/lw/4r1/how_siai_could_publish_in_mainstream_cognitive/\">academic publishing</a>, which can get more people to take you seriously because you've put forth the effort to pass a <em>basic</em> test of quality: peer-review. Really smart and accomplished people have too much to read already, and most of them are unlikely to read what you've written if you haven't even bothered to pass peer review.</p>\n<p>And, the more smart people take you seriously and read your stuff, the more brain power you can call upon in solving the problems you care about.</p>\n<p>&nbsp;</p>\n<p><em>6. You'll avoid the tendency to over-trust bearers of good info.</em></p>\n<p>Especially when approaching a subject for the first time, you might read something so bloody intelligent that <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">your mind can't help but cast a halo around its author</a>&nbsp;and accept whatever he or she said. But continuing with your scholarship, and reading lots of people who agree and disagree with that author, can help you see him or her as part of a large enterprise that has been struggling on certain problems for a long time, and may expose you to data that disproves claims made by the original author that impressed you.</p>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>Nobody on Less Wrong should be fooled by the fact that I listed more benefits than costs for scholarship. That doesn't mean scholarship is always a good idea. Often, it's <em>not</em>&nbsp;a good idea.</p>\n<p>But having a list of costs and benefits can help you decide whether scholarship is worthwhile for a particular project - or, how <em>much</em>&nbsp;scholarship is worthwhile.</p>\n<p>Now, what did I miss?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 10, "DbMQGrxbhLxtNkmca": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TFbAMgeiCLjdX4Smw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": 68, "extendedScore": null, "score": 0.000126, "legacy": true, "legacyId": "6215", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 68, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">Scholarship</a> <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">is</a> <a href=\"/lw/2un/references_resources_for_lesswrong/\">excellent</a>, but it is also <em>expensive</em>. It takes a long time to catch up to the state of the art, even for a narrow subject.</p>\n<p>I recently read 90% of the literature on <a href=\"http://commonsenseatheism.com/?p=14597\">machine ethics</a>, a&nbsp;recent and small field of inquiry, and it took me about 40 hours to find all the literature, acquire it, and read (or skim) through it. Doing the same thing for an older and larger subject will take <em>far </em>more&nbsp;time than that. And of course <em>most</em>&nbsp;of the literature on <em>any</em>&nbsp;subject is not valuable.</p>\n<p>Other times, you get lucky. Let's say you want to figure out <a href=\"/lw/3w3/how_to_beat_procrastination/\">how to beat procrastination</a>. You could <a href=\"/lw/3kv/working_hurts_less_than_procrastinating_we_fear/\">introspect</a> your way to a plausible solution, but you might end up being wrong. So, you check <a href=\"http://en.wikipedia.org/wiki/Procrastination\">Wikipedia</a>. Not very useful. Next, you search Google Scholar for \"<a href=\"http://scholar.google.com/scholar?q=procrastination&amp;hl=en&amp;btnG=Search&amp;as_sdt=1%2C5&amp;as_sdtp=on\">procrastination</a>.\" An article on the first page looks like what you want: an <em>overview</em>&nbsp;of the scientific research on procrastination. It's called \"The nature of procrastination: A meta-analytic and theoretical review of quintessential self-regulatory failure,\" and it's <a href=\"http://www.my.ilstu.edu/~dfgrayb/Personal/Procrastination.pdf\">available online</a>! As it turns out, you can do a pretty decent job of catching up on the science of procrastination just by reading <em>one article</em>. (Of course it's not <em>that</em>&nbsp;easy. You should be more thorough, and explore alternate perspectives. Psychology is not settled chemistry.)</p>\n<p>And in machine ethics, it turns out that most of what you'd want to know is summarized nicely in a single book: <em><a href=\"http://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975/\">Moral Machines</a></em>&nbsp;(2009).</p>\n<p>But on other topics, you won't be so lucky. Suppose you want to study the neuroscience of how <em>desire</em> works. You check <a href=\"http://en.wikipedia.org/wiki/Desire_(emotion)\">Wikipedia</a>, and it has a section on the <a href=\"http://en.wikipedia.org/wiki/Desire_(emotion)#Psychology_and_neurology\">psychology and neurology of desire</a>. But it doesn't tell you much. A Google Scholar <a href=\"http://scholar.google.com/scholar?q=desire&amp;hl=en&amp;btnG=Search&amp;as_sdt=1%2C5&amp;as_sdtp=on\">search</a> is even worse. You check the index of <a href=\"http://www.amazon.com/Neuroscience-Fourth-Dale-Purves/dp/0878936971/\">a large neuroscience textbook</a> for \"desire,\" and come up with basically nothing. The <em>Stanford Encyclopedia of Philosophy</em>&nbsp;article on <a href=\"http://plato.stanford.edu/entries/desire/\">desire</a> is pretty good, but it barely touches on neuroscience. It does point you to two good resources, though: the book <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three Faces of Desire</a></em>, which sounds like it will cover the neuroscience, and the work of neuroscientist <a href=\"http://www-personal.umich.edu/~berridge/\">Kent Berridge</a>. Now, because I <em>have</em>&nbsp;studied the neuroscience of desire, let me spoil the surprise at this point: <em>this</em> research project is <em>not </em>going to be so easy. You have a very long \"literature slog\" ahead of you.</p>\n<p>So I won't argue that scholarship is <em>always</em>&nbsp;or even <em>usually</em>&nbsp;the <a href=\"/lw/31/what_do_we_mean_by_rationality/\">instrumentally rational</a> thing to do when you want to make progress on a certain problem. Sometimes the costs of scholarship outweigh the benefits.</p>\n<p>But to make that judgment, it will help to know just what those costs and&nbsp;benefits&nbsp;are.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Some_Costs_of_Scholarship\">Some Costs of Scholarship</h4>\n<p><em>1. Scholarship takes time and effort.</em></p>\n<p>This is the biggie. Scholarship takes time. Especially if you don't have much experience with it already. Resources like <a href=\"http://scholar.google.com/\">Google Scholar</a> make it easier than ever, but scholarship still requires lots of patience and&nbsp;perseverance and <a href=\"/lw/3w3/how_to_beat_procrastination/\">procrastination-mastering</a>.</p>\n<p>&nbsp;</p>\n<p><em>2. Opportunity cost.</em></p>\n<p>The fact that scholarship takes up time means that while you're doing scholarship, you're <em>not</em>&nbsp;doing something else that might be more productive. Scholarship can even serve as a form of procrastination, reading things just because they're on your to-read list so that you can avoid doing something else. [thanks <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/3qkm\">taryneast</a>]</p>\n<p>&nbsp;</p>\n<p><em>3. Studying some subjects can weaken or corrupt you.</em></p>\n<p>Without (and maybe even <em>with</em>)&nbsp;rationality training, studying certain subjects will make you dumber. To me,&nbsp;<a href=\"http://el-prod.baylor.edu/certain_doubts/?p=453\">postmodernism</a>&nbsp;and even&nbsp;<a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/#non-quine\">most analytic philosophy</a>&nbsp;look like a good candidates for stupid-making subjects of study. Other candidates include <a href=\"http://en.wikipedia.org/wiki/Theology\">theology</a>, <a href=\"http://en.wikipedia.org/wiki/Literary_theory\">literary theory</a>, and&nbsp;<a href=\"http://journals.cambridge.org/action/displayJournal?jid=NTS\">scripture scholarship</a>. These fields can teach bad modes of thinking, false \"facts\", and even absurdities. Luckily, there are some <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">heuristics you can use</a> to estimate the value of a field.</p>\n<p>&nbsp;</p>\n<p><em>4. Some things cost money.</em></p>\n<p>I've spent quite a bit of money on scholarship: on gas for trips to a university library so I can download papers from behind the paywall, on hard drives to store tens of thousands of PDFs, on books purchased from Amazon, and so on.</p>\n<p>&nbsp;</p>\n<p><em>5. Scholarship can be a shiny distraction.</em></p>\n<p>A long list of footnotes and references might be built up to conceal the fact that the <em>ideas</em>&nbsp;in an article or book are of little value. [thanks&nbsp;<a href=\"/lw/4sn/costs_and_benefits_of_scholarship/3qi4\">Perplexed</a>]</p>\n<p>&nbsp;</p>\n<h4 id=\"Some_Benefits_of_Scholarship\">Some Benefits of Scholarship</h4>\n<p><em>1. You'll avoid some mistakes and confusions.</em></p>\n<p>Suppose you were about to argue, with Jeremy Bentham, that all intentional human action aims at pleasure. Doing some research on the <a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">neuroscience</a> of <a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">intentional action</a>&nbsp;would help you avoid that mistake. As it turns out, it's just <em>not true</em>&nbsp;that all intentional human action aims at pleasure. Pleasure is only one goal among many.</p>\n<p>Scholarship can also help you avoid confusions, for example&nbsp;between <a href=\"http://www.philosophyetc.net/2009/01/three-or-four-distinctions-in-goodness.html\">two kinds of intrinsic value</a>.</p>\n<p>&nbsp;</p>\n<p><em>2. You'll learn to speak the same language as everyone else, and thus communicate more effectively.</em></p>\n<p>When you read other works on the topic you're discussing, you discover the established terms already used for discussing that topic, and you can begin to speak the same language as everybody else.</p>\n<p>&nbsp;</p>\n<p><em>3. If your rationality skills are sharp, you'll become generally smarter and wiser.</em></p>\n<p>If you're equipped to recognize <a href=\"/lw/td/magical_categories/\">magical categories</a> and <a href=\"/lw/iu/mysterious_answers_to_mysterious_questions/\">mysterious answers</a>, consuming a diverse array of fields can give you <a href=\"http://metamodern.com/2009/05/17/how-to-understand-everything-and-why/\">a broad, integrative kind of knowledge</a>. But be especially wary of subjects that can make you stupid, like postmodern philosophy.</p>\n<p>&nbsp;</p>\n<p><em>4.&nbsp;You won't waste time re-stating what has already been said elsewhere, better and more&nbsp;knowledgeably&nbsp;than you can.</em></p>\n<p>Many times, I've decided I want to write about <em>X</em>. So then I start researching <em>X</em>&nbsp;to prepare for writing. Then I discover that somebody wrote an article that says everything I wanted to say about <em>X</em>, but they've been studying <em>X</em>&nbsp;for ten years and really know their stuff. Then all I have to do is type two paragraphs about it and link to it on my blog. Hurray!</p>\n<p>&nbsp;</p>\n<p><em>5. You'll be taken seriously by more people, and have more access to useful experts.</em></p>\n<p>Researching your topic and citing the relevant literature are pre-requisites for some activities like&nbsp;<a href=\"/lw/4r1/how_siai_could_publish_in_mainstream_cognitive/\">academic publishing</a>, which can get more people to take you seriously because you've put forth the effort to pass a <em>basic</em> test of quality: peer-review. Really smart and accomplished people have too much to read already, and most of them are unlikely to read what you've written if you haven't even bothered to pass peer review.</p>\n<p>And, the more smart people take you seriously and read your stuff, the more brain power you can call upon in solving the problems you care about.</p>\n<p>&nbsp;</p>\n<p><em>6. You'll avoid the tendency to over-trust bearers of good info.</em></p>\n<p>Especially when approaching a subject for the first time, you might read something so bloody intelligent that <a href=\"/lw/4b/dont_revere_the_bearer_of_good_info/\">your mind can't help but cast a halo around its author</a>&nbsp;and accept whatever he or she said. But continuing with your scholarship, and reading lots of people who agree and disagree with that author, can help you see him or her as part of a large enterprise that has been struggling on certain problems for a long time, and may expose you to data that disproves claims made by the original author that impressed you.</p>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>Nobody on Less Wrong should be fooled by the fact that I listed more benefits than costs for scholarship. That doesn't mean scholarship is always a good idea. Often, it's <em>not</em>&nbsp;a good idea.</p>\n<p>But having a list of costs and benefits can help you decide whether scholarship is worthwhile for a particular project - or, how <em>much</em>&nbsp;scholarship is worthwhile.</p>\n<p>Now, what did I miss?</p>", "sections": [{"title": "Some Costs of Scholarship", "anchor": "Some_Costs_of_Scholarship", "level": 1}, {"title": "Some Benefits of Scholarship", "anchor": "Some_Benefits_of_Scholarship", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "109 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 109, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["64FdKLwmea8MCLWkE", "xg3hXCYQPJkwHyik2", "TNHQLZK5pHbxdnz4e", "RWo4LwFzpHNQCTcYt", "9o3QBg2xJXcRCxGjS", "RcZCwxFiZzE6X7nsv", "fyZBtNB3Ki3fM4a6Y", "PoDAyQMWEXBBBEJ5P", "6i3zToomS86oj9bS6", "4oWXnodxAu4WgHnrd", "tSgcorrgBnrCH8nL3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}