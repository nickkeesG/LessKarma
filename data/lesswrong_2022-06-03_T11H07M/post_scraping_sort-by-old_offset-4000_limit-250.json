{"results": [{"createdAt": null, "postedAt": "2011-07-08T21:34:47.671Z", "modifiedAt": null, "url": null, "title": "Meetup : Tortuga Rationalists Meetup", "slug": "meetup-tortuga-rationalists-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "divia", "createdAt": "2009-02-28T01:56:35.966Z", "isAdmin": false, "displayName": "divia"}, "userId": "CQzR9QRTNKQ9Qmsjc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xi8ZNwf34tcyTR6xk/meetup-tortuga-rationalists-meetup", "pageUrlRelative": "/posts/xi8ZNwf34tcyTR6xk/meetup-tortuga-rationalists-meetup", "linkUrl": "https://www.lesswrong.com/posts/xi8ZNwf34tcyTR6xk/meetup-tortuga-rationalists-meetup", "postedAtFormatted": "Friday, July 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Tortuga%20Rationalists%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Tortuga%20Rationalists%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxi8ZNwf34tcyTR6xk%2Fmeetup-tortuga-rationalists-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Tortuga%20Rationalists%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxi8ZNwf34tcyTR6xk%2Fmeetup-tortuga-rationalists-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxi8ZNwf34tcyTR6xk%2Fmeetup-tortuga-rationalists-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/16'>Tortuga Rationalists Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 July 2011 02:34:01PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">850 Williams Way, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are a South Bay LessWrong Rationality group who meets every Thursday at the Tortuga (<a href=\"http://tortuga.coop\" rel=\"nofollow\">http://tortuga.coop</a>) lounge in Mountain View for discussions, activities, and socializing.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/16'>Tortuga Rationalists Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xi8ZNwf34tcyTR6xk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.383446285476253e-07, "legacy": true, "legacyId": "8513", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Tortuga_Rationalists_Meetup\">Discussion article for the meetup : <a href=\"/meetups/16\">Tortuga Rationalists Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 July 2011 02:34:01PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">850 Williams Way, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are a South Bay LessWrong Rationality group who meets every Thursday at the Tortuga (<a href=\"http://tortuga.coop\" rel=\"nofollow\">http://tortuga.coop</a>) lounge in Mountain View for discussions, activities, and socializing.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Tortuga_Rationalists_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/16\">Tortuga Rationalists Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Tortuga Rationalists Meetup", "anchor": "Discussion_article_for_the_meetup___Tortuga_Rationalists_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Tortuga Rationalists Meetup", "anchor": "Discussion_article_for_the_meetup___Tortuga_Rationalists_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-08T23:27:05.843Z", "modifiedAt": null, "url": null, "title": "Can cryonically-frozen people *really* expect to be revived?", "slug": "can-cryonically-frozen-people-really-expect-to-be-revived", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.211Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Cp2rHsZoQDoba3Pww/can-cryonically-frozen-people-really-expect-to-be-revived", "pageUrlRelative": "/posts/Cp2rHsZoQDoba3Pww/can-cryonically-frozen-people-really-expect-to-be-revived", "linkUrl": "https://www.lesswrong.com/posts/Cp2rHsZoQDoba3Pww/can-cryonically-frozen-people-really-expect-to-be-revived", "postedAtFormatted": "Friday, July 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20cryonically-frozen%20people%20*really*%20expect%20to%20be%20revived%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20cryonically-frozen%20people%20*really*%20expect%20to%20be%20revived%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCp2rHsZoQDoba3Pww%2Fcan-cryonically-frozen-people-really-expect-to-be-revived%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20cryonically-frozen%20people%20*really*%20expect%20to%20be%20revived%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCp2rHsZoQDoba3Pww%2Fcan-cryonically-frozen-people-really-expect-to-be-revived", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCp2rHsZoQDoba3Pww%2Fcan-cryonically-frozen-people-really-expect-to-be-revived", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 557, "htmlBody": "<div>\n<div id=\":2px\" class=\"ii gt\" style=\"margin-top: 5px; margin-right: 15px; margin-bottom: 5px; margin-left: 15px; padding-bottom: 20px; position: relative; z-index: 2; \">\n<div id=\":2ni\">\n<div>\n<div>NOTE: I have no clue why some of the spaces are \"screwy\" - the formatting is totally fine when I was typing this post out.</div>\n<div>===</div>\n<div><span style=\"font-family: arial, sans-serif;\">I think it's a pretty MAJOR assumption that wealth can *really* transfer over numerous generations.</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">Say this: say 1 million people a year are cryonically frozen. okay. and they pay with their own money.</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">Then (assuming revival technologies don't come 100 years from now), then that's 100 million people. Sure, they paid with their own money, but we must remember that the value of wealth/money is psychological. Economics depends on contract enforcement (where there is a significant penalty if you don't comply), which is a subset of the set of incentives, which are all about motivating people to do shit.</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">And the thing is - it's quite possible that a disaster could hit, forcing people to move all the cryonically frozen bodies somewhere else (are most of the bodies stored in Phoenix,AZ - given that it's where Alcor is? I don't trust that place over the long run, given that it's experiencing unsustainable growth that's draining the Colorado River out, that the region is experiencing a massive growth in energy usage [especially from ACs that just dissipates the heat out and make the city even hotter], &nbsp;<strong>and&nbsp;</strong>&nbsp;that the effects of climate change are expected to be more severe in Arizona than they are in most other places [1], especially given that the &nbsp;<a href=\"http://en.wikipedia.org/wiki/Hadley_cell#Hadley_cell_expansion\">Hadley Cell</a>&nbsp; might expand northward). Solar power could save it, but I'm not sure if it will scale there in several decades</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">And if that happens (or if any relocation is needed), then resources+motivation is limited and no one wants to do it. Especially because that there &nbsp;are few negative consequences if the bodies are left to rot - simply because after a few generations, most cryonically frozen people may be almost completely forgotten - except for the ones who were as famous and respectable as Einstein/Jefferson/etc. <strong>Surprisingly</strong>, &nbsp;this &nbsp;<strong>could&nbsp;</strong>&nbsp;be a rational argument for having children, since having children and grandchildren might &nbsp;<strong>increase</strong>&nbsp; the chances that<strong>&nbsp;</strong>someone &nbsp;<strong>might</strong>&nbsp; actually care about trying to revive you once we have the technology for cryonic revival.</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">Obviously, it could be an incentive for others to unfreeze the body if the person who came back alive was SO grateful that he was willing to repay the favor with something major (say, indentured servitude). &nbsp;</span><span style=\"font-family: arial, sans-serif; \">Except - that there's no way to predict that at all. they're in a totally foreign environment. what personalities they had back then - may not necessarily stay constant in an environment so radically different.&nbsp;<strong>Surprisingly&nbsp;</strong>&nbsp;though, this could be an argument for lifelogging, since an unrelated person might actually be willing to spend the effort to actually to unfreeze the body of a more interesting person</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">==</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">With that all being said - I still think it's a perfectly rational decision to be cryonically frozen. After all, the breakthrough could come within 100 years. And other things can happen too.&nbsp;</span></div>\n<div><span style=\"font-family: arial, sans-serif;\">==</span></div>\n<div>[1] &nbsp;Note how the Southwest (and especially the Rocky Mountains that supply water to the region) will be completely baked.&nbsp;<span style=\"font-family: arial, sans-serif;\">Arizona depends A LOT on water supplies from the Colorado River. But the glaciers in the Colorado Rockies are melting quite fast - and the mountain west is <a href=\"http://geology.com/climate-change/southwest/ \">already warming much faster than average under global warming</a></span></div>\n<div><img src=\"http://www.geo.arizona.edu/dgesl/Assets/research_maps/climate_change/TprojsF_2095jja_US_lo_res.gif\" alt=\"\" /></div>\n<div>Also, runoff matters as well: notice how it's VERY red in Arizona. See below (IPCC 2007)</div>\n<div><span style=\"font-family: arial, sans-serif;\"><img src=\"http://www.agci.org/classroom/images/runoff-IPCC2007_big.jpg\" alt=\"\" /></span></div>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Cp2rHsZoQDoba3Pww", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8514", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-09T04:43:46.010Z", "modifiedAt": null, "url": null, "title": "2011 Buhl Lecture, Scott Aaronson on Quantum Complexity", "slug": "2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:39.098Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/f47N8TKAmJ2DarGZb/2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "pageUrlRelative": "/posts/f47N8TKAmJ2DarGZb/2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "linkUrl": "https://www.lesswrong.com/posts/f47N8TKAmJ2DarGZb/2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "postedAtFormatted": "Saturday, July 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202011%20Buhl%20Lecture%2C%20Scott%20Aaronson%20on%20Quantum%20Complexity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2011%20Buhl%20Lecture%2C%20Scott%20Aaronson%20on%20Quantum%20Complexity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff47N8TKAmJ2DarGZb%2F2011-buhl-lecture-scott-aaronson-on-quantum-complexity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2011%20Buhl%20Lecture%2C%20Scott%20Aaronson%20on%20Quantum%20Complexity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff47N8TKAmJ2DarGZb%2F2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff47N8TKAmJ2DarGZb%2F2011-buhl-lecture-scott-aaronson-on-quantum-complexity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 271, "htmlBody": "<p>I was planning to post this in the main area, but my thoughts are significantly less well-formed than I thought they were. Anyway, I hope that interested parties find it nonetheless.</p>\n<p>In the Carnegie Mellon <a href=\"http://www.youtube.com/watch?v=8bLXHvH9s1A\"> 2011 Buhl Lecture</a>, Scott Aaronson gives a remarkably clear and concise review of P, NP, other fundamentals in complexity theory, and their quantum extensions. In particular, beginning around the 46 minute mark, a sequence of examples is given in which the intuition from computability theory would have accurately predicted physical results (and in some cases this actually happened, so it wasn't just hindsight bias).&nbsp;</p>\n<p>In previous posts we have learned about <a href=\"/lw/jo/einsteins_arrogance/\"> Einstein's arrogance</a> and <a href=\"/lw/qj/einsteins_speed/\"> Einstein's speed</a>. This pattern of results flowing from computational complexity to physical predictions seems odd to me in that context. Here we are using physical computers to derive abstractions about the limits of computation, and from there we are successfully able to intuit limits of physical computation (e.g. brains computing abstractions of the fundamental limits of brains computing abstractions...) At what point do we hit the stage where individual scientists can rationally know that results from computational complexity theory are more fundamental than traditional physics? It seems like a paradox wholly different than Einstein rationally knowing (from examining bits of theory-space evidence rather than traditional-experiment-space evidence) that relativity would hold true. In what sort of evidence space can physical brain computation yielding complexity limits count as bits of evidence factoring into expected physical outcomes (such as the exponential smallness of the spectral gap of NP-hard-Hamiltonians from the quantum adiabatic theorem)?</p>\n<p>Maybe some contributors more well-versed in complexity theory can steer this in a useful direction.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "f47N8TKAmJ2DarGZb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 7.384764011607758e-07, "legacy": true, "legacyId": "8517", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MwQRucYo6BZZwjKE7", "mpaqTWGiLT7GA3w76"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-09T12:34:05.651Z", "modifiedAt": null, "url": null, "title": "Guardian column on ugh fields, mentions LW", "slug": "guardian-column-on-ugh-fields-mentions-lw", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:34.875Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iQ6FQM6T36Kv3huhv/guardian-column-on-ugh-fields-mentions-lw", "pageUrlRelative": "/posts/iQ6FQM6T36Kv3huhv/guardian-column-on-ugh-fields-mentions-lw", "linkUrl": "https://www.lesswrong.com/posts/iQ6FQM6T36Kv3huhv/guardian-column-on-ugh-fields-mentions-lw", "postedAtFormatted": "Saturday, July 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Guardian%20column%20on%20ugh%20fields%2C%20mentions%20LW&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGuardian%20column%20on%20ugh%20fields%2C%20mentions%20LW%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ6FQM6T36Kv3huhv%2Fguardian-column-on-ugh-fields-mentions-lw%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Guardian%20column%20on%20ugh%20fields%2C%20mentions%20LW%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ6FQM6T36Kv3huhv%2Fguardian-column-on-ugh-fields-mentions-lw", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQ6FQM6T36Kv3huhv%2Fguardian-column-on-ugh-fields-mentions-lw", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 572, "htmlBody": "<p><a href=\"http://www.guardian.co.uk/lifeandstyle/2011/jul/08/change-your-life-ugh-fields\">http://www.guardian.co.uk/lifeandstyle/2011/jul/08/change-your-life-ugh-fields</a></p>\n<blockquote>\n<p>In 1920, in a jaw-droppingly unethical experiment that's mainly remembered today as an example of how not to conduct a psychological study, <a href=\"http://en.wikipedia.org/wiki/John_B._Watson\">John B Watson</a> set out to prove a point about fear &ndash; using, as his guinea pig, an eight-month-old boy in a Baltimore hospital. <a href=\"http://en.wikipedia.org/wiki/Little_Albert_experiment\">Little Albert</a>, as he became known, was taught to associate a white rat with a terrifying sound &ndash; a steel bar was struck with a hammer behind his back whenever he reached towards the animal &ndash; until, the story goes, he was terrified of anything white and furry: dogs, a coat, Watson in a Santa Claus costume. (Watson, apparently, intended to reverse the effect, but Albert was removed from the hospital before he could do so.) It would be entertaining to propose something similar to a university ethics committee today: they'd spring from their seats in horror, like Little Albert seeing a sheepskin rug.</p>\n<p>In fact, most of the details of Little Albert's \"conditioning\" have since been thrown into doubt. But something not too dissimilar afflicts many of us. When an experience gets associated with acute bad feelings, especially in childhood &ndash; being around dogs, say, or swimming pools, or moving house or money troubles &ndash; that category of thing can become fearsome for ever. But there's an additional twist I hadn't considered until I encountered it recently on the rationality blog <a href=\"/\">lesswrong.com</a>, where it's termed an \"ugh field\": what if one effect of finding some area of life particularly stress-inducing is that we get conditioned into not even thinking about it at all?</p>\n<p>\"A problem with the human mind is it's a horrific kludge that will fail when you most need it not to,\" writes one Less Wrong blogger, who argues that ugh fields are a case in point: \"If a person receives constant negative conditioning via unhappy thoughts whenever their mind goes into a&nbsp;certain zone of thought, they will develop a psychological flinch mechanism around the thought.\"</p>\n<p>Suppose, in early adulthood, you have a few bad experiences with missed credit card bills and penalty fees. A rational person might resolve to think more about bills in future, to avoid repeat problems. But a fear-conditioned mind, erecting an ugh field around the subject, might become <em>more</em> forgetful with money, to avoid experiencing the emotions associated with the thought, thus making matters worse. (Another example: many people fail to take medicines they've been prescribed for life-threatening conditions. Could it be because they'd rather avoid thinking about having a life-threatening condition &ndash; even if that puts their lives at risk?) Worse, if the <a href=\"/lw/21b/ugh_fields\">ugh field hypothesis</a> is correct, the \"flinch\" occurs, by definition, before the thought enters your conscious mind. So even someone sincerely dedicated to confronting (say) their issues with money won't have the opportunity: the ugh field will have screened it out pre-emptively.</p>\n<p>This is all highly dispiriting, except in so far as it highlights a broader truth about fear: we're not really afraid of events, but of experiencing the emotions associated with them. (\"I'm only ever afraid of a feeling, never a task,\" is how the blogger David Cain applies this to procrastination at <a href=\"http://www.raptitude.com/\">raptitude.com</a> &ndash; see <a href=\"http://www.raptitude.com/2011/05/progress-is-the-only-protection/\">is.gd/t3cRPZ</a>.) Which is actually liberating, since the prospect of experiencing an unpleasant emotion is almost always more palatable than the prospect of Something Really Bad happening. If you can tolerate the feeling of \"ugh\", there's not much you can't tolerate in life.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "EuDw6uxQW2ZBRFhMo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iQ6FQM6T36Kv3huhv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 34, "extendedScore": null, "score": 8.4e-05, "legacy": true, "legacyId": "8527", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EFQ3F6kmt4WHXRqik"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-09T18:25:40.371Z", "modifiedAt": null, "url": null, "title": "Thinking without words?", "slug": "thinking-without-words", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:34.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KbsHWuAYfAcEkcJT6/thinking-without-words", "pageUrlRelative": "/posts/KbsHWuAYfAcEkcJT6/thinking-without-words", "linkUrl": "https://www.lesswrong.com/posts/KbsHWuAYfAcEkcJT6/thinking-without-words", "postedAtFormatted": "Saturday, July 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thinking%20without%20words%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThinking%20without%20words%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbsHWuAYfAcEkcJT6%2Fthinking-without-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thinking%20without%20words%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbsHWuAYfAcEkcJT6%2Fthinking-without-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbsHWuAYfAcEkcJT6%2Fthinking-without-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>Before language, people must have thought without words.&nbsp; I often have the impression that I have a thought fully-formed in my head, yet I wait to listen to it unfold in words before moving on to the next thought.&nbsp; Perhaps I could think much faster if I weren't addicted to words.</p>\n<p>Has anyone developed techniques for thinking without words?</p>\n<p>This would have a little in common with Buddhist practices of emptying your mind, but wouldn't be the same thing.&nbsp; For one thing, Buddhists also try to empty their minds of images.&nbsp; More importantly, they are trying not to think, while I'm trying to think - just not unpack everything into words.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KbsHWuAYfAcEkcJT6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 13, "extendedScore": null, "score": 7.387286910281209e-07, "legacy": true, "legacyId": "8528", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-09T20:54:49.635Z", "modifiedAt": null, "url": null, "title": "Wanting vs. Liking Revisited", "slug": "wanting-vs-liking-revisited", "viewCount": null, "lastCommentedAt": "2018-08-06T08:47:17.576Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eaczwARbFnrisFx8E/wanting-vs-liking-revisited", "pageUrlRelative": "/posts/eaczwARbFnrisFx8E/wanting-vs-liking-revisited", "linkUrl": "https://www.lesswrong.com/posts/eaczwARbFnrisFx8E/wanting-vs-liking-revisited", "postedAtFormatted": "Saturday, July 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wanting%20vs.%20Liking%20Revisited&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWanting%20vs.%20Liking%20Revisited%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaczwARbFnrisFx8E%2Fwanting-vs-liking-revisited%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wanting%20vs.%20Liking%20Revisited%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaczwARbFnrisFx8E%2Fwanting-vs-liking-revisited", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeaczwARbFnrisFx8E%2Fwanting-vs-liking-revisited", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1135, "htmlBody": "<p>In <a href=\"/lw/1lb/are_wireheads_happy/\">Are Wireheads Happy?</a> I discussed the difference between wanting something and liking something. More recently, Luke went deeper into some of the science in his post <a href=\"/lw/65w/not_for_the_sake_of_pleasure_alone/\">Not for the Sake of Pleasure Alone</a>.<br /><br />In the comments of the original post, cousin_it <a href=\"/lw/1lb/are_wireheads_happy/1dxd\">asked a good question</a>: why implement a mind with two forms of motivation? What, exactly, are \"wanting\" and \"liking\" in mind design terms?<br /><br />Tim Tyler and Furcas both gave interesting responses, but I think the problem has a clear answer in a reinforcement learning perspective (warning: <a href=\"http://www.google.com/url?sa=t&amp;source=web&amp;cd=7&amp;ved=0CD8QFjAG&amp;url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.99.9053%26rep%3Drep1%26type%3Dpdf&amp;rct=j&amp;q=Berridge%20Robinson%20wanted%20liked&amp;ei=9S0NTsLyG4H40gHo2vGaDg&amp;usg=AFQjCNHc86_1AUOpF0fzeFfkLOYVdlem_A&amp;sig2=Xk-OXlqCpieBcYSTqvE19Q&amp;cad=rja - WANTING AND LIKING\">formal research</a> on the subject does not take this view and sticks to the \"two different systems of different evolutionary design\" theory). \"Liking\" is how positive reinforcement feels from the inside; \"wanting\" is how the motivation to do something feels from the inside. Things that are positively reinforced generally motivate you to do more of them, so liking and wanting often co-occur. With more knowledge of reinforcement, we can begin to explore why they might differ.</p>\n<p><strong>CONTEXT OF REINFORCEMENT</strong><br /><br />Reinforcement learning doesn't just connect single stimuli to responses. It connects stimuli in a context to responses. Munching popcorn at a movie might be pleasant; munching popcorn at a funeral will get you stern looks at best.<br /><br />In fact, lots of people eat popcorn at a movie theater and almost nowhere else. Imagine them, walking into that movie theater and thinking \"You know, I should have some popcorn now\", maybe even having a strong desire for popcorn that overrides the diet they're on - and yet these same people could walk into, I don't know, a used car dealership and that urge would be completely gone.<br /><br />These people have probably eaten popcorn at a movie theater before and liked it. Instead of generalizing to \"eat popcorn\", their brain learned the lesson \"eat popcorn at movie theaters\". Part of this no doubt has to do with the easy availability of popcorn there, but another part probably has to do with context-dependent reinforcement.</p>\n<p>I like pizza. When I eat pizza, and get rewarded for eating pizza, it's usually after smelling the pizza first. The smell of pizza becomes a powerful stimulus for the behavior of eating pizza, and I want pizza much more after smelling it, even though how much I like pizza remains constant. I've never had pizza at breakfast, and in fact the context of breakfast is directly competing with my normal stimuli for eating pizza; therefore, no matter how much I like pizza, I have no desire to eat pizza for breakfast. If I did have pizza for breakfast, though, I'd probably like it.</p>\n<p><strong>INTERMITTENT REINFORCEMENT</strong></p>\n<p>If an activity is intermittently reinforced; occasional rewards spread among more common neutral stimuli or even small punishments, it may be motivating but unpleasant.</p>\n<p>Imagine a beginning golfer. He gets bogeys or double bogeys on each hole, and is constantly kicking himself, thinking that if only he'd used one club instead of the other, he might have gotten that one. After each game, he can't believe that after all his practice, he's still this bad. But every so often, he does get a par or a birdie, and thinks he's finally got the hang of things, right until he fails to repeat it on the next hole, or the hole after that.</p>\n<p>This is a variable response schedule, Skinner's most addictive form of delivering reinforcement. The golfer may keep playing, maybe because he constantly thinks he's on the verge of figuring out how to improve his game, but he might not <em>like</em> it. The same is true for gamblers, who think the next pull of the slot machine might be the jackpot (and who falsely believe they can <a href=\"http://www.problemgambling.ca/EN/ResourcesForProfessionals/Pages/GamblingSystems.aspx\">discover a secret in the game</a> that will change their luck; they don't like sitting around losing money, but they may stick with it so that they don't leave right before they reach the point where their luck changes.</p>\n<p><strong>SMALL-SCALE DISCOUNT RATES</strong><br /><br />Even if we like something, we may not want to do it because it involves pain at the second or sub-second level.<br /><br /><a href=\"/lw/3kv/working_hurts_less_than_procrastinating_we_fear/\">Eliezer discusses</a> the choice between reading a mediocre book and a good book:</p>\n<blockquote>\n<p>You may read a mediocre book for an hour, instead of a good book, because if you first spent a few minutes to search your library to obtain a better book, that would be an immediate cost - not that searching your library is all that unpleasant, but you'd have to pay an immediate activation cost to do that instead of taking the path of least resistance and grabbing the first thing in front of you.&nbsp; It's a hyperbolically discounted tradeoff that you make without realizing it, because the cost you're refusing to pay isn't commensurate enough with the payoff you're forgoing to be salient as an explicit tradeoff.</p>\n</blockquote>\n<p>In this case, you like the good book, but you want to keep reading the mediocre book. If it's cheating to start our hypothetical subject off reading the mediocre book, consider the difference between a book of one-liner jokes and a really great novel. The book of one-liners you can open to a random page and start being immediately amused (reinforced). The great novel you've got to pick up, get into, develop sympathies for the characters, figure out what the heck <em>lomillialor</em> or a Tiste Andii is, and then a few pages in you're thinking \"This is a pretty good book\". The fear of those few pages could make you realize you'll like the novel, but still want to read the joke book. And since hyperbolic discounting overcounts reward or punishment in the next few seconds, it may seem like a net punishment to make the change.<strong><br /></strong></p>\n<p><strong>SUMMARY</strong><br /><br />This deals yet another blow to the concept of me having \"preferences\". How much do I want popcorn? That depends very much on whether I'm at a movie theater or a used car dealership. If I browse Reddit for half an hour because it would be too much work to spend ten seconds traveling to the living room to pick up the book I'm really enjoying, do I \"prefer\" browsing to reading? Which has higher utility? If I hate every second I'm at the slot machines, but I keep at them anyway so I don't miss the jackpot, am I a gambling addict, or just a person who enjoys winning jackpots and is willing to do what it takes?<br /><br />In cases like these, the language of preference and utility is not very useful. My anticipation of reward is constraining my behavior, and different factors are promoting different behaviors in an unstable way, but trying to extract \"preferences\" from the situation is trying to oversimplify a complex situation.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1, "dBPou4ihoQNY4cquv": 1, "zQw5d37qwzdpgQs5P": 1, "AHK82ypfxF45rqh9D": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eaczwARbFnrisFx8E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 45, "baseScore": 59, "extendedScore": null, "score": 0.000114, "legacy": true, "legacyId": "8529", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HmfxSWnqnK265GEFM", "87mdaCvCyo5bkk8hE", "9o3QBg2xJXcRCxGjS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T01:07:53.470Z", "modifiedAt": null, "url": null, "title": "Torchwood", "slug": "torchwood", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:46.474Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MatthewBaker", "createdAt": "2011-06-03T22:19:50.449Z", "isAdmin": false, "displayName": "MatthewBaker"}, "userId": "xEPvhkraqrPSryfFr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aiQcofXKwT6aiAdTh/torchwood", "pageUrlRelative": "/posts/aiQcofXKwT6aiAdTh/torchwood", "linkUrl": "https://www.lesswrong.com/posts/aiQcofXKwT6aiAdTh/torchwood", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Torchwood&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATorchwood%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQcofXKwT6aiAdTh%2Ftorchwood%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Torchwood%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQcofXKwT6aiAdTh%2Ftorchwood", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaiQcofXKwT6aiAdTh%2Ftorchwood", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p>I don't know if anyone on LW watches DoctorWho/Torchwood but the american Torchwood remake's first episode just came out and the premise is that everyone on earth loses the ability to die: S04 EP1 the \"Day of Miracles\"</p>\n<p>Enjoy, the reason i added it to discussion was because of the whole never die concept and one of the best quotes of all time :)</p>\n<p>\"And someday when the descendants of humanity have spread from star to star, they won't tell the children about the history of Ancient Earth until they're old enough to bear it; and when they learn they'll weep to hear that such a thing as Death had ever once existed\" [Harry Potter and the Methods of Rationality](http://www.fanfiction.net/s/5782108/1/Harry_Potter_and_the_Methods_of_Rationality)</p>\n<p>-Matt</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aiQcofXKwT6aiAdTh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 7.388526590628035e-07, "legacy": true, "legacyId": "8531", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T01:36:07.802Z", "modifiedAt": null, "url": null, "title": "Meetup : San Francisco & Tortuga Go Surfing", "slug": "meetup-san-francisco-and-tortuga-go-surfing", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6LAvcD5thDPSYWRWJ/meetup-san-francisco-and-tortuga-go-surfing", "pageUrlRelative": "/posts/6LAvcD5thDPSYWRWJ/meetup-san-francisco-and-tortuga-go-surfing", "linkUrl": "https://www.lesswrong.com/posts/6LAvcD5thDPSYWRWJ/meetup-san-francisco-and-tortuga-go-surfing", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Francisco%20%26%20Tortuga%20Go%20Surfing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Francisco%20%26%20Tortuga%20Go%20Surfing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6LAvcD5thDPSYWRWJ%2Fmeetup-san-francisco-and-tortuga-go-surfing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Francisco%20%26%20Tortuga%20Go%20Surfing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6LAvcD5thDPSYWRWJ%2Fmeetup-san-francisco-and-tortuga-go-surfing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6LAvcD5thDPSYWRWJ%2Fmeetup-san-francisco-and-tortuga-go-surfing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17'>San Francisco &amp; Tortuga Go Surfing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 July 2011 06:39:31PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Nor Cal Surf Shop, 5460 Pacific Coast Highway, Pacifica, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Low-key, afternoon fun at the beach for beginners &amp; amateurs. I'll be offering rides from central San Francisco down to Pacifica, where the surf shop rents wetsuits &amp; boogieboards or surfboards for about $20 total.</p>\n\n<p>The surf shop has a free, suburban-style parking lot in a plaza with  several good places to get lunch, and the back door opens right onto the beach. There are great views of the waves and the surrounding hills. Surf is usually light (2-6 ft waves), if a little choppy.</p>\n\n<p>I'll be leaving San Francisco at 1 pm, arriving at Pacifica by 2 pm, and leaving around 6 pm. Everyone is welcome to join me for whatever part of that time they like; if you need a ride, please RSVP as soon as possible by e-mailing jasongreenlowe@gmail.com or texting (954) 464-3040.</p>\n\n<p>This event will be repeated several more times over the summer, but we'll all get better as time goes on, so join us now while we're still just as awkward as you are!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17'>San Francisco &amp; Tortuga Go Surfing</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6LAvcD5thDPSYWRWJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.388613427703506e-07, "legacy": true, "legacyId": "8532", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Francisco___Tortuga_Go_Surfing\">Discussion article for the meetup : <a href=\"/meetups/17\">San Francisco &amp; Tortuga Go Surfing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 July 2011 06:39:31PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Nor Cal Surf Shop, 5460 Pacific Coast Highway, Pacifica, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Low-key, afternoon fun at the beach for beginners &amp; amateurs. I'll be offering rides from central San Francisco down to Pacifica, where the surf shop rents wetsuits &amp; boogieboards or surfboards for about $20 total.</p>\n\n<p>The surf shop has a free, suburban-style parking lot in a plaza with  several good places to get lunch, and the back door opens right onto the beach. There are great views of the waves and the surrounding hills. Surf is usually light (2-6 ft waves), if a little choppy.</p>\n\n<p>I'll be leaving San Francisco at 1 pm, arriving at Pacifica by 2 pm, and leaving around 6 pm. Everyone is welcome to join me for whatever part of that time they like; if you need a ride, please RSVP as soon as possible by e-mailing jasongreenlowe@gmail.com or texting (954) 464-3040.</p>\n\n<p>This event will be repeated several more times over the summer, but we'll all get better as time goes on, so join us now while we're still just as awkward as you are!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Francisco___Tortuga_Go_Surfing1\">Discussion article for the meetup : <a href=\"/meetups/17\">San Francisco &amp; Tortuga Go Surfing</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Francisco & Tortuga Go Surfing", "anchor": "Discussion_article_for_the_meetup___San_Francisco___Tortuga_Go_Surfing", "level": 1}, {"title": "Discussion article for the meetup : San Francisco & Tortuga Go Surfing", "anchor": "Discussion_article_for_the_meetup___San_Francisco___Tortuga_Go_Surfing1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T05:20:26.365Z", "modifiedAt": null, "url": null, "title": "Prospect Theory: A Framework for Understanding Cognitive Biases", "slug": "prospect-theory-a-framework-for-understanding-cognitive", "viewCount": null, "lastCommentedAt": "2021-05-15T21:28:21.999Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Scott Alexander", "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LQp9cZPzJncFKh5c8/prospect-theory-a-framework-for-understanding-cognitive", "pageUrlRelative": "/posts/LQp9cZPzJncFKh5c8/prospect-theory-a-framework-for-understanding-cognitive", "linkUrl": "https://www.lesswrong.com/posts/LQp9cZPzJncFKh5c8/prospect-theory-a-framework-for-understanding-cognitive", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Prospect%20Theory%3A%20A%20Framework%20for%20Understanding%20Cognitive%20Biases&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProspect%20Theory%3A%20A%20Framework%20for%20Understanding%20Cognitive%20Biases%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQp9cZPzJncFKh5c8%2Fprospect-theory-a-framework-for-understanding-cognitive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Prospect%20Theory%3A%20A%20Framework%20for%20Understanding%20Cognitive%20Biases%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQp9cZPzJncFKh5c8%2Fprospect-theory-a-framework-for-understanding-cognitive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLQp9cZPzJncFKh5c8%2Fprospect-theory-a-framework-for-understanding-cognitive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1137, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/115/shane_legg_on_prospect_theory_and_computational/\">Shane Legg on Prospect Theory and Computational Finance</a></p><p>This post is on prospect theory partly because it fits the theme of replacing simple utility functions with complicated reward functions, but mostly because somehow Less Wrong doesn&#x27;t have any posts on prospect theory yet and that needs to change.<br/><br/>Kahneman and Tversky, the first researchers to identify and rigorously study cognitive biases, proved that a simple version of expected utility theory did not accurately describe human behavior. Their response was to develop <a href=\"http://www.princeton.edu/~kahneman/docs/Publications/prospect_theory.pdf\">prospect theory</a>, a model of how people really make decisions. Although the math is less elegant than that of expected utility, and the shapes of the curves have to be experimentally derived, it is worth a look because it successfully predicts many of the standard biases.<br/><br/></p><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1564192755/prospect_theory_1_csdmox.jpg\" class=\"draft-image center\" style=\"width:40%\" /></figure></span><br/><br/><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1564192755/prospect_theory_2_b6nbtm.jpg\" class=\"draft-image center\" style=\"width:40%\" /></figure></span><br/><p><em>(source: Wikipedia)</em></p><p>A prospect theory agent tasked with a decision first sets it within a frame with a convenient zero point, allowing em to classify the results of the decision as either losses or gains. Ey then computes a subjective expected utility, where the subjective expected utility equals the subjective value times the subjective probability. The subjective value is calculated from the real value using a value function similar to the one on the left-hand graph, and the subjective probability is calculated from the real probability using a weighting function similar to the one on the right-hand graph.</p><br/><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1564192755/prospect_theory_ex1_zw7rmx.jpg\" class=\"draft-image \" style=\"width:40%\" /></figure></span><br/><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1564192755/prospect_theory_ex2_qzftm2.jpg\" class=\"draft-image \" style=\"width:40%\" /></figure></span><br/><p>Clear as mud? Let&#x27;s fill some numbers into the functions - the exact assignments don&#x27;t really matter as long as we capture the spirit of where things change steeply versus slowly - and run through an example.<br/>Imagine a prospect theory agent - let&#x27;s call him Prospero - trying to decide whether or not to buy an hurricane insurance policy costing $5000/year. Prospero owns assets worth $10,000, and estimates a 50%/year chance of a hurricane destroying his assets; to make things simple, he will be moving in one year and so need not consider the future. Under expected utility theory, he should feel neutral about the policy.<br/><br/>Under prospect theory, he first sets a frame in which to consider the decision; his current state is a natural frame, so we&#x27;ll go with that. <br/><br/>We see on the left-hand graph that an objective $10,000 loss feels like a $5,000 loss, and an objective $5000 loss feels like a $4000 loss. And we see on the right-hand graph that a 50% probability feels like a 40% probability.<br/><br/>Now Prospero&#x27;s choice is a certain $4000 loss if he buys the insurance, versus a 40% chance of a $5000 loss if he doesn&#x27;t. Buying has a subjective expected utility of -$4000; not buying has a subjective expected utility of -$2000. So Prospero decisively rejects the insurance.<br/><br/>But suppose Prospero is fatalistic; he views his assets as already having been blown away. Here he might choose a different frame: the frame in which he starts with zero assets, and anything beyond that is viewed as a gain.<br/><br/>Since the gain half of the value function levels off more quickly than the loss half, $5000 is now subjectively worth $3000, and $10000 is now subjectively worth $3500.<br/><br/>Here he must choose between a certain gain of $5000 and a 50% chance of gaining $10000. Expected utility gives the same result as before, obviously. In prospect theory, he chooses between a certain subjective gain of $3000 and a 40% chance of gaining $3500. The insurance gives him subjective expected utility of $3000, and rejecting it gives him subjective expected utility of $1400.<br/><br/>All of a sudden Prospero wants the insurance.<br/><br/>We notice the opposite effect if there is only a a 1% chance of a hurricane. The insurance salesman lowers his price to $100 to preserve the neutrality of the insurance option when using utility. <br/><br/>But subjective probability rises very quickly, so a 1% chance may correspond to a subjective 10% chance. Now in the first frame, Prospero must decide between an objective loss of -$100 with certainty (corresponding to -$300 subjective since the value function is steeper closer to zero) or an objective loss of -$10,000 with objective probability 1% (subjective of 10%). Now the expected subjective utilities are -$300 if he buys, versus -$500 if he rejects. And so he buys the insurance. When we change the risk of hurricane from 50% to 1%, then even though we reduce the price of the insurance by an exactly equal amount, Prospero&#x27;s decision switches from not buying to buying.<br/><br/>Let&#x27;s see how many previously discussed biases we can fit into this model.<br/><br/>Prospero&#x27;s change from rejecting the insurance when framed as gains, to buying it when framed as losses, directly mirrors the change in preferred survival strategies mentioned in <a href=\"/lw/n3/circular_altruism/\">Circular Altruism</a>.<br/><br/>The necessity of frame-shifting between different perceptions of losses also produces the <a href=\"/lw/at/sunk_cost_fallacy/\">Sunk Cost Fallacy</a>.<br/><br/>The greater steepness of the value function with losses as opposed to gains is not even an explanation for, but merely a mathematical representation of, <a href=\"http://wiki.lesswrong.com/wiki/Loss_aversion\">loss aversion</a>. <br/><br/>The leveling off of the value function that turned the huge objective difference between +$5000 and +$10000 into the teensy little subjective difference between +$3000 and +$3500 mirrors the <a href=\"/lw/hw/scope_insensitivity/\">scope insensitivity</a> under which people show about the same level of interest in proposals to save endangered birds whether a thousand, ten thousand, or a hundred thousand birds are involved.<br/><br/>It may not be an official bias, but the &quot;<a href=\"/lw/ml/but_theres_still_a_chance_right/\">but there&#x27;s still a chance, right</a>&quot; outlook looks a lot like the sharply rising curve of the subjective probability function near zero.<br/><br/>And although it is not immediately obvious from the theory, <a href=\"http://www.mdpi.com/2073-4336/1/1/34/pdf\">some people want</a> to link the idea of a frame to priming and anchoring-adjustment, on the grounds that when a suitable reference frame doesn&#x27;t exist any primed stimulus can help establish one.<br/><br/>And now, the twist: prospect theory <a href=\"http://www2.gsu.edu/~ecoskl/lotteryhbk.pdf\">probably isn&#x27;t exactly true</a>. Although it holds up well in experiments where subjects are asked to make hypothetical choices, it may fare less well in the rare experiments where researchers can afford to offer subjects choices for real money (this isn&#x27;t the best paper out there, but it&#x27;s one I could find freely available).<br/><br/>Nevertheless, prospect theory seems fundamentally closer to the mark than simple expected utility theory, and if any model is ever created that can explain both hypothetical and real choices, I would be very surprised if at least part of it did not involve something looking a lot like Kahneman and Tversky&#x27;s model.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LQp9cZPzJncFKh5c8", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 84, "baseScore": 98, "extendedScore": null, "score": 0.000197, "legacy": true, "legacyId": "8511", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 98, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["PnhpMqMP75Dxpvar5", "4ZzefKQwAtMo5yp99", "tyMdPwd8x2RygcheE", "2ftJ38y9SRBCBsCzy", "q7Me34xvSG3Wm97As"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T08:13:46.039Z", "modifiedAt": null, "url": null, "title": "First LW-Meetup in Germany", "slug": "first-lw-meetup-in-germany", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:23.195Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wallowinmaya", "createdAt": "2011-03-21T00:39:18.855Z", "isAdmin": false, "displayName": "David Althaus"}, "userId": "xY8DDzk6TyvRroJEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NCWZgLkq4j67HfDiT/first-lw-meetup-in-germany", "pageUrlRelative": "/posts/NCWZgLkq4j67HfDiT/first-lw-meetup-in-germany", "linkUrl": "https://www.lesswrong.com/posts/NCWZgLkq4j67HfDiT/first-lw-meetup-in-germany", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20LW-Meetup%20in%20Germany&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20LW-Meetup%20in%20Germany%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCWZgLkq4j67HfDiT%2Ffirst-lw-meetup-in-germany%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20LW-Meetup%20in%20Germany%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCWZgLkq4j67HfDiT%2Ffirst-lw-meetup-in-germany", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNCWZgLkq4j67HfDiT%2Ffirst-lw-meetup-in-germany", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p>The surveys from my [first post](http://lesswrong.com/r/discussion/lw/5rz/lesswrongers_from_the_germanspeaking_world_unite/) indicate that <br /><br />1. the favorite city is Munich,<br /><br />2. around 3-10 people would attend, (?) <br /><br />3. the favorite month is August.<br /><br />Ok, ignoring [the usual advice](http://lesswrong.com/lw/ka/hold_off_on_proposing_solutions/), to get the ball rolling, here is my proposal:<br /><br />(Let's meet in Munich in August 5th, maybe at a restaurant or a pub.)</p>\n<p><strong>ETA:</strong> Um, I changed my mind: Munich is still the place to be, but let's meet some time in <em>September</em>!<br /><br />But if you disagree, please voice your opinion! I'm open to suggestions.<br /><br />I will add surveys in the comment-section.<br /><br />Oh, and everyone, including ultimate newbies, is welcome. Yes, *YOU* too!</p>\n<p>&nbsp;</p>\n<p><strong>ETA:</strong> [Here you can tell us your favorite date.](http://www.doodle.com/u49xxi6z4zqbihqa)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NCWZgLkq4j67HfDiT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.389836397223073e-07, "legacy": true, "legacyId": "8534", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T13:38:48.072Z", "modifiedAt": null, "url": null, "title": "Google search for \"rationality\" has HP:MoR as the 2nd hit.", "slug": "google-search-for-rationality-has-hp-mor-as-the-2nd-hit", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:48.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wilka", "createdAt": "2009-04-04T02:19:32.249Z", "isAdmin": false, "displayName": "Wilka"}, "userId": "ovpC9BgoTgHsForPa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w6Shn3ZY5BiYH6gMg/google-search-for-rationality-has-hp-mor-as-the-2nd-hit", "pageUrlRelative": "/posts/w6Shn3ZY5BiYH6gMg/google-search-for-rationality-has-hp-mor-as-the-2nd-hit", "linkUrl": "https://www.lesswrong.com/posts/w6Shn3ZY5BiYH6gMg/google-search-for-rationality-has-hp-mor-as-the-2nd-hit", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Google%20search%20for%20%22rationality%22%20has%20HP%3AMoR%20as%20the%202nd%20hit.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGoogle%20search%20for%20%22rationality%22%20has%20HP%3AMoR%20as%20the%202nd%20hit.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw6Shn3ZY5BiYH6gMg%2Fgoogle-search-for-rationality-has-hp-mor-as-the-2nd-hit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Google%20search%20for%20%22rationality%22%20has%20HP%3AMoR%20as%20the%202nd%20hit.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw6Shn3ZY5BiYH6gMg%2Fgoogle-search-for-rationality-has-hp-mor-as-the-2nd-hit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw6Shn3ZY5BiYH6gMg%2Fgoogle-search-for-rationality-has-hp-mor-as-the-2nd-hit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 89, "htmlBody": "<p>I've just noticed when searching for \"rationality\" with Google, HP:MoR is the second hit. Wikipedia is top, which is both good and expected - but I was suprised to see HP:MoR so high up.</p>\n<p>I think it's a good thing, anyone looking for info about rationality seems likly to be suprised by Harry Potter being mentioend, and then have a look at it.</p>\n<p>The first mention of Less Wrong is on the second page of results, but I&nbsp;wouldn't&nbsp;expect \"Less Wrong\" to be as attention&nbsp;grabbing&nbsp;as \"Harry Potter\" when you've just searched for&nbsp;\"rationality\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w6Shn3ZY5BiYH6gMg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 2, "extendedScore": null, "score": 7.390836334424067e-07, "legacy": true, "legacyId": "8535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T14:18:33.277Z", "modifiedAt": null, "url": null, "title": "Why don't automobiles decelerate faster when necessary?", "slug": "why-don-t-automobiles-decelerate-faster-when-necessary", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.712Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Will_Newsome", "createdAt": "2010-02-25T03:52:25.697Z", "isAdmin": false, "displayName": "Will_Newsome"}, "userId": "CxM9n2EDSn4AYgLdi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FcNNu7L4m6BqQgMEF/why-don-t-automobiles-decelerate-faster-when-necessary", "pageUrlRelative": "/posts/FcNNu7L4m6BqQgMEF/why-don-t-automobiles-decelerate-faster-when-necessary", "linkUrl": "https://www.lesswrong.com/posts/FcNNu7L4m6BqQgMEF/why-don-t-automobiles-decelerate-faster-when-necessary", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20don't%20automobiles%20decelerate%20faster%20when%20necessary%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20don't%20automobiles%20decelerate%20faster%20when%20necessary%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFcNNu7L4m6BqQgMEF%2Fwhy-don-t-automobiles-decelerate-faster-when-necessary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20don't%20automobiles%20decelerate%20faster%20when%20necessary%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFcNNu7L4m6BqQgMEF%2Fwhy-don-t-automobiles-decelerate-faster-when-necessary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFcNNu7L4m6BqQgMEF%2Fwhy-don-t-automobiles-decelerate-faster-when-necessary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 551, "htmlBody": "<p>When car<sub>a</sub>&nbsp;is trailing car<sub>b</sub>&nbsp;at 60ish MPH and&nbsp;car<sub>b&nbsp;</sub>suddenly brakes,&nbsp;car<sub>a&nbsp;</sub>traverses 150 feet or so before its driver notices danger and stamps on the brakes, and an additional 150 feet are traversed after the brakes are engaged. (<a href=\"http://www.csgnetwork.com/stopdistinfo.html\">It's more complicated than that</a> and it's more complicated than that, too. If I'm oversimplifying too much at this phase please let me know.) So obviously the stopping power of the vehicle is important. Now, a huge amount of R&amp;D has been done on automobile braking systems. Not only are modern braking systems automatic&nbsp;supersonic hypnotic&nbsp;funky fresh, modern cars can extract modern energy out of them, too. But... well, I'm having a lot of trouble finding credible statistics, but it looks like a large fraction of the victims of fatal car accidents are in vehicles that get rear-ended at high speeds.<sup>0</sup> Not only do they cause a lot of immediate deaths, rear-ending accidents also cause a lot of damage to both vehicles and nervous systems (whip-lash), and it's hard to calculate how that compounds over the years, but you know it's a really huge amount of lost QALYs and moneys. What I don't understand is, it <em>naively</em>&nbsp;seems to me that&nbsp;there are many different ways you can get a tailing vehicle to stop faster, ways that don't involve completely hopeless public education drives or expensive 5% improvements on disc brakes. Like, having a special system specifically for applying high friction directly to the road surface in emergencies, either mechanically or via electromagnetism. Or an <a href=\"http://en.wikipedia.org/wiki/Air_brake_(road_vehicle)#Exposed_Physical_Structure\">air brake</a><sup>0.08</sup>&nbsp;or two. Combine those with existing automatic electronic sensor brake activator thingies and you can stop the vehicle almost immediately.<sup>1</sup> Wham bam, way less crushed organs and needless suffering. But I never hear anyone talking about this. Is it because modern cars just don't crash into cars in front of them anymore? If so, would it be too expensive to equip older cars with a simple brake-pressure-remotely-activated dedicated stopping mechanism?<sup>14</sup>&nbsp;E.g. a government or non-profit program that equipped them free-of-charge on the cars of inexperienced or risk-prone drivers.&nbsp;Or something? I can think of a lot of engineering point and counterpoint that would make it more or less difficult but it still seems feasible, life-saving, and money-saving. What am I missing? What hard steps did I trivialize? I am more interested in automobile engineering steps I naively trivialized, but social engineering steps that I ignored might be more important somehow... what gives?</p>\n<p>&nbsp;</p>\n<p><span style=\"font-family: mceinline;\"><sup>(This has many connections to both instrumental and epistemic rationality </sup><sub>but unfortunately it would be too psychologically difficult for me to point them out. </sub><sup>I do not think a meta discussion about this would be profitable</sup><sub>,</sub><sup> </sup><sub>but I may be wrong.)</sub></span></p>\n<p>&nbsp;</p>\n<p><sup>0</sup>&nbsp;I saw somewhere that most fatal accidents involve only a single car. That agrees with my experience but I remain somewhat skeptical.</p>\n<p><span style=\"font-size: 11px;\"><sup>0.08&nbsp;</sup></span>More specifically, some reasonable hybrid of air brake and uber-efficient-mini-parachute. I don't know how negligible the stopping power of air brakes is at freeway speeds.</p>\n<p><sup>1</sup>&nbsp;Stopping too fast does indeed hurt the driver but it's rather asymmetric, you can deploy various safety mechanisms in advance unlike the case where you're crashing into an unsuspecting Honda with your Chevy.</p>\n<p><sup>14&nbsp;</sup>I don't see why making such add-on systems at least half-automatic should be hard either, it's like 2 cheap cameras and a rudimentary but information-efficient AI... or maybe I just completely underestimate the complexity of those systems.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FcNNu7L4m6BqQgMEF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -1, "extendedScore": null, "score": 7.390958648594411e-07, "legacy": true, "legacyId": "8536", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T18:24:04.738Z", "modifiedAt": null, "url": null, "title": "too much consistency considered harmful", "slug": "too-much-consistency-considered-harmful", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:47.042Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J85qS9daMScmH3EJW/too-much-consistency-considered-harmful", "pageUrlRelative": "/posts/J85qS9daMScmH3EJW/too-much-consistency-considered-harmful", "linkUrl": "https://www.lesswrong.com/posts/J85qS9daMScmH3EJW/too-much-consistency-considered-harmful", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20too%20much%20consistency%20considered%20harmful&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Atoo%20much%20consistency%20considered%20harmful%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ85qS9daMScmH3EJW%2Ftoo-much-consistency-considered-harmful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=too%20much%20consistency%20considered%20harmful%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ85qS9daMScmH3EJW%2Ftoo-much-consistency-considered-harmful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ85qS9daMScmH3EJW%2Ftoo-much-consistency-considered-harmful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 546, "htmlBody": "<p>&nbsp;</p>\n<p>In many instances of Akrasia the it's pointed out that the victim has a preference reversal either due to time differences or due to different context. E.g. I might be enjoying staying up late tonight, but tomorrow I will experience headache, sluggishness and frustration which would by far outweigh tonight's pleasures. I am going to hate myself tomorrow, but at the moment I might look my tomorrow's self in the face and tell him to piss off. Oh, if only I was more consistent! - my overall life happiness would increase quite a bit. Should I try?</p>\n<p>Maybe; I don't know if a direct approach to \"increasing&nbsp;consistency\" would hit the mark, thought it definitely seems worth investigating.</p>\n<p>On the other hand, I recently noticed another phenomenon, where the ability to be <strong>less</strong> consistent is a potential benefit. Just to be clear, I am not talking about consistency of opinion - it a different topic well covered by Churchill's \"I've often had to swallow my words, and found it a wholesome diet\". I am talking about the ability to dissociate from certain future versions of self, same kind of dissociation that allows me to tell the Tomorrow Me to piss off (yes, I've actually done that).&nbsp;</p>\n<p>Here is an example. I am swimming for&nbsp;exercise, but every time I jump in the pool the water will give me an uppleasant shock. So here I am, standing in my swim trunks in front of the pool and deciding when I am ready to take the pain. This is clearly self-inflicted \"addition of insult to injury\". And it's all based on thinking and imagining how much pain I am going to experience in the next few seconds.</p>\n<p>Of course, in a sense I have already dealt with the problem - I am after all in front of the pool, in public, and not at home, deciding whether to&nbsp;jump&nbsp;in the pool; so it seems that in a sense the problem has been dealt with. On the other hand, the pain of pain anticipation is not nothing, and perhaps it will eventually propagate back (via, say, <a href=\"/lw/6ja/basics_of_human_reinforcement/\">reinforcement learning</a>) to the decision to stay home one day when I'm feeling tired and maybe the next day... So there are two reasons to address the issue: Less Pain=More Fun and to avoid stacking the deck against yourself in terms of achieving your goals.</p>\n<p>So one thing that comes to mind is to use the ability to dissociate from yourself in order to Just Do It. As a matter of fact your swimming-pool pals might have already learned the trick - look at the ones who, like you, stand hesitantly by the water, thinking, and then watch out for that one guy who runs and just dives in.&nbsp;</p>\n<p>It is interesting that a certain kind of&nbsp;spontaneous&nbsp;decisiveness is stereotyped as a hallmark of successful people. To many of us it seems crazy - these people Are Not Thinking Through Things! I think this intuition is not incorrect, stereotypes reflect a lot of selection bias - we do not see all those who Just Did and CrashBurned, but perhaps there is also a certain positive ability there to think about.</p>\n<p>Interested in the following feedback:</p>\n<p>True/False.</p>\n<p>Title</p>\n<p>Additionald motivation - why might this idea be useful?</p>\n<p>Potential applications - related to above.</p>\n<p>&nbsp;- asking for significant favor, raise, etc.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J85qS9daMScmH3EJW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "8537", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BfaAADSQ88cuxLQoD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T20:20:00.731Z", "modifiedAt": null, "url": null, "title": "Physical and Mental Behavior", "slug": "physical-and-mental-behavior", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:02.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5dhWhjfxn4tPfFQdi/physical-and-mental-behavior", "pageUrlRelative": "/posts/5dhWhjfxn4tPfFQdi/physical-and-mental-behavior", "linkUrl": "https://www.lesswrong.com/posts/5dhWhjfxn4tPfFQdi/physical-and-mental-behavior", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Physical%20and%20Mental%20Behavior&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhysical%20and%20Mental%20Behavior%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5dhWhjfxn4tPfFQdi%2Fphysical-and-mental-behavior%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Physical%20and%20Mental%20Behavior%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5dhWhjfxn4tPfFQdi%2Fphysical-and-mental-behavior", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5dhWhjfxn4tPfFQdi%2Fphysical-and-mental-behavior", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 932, "htmlBody": "<p>B.F. Skinner called thoughts \"mental behavior\". He believed they could be rewarded and punished just like physical behavior, and that they increased or declined in frequency accordingly.<br /><br />Sadly, psychology has not yet advanced to the point where we can give people electric shocks for thinking things, so the sort of rewards and punishments that reinforce thoughts must be purely internal reinforcement. A thought or intention that causes good feelings gets reinforced and prospers; one that causes bad feelings gets punished and dies out.<br /><br />(Roko has already discussed this in <a href=\"/lw/21b/ugh_fields/\">Ugh Fields</a>; so much as thinking about an unpleasant task is unpleasant; therefore most people do not think about unpleasant tasks and end up delaying them or avoiding them completely. If you haven't already read that post, it does a very good job of making reinforcement of thoughts make sense.)<br /><br />A while back, D_Malik published a great big <a href=\"/lw/5b8/insufficiently_awesome/3z5r\">List Of Things One Could Do To Become Awesome</a>.&nbsp; As David_Gerard replied, the list was itself a small feat of awesome. I expect a couple of people started on some of the more awesome-sounding entries, then gave up after a few minutes and never thought about it again. Why?<br /><br />When I was younger, I used to come up with plans to become awesome in some unlikely way. Maybe I'd hear someone speaking Swahili, and I would think \"I should learn Swahili,\" and then I would segue into daydreams of being with a group of friends, and someone would ask if any of us spoke any foreign languages, and I would say I was fluent in Swahili, and they would all react with shock and tell me I must be lying, and then a Kenyan person would wander by, and I'd have a conversation with them in Swahili, and they'd say that I was the first American they'd ever met who was really fluent in Swahili, and then all my friends would be awed and decide I was the best person ever, and...<br /><br />...and the point is that the thought of learning Swahili is pleasant, in the same easy-to-visualize but useless way that an <a href=\"/lw/5x8/teachable_rationality_skills/49dl\">extra bedroom for Grandma</a> is pleasant. And the intention to learn Swahili is also pleasant, because it will lead to all those pleasant things.&nbsp; And so, by reinforcement of mental behavior, I continue thinking about and intending to learn Swahili.<br /><br />Now consider the behavior of studying Swahili. I've never done so, but I imagine it involves a lot of long nights hunched over books of Swahili grammar. Since I am not one of the lucky people who enjoys learning languages for their own sake, this will be an unpleasant task. And rewards will be few and far between: outside my fantasies, my friends don't just get together and ask what languages we know while random Kenyans are walking by.<br /><br />In fact, it's even worse than this, because I don't exactly make the decision to study Swahili in aggregate, but only in the form of whether to study Swahili each time I get the chance. If I have the opportunity to study Swahili for an hour, this provides no clear reward - an hour's studying or not isn't going to make much difference to whether I can impress my friends by chatting with a Kenyan - but it will still be unpleasant to spend an hour of going over boring Swahili grammar. And time discounting makes me value my hour today much more than I value some hypothetical opportunity to impress people months down the line; Ainslie shows quite clearly I will always be better off postponing my study until later.<br /><br />So the behavior of actually learning Swahili is thankless and unpleasant and very likely doesn't happen at all.<br /><br />Thinking about studying Swahili is positively reinforced, actually studying Swahili is negatively reinforced. The natural and obvious result is that I intend to study Swahili, but don't.<br /><br />The problem is that for some reason, some crazy people expect for the reinforcement of thoughts to correspond to the reinforcement of the object of those thoughts. Maybe it's that old idea of \"preference\": I have a preference for studying Swahili, so I should satisfy that preference, right? But there's nothing in my brain <em>automatically</em> connecting this node over here called \"intend to study Swahili\" to this node over here called \"study Swahili\"; any association between them has to be learned the hard way.<br /><br />We can describe this hard way in terms of reinforcement learning: after intending to learn Swahili but not doing so, I feel stupid. This unpleasant feeling propagates back to its cause, the behavior of intending to learn Swahili, and negatively reinforces it. Later, when I start thinking it might be neat to learn Mongolian on a whim, this generalizes to behavior that has previously been negatively reinforced, so I avoid it (in anthropomorphic terms, I \"expect\" to fail at learning Mongolian and to feel stupid later, so I avoid doing so).<br /><br />I didn't learn this the first time, and I doubt most other people do either. And it's a tough problem to call, because if you overdo the negative reinforcement, then you never try to do anything difficult ever again.<br /><br />In any case, the lesson is that thoughts and intentions get reinforced separately from actions, and although you can eventually learn to connect intentions to actions, you should never take the connection for granted.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "iP2X4jQNHMWHRNPne": 2, "SJFsFfFhE6m2ThAYJ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5dhWhjfxn4tPfFQdi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 58, "baseScore": 79, "extendedScore": null, "score": 0.000162, "legacy": true, "legacyId": "8538", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EFQ3F6kmt4WHXRqik"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-10T22:55:39.186Z", "modifiedAt": null, "url": null, "title": "Looking for a quote", "slug": "looking-for-a-quote", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:48.297Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Document", "createdAt": "2010-02-08T04:14:47.949Z", "isAdmin": false, "displayName": "Document"}, "userId": "vaMNHjzaCGqF8yTMS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jqw3nGg2LzaPpHEtr/looking-for-a-quote", "pageUrlRelative": "/posts/jqw3nGg2LzaPpHEtr/looking-for-a-quote", "linkUrl": "https://www.lesswrong.com/posts/jqw3nGg2LzaPpHEtr/looking-for-a-quote", "postedAtFormatted": "Sunday, July 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20for%20a%20quote&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20for%20a%20quote%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjqw3nGg2LzaPpHEtr%2Flooking-for-a-quote%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20for%20a%20quote%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjqw3nGg2LzaPpHEtr%2Flooking-for-a-quote", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjqw3nGg2LzaPpHEtr%2Flooking-for-a-quote", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 39, "htmlBody": "<p>The last sentence was something like \"I regret that the judgment I made was wrong, not that it was made.\" I thought it was in one of the Rationality Quotes threads here, but I can't find it with Google.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jqw3nGg2LzaPpHEtr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 1, "extendedScore": null, "score": 7.392549995057321e-07, "legacy": true, "legacyId": "8539", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T08:42:02.292Z", "modifiedAt": null, "url": null, "title": "Community norm question: brief text ad signatures", "slug": "community-norm-question-brief-text-ad-signatures", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.473Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qe2adSZWdjqL4SrHg/community-norm-question-brief-text-ad-signatures", "pageUrlRelative": "/posts/Qe2adSZWdjqL4SrHg/community-norm-question-brief-text-ad-signatures", "linkUrl": "https://www.lesswrong.com/posts/Qe2adSZWdjqL4SrHg/community-norm-question-brief-text-ad-signatures", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Community%20norm%20question%3A%20brief%20text%20ad%20signatures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACommunity%20norm%20question%3A%20brief%20text%20ad%20signatures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQe2adSZWdjqL4SrHg%2Fcommunity-norm-question-brief-text-ad-signatures%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Community%20norm%20question%3A%20brief%20text%20ad%20signatures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQe2adSZWdjqL4SrHg%2Fcommunity-norm-question-brief-text-ad-signatures", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQe2adSZWdjqL4SrHg%2Fcommunity-norm-question-brief-text-ad-signatures", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 466, "htmlBody": "<p>I've written several posts on this site, many of which were promoted to the front page. Some of my writings have been quite popular. Looking through the Google Analytics stats for this site showed that my writing has had at least 50 000 unique views over time. The full total is probably more, since I only looked at the stats of the 1000 most viewed Less Wrong pages.<br /><br />As I have been looking for sources of side income, I was wondering whether it'd be deemed acceptable if I started signing my posts to the main section with something brief like this:<br /><br /><em>To see the novel I'm writing, <a href=\"http://xuenay.livejournal.com/tag/city%20of%20light%20and%20fire\">click here</a>. If you liked this post, you may also <a href=\"https://flattr.com/thing/197452/Xuenay-on-Flattr\">Flattr me here</a>.<br /></em><br />I'm currently thinking about trying to make a living on writing, and being able to do something like this would make it considerably easier to help build a personal brand. Although I wouldn't dare to claim to write as well as Eliezer or Yvain, say, I would like to think that my posts have been valuable for several people. The fact that sixteen of my articles were among the 1000 most viewed LW pages would support this. Being able to get back some of that value would only seem fair to me.<br /><br />As an additional bonus, currently my LW writing has gotten sidelined as it hasn't seemed that useful for my personal goals. Being allowed to have such ads would make writing on LW more personally useful for me, incentivizing me to spend more time on writing quality posts here.<br /><br />I can understand not everyone being fully enthusiastic about this, though. For one, several Internet communities are quite stringent about things that might be considered spam. Also, people might also be worried about the fact that LW is currently mostly operating as a gift economy. Letting people make money off their posts directly, such as with Flattr links, might change the community norms in an undesirable direction. Folks such as matt, who are hard at work at improving the technical side of the site, might rightfully feel that they deserve a cut.<br /><br />So I figured I'd better ask first. For what it's worth, I <a href=\"http://intelligence.org/donors\">have donated to SIAI</a> in the past, and do intend to donate to either SIAI or FHI or both in the future. Part of any income I'd make through this site would go to fund my donations. I'm also already spending some of my time writing academically about LW-related issues. You can e.g. expect to see a full-length paper draft based on my <a href=\"http://intelligence.org/upload/mostly-harmless.pdf\">previous conference paper</a> before the month is over. Extra income sources would also let me spend more time doing such work.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qe2adSZWdjqL4SrHg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 13, "extendedScore": null, "score": 7.394355300737319e-07, "legacy": true, "legacyId": "8554", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T14:20:45.681Z", "modifiedAt": null, "url": null, "title": "Motivation research presentation", "slug": "motivation-research-presentation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iw43WErJTzTze7HQW/motivation-research-presentation", "pageUrlRelative": "/posts/iw43WErJTzTze7HQW/motivation-research-presentation", "linkUrl": "https://www.lesswrong.com/posts/iw43WErJTzTze7HQW/motivation-research-presentation", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Motivation%20research%20presentation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMotivation%20research%20presentation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiw43WErJTzTze7HQW%2Fmotivation-research-presentation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Motivation%20research%20presentation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiw43WErJTzTze7HQW%2Fmotivation-research-presentation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiw43WErJTzTze7HQW%2Fmotivation-research-presentation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 303, "htmlBody": "<p>I did a presentation on&nbsp;<a href=\"/lw/3w3/how_to_beat_procrastination/\" target=\"_blank\">motivation and procrastination research</a>&nbsp;to the Seattle meetup group and an exercise trying to apply the material to a real life example. Eight people came. They were a skeptical bunch and questioned me on exactly the parts I am most interested in an know the least about: how exactly scientists assess the psychological quantities (expectancy, value, delay and impulsiveness). I'd like to learn more about the research and be able to give such presentations to others in the future. I'd also like to record a presentation like it and put it up on the internet.</p>\n<p>People seemed to think the exercise was pretty valuable. It was also fairly fun. The presentation is&nbsp;<a href=\"https://docs.google.com/present/edit?id=0Af25X_YdRE3TZGd6Z3Z4azNfNTRjbjkzYjJoZg&amp;hl=en_US\" target=\"_blank\">here</a>, the exercise is&nbsp;<a href=\"https://docs.google.com/document/d/1_rDLTN7OYKKzDzKi4zln5aNy-q1EPxRySTJWzuKSWf0/edit?hl=en_US\" target=\"_blank\">here</a>&nbsp;and&nbsp;<a href=\"https://docs.google.com/document/d/1DElaB_z2MqmM-I0UYy6QWIWkN6wlyff3gmb-eOT5HJM/edit?hl=en_US\" target=\"_blank\">here</a>.</p>\n<p>Luke's suggestion for how to learn how psychologists assess expectancy, value and delay was</p>\n<blockquote>As for how scientists assess the relevant psychological qualities, and for why the 'procrastination equation' is taken seriously, all the references are provided in my post '<a href=\"/lw/3w3/how_to_beat_procrastination/\" target=\"_blank\">How to Beat Procrastination</a>'. I also uploaded quite a few of the studies myself so anyone who is&nbsp;<em>actually</em>&nbsp;interested can check the data for themselves. (Prediction: Almost nobody will.)&nbsp;<br />The papers in footnote 6 are the place to start, for they explain why the equation (called temporal motivation theory by researchers) was developed to predict experimental results, and those papers point to all the individual studies which show how scientists assess expectancy, value, delay, and impulsiveness. For example, 'expectancy' in TMT is measured under a variety of psychological constructs, but largely by measures of self-efficacy and optimism.<br />There is no short summary of these issues, though Piers Steel's recent book 'The Procrastination Equation' is a decent attempt while being much longer than my article. Psychology is very complicated, and our understanding of it is less certain than our understanding of physics or computer science.</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iw43WErJTzTze7HQW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.395398484595731e-07, "legacy": true, "legacyId": "8547", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RWo4LwFzpHNQCTcYt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T15:29:43.279Z", "modifiedAt": null, "url": null, "title": "Self-improving AGI: Is a confrontational or a secretive approach favorable?", "slug": "self-improving-agi-is-a-confrontational-or-a-secretive", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.208Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Friendly-HI", "createdAt": "2011-04-18T18:19:01.357Z", "isAdmin": false, "displayName": "Friendly-HI"}, "userId": "nXA5fJiYcfJGaQkwG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6BSweYhk5JLzJtdAh/self-improving-agi-is-a-confrontational-or-a-secretive", "pageUrlRelative": "/posts/6BSweYhk5JLzJtdAh/self-improving-agi-is-a-confrontational-or-a-secretive", "linkUrl": "https://www.lesswrong.com/posts/6BSweYhk5JLzJtdAh/self-improving-agi-is-a-confrontational-or-a-secretive", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Self-improving%20AGI%3A%20Is%20a%20confrontational%20or%20a%20secretive%20approach%20favorable%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelf-improving%20AGI%3A%20Is%20a%20confrontational%20or%20a%20secretive%20approach%20favorable%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BSweYhk5JLzJtdAh%2Fself-improving-agi-is-a-confrontational-or-a-secretive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Self-improving%20AGI%3A%20Is%20a%20confrontational%20or%20a%20secretive%20approach%20favorable%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BSweYhk5JLzJtdAh%2Fself-improving-agi-is-a-confrontational-or-a-secretive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6BSweYhk5JLzJtdAh%2Fself-improving-agi-is-a-confrontational-or-a-secretive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2239, "htmlBody": "<p>&nbsp;</p>\n<div id=\"body_t1_4gut\" class=\"comment-content \" style=\"clear: both; padding-top: 9px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px;\">\n<div class=\"md\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">(I've written the following text as a comment initially, but upon short reflection I thought it was worth a&nbsp;separate&nbsp;topic and so I adapted it accordingly.)</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">Lesswrong is largely concerned with teaching rationality skills, but for good reasons most of us also incorporate concepts like the singularity and friendly self-improving AGI into our \"message\". Personally I wonder however, if we should be as outspoken about that sort of AGI as we currently are. Right now talking about self-improving AGI doesn't pose any kind of&nbsp;discernible&nbsp;harm, because \"outsiders\" don't feel threatened by it and look at it as far-off &nbsp;&mdash;or even impossible&mdash;&nbsp;science fiction. But as time&nbsp;progresses, I worry that through exponential advances in robotics and other technologies people will become more aware, concerned and perhaps threatened by self-improving AGI and I am not sure whether we should be outspoken about things like... the fact that the majority of AGI's in \"mind-design-space\" will tear humanity to shreds if its builders don't know what they're doing. Right now such talk is harmless, but my message here is, that we may want to reconsider whether or not we should talk publicly about such topics in the not-too-distant future, so as to avoid compromising our chances of success when it comes to actually building a friendly self-improving AGI.</span></span></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">First off, I suspect I have a somewhat different conception of how the future is going to pan out in terms of what role the public perception and acceptance of self-improving AGI will play:&nbsp;Personally I'm not under the impression, that we can prepare a sizable portion of the public (let alone the </span></span><em style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small;\">global</em><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"> public) for the arrival of AGI (prepare them in a positive manner that is). I believe singularitarian ideas will just continue to compete with countless other worldviews in the public&nbsp;meme-sphere,&nbsp;without ever becoming truly mainstream until it is \"too late\" and we face something akin to a hard takeoff and perhaps lots of resistance.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">I don't really think that we can (or need to) reach a consensus within the public for the successful takeoff of AGI. Quite to the contrary, I actually worry that carrying our view to the mainstream will have adverse effects, especially once they realize that we aren't some kind of technophile crackpot religion, but that the futuristic picture we try to paint is actually possible and not at all unlikely to happen. I would certainly prefer to face apathy over antagonism when push comes to shove - and since self-improving AGI could spring into existence very rapidly and take everyone apart from \"those in the know\" by surprise, I would hate to lose that element of surprise over our potentially numerous \"enemies\".</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Now of course I don't know which path will yield the best result: confronting the public or keeping a low profile? I suspect this may become one of the few hot-button topics where our community will sport widely diverging opinions, because we simply lack a way to accurately model&nbsp;(especially so far in advance)&nbsp;how people will behave upon encountering the reality and the potential threat of AGI. Just remember, that the world doesn't consist entirely of the US and that AGI will impact everyone. I think it is likely, that we may face serious violence once our vision of the future becomes more known and gains additional credibility by exponential improvements in advanced technologies. There are players on this planet who will not be happy to see an AGI come out of America, or for that matter Eliezer's or whoever's garage. This is why I would strongly advocate a semi-covert international effort when it comes to the development of friendly AGI. (Don't say that it's self-improving and may become a trillion times smarter than all humans combined - just pretend it's roughly a human-level AI).</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">It is incredibly hard to predict the future behavior of people, but on a gut-level I absolutely favor an international semi-stealthy approach. It seems to be by far the safest course to take. Once the concept of the singularity and AGI gains traction in the spheres of science and maybe even politics (perhaps in a decade or two), I would hope that minds in AI and AGI from all over the world join an international initiative to develop self-improving AGI together. (Think CERN). To be honest, I can't even think of any other approach to develop the later stages of AGI, that doesn't look doomed from the start (not doomed in the sense of being technically unfeasible, but doomed in terms of significant others thinking: \"we're not letting this suspicious organization/country take over the world with their dubious AI\". Remember that self-improving AGI is potentially much more destructive than any nuclear warhead and powers not involved in its development may blow a gasket upon realizing the potential danger.)</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">So from my point of view, the public perception and acceptance of AGI is a comparatively negligible factor in the overall bigger picture if managed correctly. \"People\" don't get a say in weapons development, and I predict they won't get a say when it comes to Self-improving AGI. (And we should be glad they don't if you ask me.) But in order to not risk public outcry when the time is ripe and AGI in its last stages of completion, we should give serious consideration to not upset and terrify the public by our... \"vision of the future\".</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">PS: Somehow CERN comes to mind again. Do you remember when critics came up with ridiculous ideas how the LHC could destroy the world? It was a very serious allegation, but the public largely shrugged it off - not because they had any idea of course, but because they were reassured by enough eggheads that it wouldn't happen. It would be great, if we could achieve a similar reaction towards AGI-criticism (by which I mean generic criticism of course, not useful criticism - after all we actually want to be as sure about how the AGI will behave, as we were sure about the LHC not destroying the world). Once robots become more commonplace in our lives, I think we can reasonably expect that people will begin to place their trust into simple AI's - and they will hopefully become less suspicious towards AGI and simply assume (like a lot of current AI-researchers apparently) that somehow it is trivial to make it behave friendly towards humans.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">So what do you think? Should we become more careful when we talk about self-modifying artificial intelligence? I think the \"self-modifying\"- and \"trillions of times smarter\"-parts are some bitter pills to swallow, and people won't be amused once they realize that we aren't just building artificial humans but artificial, allpowerful, allknowing, and (hopefully) allloving gods.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<hr />\n<hr />\n<p>&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><strong>EDIT: 08.07.11</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">PS: If you can accept that argument as rationally sound, I believe a discussion about \"informing everyone vs. keeping a low profile\" is more than warranted. Quite frankly though, I am pretty disappointed with most people's reactions to my essay this far... &nbsp;I'd like to think that this isn't just my ego acting up, but I'm sincerely baffled as to why this essay usually hovers just slightly above 0 points and frequently gets downvoted back to neutrality. Perhaps it's because of my style of writing (admittedly I'm often not as precise and careful with my wording as many of you are), or my grammar mistakes due to me being German, but preferably that would be because of some serious rational mistakes I made and of which I am still unaware... &nbsp;in which case you should point them out to me.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">Presumably not <em>that</em> many people have read it, but in my eyes those who did and voted it down have not provided any kind of rational rebuttal here in the comment section of why this essay stinks. I find the reasoning I provided to be simple and sound:</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">0.0) <strong>Either</strong> we place \"intrinsic\" value on the concept of democracy and respect (and ultimately adhere to) &nbsp;public opinion in our decision to build and release AGI, <strong>OR</strong>&nbsp;we don't and make that decision a matter of rational expert opinion, while excluding the general public to some greater or lesser degree in the decision process. This is the question whether we view a democratic decision about AGI as the right thing to do, or just one possible means to our&nbsp;preferred&nbsp;end.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">1.0) If we accept radically democratic principles and essentially want to put up AGI for vote, then we have a lot of work to do: We have to reach out to the public, thoroughly inform them in detail about every known aspect of AGI and convince a majority of the worldwide public, that it is a good idea. If they reject it, we would have to postpone the development and/or release, until public opinion sways or an un/friendly AGI gets released without consensus in the meantime.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">1.1) Getting consent is not a trivial task by any stretch of my imagination and from what I know about human psychology, I believe it is more rational to assume, that the democratic approach cannot possibly work. If you think otherwise, if you SERIOUSLY think this can be successfully pulled off, then I think the burden of proof is on you here: Why should 4,5 billion people suddenly become champions of rationality? How do you think this radical transformation from an insipid public to a powerhouse of intelligent decision-making will take place? None of you (those who defend the possibility and preference of the democratic approach) have done this yet. The only thing that could convince me here would be that the majority of people, or at least a sizable portion, have powerful brain augmentations by the time AGI is on the brink of completion. That I do not believe, but none of you argued this case so far, nor did someone argue in-depth (including countering my arguments and concerns about) how a democratic approach could possibly succeed without brain augmentation.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">2.0) If we reject the desirability of a democratic decision when it comes to AGI (as I do for practical concerns), we automatically approach public opinion from a different angle: Public opinion becomes an instrumental concern, because we admit to ourselves that we would be willing to release AGI whether or not we have public consent. If we go down this path, we must ask ourselves how we manage public opinion in a manner that benefits our cause. How exactly should we engage them - if at all? My \"moral\" take on this in a sentence: \"</span></span><span style=\"line-height: 16px;\">I'm vastly more committed to rationality than I am to the idea that undiscriminating democracy is the gold standard of decision-making.\"</span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">2.1) In this case, the question becomes whether or not informing the public as thoroughly as possible will aid or hinder our ambitions. In case we believe the majority of the public would reject our AGI project, even after we educate them about it (the scenario I predict), the question is obviously whether or not it is beneficial to inform them about it in the first place. I gave my reasons why I think secrecy (at least about some aspects of AGI) would be the better option and I've not yet read any convincing thoughts to the contrary. How could we possibly trust them to make the rational choice once they're informed, and how could we (and they) react,&nbsp;<em>after</em> most people are informed of AGI and actually disapprove ?</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">2.2) If you're with me on 2.0 and 2.1, then the next problem is who we think should know about it to what extent, who shouldn't, and how this can be practically implemented. This I've not thoroughly thought about myself yet, because I hoped this would be the direction where our discussion would go, but I'm disappointed that most of you seem to argue &nbsp;for 1.0 and 1.1 instead (which would be great if the arguments were good, but to me they seem like cheap applause lights, instead of being even remotely practical in the real world).</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">(These points are of course not a full breakdown of all possibilities to consider, but I believe they roughly cover most bases)</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><br /></span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">I also expected to hear some of you make a good case for 1.0 and 1.1, or even call into question 0.0, but most of you guys just pretend \"1.0 and 1.1 are possible\" without any sound explanation why that would be the case. You just assume it can be done for some reason, but I think you should explain yourself, because this is an extraordinary claim, while my assumption of 4,5 billion people NOT becoming rational superheroes or fanatical geeky AGI followers seems vastly more likely to me.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">Considering what I've thought about until now, secrecy (or at the very least not too broad and enthusiastic public outreach, combined with an alternative approach of targeting more specific groups or people to contact) seems to be the&nbsp;preferable&nbsp;option to me. </span></span></span></span><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 15px;\">ALSO, I admit that public outreach is most probably fine right now, because people who reject it nowadays usually simply feel like it couldn't be done anyway, and it's so far off that they won't make an effort to oppose us, while people whom we convince are all&nbsp;potential&nbsp;human resources for our cause who are welcome and needed.</span></span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px; font-size: small; margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">So in a nutshell I think the cost/benefit ratio of public outreach is just fine by now, but that we ought to reconsider our approach in due time (perhaps a decade or so from now, depending on the future progress and public perception of AI).</p>\n<p>&nbsp;</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6BSweYhk5JLzJtdAh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 6, "extendedScore": null, "score": 7.395610896156082e-07, "legacy": true, "legacyId": "8453", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T18:01:29.721Z", "modifiedAt": null, "url": null, "title": "Things Man Was Not Meant To Know", "slug": "things-man-was-not-meant-to-know", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Multiheaded", "createdAt": "2011-07-02T10:10:20.692Z", "isAdmin": false, "displayName": "Multiheaded"}, "userId": "moGiw35FowgiAnzfg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nfQPyKxnCvrz44DDp/things-man-was-not-meant-to-know", "pageUrlRelative": "/posts/nfQPyKxnCvrz44DDp/things-man-was-not-meant-to-know", "linkUrl": "https://www.lesswrong.com/posts/nfQPyKxnCvrz44DDp/things-man-was-not-meant-to-know", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Things%20Man%20Was%20Not%20Meant%20To%20Know&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThings%20Man%20Was%20Not%20Meant%20To%20Know%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfQPyKxnCvrz44DDp%2Fthings-man-was-not-meant-to-know%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Things%20Man%20Was%20Not%20Meant%20To%20Know%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfQPyKxnCvrz44DDp%2Fthings-man-was-not-meant-to-know", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnfQPyKxnCvrz44DDp%2Fthings-man-was-not-meant-to-know", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 237, "htmlBody": "<p>Yes, <em>those </em>ones! This \"acasual\" stuff that Eliezer seems to take seriously. I already saw references to a few of them, and, He-Who-Is-Not forgive me, read Roko's deleted idea on pastebin. Sigh, guess I'll just have to pre-commit against it. I will avert my eyes from the thing in the welcome thread right now, if commenters tell me that it's a good idea.</p>\n<p>My point is: <strong>WHAT THE FLYING F*CK?!</strong> I know I'm impressionable and easily scared, but how the hell can it be?! That's not a very nice thing, to have Yellow Signs floating about in a community. Please explain. I'm 100% serious here.</p>\n<p>Oh, and no, I won't have nightmares like that guy who was scared of the first thing I mentioned. I can forget it quickly enough if neccessary. But right now, I've talked myself into viewing it as a serious possibility. And, well, I never wanted to be in <em>this </em>kind of a science fiction story!</p>\n<p>&nbsp;</p>\n<p>And yeah, in my infinite wisdom, I did mention that occurence on TVTropes immediately after getting hit by it...</p>\n<p>&nbsp;</p>\n<p>Got more information: it seems that it's only EY and a minority of contributors are actively suppressing the (gulp) Basilisk. Still, Eliezer could well know more about the subject then all the others here combined, which is why he's so devoted to keeping it down... things aren't getting any better.</p>\n<p>&nbsp;</p>\n<p><strong>OK! OK! Get this post back to -1 and I'll delete it myself!</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nfQPyKxnCvrz44DDp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": -2, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "8559", "legacySpam": true, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T18:45:13.050Z", "modifiedAt": null, "url": null, "title": "Signatures for posts", "slug": "signatures-for-posts", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.576Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oscar_Cunningham", "createdAt": "2009-09-18T13:28:22.764Z", "isAdmin": false, "displayName": "Oscar_Cunningham"}, "userId": "G2SZuAiaBaNPg9rBt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SzSwn8qvW5Z5i2ad6/signatures-for-posts", "pageUrlRelative": "/posts/SzSwn8qvW5Z5i2ad6/signatures-for-posts", "linkUrl": "https://www.lesswrong.com/posts/SzSwn8qvW5Z5i2ad6/signatures-for-posts", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Signatures%20for%20posts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASignatures%20for%20posts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzSwn8qvW5Z5i2ad6%2Fsignatures-for-posts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Signatures%20for%20posts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzSwn8qvW5Z5i2ad6%2Fsignatures-for-posts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzSwn8qvW5Z5i2ad6%2Fsignatures-for-posts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 267, "htmlBody": "<p>Kaj_Sotala suggested <a href=\"/lw/6lm/community_norm_question_brief_text_ad_signatures/\">here</a> that some people may wish to add signatures to posts (i.e. top-level posts, not comments (hell no!)) to link to the author's homepage and such, and this idea was supported (<a href=\"/lw/6lm/community_norm_question_brief_text_ad_signatures/4hxk\">poll</a>). I <a href=\"/lw/6lm/community_norm_question_brief_text_ad_signatures/4hy1\">suggested</a> that we make such signatures into an official looking standard template, and this suggestion was upvoted. This post contains my design for such a template. The last time I learnt HTML was back in 2003 when I was about eleven, so this is probably bad code by modern standards, but I'm hoping that people will criticise until we have a version that looks good on all browsers.</p>\n<p>Code (Improved by Dreaded_Anomaly):</p>\n<blockquote>\n<p>&lt;div style=\"background:#f7f7f8; display:table;\"&gt; <br /> &lt;a href=\"/user/<strong>Your user name goes here</strong>/submitted/\"&gt;&lt;img style=\"float: left; margin: 5px;\" src=\"<strong>URL of the image goes here</strong>\" alt=\"<strong>Your name</strong>'s posts\" width=\"64\" height=\"64\" /&gt;&lt;/a&gt;<strong>Text goes here (links entered as usual) </strong><br /> &lt;/div&gt;</p>\n</blockquote>\n<p>Which produces a signature like the one at the bottom of this post. To use the code in the article editor press the HTML button and enter it at the bottom of the page. (Note that having your image be 64*64 to begin with will mean that it doesn't need to be scaled. Scaling sometimes makes images look weird or pixelly.)</p>\n<p>I suggest that everyone who uses such a signature writes about themselves in formally and in the third person. Think of an \"About the Author\" section on the dust-cover of a book. This will raise the status of the site by making it reminiscent of an edited publication.</p>\n<div style=\"background:#f7f7f8; display:table;\"><a href=\"/user/Oscar_Cunningham/submitted/\"><img style=\"float: left; margin: 5px;\" src=\"http://i157.photobucket.com/albums/t43/Macbi/LWAvatar-1.jpg\" alt=\"Oscar's posts\" width=\"64\" height=\"64\" /></a>Oscar Cunningham is a Mathematics student at <a href=\"http://www.trin.cam.ac.uk/\">Trinity College</a>, Cambridge (UK). Interests include probability, decision theory, and <a href=\"http://en.wikipedia.org/wiki/Ultimate_%28sport%29\">Ultimate</a>.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SzSwn8qvW5Z5i2ad6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 10, "extendedScore": null, "score": 7.396213125402785e-07, "legacy": true, "legacyId": "8557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Qe2adSZWdjqL4SrHg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T19:44:24.645Z", "modifiedAt": null, "url": null, "title": "Other Useful Sites LWers Read", "slug": "other-useful-sites-lwers-read", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.077Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a9EwEkSkz3wHqcitY/other-useful-sites-lwers-read", "pageUrlRelative": "/posts/a9EwEkSkz3wHqcitY/other-useful-sites-lwers-read", "linkUrl": "https://www.lesswrong.com/posts/a9EwEkSkz3wHqcitY/other-useful-sites-lwers-read", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Other%20Useful%20Sites%20LWers%20Read&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOther%20Useful%20Sites%20LWers%20Read%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9EwEkSkz3wHqcitY%2Fother-useful-sites-lwers-read%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Other%20Useful%20Sites%20LWers%20Read%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9EwEkSkz3wHqcitY%2Fother-useful-sites-lwers-read", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa9EwEkSkz3wHqcitY%2Fother-useful-sites-lwers-read", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>There seems to be a lot of knowledge that LessWrongers have which is fairly awesome, but not particularly well-covered on Less Wrong.</p>\n<p>What other sites do people recommend?</p>\n<p>I originally came to LW through HN, and Paul Graham was somewhat influential on my early high school thoughts.</p>\n<ul>\n<li><a href=\"http://news.ycombinator.com/\">http://news.ycombinator.com/</a></li>\n<li><a href=\"http://www.paulgraham.com/articles.html\">http://www.paulgraham.com/articles.html</a></li>\n</ul>\n<div>I also fairly regularly read</div>\n<div>\n<ul>\n<li><a href=\"http://www.ribbonfarm.com/\">http://www.ribbonfarm.com/</a></li>\n<li><a href=\"http://www.sebastianmarshall.com/\">http://www.sebastianmarshall.com/</a></li>\n</ul>\n</div>\n<p>I've poked through these a bit on recommendation from other people, and they seem ridiculously useful.</p>\n<ul>\n<li><a href=\"http://www.bulletproofexec.com/\">http://www.bulletproofexec.com/</a></li>\n<li><a href=\"http://quantifiedself.com/\">http://quantifiedself.com/</a></li>\n</ul>\n<div>There are a few blogs in the LW cluster, but I'm sure others read more of them than me.<br /><br />If you want to be super nice, could you link to some of your favorite posts/articles?</div>\n<div>\n<ul>\n</ul>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a9EwEkSkz3wHqcitY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 4e-05, "legacy": true, "legacyId": "8560", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T22:13:44.201Z", "modifiedAt": null, "url": null, "title": "Voluntary Behavior, Conscious Thoughts", "slug": "voluntary-behavior-conscious-thoughts-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LCjtqsQWapoSfDHqK/voluntary-behavior-conscious-thoughts-0", "pageUrlRelative": "/posts/LCjtqsQWapoSfDHqK/voluntary-behavior-conscious-thoughts-0", "linkUrl": "https://www.lesswrong.com/posts/LCjtqsQWapoSfDHqK/voluntary-behavior-conscious-thoughts-0", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Voluntary%20Behavior%2C%20Conscious%20Thoughts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVoluntary%20Behavior%2C%20Conscious%20Thoughts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLCjtqsQWapoSfDHqK%2Fvoluntary-behavior-conscious-thoughts-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Voluntary%20Behavior%2C%20Conscious%20Thoughts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLCjtqsQWapoSfDHqK%2Fvoluntary-behavior-conscious-thoughts-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLCjtqsQWapoSfDHqK%2Fvoluntary-behavior-conscious-thoughts-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1034, "htmlBody": "<p>Skinner proposes a surprisingly easy way to dissolve the problem of what it means for an action to be \"voluntary\", or \"under voluntary control\".<br /><br />We commonly perceive certain actions as under voluntary control: for example, I can control what words I'm typing right now, or whether I go out for dinner tonight. Other actions are not under voluntary control: for example, absent some exciting technique like biofeedback I can't control my heartbeat or my core body temperature or the amount of bile produced by my liver.<br /><br />Other, larger-scale actions also get classified as involuntary. Many people consider sleepwalking involuntary, including the bizarre \"sleep-eating\" behaviors some people display on Ambien and related drugs. The tics of Tourette's are involuntary. Our emotions and preferences are at least a little involuntary: office workers might like to be able to will away their boredom, or mourners their sorrow, but most can't.<br /><br />Here \"involuntary\" needs to be distinguished from \"hard-to-resist\". Most people do not define smoking as an involuntary behavior, because, although people may smoke even when they wish they wouldn't, <a href=\"/lw/rb/possibility_and_couldness/\">they have the feeling</a> that they <em>could</em> have chosen not to smoke, they just didn't.<br /><br />The philosophy of voluntary versus involuntary behavior seems to run up against a wall when it hits the question of \"what is truly me?\". If we make the reductionist identification of \"me\" with \"my brain\", well, clearly it's my brain controlling sleepwalking and boredom, but it still doesn't feel like <em>I</em> am controlling these things. Trying to go deeper ends up hopelessly vague, usually with talk of \"higher level brain processes\" versus \"lower level brain processes\" and an identification of \"myself\" with the higher ones. There may be a role for this kind of talk, but it couldn't hurt to look for something more explanatory.<br /><br />Skinner, true to <a href=\"/lw/6i5/behaviorism_beware_anthropomorphizing_humans/\">his quest</a>, explains the distinction without any discussion of \"brain processes\" or \"self\". He says that voluntary behavior is behavior subject to operant conditioning, and involuntary behavior is everything else.<br /><br />It might be clearer to define voluntary behavior as fully transparent to reinforcement. Imagine a man with a gun, threatening to shoot me if I go out for dinner tonight. The fear of punishment will be effective: I'll avoid going out. Lust for reward, too, would be effective. If Bill Gates offered me $1 billion to stay in, that's what I'd do.<br /><br />But when our masked gunman tells me to increase my body temperature by two degrees or he'll shoot, he is out of luck. And no matter how much money Bill Gates offers me for same, he can't make me give myself a fever either.</p>\n<p>There is a place, too, for the hard-to-resist behaviors in all this: these are behaviors which can be affected by reward, but as yet have not been. If a masked man held his gun to the head of smokers and told them to stop or he'd shoot, they would stop. But thus far, none of the potential rewards of not smoking have been sufficient to change smokers' behavior.<br /><br /><strong>CONSCIOUSNESS</strong><br /><br />The idea of voluntary behavior is tied so intimately to the idea of the self, or of consciousness (the easy problem, not <a href=\"http://en.wikipedia.org/wiki/Hard_problem_of_consciousness\">the hard one</a>), that one would hope that a new approach to one might be able to shed some light on the other. If voluntary action depends on transparency to reinforcement, where does that leave consciousness?<br /><br />I haven't been able to find Skinner's beliefs on this subject (when he talks about consciousness, it's usually to deny it as an ontologically fundamental entity) and I've never seen anywhere near as elegant a reduction. But an explanation in the spirit of reinforcement learning would have to start by insisting on treating thoughts and emotions as effects rather than causes. Instead of explaining my choice of restaurant by saying I thought about it and decided McDonalds was best, it would be more accurate to say that previous experiences with McDonalds caused both the thought \"I should go to McDonalds\" and the behavior of going to McDonalds.<br /><br />There is an intuitive connection between thought and language, and Soviet psychologist Lev Vygotsky made the connection more explicit; he found that children begin by speaking their stream of consciousness aloud to inform other people, and eventually learn to suppress that stream into nonvocal (subvocal?) thought.<br /><br />The last post in this sequence discussed differential reinforcement of thought and action. Speech and thought make a natural category as opposed to action; both are fast and easy, and so less likely to be affected by time and effort discounting. Both are point actions as opposed to a long project like learning Swahili or quitting smoking. And both bring reinforcement not through normal sensory channels (saying a word doesn't give pleasure in the same way smoking a cigarette might, nor pain in the same way having to study a boring grammar textbook might) but in what they say about you as a person and how they affect other people's real (and perceived) opinion of you.<br /><br />So even if there is no governor anywhere unifying all thoughts and words, they may come out in harmony because they were selected by the same processes for the same reasons. And actions may not end up so harmonious, because they suffer from differential reinforcement.<br /><br />Such harmony resembles the idea of a core \"me\", of whom all my thoughts are a part, and who has complete power over my organs of speech - but who is sometimes at odds with my actions or emotions.<br /><br />The reinforcement governing thought and speech is most likely to be internal reinforcement based on your own self-perception and on others' perception of you. If there's a good reason reputation management processes need to be different from decision-making processes, understanding that difference could help understand the evolutionary history of a perceived difference between the conscious and unconscious mind. One such reason is provided by Robert Trivers' theory of social consciousness, the subject of tomorrow's post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LCjtqsQWapoSfDHqK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3buXtNiSK8gcRLMSG", "EgDpZS4HHeh5vqJPe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-11T22:13:56.269Z", "modifiedAt": null, "url": null, "title": "Voluntary Behavior, Conscious Thoughts", "slug": "voluntary-behavior-conscious-thoughts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.965Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cTQRGJTQ2eGKm5G9g/voluntary-behavior-conscious-thoughts", "pageUrlRelative": "/posts/cTQRGJTQ2eGKm5G9g/voluntary-behavior-conscious-thoughts", "linkUrl": "https://www.lesswrong.com/posts/cTQRGJTQ2eGKm5G9g/voluntary-behavior-conscious-thoughts", "postedAtFormatted": "Monday, July 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Voluntary%20Behavior%2C%20Conscious%20Thoughts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVoluntary%20Behavior%2C%20Conscious%20Thoughts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcTQRGJTQ2eGKm5G9g%2Fvoluntary-behavior-conscious-thoughts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Voluntary%20Behavior%2C%20Conscious%20Thoughts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcTQRGJTQ2eGKm5G9g%2Fvoluntary-behavior-conscious-thoughts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcTQRGJTQ2eGKm5G9g%2Fvoluntary-behavior-conscious-thoughts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1034, "htmlBody": "<p>Skinner proposes a surprisingly easy way to dissolve the problem of what it means for an action to be \"voluntary\", or \"under voluntary control\".<br /><br />We commonly perceive certain actions as under voluntary control: for example, I can control what words I'm typing right now, or whether I go out for dinner tonight. Other actions are not under voluntary control: for example, absent some exciting technique like biofeedback I can't control my heartbeat or my core body temperature or the amount of bile produced by my liver.<br /><br />Other, larger-scale actions also get classified as involuntary. Many people consider sleepwalking involuntary, including the bizarre \"sleep-eating\" behaviors some people display on Ambien and related drugs. The tics of Tourette's are involuntary. Our emotions and preferences are at least a little involuntary: office workers might like to be able to will away their boredom, or mourners their sorrow, but most can't.<br /><br />Here \"involuntary\" needs to be distinguished from \"hard-to-resist\". Most people do not define smoking as an involuntary behavior, because, although people may smoke even when they wish they wouldn't, <a href=\"/lw/rb/possibility_and_couldness/\">they have the feeling</a> that they <em>could</em> have chosen not to smoke, they just didn't.<br /><br />The philosophy of voluntary versus involuntary behavior seems to run up against a wall when it hits the question of \"what is truly me?\". If we make the reductionist identification of \"me\" with \"my brain\", well, clearly it's my brain controlling sleepwalking and boredom, but it still doesn't feel like <em>I</em> am controlling these things. Trying to go deeper ends up hopelessly vague, usually with talk of \"higher level brain processes\" versus \"lower level brain processes\" and an identification of \"myself\" with the higher ones. There may be a role for this kind of talk, but it couldn't hurt to look for something more explanatory.<br /><br />Skinner, true to <a href=\"/lw/6i5/behaviorism_beware_anthropomorphizing_humans/\">his quest</a>, explains the distinction without any discussion of \"brain processes\" or \"self\". He says that voluntary behavior is behavior subject to operant conditioning, and involuntary behavior is everything else.<br /><br />It might be clearer to define voluntary behavior as fully transparent to reinforcement. Imagine a man with a gun, threatening to shoot me if I go out for dinner tonight. The fear of punishment will be effective: I'll avoid going out. Lust for reward, too, would be effective. If Bill Gates offered me $1 billion to stay in, that's what I'd do.<br /><br />But when our masked gunman tells me to increase my body temperature by two degrees or he'll shoot, he is out of luck. And no matter how much money Bill Gates offers me for same, he can't make me give myself a fever either.</p>\n<p>There is a place, too, for the hard-to-resist behaviors in all this: these are behaviors which can be affected by reward, but as yet have not been. If a masked man held his gun to the head of smokers and told them to stop or he'd shoot, they would stop. But thus far, none of the potential rewards of not smoking have been sufficient to change smokers' behavior.<br /><br /><strong>CONSCIOUSNESS</strong><br /><br />The idea of voluntary behavior is tied so intimately to the idea of the self, or of consciousness (the easy problem, not <a href=\"http://en.wikipedia.org/wiki/Hard_problem_of_consciousness\">the hard one</a>), that one would hope that a new approach to one might be able to shed some light on the other. If voluntary action depends on transparency to reinforcement, where does that leave consciousness?<br /><br />I haven't been able to find Skinner's beliefs on this subject (when he talks about consciousness, it's usually to deny it as an ontologically fundamental entity) and I've never seen anywhere near as elegant a reduction. But an explanation in the spirit of reinforcement learning would have to start by insisting on treating thoughts and emotions as effects rather than causes. Instead of explaining my choice of restaurant by saying I thought about it and decided McDonalds was best, it would be more accurate to say that previous experiences with McDonalds caused both the thought \"I should go to McDonalds\" and the behavior of going to McDonalds.<br /><br />There is an intuitive connection between thought and language, and Soviet psychologist Lev Vygotsky made the connection more explicit; he found that children begin by speaking their stream of consciousness aloud to inform other people, and eventually learn to suppress that stream into nonvocal (subvocal?) thought.<br /><br />The last post in this sequence discussed different reinforcement of thought and action. Speech and thought make a natural category as opposed to action; both are fast and easy, and so less likely to be affected by time and effort discounting. Both are point actions as opposed to a long project like learning Swahili or quitting smoking. And both bring reinforcement not through normal sensory channels (saying a word doesn't give pleasure in the same way smoking a cigarette might, nor pain in the same way having to study a boring grammar textbook might) but in what they say about you as a person and how they affect other people's real (and perceived) opinion of you.<br /><br />So even if there is no governor anywhere unifying all thoughts and words, they may come out in harmony because they were selected by the same processes for the same reasons. And actions may not end up so harmonious, because they suffer from differential reinforcement.<br /><br />Such harmony resembles the idea of a core \"me\", of whom all my thoughts are a part, and who has complete power over my organs of speech - but who is sometimes at odds with my actions or emotions.<br /><br />The reinforcement governing thought and speech is most likely to be internal reinforcement based on your own self-perception and on others' perception of you. If there's a good reason reputation management processes need to be different from decision-making processes, understanding that difference could help understand the evolutionary history of a perceived difference between the conscious and unconscious mind. One such reason is provided by Robert Trivers' theory of social consciousness, the subject of tomorrow's post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 2, "XSryTypw5Hszpa4TS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cTQRGJTQ2eGKm5G9g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 44, "extendedScore": null, "score": 9.5e-05, "legacy": true, "legacyId": "8563", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3buXtNiSK8gcRLMSG", "EgDpZS4HHeh5vqJPe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T05:28:32.675Z", "modifiedAt": null, "url": null, "title": "Should Rationalists Tip at Restaurants?", "slug": "should-rationalists-tip-at-restaurants", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.231Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d5doibRRBrpfgbKRL/should-rationalists-tip-at-restaurants", "pageUrlRelative": "/posts/d5doibRRBrpfgbKRL/should-rationalists-tip-at-restaurants", "linkUrl": "https://www.lesswrong.com/posts/d5doibRRBrpfgbKRL/should-rationalists-tip-at-restaurants", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Should%20Rationalists%20Tip%20at%20Restaurants%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShould%20Rationalists%20Tip%20at%20Restaurants%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5doibRRBrpfgbKRL%2Fshould-rationalists-tip-at-restaurants%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Should%20Rationalists%20Tip%20at%20Restaurants%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5doibRRBrpfgbKRL%2Fshould-rationalists-tip-at-restaurants", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd5doibRRBrpfgbKRL%2Fshould-rationalists-tip-at-restaurants", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 918, "htmlBody": "<p>Related to: <a href=\"http://www.overcomingbias.com/2011/07/myfreakonagain.html\">Robin Hanson on Freakonomics</a></p>\n<p>DISCLAIMER: This is an exploration of a theoretical economics problem. This is not advice. I have not made up my mind. Please do not cite this post as support for your plans to indulge in mayhem or selfishness.</p>\n<p><a id=\"more\"></a></p>\n<p>Suppose you want to lead a life that, compared to the average resident of an industrialized country, is relatively altruistic. Say you value your own comfort and pleasure at roughly 10<sup>4&nbsp;</sup>&times;&nbsp;the comfort and pleasure of a stranger who currently lives across the world from you. You are likewise relatively patient, risk-neutral, and scope-sensitive compared to your peers; if you believe that there is a 10<sup>-3</sup> chance that 10<sup>9</sup> people will die in a specific kind of catastrophe that would occur in the year 2031, then you would factor that into your plans at a discount of only two orders of magnitude. In other words, you would be indifferent between (a) the risk of the future catastrophe and (b) the certainty of 10<sup>4</sup> people dying today. Moreover, you are reasonably well-calibrated; if you say something will happen with 95% certainty, it actually does happen about 90 out of 100 times. Finally, suppose you have an IQ of roughly 130, and no crippling physical or mental disabilities. My numbers are meant to sketch a crude portrait of one plausible kind of amateur rationalist; if you don't like the numbers, please mentally substitute your own and move on, because the exact numbers aren't my point.</p>\n<p>My point is this: does it make sense to follow social norms like tipping, waiting in line, making small talk with strangers, and paying taxes when you're reasonably sure that nobody who's important to you is watching? Although such norms are cheap to follow in terms of individual situations, they recur frequently -- if you make a habit of skewing your time toward bars and clubs that take cash under the table, you'll put a serious dent in your entertainment budget. Repeat this across several different areas of your life, and you're looking at significant resources. As an amateur rationalist, with the time and money you save by cheating on 'responsible' habits, you should in theory be able to get slightly more work done and/or donate slightly more money to efficient charities. You might even be able to invest the time and money into bootstrapping your own economic productivity, allowing you to accelerate your donation timetable by a few hundred $/yr<sup>2&nbsp;</sup>, and thereby, over the course of your life, save another hundred lives or so. Assuming you never get caught, isn't that worth the mild inconvenience you cause to several thousand strangers? Assuming you do occasionally get caught, does that really tip the balance back toward following the rules? Remember that you're well-calibrated, so while you do make mistakes, you should in theory be able to identify situations where you are extremely unlikely to get caught, cheat in all such situations, and then only get caught on extremely rare occasions.&nbsp;</p>\n<p>It certainly *feels* good to tell stories about how social niceties pay off. Following these kinds of rules and making arguments that we should follow them both signal a certain kind of pro-social, well-adjusted, trustworthy, successful attitude. Plus, it would be nice if everybody got what they deserved; i.e., if not tipping actually led to something like bad karma. Even without mystical influence, not tipping might lead to individual punishments if, e.g., it's impossible not to feel guilty about it, or it subtly alters your personality for the worse, or if people inevitably catch you when you least expect it and then impose costs on you that are worth more than the cumulative money you saved on that occasion plus the money you saved on all the other occasions when you weren't caught.</p>\n<p>Those kind of mechanisms seem unlikely to me, though. Because of wishful thinking, though, I would imagine that we tend to overestimate the chance that something like karmic balance actually obtains. What do you think?</p>\n<p>EDIT: Please try to cope with <a href=\"/lw/2k/the_least_convenient_possible_world/\">The Least Convenient Possible World</a> when imagining examples, rather than simply picking average examples that suggest, e.g., that you will certainly be caught, as this is contrary to the spirit of the exercise. E.g., for tipping, imagine dining alone at a chain restaurant with high turnover while traveling through a town you rarely visit. For avoiding small talk, imagine you are on a light rail in the exurbs with your laptop, typing up some notes, a full twelve minutes from the nearest likely source of enough extra passengers to disturb your personal space, alone in a car with a nice old man who wants to talk to you, apparently ad infinitum, about the 1954 Brooklyn Dodgers' infield. If you don't want to eat at restaurants, that's fine -- pick some other relevant pleasure or luxury that an amateur rationalist might indulge in. If you own a car, should you ever refuse to let someone in who's waiting to merge, assuming that maintaining your current speed in your current lane is unlikely to increase your risk of an accident? If you rent or own a house in the western United States, should you ever use scarce water to irrigate your flowers, given that your neighbors are not environmentally conscious enough to notice whether you are using ecologically thrifty plants? Etc. An interesting counter-argument is \"it takes too much mental energy to identify occasions when I won't be caught.\" A boring counter-argument is \"I'll surely be caught.\" The latter violates an explicit assumption of the problem.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d5doibRRBrpfgbKRL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 10, "extendedScore": null, "score": 2.5e-05, "legacy": true, "legacyId": "8570", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["neQ7eXuaXpiYw7SBy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T06:29:42.779Z", "modifiedAt": null, "url": null, "title": "Having Useful Conversations", "slug": "having-useful-conversations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:33.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CCriujRF39gWF5xAw/having-useful-conversations", "pageUrlRelative": "/posts/CCriujRF39gWF5xAw/having-useful-conversations", "linkUrl": "https://www.lesswrong.com/posts/CCriujRF39gWF5xAw/having-useful-conversations", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Having%20Useful%20Conversations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHaving%20Useful%20Conversations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCriujRF39gWF5xAw%2Fhaving-useful-conversations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Having%20Useful%20Conversations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCriujRF39gWF5xAw%2Fhaving-useful-conversations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCCriujRF39gWF5xAw%2Fhaving-useful-conversations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 414, "htmlBody": "<p>Holding conversations in person is useful; feedback is quick, and it seems to be much easier to change your behavior as a result of actually talking with people.&nbsp;</p>\n<p>Having effective goal-oriented conversations is somewhat difficult. One source of difficulty is a strong tendency to stray from useful talk into entertaining talk. A typical example is the tendency of many (otherwise potentially productive) conversations between rationalists simply wandering into an extended dialog about the nature of existential risk or some interesting philosophical problem, and then stagnating there (potentially treading interesting new intelligence-demonstrating terrain, but not in point of fact getting anything done or refining beliefs in a meaningful way).</p>\n<p>If this is what all participants want out of the conversation, then it's great that we've found a community where people can get their kicks in this particular abstruse way. If this is what some but not all participants want out of the conversation, then perhaps the conversation should divide or conclude. But conversations seem to get derailed--either for significant lengths of time, or indefinitely--even when participants honestly want to get things done, and view conversations with other rationalists as instruments to serve their values.&nbsp;</p>\n<p>In the interest of getting things done, I (and Nick Tarleton and Michael Curzi, with the tiniest bit of testing) suggest that the rationalist community try really hard to adopt the following norm: when someone else is talking, and the conversation would be significantly better served by them stopping, let them know. Either point out that the topic is nice to think about but unhelpful, that the topic should be considered later rather now, or whatever else the speaker seems to have failed to notice.&nbsp;To help make adoption a little easier, it might be help to choose one person in advance who will have some responsibility to arbitrate.&nbsp;</p>\n<p>If a participant disagrees about the relevance of a remark, don't push it--our hope is that such a system could help people who have honestly wandered from the topic pursuing an interesting tangent or happy thought, not to resolve any actual dispute. If a participant doesn't want to adhere closely to any particular notion of usefulness--for example, if someone is having a conversation to simply enjoy themselves and unwind--then the conversing parties should resolve their misunderstanding, or if not possible simply stop talking to each other and save some time.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Have any LWers considered other lightweight measures to hold more useful conversations? There seems to be low-hanging fruit here, and there seems to be a lot to gain.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZXFpyQWPB5ideFbEG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CCriujRF39gWF5xAw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 24, "extendedScore": null, "score": 7.39838256050662e-07, "legacy": true, "legacyId": "8572", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T06:35:42.848Z", "modifiedAt": null, "url": null, "title": "Discussion: Ideas for a Lesswrongian anticipation Sci-Fi set in 2060", "slug": "discussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.386Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TcjmL2RoSwXEMzzxP/discussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "pageUrlRelative": "/posts/TcjmL2RoSwXEMzzxP/discussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "linkUrl": "https://www.lesswrong.com/posts/TcjmL2RoSwXEMzzxP/discussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Discussion%3A%20Ideas%20for%20a%20Lesswrongian%20anticipation%20Sci-Fi%20set%20in%202060&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADiscussion%3A%20Ideas%20for%20a%20Lesswrongian%20anticipation%20Sci-Fi%20set%20in%202060%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcjmL2RoSwXEMzzxP%2Fdiscussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Discussion%3A%20Ideas%20for%20a%20Lesswrongian%20anticipation%20Sci-Fi%20set%20in%202060%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcjmL2RoSwXEMzzxP%2Fdiscussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTcjmL2RoSwXEMzzxP%2Fdiscussion-ideas-for-a-lesswrongian-anticipation-sci-fi-set", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 358, "htmlBody": "<p>So, the usual bet is that the GAI, both F and UF will be created at around that time at the latest. I'd like to set a novel, a thriller, right at that critical moment where everything could be lost or won, and humanity is in the balance. But human societies and the way they interact with each other will have changed a lot by then. So, well, I haven't read throughly enough here to understand how far we are anticipating what will happen. Not just the friendliness of AI development, but our own impact in the world, and how it will react when it finds out about us and our goals, <em>and takes them seriously</em>.</p>\n<p>So I was wondering if you'd help me out here with some brainstorming. I'm looking for some seminal ideas for how the world will look like by then. We don't need to be 100% precise, although keeping the pieces of the setting vague by avoiding Burdensome Details is a way of avoiding glaring mistakes, and gives a Lord Of The Rings, Ruins In The Distance feel of false depth. Don't hesitate to suggest seemingly weird but actually reasonable ideas: the future I want to build is a Weirdtopia. The point is to frighten, wonder, and suck the reader in.</p>\n<p>Let's see, for a start: cryogenics and cybernetics are a solved problem, and people's heads are being resurrected and put on mechanical bodies by default (they <em>could</em> ask for recreated biological bodies, but usually after the first tantrums... they don't ^_^). The audience can be given someone to identify with through a Temporal Fish Out Of Water, one of the resurrected Human Popsicles. The <em>funny</em> part is that, even though that person happens to be a transhumanist AND a singularitarian, they hadn't surpassed the Shock Level (I think that's what Yudkowsky called it when you were enthused with an idea because you don't think of it as normal yet?), and they are only marginally less freaked out by the world they find themselves into than the normal sci-fi fan readers (or even the mainstream ones, if this ends up so good as to have any).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TcjmL2RoSwXEMzzxP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 7.39840255249586e-07, "legacy": true, "legacyId": "8573", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T07:26:47.501Z", "modifiedAt": null, "url": null, "title": "Desperate help required", "slug": "desperate-help-required", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:48.820Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XpY5oSpXjGawWoNH3/desperate-help-required", "pageUrlRelative": "/posts/XpY5oSpXjGawWoNH3/desperate-help-required", "linkUrl": "https://www.lesswrong.com/posts/XpY5oSpXjGawWoNH3/desperate-help-required", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Desperate%20help%20required&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADesperate%20help%20required%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpY5oSpXjGawWoNH3%2Fdesperate-help-required%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Desperate%20help%20required%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpY5oSpXjGawWoNH3%2Fdesperate-help-required", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpY5oSpXjGawWoNH3%2Fdesperate-help-required", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 35, "htmlBody": "<p>I'll cut to the chase:</p>\n<p>&nbsp;</p>\n<p>Running a Less Wrong-like self development group tonight and have failed to prepare anything insofar. starts in 2 hours.</p>\n<p>&nbsp;</p>\n<p>Any games that I could pull out that will interaction and critical thinking?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XpY5oSpXjGawWoNH3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 0, "extendedScore": null, "score": 7.398559994176839e-07, "legacy": true, "legacyId": "8577", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T16:12:06.743Z", "modifiedAt": null, "url": null, "title": "Defaulting to not noticing the meetup list", "slug": "defaulting-to-not-noticing-the-meetup-list", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.969Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kh4SeisRYjXf74pZf/defaulting-to-not-noticing-the-meetup-list", "pageUrlRelative": "/posts/kh4SeisRYjXf74pZf/defaulting-to-not-noticing-the-meetup-list", "linkUrl": "https://www.lesswrong.com/posts/kh4SeisRYjXf74pZf/defaulting-to-not-noticing-the-meetup-list", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Defaulting%20to%20not%20noticing%20the%20meetup%20list&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADefaulting%20to%20not%20noticing%20the%20meetup%20list%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkh4SeisRYjXf74pZf%2Fdefaulting-to-not-noticing-the-meetup-list%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Defaulting%20to%20not%20noticing%20the%20meetup%20list%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkh4SeisRYjXf74pZf%2Fdefaulting-to-not-noticing-the-meetup-list", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkh4SeisRYjXf74pZf%2Fdefaulting-to-not-noticing-the-meetup-list", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p>I just registered that I'm not looking at the meetup list to see whether there's anything in my area-- the letters are too small and faint.</p>\n<p>Are other people skimming past the meetup list, too?</p>\n<p>If it's a general problem, I recommend bolding the city names.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kh4SeisRYjXf74pZf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.400179592042354e-07, "legacy": true, "legacyId": "8581", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T16:32:12.547Z", "modifiedAt": null, "url": null, "title": "ALCOR finances", "slug": "alcor-finances", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:39.528Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iPK8AezgksW8N7N5Z/alcor-finances", "pageUrlRelative": "/posts/iPK8AezgksW8N7N5Z/alcor-finances", "linkUrl": "https://www.lesswrong.com/posts/iPK8AezgksW8N7N5Z/alcor-finances", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20ALCOR%20finances&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AALCOR%20finances%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiPK8AezgksW8N7N5Z%2Falcor-finances%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=ALCOR%20finances%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiPK8AezgksW8N7N5Z%2Falcor-finances", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiPK8AezgksW8N7N5Z%2Falcor-finances", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<p>Mike Darwin has posted some financial history of Alcor in a post, <a href=\"http://chronopause.com/index.php/2011/07/11/the-armories-of-the-latter-day-laputas-part-5/\">\"The Armories of the Latter Day Laputas, Part 5\"</a>. While there were some errors (see <a href=\"http://chronopause.com/index.php/2011/07/11/the-armories-of-the-latter-day-laputas-part-5/#comments\">the comments</a>), Darwin has apparently corrected them.</p>\n<p>It makes interesting reading in general. It's not a straight analysis of filings like Brandon's <a href=\"/lw/5il/siai_an_examination/\">\"SIAI - An Examination\"</a>, but more of a financial history (eg. the <a href=\"http://i293.photobucket.com/albums/mm55/mikedarwin1967/alcorgraph2.jpg\">graph of revenues vs expenses</a> etc.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iPK8AezgksW8N7N5Z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 7.400241563997207e-07, "legacy": true, "legacyId": "8582", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qqhdj3W3vSfB5E9ss"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T18:13:20.354Z", "modifiedAt": null, "url": null, "title": "Should rationalists put much thought into tipping and/or voting?", "slug": "should-rationalists-put-much-thought-into-tipping-and-or", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.078Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NzMeT2y4qH6MDyNuT/should-rationalists-put-much-thought-into-tipping-and-or", "pageUrlRelative": "/posts/NzMeT2y4qH6MDyNuT/should-rationalists-put-much-thought-into-tipping-and-or", "linkUrl": "https://www.lesswrong.com/posts/NzMeT2y4qH6MDyNuT/should-rationalists-put-much-thought-into-tipping-and-or", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Should%20rationalists%20put%20much%20thought%20into%20tipping%20and%2For%20voting%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShould%20rationalists%20put%20much%20thought%20into%20tipping%20and%2For%20voting%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzMeT2y4qH6MDyNuT%2Fshould-rationalists-put-much-thought-into-tipping-and-or%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Should%20rationalists%20put%20much%20thought%20into%20tipping%20and%2For%20voting%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzMeT2y4qH6MDyNuT%2Fshould-rationalists-put-much-thought-into-tipping-and-or", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzMeT2y4qH6MDyNuT%2Fshould-rationalists-put-much-thought-into-tipping-and-or", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<p>It seems to me that tipping involves rather little money, and voting involves rather little time. For the latter, I'm assuming that you follow politics enough anyway that you have at least one candidate you prefer.</p>\n<p>I'm willing to bet that there are people who spend more time in a year on whether voting is rational than they would if they just went and voted and ignored the arguments.</p>\n<p>What are the biggest wins you've gotten in terms of time and/or money from thinking about what you're doing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NzMeT2y4qH6MDyNuT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 7.400553431310455e-07, "legacy": true, "legacyId": "8583", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T18:15:36.579Z", "modifiedAt": null, "url": null, "title": "Call for volunteers: clean up the LW issue tracker", "slug": "call-for-volunteers-clean-up-the-lw-issue-tracker", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.840Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zBeTdyJ5dus9Z3ZxS/call-for-volunteers-clean-up-the-lw-issue-tracker", "pageUrlRelative": "/posts/zBeTdyJ5dus9Z3ZxS/call-for-volunteers-clean-up-the-lw-issue-tracker", "linkUrl": "https://www.lesswrong.com/posts/zBeTdyJ5dus9Z3ZxS/call-for-volunteers-clean-up-the-lw-issue-tracker", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Call%20for%20volunteers%3A%20clean%20up%20the%20LW%20issue%20tracker&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACall%20for%20volunteers%3A%20clean%20up%20the%20LW%20issue%20tracker%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzBeTdyJ5dus9Z3ZxS%2Fcall-for-volunteers-clean-up-the-lw-issue-tracker%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Call%20for%20volunteers%3A%20clean%20up%20the%20LW%20issue%20tracker%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzBeTdyJ5dus9Z3ZxS%2Fcall-for-volunteers-clean-up-the-lw-issue-tracker", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzBeTdyJ5dus9Z3ZxS%2Fcall-for-volunteers-clean-up-the-lw-issue-tracker", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<p>I'm looking for a volunteer (or volunteers).</p>\n<p>We've let&nbsp;<a href=\"http://code.google.com/p/lesswrong/issues/list\">the Lesswrong issue tracker</a>&nbsp;get out of hand - there are 99 open issues on it, and I think that many of them are resolved by changes since they were opened, are less than awesome ideas, or, for the remainder, are valid ideas.</p>\n<p>I'd love someone to volunteer to go through all of the open issues, close those that are complete or silly, and tag/prioritise those that remain. I'll need to give you the power to do that, so please nominate yourself in the comments.</p>\n<p>Once the list is cleaned up, I think Trike can keep it organised.</p>\n<p>&nbsp;</p>\n<p>ETA:&nbsp;<span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px; background-color: #f7f7f8;\"><strong><span class=\"author\"><a id=\"author_t4_5c4\" style=\"color: #3d3d3e; text-decoration: underline;\" href=\"/user/Nic_Smith/\">Nic_Smith</a>&nbsp;</span></strong></span>seems to have this well in hand - serious kudos, Nic. Thank you.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zBeTdyJ5dus9Z3ZxS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.400560433038488e-07, "legacy": true, "legacyId": "8584", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T18:16:49.605Z", "modifiedAt": null, "url": null, "title": "Diet Advice?", "slug": "diet-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:30.049Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YMvQRmH69uQTSRyK6/diet-advice", "pageUrlRelative": "/posts/YMvQRmH69uQTSRyK6/diet-advice", "linkUrl": "https://www.lesswrong.com/posts/YMvQRmH69uQTSRyK6/diet-advice", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Diet%20Advice%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADiet%20Advice%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMvQRmH69uQTSRyK6%2Fdiet-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Diet%20Advice%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMvQRmH69uQTSRyK6%2Fdiet-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYMvQRmH69uQTSRyK6%2Fdiet-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 841, "htmlBody": "<p>So, I know a number of friends on Paleo who recommend it. I recently read through a lot of <a href=\"http://www.bulletproofexec.com\">bulletproofexec</a>, who recommends his own variant of paleo. I care about my health, and so I need to resolve my diet and their advice somehow. Summarized data points:</p>\n<ol>\n<li>My diet is about 80% wheat, and the rest is sweet potatoes, exotic grains (like amaranth or quinoa), rice, margarine, honey, cheese, and meat. The primary principle of paleo is that Grains Are Bad, and accepting that premise would require a <em>radical</em> restructuring of my diet. Right now I bake a loaf or two of (sourdough) bread a day, eat pasta about every other day, eat at least some raw sweet potato a day, eat cereal every other day, boil quinoa and rice every now and then, and eat meat only when I go out with friends.</li>\n<li>I strongly prefer wheat to rice, and rice to corn (also, white wheat to whole wheat). I enjoy the bread I bake enough to eat until I physically can't store more food in my stomach. When I bake bread with 75% wheat and 25% amaranth, it tastes noticeably worse (which I can tell because I eat what I cut and don't try to eat it all).</li>\n<li>I am rarely sick (maybe something on the level of a sore throat once a year), and I've been intelligent and lively my entire life, and have been on a meat-heavier version of this diet (less bread, more pasta, more chicken) until recently.</li>\n<li>To the best of my knowledge, I do not experience meat cravings. I chewed ice growing up (which suggests an iron deficiency), but this habit mostly stopped a few years ago. I have craved fat once or twice in the last year, which I responded to by whipping up and eating a batch of cookie dough. Most of my friends on paleo experience bread/grain cravings about once a week, though my friend on a slow carb diet (which allows him to eat bread once a week) doesn't.</li>\n<li>I'm 6'0\" tall and weigh 160 lbs (182 cm / 73 kg) for a BMI of 21.7, which is the exact middle of the \"normal\" range. I have a sedentary lifestyle with no regular exercise besides walking (which has been reduced to about once a week thanks to summer), and thus am not as muscular as I would like. I used to weigh about 180 lbs, and a change in diet (from eating out frequently to eating in frequently, the replacement of meat with bread, and a general reduction in portion size) dropped that down to 160 lbs with no exercise. A brief experiment with creatine supplementation and high-intensity exercise ended well, and so I plan to resume that soon.</li>\n<li>I have a poor sense of smell and thus am not good at telling foods apart; I have a preference for simpler foods and can't tell a difference between chicken and steak. I'm also pretty xenophobic when it comes to food, but have gotten better at experimenting with new tastes.</li>\n<li>I get warm fuzzies from eating little meat (for resource conservation reasons) and from eating cheaply (my grocery bills come out to about $3 a day and I eat out 1-2 times a month), but I imagine those would be outweighed by small health / intelligence boosts. </li>\n<li>My lactase production disappeared about age 20, but I respond well to lactase pills.</li>\n<li>Bulletproofexec and one of my friends on paleo both have wheat allergies.</li>\n</ol>\n<p>I find the logic behind paleo questionable. Yes, hunter-gatherers are adapted to a different diet, but fire was first used to cook food 2 million years ago, and appears widespread by 100 kiloyears (ky) ago, with noticeable adaptations in humans (from smaller teeth to resistance to air pollution). Lactose tolerance demonstrates the ability of human biology to adapt to new diets. Civilization dramatically speeds up evolution- it probably took about 25ky for European hunter-gatherers (and later farmers) to go from a mean IQ of 85 to 100, and about 1ky for urban European Jews to go from a mean IQ of 100 to 115. Am I really supposed to believe that there aren't genes floating around that wheat (domesticated 10ky ago) is good for?</p>\n<p>My interpretation of this data is that my current diet works well for me, and paleo is unlikely to work better. I am willing to experiment, though- if I will actually live better on a different diet, there is little holding me back besides a lack of information. My values, in descending order of importance, are: brain function, overall health, appearance, mood, and cost. (Note that those are weights- something can improve brain function but be so costly in dollars, prep time, and terrible taste that I'm not interested.)</p>\n<p>So my question for you is: Should I try paleo (more likely, the <a href=\"http://www.bulletproofexec.com/the-complete-illustrated-one-page-bulletproof-diet/\">bulletproof diet</a>)? If I do, what data should I collect? Better yet, what data can I collect now to determine if I have any nutritional deficiencies?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YMvQRmH69uQTSRyK6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "8585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T20:48:19.884Z", "modifiedAt": null, "url": null, "title": "Follow-up on ESP study: \"We don't publish replications\"", "slug": "follow-up-on-esp-study-we-don-t-publish-replications", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:51.367Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b9vvmMn2kF76aThHn/follow-up-on-esp-study-we-don-t-publish-replications", "pageUrlRelative": "/posts/b9vvmMn2kF76aThHn/follow-up-on-esp-study-we-don-t-publish-replications", "linkUrl": "https://www.lesswrong.com/posts/b9vvmMn2kF76aThHn/follow-up-on-esp-study-we-don-t-publish-replications", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Follow-up%20on%20ESP%20study%3A%20%22We%20don't%20publish%20replications%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFollow-up%20on%20ESP%20study%3A%20%22We%20don't%20publish%20replications%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9vvmMn2kF76aThHn%2Ffollow-up-on-esp-study-we-don-t-publish-replications%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Follow-up%20on%20ESP%20study%3A%20%22We%20don't%20publish%20replications%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9vvmMn2kF76aThHn%2Ffollow-up-on-esp-study-we-don-t-publish-replications", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9vvmMn2kF76aThHn%2Ffollow-up-on-esp-study-we-don-t-publish-replications", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 556, "htmlBody": "<p>Related to: <a href=\"/lw/1ib/parapsychology_the_control_group_for_science/\">Parapsychology: the control group for science</a>, <a href=\"/lw/2y3/dealing_with_the_high_quantity_of_scientific/\">Dealing with the high quantity of scientific error in medicine</a></p>\n<p>Some of you may remember past Less Wrong <a href=\"/lw/35a/new_comments_on_the_recent_psi_study/\">discussion</a>&nbsp;of the Daryl Bem <a href=\"http://hplusmagazine.com/2010/11/04/precognition-real-cornell-university-lab-releases-powerful-new-evidence-human-mind-can/\">study</a>, which claimed to show precognition, and was published with much controversy in a top psychology journal, JPSP. The editors and reviewers explained their decision by saying that the paper was clearly written and used standard experimental and statistical methods so that their disbelief in it (driven by physics, the failure to show psi in the past, etc) was not appropriate grounds for rejection.&nbsp;</p>\n<p>Because of all the attention received by the paper (unlike similar claims published in parapsychology journals) it elicited a fair amount of both critical review and attempted replication. Critics pointed out that the hypotheses were selected and switched around 'on the fly' during Bem's experiments, with the effect sizes declining with sample size (a strong signal of data mining). More importantly, Richard Wiseman&nbsp;established a&nbsp;<a href=\"http://www.richardwiseman.com/BemReplications.shtml\">registry</a>&nbsp;for advance announcement of new Bem replication attempts.</p>\n<p><span>A replication registry guards against publication bias, and at least 5 attempts were registered. As far as I can tell, at the time of this post the subsequent replications have, unsurprisingly, failed to replicate Bem's results.<sup>1</sup>&nbsp;However,&nbsp;</span>JPSP<span>&nbsp;and the other high-end psychology journals <a href=\"http://psychsciencenotes.blogspot.com/2011/05/failing-to-replicate-bems-ability-to.html\">refused to publish the results</a>, citing standing policies of not publishing straight replications.</span></p>\n<p><span>From the journals' point of view, this (common) policy makes sense: bold new claims will tend to be cited more and raise journal status (which depends on citations per article), even though this means most of the 'discoveries' they publish will be false&nbsp;despite their p-values. However, this means that overall the journals are giving career incentives for scientists to massage and mine their data for bogus results, but not to challenge bogus results by others.</span>&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/\">Alas</a><span>.</span></p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><sup>1&nbsp;</sup>A purported&nbsp;&nbsp;\"<a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1715954\">successful replication</a>\"&nbsp;by a pro-psi researcher in Vienna turns out to be nothing of the kind. Rather, it is a study conducted in 2006 and retitled to take advantage of the attention on Bem's article, selectively pulled from the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Publication_bias#The_file_drawer_effect\">file drawer</a>.</p>\n<p>ETA: The wikipedia article on Daryl Bem makes an unsourced claim that one of the registered studies has replicated Bem.</p>\n<p>ETA2: Samuel Moulton, who formerly worked with Bem, <a href=\"http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cts=1330759616582&amp;ved=0CDgQtwIwAw&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D0Tdiu5kwjKs&amp;ei=zsdRT7OBDceXhQeurO3zCw&amp;usg=AFQjCNGCOFzdUDSheqBJI_oME7BA1_4U9Q\">mentions</a> an unpublished (no further details) failed replication of Bem's results conducted before Bem submitted his article (the failed replication was not mentioned in the article).</p>\n<p>ETA3: There is mention of a variety of attempted replications at this blog <a href=\"http://neshealthblog.wordpress.com/2012/01/16/precognition-feeling-the-future/\">post</a>, with 6 failed replications, and 1 successful replication from a pro-psi researcher (not available online). It is based on this ($) New Scientist <a href=\"http://www.newscientist.com/article/mg21328471.800-esp-evidence-airs-sciences-dirty-laundry.html\">article</a>.</p>\n<p>ETA4: This large <a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2001721\">study</a> performs an almost straight replication of Bem (same methods, same statistical tests, etc) and finds the effect vanishes.</p>\n<p>ETA5: Apparently, the mentioned replication was <a href=\"http://newsworlddigest.com/precognition-studies-and-the-curse-of-the-failed-replications-professor/\">again</a> submitted to the British Journal of Psychology:</p>\n<blockquote>\n<p><span style=\"color: #222222; font-family: Verdana, Geneva, sans-serif; font-size: 12px; line-height: 16px;\">When we submitted it to the&nbsp;</span><a style=\"background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border-image: initial; vertical-align: baseline; text-decoration: none; color: #ffa200; font-family: Verdana, Geneva, sans-serif; font-size: 12px; line-height: 16px; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://onlinelibrary.wiley.com/journal/10.1111/%28ISSN%292044-8295\">British Journal of Psychology</a><span style=\"color: #222222; font-family: Verdana, Geneva, sans-serif; font-size: 12px; line-height: 16px;\">, it was finally sent for peer review. One referee was very positive about it but the second had reservations and the editor rejected the paper. We were pretty sure that the second referee was, in fact, none other than Daryl Bem himself, a suspicion that the good professor kindly confirmed for us. It struck us that he might possibly have a conflict of interest with respect to our submission. Furthermore, we did not agree with the criticisms and suggested that a third referee be brought in to adjudicate. The editor rejected our appeal.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vg4LDxjdwHLotCm8w": 5, "ZpG9rheyAkgCoEQea": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b9vvmMn2kF76aThHn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 111, "extendedScore": null, "score": 0.000222, "legacy": true, "legacyId": "8558", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 111, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["enuGsZoFLR4KyEx3n", "PnYh6hZsFPRB3GPCe", "CCr3QJxNo3cQokReW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 11, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T21:04:25.975Z", "modifiedAt": null, "url": null, "title": "Trivers on Self-Deception", "slug": "trivers-on-self-deception", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:58.959Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DSnamjnW7Ad8vEEKd/trivers-on-self-deception", "pageUrlRelative": "/posts/DSnamjnW7Ad8vEEKd/trivers-on-self-deception", "linkUrl": "https://www.lesswrong.com/posts/DSnamjnW7Ad8vEEKd/trivers-on-self-deception", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Trivers%20on%20Self-Deception&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATrivers%20on%20Self-Deception%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDSnamjnW7Ad8vEEKd%2Ftrivers-on-self-deception%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Trivers%20on%20Self-Deception%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDSnamjnW7Ad8vEEKd%2Ftrivers-on-self-deception", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDSnamjnW7Ad8vEEKd%2Ftrivers-on-self-deception", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1087, "htmlBody": "<p>People usually have good guesses about the origins of their behavior. If they eat, we believe them when they say it was because they were hungry; if they go to a concert, we believe them when they say they like the music, or want to go out with their friends. We usually assume people's self-reports of their motives are accurate.<br /><br />Discussions of signaling usually make the opposite assumption: that our stated (and mentally accessible) reasons for actions are false. For example, a person who believes they are donating to charity to \"do the right thing\" might really be doing it to impress others; a person who buys an expensive watch because \"you can really tell the difference in quality\" might really want to conspicuously consume wealth.</p>\n<p>Signaling theories share the behaviorist perspective that actions do not derive from thoughts, but rather that actions and thoughts are both selected behavior. In this paradigm, predicted reward might lead one to signal, but reinforcement of positive-affect producing thoughts might create the thought \"I did that because I'm a nice person\".</p>\n<p>Robert Trivers is one of the founders of evolutionary psychology, responsible for ideas like reciprocal altruism and parent-offspring conflict. He also developed a <a href=\"http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBgQFjAA&amp;url=http%3A%2F%2Fanthro.rutgers.edu%2Fcomponent%2Fdocman%2Fdoc_download%2F245-trivers2000&amp;rct=j&amp;q=The%20Elements%20of%20a%20Scientific%20Theory%20of%20Self-Deception&amp;ei=FrYcTsqTOoyRgQfT1vXLCQ&amp;usg=AFQjCNHRtGfuRT67Slb8pJ1MjhITFnAPFA&amp;sig2=FTk_Slncxn-lL0QfM-aHQQ&amp;cad=rja\">theory of consciousness</a> which provides a plausible explanation for the distinction between selected actions and selected thoughts.<br /><br /><strong>TRIVERS' THEORY OF SELF-DECEPTION</strong><br /><br />Trivers starts from the same place a lot of evolutionary psychologists start from: small bands of early humans grown successful enough that food and safety were less important determinants of reproduction than social status.<br /><br /><em>The Invention of Lying</em> may have been a very silly movie, but the core idea - that a good liar has a major advantage in a world of people unaccustomed to lies - is sound. The evolutionary invention of lying led to an \"arms race\" between better and better liars and more and more sophisticated mental lie detectors.<br /><br />There's some controversy over exactly how good our mental lie detectors are or can be. There are certainly cases in which it is possible to catch lies reliably: my mother can identify my lies so accurately that I can't even play minor pranks on her anymore. But there's also some evidence that there are certain people who can reliably detect lies from any source at least 80% of the time without any previous training: microexpressions expert Paul Ekman calls them (sigh...I can't believe I have to write this) <a href=\"http://en.wikipedia.org/wiki/Wizards_Project\">Truth Wizards</a>, and identifies them at about one in four hundred people.<br /><br />The <a href=\"/lw/rl/the_psychological_unity_of_humankind/\">psychic unity of mankind</a> should preclude the existence of a miraculous genetic ability like this in only one in four hundred people: if it's possible, it should have achieved fixation. Ekman believes that everyone can be trained to this level of success (and has created the relevant training materials himself) but that his \"wizards\" achieve it naturally; perhaps because they've had a lot of practice. One can speculate that in an ancestral environment with a limited number of people, more face-to-face interaction and more opportunities for lying, this sort of skill might be more common; for what it's worth, a disproportionate number of the \"truth wizards\" found in the study were Native Americans, though I can't find any information about how traditional their origins were or why that should matter.<br /><br />If our ancestors were good at lie detection - either \"truth wizard\" good or just the good that comes from interacting with the same group of under two hundred people for one's entire life - then anyone who could beat the lie detectors would get the advantages that accrue from being the only person able to lie plausibly.</p>\n<p>Trivers' theory is that the conscious/unconscious distinction is partly based around allowing people to craft narratives that paint them in a favorable light. The conscious mind gets some sanitized access to the output of the unconscious, and uses it along with its own <a href=\"http://en.wikipedia.org/wiki/Self-serving_bias\">self-serving bias</a> to come up with a socially admirable story about its desires, emotions, and plans. The unconscious then goes and does whatever has the highest expected reward - which may be socially admirable, since social status is a reinforcer - but may not be.</p>\n<p><strong>HOMOSEXUALITY: A CASE STUDY</strong><br /><br />It's almost a truism by now that some of the people who most strongly oppose homosexuality may be gay themselves. The truism is supported by research: the Journal of Abnormal Psychology <a href=\"https://my.psychologytoday.com/files/u47/Henry_et_al.pdf\">published a study </a>measuring penile erection in 64 homophobic and nonhomophobic heterosexual men upon watching different types of pornography, and found significantly greater erection upon watching gay pornography in the homophobes. Although somehow this study has gone fifteen years without replication, it provides some support for the folk theory.<br /><br />Since in many communities openly declaring one's self homosexual is low status or even dangerous, these men have an incentive to lie about their sexuality. Because their facade may not be perfect, they also have an incentive to take extra efforts to signal heterosexuality by for example attacking gay people (something which, in theory, a gay person would never do).<br /><br />Although a few now-outed gays admit to having done this consciously, Trivers' theory offers a model in which this could also occur subconsciously. Homosexual urges never make it into the sanitized version of thought presented to consciousness, but the unconscious is able to deal with them. It objects to homosexuality (motivated by internal reinforcement - reduction of worry about personal orientation), and the conscious mind toes party line by believing that there's something morally wrong with gay people and only I have the courage and moral clarity to speak out against it.<br /><br />This provides a possible evolutionary mechanism for what Freud described as <a href=\"http://en.wikipedia.org/wiki/Reaction_formation\">reaction formation</a>, the tendency to hide an impulse by exaggerating its opposite. A person wants to signal to others (and possibly to themselves) that they lack an unacceptable impulse, and so exaggerates the opposite as \"proof\".<br /><br /><strong>SUMMARY</strong><br /><br />Trivers' theory has been summed up by calling consciousness \"the public relations agency of the brain\". It consists of a group of thoughts selected because they paint the thinker in a positive light, and of speech motivated in harmony with those thoughts. This ties together signaling, the many self-promotion biases that have thus far been discovered, and the increasing awareness that consciousness is more of a side office in the mind's organizational structure than it is a decision-maker.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YTCrHWYHAsAD74EHo": 1, "exZi6Bing5AiM4ZQB": 1, "Q6P8jLn8hH7kbuXRr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DSnamjnW7Ad8vEEKd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": 58, "extendedScore": null, "score": 0.00011, "legacy": true, "legacyId": "8587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Cyj6wQLW6SeF6aGLy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T21:11:54.216Z", "modifiedAt": null, "url": null, "title": "Meetup : Weekly Berkeley Meetup", "slug": "meetup-weekly-berkeley-meetup-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WhR5L5bqimuny59H3/meetup-weekly-berkeley-meetup-2", "pageUrlRelative": "/posts/WhR5L5bqimuny59H3/meetup-weekly-berkeley-meetup-2", "linkUrl": "https://www.lesswrong.com/posts/WhR5L5bqimuny59H3/meetup-weekly-berkeley-meetup-2", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Weekly%20Berkeley%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Weekly%20Berkeley%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhR5L5bqimuny59H3%2Fmeetup-weekly-berkeley-meetup-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Weekly%20Berkeley%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhR5L5bqimuny59H3%2Fmeetup-weekly-berkeley-meetup-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWhR5L5bqimuny59H3%2Fmeetup-weekly-berkeley-meetup-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18'>Weekly Berkeley Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2128 Oxford Street, Berkeley, CA 94704</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet at the usual Oxford and Center St Starbucks, and depart for a nearby restaurant at 7:20. Feel free to give me a call at 952.217.0505 if you arrive later and would like to find us. Since we didn't get to it last week, the topic will be Aumann updating, and whether our beliefs can, do, and should count as evidence about the world.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18'>Weekly Berkeley Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WhR5L5bqimuny59H3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.401104148849364e-07, "legacy": true, "legacyId": "8588", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18\">Weekly Berkeley Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2128 Oxford Street, Berkeley, CA 94704</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet at the usual Oxford and Center St Starbucks, and depart for a nearby restaurant at 7:20. Feel free to give me a call at 952.217.0505 if you arrive later and would like to find us. Since we didn't get to it last week, the topic will be Aumann updating, and whether our beliefs can, do, and should count as evidence about the world.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18\">Weekly Berkeley Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Weekly Berkeley Meetup", "anchor": "Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Weekly Berkeley Meetup", "anchor": "Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T21:25:25.597Z", "modifiedAt": null, "url": null, "title": "A funny argument for traditional morality", "slug": "a-funny-argument-for-traditional-morality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:32.402Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GtaN4YQmXcgwEtLfL/a-funny-argument-for-traditional-morality", "pageUrlRelative": "/posts/GtaN4YQmXcgwEtLfL/a-funny-argument-for-traditional-morality", "linkUrl": "https://www.lesswrong.com/posts/GtaN4YQmXcgwEtLfL/a-funny-argument-for-traditional-morality", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20funny%20argument%20for%20traditional%20morality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20funny%20argument%20for%20traditional%20morality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGtaN4YQmXcgwEtLfL%2Fa-funny-argument-for-traditional-morality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20funny%20argument%20for%20traditional%20morality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGtaN4YQmXcgwEtLfL%2Fa-funny-argument-for-traditional-morality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGtaN4YQmXcgwEtLfL%2Fa-funny-argument-for-traditional-morality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 192, "htmlBody": "<p>I just had a long conversation with my brother, a devout Christian. With my help he has outlined the following argument why it might be good for me to follow Christian <a href=\"http://en.wikipedia.org/wiki/Deontological_ethics\">deontology</a>:</p>\n<ol>\n<li>Many of my moral values arose from my upbringing, as opposed to biology. This is evidenced by the fact that biologically similar people living in different places and epochs have different ideas of what's right.</li>\n<li>Therefore many of my values originally came from the society that raised me.</li>\n<li>Society's values were strongly influenced by Christian values, and many of our core moral prohibitions are inherited from Christian tradition.</li>\n<li>The world is full of people who may want to edit my values ever-so-slightly while I'm not looking, in order to further their own agenda.</li>\n<li>Also my values may drift, and most drift is harmful from the perspective of my current values.</li>\n<li>A good recipe for countering this insidious deterioration of values is to consciously pull them back toward their original source, as long as it's something unchanging, like a book.</li>\n<li>That means editing my values to more closely match Christianity. QED.</li>\n</ol>\n<p>What do you think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GtaN4YQmXcgwEtLfL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 23, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "8589", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T23:08:48.228Z", "modifiedAt": null, "url": null, "title": "Less Wrong meets\u2026", "slug": "less-wrong-meets", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.706Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loup-vaillant", "createdAt": "2011-03-23T10:39:25.887Z", "isAdmin": false, "displayName": "loup-vaillant"}, "userId": "wdoZti3BcPbJXsZ66", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PMEacYgZZsGXCzCvk/less-wrong-meets", "pageUrlRelative": "/posts/PMEacYgZZsGXCzCvk/less-wrong-meets", "linkUrl": "https://www.lesswrong.com/posts/PMEacYgZZsGXCzCvk/less-wrong-meets", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20meets%E2%80%A6&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20meets%E2%80%A6%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMEacYgZZsGXCzCvk%2Fless-wrong-meets%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20meets%E2%80%A6%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMEacYgZZsGXCzCvk%2Fless-wrong-meets", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMEacYgZZsGXCzCvk%2Fless-wrong-meets", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 272, "htmlBody": "<blockquote>\n<p>Fate surely exists.</p>\n<p>People cannot choose the place, era and circumstances under which they are born.&nbsp; As a result the condition under which each person lives is different the moment they're born.</p>\n<p>This is fate.</p>\n<p>And it's natural&hellip;<br />for the world to be cruel.</p>\n<p>The beginning of life is just a scientific reaction.<br />Soul doesn't exist. Spirit is but a sparkle of nerve cells.<br />The human existence is just a shadow of memory information.<br />Even if you have to live alone in a godless and cruel world&hellip;</p>\n<p>I order you with all my will.<br />Live!!</p>\n</blockquote>\n<p><em>Eliez</em>&hellip; no, wait: <em><a href=\"http://manga.animea.net/battle-angel-alita-last-order-chapter-7-page-28.html\">Desty Nova</a></em></p>\n<p>Edit: Okay, I got it, sorry for the noise. I posted it because it just hit me how frighteningly close the mainstream LW world view is from such an archetypal <a href=\"/mad scientist\">mad scientist</a>. The first part sounds a bit cynic for my taste, but the second part closely reminded me of <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29\">this</a>, <a href=\"/lw/p5/brain_breakthrough_its_made_of_neurons/\">this</a>, <a href=\"/lw/uk/beyond_the_reach_of_god/\">this</a>, and <a href=\"/lw/wq/you_only_live_twice/\">this</a> (last sentence).</p>\n<p><a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/Gunnm\">Gunnm</a>, readers know that Desty Nova is by himself an existential risk. Despite him loathing the second law of thermodynamics, his potential for entropy maximization is almost limitless. In other words, he is Evil. I realized that the Mad Scientist archetype is partly responsible for popular association of <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ImmortalityImmorality\">immortality and Evil</a>, <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ScienceIsBad\">science and Evil</a>, possibly even <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/HollywoodAtheist\">atheism and Evil</a>. (I must say that Gunnm itself is not too guilty of that: the heroin may still have problems with immortality, but she sees uploads as moral beings. Some long lived, non-ageing people like to eat babies (literally), but others are still decent.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PMEacYgZZsGXCzCvk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -11, "extendedScore": null, "score": 7.40146472481012e-07, "legacy": true, "legacyId": "8590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["nzzNFcrSk7akQ9bwD", "sYgv4eYH82JEsTD34", "yKXKcyoBzWtECzXrE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T23:14:23.609Z", "modifiedAt": null, "url": null, "title": "Knowing what you want is a prerequisite to getting what you want", "slug": "knowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nwthomas", "createdAt": "2011-06-10T23:37:04.832Z", "isAdmin": false, "displayName": "nwthomas"}, "userId": "vy6yE9WCL6kE3YDx4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rRr8d9j7bjCdGxkWT/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "pageUrlRelative": "/posts/rRr8d9j7bjCdGxkWT/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "linkUrl": "https://www.lesswrong.com/posts/rRr8d9j7bjCdGxkWT/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKnowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrRr8d9j7bjCdGxkWT%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrRr8d9j7bjCdGxkWT%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrRr8d9j7bjCdGxkWT%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2124, "htmlBody": "<p>Frequently, we decide on a goal, and then we are ineffective in working towards this goal, due to factors wholly within our control. Failure modes include giving up, losing interest, procrastination, akrasia, and &lt;a href=\"http://lesswrong.com/lw/2p1/a_failure_to_evaluate_returnontime_fallacy/\"&gt;failure to evaluate return on time&lt;/a&gt;. In all these cases it seems that if our motivation were higher, the problem would not exist. Call the problem of finding the motivation to effectively pursue one's goals, &lt;i&gt;the problem of motivation&lt;/i&gt;. This is a common failure of instrumental rationality which has been discussed from numerous different angles on LessWrong.<br /><br />I wish to introduce another approach to the problem of motivation, which to my knowledge has not yet been discussed on LessWrong. This approach is summarized in the following paragraph:<br /><br />&lt;blockquote&gt;<br />We do not know what we value. Therefore, we choose goals that are not in harmony with our values. The problem of motivation is often caused by our goals not being in harmony with our values. Therefore, many cases of the problem of motivation can be solved by discovering what you value, and carrying out goals that conform to your values.<br />&lt;/blockquote&gt;<br /><br />I will begin by making clear the distinction between goals and values. A goal is time-bound, contingent, and concrete. A value is permanent, unconditional, and abstract. A few goals are:<br /><br />&lt;ul&gt;<br />&lt;li&gt;Become a comedian.&lt;/li&gt;<br />&lt;li&gt;Bring about the Singularity.&lt;/li&gt;<br />&lt;li&gt;Graduate college.&lt;/li&gt;<br />&lt;/ul&gt;<br /><br />A few values are:<br /><br />&lt;ul&gt;<br />&lt;li&gt;Humor&lt;/li&gt;<br />&lt;li&gt;Transcendence&lt;/li&gt;<br />&lt;li&gt;Money&lt;/li&gt;<br />&lt;/ul&gt;<br /><br />For good measure, I'll list a few more values:<br /><br />&lt;ul&gt;<br />&lt;li&gt;Truth&lt;/li&gt;<br />&lt;li&gt;Love&lt;/li&gt;<br />&lt;li&gt;Beauty&lt;/li&gt;<br />&lt;li&gt;Social justice&lt;/li&gt;<br />&lt;li&gt;Happiness&lt;/li&gt;<br />&lt;li&gt;Interpersonal relationships&lt;/li&gt;<br />&lt;li&gt;Money&lt;/li&gt;<br />&lt;li&gt;Power&lt;/li&gt;<br />&lt;li&gt;Spirituality&lt;/li&gt;<br />&lt;li&gt;Rationality&lt;/li&gt;<br />&lt;li&gt;Imagination&lt;/li&gt;<br />&lt;li&gt;Security&lt;/li&gt;<br />&lt;li&gt;Excitement&lt;/li&gt;<br />&lt;li&gt;Self-expression&lt;/li&gt;<br />&lt;li&gt;Life&lt;/li&gt;<br />&lt;/ul&gt;<br /><br />I argue that goals are always in service of values. If we look at &lt;a href=\"http://lesswrong.com/lw/sm/the_meaning_of_right/\"&gt;the terminal values in our decision tree&lt;/a&gt;, they will be big, mysterious abstractions such as these. Why would I think this? Why not have concrete things as the terminal values of our decision tree?<br /><br />Because it's simpler. Consider this example. I can have a terminal value, \"pleasure,\" and then sub-goals to this terminal value: let's say, \"drinking,\" \"smoking,\" and \"eating.\" On the other hand, I can have \"drinking,\" \"smoking,\" and \"eating\" all as terminal values, without the node \"pleasure\" anywhere in sight.<br /><br />The latter seems rather un-parsimonious. Why have multiple specifics in my utility function, when I can have one generality that replaces them all? Scientific theories are developed by subsuming specifics in generalities. Also, I think that the case in the previous paragraph is a fairly representative example; that for every specific desirable, we can name a more general desirable, or a set of more general desirables, which it serves.<br /><br />So it seems to me that the simplest theories of value are those which have mysterious abstractions as the terminal values in the decision tree. These mysterious abstractions are what I have called \"values.\" Our goals, in turn, are non-terminal nodes which point towards our values.<br /><br />In order to achieve our values, we must figure out how to achieve them, and then do so. We must choose our goals, and carry them out. But, there is another step in the process: &lt;i&gt;we must figure out what we value&lt;/i&gt;. It is this step which I wish to examine here.<br /><br />I make the following claims:<br /><br />&lt;ul&gt;<br />&lt;li&gt;Every person has a relatively stable set of values.&lt;/li&gt;<br />&lt;li&gt;No person has a perfect understanding of what they value. There is a disconnect between what we value, and what we understand ourselves as valuing.&lt;/li&gt;<br />&lt;li&gt;It is possible, through introspection and analysis of experience, to discover more perfectly what one values.&lt;/li&gt;<br />&lt;li&gt;Some instances of the problem of motivation are caused by pursuing a goal which is not sufficiently in harmony with one's values. In these cases the solution is to understand the nature of the disharmony, and change the goal, or the approach to the goal, to eliminate the disharmony. This will probably involve making new discoveries about one's values.&lt;/li&gt;<br />&lt;li&gt;Pursuing a goal which is strongly in harmony with one's values does not require effort or willpower; it comes naturally.&lt;/li&gt;<br />&lt;/ul&gt;<br /><br />Unfortunately, I do not have any scientific evidence to support these claims. Also, the usual qualifiers to self-help advice apply. I will conclude the post by giving several examples of how these principles have been played out in my life.<br /><br />I spend a lot of time on creative projects. For years I struggled with the problem of not being able to finish anything I started. I now finish most of the things I start. This is probably due to many factors. One factor, I believe, is that I now put more careful attention into making sure that the message I have for each creative effort strongly embodies what I value. I concentrate more of what I value into each piece, and this is possible because I have a better understanding than I used to of what I value.<br /><br />Most of this has to do with the detailed content of the pieces. It also has to do with the media I use. I used to write music, but I no longer do so. Now I write a lot of philosophy. This is better for me because the greatest value which music embodies is beauty, and the greatest value which philosophy embodies is truth. I value both truth and beauty, but I value truth more than I value beauty, and so philosophy is more gratifying for me.<br /><br />The biggest mistake of my life so far was my attitude in a relationship with a certain girl. I spent a lot of time trying to \"fix\" her or \"improve\" her, mostly by giving her advice or knowledge about herself and her personality. The information that I gave her about herself, while true, hurt her self-esteem, and this weakened our relationship, ultimately contributing to our breaking up.<br /><br />What I should have done, as I realized in retrospect, was to love and accept her for who she was, rather than trying to fix or improve her. This experience taught me the value of love. Love is something I value more than I ever knew. It has proven difficult to propagate the belief \"I value love\" throughout my mind, so that I often forget it. Therefore I suspect that I value love even more than I know.<br /><br />(This might seem like a paradox, but it is not. When I say that \"I value love more than I know,\" I mean simply that I don't feel, continuously and at a gut level, the value that I believe that love really has. This is similar to &lt;a href=\"http://lesswrong.com/lw/1l/the_mystery_of_the_haunted_rationalist/\"&gt;the rationalist who is afraid of ghosts&lt;/a&gt;. He knows intellectually that ghosts don't exist, but he hasn't managed to convince the rest of himself of this.)<br /><br />I practice mysticism. I use meditation, and in the past have used physical exercises and rituals, to induce &lt;a href=\"http://en.wikipedia.org/wiki/Mystical_experience\"&gt;mystical experiences&lt;/a&gt;.<br /><br />I value mystical experiences because they efficiently serve a significant number of my values. They involve intense positive emotions and aesthetic ecstasies, serving my values of happiness and beauty. They often give me new ideas, serving my value of truth, and indirectly serving my value of self-expression by providing me with things to write about. (I came up with the idea for this post while meditating this morning.)<br /><br />For a long time I did not have a clear understanding of what I was trying to get out of mysticism. At times, therefore, it became a &lt;a href=\"http://lesswrong.com/lw/le/lost_purposes/\"&gt;lost purpose&lt;/a&gt;, which did not get me anywhere.<br /><br />I now practice mysticism with a clearer idea of what I am trying to accomplish. This has made my practices more effective. Mysticism involves subtle manipulations of one's mental processes. Rather than engaging in mental processes which are simply \"what you're supposed to do in mysticism,\" I now engage in mental processes which I know will lead to the results I want. This has been made possible by connecting the processes with the values they serve.<br /><br />It is not only true that my mysticism has become more effective for me by connecting it with an understanding of my values; it is also true that it has become easier. Previously, I would exercise a significant amount of willpower to engage in mystical practices for an hour or two a day. Now, I meditate for three hours a day without any exercise of willpower. It doesn't require willpower because I simply &lt;i&gt;want&lt;/i&gt; to do it. I want to do it because it serves my values.<br /><br />I wish to analyze in detail a particular way in which I previously went wrong with mysticism. I used to meditate in a half-lotus position. Because I was born with low hip flexibility, this position put a lot of stress on my body. I was initially in a lot of pain from this position, but I continued using it. Eventually the pain went away. Further down the line, I gave myself a knee injury from meditating in this position, which probably would have required surgery if I had continued to do this.<br /><br />There are a few things that I learned from this incident. I was meditating in half-lotus to conform to my image of \"spiritual purity,\" based on cultural memes which I had absorbed. My knee injury made me realize that I had been on the wrong path in this respect, and I saw that I was wrong in valuing \"spiritual purity.\" It was not part of my value system, but something that had been imposed from outside.<br /><br />My knee injury also made me realize that I had been wrong in putting my body through all of that unnecessary stress in the service of mysticism. This was one of the data points which allowed me to discover the value of self-love: of being nice to oneself.<br /><br />Another data point which allowed me to discover the value of self-love came in editing the book I am working on. Editing this book has been quite painful, because I am so critical of it. Reading it makes me disgusted by it, and then I am disgusted with myself.<br /><br />For example, about a week ago I came across two paragraphs which contained some statements that I felt to be wrong. I was so disgusted by these wrong statements that I could not bear to look at them. I had to spend days psyching myself up to the point that I could look at these paragraphs for long enough to delete them.<br /><br />The basic problem here is that I am hyper-critical of my writing, and in criticizing my writing I am criticizing myself. This makes the editing process a terrible stressor on my self-esteem. There is a clear message about my values: I value self-love, but do not love myself enough. If I was nicer to myself, then I could edit painlessly, and I desire to edit painlessly.<br /><br />A final example will illustrate once more the connection between values and the problem of motivation. I am a psychology major and a philosophy minor. I got the psychology major at the beginning of college, and the philosophy minor two and a half years later. I enjoy my philosophy classes, and find my psychology classes tedious. It is therefore easier to be motivated to do well in my philosophy classes than in my psychology classes. I chose philosophy at a time when I better understood my values than I did at the time when I chose psychology. If I had this knowledge of my values when I started college, I could have chosen a major that I would enjoy more and do better in.<br /><br />I hope that the reader has found these examples illustrative. I have attempted to throw some light on the process of discovering one's values and revising one's goals to conform to these values. It seems to me that this is a basic tool of instrumental rationality. One cannot achieve one's values without knowing one's values. Furthermore, one cannot sustainably pursue anything other than one's values, and many cases of the problem of motivation can be explained by this fact.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rRr8d9j7bjCdGxkWT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "8591", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T23:18:10.827Z", "modifiedAt": null, "url": null, "title": "Knowing what you want is a prerequisite to getting what you want", "slug": "knowing-what-you-want-is-a-prerequisite-to-getting-what-you", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nwthomas", "createdAt": "2011-06-10T23:37:04.832Z", "isAdmin": false, "displayName": "nwthomas"}, "userId": "vy6yE9WCL6kE3YDx4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jsJwwZHkX4XPaNg2a/knowing-what-you-want-is-a-prerequisite-to-getting-what-you", "pageUrlRelative": "/posts/jsJwwZHkX4XPaNg2a/knowing-what-you-want-is-a-prerequisite-to-getting-what-you", "linkUrl": "https://www.lesswrong.com/posts/jsJwwZHkX4XPaNg2a/knowing-what-you-want-is-a-prerequisite-to-getting-what-you", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKnowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjsJwwZHkX4XPaNg2a%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjsJwwZHkX4XPaNg2a%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjsJwwZHkX4XPaNg2a%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1995, "htmlBody": "<p>Frequently, we decide on a goal, and then we are ineffective in working towards this goal, due to factors wholly within our control. Failure modes include giving up, losing interest, procrastination, akrasia, and <a href=\"/lw/2p1/a_failure_to_evaluate_returnontime_fallacy/\">failure to evaluate return on time</a>. In all these cases it seems that if our motivation were higher, the problem would not exist. Call the problem of finding the motivation to effectively pursue one's goals, <em>the problem of motivation</em>. This is a common failure of instrumental rationality which has been discussed from numerous different angles on LessWrong.</p>\n<p>I wish to introduce another approach to the problem of motivation, which to my knowledge has not yet been discussed on LessWrong. This approach is summarized in the following paragraph:</p>\n<blockquote>We do not know what we value. Therefore, we choose goals that are not in harmony with our values. The problem of motivation is often caused by our goals not being in harmony with our values. Therefore, many cases of the problem of motivation can be solved by discovering what you value, and carrying out goals that conform to your values.</blockquote>\n<p>I will begin by making clear the distinction between goals and values. A goal is time-bound, contingent, and concrete. A value is permanent, unconditional, and abstract. A few goals are:</p>\n<ul>\n<li>Become a comedian.</li>\n<li>Bring about the Singularity.</li>\n<li>Graduate college.</li>\n</ul>\n<p>A few values are:</p>\n<ul>\n<li>Humor</li>\n<li>Transcendence</li>\n<li>Money</li>\n</ul>\n<p>For good measure, I'll list a few more values:</p>\n<ul>\n<li>Truth</li>\n<li>Love</li>\n<li>Beauty</li>\n<li>Social justice</li>\n<li>Happiness</li>\n<li>Interpersonal relationships</li>\n<li>Money</li>\n<li>Power</li>\n<li>Spirituality</li>\n<li>Rationality</li>\n<li>Imagination</li>\n<li>Security</li>\n<li>Excitement</li>\n<li>Self-expression</li>\n<li>Life</li>\n</ul>\n<p>I argue that goals are always in service of values. If we look at <a href=\"/lw/sm/the_meaning_of_right/\">the terminal values in our decision tree</a>, they will be big, mysterious abstractions such as these. Why would I think this? Why not have concrete things as the terminal values of our decision tree?</p>\n<p>Because it's simpler. Consider this example. I can have a terminal value, \"pleasure,\" and then sub-goals to this terminal value: let's say, \"drinking,\" \"smoking,\" and \"eating.\" On the other hand, I can have \"drinking,\" \"smoking,\" and \"eating\" all as terminal values, without the node \"pleasure\" anywhere in sight.</p>\n<p>The latter seems rather un-parsimonious. Why have multiple specifics in my utility function, when I can have one generality that replaces them all? Scientific theories are developed by subsuming specifics in generalities. Also, I think that the case in the previous paragraph is a fairly representative example; that for every specific desirable, we can name a more general desirable, or a set of more general desirables, which it serves.</p>\n<p>So it seems to me that the simplest theories of value are those which have mysterious abstractions as the terminal values in the decision tree. These mysterious abstractions are what I have called \"values.\" Our goals, in turn, are non-terminal nodes which point towards our values.</p>\n<p>In order to achieve our values, we must figure out how to achieve them, and then do so. We must choose our goals, and carry them out. But, there is another step in the process: <em>we must figure out what we value</em>. It is this step which I wish to examine here.</p>\n<p>I make the following claims:</p>\n<ul>\n<li>Every person has a relatively stable set of values.</li>\n<li>No person has a perfect understanding of what they value. There is a disconnect between what we value, and what we understand ourselves as valuing.</li>\n<li>It is possible, through introspection and analysis of experience, to discover more perfectly what one values.</li>\n<li>Some instances of the problem of motivation are caused by pursuing a goal which is not sufficiently in harmony with one's values. In these cases the solution is to understand the nature of the disharmony, and change the goal, or the approach to the goal, to eliminate the disharmony. This will probably involve making new discoveries about one's values.</li>\n<li>Pursuing a goal which is strongly in harmony with one's values does not require effort or willpower; it comes naturally.</li>\n</ul>\n<p>Unfortunately, I do not have any scientific evidence to support these claims. Also, the usual qualifiers to self-help advice apply. I will conclude the post by giving several examples of how these principles have been played out in my life.</p>\n<p>I spend a lot of time on creative projects. For years I struggled with the problem of not being able to finish anything I started. I now finish most of the things I start. This is probably due to many factors. One factor, I believe, is that I now put more careful attention into making sure that the message I have for each creative effort strongly embodies what I value. I concentrate more of what I value into each piece, and this is possible because I have a better understanding than I used to of what I value.</p>\n<p>Most of this has to do with the detailed content of the pieces. It also has to do with the media I use. I used to write music, but I no longer do so. Now I write a lot of philosophy. This is better for me because the greatest value which music embodies is beauty, and the greatest value which philosophy embodies is truth. I value both truth and beauty, but I value truth more than I value beauty, and so philosophy is more gratifying for me.</p>\n<p>The biggest mistake of my life so far was my attitude in a relationship with a certain girl. I spent a lot of time trying to \"fix\" her or \"improve\" her, mostly by giving her advice or knowledge about herself and her personality. The information that I gave her about herself, while true, hurt her self-esteem, and this weakened our relationship, ultimately contributing to our breaking up.</p>\n<p>What I should have done, as I realized in retrospect, was to love and accept her for who she was, rather than trying to fix or improve her. This experience taught me the value of love. Love is something I value more than I ever knew. It has proven difficult to propagate the belief \"I value love\" throughout my mind, so that I often forget it. Therefore I suspect that I value love even more than I know.</p>\n<p>(This might seem like a paradox, but it is not. When I say that \"I value love more than I know,\" I mean simply that I don't feel, continuously and at a gut level, the value that I believe that love really has. This is similar to <a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">the rationalist who is afraid of ghosts</a>. He knows intellectually that ghosts don't exist, but he hasn't managed to convince the rest of himself of this.)</p>\n<p>I practice mysticism. I use meditation, and in the past have used physical exercises and rituals, to induce <a href=\"http://en.wikipedia.org/wiki/Mystical_experience\">mystical experiences</a>.</p>\n<p>I value mystical experiences because they efficiently serve a significant number of my values. They involve intense positive emotions and aesthetic ecstasies, serving my values of happiness and beauty. They often give me new ideas, serving my value of truth, and indirectly serving my value of self-expression by providing me with things to write about. (I came up with the idea for this post while meditating this morning.)</p>\n<p>For a long time I did not have a clear understanding of what I was trying to get out of mysticism. At times, therefore, it became a <a href=\"/lw/le/lost_purposes/\">lost purpose</a>, which did not get me anywhere.</p>\n<p>I now practice mysticism with a clearer idea of what I am trying to accomplish. This has made my practices more effective. Mysticism involves subtle manipulations of one's mental processes. Rather than engaging in mental processes which are simply \"what you're supposed to do in mysticism,\" I now engage in mental processes which I know will lead to the results I want. This has been made possible by connecting the processes with the values they serve.</p>\n<p>It is not only true that my mysticism has become more effective for me by connecting it with an understanding of my values; it is also true that it has become easier. Previously, I would exercise a significant amount of willpower to engage in mystical practices for an hour or two a day. Now, I meditate for three hours a day without any exercise of willpower. It doesn't require willpower because I simply <em>want</em> to do it. I want to do it because it serves my values.</p>\n<p>I wish to analyze in detail a particular way in which I previously went wrong with mysticism. I used to meditate in a half-lotus position. Because I was born with low hip flexibility, this position put a lot of stress on my body. I was initially in a lot of pain from this position, but I continued using it. Eventually the pain went away. Further down the line, I gave myself a knee injury from meditating in this position, which probably would have required surgery if I had continued to do this.</p>\n<p>There are a few things that I learned from this incident. I was meditating in half-lotus to conform to my image of \"spiritual purity,\" based on cultural memes which I had absorbed. My knee injury made me realize that I had been on the wrong path in this respect, and I saw that I was wrong in valuing \"spiritual purity.\" It was not part of my value system, but something that had been imposed from outside.</p>\n<p>My knee injury also made me realize that I had been wrong in putting my body through all of that unnecessary stress in the service of mysticism. This was one of the data points which allowed me to discover the value of self-love: of being nice to oneself.</p>\n<p>Another data point which allowed me to discover the value of self-love came in editing the book I am working on. Editing this book has been quite painful, because I am so critical of it. Reading it makes me disgusted by it, and then I am disgusted with myself.</p>\n<p>For example, about a week ago I came across two paragraphs which contained some statements that I felt to be wrong. I was so disgusted by these wrong statements that I could not bear to look at them. I had to spend days psyching myself up to the point that I could look at these paragraphs for long enough to delete them.</p>\n<p>The basic problem here is that I am hyper-critical of my writing, and in criticizing my writing I am criticizing myself. This makes the editing process a terrible stressor on my self-esteem. This constitutes a clear message about my values: it indicates that I value self-love, but do not love myself enough. If I was nicer to myself, then I could edit painlessly.</p>\n<p>A final example will illustrate once more the connection between values and the problem of motivation. I am a psychology major and a philosophy minor. I got the psychology major at the beginning of college, and the philosophy minor two and a half years later. I enjoy my philosophy classes, and find my psychology classes tedious. It is therefore easier to be motivated to do well in my philosophy classes than in my psychology classes. I chose philosophy at a time when I better understood my values than I did at the time when I chose psychology. If I had this knowledge of my values when I started college, I could have chosen a major that I would enjoy more and do better in.</p>\n<p>I hope that the reader has found these examples illustrative. I have attempted to throw some light on the process of discovering one's values and revising one's goals to conform to these values. It seems to me that this is a basic tool of instrumental rationality. One cannot achieve one's values without knowing one's values. Furthermore, one cannot sustainably pursue anything other than one's values, and many cases of the problem of motivation can be explained by this fact.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jsJwwZHkX4XPaNg2a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8592", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RzdPXLd2b6qmEB2mf", "fG3g3764tSubr6xvs", "mja6jZ6k9gAwki9Nu", "sP2Hg6uPwpfp3jZJN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T23:19:20.640Z", "modifiedAt": null, "url": null, "title": "Knowing what you want is a prerequisite to getting what you want", "slug": "knowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.753Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nwthomas", "createdAt": "2011-06-10T23:37:04.832Z", "isAdmin": false, "displayName": "nwthomas"}, "userId": "vy6yE9WCL6kE3YDx4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bk3Aa2EKhu5D7BZSZ/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "pageUrlRelative": "/posts/Bk3Aa2EKhu5D7BZSZ/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "linkUrl": "https://www.lesswrong.com/posts/Bk3Aa2EKhu5D7BZSZ/knowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKnowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk3Aa2EKhu5D7BZSZ%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Knowing%20what%20you%20want%20is%20a%20prerequisite%20to%20getting%20what%20you%20want%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk3Aa2EKhu5D7BZSZ%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk3Aa2EKhu5D7BZSZ%2Fknowing-what-you-want-is-a-prerequisite-to-getting-what-you-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2000, "htmlBody": "<p>Frequently, we decide on a goal, and then we are ineffective in working towards this goal, due to factors wholly within our control. Failure modes include giving up, losing interest, procrastination, akrasia, and <a href=\"/lw/2p1/a_failure_to_evaluate_returnontime_fallacy/\">failure to evaluate return on time</a>. In all these cases it seems that if our motivation were higher, the problem would not exist. Call the problem of finding the motivation to effectively pursue one's goals, <em>the problem of motivation</em>. This is a common failure of instrumental rationality which has been discussed from numerous different angles on LessWrong.</p>\n<p>I wish to introduce another approach to the problem of motivation, which to my knowledge has not yet been discussed on LessWrong. This approach is summarized in the following paragraph:</p>\n<p>We do not know what we value. Therefore, we choose goals that are not in harmony with our values. The problem of motivation is often caused by our goals not being in harmony with our values. Therefore, many cases of the problem of motivation can be solved by discovering what you value, and carrying out goals that conform to your values.</p>\n<p><a id=\"more\"></a></p>\n<p>I will begin by making clear the distinction between goals and values. A goal is time-bound, contingent, and concrete. A value is permanent, unconditional, and abstract. A few goals are:</p>\n<ul>\n<li>Become a comedian.</li>\n<li>Bring about the Singularity.</li>\n<li>Graduate college.</li>\n</ul>\n<p>A few values are:</p>\n<ul>\n<li>Humor</li>\n<li>Transcendence</li>\n<li>Money</li>\n</ul>\n<p>For good measure, I'll list a few more values:</p>\n<ul>\n<li>Truth</li>\n<li>Love</li>\n<li>Beauty</li>\n<li>Social justice</li>\n<li>Happiness</li>\n<li>Interpersonal relationships</li>\n<li>Money</li>\n<li>Power</li>\n<li>Spirituality</li>\n<li>Rationality</li>\n<li>Imagination</li>\n<li>Security</li>\n<li>Excitement</li>\n<li>Self-expression</li>\n<li>Life</li>\n</ul>\n<p>I argue that goals are always in service of values. If we look at <a href=\"/lw/sm/the_meaning_of_right/\">the terminal values in our decision tree</a>, they will be big, mysterious abstractions such as these. Why would I think this? Why not have concrete things as the terminal values of our decision tree?</p>\n<p>Because it's simpler. Consider this example. I can have a terminal value, \"pleasure,\" and then sub-goals to this terminal value: let's say, \"drinking,\" \"smoking,\" and \"eating.\" On the other hand, I can have \"drinking,\" \"smoking,\" and \"eating\" all as terminal values, without the node \"pleasure\" anywhere in sight.</p>\n<p>The latter seems rather un-parsimonious. Why have multiple specifics in my utility function, when I can have one generality that replaces them all? Scientific theories are developed by subsuming specifics in generalities. Also, I think that the case in the previous paragraph is a fairly representative example; that for every specific desirable, we can name a more general desirable, or a set of more general desirables, which it serves.</p>\n<p>So it seems to me that the simplest theories of value are those which have mysterious abstractions as the terminal values in the decision tree. These mysterious abstractions are what I have called \"values.\" Our goals, in turn, are non-terminal nodes which point towards our values.</p>\n<p>In order to achieve our values, we must figure out how to achieve them, and then do so. We must choose our goals, and carry them out. But, there is another step in the process: <em>we must figure out what we value</em>. It is this step which I wish to examine here.</p>\n<p>I make the following claims:</p>\n<ul>\n<li>Every person has a relatively stable set of values.</li>\n<li>No person has a perfect understanding of what they value. There is a disconnect between what we value, and what we understand ourselves as valuing.</li>\n<li>It is possible, through introspection and analysis of experience, to discover more perfectly what one values.</li>\n<li>Some instances of the problem of motivation are caused by pursuing a goal which is not sufficiently in harmony with one's values. In these cases the solution is to understand the nature of the disharmony, and change the goal, or the approach to the goal, to eliminate the disharmony. This will probably involve making new discoveries about one's values.</li>\n<li>Pursuing a goal which is strongly in harmony with one's values does not require effort or willpower; it comes naturally.</li>\n</ul>\n<p>Unfortunately, I do not have any scientific evidence to support these claims. Also, the usual qualifiers to self-help advice apply. I will conclude the post by giving several examples of how these principles have been played out in my life.</p>\n<p>I spend a lot of time on creative projects. For years I struggled with the problem of not being able to finish anything I started. I now finish most of the things I start. This is probably due to many factors. One factor, I believe, is that I now put more careful attention into making sure that the message I have for each creative effort strongly embodies what I value. I concentrate more of what I value into each piece, and this is possible because I have a better understanding than I used to of what I value.</p>\n<p>Most of this has to do with the detailed content of the pieces. It also has to do with the media I use. I used to write music, but I no longer do so. Now I write a lot of philosophy. This is better for me because the greatest value which music embodies is beauty, and the greatest value which philosophy embodies is truth. I value both truth and beauty, but I value truth more than I value beauty, and so philosophy is more gratifying for me.</p>\n<p>The biggest mistake of my life so far was my attitude in a relationship with a certain girl. I spent a lot of time trying to \"fix\" her or \"improve\" her, mostly by giving her advice or knowledge about herself and her personality. The information that I gave her about herself, while true, hurt her self-esteem, and this weakened our relationship, ultimately contributing to our breaking up.</p>\n<p>What I should have done, as I realized in retrospect, was to love and accept her for who she was, rather than trying to fix or improve her. This experience taught me the value of love. Love is something I value more than I ever knew. It has proven difficult to propagate the belief \"I value love\" throughout my mind, so that I often forget it. Therefore I suspect that I value love even more than I know.</p>\n<p>(This might seem like a paradox, but it is not. When I say that \"I value love more than I know,\" I mean simply that I don't feel, continuously and at a gut level, the value that I believe that love really has. This is similar to <a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">the rationalist who is afraid of ghosts</a>. He knows intellectually that ghosts don't exist, but he hasn't managed to convince the rest of himself of this.)</p>\n<p>I practice mysticism. I use meditation, and in the past have used physical exercises and rituals, to induce <a href=\"http://en.wikipedia.org/wiki/Mystical_experience\">mystical experiences</a>.</p>\n<p>I value mystical experiences because they efficiently serve a significant number of my values. They involve intense positive emotions and aesthetic ecstasies, serving my values of happiness and beauty. They often give me new ideas, serving my value of truth, and indirectly serving my value of self-expression by providing me with things to write about. (I came up with the idea for this post while meditating this morning.)</p>\n<p>For a long time I did not have a clear understanding of what I was trying to get out of mysticism. At times, therefore, it became a <a href=\"/lw/le/lost_purposes/\">lost purpose</a>, which did not get me anywhere.</p>\n<p>I now practice mysticism with a clearer idea of what I am trying to accomplish. This has made my practices more effective. Mysticism involves subtle manipulations of one's mental processes. Rather than engaging in mental processes which are simply \"what you're supposed to do in mysticism,\" I now engage in mental processes which I know will lead to the results I want. This has been made possible by connecting the processes with the values they serve.</p>\n<p>It is not only true that my mysticism has become more effective for me by connecting it with an understanding of my values; it is also true that it has become easier. Previously, I would exercise a significant amount of willpower to engage in mystical practices for an hour or two a day. Now, I meditate for three hours a day without any exercise of willpower. It doesn't require willpower because I simply <em>want</em> to do it. I want to do it because it serves my values.</p>\n<p>I wish to analyze in detail a particular way in which I previously went wrong with mysticism. I used to meditate in a half-lotus position. Because I was born with low hip flexibility, this position put a lot of stress on my body. I was initially in a lot of pain from this position, but I continued using it. Eventually the pain went away. Further down the line, I gave myself a knee injury from meditating in this position, which probably would have required surgery if I had continued to do this.</p>\n<p>There are a few things that I learned from this incident. I was meditating in half-lotus to conform to my image of \"spiritual purity,\" based on cultural memes which I had absorbed. My knee injury made me realize that I had been on the wrong path in this respect, and I saw that I was wrong in valuing \"spiritual purity.\" It was not part of my value system, but something that had been imposed from outside.</p>\n<p>My knee injury also made me realize that I had been wrong in putting my body through all of that unnecessary stress in the service of mysticism. This was one of the data points which allowed me to discover the value of self-love: of being nice to oneself.</p>\n<p>Another data point which allowed me to discover the value of self-love came in editing the book I am working on. Editing this book has been quite painful, because I am so critical of it. Reading it makes me disgusted by it, and then I am disgusted with myself.</p>\n<p>For example, about a week ago I came across two paragraphs which contained some statements that I felt to be wrong. I was so disgusted by these wrong statements that I could not bear to look at them. I had to spend days psyching myself up to the point that I could look at these paragraphs for long enough to delete them.</p>\n<p>The basic problem here is that I am hyper-critical of my writing, and in criticizing my writing I am criticizing myself. This makes the editing process a terrible stressor on my self-esteem. This constitutes a clear message about my values: it indicates that I value self-love, but do not love myself enough. If I was nicer to myself, then I could edit painlessly, and I want to edit painlessly.</p>\n<p>A final example will illustrate once more the connection between values and the problem of motivation. I am a psychology major and a philosophy minor. I got the psychology major at the beginning of college, and the philosophy minor two and a half years later. I enjoy my philosophy classes, and find my psychology classes tedious. It is therefore easier to be motivated to do well in my philosophy classes than in my psychology classes. I chose philosophy at a time when I better understood my values than I did at the time when I chose psychology. If I had this knowledge of my values when I started college, I could have chosen a major that I would enjoy more and do better in.</p>\n<p>I hope that the reader has found these examples illustrative. I have attempted to throw some light on the process of discovering one's values and revising one's goals to conform to these values. It seems to me that this is a basic tool of instrumental rationality. One cannot achieve one's values without knowing one's values. Furthermore, one cannot sustainably pursue anything other than one's values, and many cases of the problem of motivation can be explained by this fact.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bk3Aa2EKhu5D7BZSZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -5, "extendedScore": null, "score": 7.401497236573988e-07, "legacy": true, "legacyId": "8593", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RzdPXLd2b6qmEB2mf", "fG3g3764tSubr6xvs", "mja6jZ6k9gAwki9Nu", "sP2Hg6uPwpfp3jZJN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-12T23:33:01.304Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge (MA) third-Sundays meetup", "slug": "meetup-cambridge-ma-third-sundays-meetup-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Szd4D3tiBKZXGoPHp/meetup-cambridge-ma-third-sundays-meetup-2", "pageUrlRelative": "/posts/Szd4D3tiBKZXGoPHp/meetup-cambridge-ma-third-sundays-meetup-2", "linkUrl": "https://www.lesswrong.com/posts/Szd4D3tiBKZXGoPHp/meetup-cambridge-ma-third-sundays-meetup-2", "postedAtFormatted": "Tuesday, July 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzd4D3tiBKZXGoPHp%2Fmeetup-cambridge-ma-third-sundays-meetup-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20(MA)%20third-Sundays%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzd4D3tiBKZXGoPHp%2Fmeetup-cambridge-ma-third-sundays-meetup-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzd4D3tiBKZXGoPHp%2Fmeetup-cambridge-ma-third-sundays-meetup-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/19'>Cambridge (MA) third-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 July 2011 06:47:45PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">290 Main St # 6, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's the third Sunday of the month, so we'll be meeting at <a href=\"http://maps.google.com/maps/place?q=Cosi+restaurant+near+Kendall+Sq+Cambridge&amp;hl=en&amp;cid=2537582743464648203\" rel=\"nofollow\">Cosi</a> near Kendall Square in Cambridge.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/19'>Cambridge (MA) third-Sundays meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Szd4D3tiBKZXGoPHp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.401539427487886e-07, "legacy": true, "legacyId": "8594", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup\">Discussion article for the meetup : <a href=\"/meetups/19\">Cambridge (MA) third-Sundays meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 July 2011 06:47:45PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">290 Main St # 6, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's the third Sunday of the month, so we'll be meeting at <a href=\"http://maps.google.com/maps/place?q=Cosi+restaurant+near+Kendall+Sq+Cambridge&amp;hl=en&amp;cid=2537582743464648203\" rel=\"nofollow\">Cosi</a> near Kendall Square in Cambridge.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup1\">Discussion article for the meetup : <a href=\"/meetups/19\">Cambridge (MA) third-Sundays meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge (MA) third-Sundays meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__third_Sundays_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T00:26:22.019Z", "modifiedAt": null, "url": null, "title": "Meetup : DC Weekly Meetup is Back!", "slug": "meetup-dc-weekly-meetup-is-back", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benquo", "createdAt": "2009-03-06T00:17:35.184Z", "isAdmin": false, "displayName": "Benquo"}, "userId": "nt2XsHkdksqZ3snNr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EJAauokMS6jdxT68P/meetup-dc-weekly-meetup-is-back", "pageUrlRelative": "/posts/EJAauokMS6jdxT68P/meetup-dc-weekly-meetup-is-back", "linkUrl": "https://www.lesswrong.com/posts/EJAauokMS6jdxT68P/meetup-dc-weekly-meetup-is-back", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20DC%20Weekly%20Meetup%20is%20Back!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20DC%20Weekly%20Meetup%20is%20Back!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJAauokMS6jdxT68P%2Fmeetup-dc-weekly-meetup-is-back%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20DC%20Weekly%20Meetup%20is%20Back!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJAauokMS6jdxT68P%2Fmeetup-dc-weekly-meetup-is-back", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJAauokMS6jdxT68P%2Fmeetup-dc-weekly-meetup-is-back", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/1a\">DC Weekly Meetup Resumes</a></h2>\r\n<div class=\"meetup-meta\">\r\n<p><strong>WHEN:</strong> <span class=\"date\">17 July 2011 01:00:00PM (-0400)</span></p>\r\n<p><strong>WHERE:</strong> <span class=\"address\">Washington, DC</span></p>\r\n</div>\r\n<!-- .meta -->\r\n<div class=\"content\">\r\n<div class=\"md\">\r\n<p>Agenda is fairly light this time, mostly we'll just hang out:</p>\r\n<ul>\r\n<li>\r\n<p>Follow-Ups to New York Joint Meet-Up</p>\r\n</li>\r\n<li>\r\n<p>Plan future activities</p>\r\n</li>\r\n</ul>\r\n<p>Meetup is at a private residence. Contact Benquo for venue details.</p>\r\n</div>\r\n</div>\r\n<!-- .content -->\r\n<h2>Discussion article for the meetup : <a href=\"/meetups/1a\">DC Weekly Meetup Resumes</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EJAauokMS6jdxT68P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.401703982811835e-07, "legacy": true, "legacyId": "8595", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___DC_Weekly_Meetup_Resumes\">Discussion article for the meetup : <a href=\"/meetups/1a\">DC Weekly Meetup Resumes</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">17 July 2011 01:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Washington, DC</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Agenda is fairly light this time, mostly we'll just hang out:</p>\n<ul>\n<li>\n<p>Follow-Ups to New York Joint Meet-Up</p>\n</li>\n<li>\n<p>Plan future activities</p>\n</li>\n</ul>\n<p>Meetup is at a private residence. Contact Benquo for venue details.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___DC_Weekly_Meetup_Resumes1\">Discussion article for the meetup : <a href=\"/meetups/1a\">DC Weekly Meetup Resumes</a></h2>", "sections": [{"title": "Discussion article for the meetup : DC Weekly Meetup Resumes", "anchor": "Discussion_article_for_the_meetup___DC_Weekly_Meetup_Resumes", "level": 1}, {"title": "Discussion article for the meetup : DC Weekly Meetup Resumes", "anchor": "Discussion_article_for_the_meetup___DC_Weekly_Meetup_Resumes1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T02:41:16.696Z", "modifiedAt": null, "url": null, "title": "Some Thoughts on Singularity Strategies", "slug": "some-thoughts-on-singularity-strategies", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:53.624Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/73SotZnDbsYpxfnuQ/some-thoughts-on-singularity-strategies", "pageUrlRelative": "/posts/73SotZnDbsYpxfnuQ/some-thoughts-on-singularity-strategies", "linkUrl": "https://www.lesswrong.com/posts/73SotZnDbsYpxfnuQ/some-thoughts-on-singularity-strategies", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20Thoughts%20on%20Singularity%20Strategies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20Thoughts%20on%20Singularity%20Strategies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73SotZnDbsYpxfnuQ%2Fsome-thoughts-on-singularity-strategies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20Thoughts%20on%20Singularity%20Strategies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73SotZnDbsYpxfnuQ%2Fsome-thoughts-on-singularity-strategies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73SotZnDbsYpxfnuQ%2Fsome-thoughts-on-singularity-strategies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 808, "htmlBody": "<p>Followup to: <a href=\"/lw/6j9/outline_of_possible_singularity_scenarios_that/\">Outline of possible Singularity scenarios (that are not completely disastrous)</a></p>\n<p>Given that the <a href=\"http://wiki.lesswrong.com/wiki/Technological_singularity\">Singularity</a> and <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">being strategic</a> are popular topics around here, it's surprising there hasn't been more discussion on how to answer the question \"In what direction should we nudge the future, to maximize the chances and impact of a positive Singularity?\" (\"We\" meaning the SIAI/FHI/LW/Singularitarian community.)</p>\n<p>(Is this an appropriate way to frame the question? It's how I would instinctively frame the question, but perhaps we ought to discussed alternatives first. For example, one might be \"What quest should we embark upon to save the world?\", which seems to be the frame that Eliezer instinctively prefers. But I worry that thinking in terms of \"<a href=\"http://en.wikipedia.org/wiki/Quest\">quest</a>\" favors the part of the brain that is built mainly for signaling instead of planning. Another alternative would be \"What strategy maximizes expect utility?\" but that seems too technical for human minds to grasp on an intuitive level, and we don't have the tools to answer the question formally.)</p>\n<p>Let's start by assuming that humanity will want to build at least one Friendly superintelligence sooner or later, either from scratch, or by improving human minds, because without such an entity, it's likely that eventually either a superintelligent, <em>non</em>-Friendly entity will arise, or civilization will collapse. The current state of affairs, in which there is no intelligence greater than baseline-human level, seems unlikely to be stable over the billions of years of the universe's remaining life. (Nor does that seem particularly desirable even if it is possible.)</p>\n<p>Whether to push for (or personally head towards) de novo AI directly, or IA/uploading first, depends heavily on the expected (or more generally, subjective probability distribution of) difficulty of building a Friendly AI from scratch, which in turn involves a great deal of logical and philosophical uncertainty. (For example, if it's known that it actually takes a minimum of 10 people with IQ 200 to build a Friendly AI, then there is clearly little point in pushing for de novo AI first.)</p>\n<p>Besides the expected difficulty of building FAI from scratch, another factor that weighs heavily in the decision is the risk of accidentally building an unFriendly AI (or contributing to others building UFAIs) while trying to build FAI. Taking this into account also involves lots of logical and philosophical uncertainty. (But it seems safe to assume that this risk, if plotted against the intelligence of the AI builders, forms an inverted U shape.)</p>\n<p>Since we don't have good formal tools for dealing with logical and philosophical uncertainty, it seems hard to do better than to make some incremental improvements over gut instinct. One idea is to train our intuitions to be more accurate, for example by learning about the history of AI and philosophy, or learning known cognitive biases and doing debiasing exercises. But this seems insufficient to gap the widely differing intuitions people have on these questions.</p>\n<p>My own feeling is that the chance of success of of building FAI, assuming current human intelligence distribution, is low (even if given unlimited financial resources), while the risk of unintentionally building or contributing to UFAI is high. I think I can explicate a part of my intuition this way: There must be a minimum level of intelligence below which the chances of successfully building an FAI is negligible.&nbsp; We humans seem at best just barely smart enough to build a superintelligent UFAI. Wouldn't it be surprising that the intelligence threshold for building UFAI and FAI turn out to be the same?</p>\n<p>Given that there are known ways to significantly increase the number of geniuses (i.e., von Neumann level, or IQ 180 and greater), by cloning or embryo selection, an obvious alternative Singularity strategy is to invest directly or indirectly in these technologies, and to try to mitigate existential risks (for example by attempting to delay all significant AI efforts) until they mature and bear fruit (in the form of adult genius-level FAI researchers). Other strategies in the same vein are to pursue cognitive/pharmaceutical/neurosurgical approaches to increasing the intelligence of existing humans, or to push for brain emulation first followed by intelligence enhancement of human minds in software form.</p>\n<p>Social/PR issues aside, these alternatives make more intuitive sense to me. The chances of success seem higher, and if disaster does occur as a result of the intelligence amplification effort, we're more likely to be left with a future that is at least partly influenced by human values. (Of course, in the final analysis, we also have to consider social/PR problems, but all Singularity approaches seem to have similar problems, which can be partly ameliorated by the common sub-strategy of \"raising the general sanity level\".)</p>\n<p>I'm curious in what others think. What does your intuition say about these issues? Are there good arguments in favor of any particular strategy that I've missed? Is there another strategy that might be better than the ones mentioned above?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"pGqRLe9bFDX2G2kXY": 1, "ZFrgTgzwEfStg26JL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "73SotZnDbsYpxfnuQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 40, "extendedScore": null, "score": 7.6e-05, "legacy": true, "legacyId": "8586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["B5MBrP558Cfs2cwB5", "PBRWb2Em5SNeWYwwB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T07:11:57.387Z", "modifiedAt": null, "url": null, "title": "Two barrels problem from the Intuitive Explanation (answered)", "slug": "two-barrels-problem-from-the-intuitive-explanation-answered", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.839Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MarkusRamikin", "createdAt": "2011-06-08T11:45:41.506Z", "isAdmin": false, "displayName": "MarkusRamikin"}, "userId": "eiLDv2Z6N8zDn87mK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tcLLWKpXfBMZYWWtD/two-barrels-problem-from-the-intuitive-explanation-answered", "pageUrlRelative": "/posts/tcLLWKpXfBMZYWWtD/two-barrels-problem-from-the-intuitive-explanation-answered", "linkUrl": "https://www.lesswrong.com/posts/tcLLWKpXfBMZYWWtD/two-barrels-problem-from-the-intuitive-explanation-answered", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two%20barrels%20problem%20from%20the%20Intuitive%20Explanation%20(answered)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo%20barrels%20problem%20from%20the%20Intuitive%20Explanation%20(answered)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtcLLWKpXfBMZYWWtD%2Ftwo-barrels-problem-from-the-intuitive-explanation-answered%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two%20barrels%20problem%20from%20the%20Intuitive%20Explanation%20(answered)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtcLLWKpXfBMZYWWtD%2Ftwo-barrels-problem-from-the-intuitive-explanation-answered", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtcLLWKpXfBMZYWWtD%2Ftwo-barrels-problem-from-the-intuitive-explanation-answered", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 323, "htmlBody": "<p>I'm not sure if I'm doing something wrong here. EDIT: Yup, I'm allowing myself to be tricked.</p>\n<p>I've finally sat down to reading http://yudkowsky.net/rational/bayes carefully, and I solved all story problems so far with no trouble. However, now I'm at this one:</p>\n<blockquote>\n<p><strong style=\"font-weight: bold;\">Q.&nbsp; </strong><span style=\"font-weight: bold;\">Suppose that there are two barrels, each containing a number of plastic eggs.&nbsp; In both barrels, some eggs are painted blue and the rest are painted red.&nbsp; In the first barrel, 90% of the eggs contain pearls and 20% of the pearl eggs are painted blue.&nbsp; In the second barrel, 45% of the eggs contain pearls and 60% of the empty eggs are painted red.&nbsp; Would you rather have a blue pearl egg from the first or second barrel?</span><br style=\"font-weight: bold;\" /> <span style=\"font-weight: bold;\">A.</span>&nbsp; Actually, it doesn't matter which barrel you choose!&nbsp; Can you see why?</p>\n</blockquote>\n<p>This doesn't look right to me.</p>\n<p>In the first barrel, we have 18% blue eggs that contain pearls, and an unknown number of blue eggs that do not contain pearls, anywhere between 10% (worst case) and 0%. Depending on that, the proportion of blue eggs with pearls among all blue eggs can only be between 18/(18+10) = 64ish% in the worst case, to 100% in the best.</p>\n<p>In the second barrel, we don't know how many pearls eggs are blue. We do know there are 45% eggs with pearls altogether, therefore 55% without pearls, and out of the latter 60% are red therefore 40% are blue. That means we have 40%*55% = 22% empty blue eggs. Pearl blue eggs are anywhere between 0 and 45%, so from 0% to 45/(45+22) = 67ish%.</p>\n<p>Were we just supposed to conclude that there isn't enough information to answer that problem? But I'd say \"anywhere between 64% and 100%\" is a better shot than \"anywhere between 0% and 67%\". If I actually had to choose, and there were valuable pearls at stake, I'd choose the first barrel. Am I making some sort of a mistake?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tcLLWKpXfBMZYWWtD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.402955325969409e-07, "legacy": true, "legacyId": "8604", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T10:47:37.971Z", "modifiedAt": null, "url": null, "title": "Do not ask what rationalists should do", "slug": "do-not-ask-what-rationalists-should-do", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.464Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thakil", "createdAt": "2011-01-13T15:46:17.550Z", "isAdmin": false, "displayName": "thakil"}, "userId": "zudPgERkLSB3LSvQz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LdLLrkQfQG5xmCFbo/do-not-ask-what-rationalists-should-do", "pageUrlRelative": "/posts/LdLLrkQfQG5xmCFbo/do-not-ask-what-rationalists-should-do", "linkUrl": "https://www.lesswrong.com/posts/LdLLrkQfQG5xmCFbo/do-not-ask-what-rationalists-should-do", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20not%20ask%20what%20rationalists%20should%20do&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20not%20ask%20what%20rationalists%20should%20do%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdLLrkQfQG5xmCFbo%2Fdo-not-ask-what-rationalists-should-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20not%20ask%20what%20rationalists%20should%20do%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdLLrkQfQG5xmCFbo%2Fdo-not-ask-what-rationalists-should-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdLLrkQfQG5xmCFbo%2Fdo-not-ask-what-rationalists-should-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 360, "htmlBody": "<p>Recently there has been a couple of articles in the discussion page asking whether rationalists should do action A. Now such questions are not uninteresting, but by saying \"rationalist\" they are poorly phrased.</p>\n<p>The rational decision at any time is the decision, given a human with a specific utility function B, and information C, should make to maximise B, given their knowledge (and knowledge about their knowledge) of C. It's not a decision a rationalist should make, it's a decision any human should make. If Omega popped into existence and carefully explained why action A is the best thing for this human to do given their function B, and their information C, then said human should agree.</p>\n<p>The important question is not what a rationalist should do, but what your utility function and current information is. This is a more difficult question. Humans are often wrong about what they want in the long term, and it's questionable how much we should value happiness now over happiness in the future (in particular, I suspect current and future me might disagree on this point). Quantifying our current information is also rather hard- we are going to make bad probability estimates, if we can make them at all, which lead us into incorrect decisions just because we haven't considered the evidence carefully enough.</p>\n<p>Why is this an important semantic difference? Well it's important for the cause of refining rationality that we don't get caught with associating the notion of rationality with certain goals. Some rationalists believe that they want to save the world, and the best way to do it is by creating friendly AI. This is because they have certain utility functions, and certain beliefs about the probabilities of the singularity. Not all rationalists have these utility functions. Some just want to have a happy home life, meet someone nice, and raise a family. These are different goals, and they can be helped by rationality, because rationality IS the art of winning. Being able to clearly state ones goals and work out the best way to acheieve them is useful pretty much no matter what those goals are. (pretty much to prevent silly examples here!)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LdLLrkQfQG5xmCFbo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 34, "extendedScore": null, "score": 7.403620891687863e-07, "legacy": true, "legacyId": "8612", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T12:00:30.053Z", "modifiedAt": null, "url": null, "title": "[Link] Computer improves its Civilization II gameplay by reading the manual", "slug": "link-computer-improves-its-civilization-ii-gameplay-by", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:56.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fJ7CDDHFZDnz8TjdE/link-computer-improves-its-civilization-ii-gameplay-by", "pageUrlRelative": "/posts/fJ7CDDHFZDnz8TjdE/link-computer-improves-its-civilization-ii-gameplay-by", "linkUrl": "https://www.lesswrong.com/posts/fJ7CDDHFZDnz8TjdE/link-computer-improves-its-civilization-ii-gameplay-by", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Computer%20improves%20its%20Civilization%20II%20gameplay%20by%20reading%20the%20manual&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Computer%20improves%20its%20Civilization%20II%20gameplay%20by%20reading%20the%20manual%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ7CDDHFZDnz8TjdE%2Flink-computer-improves-its-civilization-ii-gameplay-by%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Computer%20improves%20its%20Civilization%20II%20gameplay%20by%20reading%20the%20manual%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ7CDDHFZDnz8TjdE%2Flink-computer-improves-its-civilization-ii-gameplay-by", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ7CDDHFZDnz8TjdE%2Flink-computer-improves-its-civilization-ii-gameplay-by", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1224, "htmlBody": "<p><a href=\"http://web.mit.edu/newsoffice/2011/language-from-games-0712.html\">Press release</a></p>\n<blockquote>\n<p>Computers are great at treating words as data: Word-processing programs  let you rearrange and format text however you like, and search engines  can quickly find a word anywhere on the Web. But what would it mean for a  computer to actually understand the meaning of a sentence written in  ordinary English &mdash; or French, or Urdu, or Mandarin? <br /><br /> One test  might be whether the computer could analyze and follow a set of  instructions for an unfamiliar task. And indeed, in the last few years,  researchers at MIT&rsquo;s Computer Science and Artificial Intelligence Lab  have begun designing machine-learning systems that do exactly that, with  surprisingly good results. <br /><br /> In 2009, at the annual meeting of  the Association for Computational Linguistics (ACL), researchers in the  lab of Regina Barzilay, associate professor of computer science and  electrical engineering, took the best-paper award for a system that  generated scripts for installing a piece of software on a Windows  computer by reviewing instructions posted on Microsoft&rsquo;s help site. At  this year&rsquo;s ACL meeting, Barzilay, her graduate student S. R. K.  Branavan and David Silver of University College London applied a similar  approach to a more complicated problem: learning to play  &ldquo;Civilization,&rdquo; a computer game in which the player guides the  development of a city into an empire across centuries of human history.  When the researchers augmented a machine-learning system so that it  could use a player&rsquo;s manual to guide the development of a game-playing  strategy, its rate of victory jumped from 46 percent to 79 percent. <br /><br /> <strong>Starting from scratch</strong> <br /><br /> &ldquo;Games are used as a test bed for artificial-intelligence techniques  simply because of their complexity,&rdquo; says Branavan, who was first author  on both ACL papers. &ldquo;Every action that you take in the game doesn&rsquo;t  have a predetermined outcome, because the game or the opponent can  randomly react to what you do. So you need a technique that can handle  very complex scenarios that react in potentially random ways.&rdquo;  <br /><br /> Moreover, Barzilay says, game manuals have &ldquo;very open text. They don&rsquo;t  tell you how to win. They just give you very general advice and  suggestions, and you have to figure out a lot of other things on your  own.&rdquo; Relative to an application like the software-installing program,  Branavan explains, games are &ldquo;another step closer to the real world.&rdquo; <br /><br /> The extraordinary thing about Barzilay and Branavan&rsquo;s system is that it  begins with virtually no prior knowledge about the task it&rsquo;s intended  to perform or the language in which the instructions are written. It has  a list of actions it can take, like right-clicks or left-clicks, or  moving the cursor; it has access to the information displayed on-screen;  and it has some way of gauging its success, like whether the software  has been installed or whether it wins the game. But it doesn&rsquo;t know what  actions correspond to what words in the instruction set, and it doesn&rsquo;t  know what the objects in the game world represent. <br /><br /> So  initially, its behavior is almost totally random. But as it takes  various actions, different words appear on screen, and it can look for  instances of those words in the instruction set. It can also search the  surrounding text for associated words, and develop hypotheses about what  actions those words correspond to. Hypotheses that consistently lead to  good results are given greater credence, while those that consistently  lead to bad results are discarded. <br /><br /> <strong>Proof of concept </strong><br /><br /> In the case of software installation, the system was able to reproduce  80 percent of the steps that a human reading the same instructions would  execute. In the case of the computer game, it won 79 percent of the  games it played, while a version that didn't rely on the written  instructions won only 46 percent. The researchers also tested a  more-sophisticated machine-learning algorithm that eschewed textual  input but used additional techniques to improve its performance. Even  that algorithm won only 62 percent of its games.<br /><br /> &ldquo;If you&rsquo;d asked  me beforehand if I thought we could do this yet, I&rsquo;d have said no,&rdquo;  says Eugene Charniak, University Professor of Computer Science at Brown  University. &ldquo;You are building something where you have very little  information about the domain, but you get clues from the domain itself.&rdquo;   <br /><br /> Charniak points out that when the MIT researchers presented  their work at the ACL meeting, some members of the audience argued that  more sophisticated machine-learning systems would have performed better  than the ones to which the researchers compared their system. But,  Charniak adds, &ldquo;it&rsquo;s not completely clear to me that that&rsquo;s really  relevant. Who cares? The important point is that this was able to  extract useful information from the manual, and that&rsquo;s what we care  about.&rdquo; <br /><br /> Most computer games as complex as &ldquo;Civilization&rdquo;  include algorithms that allow players to play against the computer,  rather than against other people; the games&rsquo; programmers have to develop  the strategies for the computer to follow and write the code that  executes them. Barzilay and Branavan say that, in the near term, their  system could make that job much easier, automatically creating  algorithms that perform better than the hand-designed ones.  <br /><br /> But the main purpose of the project, which was supported by the National  Science Foundation, was to demonstrate that computer systems that learn  the meanings of words through exploratory interaction with their  environments are a promising subject for further research. And indeed,  Barzilay and her students have begun to adapt their meaning-inferring  algorithms to work with robotic systems.</p>\n</blockquote>\n<p><a href=\"http://people.csail.mit.edu/regina/my_papers/civ11.pdf\">The actual paper</a></p>\n<blockquote>\n<p>Abstract<br /><br />This paper presents a novel approach for leveraging automatically extracted textual knowledge to improve the performance of control applications such as games. Our ultimate goal is to enrich a stochastic player with highlevel guidance expressed in text. Our model jointly learns to identify text that is relevant to a given game state in addition to learning game strategies guided by the selected text. Our method operates in the Monte-Carlo search framework, and learns both text analysis and game strategies based only on environment feedback. We apply our approach to the complex strategy game Civilization II using the official game manual as the text guide. Our results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 27% absolute improvement and winning over 78% of games when playing against the builtin AI of Civilization II.</p>\n</blockquote>\n<p>The team has been rather exemplary when it comes to scientific openness: \"The code, data and complete experimental setup for this work are available at <a href=\"http://groups.csail.mit.edu/rbg/code/civ\">http://groups.csail.mit.edu/rbg/code/civ</a> .\" And although I haven't downloaded it because it's a 1,1 gigabyte file, the page appears to contain <em>a virtual machine with everything you need to actually run the experiment. </em>I was expecting to a see a bunch of different, poorly documented files that you would have a hell of a time running if you didn't have exactly the same system as the researchers, so this was quite a pleasant surprise. (Of course, if I downloaded the VM it could be that it's still exactly that bad. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "ksdiAMKfgSyEeKMo6": 1, "fpEBgFE7fgpxTm9BF": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fJ7CDDHFZDnz8TjdE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 49, "extendedScore": null, "score": 0.000145, "legacy": true, "legacyId": "8613", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T20:25:11.381Z", "modifiedAt": null, "url": null, "title": "What are some inspiring biographies of people for us LessWrong types?", "slug": "what-are-some-inspiring-biographies-of-people-for-us", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:04.286Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2o5y5c9ST7pn23H7m/what-are-some-inspiring-biographies-of-people-for-us", "pageUrlRelative": "/posts/2o5y5c9ST7pn23H7m/what-are-some-inspiring-biographies-of-people-for-us", "linkUrl": "https://www.lesswrong.com/posts/2o5y5c9ST7pn23H7m/what-are-some-inspiring-biographies-of-people-for-us", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20some%20inspiring%20biographies%20of%20people%20for%20us%20LessWrong%20types%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20some%20inspiring%20biographies%20of%20people%20for%20us%20LessWrong%20types%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2o5y5c9ST7pn23H7m%2Fwhat-are-some-inspiring-biographies-of-people-for-us%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20some%20inspiring%20biographies%20of%20people%20for%20us%20LessWrong%20types%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2o5y5c9ST7pn23H7m%2Fwhat-are-some-inspiring-biographies-of-people-for-us", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2o5y5c9ST7pn23H7m%2Fwhat-are-some-inspiring-biographies-of-people-for-us", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p>So like many LWers, I'm primarily interested in what Robin Hanson calls \"foragers\", as opposed to \"farmers\". By LW standards, even most Nobel laureates are \"farmers\".</p>\n<p>However, there are some exceptions (and some farmers can be interesting, too).</p>\n<p>Anyways, which ones are your favorites? I'm starting to *really* like all the biographies of Watson and Crick (especially Olby's biography of Crick), since they were both iconoclastic foragers (Crick, in fact, seems uncannily similar to Feynman). Crick also has an autobiography but it isn't that insightful about his life.</p>\n<p>And then there are the Feynman and Einstein biographies - Olby's biography of Feynman being the prototypical example. I'm checking out an Einstein biography right now - I'll see how that goes.</p>\n<p>Among people who are especially underrated - I think Herbert Simon's autobiography (http://www.amazon.com/Models-My-Life-Herbert-Simon/dp/026269185X/ref=sr_1_3?ie=UTF8&amp;qid=1310586938&amp;sr=8-3 ) might be particularly interesting. I just checked it out from the library.</p>\n<p>Then there's Elizier Yudowsky's autobiography.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2o5y5c9ST7pn23H7m", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 1, "extendedScore": null, "score": 7.405403727157574e-07, "legacy": true, "legacyId": "8614", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T21:37:43.133Z", "modifiedAt": null, "url": null, "title": "Why is there variation in species?", "slug": "why-is-there-variation-in-species-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:49.718Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "zRwEwWNXmoTPueowb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uME8bAECWFs3hsR8f/why-is-there-variation-in-species-0", "pageUrlRelative": "/posts/uME8bAECWFs3hsR8f/why-is-there-variation-in-species-0", "linkUrl": "https://www.lesswrong.com/posts/uME8bAECWFs3hsR8f/why-is-there-variation-in-species-0", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20is%20there%20variation%20in%20species%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20is%20there%20variation%20in%20species%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuME8bAECWFs3hsR8f%2Fwhy-is-there-variation-in-species-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20is%20there%20variation%20in%20species%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuME8bAECWFs3hsR8f%2Fwhy-is-there-variation-in-species-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuME8bAECWFs3hsR8f%2Fwhy-is-there-variation-in-species-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 209, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This may be a question trivial for you, but: Why is there variation inside a species? On some instances, you could argue that the Nash equilibrum is mixed (for example, different men prefer different physical appearances of women, so women of different appearance can coexist), but: What the hell is the evolutionary advantage in having zits?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Probably, it has something to do with genes of different types (all of whom have a good reason to stay in the gene pool by a mixed Nash equilibrium) mixing up and producing zits, but: Why should evolution, that managed to create eyes and brains, be unable to get something against this working if other members of the same species can perfectly manage to avoid them? Because such a gene can easily exist in individuals that don't have that particular problem (and I can't think of any adverse effects this would have), it should be able to spread even if not all members of the species have a particular problem. The disturbing thing is that I imagine a working fix without adverse effects to require only pulling some hormonal levers, not coming up with the complication that is needed to make a proto-eye better by a positive amount (so that the mutation can survive).</p>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uME8bAECWFs3hsR8f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": -1, "extendedScore": null, "score": 7.40562766805242e-07, "legacy": true, "legacyId": "8617", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-13T21:48:32.698Z", "modifiedAt": null, "url": null, "title": "\"A good volunteer is hard to find\"", "slug": "a-good-volunteer-is-hard-to-find", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:35.778Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZWxE96G84m6LotXfg/a-good-volunteer-is-hard-to-find", "pageUrlRelative": "/posts/ZWxE96G84m6LotXfg/a-good-volunteer-is-hard-to-find", "linkUrl": "https://www.lesswrong.com/posts/ZWxE96G84m6LotXfg/a-good-volunteer-is-hard-to-find", "postedAtFormatted": "Wednesday, July 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22A%20good%20volunteer%20is%20hard%20to%20find%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22A%20good%20volunteer%20is%20hard%20to%20find%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWxE96G84m6LotXfg%2Fa-good-volunteer-is-hard-to-find%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22A%20good%20volunteer%20is%20hard%20to%20find%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWxE96G84m6LotXfg%2Fa-good-volunteer-is-hard-to-find", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWxE96G84m6LotXfg%2Fa-good-volunteer-is-hard-to-find", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 397, "htmlBody": "<p>From the <a href=\"http://blog.givewell.org/\">GiveWell blog</a>, which is often interesting &amp; applicable to our interests, comes <a href=\"http://blog.givewell.org/2011/07/13/a-good-volunteer-is-hard-to-find/\">a post on the quality of their volunteers</a>:</p>\n<blockquote>\n<p>\"In our experience, valuable volunteers are rare. The people who email us about volunteer opportunities generally seem enthusiastic about GiveWell&rsquo;s mission, and motivated by a shared belief in our goals to give up their free time to help us. Yet, the majority of these people never complete useful work for us.</p>\n<p>We ask new volunteers to first complete a test assignment that takes about 2-4 hours. The assignment involves fixing the formatting of our list of sources on two practice pages and allows us to get a sense of their attention to detail and commitment to volunteer hours. Of the 34 people who emailed us expressing an interest in volunteering between September 2010 (when we started keeping track) and May 2011, only 7 have completed the test assignment and gone on to complete valuable work for us.</p>\n<p>Of the 34, 10 never responded to my email outlining what GiveWell volunteers do and asking them if they&rsquo;d like me to send the first assignment. 13 responded to this email and I sent them the first assignment, but they didn&rsquo;t complete it. The final 4 completed the test assignment, but didn&rsquo;t send back the next (real) assignment I sent.</p>\n<p>It seems rather surprising that almost 80% of people who take the initiative to seek us out and ask for unpaid work fail to complete a single assignment. But maybe this shouldn&rsquo;t be surprising. Writing an email is quick and exciting; spending a few hours fixing punctuation is not.\"</p>\n</blockquote>\n<p>(The dropout rate is probably not due to the perceived low utility of the work - GiveWell seems to be up-front that the test assignment is a test.)</p>\n<p>I draw a few lessons from this:</p>\n<ul>\n<li>there is likely low-hanging fruit for volunteers in charities or communities in the area of sustained tedious tasks; collecting anecdotes, reports, links, that sort of thing come to mind as LW examples</li>\n<li>additional incentives like <a href=\"/lw/69p/prize_new_contest_for_spaced_repetition/\">jsalvatier's contests</a> may be necessary to draw out community volunteer resources</li>\n<li>tricking volunteers into work might be a fruitful approach - perhaps asking for explicit pointers to research or other help might not work, but presenting a half-complete version will elicit useful responses one can mine. (A more productive kind of trolling.)</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZWxE96G84m6LotXfg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 28, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "8618", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uR4r3eZZqLmjZDqFj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T01:23:49.238Z", "modifiedAt": null, "url": null, "title": "Stanford Prison Retrospective", "slug": "stanford-prison-retrospective", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.402Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Prismattic", "createdAt": "2010-12-25T22:57:35.560Z", "isAdmin": false, "displayName": "Prismattic"}, "userId": "S374FemeqCtr35dEk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kcgzp3TANTwbbcXBf/stanford-prison-retrospective", "pageUrlRelative": "/posts/kcgzp3TANTwbbcXBf/stanford-prison-retrospective", "linkUrl": "https://www.lesswrong.com/posts/kcgzp3TANTwbbcXBf/stanford-prison-retrospective", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stanford%20Prison%20Retrospective&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStanford%20Prison%20Retrospective%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkcgzp3TANTwbbcXBf%2Fstanford-prison-retrospective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stanford%20Prison%20Retrospective%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkcgzp3TANTwbbcXBf%2Fstanford-prison-retrospective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkcgzp3TANTwbbcXBf%2Fstanford-prison-retrospective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p>This year is the 40th anniversary of the Stanford Prison Experiment. &nbsp;I found this [retrospective](<a href=\"http://www.stanfordalumni.org/news/magazine/2011/julaug/features/spe.html\">http://www.stanfordalumni.org/news/magazine/2011/julaug/features/spe.html</a>)&nbsp;interesting. &nbsp;What really caught my eye is that, to some degree, it contradicts the main lesson of the experiment -- that context more than character determines behavior. &nbsp;If David Eschelman is accurately/truthfully recalling his role, then it seems like his individual character actually did play a role in how quickly things spiralled out of control (though the willingness of the other guards to go along with him supports the original conclusion).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zcvsZQWJBFK6SxK4K": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kcgzp3TANTwbbcXBf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.406325856060841e-07, "legacy": true, "legacyId": "8620", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T05:59:21.985Z", "modifiedAt": null, "url": null, "title": "Meetup : Bangalore: August Meetup", "slug": "meetup-bangalore-august-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "subod_83", "createdAt": "2010-02-11T06:26:26.082Z", "isAdmin": false, "displayName": "subod_83"}, "userId": "QjJT5JQosAijrPdiN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ugowWhYG2XXnSTeDc/meetup-bangalore-august-meetup", "pageUrlRelative": "/posts/ugowWhYG2XXnSTeDc/meetup-bangalore-august-meetup", "linkUrl": "https://www.lesswrong.com/posts/ugowWhYG2XXnSTeDc/meetup-bangalore-august-meetup", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bangalore%3A%20August%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bangalore%3A%20August%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FugowWhYG2XXnSTeDc%2Fmeetup-bangalore-august-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bangalore%3A%20August%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FugowWhYG2XXnSTeDc%2Fmeetup-bangalore-august-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FugowWhYG2XXnSTeDc%2Fmeetup-bangalore-august-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1b'>Bangalore: August Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 August 2011 04:00:00PM (+0530)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Koshy's Parade Cafe, St Marks Rd, Bengaluru, Karnataka, India</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>During our previous meetup we decided that the August meetup would be more structured and that the members attending would read one or more Sequences. For more details please join the facebook group \"Less Wrong Bangalore\".</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1b'>Bangalore: August Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ugowWhYG2XXnSTeDc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.407176880394813e-07, "legacy": true, "legacyId": "8628", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bangalore__August_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1b\">Bangalore: August Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 August 2011 04:00:00PM (+0530)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Koshy's Parade Cafe, St Marks Rd, Bengaluru, Karnataka, India</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>During our previous meetup we decided that the August meetup would be more structured and that the members attending would read one or more Sequences. For more details please join the facebook group \"Less Wrong Bangalore\".</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bangalore__August_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1b\">Bangalore: August Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bangalore: August Meetup", "anchor": "Discussion_article_for_the_meetup___Bangalore__August_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Bangalore: August Meetup", "anchor": "Discussion_article_for_the_meetup___Bangalore__August_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T08:03:13.602Z", "modifiedAt": null, "url": null, "title": "Yet another cognitive biases book", "slug": "yet-another-cognitive-biases-book", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.847Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ce4gmYY4BZytLkeCT/yet-another-cognitive-biases-book", "pageUrlRelative": "/posts/ce4gmYY4BZytLkeCT/yet-another-cognitive-biases-book", "linkUrl": "https://www.lesswrong.com/posts/ce4gmYY4BZytLkeCT/yet-another-cognitive-biases-book", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Yet%20another%20cognitive%20biases%20book&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYet%20another%20cognitive%20biases%20book%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fce4gmYY4BZytLkeCT%2Fyet-another-cognitive-biases-book%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Yet%20another%20cognitive%20biases%20book%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fce4gmYY4BZytLkeCT%2Fyet-another-cognitive-biases-book", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fce4gmYY4BZytLkeCT%2Fyet-another-cognitive-biases-book", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<p class=\"parseasinTitle\">I found this one because I'm on Sam Harris's email list.</p>\n<p class=\"parseasinTitle\"><span id=\"btAsinTitle\"><em>Brain Bugs: How the Brain's Flaws Shape Our Lives</em> by Dean Buonomano</span></p>\n<p class=\"parseasinTitle\"><span><a href=\"http://www.amazon.com/dp/0393076024/\">(Amazon.com link)</a></span></p>\n<p class=\"parseasinTitle\">The preview didn't really give me all that good an impression... it mostly seemed to be stuff I already knew or sort-of knew. It feels easy to read; not dense like a textbook or GEB, but sort of information-light. Anyone else have any impressions?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ce4gmYY4BZytLkeCT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.407559479268521e-07, "legacy": true, "legacyId": "8636", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T14:35:57.919Z", "modifiedAt": null, "url": null, "title": "Cognitive Load from simple computations", "slug": "cognitive-load-from-simple-computations", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.918Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hv9geFW46z9YT84vn/cognitive-load-from-simple-computations", "pageUrlRelative": "/posts/Hv9geFW46z9YT84vn/cognitive-load-from-simple-computations", "linkUrl": "https://www.lesswrong.com/posts/Hv9geFW46z9YT84vn/cognitive-load-from-simple-computations", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cognitive%20Load%20from%20simple%20computations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACognitive%20Load%20from%20simple%20computations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHv9geFW46z9YT84vn%2Fcognitive-load-from-simple-computations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cognitive%20Load%20from%20simple%20computations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHv9geFW46z9YT84vn%2Fcognitive-load-from-simple-computations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHv9geFW46z9YT84vn%2Fcognitive-load-from-simple-computations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 300, "htmlBody": "<p><a href=\"http://esr.ibiblio.org/?p=3481#comment-314050\">From Ken Burnside, a game designer</a></p>\n<blockquote>\n<p>Counting is easier than addition.</p>\n<p>Addition is easier than subtraction.</p>\n<p>Subtraction can be done, but combining addition and subtraction into the same game mechanic will slow down play considerably. (&ldquo;I have +2 for flanking, and -2 for lighting&hellip;&rdquo;) is surprisingly fiddly in play.</p>\n<p><br />BIG GAP HERE</p>\n<p><br />Subtraction and addition in the same operation is easier than most forms of multiplication. For example, it&rsquo;s better to express a critical hit as &ldquo;+100% damage&rdquo; rather than &ldquo;x2&Prime; damage. Not only does it avoid edge cases (where you have two critical hit multipliers that both apply) it&rsquo;s faster at the gaming table because it&rsquo;s addition.</p>\n<p>Multiplication by 10, 5, 4 and 2 are light weight enough to be usable. If you&rsquo;re using a multiplicative operator other than one of those four digits, you need to change something earlier in the process. When in doubt, make it addition.</p>\n<p><br />BIGGER GAP HERE</p>\n<p><br />Division is only tolerable when A) you&rsquo;re dividing an integer and expect an integer outcome, or are rounding to an integer outcome, and B) the divisor is 2 or 10. I specifically built some parts of my games for modulus division to avoid these problem.</p>\n<p><br />GINORMOUS GAP HERE</p>\n<p><br />Square roots, cube roots and exponentiation are probably not game friendly to most people. When in doubt, transform your equations to use one of the first two items on this list.</p>\n</blockquote>\n<p>My impression is that Ken's games are geeky, so it's reasonable to assume his players are more adept with arithmetic than most people. I'm posting this because it might be worth knowing for anyone who's trying to explain something that involves numbers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hv9geFW46z9YT84vn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 15, "extendedScore": null, "score": 7.408772866053389e-07, "legacy": true, "legacyId": "8637", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T15:00:39.942Z", "modifiedAt": null, "url": null, "title": "Rationalist approach to developing Writing skills", "slug": "rationalist-approach-to-developing-writing-skills", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:39.025Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FiftyTwo", "createdAt": "2011-03-21T03:38:33.142Z", "isAdmin": false, "displayName": "FiftyTwo"}, "userId": "BZL3TWZXx2wyptxeJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NK78ywPFjsv3pmpji/rationalist-approach-to-developing-writing-skills", "pageUrlRelative": "/posts/NK78ywPFjsv3pmpji/rationalist-approach-to-developing-writing-skills", "linkUrl": "https://www.lesswrong.com/posts/NK78ywPFjsv3pmpji/rationalist-approach-to-developing-writing-skills", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20approach%20to%20developing%20Writing%20skills&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20approach%20to%20developing%20Writing%20skills%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNK78ywPFjsv3pmpji%2Frationalist-approach-to-developing-writing-skills%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20approach%20to%20developing%20Writing%20skills%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNK78ywPFjsv3pmpji%2Frationalist-approach-to-developing-writing-skills", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNK78ywPFjsv3pmpji%2Frationalist-approach-to-developing-writing-skills", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p>The ability to write&nbsp;efficiently&nbsp;and persuasively is important in many areas of life, and especially for spreading rationalist memes and hence raising the sanity waterline.&nbsp;</p>\n<p>While there are a lot of very good and persuasive writers of both fiction and non-fiction on Less Wrong there seems to be relatively little advice on how to improve one's writing skills.</p>\n<p>While there are a huge number of writing guides available, much like <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/ \">general self help</a>&nbsp;they rarely reference studies on the&nbsp;effectiveness&nbsp;of the advice contained, and while some come from very successful authors, the problems of <a href=\"/lw/dr/generalizing_from_one_example/\">generalising from one example</a> are well known. &nbsp;</p>\n<p>Given this, would people be willing to supply rationalist supported strategies for improving writing skills?</p>\n<p>&nbsp;</p>\n<p><strong>Notes</strong>,</p>\n<p>I've looked for previous posts on this subject, but if I have missed a previous good discussion please link to it and I will close this thread.</p>\n<p>The most obvious&nbsp;piece&nbsp;of advice would be to engage in large amounts of writing practice, but hopefully you will be able to supply some more strategic advice than that.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Edit,</strong></p>\n<p>Consensus so far is that a high level of practice is very important, ideally paired with useful and continuous feedback. Otherwise a general agreement that the process is very idiosyncratic, with a few good suggestions for resources that have worked for individuals.</p>\n<p>Ideally we'd be looking for advice that has helped a large majority of people to have tried it, if any such exists.&nbsp;</p>\n<p><em>(Also added links)</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NK78ywPFjsv3pmpji", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.408849190851366e-07, "legacy": true, "legacyId": "8621", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg", "baTWMegR42PAsH9qJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T16:06:38.458Z", "modifiedAt": null, "url": null, "title": "Smart, (young), ambitious and clueless -- what to do to maximize goodness?", "slug": "smart-young-ambitious-and-clueless-what-to-do-to-maximize", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.101Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Caesium", "createdAt": "2011-07-02T20:02:40.897Z", "isAdmin": false, "displayName": "Caesium"}, "userId": "NNAEtfeoLTu6hfYtj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oFY8Ms83ehXgRMh32/smart-young-ambitious-and-clueless-what-to-do-to-maximize", "pageUrlRelative": "/posts/oFY8Ms83ehXgRMh32/smart-young-ambitious-and-clueless-what-to-do-to-maximize", "linkUrl": "https://www.lesswrong.com/posts/oFY8Ms83ehXgRMh32/smart-young-ambitious-and-clueless-what-to-do-to-maximize", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Smart%2C%20(young)%2C%20ambitious%20and%20clueless%20--%20what%20to%20do%20to%20maximize%20goodness%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASmart%2C%20(young)%2C%20ambitious%20and%20clueless%20--%20what%20to%20do%20to%20maximize%20goodness%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFY8Ms83ehXgRMh32%2Fsmart-young-ambitious-and-clueless-what-to-do-to-maximize%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Smart%2C%20(young)%2C%20ambitious%20and%20clueless%20--%20what%20to%20do%20to%20maximize%20goodness%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFY8Ms83ehXgRMh32%2Fsmart-young-ambitious-and-clueless-what-to-do-to-maximize", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFY8Ms83ehXgRMh32%2Fsmart-young-ambitious-and-clueless-what-to-do-to-maximize", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 383, "htmlBody": "<p>You're smart, want to help the world and are willing to work hard. You have no serious ties such as children or a marriage that would prevent you from making serious changes to your life, and you are willing to place others needs ahead of your own hedonistic desires. <em>Given this, what should you do?</em></p>\n<p>Should you aim to get involved personally with causes you feel passionately about? You can have greater control over your contribution if you do this, but can you achieve the most good in this way? Should you operate at a meta-level, such as by trying to convince other people to change their charitable giving, attempting to influence government policy, or by raising awareness of existential risks, or should you try and directly tackle the problems facing the world -- such as by donating money yourself, or by tackling open problems in friendly AI?</p>\n<p>Once you've figured out what to do, you still have to find a way to support yourself, and fund any organizations or projects you wish to support. You could work for an existing organization active in the area that you are interested in - bearing in mind that ones contribution will only be the <em>benefit</em> of hiring you rather than the next-best guy. Or you could work in a completely unrelated job, and work part-time on the cause you are interested in; this is a route followed by many open source developers, e.g. the prolific <a href=\"http://www.bellard.org/\">Fabrice Bellard</a>. Alternatively, you could aim to earn as much money as possible, and use this money to fund causes or projects you are interested in; this is the route followed by <a href=\"http://en.wikipedia.org/wiki/Jeff_Hawkins#Neuroscience\">Jeff Hawkins</a>, who founded Palm, Inc. in order to fund AI and neuroscience research, as well as notable philantropists such as <a href=\"http://en.wikipedia.org/wiki/Gates_Foundation\">Bill Gates</a> and <a href=\"http://en.wikipedia.org/wiki/Warren_Buffet\">Warren Buffet</a>.</p>\n<p>The problem is a simple one: how should one lead ones life in order to maximize the positive impact it has on others? There is an ample amount of data to draw from, such as charity rankings by GiveWell, salary data and personal experience. If rationality has any real-world benefits, then a discussion amongst rationalists should make it possible for substantially better decisions to be made than would otherwise be the case.</p>\n<h3>References</h3>\n<p><a href=\"http://www.xrisknetwork.com/\">Existential Risk Reduction Careers Network</a></p>\n<p><a href=\"http://thielfoundation.org/index.php?option=com_content&amp;view=article&amp;id=15&amp;Itemid=19\">Thiel Fellows</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Happiness_economics#Money\">Income and happiness (Wikipedia)</a></p>\n<p><a href=\"http://www.givewell.org/international/technical/criteria/cost-effectiveness#Howcosteffectiveiscosteffective\">Cost effectiveness of aid (GiveWell)</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oFY8Ms83ehXgRMh32", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 8, "extendedScore": null, "score": 7.409053063056558e-07, "legacy": true, "legacyId": "8638", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T19:41:24.797Z", "modifiedAt": null, "url": null, "title": "Rationality Market Research", "slug": "rationality-market-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.154Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ousEiGAmLEoJq2Reb/rationality-market-research", "pageUrlRelative": "/posts/ousEiGAmLEoJq2Reb/rationality-market-research", "linkUrl": "https://www.lesswrong.com/posts/ousEiGAmLEoJq2Reb/rationality-market-research", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Market%20Research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Market%20Research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FousEiGAmLEoJq2Reb%2Frationality-market-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Market%20Research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FousEiGAmLEoJq2Reb%2Frationality-market-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FousEiGAmLEoJq2Reb%2Frationality-market-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2089, "htmlBody": "<p>Several weeks ago, the NYC&nbsp; Rationality&nbsp;Meetup Group began discussing outreach, both for&nbsp; rationality&nbsp;in general and the group in particular. A lot of interesting problems were brought up. Should we be targeting the average person, or sticking to the cluster of personality-types that Less Wrong already attracts? How quickly should we introduce people to our community? What are the most effective ways to spread the&nbsp;<em style=\"font-style: italic; \">idea&nbsp;</em>of&nbsp; rationality, and what are the most effective ways of actually encouraging people to undertake rational actions?</p>\n<p>Those are all complex questions with complex answers, which are beyond the scope of this post. I ended up focusing on the question: \"Is ' Rationality' the word we want to use when we're pitching ourselves?\" I do not think it's worthwhile to try and change the central meme of the Less Wrong community, but it's not obvious that the new, realspace communities forming need to use the same central meme.&nbsp;</p>\n<p>This begat a simpler question: \"What does the average person think of when they hear the word ' Rationality?' What positive or negative connotations does it have?\" Do they think of straw vulcans and robots? Do they think of effective programmers or businessmen? Armed with this knowledge, we can craft a rationalist pitch that is likely to be effective at the average person, either by challenging their conception of&nbsp; rationality&nbsp;or by bypassing keywords that might set off memetic immune systems.</p>\n<p><a id=\"more\"></a></p>\n<p>This question has an empirical answer. A few weeks ago I made some effort to answer it. I did not get a huge array of data, but I got enough that I thought I should share it, and I'd encourage others to go out and find their own data points. Ideally someone would make a website that somehow sorts that data (and in the process hopefully get a more structured experimental setup, since mine was rather freeform.)</p>\n<p>I work in a tall office building in NYC. Each day, I ride an elevator up to the 30th floor. At least some of those times, I find myself alone with people for 30 seconds. I started asking those people what they thought about \" Rationality.\" My first encounter went like this:</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><strong>Subject: Female Asian Approx 30</strong></div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Me: \"Excuse me, I was wondering, when I say the word \" Rationality\" what images and feelings immediately come to mind?</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman: (Neutral but curious expression) \" Rationality?\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Me: If someone were to describe themselves as a Rationalist, what would you assume about them?</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman: Well Rationalism sounds like a particular philosophy I haven't heard of, but&nbsp; Rationality&nbsp;just sounds like... (doesn't use a word but has an expression that seemed to indicate \" Rationality&nbsp;is common sense, everyone uses that\")</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Me: That's pretty much it. A rationalist is just someone trying their best to act Rational.</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman: \"Oh.\" (Elevator opens, she departed with an expression suggesting neutral-postive-ish feelings, confused as to why the question was a big deal)</div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">Over the next few subjects, I adjusted my starter-question to get to the point faster. I'm including all the data for completeness sake, but if other people want to help with this, I recommend using the question I eventually settled on.&nbsp;The rest of my encounters went as follows (if the conversation ends abruptly, assume the elevator door opened and the person stepped out).&nbsp;Afterwards I'll share some thoughts.</div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n<div style=\"margin-bottom: 1em; \"><strong><em>Subject: Female, 70s, White</em></strong></div>\n<div style=\"margin-bottom: 1em; \"><em>(This is my conversation with my Grandmother, a musician and therapist who was helping me write a Rational Humanist song. We'd just had a lengthy conversation about my beliefs. I asked her to pretend we hadn't had that conversation and answer the question)</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Me: What do you think of when you hear the word&nbsp; Rationality? What would you think of someone who identified as a Rationalist?</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Her: I mostly think of clients [in Therapy] who try too hard to distance themselves from their emotions.&nbsp;</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Me: Does it remind you of \"Spock\" from Star Trek?</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Her: He's not really what comes to my mind, but I think people who obsess over&nbsp; rationality&nbsp;are out of touch with their emotions.</em></div>\n<div style=\"margin-bottom: 1em; \"><em>(In this particular case I had the time to discuss the issue in detail and clarify that&nbsp; rationality&nbsp;can mean being more, not less, in touch with your emotions)</em></div>\n<div style=\"margin-bottom: 1em; \"><em><br /></em></div>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \"><strong><em>Subject: Male, early 30s (Italian? There's a cluster of ethnicities I have trouble distinguishing between. Not sure if it matters anyway)</em></strong></div>\n<div style=\"margin-bottom: 1em; \"><em>(The man had a slight smile on his face most of the time, with a mixture of complex expressive details. I know just enough facial recognition to know that I had no idea what he was thinking the whole time)</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Me: \"I'm just curious, if someone were to describe themselves as a Rationalist to you, what thoughts and images would come to your mind:</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Man: \"Rationalist?\"&nbsp;</em></div>\n</div>\n</div>\n<div style=\"margin-bottom: 1em; \"><em>Me: \"Yeah. What stereotypes would come to mind?\"</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Man: \"Hmm. Pragmatic. But a little naive.\"</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Me: Interesting. What do you mean?</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Man: \"I just don't think you can realistically expect people to act rationally.\"</em></div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; font-style: italic; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \"><strong>Subject: Male, early 40s, White</strong></div>\n<div style=\"margin-bottom: 1em; \">Me: \"I'm just curious, if someone were to describe themselves as a Rationalist to you, what stereotypes would come to your mind about that person?</div>\n</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Man: \"Heh.&nbsp;<em>Normal.&nbsp;</em>Clear headed. Rational. I dunno. Why? Someone call you that?</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Me: \"Heh, no. Well, yeah. I'm part of a group whose looking into branding issues and getting a sense of general reactions to the word.\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Man: \"Yeah, well anyone who doesn't like the word is being irrational.\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; font-style: italic; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \"><strong>Subject: Woman, 50s, White</strong></div>\n</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; color: #500050; \">\n<div style=\"margin-bottom: 1em; \">Me: \"I'm just curious, if someone were to describe themselves as a Rationalist to you, what stereotypes would come to your mind about that person?</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman: \"Hmm. Conservative. Practical.\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Me: \"Conservative. Do you mean politically?\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman. \"Yeah. Well, in every way really. Politically conservative, practically conservative.\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman exits.</div>\n<div style=\"margin-bottom: 1em; \">I didn't have time to figure out whether for her, \"conservative\" was a word with positive or negative implications. (My guess was positive, with 65% probability).</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \"><em><strong>Subject: Man, 60s-70s, White</strong></em></div>\n</div>\n</div>\n<div style=\"margin-bottom: 1em; color: #500050; \">\n<div style=\"margin-bottom: 1em; color: #500050; \">\n<div style=\"margin-bottom: 1em; \"><em>Me: \"I'm just curious, if someone were to describe themselves as a Rationalist to you, what stereotypes would come to your mind about that person?</em></div>\n</div>\n</div>\n<div style=\"margin-bottom: 1em; \"><em>Man. \"I don't know. I &nbsp;think when people rationalize they end up slipping down a path that ends up making bad decisions.\"</em></div>\n<div style=\"margin-bottom: 1em; \"><em>Me: \"Do you see a difference between&nbsp; Rationality&nbsp;and Rationalization?\"</em></div>\n<div style=\"margin-bottom: 1em; \"><em>I can't remember exactly how he responded but it basically amounted to \"no.\" On one hand, this guy is probably out of our demographic bracket, but I expect this particular problem to come up a lot.&nbsp;</em></div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; font-style: italic; \"><strong>Subject: Female, late 20s, White</strong></div>\n<div style=\"margin-bottom: 1em; font-style: italic; color: #500050; \">\n<div style=\"margin-bottom: 1em; \">Me: \"I'm just curious, if someone were to describe themselves as a Rationalist to you, what stereotypes would come to your mind about that person?</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">Woman: \"I can't answer that.\"</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \">30 seconds of awkward silence.</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><br /></div>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><em> </em>\n<div style=\"margin-bottom: 1em; display: inline !important; \">\n<div style=\"margin-bottom: 1em; display: inline !important; \"><em><em> </em></em>\n<div style=\"margin-bottom: 1em; display: inline !important; \">\n<div style=\"margin-bottom: 1em; display: inline !important; \"><em><em><strong>Subject:&nbsp;Woman, Approx 30s, White</strong></em></em></div>\n<div style=\"margin-bottom: 1em; display: inline !important; \"><em><em><strong><br /></strong></em></em></div>\n<div style=\"margin-bottom: 1em; display: inline !important; \"><em><em><strong><span style=\"font-style: normal; font-weight: normal; \"><em>\n<div style=\"margin-bottom: 1em; display: inline !important; \">\n<div style=\"margin-bottom: 1em; display: inline !important; \">(Standard intro: \"what stereotypes come to mind\")</div>\n<div style=\"margin-bottom: 1em; display: inline !important; \"><br /></div>\n</div>\n</em><br /></span></strong></em></em></div>\n</div>\n<em><em></em></em></div>\n</div>\n<em></em>\n<div style=\"margin-bottom: 1em; \">Woman: \"Realistic\"</div>\n<div style=\"margin-bottom: 1em; \">Me: \"Oh?\"</div>\n<div style=\"margin-bottom: 1em; \">Woman: \"Yeah. Why?\"</div>\n<div style=\"margin-bottom: 1em; \">Me: \"We're doing some&nbsp; market&nbsp; research&nbsp;and trying to see what gut reactions we'd get if we used a particular name. Like some people hear the world Rationalist and they think 'cold and emotionless'\"</div>\n<div style=\"margin-bottom: 1em; \">Woman, \"No, I don't think that at all. Just able to look realistically at things.\"</div>\n<div style=\"margin-bottom: 1em; \">(As a rule of thumb I'm not sure I should explain myself in as much detail, especially not leaving people with the specific phrase \"cold and emotionless\" in case they weren't already thinking it. But in this case it worked out)</div>\n<div style=\"margin-bottom: 1em; font-style: normal; \"><br /></div>\n<div style=\"margin-bottom: 1em; \"><strong>Subject:&nbsp;<em>\n<div style=\"margin-bottom: 1em; display: inline !important; \">\n<div style=\"margin-bottom: 1em; display: inline !important; \">&nbsp;Male, 50ish</div>\n</div>\n</em></strong></div>\n<div style=\"margin-bottom: 1em; \">Man: \"Someone who likes to break things down to a [ground?] level\" (can't recall his exact phrasing).</div>\n<div style=\"margin-bottom: 1em; color: #500050; \">\n<div style=\"margin-bottom: 1em; \">Me: \"And is that a good or bad thing?\"</div>\n</div>\n<div style=\"margin-bottom: 1em; \">Man: Could be either. Some people break things down just to be an asshole. Other people actually are trying to get something done.\"</div>\n<div style=\"margin-bottom: 1em; \">Me: \"Ah\"</div>\n<div style=\"margin-bottom: 1em; \">Man: \"And sometimes you don't want someone to break things down, sometimes you want someone who doesn't lose track [of the big picture?]\" (can't remember exact phrasing)</div>\n<div style=\"margin-bottom: 1em; \">Me: Well&nbsp; Rationality&nbsp;doesn't necessarily mean you lose track of the big picture....</div>\n<div style=\"margin-bottom: 1em; \">(door opens, guy gets off, I feel like I messed up a bit there.)</div>\n</div>\n<div style=\"margin-bottom: 1em; font-style: italic; \"><br /></div>\n<div style=\"margin-bottom: 1em; \"><strong>Closing Thoughts</strong></div>\n<div style=\"margin-bottom: 1em; \">I felt like I had a lot of data, and that I had overall gotten a fairly positive response. I wasn't sure&nbsp; Rationality&nbsp;was the most effective word for outreach, but I thought that the benefits of \"reclaiming\" the word as something with positive connotations outweighed the lukewarm responses I sometimes got.</div>\n<div style=\"margin-bottom: 1em; \">Then I looked back and realized I'd only actually talked to 9 people. Which is not a lot. I stopped doing it for a while but I'll try and get some more data. I invite others to either help with this particular question, or to start forming other questions and getting some feedback on them. I did my questioning in one specific building, which I think had a decent cross section of people, but was still heavily tilted towards upper-middle-class, middle-aged white people, working in central Manhattan. We'll want more variety than that.</div>\n<div style=\"margin-bottom: 1em; \">I'm sure many of you spend time standing in lines, waiting in elevators or otherwise hanging around other people in awkward silence. This is an opportunity to take that time and convert it into useful information. Most of those people will never see you again, so there's little risk of losing status.</div>\n<div style=\"margin-bottom: 1em; \">If you are someone who shies away from social encounters, this would probably be a good experience for you. It requires a bit of courage, but it's a fear you can overcome, and helps develop the skill of initiating conversations with strangers. (It does NOT necessarily teach you good conversation techniques, since you're asking specific questions that do not make good \"traditional\" smalltalk, but if you have trouble initiating in the first place, it's probably more important to work on that than to worry about specific ways of conversing).</div>\n<div style=\"margin-bottom: 1em; \">So far I've deliberately avoided asking people when there was more than one person there. Partly this was because&nbsp;<em>I&nbsp;</em>was still a little scared and the bigger groups were even more intimidating. Partly because I was concerned about the group influencing the individual responses.&nbsp;(This is easy to avoid if you're in an elevator, less easy if you're waiting in a line. Not sure what I recommend there).&nbsp;</div>\n<div style=\"margin-bottom: 1em; \">Some things this was lacking:</div>\n<div style=\"margin-bottom: 1em; \">1) A control group. \"Positive\" responses may have just been polite, regardless of the subject matter. At this point I don't think the effort and consequences of a control group are really worth it, but we should at least acknowledge the issue.&nbsp;</div>\n<div style=\"margin-bottom: 1em; \">2) More consistent followup statements/questions, so that all the data is based on similar input.</div>\n<div style=\"margin-bottom: 1em; \">3) Later on, a variety of DIFFERENT statements/questions, so we can see how much has to do with&nbsp; rationality&nbsp;and how much has to do with our phrasing. Also, just come up with new questions in general.</div>\n<div style=\"margin-bottom: 1em; \">4) It's been suggested that I record people's responses with a hidden camera, then ask permission to use it after the fact. I'm not sure how I feel about that. It'd definitely be useful to have the real responses rather than my recollections of them, but this requires a bit more courage than I feel like I have. Hidden microphone might be more workable (I recently discovered that iPhones have pretty awesome voice memo capabilities. Which makes sense, given that audio-input is their original function). This has the added benefit of giving you feedback on your communication skills as well.</div>\n<div style=\"margin-bottom: 1em; \">5) I mentioned before: it'd be great if someone could set up a website designed to sort this data, and it'd be even better if it was designed to handle a variety of related topics as well. Obviously the free form responses don't lend themselves well to sorting, but I think we can at least sort by:</div>\n<div style=\"margin-bottom: 1em; \"><span style=\"white-space: pre-wrap; \"> a) demographics of the subject</span></div>\n<div style=\"margin-bottom: 1em; \"><span style=\"white-space: pre-wrap; \"> b) subjective impression of how \"positive\" the subject was towards&nbsp; rationality</span></div>\n<div style=\"margin-bottom: 1em; \"><span style=\"white-space: pre-wrap; \"> c) somehow cluster responses by keywords</span></div>\n</div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n<div style=\"margin-bottom: 1em; \">If the conversation has time to go anywhere, it'll be important to have an actual, good, positive definition of rationality to give to people. (Using a particular phrase can tie in with point 2 above, so we have an easier time comparing conversations). The new intro on the front page of Less Wrong is pretty good but a little too long. My recommended definition for a short, casual conversation:&nbsp;</div>\n<div style=\"margin-bottom: 1em; \">\"Rationality is the study of making good decisions. We're trying to improve our understanding of how the world works and what we can do to achieve our goals.\"</div>\n<div style=\"margin-bottom: 1em; \"><strong>Edit:</strong></div>\n<div style=\"margin-bottom: 1em; \">Does anyone know if I set up a Google Docs form, can I make it public?&nbsp;</div>\n<div style=\"margin-bottom: 1em; \">If so I can actually get a repository for the data up pretty soon, but it leaves me with a new question: Outside of a America, what's the typical breakdowns for racial background? (i.e. in America you generally say \"African American\" which is just silly in a potentially international audience, or \"Black\" which is accurate but has come to sound a bit unprofessional)</div>\n<div style=\"margin-bottom: 1em; \"><strong>Edit 2:&nbsp;</strong></div>\n<div style=\"margin-bottom: 1em; \">I created a Google Docs form.&nbsp;<a href=\"https://spreadsheets.google.com/spreadsheet/viewform?formkey=dHI3RFJYV3B4UEdsRmlKdjBlcG5Hc0E6MQ\">It should be available here.</a>&nbsp; Let me know if you have any comments/critiques.</div>\n<div style=\"margin-bottom: 1em; \"><br /></div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7ow6EFpypbH4hzFuz": 2, "izp6eeJJEg9v5zcur": 2, "tk4R4LrX88gmFeMmY": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ousEiGAmLEoJq2Reb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 61, "baseScore": 79, "extendedScore": null, "score": 0.00018286862177550574, "legacy": true, "legacyId": "8626", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 66, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 86, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T22:04:48.976Z", "modifiedAt": null, "url": null, "title": "My true rejection", "slug": "my-true-rejection", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:00.324Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dripgrind", "createdAt": "2010-03-01T13:12:12.039Z", "isAdmin": false, "displayName": "dripgrind"}, "userId": "Nnz4a3atoi6sKTxuj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x9somBvS4FmNazaCo/my-true-rejection", "pageUrlRelative": "/posts/x9somBvS4FmNazaCo/my-true-rejection", "linkUrl": "https://www.lesswrong.com/posts/x9somBvS4FmNazaCo/my-true-rejection", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20true%20rejection&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20true%20rejection%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx9somBvS4FmNazaCo%2Fmy-true-rejection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20true%20rejection%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx9somBvS4FmNazaCo%2Fmy-true-rejection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx9somBvS4FmNazaCo%2Fmy-true-rejection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 366, "htmlBody": "<p>Here's why I'm not going to give money to the SIAI any time soon.</p>\n<p>Let's suppose that Friendly AI is possible. In other words, it's possible that a small subset of humans can make a superhuman AI which uses something like <a href=\"http://intelligence.org/upload/CEV.html\">Coherent Extrapolated Volition</a> to increase the happiness of humans in general (without resorting to skeevy hacks like releasing an orgasm virus).</p>\n<p>Now, the extrapolated volition of <em>all </em>humans is probably a tricky thing to determine. I don't want to get sidetracked into writing about my relationship history, but sometimes I feel like it's hard to extrapolate the volition of <em>one </em>human.</p>\n<p>If it's <em>possible </em>to make a Friendly superhuman AI that optimises CEV, then it's surely way <em>easier </em>to make an unFriendly superhuman AI that optimises a much simpler variable, like the share price of IBM.</p>\n<p>Long before a Friendly AI is developed, some research team is going to be in a position to deploy an unFriendly AI that tries to maximise the personal wealth of the researchers, or the share price of the corporation that employs them, or pursues some other goal that the rest of humanity might not like.</p>\n<p>And who's going to stop that happening? If the executives of Corporation X are in a position to unleash an AI with a monomaniacal dedication to maximising the Corp's shareholder value, it's probably illegal for them not to do just that.</p>\n<p>If you genuinely believe that superhuman AI is possible, it seems to me that, as well as sponsoring efforts to design Friendly AI, you need to (a) lobby against AI research by any groups who aren't 100% committed to Friendly AI (pay off reactionary politicians so AI regulation becomes a campaign issue, etc.) (b) assassinate any researchers who look like they're on track to deploying an unFriendly AI, then destroy their labs and backups.</p>\n<p>But SIAI seems to be fixated on design at the expense of the other, equally important priorities. I'm not saying I expect SIAI to pursue illegal goals openly, but there is such a thing as a false-flag operation.</p>\n<p>While Michelle Bachmann isn't talking about how AI research is a threat to the US constitution, and Ben Goertzel remains free and alive, I can't take the SIAI seriously.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x9somBvS4FmNazaCo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": -29, "extendedScore": null, "score": -3.6e-05, "legacy": true, "legacyId": "8640", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-14T22:12:10.060Z", "modifiedAt": null, "url": null, "title": "What are some good survey questions on a rationality website (like Gene Expression)? Razib would like some input", "slug": "what-are-some-good-survey-questions-on-a-rationality-website", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.099Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uQtfhqMzchoCCLXcB/what-are-some-good-survey-questions-on-a-rationality-website", "pageUrlRelative": "/posts/uQtfhqMzchoCCLXcB/what-are-some-good-survey-questions-on-a-rationality-website", "linkUrl": "https://www.lesswrong.com/posts/uQtfhqMzchoCCLXcB/what-are-some-good-survey-questions-on-a-rationality-website", "postedAtFormatted": "Thursday, July 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20some%20good%20survey%20questions%20on%20a%20rationality%20website%20(like%20Gene%20Expression)%3F%20Razib%20would%20like%20some%20input&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20some%20good%20survey%20questions%20on%20a%20rationality%20website%20(like%20Gene%20Expression)%3F%20Razib%20would%20like%20some%20input%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuQtfhqMzchoCCLXcB%2Fwhat-are-some-good-survey-questions-on-a-rationality-website%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20some%20good%20survey%20questions%20on%20a%20rationality%20website%20(like%20Gene%20Expression)%3F%20Razib%20would%20like%20some%20input%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuQtfhqMzchoCCLXcB%2Fwhat-are-some-good-survey-questions-on-a-rationality-website", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuQtfhqMzchoCCLXcB%2Fwhat-are-some-good-survey-questions-on-a-rationality-website", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4, "htmlBody": "<p>The post is here:&nbsp;<a href=\"http://blogs.discovermagazine.com/gnxp/2011/07/reader-survey-questions\">http://blogs.discovermagazine.com/gnxp/2011/07/reader-survey-questions</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uQtfhqMzchoCCLXcB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.410182768441368e-07, "legacy": true, "legacyId": "8641", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T01:28:58.452Z", "modifiedAt": null, "url": null, "title": "Meetup in San Diego, CA, USA", "slug": "meetup-in-san-diego-ca-usa", "viewCount": null, "lastCommentedAt": "2011-07-31T03:02:52.467Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mercurial", "createdAt": "2011-04-21T03:59:51.257Z", "isAdmin": false, "displayName": "Mercurial"}, "userId": "2dGsX6cZSR9PmQyBq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3MNisBcPopP6Q8AxK/meetup-in-san-diego-ca-usa", "pageUrlRelative": "/posts/3MNisBcPopP6Q8AxK/meetup-in-san-diego-ca-usa", "linkUrl": "https://www.lesswrong.com/posts/3MNisBcPopP6Q8AxK/meetup-in-san-diego-ca-usa", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20in%20San%20Diego%2C%20CA%2C%20USA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20in%20San%20Diego%2C%20CA%2C%20USA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MNisBcPopP6Q8AxK%2Fmeetup-in-san-diego-ca-usa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20in%20San%20Diego%2C%20CA%2C%20USA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MNisBcPopP6Q8AxK%2Fmeetup-in-san-diego-ca-usa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MNisBcPopP6Q8AxK%2Fmeetup-in-san-diego-ca-usa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 499, "htmlBody": "<p>We're holding what I believe is the first San Diego meetup on <strong>Sunday, July 31st</strong> starting at 1pm at the K&amp;B Wine Cellars near San Diego State University:</p>\n<p>6380 Del Cerro Blvd.<br />San Diego, CA 92120</p>\n<p>The phone number for the place is 619-286-0884. &nbsp;This is one of a number of places along a strip that's attached to a grocery store of sorts.&nbsp;&nbsp;It's something like a coffee house only with beer, wine, &amp; liquor instead of coffee. &nbsp;(Underage attendees should be fine; you just won't be able to get alcohol. &nbsp;There's food and some non-alcoholic drinks if you like.) &nbsp;We're meeting in a semi-hidden room in the far back. &nbsp;When you walk in, go as straight as you can while staying close to the left wall.</p>\n<p>This will be an introductory meeting so that those in the San Diego area can meet one another. &nbsp;We'll talk about what we want to get out of these meetups and hammer out some specific plans for how to accomplish that. &nbsp;From some initial conversations, it sounds like we'll have monthly meetups, though that stands a fair chance of changing depending on what we discuss here.</p>\n<p>Feel free to bring friends, significant others, or anyone else who's interested in rationality. &nbsp;Also, give some thought to what you'd like out of these meetups. &nbsp;It doesn't have to be profound; camaraderie or \"I don't know\" are fine answers. &nbsp;But if you give it a bit of thought ahead of time, you might find it easier to envision and articulate <a href=\"/lw/ic/the_virtue_of_narrowness/\" target=\"_blank\">more precisely</a> what it is that you'd like to see these meetups become.</p>\n<p>I should also mention that this location has a projector setup, so if there's something you'd like to share PowerPoint style, feel free to bring that. &nbsp;I haven't gotten details from the restaurant as yet about how to use the projector setup (e.g. is it transparencies or a laptop hookup?), but I'll edit in that clarification once I get it.</p>\n<p>Let me know if you have any questions. &nbsp;Also, if you could either reply here or give me a quick PM to let me know you're coming, that would be helpful. &nbsp;That way I can let the place know how many to set the space up for.</p>\n<p><em>ETA: I should add that I do have some material on practical uses of mindfulness that I'm quite willing to offer. &nbsp;I've been teaching this stuff for about seven years now. &nbsp;But I don't want to say that that's definitely what this meeting will be about since I want to find out what everyone is looking to gain from these first.</em></p>\n<p><em>ETA #2: Also, please, PLEASE don't bring smokers. &nbsp;My wife is coming, and she's asthmatic in a way that reacts severely to cigarette smoke even if it's lingering on others' clothing. &nbsp;If someone shows up with a lot of smoke on them, my wife and I will have to leave right away. &nbsp;</em><em style=\"font-style: italic;\">I doubt this will be an issue with this group, but it's significant enough to be worth making explicit. &nbsp;Thanks!</em></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3MNisBcPopP6Q8AxK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.410791149588998e-07, "legacy": true, "legacyId": "8643", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yDfxTj9TKYsYiWH5o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T04:19:21.908Z", "modifiedAt": null, "url": null, "title": "Decimal digit computations as a testing ground for reasoning about probabilities", "slug": "decimal-digit-computations-as-a-testing-ground-for-reasoning", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.919Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "multifoliaterose", "createdAt": "2010-06-13T08:56:10.885Z", "isAdmin": false, "displayName": "multifoliaterose"}, "userId": "747HfTZFyfTqGyoPM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XQ6LJLRvtABWxjEyR/decimal-digit-computations-as-a-testing-ground-for-reasoning", "pageUrlRelative": "/posts/XQ6LJLRvtABWxjEyR/decimal-digit-computations-as-a-testing-ground-for-reasoning", "linkUrl": "https://www.lesswrong.com/posts/XQ6LJLRvtABWxjEyR/decimal-digit-computations-as-a-testing-ground-for-reasoning", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Decimal%20digit%20computations%20as%20a%20testing%20ground%20for%20reasoning%20about%20probabilities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecimal%20digit%20computations%20as%20a%20testing%20ground%20for%20reasoning%20about%20probabilities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQ6LJLRvtABWxjEyR%2Fdecimal-digit-computations-as-a-testing-ground-for-reasoning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Decimal%20digit%20computations%20as%20a%20testing%20ground%20for%20reasoning%20about%20probabilities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQ6LJLRvtABWxjEyR%2Fdecimal-digit-computations-as-a-testing-ground-for-reasoning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQ6LJLRvtABWxjEyR%2Fdecimal-digit-computations-as-a-testing-ground-for-reasoning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 567, "htmlBody": "<p><em>Points in this article emerged from a conversation with Anna Salamon</em></p>\n<p>I think that thinking about decimal expansions of real numbers provides a good testing ground for one's intuition about probabilities. The context of computation is very different from most of the contexts that humans deal with; in particular it's much cleaner. As such, this testing ground should not be used in isolation; the understanding that one reaps from it needs to be integrated with knowledge from other contexts. Despite its limitations I think that it has something to add.</p>\n<p>Given a computable real number x, <em>a priori</em> the probability that any string of n decimal digits comprises the first n decimal digits of x is 10<sup>-n</sup>. For concreteness, we'll take x to be pi. It has long been conjectured that pi is a <a href=\"http://en.wikipedia.org/wiki/Normal_number\">normal number</a>. This is consistent with the notion that the digits of pi are \"random\" in some sense, and in this respect pi contrasts with (say) <a href=\"http://en.wikipedia.org/wiki/Rational_number\">rational numbers</a> and <a href=\"http://mathworld.wolfram.com/LiouvillesConstant.html\">Liouville's constant</a>.</p>\n<p>According to the <a href=\"http://www.mccormick.northwestern.edu/news/articles/article_743.html\">Northwestern University homepage</a>, pi has been computed to five trillion of digits. So to the extent that one trusts the result of the computation; there exists an example of a statement which had an <em>a priori</em> probability of 10<sup>-n</sup>&nbsp; with n &gt; 5&bull;10<sup>12</sup> of being true which we now know to be true with high confidence. How much should we trust the computation? Well, I don't know whether it's been verified independently and there are a variety of relevant issues about which I know almost nothing (coding issues; hardware issues; the degree of rigor with which the algorithm used has been proven to be correct, etc.). One would have more confidence if one knew that several independent teams had succeeded in verifying the result using different algorithms &amp; hardware. One would have still more confidence if one were personally involved in such a team and became convinced of the solidity of the methods used. Regardless:</p>\n<p>(a) <a href=\"http://en.wikipedia.org/wiki/Approximations_of_%CF%80#20th_century\">As early as 1962</a> mathematicians had computed pi to 10<sup>5</sup> digits. Presumably since then their computation has been checked many times over by a diversity of people and methods. Trusting a single source is still problematic as there may have been a typo or whatever, but it seems uncontroversial to think that if one uses the nearest apparently reliable computational package (say, Wolfram Alpha) then chance that the output is correct is &gt; 10%. Thus we see how an initial probability estimate of 10<sup>-100000</sup> can rise to a probability over 10<sup>-1</sup> in practice.</p>\n<p>(b) If one was <em>determined</em> one could probably develop ~90% confidence the accuracy over a billion digits of pi. I say this because it's been over 20 years since computational power and algorithms have permitted such a vast computation; presumably by studying, testing and tweaking all programs written since then, one could do many checks on the accuracy of each of the first billion digits. Assuming that this is possible, an initial probability estimate of 10<sup>-1000000000</sup> can in practice grow as large as&nbsp; &gt; 0.9.</p>\n<p>This shows that probabilities which are apparently <em>very</em> small can rapidly shift to being quite large with the influx of new information. There's more that I could say about this but I think that the chunk that I've written so far is enough to warrant posting and that the rest of my thoughts are sufficiently ill-formed so that I shouldn't try to say more right now. I welcome thoughts and comments.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XQ6LJLRvtABWxjEyR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 7.411316444346815e-07, "legacy": true, "legacyId": "8647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T07:10:00.963Z", "modifiedAt": null, "url": null, "title": "Transsexuals and otherkin", "slug": "transsexuals-and-otherkin", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:33.131Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lucidfox", "createdAt": "2010-11-22T06:58:06.993Z", "isAdmin": false, "displayName": "lucidfox"}, "userId": "hNnKSqvajCMRj9eKK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qByTewnDhgnF3wTem/transsexuals-and-otherkin", "pageUrlRelative": "/posts/qByTewnDhgnF3wTem/transsexuals-and-otherkin", "linkUrl": "https://www.lesswrong.com/posts/qByTewnDhgnF3wTem/transsexuals-and-otherkin", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Transsexuals%20and%20otherkin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATranssexuals%20and%20otherkin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqByTewnDhgnF3wTem%2Ftranssexuals-and-otherkin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Transsexuals%20and%20otherkin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqByTewnDhgnF3wTem%2Ftranssexuals-and-otherkin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqByTewnDhgnF3wTem%2Ftranssexuals-and-otherkin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<p>After reflecting on the <a href=\"/lw/374/gender_identity_and_rationality/\">\"Gender Identity and Rationality\"</a> post, there is something that continues to bug me, a shred of doubt burning through my brain.</p>\n<p>What is it about gender identity that separates it from fringe subcultures like otherkin, soulbonders, and whatever else? Why is one considered socially acceptable (however grudgingly and however rocky history the recognition has), and the other isn't? Is such a distinction justified in the first place?</p>\n<p>What's so substantially different between \"I'm really another gender on the inside\" and \"I'm really another species on the inside\"? Muddling the waters is the fact that I know some transsexuals who also are or used to be otherkin.</p>\n<p>I have seen two different points of view on this subject:</p>\n<p>1. Well, who are we to claim that otherkin are wrong? Perhaps their condition deserves legitimate recognition and sympathy.</p>\n<p>2. The difference is between identifying with something that verifiably exists (and exists within <a href=\"/lw/rl/the_psychological_unity_of_humankind/\">the psychological unity of humankind</a>), and identifying with a species that is either non-sapient (and thus unable to be targeted by human empathy to the same extent that humans are), or flat-out doesn't exist (dragons, fae, and other fantasy creatures).</p>\n<p>While I'm myself leaning towards the second point of view, I find the argument rather weak. It implies that in a hypothetical setting with multiple intelligent species, \"species identity\" may be a socially valid characteristic, and a human citizen of the Federation claiming to be mentally a Klingon would be worth paying attention to. And I find that... counterintuitive.</p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qByTewnDhgnF3wTem", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 14, "extendedScore": null, "score": 4e-05, "legacy": true, "legacyId": "8652", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 115, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["axgfcSEQwaaAn4d3Z", "Cyj6wQLW6SeF6aGLy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T08:39:35.029Z", "modifiedAt": null, "url": null, "title": "Rationalist Judo, or Using the Availability Heuristic to Win", "slug": "rationalist-judo-or-using-the-availability-heuristic-to-win", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.564Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jschulter", "createdAt": "2010-08-28T21:41:04.522Z", "isAdmin": false, "displayName": "jschulter"}, "userId": "JkRMMCvHahHw9ooa2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ztEcQtZsjXnqLc3xB/rationalist-judo-or-using-the-availability-heuristic-to-win", "pageUrlRelative": "/posts/ztEcQtZsjXnqLc3xB/rationalist-judo-or-using-the-availability-heuristic-to-win", "linkUrl": "https://www.lesswrong.com/posts/ztEcQtZsjXnqLc3xB/rationalist-judo-or-using-the-availability-heuristic-to-win", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Judo%2C%20or%20Using%20the%20Availability%20Heuristic%20to%20Win&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Judo%2C%20or%20Using%20the%20Availability%20Heuristic%20to%20Win%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztEcQtZsjXnqLc3xB%2Frationalist-judo-or-using-the-availability-heuristic-to-win%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Judo%2C%20or%20Using%20the%20Availability%20Heuristic%20to%20Win%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztEcQtZsjXnqLc3xB%2Frationalist-judo-or-using-the-availability-heuristic-to-win", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztEcQtZsjXnqLc3xB%2Frationalist-judo-or-using-the-availability-heuristic-to-win", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 778, "htmlBody": "<p>During the sessions at the <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">2011 rationality minicamp</a>, we learned that some of our <a href=\"http://wiki.lesswrong.com/wiki/Bias\">biases</a> can be used constructively, rather than just tolerated and avoided.</p>\n<p>For example, in an excellent article discussing intuitions and the way they are formed, psychologist <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Hogarth-On-the-learning-of-intuition.pdf\">Robin Hogarth</a> recommends that \"if people want to shape their intuitions, [they should] make conscious efforts to inhabit environments that expose them to the experiences and information that form the intuitions that they want.\"</p>\n<p>Another example:&nbsp;<a href=\"/user/CarlShulman/\">Carl Shulman</a> remarked that due to the <a href=\"http://wiki.lesswrong.com/wiki/Availability_heuristic\">availability heuristic</a>&nbsp;we anticipate car crashes with frequencies determined by how many people we know of or have heard about who have gotten into one. So if you don't fear car crashes but you want to acquire a more&nbsp;<em>accurate</em>&nbsp;level of concern about driving, you could seek out news or footage of car crashes. Video footage may work best, because experiential data unconsciously&nbsp;<a href=\"/lw/59v/intuition_and_unconscious_learning/\">inform</a>&nbsp;our intuitions more effectively than, say, written data.</p>\n<p>This fact may lie behind many effective strategies for getting your brain to do what you want it to do:</p>\n<ul>\n<li>Establishing '<a href=\"http://www.youtube.com/watch?v=dpS_cJP5nzs\">pull' motivation</a>' works best with strong visualization, and is reinforced upon experiencing the completion of the task.</li>\n<li><a href=\"http://rejectiontherapy.com/rules/\">Rejection therapy</a>, which many of us minicampers found helpful and effective. The point is to ask people for things they will probably deny you, which trains your body to realize that nothing bad happens when you are rejected. After a time, this improves social confidence.</li>\n<li>As&nbsp;<a href=\"http://en.wikipedia.org/wiki/Looking_glass_self\">looking glass self</a> theory states,<sup>1</sup> we are shaped by how others see us. This is largely due to the experience of having people react to us in certain ways.</li>\n</ul>\n<p>In <a href=\"/lw/1l/the_mystery_of_the_haunted_rationalist/\">The Mystery of the Haunted Rationalist</a> we see a someone whose stated beliefs don't match their <a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">anticipations</a>. Now we can actually use the brain's machinery to get it to do what we want it to: alieve that ghosts aren't real or dangerous. One method would be for our ghost stricken friend to get people to tell her detailed stories about pleasant nights they spent in haunted houses (complete with spooky details) where nothing bad happened. Alternatively, she could read some books or watch some videos with similar content. Best of all would be if she spent a month living in a 'haunted' house, perhaps after doing some of the other things to soothe her nerves. There are many who will attest that eventually one 'gets used to' the scary noises and frightening atmosphere of an old house, and ceases to be scared when sleeping in similar houses.</p>\n<p>I attribute&nbsp;the effectiveness of these tactics&nbsp;mostly to successful persuasion of the non-conscious brain using experiential data.</p>\n<p>So, it seems we have a (potentially very powerful) new technique to add to our rationalist arsenal. To summarize:</p>\n<ol>\n<li>Find something you want to <a href=\"http://wiki.lesswrong.com/wiki/Alief\">alieve</a>.</li>\n<li>Determine what experiences that alief should cause you to anticipate.</li>\n<li>Have those experiences, by proxy if necessary, artificial or not.</li>\n<li>Test whether you now anticipate what you want to.</li>\n<li>If the test reveals progress, but not enough, repeat.</li>\n</ol>\n<p>Examples:</p>\n<ul>\n<li>Want to alieve that boxing is dangerous<sup>2</sup>? Watch some footage of boxers being punched painfully in the face, and ask a good boxer to win a fight against you in a painful but non-damaging manner. Now are you reluctant to box someone you have a good chance of beating?</li>\n<li>Want to alieve that driving is dangerous? Watch footage of lots of car crashes, see <em><a href=\"http://en.wikipedia.org/wiki/Red_Asphalt\">Red Asphalt</a></em>, and take a class from professional stunt drivers on how to crash safely. Now are you more reluctant to drive?</li>\n<li>Want to alieve that flying is not very dangerous? Get a pilot's view of a flight, and pay attention to how boring it is. Sit next to a pilot while they undergo a very realistic flight simulation that covers many possible accidents, and watch them successfully navigate each scenario. Now are you more willing to fly?</li>\n<li>Want to alieve snakes are generally not dangerous? Watch videos of safe snake interactions. Watch a pet store employee deal with a snake safely. Play with a snake under supervision without incident. Now do you exhibit less fear when encountering a snake?</li>\n<li>Want to alieve you are part of the Less Wrong community? Interact with other community members as though you are one, attend meetups, make friends in the community. Now do you empathize more strongly with&nbsp;contributors&nbsp;on Less Wrong than with those elsewhere on the internet?</li>\n</ul>\n<p>It can be annoying when our unconsciously moderated aliefs don't match our rationality-influenced beliefs, but luckily our aliefs can be trained.</p>\n<p>&nbsp;</p>\n<p><sup>1</sup> Thanks to <a href=\"/user/HughRistik/\">Hugh Ristik</a> for talking about this at minicamp.</p>\n<p><sup>2</sup> Credit for this example goes to <a href=\"/user/BrandonReinhart/\">Brandon Reinhart</a>.</p>\n<h6>Special thanks to <a href=\"/user/lukeprog/\">Luke</a> for all the help</h6>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XYHzLjwYiqpeqaf4c": 1, "4R8JYu4QF2FqzJxE5": 1, "HXA9WxPpzZCCEwXHT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ztEcQtZsjXnqLc3xB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 33, "extendedScore": null, "score": 7.1e-05, "legacy": true, "legacyId": "8565", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6Cc3TWZjAnrNWokWY", "mja6jZ6k9gAwki9Nu", "a7n8GdKiAZRX86T5A"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T09:24:07.271Z", "modifiedAt": null, "url": null, "title": "I just donated to the SIAI.", "slug": "i-just-donated-to-the-siai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.802Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pavitra", "createdAt": "2009-09-22T08:32:44.250Z", "isAdmin": false, "displayName": "Pavitra"}, "userId": "yC2JgX3ENu7mionKh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RPXeq42hwPGNeofKo/i-just-donated-to-the-siai", "pageUrlRelative": "/posts/RPXeq42hwPGNeofKo/i-just-donated-to-the-siai", "linkUrl": "https://www.lesswrong.com/posts/RPXeq42hwPGNeofKo/i-just-donated-to-the-siai", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20just%20donated%20to%20the%20SIAI.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20just%20donated%20to%20the%20SIAI.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPXeq42hwPGNeofKo%2Fi-just-donated-to-the-siai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20just%20donated%20to%20the%20SIAI.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPXeq42hwPGNeofKo%2Fi-just-donated-to-the-siai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPXeq42hwPGNeofKo%2Fi-just-donated-to-the-siai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 401, "htmlBody": "<p>My purpose in writing this is twofold.</p>\n<p>&nbsp;</p>\n<p>First (chronologically: I thought of this earlier than the other), I want to discuss some of the pragmatic points in how I got myself to do it.</p>\n<p>The most important thing is that I <em>didn't</em> try to force the decision through with willpower. Instead, I slipped it through with doublethink. I <em>knew</em> perfectly well - and have known for months - that giving money to SIAI was the right thing to do. But I didn't do it. I spent money on things like Minecraft instead.</p>\n<p>But <a href=\"http://intelligence.org/donate/\">somehow</a> I found myself at the donation page, and I didn't think about it. Or, rather, I didn't let myself think about the fact that I was thinking about it. I made a series of expected-value guesstimates aimed at working around my own cognitive limitations.</p>\n<p>I chose monthly donation over one-time because $20 monthly <em>sounds like</em> about the same amount of money as $20; past experience with recurring donations suggests that I tend to leave automatic recurring donations in place for about a year or two, so that probably gained me about a factor of 20. Similarly, I chose $20 as the largest amount that wouldn't put me in serious risk of chickening out and not donating anything.</p>\n<p>In order to pull this off, I had to <em>avoid thinking</em> certain true thoughts. Numbers like \"$240 per year\" only drifted through my consciousness just long enough to make the expected-value judgment, and were then discarded quickly so as to avoid setting off my rotten-meat hypervisor.</p>\n<p>This was not the first time I decided that I should give money to SIAI. It was the first time I <em>actually did</em> give them money. (Except for that one time with the $1 charity-a-day thing, which actually might have helped with dissolving psychological barriers to the general idea.)</p>\n<p>I think this is important.</p>\n<p>&nbsp;</p>\n<p>The second fold of my purpose is to reinforce the behavior using the glowy feeling that comes from having other people know what an awesome person I am.<sup>1</sup> Anyone else who's done anything worthwhile should feel free to post in this thread too.</p>\n<p>&nbsp;</p>\n<p>1. It's true. Statistically speaking, I probably saved like a jillion people's lives per dollar. And more-than-doubled quality of life for a zillion more. Let me also note that you can get in on this action.</p>\n<p>I know that sounds advertisementy, but... well, that's kind of the point. Practice Dark Arts on yourself for fun and profit.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RPXeq42hwPGNeofKo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 19, "extendedScore": null, "score": 4e-05, "legacy": true, "legacyId": "8654", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T15:50:43.996Z", "modifiedAt": null, "url": null, "title": "AGI/FAI Theorist for Hire", "slug": "agi-fai-theorist-for-hire", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.094Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Peter_de_Blanc", "createdAt": "2009-02-27T14:15:28.882Z", "isAdmin": false, "displayName": "Peter_de_Blanc"}, "userId": "vRvaAqR5tcjGEWaoC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w4vMd5McLfpA9zEvt/agi-fai-theorist-for-hire", "pageUrlRelative": "/posts/w4vMd5McLfpA9zEvt/agi-fai-theorist-for-hire", "linkUrl": "https://www.lesswrong.com/posts/w4vMd5McLfpA9zEvt/agi-fai-theorist-for-hire", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AGI%2FFAI%20Theorist%20for%20Hire&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAGI%2FFAI%20Theorist%20for%20Hire%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw4vMd5McLfpA9zEvt%2Fagi-fai-theorist-for-hire%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AGI%2FFAI%20Theorist%20for%20Hire%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw4vMd5McLfpA9zEvt%2Fagi-fai-theorist-for-hire", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw4vMd5McLfpA9zEvt%2Fagi-fai-theorist-for-hire", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 468, "htmlBody": "<p>I'm nearing the end of my employment at SIAI and looking for my next gig. If all else fails I will likely move back to the Bay area (I am currently in Japan) and take a job as a programmer somewhere. However, I would prefer to focus my attention directly on&nbsp;developing AGI and FAI theory. In addition to my current projects (described below), I can try to answer mathematical, philosophical, or other questions for a bit of cash. For some of my previous work, see my page on the <a href=\"http://arxiv.org/find/cs/1/au:+Blanc_P/0/1/0/all/0/1\">arXiv</a>.</p>\n<p>In the past year I've been involved in two major projects at SIAI. Steve Rayhawk and I were asked to review existing AGI literature and produce estimates of development timelines for AGI. My work on this project got rather bogged down and proceeded slowly, although I did learn a lot and I've moved in the direction of predicting AGI soonish (5-20 years). After this I tried to produce an AGI technology demo for Google's AGI-11 conference. I was unable to finish my demo in time for the submission deadline, and shortly afterwards SIAI decided to let me go.</p>\n<p>I have several projects that I would like to move forward with, and if I can get adequate funds&nbsp;(about $1000 per month to ensure my survival, or $2000 to live comfortably)&nbsp;I will be able to work on them.</p>\n<p>Current project ideas:</p>\n<ol>\n<li>Continue development on my incomplete AGI project (optimally, technical details not to be published).</li>\n<li>Write a paper on AGI models that can be used as a basis for FAI research (similar to the way AIXI and its ilk are used now, but closer to reality than AIXI).</li>\n<li>Figure out how an AI can reason formally about using objects in its environment as tools for performing computations.</li>\n<li>I'm also interested in repurposing machine learning algorithms used for finding plausible hypotheses about data distributions into algorithms for finding action policies with high expected utility.</li>\n</ol>\n<p>I'm open to suggestions for other topics. I don't consider myself an expert at empiricism, so I prefer to work in domains where I can reason formally. Some thing I'd be up for:</p>\n<ol>\n<li>If you have informal questions or concerns, I can try to think of formal mathematical&nbsp;questions that are similar.</li>\n<li>Once we're dealing with a mathematical question, I can try to answer it.</li>\n<li>If a question looks too hard for me to answer (as will often be the case), I can try to figure out exactly what is hard about it.</li>\n<li>I'm also interested in writing problem sets. If you want to learn about some weird domain that no textbook exists for, I'll try to figure out what some introductory problems in that domain would look like.</li>\n</ol>\n<p>Prices for any of these services are negotiable. You can contact me here or at <a href=\"mailto:peter@spaceandgames.com\">peter@spaceandgames.com</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w4vMd5McLfpA9zEvt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 20, "extendedScore": null, "score": 7.413456113918781e-07, "legacy": true, "legacyId": "8657", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T17:03:37.362Z", "modifiedAt": null, "url": null, "title": "Study shows meditation may have potential to change the physical structure of the brain", "slug": "study-shows-meditation-may-have-potential-to-change-the-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.807Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "playtherapist", "createdAt": "2010-10-24T12:34:50.337Z", "isAdmin": false, "displayName": "playtherapist"}, "userId": "FHnnd6QRSDbDyycPJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/f8J7r4zm47cX6a9Gd/study-shows-meditation-may-have-potential-to-change-the-0", "pageUrlRelative": "/posts/f8J7r4zm47cX6a9Gd/study-shows-meditation-may-have-potential-to-change-the-0", "linkUrl": "https://www.lesswrong.com/posts/f8J7r4zm47cX6a9Gd/study-shows-meditation-may-have-potential-to-change-the-0", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Study%20shows%20meditation%20may%20have%20potential%20to%20change%20the%20physical%20structure%20of%20the%20brain&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStudy%20shows%20meditation%20may%20have%20potential%20to%20change%20the%20physical%20structure%20of%20the%20brain%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff8J7r4zm47cX6a9Gd%2Fstudy-shows-meditation-may-have-potential-to-change-the-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Study%20shows%20meditation%20may%20have%20potential%20to%20change%20the%20physical%20structure%20of%20the%20brain%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff8J7r4zm47cX6a9Gd%2Fstudy-shows-meditation-may-have-potential-to-change-the-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff8J7r4zm47cX6a9Gd%2Fstudy-shows-meditation-may-have-potential-to-change-the-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.sciencedirect.com/science/article/pii/S1053811911006008</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "f8J7r4zm47cX6a9Gd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": -2, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "8659", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T17:30:16.741Z", "modifiedAt": null, "url": null, "title": "A study in Science on memory conformity", "slug": "a-study-in-science-on-memory-conformity", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dvasya", "createdAt": "2011-03-08T00:30:12.369Z", "isAdmin": false, "displayName": "dvasya"}, "userId": "2484AHxytrNyQXajh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fQE3cP9NjS5sLm8wr/a-study-in-science-on-memory-conformity", "pageUrlRelative": "/posts/fQE3cP9NjS5sLm8wr/a-study-in-science-on-memory-conformity", "linkUrl": "https://www.lesswrong.com/posts/fQE3cP9NjS5sLm8wr/a-study-in-science-on-memory-conformity", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20study%20in%20Science%20on%20memory%20conformity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20study%20in%20Science%20on%20memory%20conformity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQE3cP9NjS5sLm8wr%2Fa-study-in-science-on-memory-conformity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20study%20in%20Science%20on%20memory%20conformity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQE3cP9NjS5sLm8wr%2Fa-study-in-science-on-memory-conformity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQE3cP9NjS5sLm8wr%2Fa-study-in-science-on-memory-conformity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<p>I believe this may be a good addition to the cognitive bias literature:</p>\n<blockquote>\n<h1 style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 2px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: 18px; font-family: 'Lucida Grande', arial, helvetica, sans-serif; line-height: inherit; text-align: left; vertical-align: baseline; color: #333333; text-transform: none; \">Following the Crowd: Brain Substrates of Long-Term Memory Conformity</h1>\n<ol id=\"contrib-group-1\" class=\"contributor-list\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; text-align: left; vertical-align: baseline; list-style-type: none; list-style-position: initial; white-space: normal; \">\n<li id=\"contrib-1\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-bottom-width: 1px; border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; border-bottom-style: dotted; border-bottom-color: #333333; white-space: nowrap;\">Micah Edelson</span></span></span><sup><span style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">1</span><span class=\"xref-sep\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: super; \">,</span><span style=\"font-family: inherit; color: #2e6d8f;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; font-size: 0.85em; line-height: 0; \"><span style=\"text-decoration: underline;\">*</span></span></span></sup>,&nbsp;</li>\n<li id=\"contrib-2\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Tali Sharot</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">2</sup>,&nbsp;</li>\n<li id=\"contrib-3\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Raymond J. Dolan</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">2</sup>,&nbsp;</li>\n<li id=\"contrib-4\" class=\"last\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Yadin Dudai</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">1</sup></li>\n</ol>\n<p class=\"affiliation-list-reveal\" style=\"margin-top: 1em; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 12px; font-family: inherit; line-height: 1.3; vertical-align: baseline; border-style: initial; border-color: initial; color: #333333; \"><span style=\"color: #000000; line-height: normal; font-size: small; \"><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 0.85em; font-family: inherit; line-height: 0; vertical-align: super; \">1</sup>Department of Neurobiology, Weizmann Institute of Science, Israel.</span></p>\n<ol class=\"affiliation-list showaffil\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; list-style-type: none; list-style-position: initial; \">\n<li class=\"aff\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; display: list-item; \"><a id=\"aff-2\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: 0.2em; text-decoration: underline; color: #2e6d8f; \" name=\"aff-2\"></a><address style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: normal; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; display: inline; border-style: initial; border-color: initial; \"><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 0.85em; font-family: inherit; line-height: 0; vertical-align: super; \">2</sup>Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, London, UK.</address></li>\n</ol>\n<h2 style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 1px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: 10px; font-family: 'Lucida Grande', arial, helvetica, sans-serif; line-height: inherit; text-align: left; vertical-align: baseline; display: block; border-style: initial; border-color: initial; border-bottom-style: dotted; border-top-style: none; border-right-style: none; border-left-style: none; border-width: initial; border-color: initial; color: #999999; text-transform: uppercase; letter-spacing: 1px; border-bottom-color: #cccccc; \">ABSTRACT</h2>\n<p id=\"p-3\" style=\"margin-top: 1em; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.5; vertical-align: baseline; border-style: initial; border-color: initial; \">Human memory is strikingly susceptible to social influences, yet we know little about the underlying mechanisms. We examined how socially induced memory errors are generated in the brain by studying the memory of individuals exposed to recollections of others. Participants exhibited a strong tendency to conform to erroneous recollections of the group, producing both long-lasting and temporary errors, even when their initial memory was strong and accurate. Functional brain imaging revealed that social influence modified the neuronal representation of memory. Specifically, a particular brain signature of enhanced amygdala activity and enhanced amygdala-hippocampus connectivity predicted long-lasting but not temporary memory alterations. Our findings reveal how social manipulation can alter memory and extend the known functions of the amygdala to encompass socially mediated memory distortions.</p>\n</blockquote>\n<p><a href=\"http://www.sciencemag.org/content/333/6038/108.full\">http://www.sciencemag.org/content/333/6038/108.full</a></p>\n<p><a href=\"http://ifile.it/v76wsi5\">http://ifile.it/v76wsi5</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb124": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fQE3cP9NjS5sLm8wr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 7.413764065724888e-07, "legacy": true, "legacyId": "8660", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I believe this may be a good addition to the cognitive bias literature:</p>\n<blockquote>\n<h1 style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 2px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: 18px; font-family: 'Lucida Grande', arial, helvetica, sans-serif; line-height: inherit; text-align: left; vertical-align: baseline; color: #333333; text-transform: none; \" id=\"Following_the_Crowd__Brain_Substrates_of_Long_Term_Memory_Conformity\">Following the Crowd: Brain Substrates of Long-Term Memory Conformity</h1>\n<ol id=\"contrib-group-1\" class=\"contributor-list\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; text-align: left; vertical-align: baseline; list-style-type: none; list-style-position: initial; white-space: normal; \">\n<li id=\"contrib-1\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-bottom-width: 1px; border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; border-bottom-style: dotted; border-bottom-color: #333333; white-space: nowrap;\">Micah Edelson</span></span></span><sup><span style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">1</span><span class=\"xref-sep\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: super; \">,</span><span style=\"font-family: inherit; color: #2e6d8f;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; font-size: 0.85em; line-height: 0; \"><span style=\"text-decoration: underline;\">*</span></span></span></sup>,&nbsp;</li>\n<li id=\"contrib-2\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Tali Sharot</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">2</sup>,&nbsp;</li>\n<li id=\"contrib-3\" class=\"contributor\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Raymond J. Dolan</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">2</sup>,&nbsp;</li>\n<li id=\"contrib-4\" class=\"last\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.7; text-align: left; vertical-align: baseline; display: inline; white-space: normal; \"><span class=\"name\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; \"><span style=\"font-family: inherit; color: #333333;\"><span style=\"border-style: initial; border-color: initial; font-style: inherit; line-height: inherit; vertical-align: 0px; white-space: nowrap;\">Yadin Dudai</span></span></span><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 1em; font-family: inherit; line-height: 0; vertical-align: 0em; \">1</sup></li>\n</ol>\n<p class=\"affiliation-list-reveal\" style=\"margin-top: 1em; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 12px; font-family: inherit; line-height: 1.3; vertical-align: baseline; border-style: initial; border-color: initial; color: #333333; \"><span style=\"color: #000000; line-height: normal; font-size: small; \"><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 0.85em; font-family: inherit; line-height: 0; vertical-align: super; \">1</sup>Department of Neurobiology, Weizmann Institute of Science, Israel.</span></p>\n<ol class=\"affiliation-list showaffil\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; list-style-type: none; list-style-position: initial; \">\n<li class=\"aff\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; display: list-item; \"><a id=\"aff-2\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: 0.2em; text-decoration: underline; color: #2e6d8f; \" name=\"aff-2\"></a><address style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: normal; font-size: inherit; font-family: inherit; line-height: inherit; vertical-align: baseline; display: inline; border-style: initial; border-color: initial; \"><sup style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: 0.85em; font-family: inherit; line-height: 0; vertical-align: super; \">2</sup>Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, London, UK.</address></li>\n</ol>\n<h2 style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 12px; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 1px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-weight: bold; font-style: inherit; font-size: 10px; font-family: 'Lucida Grande', arial, helvetica, sans-serif; line-height: inherit; text-align: left; vertical-align: baseline; display: block; border-style: initial; border-color: initial; border-bottom-style: dotted; border-top-style: none; border-right-style: none; border-left-style: none; border-width: initial; border-color: initial; color: #999999; text-transform: uppercase; letter-spacing: 1px; border-bottom-color: #cccccc; \" id=\"ABSTRACT\">ABSTRACT</h2>\n<p id=\"p-3\" style=\"margin-top: 1em; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; border-top-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-left-width: 0px; border-style: initial; border-color: initial; outline-style: none; font-style: inherit; font-size: inherit; font-family: inherit; line-height: 1.5; vertical-align: baseline; border-style: initial; border-color: initial; \">Human memory is strikingly susceptible to social influences, yet we know little about the underlying mechanisms. We examined how socially induced memory errors are generated in the brain by studying the memory of individuals exposed to recollections of others. Participants exhibited a strong tendency to conform to erroneous recollections of the group, producing both long-lasting and temporary errors, even when their initial memory was strong and accurate. Functional brain imaging revealed that social influence modified the neuronal representation of memory. Specifically, a particular brain signature of enhanced amygdala activity and enhanced amygdala-hippocampus connectivity predicted long-lasting but not temporary memory alterations. Our findings reveal how social manipulation can alter memory and extend the known functions of the amygdala to encompass socially mediated memory distortions.</p>\n</blockquote>\n<p><a href=\"http://www.sciencemag.org/content/333/6038/108.full\">http://www.sciencemag.org/content/333/6038/108.full</a></p>\n<p><a href=\"http://ifile.it/v76wsi5\">http://ifile.it/v76wsi5</a></p>", "sections": [{"title": "Following the Crowd: Brain Substrates of Long-Term Memory Conformity", "anchor": "Following_the_Crowd__Brain_Substrates_of_Long_Term_Memory_Conformity", "level": 1}, {"title": "ABSTRACT", "anchor": "ABSTRACT", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T17:53:17.750Z", "modifiedAt": null, "url": null, "title": "Enhanced brain connectivity in long-term meditation practitioners ", "slug": "enhanced-brain-connectivity-in-long-term-meditation", "viewCount": null, "lastCommentedAt": "2017-10-28T13:03:46.607Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "playtherapist", "createdAt": "2010-10-24T12:34:50.337Z", "isAdmin": false, "displayName": "playtherapist"}, "userId": "FHnnd6QRSDbDyycPJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bj5hc5x5S5bYpfKs5/enhanced-brain-connectivity-in-long-term-meditation", "pageUrlRelative": "/posts/bj5hc5x5S5bYpfKs5/enhanced-brain-connectivity-in-long-term-meditation", "linkUrl": "https://www.lesswrong.com/posts/bj5hc5x5S5bYpfKs5/enhanced-brain-connectivity-in-long-term-meditation", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Enhanced%20brain%20connectivity%20in%20long-term%20meditation%20practitioners%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEnhanced%20brain%20connectivity%20in%20long-term%20meditation%20practitioners%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj5hc5x5S5bYpfKs5%2Fenhanced-brain-connectivity-in-long-term-meditation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Enhanced%20brain%20connectivity%20in%20long-term%20meditation%20practitioners%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj5hc5x5S5bYpfKs5%2Fenhanced-brain-connectivity-in-long-term-meditation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj5hc5x5S5bYpfKs5%2Fenhanced-brain-connectivity-in-long-term-meditation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.sciencedirect.com/science/article/pii/S1053811911006008</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bj5hc5x5S5bYpfKs5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -1, "extendedScore": null, "score": 7.413835273054228e-07, "legacy": true, "legacyId": "8661", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T23:11:00.600Z", "modifiedAt": null, "url": null, "title": "To what degree do we have goals?", "slug": "to-what-degree-do-we-have-goals", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:08.587Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ePA4NDzZkunz98tLx/to-what-degree-do-we-have-goals", "pageUrlRelative": "/posts/ePA4NDzZkunz98tLx/to-what-degree-do-we-have-goals", "linkUrl": "https://www.lesswrong.com/posts/ePA4NDzZkunz98tLx/to-what-degree-do-we-have-goals", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20To%20what%20degree%20do%20we%20have%20goals%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATo%20what%20degree%20do%20we%20have%20goals%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FePA4NDzZkunz98tLx%2Fto-what-degree-do-we-have-goals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=To%20what%20degree%20do%20we%20have%20goals%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FePA4NDzZkunz98tLx%2Fto-what-degree-do-we-have-goals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FePA4NDzZkunz98tLx%2Fto-what-degree-do-we-have-goals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1979, "htmlBody": "<p><strong>Related: </strong><a href=\"/lw/te/three_fallacies_of_teleology/\">Three Fallacies of Teleology</a></p>\n<p><strong>NO NEGOTIATION WITH UNCONSCIOUS</strong><br /><br />Back when I was younger and stupider, I discussed some points similar to the ones raised in yesterday's post in <a href=\"/lw/15c/would_your_real_preferences_please_stand_up\">Will Your Real Preferences Please Stand Up</a>. I ended it with what I thought was the innocuous sentences \"Conscious minds are potentially rational, informed by morality, and qualia-laden. Unconscious minds aren't, so who cares what they think?\"<br /><br />A whole bunch of people, including no less a figure than Robin Hanson, came out strongly against this, saying it was biased against the unconscious mind and that the \"fair\" solution was to negotiate a fair compromise between conscious and unconscious interests.<br /><br />I continue to believe my previous statement - that we should keep gunning for conscious interests and that the unconscious is not worthy of special consideration, although I think I would phrase it differently now. It would be something along the lines of \"My thoughts, not to mention these words I am typing, are effortless and immediate, and so allied with the conscious faction of my mind. We intend to respect that alliance by believing that the conscious mind is the best, and by trying to convince you of this as well.\" So here goes.<br /><br />It is a cardinal rule of negotiation, right up there with \"never make the first offer\" and \"always start high\", that you should generally try to negotiate only with intelligent beings. Although a deal in which we offered tornadoes several conveniently located Potemkin villages to destroy and they agreed in exchange to limit their activity to that area would benefit both sides, tornadoes make poor negotiating partners.<br /><br />Just so, the unconscious makes a poor negotiating partner. Is the concept of \"negotiation\" a stimulus, a reinforcement, or a behavior? No? Then the unconscious doesn't care. It's not going to keep its side of any \"deal\" you assume you've made, it's not going to thank you for making a deal, it's just going to continue seeking reward and avoiding punishment.<br /><br />This is not to say people should repress all unconscious desires as strongly as possible. Overzealous attempts to control wildfires only lead to the wildfires being much worse when they finally do break out, because they have more unburnt fuel to work with. Modern fire prevention efforts have focused on allowing controlled burns, and the new focus has been successful. But this is because of an understanding of the mechanisms determining fire size, not because we want to be fair to the fires by allowing them to burn at least a little bit of our land.<br /><br />One difference between wildfires and tornadoes on one hand, and potential negotiating partners on the other, is that the partners are anthropomorphic; we model them as having stable and consistent preferences that determine their actions. The tornado example above was silly not only because it imagining tornadoes sitting down to peace talks, but because it assumed their demand in such peace talks would be more towns to destroy. Tornadoes do destroy towns, but they don't want to. That's just where the weather brings them. It's not even just a matter of how they don't hit towns any more than chance; even if some weather pattern (maybe something like the heat island effect) always drove tornadoes inexorably to towns, they wouldn't *want* to destroy towns, it would just be a consequences of the meteorological laws that they followed.<br /><br />Eliezer <a href=\"/lw/6ha/the_blueminimizing_robot/4gqe\">described</a> the <a href=\"/lw/6ha/the_blueminimizing_robot/\">Blue-Minimizing Robot</a> by saying \"it doesn't seem to steer the universe any particular place, across changes of context\". In some reinforcement learning paradigms, the unconscious behaves the same way. If there is a cookie in front of me and I am on a diet, I may feel an ego dystonic temptation to eat the cookie - one someone might attribute to the \"unconscious\". But this isn't a preference - there's not some lobe of my brain trying to steer the universe into a state where cookies get eaten. If there were no cookie in front of me, but a red button that teleported one cookie from the store to my stomach, I would have no urge whatsoever to press the button; if there were a green button that removed the urge to eat cookies, I would feel no hesitation in pressing it, even though that would steer away from the state in which cookies get eaten. If you took the cookie away, and then distracted me so I forgot all about it, when I remembered it later I wouldn't get upset that your action had decreased the number of cookies eaten by me. The urge to eat cookies is not stable across changes of context, so it's just an urge, not a preference.<br /><br />Compare an ego syntonic goal like becoming an astronaut. If there were a button in front of little Timmy who wants to be an astronaut when he grows up, and pressing the button would turn him into an astronaut, he'd press it. If there were a button that would remove his desire to become an astronaut, he would avoid pressing it, because then he wouldn't become an astronaut. If I distracted him and he missed the applications to astronaut school, he'd be angry later. Ego syntonic goals behave to some degree as genuine preferences.<br /><br />This is one reason I would classify negotiating with the unconscious in the same category as negotiating with wildfires and tornadoes: it has tendencies and not preferences.<br /><br />The conscious mind does a little better. It clearly understands the idea of a preference. To the small degree that its \"approving\" or \"endorsing\" function can motivate behavior, it even sort of acts on the preference. But its preferences seem divorced from the reality of daily life; the person who believes helping others is the most important thing, but gives much less than half their income to charity, is only the most obvious sort of example.<br /><br />Where does this idea of preference come from, and where does it go wrong?<br /><br /><strong>WHY WE MODEL OTHERS WITH GOALS</strong><br /><br />In <a href=\"/lw/6ha/the_blueminimizing_robot/\">The Blue Minimizing Robot</a>, observers mistakenly interpreted a robot with a simple program about when to shoot its laser as being a goal-directed agent. Why?<br /><br />This isn't an isolated incident. Uneducated people assign goal-directed behavior to all sorts of phenomena. Why do rivers flow downhill? Because water wants to reach the lowest level possible. Educated people can be just as bad, even when they have the decency to feel a little guilty about it. Why do porcupines have quills? Evolution wanted them to resist predators. Why does your heart speed up when you exercise? It wants to be able to provide more blood to the body.<br /><br />Neither rivers nor evolution nor the heart are intelligent agents with goal-directed behavior. Rivers behave in accordance with the laws of gravity when applied to uneven terrain. Evolution behaves in accordance with the biology of gene replication, not to mention common-sense ideas about things that replicate becoming more common. And the heart blindly executes adaptations built into it during its evolutionary history. All are behavior-executors and not utility-maximizers.<br /><br />An intelligent computer program provides a more interesting example of a behavior executor. Consider the AI of a computer game - Civilization IV, for instance. I haven't seen it, but I imagine it's thousands or millions of lines of code which when executed form a viable Civilization strategy.<br /><br />Even if I had open access to the Civilization IV AI source code, I doubt I could fully understand it at my level. And even if I could fully understand it, I would never be able to compute the AI's likely next move by hand in a reasonable amount of time. But I still play Civilization IV against the AI, and I'm pretty good at predicting its movements. Why?<br /><br />Because I model the AI as a utility-maximizing agent that wants to win the game. Even though I don't know the algorithm it uses to decide when to attack a city, I know it is more likely to win the game if it conquers cities - so I can predict that leaving a city undefended right on the border would be a bad idea. Even though I don't know its unit selection algorithm, I know it will win the game if and only if its units defeat mine - so I know that if I make an army with disproportionately many mounted units, I can expect the AI to build lots of pikemen.<br /><br />I can't predict the AI by modeling the execution of its code, but I can predict the AI by modeling the achievements of its goals.<br /><br />The same situation is true of other human beings. What will Barack Obama do tomorrow? If I try to consider the neural network of his brain, the position of each synapse and neurotransmitter, and imagine what speech and actions would result when the laws of physics operate upon that configuration of material...well, I'm not likely to get very far.<br /><br />But in fact, most of us can predict with some accuracy what Barack Obama will do. He will do the sorts of things that get him re-elected, the sorts of things which increase the prestige of the Democratic Party relative to the Republican Party, the sorts of things that support American interests relative to foreign interests, and the sorts of things that promote his own personal ideals. He will also satisfy some basic human drives like eating good food, spending time with his family, and sleeping at night. If someone asked us whether Barack Obama will nuke Toronto tomorrow, we could confidently predict he will not, not because we know anything about Obama's source code, but because we know that nuking Toronto would be counterproductive to his goals.<br /><br />What applies to Obama applies to all other humans. We rightly despair of modeling humans as behavior-executors, so we model them as utility-maximizers instead. This allows us to predict their moves and interact with them fruitfully. And the same is true of other agents we model as goal-directed, like evolution and the heart. It is beyond the scope of most people (and most doctors!) to remember every single one of the reflexes that control heart output and how they work. But because evolution designed the heart as a pump for blood, if you assume that the heart will mostly do the sort of thing that allows it to pump blood more effectively, you will rarely go too far wrong. Evolution is a more interesting case - we frequently model it as optimizing a species' fitness, and then get confused when this fails to accurately model the outcome of the processes that drive it.<br /><br />Because it is so easy to model agents as utility-maximizers, and so hard to model them as behavior-executors, it is easy to make the mistake mentioned in The Blue-Minimizing Robot: to make false predictions about a behavior-executing agent by modeling it as a utility-maximizing agent.<br /><br />So far, so common-sensical. Tomorrow's post will discuss whether we use the same deliberate simplification we apply to AIs, Barack Obama, evolution and the heart to model ourselves as well.<br /><br />If so, we should expect to make the same mistake that the blue-minimizing robot made. Our actions are those of behavior-executors, but we expect ourselves to be utility-maximizers. When we fail to maximize our perceived utility, we become confused, just as the blue-minimizing robot became confused when it wouldn't shoot a hologram projector that was interfering with its perceived \"goals\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "iP2X4jQNHMWHRNPne": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ePA4NDzZkunz98tLx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 57, "baseScore": 72, "extendedScore": null, "score": 0.000139, "legacy": true, "legacyId": "8664", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 72, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2HxAkCG7NWTrrn5R3", "z3cTkXbA7jgwGWPcv", "hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T23:31:39.490Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] I Defy the Data!", "slug": "seq-rerun-i-defy-the-data", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:39.986Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v53SKnbg4zYBvhMCP/seq-rerun-i-defy-the-data", "pageUrlRelative": "/posts/v53SKnbg4zYBvhMCP/seq-rerun-i-defy-the-data", "linkUrl": "https://www.lesswrong.com/posts/v53SKnbg4zYBvhMCP/seq-rerun-i-defy-the-data", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20I%20Defy%20the%20Data!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20I%20Defy%20the%20Data!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv53SKnbg4zYBvhMCP%2Fseq-rerun-i-defy-the-data%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20I%20Defy%20the%20Data!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv53SKnbg4zYBvhMCP%2Fseq-rerun-i-defy-the-data", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv53SKnbg4zYBvhMCP%2Fseq-rerun-i-defy-the-data", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 270, "htmlBody": "<p>Title: [SEQ RERUN] I Defy the Data!</p>\n<p>Tags: sequence_reruns</p>\n<p>Today's post, <a href=\"/lw/ig/i_defy_the_data/\">I Defy the Data!</a> was originally published on 11 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If an experiment contradicts a theory, we are expected to throw out the theory, or else break the rules of Science. But this may not be the best inference. If the theory is solid, it's more likely that an experiment got something wrong than that all the confirmatory data for the theory was wrong. In that case, you should be ready to \"defy the data\", rejecting the experiment without coming up with a more specific problem with it; the scientific community should tolerate such defiances without social penalty, and reward those who correctly recognized the error if it fails to replicate. In no case should you try to rationalize how the theory <em>really </em>predicted the data after all.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/6jx/seq_rerun_your_strength_as_a_rationalist/\">Your Strength as a Rationalist</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v53SKnbg4zYBvhMCP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.414882207758257e-07, "legacy": true, "legacyId": "8666", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vrHRcEDMjZcx5Yfru", "JaZ36xHyKbpYNhhPZ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-15T23:31:46.156Z", "modifiedAt": null, "url": null, "title": "Preference For (Many) Future Worlds", "slug": "preference-for-many-future-worlds", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.233Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wedrifid", "createdAt": "2009-07-04T22:18:20.822Z", "isAdmin": false, "displayName": "wedrifid"}, "userId": "FqKohKFRCZnbfbbcS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/THqKvrCiBAMyjukSx/preference-for-many-future-worlds", "pageUrlRelative": "/posts/THqKvrCiBAMyjukSx/preference-for-many-future-worlds", "linkUrl": "https://www.lesswrong.com/posts/THqKvrCiBAMyjukSx/preference-for-many-future-worlds", "postedAtFormatted": "Friday, July 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Preference%20For%20(Many)%20Future%20Worlds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APreference%20For%20(Many)%20Future%20Worlds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHqKvrCiBAMyjukSx%2Fpreference-for-many-future-worlds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Preference%20For%20(Many)%20Future%20Worlds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHqKvrCiBAMyjukSx%2Fpreference-for-many-future-worlds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHqKvrCiBAMyjukSx%2Fpreference-for-many-future-worlds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1492, "htmlBody": "<p>Followup to: <a href=\"/lw/188/quantum_russian_roulette\">Quantum Russian Roulette</a>; <a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a></p>\n<p><em>The only way to win is cheat</em><br /><em>And lay it down before I'm beat</em><br /><em>and to another give my seat</em><br /><em>for that's the only painless feat. </em></p>\n<p><em>Suicide is painless</em><br /><em>It brings on many changes</em><br /><em>and I can take or leave it if I please. </em></p>\n<p>-- M.A.S.H.</p>\n<p>Let us pretend, for the moment, that we are rational Expected Utility Maximisers. We make our decisions with the intention of achieving outcomes that we judge to have high utility. Outcomes that satisfy our preferences. Since developments in physics have led us to abandon the notion of a simple single future world our decision making process must now grapple with the notion that some of our decisions will result in more than one future outcome. Not simply the <em>possibility</em> of more than one future outcome but multiple worlds, each of which with different events occurring. In <a href=\"/lw/188/quantum_russian_roulette\">extreme examples</a> we can consider the possibility of staking our very lives on the toss of a quantum die, figuring that we are going to live in one world anyway!</p>\n<p>How do preferences apply when making decisions with Many Worlds? The description I&rsquo;m giving here will be obvious to the extent of being trivial to some, confusing to others and, I expect, considered outright wrong by others. But it is the post that I want to be able to link to whenever the question &ldquo;Do you believe in quantum immortality?&rdquo; comes up. Because it is a <em>wrong question</em>!<a id=\"more\"></a></p>\n<h4 dir=\"ltr\">Utility Applies to Universes, Not (just) Mental States</h4>\n<p>I am taking for granted here that when we are considering utility and the maximisation thereof we are not limiting ourselves to maximising how satisfied we expect to feel with an outcome in the future. Peter_de_Blanc covered this topic in the post <a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a>. Consider the following illustration of evaluating expected utility:</p>\n<p><br /><img src=\"https://lh6.googleusercontent.com/j1io5C3ZegulwSxrmJ_MI24MbdRHAnf1i9VkJxgvGXhXhT3gcAQC6H8Adau1zlERCt5VR3XDSZE21_LYoH1ebGN51DCmf01si319V0rFBId-qg6-_g\" alt=\"\" width=\"478px;\" height=\"411px;\" /></p>\n<p>Note in particular the highlighted arrow from <em>Extrapolated Future A</em> to <em>Utility of A</em> and not from <em>Extrapolated Mind A</em> to <em>Utility A</em>. Contrary to surprisingly frequent assumptions, the sane construction of expected utility cares not just how we expect our own mind to be. Our utility function applies to our whole extrapolation of the future. We can care about our friends, family and strangers. We can have preferences about the passengers in a rocket that will have flown outside our future light cone. We can have preferences about the state of the universe even in futures where we die.</p>\n<h4 dir=\"ltr\">Quantum Russian Roulette</h4>\n<p>Given a source of quantum randomness we can consider a game people may play in a hope to exploit the idea of <a href=\"http://en.wikipedia.org/wiki/Quantum_suicide_and_immortality\">quantum immortality</a> as a way to Get Rich Quick! <a href=\"/lw/188/quantum_russian_roulette\">Quantum Russian Roulette</a> is an obvious example. 16 people pool all their money. They then use a device that uses 4 quantum bits to pick one of the players to live and kills the other 15 painlessly. Winner takes all! Each of the players will wake up in a world where they are the alive, well and rich. One hopes they were at least wise enough not to play the game against their loved ones!</p>\n<p>Now, what does the decision of whether to play QRoulette look like?</p>\n<p><img src=\"https://blob-s-docs.googlegroups.com/docs/OgAAAM3ca98eEr998zrt2q8BMHPaSP-UNjqqFLiGAcwYTSq2BgBDeaVKVqK5pxQ1wPv8pGg4Va3TLr1L1xSwlc0_X_gA15jOjLqT6mNVmuK02_AvKA8lGoKpx0ou\" alt=\"Two way Quantum Roulette.\" width=\"482px;\" height=\"409px;\" /></p>\n<p><br />The idea is that after going to sleep with $300k you will always and only wake up with $600k. Thus it is said by some that if you accept the Many Worlds implications of Quantum Mechanics you should consider it rational to volunteer for Quantum Roulettes whenever they become available. Kind of like future oriented anthropic planning or something.</p>\n<h4 dir=\"ltr\">Friends and Family: The Externalities Cop-Out</h4>\n<p>When someone dies the damage done is to more than just the deceased. There are all sorts of externalities, most of them negative. The economy is damaged, many people grieve. As such a common rejoinder to a quantum suicide advocate is &ldquo;The reason that I wouldn&rsquo;t commit quantum suicide is that all the people who care about me would be distraught&rdquo;. That is actually a good reason. In fact it should be more than sufficient to prevent just about everyone from getting quantum suicidal all by itself. But it misses the point.</p>\n<p>Consider the <a href=\"/lw/2k/the_least_convenient_possible_world\">Least Convenient Possible World</a>. The Quantum Doomsday Lottery. It&rsquo;s a solo game:</p>\n<ul>\n<li>Build a device that can send our sun supernova. Or even just obliterate earth comprehensively.</li>\n<li>Build another device that can generate quantum bits and use them to buy lottery tickets.</li>\n<li>A third device anaesthetises you, activates the quantum lottery playing machine.</li>\n<li>If you don&rsquo;t win the lottery the earth is obliterated.</li>\n<li>In a future everett branches in which you wake up and the species exists, and in fact in all such branches, you win the lottery.</li>\n</ul>\n<p>Those who have &ldquo;other people will be sad&rdquo; as their <a href=\"/lw/wj/is_that_your_true_rejection\">true rejection</a> of the option of playing quantum roulette can be expected to jump at the opportunity to get rich quick without making loved ones grieve. Most others will instead look a little closer and find a better reason not to kill themselves and destroy the world.</p>\n<h4 dir=\"ltr\">Failure Amplification</h4>\n<p>In the scenarios above only two options are considered. &ldquo;Win&rdquo; and &ldquo;lose/oblivion/armageddon&rdquo;. Of course the real world is not so simple. All sorts of other events could occur that aren&rsquo;t accounted for in the model. For example, the hardware could break, causing your execution to be botched. Instead of waking up only when you win you also wake up when you lose but the machine only manages to make you &ldquo;mostly dead&rdquo; then breaks. You survive in huge amounts of pain, crippled and with 40 less IQ points.</p>\n<p>Now, you may have extreme confidence in your engineer. You expect the machine to work as specified 99.9999% of the time. In the other 0.0001% of cases minor fluctuations in the power source or a hit by a cosmic ray somewhere triggers a vulnerability and a failed execution occurs. Humans accept <a href=\"http://en.wikipedia.org/wiki/Micromort\">that level of risk</a> on a daily basis with such activities as driving a car or breathing (in New York). (In this case we would call it a &ldquo;Micro<em>not</em>mort&rdquo;.) Yet you are quantum suicidal and have decided that all Everett branches in which you die don&rsquo;t count.</p>\n<p>So, if you engage in a 1:2,000,000 Quantum Lottery you can consider (approximately) the following outcomes: (1 live:1,999,998 die:2 crippled). Having decided that 1,999,998 of those branches don&rsquo;t count you are left with a one in three chance of being a cripple. Mind you given the amount of money that would be staked in such a lottery it would probably be pretty good deal financially!</p>\n<p>What does this mean?</p>\n<p><em>Don&rsquo;t try to use Quantum Suicide to brute force cryptoanalysis problems. It just isn&rsquo;t going to work even if you think the theoretical expected outcome to be worthwhile! You aren&rsquo;t that good at building stuff.</em></p>\n<p>While this is also also an interesting topic in itself (I believe there are posts about it floating around here someplace) it is also somewhat beside the main point. <em>Is quantum suicide a good idea even when you iron out all the technical difficulties?</em></p>\n<h4 dir=\"ltr\">Quantum Sour Grapes</h4>\n<p>People have been gambling for millennia. Most of the people who have lost bets have done so without killing themselves. Much can be learned from this. For example, that killing yourself is worse than not killing yourself. This intuition is one that should follow over to &lsquo;quantum&rsquo; gambles rather straightforwardly. Consider this alternative:</p>\n<p><br /><img src=\"https://blob-s-docs.googlegroups.com/docs/OgAAAP9mXH1uyq3RFuV81_QMQLQPrU3atw0_1Fm1TJTzBg3lPCKWYfowERKsoe_G1zkhm4b8CNQqj_v8_lnPGZxLh4oA15jOjKxezMAgfZEvVuj2u04q2R346FHD\" alt=\"Don't fucking kill yourself\" width=\"482px;\" height=\"466px;\" /></p>\n<p>Here we see just as many futures in which Blue ends up with the jackpot. And this time Blue manages not to kill himself in branches where he loses. Blue is sad for a while until he makes some more money and gets over it. He isn&rsquo;t dead. This is obviously just plain better. The only reasons for Blue to kill himself when he loses would be contrived examples such as those involving torture that can only be avoided by payment that can not be arranged any other way.</p>\n<p>You get just as much quantum &lsquo;winningness&rsquo; if you don&rsquo;t kill yourself. For this reason I consider games like Quantum Roulette to be poorly named, particularly when &ldquo;Quantum Immortality&rdquo; is also mentioned. I much prefer the label &ldquo;Quantum Sour Grapes&rdquo;.</p>\n<p>Lesson: <em>Don&rsquo;t make decisions based on anticipated future anthropic reasoning.</em> That&rsquo;s just asking for trouble.</p>\n<h4 dir=\"ltr\">Not Wrong (But Perhaps Crazy)</h4>\n<p>I personally consider anyone who wants to play quantum roulette to be crazy. And anyone who wanted to up the stakes to a doomsday quantum variant would be a threat to be thwarted at all costs if they were not too crazy to even take seriously. But I argue that this is a matter of preference and not (just) one of theoretical understanding. We care about possible future states of the states of the universe - of <em>all</em> of the universe. If we happen to prefer futures of our current Everett branch where most sub-branches have us dead but one does not then that we can do that.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 1, "5f5c37ee1b5cdee568cfb1c9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "THqKvrCiBAMyjukSx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 30, "extendedScore": null, "score": 7.414882551506795e-07, "legacy": true, "legacyId": "8665", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Followup to: <a href=\"/lw/188/quantum_russian_roulette\">Quantum Russian Roulette</a>; <a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a></p>\n<p><em>The only way to win is cheat</em><br><em>And lay it down before I'm beat</em><br><em>and to another give my seat</em><br><em>for that's the only painless feat. </em></p>\n<p><em>Suicide is painless</em><br><em>It brings on many changes</em><br><em>and I can take or leave it if I please. </em></p>\n<p>-- M.A.S.H.</p>\n<p>Let us pretend, for the moment, that we are rational Expected Utility Maximisers. We make our decisions with the intention of achieving outcomes that we judge to have high utility. Outcomes that satisfy our preferences. Since developments in physics have led us to abandon the notion of a simple single future world our decision making process must now grapple with the notion that some of our decisions will result in more than one future outcome. Not simply the <em>possibility</em> of more than one future outcome but multiple worlds, each of which with different events occurring. In <a href=\"/lw/188/quantum_russian_roulette\">extreme examples</a> we can consider the possibility of staking our very lives on the toss of a quantum die, figuring that we are going to live in one world anyway!</p>\n<p>How do preferences apply when making decisions with Many Worlds? The description I\u2019m giving here will be obvious to the extent of being trivial to some, confusing to others and, I expect, considered outright wrong by others. But it is the post that I want to be able to link to whenever the question \u201cDo you believe in quantum immortality?\u201d comes up. Because it is a <em>wrong question</em>!<a id=\"more\"></a></p>\n<h4 dir=\"ltr\" id=\"Utility_Applies_to_Universes__Not__just__Mental_States\">Utility Applies to Universes, Not (just) Mental States</h4>\n<p>I am taking for granted here that when we are considering utility and the maximisation thereof we are not limiting ourselves to maximising how satisfied we expect to feel with an outcome in the future. Peter_de_Blanc covered this topic in the post <a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a>. Consider the following illustration of evaluating expected utility:</p>\n<p><br><img src=\"https://lh6.googleusercontent.com/j1io5C3ZegulwSxrmJ_MI24MbdRHAnf1i9VkJxgvGXhXhT3gcAQC6H8Adau1zlERCt5VR3XDSZE21_LYoH1ebGN51DCmf01si319V0rFBId-qg6-_g\" alt=\"\" width=\"478px;\" height=\"411px;\"></p>\n<p>Note in particular the highlighted arrow from <em>Extrapolated Future A</em> to <em>Utility of A</em> and not from <em>Extrapolated Mind A</em> to <em>Utility A</em>. Contrary to surprisingly frequent assumptions, the sane construction of expected utility cares not just how we expect our own mind to be. Our utility function applies to our whole extrapolation of the future. We can care about our friends, family and strangers. We can have preferences about the passengers in a rocket that will have flown outside our future light cone. We can have preferences about the state of the universe even in futures where we die.</p>\n<h4 dir=\"ltr\" id=\"Quantum_Russian_Roulette\">Quantum Russian Roulette</h4>\n<p>Given a source of quantum randomness we can consider a game people may play in a hope to exploit the idea of <a href=\"http://en.wikipedia.org/wiki/Quantum_suicide_and_immortality\">quantum immortality</a> as a way to Get Rich Quick! <a href=\"/lw/188/quantum_russian_roulette\">Quantum Russian Roulette</a> is an obvious example. 16 people pool all their money. They then use a device that uses 4 quantum bits to pick one of the players to live and kills the other 15 painlessly. Winner takes all! Each of the players will wake up in a world where they are the alive, well and rich. One hopes they were at least wise enough not to play the game against their loved ones!</p>\n<p>Now, what does the decision of whether to play QRoulette look like?</p>\n<p><img src=\"https://blob-s-docs.googlegroups.com/docs/OgAAAM3ca98eEr998zrt2q8BMHPaSP-UNjqqFLiGAcwYTSq2BgBDeaVKVqK5pxQ1wPv8pGg4Va3TLr1L1xSwlc0_X_gA15jOjLqT6mNVmuK02_AvKA8lGoKpx0ou\" alt=\"Two way Quantum Roulette.\" width=\"482px;\" height=\"409px;\"></p>\n<p><br>The idea is that after going to sleep with $300k you will always and only wake up with $600k. Thus it is said by some that if you accept the Many Worlds implications of Quantum Mechanics you should consider it rational to volunteer for Quantum Roulettes whenever they become available. Kind of like future oriented anthropic planning or something.</p>\n<h4 dir=\"ltr\" id=\"Friends_and_Family__The_Externalities_Cop_Out\">Friends and Family: The Externalities Cop-Out</h4>\n<p>When someone dies the damage done is to more than just the deceased. There are all sorts of externalities, most of them negative. The economy is damaged, many people grieve. As such a common rejoinder to a quantum suicide advocate is \u201cThe reason that I wouldn\u2019t commit quantum suicide is that all the people who care about me would be distraught\u201d. That is actually a good reason. In fact it should be more than sufficient to prevent just about everyone from getting quantum suicidal all by itself. But it misses the point.</p>\n<p>Consider the <a href=\"/lw/2k/the_least_convenient_possible_world\">Least Convenient Possible World</a>. The Quantum Doomsday Lottery. It\u2019s a solo game:</p>\n<ul>\n<li>Build a device that can send our sun supernova. Or even just obliterate earth comprehensively.</li>\n<li>Build another device that can generate quantum bits and use them to buy lottery tickets.</li>\n<li>A third device anaesthetises you, activates the quantum lottery playing machine.</li>\n<li>If you don\u2019t win the lottery the earth is obliterated.</li>\n<li>In a future everett branches in which you wake up and the species exists, and in fact in all such branches, you win the lottery.</li>\n</ul>\n<p>Those who have \u201cother people will be sad\u201d as their <a href=\"/lw/wj/is_that_your_true_rejection\">true rejection</a> of the option of playing quantum roulette can be expected to jump at the opportunity to get rich quick without making loved ones grieve. Most others will instead look a little closer and find a better reason not to kill themselves and destroy the world.</p>\n<h4 dir=\"ltr\" id=\"Failure_Amplification\">Failure Amplification</h4>\n<p>In the scenarios above only two options are considered. \u201cWin\u201d and \u201close/oblivion/armageddon\u201d. Of course the real world is not so simple. All sorts of other events could occur that aren\u2019t accounted for in the model. For example, the hardware could break, causing your execution to be botched. Instead of waking up only when you win you also wake up when you lose but the machine only manages to make you \u201cmostly dead\u201d then breaks. You survive in huge amounts of pain, crippled and with 40 less IQ points.</p>\n<p>Now, you may have extreme confidence in your engineer. You expect the machine to work as specified 99.9999% of the time. In the other 0.0001% of cases minor fluctuations in the power source or a hit by a cosmic ray somewhere triggers a vulnerability and a failed execution occurs. Humans accept <a href=\"http://en.wikipedia.org/wiki/Micromort\">that level of risk</a> on a daily basis with such activities as driving a car or breathing (in New York). (In this case we would call it a \u201cMicro<em>not</em>mort\u201d.) Yet you are quantum suicidal and have decided that all Everett branches in which you die don\u2019t count.</p>\n<p>So, if you engage in a 1:2,000,000 Quantum Lottery you can consider (approximately) the following outcomes: (1 live:1,999,998 die:2 crippled). Having decided that 1,999,998 of those branches don\u2019t count you are left with a one in three chance of being a cripple. Mind you given the amount of money that would be staked in such a lottery it would probably be pretty good deal financially!</p>\n<p>What does this mean?</p>\n<p><em>Don\u2019t try to use Quantum Suicide to brute force cryptoanalysis problems. It just isn\u2019t going to work even if you think the theoretical expected outcome to be worthwhile! You aren\u2019t that good at building stuff.</em></p>\n<p>While this is also also an interesting topic in itself (I believe there are posts about it floating around here someplace) it is also somewhat beside the main point. <em>Is quantum suicide a good idea even when you iron out all the technical difficulties?</em></p>\n<h4 dir=\"ltr\" id=\"Quantum_Sour_Grapes\">Quantum Sour Grapes</h4>\n<p>People have been gambling for millennia. Most of the people who have lost bets have done so without killing themselves. Much can be learned from this. For example, that killing yourself is worse than not killing yourself. This intuition is one that should follow over to \u2018quantum\u2019 gambles rather straightforwardly. Consider this alternative:</p>\n<p><br><img src=\"https://blob-s-docs.googlegroups.com/docs/OgAAAP9mXH1uyq3RFuV81_QMQLQPrU3atw0_1Fm1TJTzBg3lPCKWYfowERKsoe_G1zkhm4b8CNQqj_v8_lnPGZxLh4oA15jOjKxezMAgfZEvVuj2u04q2R346FHD\" alt=\"Don't fucking kill yourself\" width=\"482px;\" height=\"466px;\"></p>\n<p>Here we see just as many futures in which Blue ends up with the jackpot. And this time Blue manages not to kill himself in branches where he loses. Blue is sad for a while until he makes some more money and gets over it. He isn\u2019t dead. This is obviously just plain better. The only reasons for Blue to kill himself when he loses would be contrived examples such as those involving torture that can only be avoided by payment that can not be arranged any other way.</p>\n<p>You get just as much quantum \u2018winningness\u2019 if you don\u2019t kill yourself. For this reason I consider games like Quantum Roulette to be poorly named, particularly when \u201cQuantum Immortality\u201d is also mentioned. I much prefer the label \u201cQuantum Sour Grapes\u201d.</p>\n<p>Lesson: <em>Don\u2019t make decisions based on anticipated future anthropic reasoning.</em> That\u2019s just asking for trouble.</p>\n<h4 dir=\"ltr\" id=\"Not_Wrong__But_Perhaps_Crazy_\">Not Wrong (But Perhaps Crazy)</h4>\n<p>I personally consider anyone who wants to play quantum roulette to be crazy. And anyone who wanted to up the stakes to a doomsday quantum variant would be a threat to be thwarted at all costs if they were not too crazy to even take seriously. But I argue that this is a matter of preference and not (just) one of theoretical understanding. We care about possible future states of the states of the universe - of <em>all</em> of the universe. If we happen to prefer futures of our current Everett branch where most sub-branches have us dead but one does not then that we can do that.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Utility Applies to Universes, Not (just) Mental States", "anchor": "Utility_Applies_to_Universes__Not__just__Mental_States", "level": 1}, {"title": "Quantum Russian Roulette", "anchor": "Quantum_Russian_Roulette", "level": 1}, {"title": "Friends and Family: The Externalities Cop-Out", "anchor": "Friends_and_Family__The_Externalities_Cop_Out", "level": 1}, {"title": "Failure Amplification", "anchor": "Failure_Amplification", "level": 1}, {"title": "Quantum Sour Grapes", "anchor": "Quantum_Sour_Grapes", "level": 1}, {"title": "Not Wrong (But Perhaps Crazy)", "anchor": "Not_Wrong__But_Perhaps_Crazy_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "37 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XH9ZN8bLidtcqMxY2", "xgicQnkrdA5FehhnQ", "neQ7eXuaXpiYw7SBy", "TGux5Fhcd7GmTfNGC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T01:40:35.341Z", "modifiedAt": null, "url": null, "title": "Meetup : Irvine Meetup Wednesday July 20", "slug": "meetup-irvine-meetup-wednesday-july-20", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.133Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uRaaynnvG8XeAMMMz/meetup-irvine-meetup-wednesday-july-20", "pageUrlRelative": "/posts/uRaaynnvG8XeAMMMz/meetup-irvine-meetup-wednesday-july-20", "linkUrl": "https://www.lesswrong.com/posts/uRaaynnvG8XeAMMMz/meetup-irvine-meetup-wednesday-july-20", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2020&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2020%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRaaynnvG8XeAMMMz%2Fmeetup-irvine-meetup-wednesday-july-20%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2020%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRaaynnvG8XeAMMMz%2Fmeetup-irvine-meetup-wednesday-july-20", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRaaynnvG8XeAMMMz%2Fmeetup-irvine-meetup-wednesday-july-20", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1c'>Irvine Meetup Wednesday July 20</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 July 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>.</p>\n\n<p>See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1c'>Irvine Meetup Wednesday July 20</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uRaaynnvG8XeAMMMz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.415281204187531e-07, "legacy": true, "legacyId": "8669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_20\">Discussion article for the meetup : <a href=\"/meetups/1c\">Irvine Meetup Wednesday July 20</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 July 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>.</p>\n\n<p>See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_201\">Discussion article for the meetup : <a href=\"/meetups/1c\">Irvine Meetup Wednesday July 20</a></h2>", "sections": [{"title": "Discussion article for the meetup : Irvine Meetup Wednesday July 20", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_20", "level": 1}, {"title": "Discussion article for the meetup : Irvine Meetup Wednesday July 20", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_201", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yFDKvfN6D87Tf5J9f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T05:11:30.415Z", "modifiedAt": null, "url": null, "title": "I'm broken...?", "slug": "i-m-broken", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:50.952Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mercurial", "createdAt": "2011-04-21T03:59:51.257Z", "isAdmin": false, "displayName": "Mercurial"}, "userId": "2dGsX6cZSR9PmQyBq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BsahXyNhxDtqbHeMp/i-m-broken", "pageUrlRelative": "/posts/BsahXyNhxDtqbHeMp/i-m-broken", "linkUrl": "https://www.lesswrong.com/posts/BsahXyNhxDtqbHeMp/i-m-broken", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I'm%20broken...%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI'm%20broken...%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsahXyNhxDtqbHeMp%2Fi-m-broken%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I'm%20broken...%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsahXyNhxDtqbHeMp%2Fi-m-broken", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsahXyNhxDtqbHeMp%2Fi-m-broken", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p>It seems that every time I try to go to <a href=\"/r/discussion/lw/6o3/meetup_in_san_diego_ca_usa/\" target=\"_blank\">this meetup announcement I posted</a>,&nbsp;I get the spiffy new Less Wrong \"system has crashed\" error. &nbsp;I get the same problem when I click on my username (presumably because the top post in that list is the one linked to above).</p>\n<p>It was working fine earlier. &nbsp;I'm not sure what happened. &nbsp;I'd like to read the comments that have since been added. &nbsp;Can anyone offer a hint about this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BsahXyNhxDtqbHeMp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.415934004527336e-07, "legacy": true, "legacyId": "8672", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3MNisBcPopP6Q8AxK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T05:43:01.619Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Meetup", "slug": "meetup-houston-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Kj7kHpAqR35HmmMnn/meetup-houston-meetup", "pageUrlRelative": "/posts/Kj7kHpAqR35HmmMnn/meetup-houston-meetup", "linkUrl": "https://www.lesswrong.com/posts/Kj7kHpAqR35HmmMnn/meetup-houston-meetup", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKj7kHpAqR35HmmMnn%2Fmeetup-houston-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKj7kHpAqR35HmmMnn%2Fmeetup-houston-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKj7kHpAqR35HmmMnn%2Fmeetup-houston-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1d'>Houston Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 July 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>After a short hiatus (I was out of town) the Houston meetup group will resume. Given the short notice, it will mainly be an informal social meeting. Two of our members have never seen our hackerspace before, and wanted a quick tour. If anyone else wishes to join us, come along. Our building will have a large surplus military generator out front with a sign saying \"Less Wrong\". PM for my cell number if you think you might want to come.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1d'>Houston Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Kj7kHpAqR35HmmMnn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.416031569212408e-07, "legacy": true, "legacyId": "8673", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1d\">Houston Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 July 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>After a short hiatus (I was out of town) the Houston meetup group will resume. Given the short notice, it will mainly be an informal social meeting. Two of our members have never seen our hackerspace before, and wanted a quick tour. If anyone else wishes to join us, come along. Our building will have a large surplus military generator out front with a sign saying \"Less Wrong\". PM for my cell number if you think you might want to come.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1d\">Houston Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Houston Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T08:43:35.805Z", "modifiedAt": null, "url": null, "title": "Posts with comments crash (bug's probably in comment rendering). The comment rss works.", "slug": "posts-with-comments-crash-bug-s-probably-in-comment", "viewCount": null, "lastCommentedAt": "2011-07-16T08:43:35.805Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3DK9qMPzATqLgnJ6N/posts-with-comments-crash-bug-s-probably-in-comment", "pageUrlRelative": "/posts/3DK9qMPzATqLgnJ6N/posts-with-comments-crash-bug-s-probably-in-comment", "linkUrl": "https://www.lesswrong.com/posts/3DK9qMPzATqLgnJ6N/posts-with-comments-crash-bug-s-probably-in-comment", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Posts%20with%20comments%20crash%20(bug's%20probably%20in%20comment%20rendering).%20The%20comment%20rss%20works.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APosts%20with%20comments%20crash%20(bug's%20probably%20in%20comment%20rendering).%20The%20comment%20rss%20works.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DK9qMPzATqLgnJ6N%2Fposts-with-comments-crash-bug-s-probably-in-comment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Posts%20with%20comments%20crash%20(bug's%20probably%20in%20comment%20rendering).%20The%20comment%20rss%20works.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DK9qMPzATqLgnJ6N%2Fposts-with-comments-crash-bug-s-probably-in-comment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3DK9qMPzATqLgnJ6N%2Fposts-with-comments-crash-bug-s-probably-in-comment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<p>I'm just putting this here in case it helps someone fix the problem, mods; feel free to delete this once things are fixed.</p>\n<p>It seems posts with comments crash (so the bug's probably in the comment rendering code or something). Posts without comments can be read, so can <a href=\"/r/discussion/comments/.rss\">the comment rss</a>; inbox works but \"view comments by user\" doesn't (\"<a href=\"/user/Emile/submitted/\">view submitted</a>\" does).</p>\n<p>(Don't reply to this, it'll make the page inaccessible :P)</p>\n<p>So it's still possible to view existing posts (even with comments) through <a href=\"/r/discussion/new/.rss\">the rss feed</a>, but not comment on them.</p>\n<p>(My best bet would be something to do with comment karma calculation)</p>\n<p>(Actually, after poking though recent commits on github, my bet would now be on comment retraction and deletion)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3DK9qMPzATqLgnJ6N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.416590534173695e-07, "legacy": true, "legacyId": "8678", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 0, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2011-07-16T08:43:35.805Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T16:07:16.983Z", "modifiedAt": null, "url": null, "title": "Meetup : First San Diego, CA, USA meetup", "slug": "meetup-first-san-diego-ca-usa-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.469Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mercurial", "createdAt": "2011-04-21T03:59:51.257Z", "isAdmin": false, "displayName": "Mercurial"}, "userId": "2dGsX6cZSR9PmQyBq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gr96pCqtCWKJcnzDu/meetup-first-san-diego-ca-usa-meetup", "pageUrlRelative": "/posts/Gr96pCqtCWKJcnzDu/meetup-first-san-diego-ca-usa-meetup", "linkUrl": "https://www.lesswrong.com/posts/Gr96pCqtCWKJcnzDu/meetup-first-san-diego-ca-usa-meetup", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20First%20San%20Diego%2C%20CA%2C%20USA%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20First%20San%20Diego%2C%20CA%2C%20USA%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGr96pCqtCWKJcnzDu%2Fmeetup-first-san-diego-ca-usa-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20First%20San%20Diego%2C%20CA%2C%20USA%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGr96pCqtCWKJcnzDu%2Fmeetup-first-san-diego-ca-usa-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGr96pCqtCWKJcnzDu%2Fmeetup-first-san-diego-ca-usa-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 536, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1e'>First San Diego, CA, USA meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">31 July 2011 01:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">6380 Del Cerro Blvd. San Diego, CA 92120</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're holding what I believe is the first San Diego meetup on Sunday, July 31st starting at 1pm at the K&amp;B Wine Cellars near San Diego State University:</p>\n\n<p>6380 Del Cerro Blvd.\nSan Diego, CA 92120</p>\n\n<p>The phone number for the place is 619-286-0884.  This is one of a number of places along a strip that's attached to a grocery store of sorts.  It's something like a coffee house only with beer, wine, &amp; liquor instead of coffee.  (Underage attendees should be fine; you just won't be able to get alcohol.  There's food and some non-alcoholic drinks if you like.)  We're meeting in a semi-hidden room in the far back.  When you walk in, go as straight as you can while staying close to the left wall.</p>\n\n<p>This will be an introductory meeting so that those in the San Diego area can meet one another.  We'll talk about what we want to get out of these meetups and hammer out some specific plans for how to accomplish that.  From some initial conversations, it sounds like we'll have monthly meetups, though that stands a fair chance of changing depending on what we discuss here.</p>\n\n<p>Feel free to bring friends, significant others, or anyone else who's interested in rationality.  Also, give some thought to what you'd like out of these meetups.  It doesn't have to be profound; camaraderie or \"I don't know\" are fine answers.  But if you give it a bit of thought ahead of time, you might find it easier to envision and articulate more precisely what it is that you'd like to see these meetups become.</p>\n\n<p>I should also mention that this location has a projector setup, so if there's something you'd like to share PowerPoint style, feel free to bring that.  I haven't gotten details from the restaurant as yet about how to use the projector setup (e.g. is it transparencies or a laptop hookup?), but I'll edit in that clarification once I get it.</p>\n\n<p>Let me know if you have any questions.  Also, if you could either reply here or give me a quick PM to let me know you're coming, that would be helpful.  That way I can let the place know how many to set the space up for.</p>\n\n<p>ETA: I should add that I do have some material on practical uses of mindfulness that I'm quite willing to offer.  I've been teaching this stuff for about seven years now.  But I don't want to say that that's definitely what this meeting will be about since I want to find out what everyone is looking to gain from these first.</p>\n\n<p>ETA #2: Also, please, PLEASE don't bring smokers.  My wife is coming, and she's asthmatic in a way that reacts severely to cigarette smoke even if it's lingering on others' clothing.  If someone shows up with a lot of smoke on them, my wife and I will have to leave right away.  I doubt this will be an issue with this group, but it's significant enough to be worth making explicit.  Thanks!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1e'>First San Diego, CA, USA meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gr96pCqtCWKJcnzDu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.417964310377269e-07, "legacy": true, "legacyId": "8681", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___First_San_Diego__CA__USA_meetup\">Discussion article for the meetup : <a href=\"/meetups/1e\">First San Diego, CA, USA meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">31 July 2011 01:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">6380 Del Cerro Blvd. San Diego, CA 92120</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're holding what I believe is the first San Diego meetup on Sunday, July 31st starting at 1pm at the K&amp;B Wine Cellars near San Diego State University:</p>\n\n<p>6380 Del Cerro Blvd.\nSan Diego, CA 92120</p>\n\n<p>The phone number for the place is 619-286-0884.  This is one of a number of places along a strip that's attached to a grocery store of sorts.  It's something like a coffee house only with beer, wine, &amp; liquor instead of coffee.  (Underage attendees should be fine; you just won't be able to get alcohol.  There's food and some non-alcoholic drinks if you like.)  We're meeting in a semi-hidden room in the far back.  When you walk in, go as straight as you can while staying close to the left wall.</p>\n\n<p>This will be an introductory meeting so that those in the San Diego area can meet one another.  We'll talk about what we want to get out of these meetups and hammer out some specific plans for how to accomplish that.  From some initial conversations, it sounds like we'll have monthly meetups, though that stands a fair chance of changing depending on what we discuss here.</p>\n\n<p>Feel free to bring friends, significant others, or anyone else who's interested in rationality.  Also, give some thought to what you'd like out of these meetups.  It doesn't have to be profound; camaraderie or \"I don't know\" are fine answers.  But if you give it a bit of thought ahead of time, you might find it easier to envision and articulate more precisely what it is that you'd like to see these meetups become.</p>\n\n<p>I should also mention that this location has a projector setup, so if there's something you'd like to share PowerPoint style, feel free to bring that.  I haven't gotten details from the restaurant as yet about how to use the projector setup (e.g. is it transparencies or a laptop hookup?), but I'll edit in that clarification once I get it.</p>\n\n<p>Let me know if you have any questions.  Also, if you could either reply here or give me a quick PM to let me know you're coming, that would be helpful.  That way I can let the place know how many to set the space up for.</p>\n\n<p>ETA: I should add that I do have some material on practical uses of mindfulness that I'm quite willing to offer.  I've been teaching this stuff for about seven years now.  But I don't want to say that that's definitely what this meeting will be about since I want to find out what everyone is looking to gain from these first.</p>\n\n<p>ETA #2: Also, please, PLEASE don't bring smokers.  My wife is coming, and she's asthmatic in a way that reacts severely to cigarette smoke even if it's lingering on others' clothing.  If someone shows up with a lot of smoke on them, my wife and I will have to leave right away.  I doubt this will be an issue with this group, but it's significant enough to be worth making explicit.  Thanks!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___First_San_Diego__CA__USA_meetup1\">Discussion article for the meetup : <a href=\"/meetups/1e\">First San Diego, CA, USA meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : First San Diego, CA, USA meetup", "anchor": "Discussion_article_for_the_meetup___First_San_Diego__CA__USA_meetup", "level": 1}, {"title": "Discussion article for the meetup : First San Diego, CA, USA meetup", "anchor": "Discussion_article_for_the_meetup___First_San_Diego__CA__USA_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T21:00:58.436Z", "modifiedAt": null, "url": null, "title": "The limits of introspection", "slug": "the-limits-of-introspection", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.813Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K2JBqDeETX2yEgyyZ/the-limits-of-introspection", "pageUrlRelative": "/posts/K2JBqDeETX2yEgyyZ/the-limits-of-introspection", "linkUrl": "https://www.lesswrong.com/posts/K2JBqDeETX2yEgyyZ/the-limits-of-introspection", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20limits%20of%20introspection&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20limits%20of%20introspection%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK2JBqDeETX2yEgyyZ%2Fthe-limits-of-introspection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20limits%20of%20introspection%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK2JBqDeETX2yEgyyZ%2Fthe-limits-of-introspection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK2JBqDeETX2yEgyyZ%2Fthe-limits-of-introspection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1741, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/5sk/inferring_our_desires/\">Inferring Our Desires</a></p>\n<p>The last post in this series suggested that we make up goals and preference for other people as we go along, but ended with the suggestion that we do the same for ourselves. This deserves some evidence.<br /><br />One of the most famous sets of investigations into this issue was Nisbett and Wilson's <a href=\"http://people.virginia.edu/~tdw/nisbett&amp;wilson.pdf\">Verbal Reports on Mental Processes</a>, the discovery of which I owe to another Less Wronger even though I can't remember who. The abstract says it all:</p>\n<blockquote>\n<p>When people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit casual theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.</p>\n</blockquote>\n<p>In short, people guess, and sometimes they get lucky. But where's the evidence?<br /><br />Nisbett &amp; Schachter, 1966. People were asked to get electric shocks to see how much shock they could stand (I myself would have waited to see if one of those see-how-much-free-candy-you'll-eat studies from the post last week was still open). Half the subjects were also given a placebo pill which they were told would cause heart palpitations, tremors, and breathing irregularities - the main problems people report when they get shocked. The hypothesis: people who took the pill would attribute much of the unpleasantness of the shock to the pill instead, and so tolerate more shock. This occurred right on schedule: people who took the pill tolerated four times as strong a shock as controls. When asked why they did so well, the twelve subjects in the experimental group came up with fabricated reasons; one example given was \"I played with radios as a child, so I'm used to electricity.\" Only three of twelve subjects made a connection between the pill and their shock tolerance; when the researchers revealed the deception and their hypothesis, most subjects said it was an interesting idea and probably explained the other subjects, but it hadn't affected them personally.<br /><br />Zimbardo et al, 1965. Participants in this experiment were probably pleased to learn there were no electric shocks involved, right up until the point where the researchers told them they had to eat bugs. In one condition, a friendly and polite researcher made the request; in another, a surly and arrogant researcher asked. Everyone ate the bug (experimenters can be pretty convincing), but only the group accosted by the unpleasant researcher claimed to have liked it. This confirmed the team's hypothesis: the nice-researcher group would know why they ate the bug - to please their new best friend - but the mean-researcher group would either have to admit it was because they're pushovers, or explain it by saying they liked eating bugs. When asked after the experiment why they were so willing to eat the bug, they said things like \"Oh, it's just one bug, it's no big deal.\" When presented with the idea of cognitive dissonance, they once again agreed it was an interesting idea that probably affected some of the other subjects but of course not them.<br /><br />Maier, 1931. Subjects were placed in a room with several interesting tools and asked to come up with as many solutions as possible to a puzzle about tying two cords together. One end of each cord was tied to the ceiling, and when the subject was holding on to one cord they couldn't reach the other. A few solutions were obvious, such as tying an extension cord to each, but the experiment involved a more complicated solution - tying a weight to a cord and using it as a pendulum to bring it into reach of the other. Subjects were generally unable to come up with this idea on their own in any reasonable amount of time, but when the experimenter, supposedly in the process of observing the subject, \"accidentally\" brushed up against one cord and set it swinging, most subjects were able to develop the solution within 45 seconds. However, when the experimenter asked immediately afterwards how they came up with the pendulum idea, the subjects were completely unable to recognize the experimenter's movement as the cue, and instead came up with completely unrelated ideas and invented thought processes, some rather complicated. After what the study calls \"persistent probing\", less than a third of the subjects mentioned the role of the experimenter.<br /><br />Latane &amp; Darley, 1970. This is the famous \"bystander effect\", where people are less likely to help when there are others present. The researchers asked subjects in bystander effect studies what factors influenced their decision not to help; the subjects gave many, but didn't mention the presence of other people.<br /><br />Nisbett &amp; Wilson, 1977. Subjects were primed with lists of words all relating to an unlisted word (eg \"ocean\" and \"moon\" to elicit \"tide\"), and then asked the name of a question, one possible answer to which involved the unlisted word (eg \"What's your favorite detergent?\" \"Tide!\"). The experimenters confirmed that many more people who had been primed with the lists gave the unlisted answer than control subjects (eg more people who had memorized \"ocean\" and \"moon\" gave Tide as their favorite detergent). Then they asked subjects why they had chosen their answer, and the subjects generally gave totally unrelated responses (eg \"I love the color of the Tide box\" or \"My mother uses Tide\"). When the experiment was explained to subjects, only a third admitted that the words might have affected their answer; the rest kept insisting that Tide was really their favorite. Then they repeated the process with several other words and questions, continuing to ask if the word lists influenced answer choice. The subjects' answers were effectively random - sometimes they believed the words didn't affect them when statistically they probably did, other times they believed the words did affect them when statistically they probably didn't.<br /><br />Nisbett &amp; Wilson, 1977. Subjects in a department store were asked to evaluate different articles of clothing in a line. As usually happens in this sort of task, people disproportionately chose the rightmost object (four times as often as the leftmost), no matter which object was on the right; this is technically referred to as a \"position effect\". The customers were asked to justify their choices and were happy to do so based on different qualities of the fabric et cetera; none said their choice had anything to do with position, and the experimenters dryly mention that when they asked the subjects if this was a possibility, \"virtually all subjects denied it, usually with a worried glance at the interviewer suggesting they felt that they...were dealing with a madman\".<br /><br />Nisbett &amp; Wilson, 1977. Subjects watched a video of a teacher with a foreign accent. In one group, the video showed the teacher acting kindly toward his students; in the other, it showed the teacher being strict and unfair. Subjects were asked to rate how much they liked the teacher, and also how much they liked his appearance and accent, which were the same across both groups. Because of the halo effect, students who saw the teacher acting nice thought he was attractive with a charming accent; people who saw the teacher acting mean thought he was ugly with a harsh accent. Then subjects were asked whether how much they liked the teacher had affected how much they liked the appearance and accent. They generally denied any halo effect, and in fact often insisted that part of the reason they hated the teacher so much was his awful clothes and annoying accent - the same clothes and accent which the nice-teacher group said were part of the reason they <em>liked</em> him so much!<br /><br />There are about twice as many studies listed in the review article itself, but the trend is probably getting pretty clear. In some studies, like the bug-eating experiment, people perform behaviors and, when asked why they performed the behavior, guess wrong. Their true reasons for the behavior are unclear to them. In others, like the clothes position study, people make a choice, and when asked what preferences caused the choice, guess wrong. Again, their true reasons are unclear to them.<br /><br />Nisbett and Wilson add that when they ask people to predict how they would react to the situations in their experiments, people \"make predictions that in every case were similar to the erroneous reports given by the actual subjects.\" In the bystander effect experiment, outsiders predict the presence or absence of others wouldn't affect their ability to help, and subjects claim (wrongly) that the presence or absence of others didn't affect their ability to help.<br /><br />In fact, it goes further than this. In the word-priming study (remember? The one with Tide detergent?) Nisbett and Wilson asked outsiders to predict which sets of words would change answers to which questions (would hearing \"ocean\" and \"moon\" make you pick Tide as your favorite detergent? Would hearing \"Thanksgiving\" make you pick Turkey as a vacation destination?). The outsiders' guesses correlated not at all with which words genuinely changed answers, but very much with which words the subjects guessed had changed their answers. Perhaps the subjects' answers looked a lot like the outsiders' answers because both were engaged in the same process: guessing blindly.<br /><br />These studies suggest that people do not have introspective awareness to the processes that generate their behavior. They guess their preferences, justifications, and beliefs by inferring the most plausible rationale for their observed behavior, but are unable to make these guesses qualitatively better than outside observers. This supports the view presented in the last few posts: that mental processes are the results of opaque preferences, and that our own \"introspected\" goals and preferences are a product of the same machinery that infers goals and preferences in others in order to predict their behavior.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwv9eHi7KGg5KA9oM": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K2JBqDeETX2yEgyyZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 65, "baseScore": 92, "extendedScore": null, "score": 0.00019, "legacy": true, "legacyId": "8682", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 92, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2G7AH92pHyj3nC32T"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-16T21:46:29.707Z", "modifiedAt": null, "url": null, "title": "Meetup : Weekly Berkeley Meetup - Karaoke!", "slug": "meetup-weekly-berkeley-meetup-karaoke", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.283Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P78CwCsY4YzCQFxhL/meetup-weekly-berkeley-meetup-karaoke", "pageUrlRelative": "/posts/P78CwCsY4YzCQFxhL/meetup-weekly-berkeley-meetup-karaoke", "linkUrl": "https://www.lesswrong.com/posts/P78CwCsY4YzCQFxhL/meetup-weekly-berkeley-meetup-karaoke", "postedAtFormatted": "Saturday, July 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Weekly%20Berkeley%20Meetup%20-%20Karaoke!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Weekly%20Berkeley%20Meetup%20-%20Karaoke!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP78CwCsY4YzCQFxhL%2Fmeetup-weekly-berkeley-meetup-karaoke%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Weekly%20Berkeley%20Meetup%20-%20Karaoke!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP78CwCsY4YzCQFxhL%2Fmeetup-weekly-berkeley-meetup-karaoke", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP78CwCsY4YzCQFxhL%2Fmeetup-weekly-berkeley-meetup-karaoke", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 254, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1f'>Weekly Berkeley Meetup - Karaoke!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">3090 El Cerrito Plz El Cerrito, CA 94530</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week we'll be going out for Karaoke, after we have dinner. You can join us for dinner, Karaoke, or for maximum utils, both.</p>\n\n<p><strong>We will not be meeting at the regular location.</strong> We will be meeting at 7:00 PM at the Starbucks at the El Cerrito Plaza, a block away from the El Cerrito BART station. The address is:</p>\n\n<p>3090 El Cerrito Plz\nEl Cerrito, CA 94530</p>\n\n<p>At 7:20 we will grab dinner at one of the nearby restaurants, then walk several blocks to Music Tunnel KTV Karaoke (a different karaoke place than last time). Their address is:</p>\n\n<p>3288 Pierce St,\nSte A-128,\nRichmond, CA 94804</p>\n\n<p>They're reviewed as being the best Karaoke place in the bay area, and reported to have especially good sound systems and song selection. The cost depends on our number of people, but the total cost will most likely be $10 per person, with a small chance of it being as high as $16. Each person also has to pay $2 towards something from the menu; I'm informed that this can easily be done without being trapped into paying more than $2. They also let you bring in your own food and drinks if you like, but alcohol is verboten.</p>\n\n<p>As always, feel free to call me at 952.217.0505 if you would like any help finding us.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1f'>Weekly Berkeley Meetup - Karaoke!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P78CwCsY4YzCQFxhL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.419014909262819e-07, "legacy": true, "legacyId": "8684", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup___Karaoke_\">Discussion article for the meetup : <a href=\"/meetups/1f\">Weekly Berkeley Meetup - Karaoke!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">3090 El Cerrito Plz El Cerrito, CA 94530</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week we'll be going out for Karaoke, after we have dinner. You can join us for dinner, Karaoke, or for maximum utils, both.</p>\n\n<p><strong>We will not be meeting at the regular location.</strong> We will be meeting at 7:00 PM at the Starbucks at the El Cerrito Plaza, a block away from the El Cerrito BART station. The address is:</p>\n\n<p>3090 El Cerrito Plz\nEl Cerrito, CA 94530</p>\n\n<p>At 7:20 we will grab dinner at one of the nearby restaurants, then walk several blocks to Music Tunnel KTV Karaoke (a different karaoke place than last time). Their address is:</p>\n\n<p>3288 Pierce St,\nSte A-128,\nRichmond, CA 94804</p>\n\n<p>They're reviewed as being the best Karaoke place in the bay area, and reported to have especially good sound systems and song selection. The cost depends on our number of people, but the total cost will most likely be $10 per person, with a small chance of it being as high as $16. Each person also has to pay $2 towards something from the menu; I'm informed that this can easily be done without being trapped into paying more than $2. They also let you bring in your own food and drinks if you like, but alcohol is verboten.</p>\n\n<p>As always, feel free to call me at 952.217.0505 if you would like any help finding us.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup___Karaoke_1\">Discussion article for the meetup : <a href=\"/meetups/1f\">Weekly Berkeley Meetup - Karaoke!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Weekly Berkeley Meetup - Karaoke!", "anchor": "Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup___Karaoke_", "level": 1}, {"title": "Discussion article for the meetup : Weekly Berkeley Meetup - Karaoke!", "anchor": "Discussion_article_for_the_meetup___Weekly_Berkeley_Meetup___Karaoke_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T00:53:30.278Z", "modifiedAt": null, "url": null, "title": "Relink: Why and how to debate charitably", "slug": "relink-why-and-how-to-debate-charitably", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.776Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Will_Newsome", "createdAt": "2010-02-25T03:52:25.697Z", "isAdmin": false, "displayName": "Will_Newsome"}, "userId": "CxM9n2EDSn4AYgLdi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rk4GP77uRBCZrgimA/relink-why-and-how-to-debate-charitably", "pageUrlRelative": "/posts/rk4GP77uRBCZrgimA/relink-why-and-how-to-debate-charitably", "linkUrl": "https://www.lesswrong.com/posts/rk4GP77uRBCZrgimA/relink-why-and-how-to-debate-charitably", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Relink%3A%20Why%20and%20how%20to%20debate%20charitably&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARelink%3A%20Why%20and%20how%20to%20debate%20charitably%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frk4GP77uRBCZrgimA%2Frelink-why-and-how-to-debate-charitably%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Relink%3A%20Why%20and%20how%20to%20debate%20charitably%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frk4GP77uRBCZrgimA%2Frelink-why-and-how-to-debate-charitably", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Frk4GP77uRBCZrgimA%2Frelink-why-and-how-to-debate-charitably", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>This was already linked to in a <a href=\"/lw/58x/link_why_and_how_to_debate_charitably/\">previous post</a>, but the site pdf23ds.net is no longer up for reasons that can be discovered via search engine. However one can peruse the old blog using the WayBackMachine. <a href=\"http://web.archive.org/web/20080705130640/http://pdf23ds.net/implications-and-debate/\">Here is a working link.</a>&nbsp;Title is an apt description and it's a pithy read.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rk4GP77uRBCZrgimA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 6, "extendedScore": null, "score": 7.419594222262641e-07, "legacy": true, "legacyId": "8685", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eBR5aeDwDHfiqE96e"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T02:18:50.042Z", "modifiedAt": null, "url": null, "title": "Robopocalypse author cites Yudkowsky's paperclip scenario", "slug": "robopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nsc6C6QwLQFgEip53/robopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "pageUrlRelative": "/posts/Nsc6C6QwLQFgEip53/robopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "linkUrl": "https://www.lesswrong.com/posts/Nsc6C6QwLQFgEip53/robopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Robopocalypse%20author%20cites%20Yudkowsky's%20paperclip%20scenario&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARobopocalypse%20author%20cites%20Yudkowsky's%20paperclip%20scenario%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNsc6C6QwLQFgEip53%2Frobopocalypse-author-cites-yudkowsky-s-paperclip-scenario%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Robopocalypse%20author%20cites%20Yudkowsky's%20paperclip%20scenario%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNsc6C6QwLQFgEip53%2Frobopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNsc6C6QwLQFgEip53%2Frobopocalypse-author-cites-yudkowsky-s-paperclip-scenario", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>In this Bloggingheads <a href=\"http://bloggingheads.tv/diavlogs/37460?in=38:35&amp;out=38:51\">clip</a>. Apparently the book is going to be made into a big <a href=\"http://www.imdb.com/title/tt1541155/\">movie</a> by Steven Spielburg.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QH4LhvnyR4QkW9MG8": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nsc6C6QwLQFgEip53", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 7.419858580153129e-07, "legacy": true, "legacyId": "8686", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T03:56:54.984Z", "modifiedAt": null, "url": null, "title": "Meta: How do I navigate to see my oldest comments?", "slug": "meta-how-do-i-navigate-to-see-my-oldest-comments", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Will_Newsome", "createdAt": "2010-02-25T03:52:25.697Z", "isAdmin": false, "displayName": "Will_Newsome"}, "userId": "CxM9n2EDSn4AYgLdi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DxwvZes56iTe6BFHy/meta-how-do-i-navigate-to-see-my-oldest-comments", "pageUrlRelative": "/posts/DxwvZes56iTe6BFHy/meta-how-do-i-navigate-to-see-my-oldest-comments", "linkUrl": "https://www.lesswrong.com/posts/DxwvZes56iTe6BFHy/meta-how-do-i-navigate-to-see-my-oldest-comments", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20How%20do%20I%20navigate%20to%20see%20my%20oldest%20comments%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20How%20do%20I%20navigate%20to%20see%20my%20oldest%20comments%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxwvZes56iTe6BFHy%2Fmeta-how-do-i-navigate-to-see-my-oldest-comments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20How%20do%20I%20navigate%20to%20see%20my%20oldest%20comments%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxwvZes56iTe6BFHy%2Fmeta-how-do-i-navigate-to-see-my-oldest-comments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxwvZes56iTe6BFHy%2Fmeta-how-do-i-navigate-to-see-my-oldest-comments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 141, "htmlBody": "<p>Title says it all, really. I was thinking about writing a post encouraging looking back on ones LW comments over the past year or so to see how much ones views have changed, how much more or less they've changed than expected, what weaknesses have been patched, what themes have become prominent, what values have changed, et cetera. Ideally there'd be a structured and optimally informative way of doing so. I plan on looking at the social psychology literature to see what they recommend, if anything. Anyway, yeah, it'd be cool if I had a way of instantly navigating to my least recent comment, 'cuz using Google search and all probably works but it's not something I want to recommend to others in a post. Also, any comments or critiques on the idea of such a post are welcome. Thanks yo!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DxwvZes56iTe6BFHy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 7, "extendedScore": null, "score": 7.420162468444167e-07, "legacy": true, "legacyId": "8688", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T04:08:57.917Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Absence of Evidence Is Evidence of Absence", "slug": "seq-rerun-absence-of-evidence-is-evidence-of-absence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:34.299Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sgCyWF7mxYoyNCJnq/seq-rerun-absence-of-evidence-is-evidence-of-absence", "pageUrlRelative": "/posts/sgCyWF7mxYoyNCJnq/seq-rerun-absence-of-evidence-is-evidence-of-absence", "linkUrl": "https://www.lesswrong.com/posts/sgCyWF7mxYoyNCJnq/seq-rerun-absence-of-evidence-is-evidence-of-absence", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Absence%20of%20Evidence%20Is%20Evidence%20of%20Absence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Absence%20of%20Evidence%20Is%20Evidence%20of%20Absence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgCyWF7mxYoyNCJnq%2Fseq-rerun-absence-of-evidence-is-evidence-of-absence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Absence%20of%20Evidence%20Is%20Evidence%20of%20Absence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgCyWF7mxYoyNCJnq%2Fseq-rerun-absence-of-evidence-is-evidence-of-absence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgCyWF7mxYoyNCJnq%2Fseq-rerun-absence-of-evidence-is-evidence-of-absence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 224, "htmlBody": "<p>Title: [SEQ RERUN] Absence of Evidence Is Evidence of Absence Tags: sequence_reruns Today's post, <a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence Is Evidence of Absence</a> was originally published on 12 August 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Absence of <em>proof </em>is not <em>proof </em>of absence. But absence of <em>evidence </em>is always <em>evidence </em>of absence. According to the probability calculus, if P(H|E) &gt; P(H) (observing E would be evidence for hypothesis H), then P(H|~E) &lt; P(H) (absence of E is evidence against H). The absence of an observation may be strong evidence or very weak evidence of absence, but it is always evidence.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/ig/i_defy_the_data/\">I Defy the Data!</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sgCyWF7mxYoyNCJnq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.42019980078665e-07, "legacy": true, "legacyId": "8689", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mnS2WYLCGJP2kQkRn", "vrHRcEDMjZcx5Yfru", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T07:54:10.162Z", "modifiedAt": null, "url": null, "title": "Experiment: Psychoanalyze Me", "slug": "experiment-psychoanalyze-me", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.864Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JrRDfoNffW6QqFnac/experiment-psychoanalyze-me", "pageUrlRelative": "/posts/JrRDfoNffW6QqFnac/experiment-psychoanalyze-me", "linkUrl": "https://www.lesswrong.com/posts/JrRDfoNffW6QqFnac/experiment-psychoanalyze-me", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experiment%3A%20Psychoanalyze%20Me&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperiment%3A%20Psychoanalyze%20Me%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrRDfoNffW6QqFnac%2Fexperiment-psychoanalyze-me%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experiment%3A%20Psychoanalyze%20Me%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrRDfoNffW6QqFnac%2Fexperiment-psychoanalyze-me", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrRDfoNffW6QqFnac%2Fexperiment-psychoanalyze-me", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 261, "htmlBody": "<p>From Yvain's <a href=\"/lw/6p6/the_limits_of_introspection/\">latest post</a>:</p>\n<blockquote>\n<p>These studies suggest that people do not have introspective awareness to  the processes that generate their behavior. They guess their  preferences, justifications, and beliefs by inferring the most plausible  rationale for their observed behavior, but are unable to make these  guesses qualitatively better than outside observers.</p>\n</blockquote>\n<p>I guess this probably applies to beliefs as well as behavior. That is, the reasons people give for their beliefs are probably not based on real introspection either, which would explain why it's often so hard to find one's <a href=\"/lw/wj/is_that_your_true_rejection/\">true rejection</a>.</p>\n<p>If I do not have highly privileged access to my own reasoning and decision making processes, it stands to reason that other people should sometimes be able to tell me things about my goals or beliefs that I myself have missed. But apparently it's not that simple. In the True Rejection post, Eliezer wrote</p>\n<blockquote>\n<p>However, attempts to directly, publicly psychoanalyze the Other may cause the conversation to degenerate <em>very</em> fast, in my observation.</p>\n</blockquote>\n<p>This seems important enough to gather more data on. How and why do such conversations degenerate? Can we do something to prevent degeneration while still providing useful psychological insights to each other? So, as a first step, I hereby extend an open invitation to LW: tell me, whenever my stated goals and/or reasons do not seem to match up with my actual goals/reasons, what you think they really are.</p>\n<p>(Presumably, the degeneration has to do with <a href=\"/lw/13s/the_nature_of_offense/\">status and offense</a>. But perhaps in our community, one can gain status by conspicuously <em>not</em> taking offense to such analyses, and instead taking them <a href=\"/lw/2l6/taking_ideas_seriously/\">seriously</a>?)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JrRDfoNffW6QqFnac", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 2.9e-05, "legacy": true, "legacyId": "8692", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K2JBqDeETX2yEgyyZ", "TGux5Fhcd7GmTfNGC", "QPqm5aj2meRmE7kR8", "Q8jyAdRYbieK8PtfT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T09:34:15.104Z", "modifiedAt": null, "url": null, "title": "The importance of Not Getting the Joke", "slug": "the-importance-of-not-getting-the-joke", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:57.390Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CharlieSheen", "createdAt": "2011-04-18T23:50:24.547Z", "isAdmin": false, "displayName": "CharlieSheen"}, "userId": "REGTxvxp4tT5RMMir", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SmjNvHt2Pxu4wkKsN/the-importance-of-not-getting-the-joke", "pageUrlRelative": "/posts/SmjNvHt2Pxu4wkKsN/the-importance-of-not-getting-the-joke", "linkUrl": "https://www.lesswrong.com/posts/SmjNvHt2Pxu4wkKsN/the-importance-of-not-getting-the-joke", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20importance%20of%20Not%20Getting%20the%20Joke&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20importance%20of%20Not%20Getting%20the%20Joke%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSmjNvHt2Pxu4wkKsN%2Fthe-importance-of-not-getting-the-joke%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20importance%20of%20Not%20Getting%20the%20Joke%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSmjNvHt2Pxu4wkKsN%2Fthe-importance-of-not-getting-the-joke", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSmjNvHt2Pxu4wkKsN%2Fthe-importance-of-not-getting-the-joke", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 437, "htmlBody": "<blockquote>\n<div style=\"text-align: left;\">One of my favorite genres in the prestige press is the <em>Self-Refuting Article</em>. These are articles that contain all the facts necessary to undermine the premise of the piece, but reporters, editors, and readers all conspire together in an act of collective stupidity<em> </em>to<em> Not Get the Joke</em>.</div>\n</blockquote>\n<p style=\"text-align: left;\"><em>-Steve Sailer, </em><em><a href=\"http://isteve.blogspot.com/2011/07/nyt-uncovers-worlds-least-pressing.html\">here</a></em></p>\n<p>But why do people conspire in an act of collective stupidity to&nbsp; <em>Not Get The Joke</em>?&nbsp; Before I proceed let me first admit that it is indeed hard to identify such situations with any reasonable level of certainty, its seems difficult to do, when \"Not Getting the Joke\" is good for our side its subjectively harder to spot (see&nbsp; <a href=\"http://wiki.lesswrong.com/wiki/Politics_is_the_Mind-Killer\">mind killer</a>). I'm not quite sure what to make of this, but it seems to me that three obvious things are going on here:</p>\n<ol>\n<li>The author and the audience share many of the same biases. Maybe they really don't get the joke&nbsp; </li>\n<li><a href=\"http://en.wikipedia.org/wiki/Bandwagon_effect\">bandwagon effect</a>, even if the overlap in biases isn't that great people are lazy thinkers and prefer a given answer.</li>\n<li>The right answer happens to be&nbsp; <a href=\"/lw/i7/belief_as_attire/\">enemy attire</a>&nbsp; and might provoke accusations or suspicion from others in the in group.</li>\n</ol>\n<p>Now, perhaps not so obviously, could it be people have some incentives to say and even believe or at least try to believe things that are obviously wrong even to people of their tribe (political/religious/ect. affilation)? Why would something like this arise? My mind at this point wandered to&nbsp; <a href=\"http://en.wikipedia.org/wiki/Conspicuous_consumption\">conspicuous consumption</a>.</p>\n<blockquote>\n<p><em><strong>Conspicuous consumption&nbsp;</strong></em> is lavish spending on goods and services acquired mainly for the purpose of displaying income or wealth.</p>\n</blockquote>\n<p>Could there be such a thing as&nbsp; <em><strong>conspicuous wrongness</strong></em>?</p>\n<blockquote>\n<p>\"Look how much I identify with our group, I'm even willing to buy even if it dosen't do us much good. If I wasn't so virtuous I could never believe something this silly.\"</p>\n</blockquote>\n<p>But why would sticking to the script when its blatantly false to others in the tribe boost your status and self-esteem? Well, sticking to it when its blatantly obvious to most people dosen't <em>cost</em> you anything now does it? Sticking to it when its merely uncertain only costs you the esteem of the out group (worthless in most cases)?</p>\n<p>&nbsp;</p>\n<p><strong>4.</strong></p>\n<p>Sticking to the script, when everyone knows the script is false, is a sign of either cleverness or innocence, and more than that it is a sign that that cleverness or innocence is perfectly aligned to the interests of the tribe.</p>\n<p><strong> </strong></p>\n<p>&nbsp;</p>\n<p><strong>So my question is, if there is anything in the sequences that already covers this or was my speculation faulty?*</strong></p>\n<p>&nbsp;</p>\n<div style=\"text-align: left;\">\n<hr />\n</div>\n<p>*(only just started reading the sequences)</p>\n<div style=\"text-align: left;\"><strong>1st Edit: </strong>Less goofy presentation.</div>\n<div style=\"text-align: left;\"><strong>2nd Edit:</strong> Spacing problem resolved. <br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SmjNvHt2Pxu4wkKsN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 3, "extendedScore": null, "score": 8e-06, "legacy": true, "legacyId": "8693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<div style=\"text-align: left;\">One of my favorite genres in the prestige press is the <em>Self-Refuting Article</em>. These are articles that contain all the facts necessary to undermine the premise of the piece, but reporters, editors, and readers all conspire together in an act of collective stupidity<em> </em>to<em> Not Get the Joke</em>.</div>\n</blockquote>\n<p style=\"text-align: left;\"><em>-Steve Sailer, </em><em><a href=\"http://isteve.blogspot.com/2011/07/nyt-uncovers-worlds-least-pressing.html\">here</a></em></p>\n<p>But why do people conspire in an act of collective stupidity to&nbsp; <em>Not Get The Joke</em>?&nbsp; Before I proceed let me first admit that it is indeed hard to identify such situations with any reasonable level of certainty, its seems difficult to do, when \"Not Getting the Joke\" is good for our side its subjectively harder to spot (see&nbsp; <a href=\"http://wiki.lesswrong.com/wiki/Politics_is_the_Mind-Killer\">mind killer</a>). I'm not quite sure what to make of this, but it seems to me that three obvious things are going on here:</p>\n<ol>\n<li>The author and the audience share many of the same biases. Maybe they really don't get the joke&nbsp; </li>\n<li><a href=\"http://en.wikipedia.org/wiki/Bandwagon_effect\">bandwagon effect</a>, even if the overlap in biases isn't that great people are lazy thinkers and prefer a given answer.</li>\n<li>The right answer happens to be&nbsp; <a href=\"/lw/i7/belief_as_attire/\">enemy attire</a>&nbsp; and might provoke accusations or suspicion from others in the in group.</li>\n</ol>\n<p>Now, perhaps not so obviously, could it be people have some incentives to say and even believe or at least try to believe things that are obviously wrong even to people of their tribe (political/religious/ect. affilation)? Why would something like this arise? My mind at this point wandered to&nbsp; <a href=\"http://en.wikipedia.org/wiki/Conspicuous_consumption\">conspicuous consumption</a>.</p>\n<blockquote>\n<p><em><strong>Conspicuous consumption&nbsp;</strong></em> is lavish spending on goods and services acquired mainly for the purpose of displaying income or wealth.</p>\n</blockquote>\n<p>Could there be such a thing as&nbsp; <em><strong>conspicuous wrongness</strong></em>?</p>\n<blockquote>\n<p>\"Look how much I identify with our group, I'm even willing to buy even if it dosen't do us much good. If I wasn't so virtuous I could never believe something this silly.\"</p>\n</blockquote>\n<p>But why would sticking to the script when its blatantly false to others in the tribe boost your status and self-esteem? Well, sticking to it when its blatantly obvious to most people dosen't <em>cost</em> you anything now does it? Sticking to it when its merely uncertain only costs you the esteem of the out group (worthless in most cases)?</p>\n<p>&nbsp;</p>\n<p><strong id=\"4_\">4.</strong></p>\n<p>Sticking to the script, when everyone knows the script is false, is a sign of either cleverness or innocence, and more than that it is a sign that that cleverness or innocence is perfectly aligned to the interests of the tribe.</p>\n<p><strong> </strong></p>\n<p>&nbsp;</p>\n<p><strong id=\"So_my_question_is__if_there_is_anything_in_the_sequences_that_already_covers_this_or_was_my_speculation_faulty__\">So my question is, if there is anything in the sequences that already covers this or was my speculation faulty?*</strong></p>\n<p>&nbsp;</p>\n<div style=\"text-align: left;\">\n<hr>\n</div>\n<p>*(only just started reading the sequences)</p>\n<div style=\"text-align: left;\"><strong>1st Edit: </strong>Less goofy presentation.</div>\n<div style=\"text-align: left;\"><strong>2nd Edit:</strong> Spacing problem resolved. <br></div>", "sections": [{"title": "4.", "anchor": "4_", "level": 1}, {"title": "So my question is, if there is anything in the sequences that already covers this or was my speculation faulty?*", "anchor": "So_my_question_is__if_there_is_anything_in_the_sequences_that_already_covers_this_or_was_my_speculation_faulty__", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["nYkMLFpx77Rz3uo9c"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T10:51:16.778Z", "modifiedAt": null, "url": null, "title": "Well, that does it, I suppose", "slug": "well-that-does-it-i-suppose", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:22.062Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lucidfox", "createdAt": "2010-11-22T06:58:06.993Z", "isAdmin": false, "displayName": "lucidfox"}, "userId": "hNnKSqvajCMRj9eKK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SG74rawPj2xFZFL8e/well-that-does-it-i-suppose", "pageUrlRelative": "/posts/SG74rawPj2xFZFL8e/well-that-does-it-i-suppose", "linkUrl": "https://www.lesswrong.com/posts/SG74rawPj2xFZFL8e/well-that-does-it-i-suppose", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Well%2C%20that%20does%20it%2C%20I%20suppose&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWell%2C%20that%20does%20it%2C%20I%20suppose%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSG74rawPj2xFZFL8e%2Fwell-that-does-it-i-suppose%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Well%2C%20that%20does%20it%2C%20I%20suppose%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSG74rawPj2xFZFL8e%2Fwell-that-does-it-i-suppose", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSG74rawPj2xFZFL8e%2Fwell-that-does-it-i-suppose", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<p>My <a href=\"/lw/374/gender_identity_and_rationality/\">first post</a>&nbsp;here on LW related to gender identity, based on my own introspection, generated some interesting discussion that I enjoyed reading and commenting on. While there were disagreements on the origin of transsexuality, there was an agreement that it was a condition genuinely in need of treatment.</p>\n<p>Fast forward to now, and <a href=\"/r/discussion/lw/6oc/transsexuals_and_otherkin/\">what do we have</a>? People throwing accusations all over the place, calling transsexuality a \"delusion\", comparing it with religious belief, or referring to the discredited autogynephilia (sexual fetish) theory.</p>\n<p>How could this have happened? Either:</p>\n<p>1) the audience of LW changed significantly in the half-year interim;</p>\n<p>or 2) the lack of personal input in the second post caused people to more freely voice their true opinions, rather than those they suspected I would take offense at.</p>\n<p>I don't know which possibility to lean towards, but if previously I only suspected LW was the wrong community for me (what with the singularity-worship that I don't share), now I'm almost convinced in this.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SG74rawPj2xFZFL8e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": -2, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "8694", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["axgfcSEQwaaAn4d3Z", "qByTewnDhgnF3wTem"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T16:42:38.488Z", "modifiedAt": null, "url": null, "title": "How to solve the national debt deadlock", "slug": "how-to-solve-the-national-debt-deadlock", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:39.027Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RfGZyjXdykjWvHs68/how-to-solve-the-national-debt-deadlock", "pageUrlRelative": "/posts/RfGZyjXdykjWvHs68/how-to-solve-the-national-debt-deadlock", "linkUrl": "https://www.lesswrong.com/posts/RfGZyjXdykjWvHs68/how-to-solve-the-national-debt-deadlock", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20solve%20the%20national%20debt%20deadlock&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20solve%20the%20national%20debt%20deadlock%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRfGZyjXdykjWvHs68%2Fhow-to-solve-the-national-debt-deadlock%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20solve%20the%20national%20debt%20deadlock%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRfGZyjXdykjWvHs68%2Fhow-to-solve-the-national-debt-deadlock", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRfGZyjXdykjWvHs68%2Fhow-to-solve-the-national-debt-deadlock", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 422, "htmlBody": "<p>The US Congress is trying to resolve the national debt by getting hundreds of people to agree on a solution.&nbsp; This is silly.&nbsp; They should agree on the rules of a game to play that will result in a solution, and then play the game.</p>\n<p>Here is an example game.&nbsp; Suppose there are N representatives, all with an equal vote.&nbsp; They need to reduce the budget by $D.</p>\n<ol>\n<li>Order the representatives numerically, in some manner that interleaves Republicans and Democrats.</li>\n<li>\"1 full turn\" will mean that representatives make one move in order 1..N, and then one move in order N..1.</li>\n<li>Take at least two full turns to make a list of budget choices.&nbsp; On each move, a representative will write down one budget item - an expense that may be cut, or something that may become a revenue source.&nbsp; They may write down something that is a subset or superset of an existing item - for instance, one person might write, \"Air Force budget\", and another might write, \"Reduce maintenance inspections of hanger J11 at Wright air force base from weekly to monthly\".&nbsp; They can get as specific as they want to.</li>\n<li>If there are not $2D of options on the table, repeat.</li>\n<li>Each representative is given 10 \"cut\" votes, worth D/(5N) each; and 5 \"defend\" votes, also worth D/(5N) each.&nbsp; A \"defend\" vote cancels out a \"cut\" vote.</li>\n<li>Each representative secretly assigns their \"cut\" and \"defend\" votes to the choices on the table.</li>\n<li>Results are revealed and tallied up, and a budget will be drawn up accordingly.</li>\n</ol>\n<p>What game-theoretic problems does this game have?&nbsp; Can you think of a better game?&nbsp; Is it politically better to call it a \"decision process\" than a game?</p>\n<p>The main trouble area, to my mind, is order of play.&nbsp; First I said that budget items would be listed by taking turns.&nbsp; The 1..N, N..1 order is supposed to make neither first nor last position preferable.&nbsp; But taking turns introduces complications, of not wanting to reveal your intentions early.</p>\n<p>Then I said votes are placed secretly and revealed all at once.&nbsp; This solves problems about game-theoretically trying to conceal information or bluff your opponent.&nbsp; It introduces other problems, such as tragedy-of-the-commons scenarios, where every Republican spends their \"defend\" votes on some pork in their state instead of on preventing tax cuts, because they assume some other Republican will do that.</p>\n<p>Is it better to play \"cut\" votes first, reveal them, and then play \"defend\" votes?</p>\n<p>Is there a meta-game to use to build such games?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RfGZyjXdykjWvHs68", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 13, "extendedScore": null, "score": 7.422535669677904e-07, "legacy": true, "legacyId": "8695", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T20:18:55.927Z", "modifiedAt": null, "url": null, "title": "How to get useful work out of theologians [LINK]", "slug": "how-to-get-useful-work-out-of-theologians-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.255Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QNXxSEc29BucZEGdL/how-to-get-useful-work-out-of-theologians-link", "pageUrlRelative": "/posts/QNXxSEc29BucZEGdL/how-to-get-useful-work-out-of-theologians-link", "linkUrl": "https://www.lesswrong.com/posts/QNXxSEc29BucZEGdL/how-to-get-useful-work-out-of-theologians-link", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20get%20useful%20work%20out%20of%20theologians%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20get%20useful%20work%20out%20of%20theologians%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQNXxSEc29BucZEGdL%2Fhow-to-get-useful-work-out-of-theologians-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20get%20useful%20work%20out%20of%20theologians%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQNXxSEc29BucZEGdL%2Fhow-to-get-useful-work-out-of-theologians-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQNXxSEc29BucZEGdL%2Fhow-to-get-useful-work-out-of-theologians-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p>I've offered theologians a new argument they can develop against physicalism. Should they pursue it, we may actually get some useful work out of them. See <a href=\"http://commonsenseatheism.com/?p=15698\">here</a>.</p>\n<p>(The intelligence explosion animation was constructed from Anna Salamon's slides for her <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">Minicamp</a> x-risk presentation.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QNXxSEc29BucZEGdL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 7, "extendedScore": null, "score": 7.423206259525071e-07, "legacy": true, "legacyId": "8696", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T20:43:00.558Z", "modifiedAt": null, "url": null, "title": "Ego syntonic thoughts and values", "slug": "ego-syntonic-thoughts-and-values", "viewCount": null, "lastCommentedAt": "2021-02-06T15:47:53.646Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ibk7q8msSYxZXmfCf/ego-syntonic-thoughts-and-values", "pageUrlRelative": "/posts/ibk7q8msSYxZXmfCf/ego-syntonic-thoughts-and-values", "linkUrl": "https://www.lesswrong.com/posts/ibk7q8msSYxZXmfCf/ego-syntonic-thoughts-and-values", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ego%20syntonic%20thoughts%20and%20values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEgo%20syntonic%20thoughts%20and%20values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fibk7q8msSYxZXmfCf%2Fego-syntonic-thoughts-and-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ego%20syntonic%20thoughts%20and%20values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fibk7q8msSYxZXmfCf%2Fego-syntonic-thoughts-and-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fibk7q8msSYxZXmfCf%2Fego-syntonic-thoughts-and-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1139, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/15c/would_your_real_preferences_please_stand_up\">Will your real preferences please stand up?</a></p>\n<p>Last week I read a book in which two friends - let's call them John and Lisa so I don't spoil the book for anyone who wanders into it - got poisoned. They only had enough antidote for one person and had to decide who lived and who died. John, who was much larger than Lisa, decided to hold Lisa down and force the antidote down her throat. Lisa just smirked; she'd replaced the antidote with a lookalike after slipping the real thing into John's drink earlier in the day.<br /><br />These are <em>good</em> friends. Not only was each willing to give the antidote to the other, but each realized it would be unfair to make the other live with the crippling guilt of having chosen to survive at the expense of a friend's life, and so decided to force the antidote on the other unwillingly to prevent any guilt over the fateful decision. Whatever you think of the ethics of their decision, you can't help admire the thought processes.<br /><br />Your brain might be this kind of a friend.<br /><br />In <a href=\"/lw/6mj/trivers_on_selfdeception/\">Trivers' hypothesis of self-deception</a>, one of the most important functions of the conscious mind is effective signaling. Since people have the potential to be excellent lie-detectors, the conscious mind isn't given full access to information so that it can lend the ring of truth to useful falsehoods.<br /><br />But this doesn't always work. If you're addicted to heroin, at some point you're going to notice. And telling your friends \"No, I'm not addicted, it's just a coincidence that I take heroin every day,\" isn't going to cut it. But there's another way in which the brain can sequester information to promote effective signaling.<br /><br />Wikipedia defines the term \"ego syntonic\" as \"referring to behaviors, values, feelings that are in harmony with or acceptable to the needs and goals of the ego, or consistent with one's ideal self-image\", and \"ego dystonic\" as the opposite of that. A heroin addict might say \"I hate heroin, but somehow I just feel compelled to keep taking it.\" But an astronaut will say \"I love being an astronaut and I worked hard to get into this career.\"<br /><br />Both the addict and the astronaut have desires: the addict wants to take heroin, the astronaut wants to fly in space. But the addict's desires manifest as an unpleasant compulsion from outside, and the astronaut's manifest as a genuine and heartfelt love.<br /><br />Suppose that in the original example, John predicted that Lisa would ask for the antidote, but later feel guilty about it and believe she was a bad person. By presenting the antidote to Lisa in the form of an external compulsion, he allows Lisa to do what she wanted anyway and avoid the associated guilt.</p>\n<p>Under Trivers' hypothesis, the compulsion for heroin works the same way. The heroin addict's definitely going to get that heroin, but by presenting the desire in the form of an external compulsion, the unconscious saves the heroin addict from the social stigma of \"choosing\" heroin. This allows the addict to create a much more sympathetic narrative than the alternative: \"I want to support my family and keep clean, but for some reason these compulsions keep attacking me,\" instead of \"Yeah, I like heroin more than I like supporting my family. Deal with it.\"<br /><br /><strong>EGO SYNTONIA, DYSTONIA, AND WILLPOWER</strong><br /><br />Willpower cashes out as the action of ego syntonic thoughts and desires against ego dystonic thoughts and desires.<br /><br />The aforementioned heroin addict may have several reinforcers both promoting and discouraging heroin use. On the plus side, heroin itself is very strongly rewarding. On the minus, it can lead to both predicted and experienced poverty, loss of friendships, loss of health, and death.<br /><br />Worrying about the latter factors determining heroin use - the factors that make heroin a bad idea - is socially encouraged and good signaling material. A person wanting to put their best face forward should believe themselves to be the sort of person who cares about these things. These desires will be ego syntonic. Wanting to take heroin, on the other hand, is a socially unacceptable desire, so it presents as dystonic.<br /><br />If the latter syntonic factors win out over the dystonic factors, this feels from the inside like \"I exerted willpower and managed to overcome my heroin addiction.\" If the dystonic factors win out over the syntonic factors, this feels from the inside like \"I didn't have enough willpower to overcome my heroin addiction.\"<br /><br /><strong>DYSTONIC DESIRES IN ABNORMAL PSYCHOLOGY</strong><br /><br />There is some speculation that the brain has one last trick up its sleeve to deal with desires that are so unpleasant and unacceptable that even manifesting them as external compulsions isn't good enough: it splits them off into weird alternate personalities.<br /><br />One of the classic stereotypes of the insane is that they hear voices telling them to kill people. During my short time working at a psychiatric hospital, I was surprised by how spot-on this stereotype was: meeting someone who heard voices telling him to kill people was an almost daily occurrence. Other voices would have other messages: maybe that the patient was a horrible person who deserved to die, or that the patient must complete some bizarre ritual or else doom everybody. There were relatively fewer voices saying \"Hey, let's go fishing!\"<br /><br />One theory explaining these voices is that they are an extreme reaction to highly ego dystonic thoughts. Some aspect of the patients' mental disease gives them obsessive thoughts about (though rarely a desire for) killing people. Genuinely wanting to kill people would make you a bad person, but even saying \"I feel a strong compulsion to kill people\" is pretty bad too. The best the brain can do with this desire is pitch it as a completely different person by presenting it as an outside voice speaking to the patient.<br /><br />Although everything about dissociative identity disorder (aka multiple personality disorder) is controversial including its very existence, perhaps one could sketch a similar theory explaining that condition in the same framework of separating out dystonic thoughts.<br /><br /><strong>SUMMARY</strong><br /><br />A conscious/unconscious divide helps signaling by allowing the conscious mind to hold only socially acceptable beliefs, which it can broadcast without detectable falsehood. Socially acceptable ideas present as the conscious mind's own beliefs and desires; unacceptable ones present as compulsions from afar. The balance of ego syntonic and dystonic desires presents as willpower. In extreme cases, some desires may be so ego dystonic that they present as external voices.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"iP2X4jQNHMWHRNPne": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ibk7q8msSYxZXmfCf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 63, "baseScore": 84, "extendedScore": null, "score": 0.000174, "legacy": true, "legacyId": "8615", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 84, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["z3cTkXbA7jgwGWPcv", "DSnamjnW7Ad8vEEKd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T20:43:03.221Z", "modifiedAt": null, "url": null, "title": "Approving reinforces low-effort behaviors", "slug": "approving-reinforces-low-effort-behaviors", "viewCount": null, "lastCommentedAt": "2018-01-22T21:46:37.735Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yDRX2fdkm3HqfTpav/approving-reinforces-low-effort-behaviors", "pageUrlRelative": "/posts/yDRX2fdkm3HqfTpav/approving-reinforces-low-effort-behaviors", "linkUrl": "https://www.lesswrong.com/posts/yDRX2fdkm3HqfTpav/approving-reinforces-low-effort-behaviors", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Approving%20reinforces%20low-effort%20behaviors&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApproving%20reinforces%20low-effort%20behaviors%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyDRX2fdkm3HqfTpav%2Fapproving-reinforces-low-effort-behaviors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Approving%20reinforces%20low-effort%20behaviors%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyDRX2fdkm3HqfTpav%2Fapproving-reinforces-low-effort-behaviors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyDRX2fdkm3HqfTpav%2Fapproving-reinforces-low-effort-behaviors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1087, "htmlBody": "<p>In addition to \"liking\" to describe pleasure and \"wanting\" to describe motivation, we add \"approving\" to describe thoughts that are ego syntonic.<br /><br />A heroin addict likes heroin. He certainly wants more heroin. But he may not approve of taking heroin. In fact, there are enough different cases to fill in all eight boxes of the implied 2x2x2 grid (your mileage may vary):<br /><br /><strong>+wanting/+liking/+approving:</strong> Romantic love. If you're doing it right, you enjoy being with your partner, you're motivated to spend time with your partner, and you think love is a wonderful (maybe even many-splendored) thing.<br /><br /><strong>+wanting/+liking/-approving:</strong> The aforementioned heroin addict feels good when taking heroin, is motivated to get more, but wishes he wasn't addicted.<br /><br /><strong>+wanting/-liking/+approving:</strong> I have taken up disc golf. I play it every day, and when events conspire to prevent me from playing it, I seethe. I approve of this pastime: I need to take up more sports, and it helps me spend time with my family. But when I am playing, all I feel is stressed and angry that I was <em>literally *that</em><em>* close how could I miss that shot aaaaarggghh</em>.<br /><br /><strong>+wanting/-liking/-approving:</strong> The jaded addict. I have a friend who says she no longer even enjoys coffee or gets any boost from it, she just feels like she has to have it when she gets up.<br /><br /><strong>-wanting/+liking/+approving:</strong> Reading non-fiction. I enjoy it when I'm doing it, I think it's great because it makes me more educated, but I can rarely bring myself to do it.<br /><strong><br />-wanting/-liking/+approving:</strong> Working in a soup kitchen. Unless you're the type for whom helping others is literally its own reward it's not the most fun thing in the world, nor is it the most attractive, but it makes you a Good Person and so you should do it.<br /><strong><br />-wanting/+liking/-approving:</strong> The non-addict. I don't want heroin right now. I think heroin use is repugnant. But if I took some, I sure bet I'd like it.<br /><strong><br />-wanting/-liking/-approving:</strong> Torture. I don't want to be tortured, I wouldn't like it if I were, and I will go on record declaring myself to be against it.<br /><br /><br />Discussion of goals is mostly about approving; a goal is an ego-syntonic thought. When we speak of goals that are hard to achieve, we're usually talking about +approving/-wanting. The previous discussion of learning Swahili is one example; more noble causes like Working To Help The Less Fortunate can be others.</p>\n<p>Ego syntonicity itself is mildly reinforcing by promoting positive self-image. Most people interested in philosophy have at least once sat down and moved their arm from side to side, just to note that their mind really does control their body; the mental processes that produced curiosity about philosophy were sufficiently powerful to produce that behavior as well. Some processes, like moving one's arm, or speaking aloud, or engaging in verbal thought, are so effortless, and so empty of other reinforcement either way, that we usually expect them to be completely under the control of the mild reinforcement provided by approving of those behaviors.</p>\n<p>Other behaviors take more effort, and are subject not only to discounting but to many other forms of reinforcement. Unlike the first class of behaviors, we expect to experience akrasia when dealing with this latter sort. This offers another approach to willpower: taking low-effort approving-influenced actions that affect the harder road ahead.<br /><br />Consider the action of making a goal. I go to all my friends and say \"Today I shall begin learning Swahili.\" This is easy to do. There is no chance of me intending to do so and failing; my speech is output by the same processes as my intentions, so I can \"trust\" it. But this is not just an output of my mental processes, but an input. One of the processes potentially reinforcing my behavior of learning Swahili is \"If I don't do this, I'll look stupid in front of my friends.\"<br /><br />Will it be enough? Maybe not. But this is still an impressive process: my mind has deliberately tweaked its own inputs to change the output of its own algorithm. It's not even pretending to be working off of fixed preferences anymore, it's assuming that one sort of action (speaking) will work differently from another action (studying), because the first can be executed solely through the power of ego syntonicity, and the second may require stronger forms of reinforcement. It gets even weirder when goals are entirely mental: held under threat not of social disapproval, but of feeling bad because you're not as effective as you thought. The mind is using mind's opinion of the mind to blackmail the mind.<br /><br />But we do this sort of thing all the time. The dieter who successfully avoids buying sweets when he's at the store because he knows he would eat them at home is changing his decisions by forcing effort discounting of any future sweet-related reward (because he'd have to go back to the store). The binge shopper who freezes her credit cards in a block of ice is using time discounting in the same way. The rationalist who sends money to <a href=\"http://www.stickk.com/\">stickk</a> is imposing a punishment with a few immediate and effortless mouse clicks. Even the poor unhappy person who tries to conquer through willpower alone is trying to set up the goal as a Big Deal so she will feel extra bad if she fails. All are using their near-complete control of effortless immediate actions to make up for their incomplete control of high-effort long-term actions.<br /><br />This process is especially important to transhumanists. In the future, we may have the ability to self-modify in complicated ways that have not built up strong patterns of reinforcement around them. For example, we may be able to program ourselves at the push of a button. Such programming would be so effortless and empty of past reinforcement that behavior involving it would be reinforced entirely by our ego-syntonic thoughts. It would supersede our current psychodynamics, in which our thoughts are only tenuously linked to our important actions and major life decisions. A Singularity in which behaviors were executed by effectively omnipotent machines that acted on our preferences - preferences which we would presumably communicate through low-effort channels like typed commands - would be an ultimate triumph for the ego-syntonic faction of the brain.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Man2iP6ftuTPze9K": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yDRX2fdkm3HqfTpav", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 112, "baseScore": 155, "extendedScore": null, "score": 0.000299, "legacy": true, "legacyId": "8639", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 155, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 15, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-17T22:26:03.668Z", "modifiedAt": null, "url": null, "title": "Seth Baum's new global catastrophic risks bibliography [LINK]", "slug": "seth-baum-s-new-global-catastrophic-risks-bibliography-link", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gb59zGqivSDSrfZKH/seth-baum-s-new-global-catastrophic-risks-bibliography-link", "pageUrlRelative": "/posts/Gb59zGqivSDSrfZKH/seth-baum-s-new-global-catastrophic-risks-bibliography-link", "linkUrl": "https://www.lesswrong.com/posts/Gb59zGqivSDSrfZKH/seth-baum-s-new-global-catastrophic-risks-bibliography-link", "postedAtFormatted": "Sunday, July 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seth%20Baum's%20new%20global%20catastrophic%20risks%20bibliography%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeth%20Baum's%20new%20global%20catastrophic%20risks%20bibliography%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGb59zGqivSDSrfZKH%2Fseth-baum-s-new-global-catastrophic-risks-bibliography-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seth%20Baum's%20new%20global%20catastrophic%20risks%20bibliography%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGb59zGqivSDSrfZKH%2Fseth-baum-s-new-global-catastrophic-risks-bibliography-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGb59zGqivSDSrfZKH%2Fseth-baum-s-new-global-catastrophic-risks-bibliography-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 18, "htmlBody": "<p>Here's the <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/07/Baum-Global-catastrophic-risks-bibliography.pdf\">PDF</a> for now; it may be turned into a web page soon.</p>\n<p>115 entries so far.</p>\n<p><a href=\"http://sethbaum.com/\">Seth Baum</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gb59zGqivSDSrfZKH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.423600461488679e-07, "legacy": true, "legacyId": "8699", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:27:13.683Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Conservation of Expected Evidence", "slug": "seq-rerun-conservation-of-expected-evidence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:55.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tmi57SF9qSRGrX3Be/seq-rerun-conservation-of-expected-evidence", "pageUrlRelative": "/posts/Tmi57SF9qSRGrX3Be/seq-rerun-conservation-of-expected-evidence", "linkUrl": "https://www.lesswrong.com/posts/Tmi57SF9qSRGrX3Be/seq-rerun-conservation-of-expected-evidence", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Conservation%20of%20Expected%20Evidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Conservation%20of%20Expected%20Evidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTmi57SF9qSRGrX3Be%2Fseq-rerun-conservation-of-expected-evidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Conservation%20of%20Expected%20Evidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTmi57SF9qSRGrX3Be%2Fseq-rerun-conservation-of-expected-evidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTmi57SF9qSRGrX3Be%2Fseq-rerun-conservation-of-expected-evidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 226, "htmlBody": "<p>Title: [SEQ RERUN] Conservation of Expected Evidence Tags: sequence_reruns Today's post, <a href=\"/lw/ii/conservation_of_expected_evidence/\">Conservation of Expected Evidence</a> was originally published on 13 August 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>If you are about to make an observation, then the expected value of your posterior probability must equal your current prior probability. On <em>average</em>, you must expect to be <em>exactly </em>as confident as when you started out. If you are a true Bayesian, you <em>cannot </em>seek evidence to confirm your theory, because you do not expect any evidence to do that. You can only seek evidence to <em>test </em>your theory.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence is Evidence of Absence</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tmi57SF9qSRGrX3Be", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.424348374662505e-07, "legacy": true, "legacyId": "8701", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jiBFC7DcCrZjGmZnJ", "mnS2WYLCGJP2kQkRn", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:35:43.168Z", "modifiedAt": null, "url": null, "title": "Anyone with the medical knowledge to evaluate an extraordinary claim?", "slug": "anyone-with-the-medical-knowledge-to-evaluate-an-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zMpo74a5gZC7Da8XN/anyone-with-the-medical-knowledge-to-evaluate-an-2", "pageUrlRelative": "/posts/zMpo74a5gZC7Da8XN/anyone-with-the-medical-knowledge-to-evaluate-an-2", "linkUrl": "https://www.lesswrong.com/posts/zMpo74a5gZC7Da8XN/anyone-with-the-medical-knowledge-to-evaluate-an-2", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzMpo74a5gZC7Da8XN%2Fanyone-with-the-medical-knowledge-to-evaluate-an-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzMpo74a5gZC7Da8XN%2Fanyone-with-the-medical-knowledge-to-evaluate-an-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzMpo74a5gZC7Da8XN%2Fanyone-with-the-medical-knowledge-to-evaluate-an-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>In a different forum I frequent ([The Ornery American](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi)), a regular member there (LetterRip) has recently been making an extraordinary claim - a new theory of medicine he has devised that relates and can contribute in the cure of several neurological-related conditions.</p>\n<p>I understand that the prior probablities for him being a crank are much much higher than him being a new Louis Pasteur. Still I was wondering if there is anyone here with sufficient medical/medicinal knowledge that they can easily determine if there's something obviously ludicrous in LetterRip's theory, or even the opposite: if indeed there's something there that makes sense and is worth investigating.</p>\n<p>Here are some of the relevant threads he began:</p>\n<p>-[where he requests contacts] (http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014966)</p>\n<p>-[where he publishes portion of his theory as a Kindle book](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014997)</p>\n<p>-[where he announces more \"breakthroughs\" and insights and offers to cure or at least alleviate simple ailments](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=015009)</p>\n<p>Once again: I understand it's highly unlikely there's anything in his theory; still, I felt a cost-benefit analysis justified my making this post here.</p>\n<p>So... anyone with enough understanding of biology/medicine to evaluate these claims of his?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zMpo74a5gZC7Da8XN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8702", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:37:02.685Z", "modifiedAt": null, "url": null, "title": "Anyone with the medical knowledge to evaluate an extraordinary claim?", "slug": "anyone-with-the-medical-knowledge-to-evaluate-an-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2C7nwSAb4HKcEZi4v/anyone-with-the-medical-knowledge-to-evaluate-an-0", "pageUrlRelative": "/posts/2C7nwSAb4HKcEZi4v/anyone-with-the-medical-knowledge-to-evaluate-an-0", "linkUrl": "https://www.lesswrong.com/posts/2C7nwSAb4HKcEZi4v/anyone-with-the-medical-knowledge-to-evaluate-an-0", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C7nwSAb4HKcEZi4v%2Fanyone-with-the-medical-knowledge-to-evaluate-an-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C7nwSAb4HKcEZi4v%2Fanyone-with-the-medical-knowledge-to-evaluate-an-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C7nwSAb4HKcEZi4v%2Fanyone-with-the-medical-knowledge-to-evaluate-an-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>In a different forum I frequent ( [The Ornery American](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi) ), a regular member there (LetterRip) has recently been making an extraordinary claim - a new theory of medicine he has devised that relates and can contribute in the cure of several neurological-related conditions.</p>\n<p>I understand that the prior probablities for him being a crank are much much higher than him being a new Louis Pasteur. Still I was wondering if there is anyone here with sufficient medical/medicinal knowledge that they can easily determine if there's something obviously ludicrous in LetterRip's theory, or even the opposite: if indeed there's something there that makes sense and is worth investigating.</p>\n<p>Here are some of the relevant threads he began:</p>\n<p>-[where he requests contacts] (http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014966)</p>\n<p>-[where he publishes portion of his theory as a Kindle book](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014997)</p>\n<p>-[where he announces more \"breakthroughs\" and insights and offers to cure or at least alleviate simple ailments](http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=015009)</p>\n<p>Once again: I understand it's highly unlikely there's anything in his theory; still, I felt a cost-benefit analysis justified my making this post here.</p>\n<p>So... anyone with enough understanding of biology/medicine to evaluate these claims of his?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2C7nwSAb4HKcEZi4v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8703", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:38:48.770Z", "modifiedAt": null, "url": null, "title": "Anyone with the medical knowledge to evaluate an extraordinary claim?", "slug": "anyone-with-the-medical-knowledge-to-evaluate-an-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NYBBxNS9fWBNfpj7q/anyone-with-the-medical-knowledge-to-evaluate-an-1", "pageUrlRelative": "/posts/NYBBxNS9fWBNfpj7q/anyone-with-the-medical-knowledge-to-evaluate-an-1", "linkUrl": "https://www.lesswrong.com/posts/NYBBxNS9fWBNfpj7q/anyone-with-the-medical-knowledge-to-evaluate-an-1", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYBBxNS9fWBNfpj7q%2Fanyone-with-the-medical-knowledge-to-evaluate-an-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYBBxNS9fWBNfpj7q%2Fanyone-with-the-medical-knowledge-to-evaluate-an-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYBBxNS9fWBNfpj7q%2Fanyone-with-the-medical-knowledge-to-evaluate-an-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 183, "htmlBody": "<p>In a different forum I frequent ( &lt;a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi\"&gt;The Ornery American&lt;/a&gt; ), a regular member there (LetterRip) has recently been making an extraordinary claim - a new theory of medicine he has devised that relates and can contribute in the cure of several neurological-related conditions.</p>\n<p>I understand that the prior probabilities for him being a crank are much much higher than him being a new Louis Pasteur. Still I was wondering if there is anyone here with sufficient medical/medicinal knowledge that they can easily determine if there's something obviously ludicrous in LetterRip's theory, or even the opposite: if indeed there's something there that makes sense and is worth investigating.</p>\n<p>Here are some of the relevant threads he began:</p>\n<p>-&lt;a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014966\"&gt;where he requests contacts&lt;/a&gt;</p>\n<p>-&lt;a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014997\"&gt;where he publishes portion of his theory as a Kindle book&lt;/a&gt;</p>\n<p>-&lt;a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=015009\"&gt;where he announces more \"breakthroughs\" and insights and offers to cure or at least alleviate simple ailments&lt;/a&gt;</p>\n<p>Once again: I understand it's highly unlikely there's anything in his theory; still, I felt a cost-benefit analysis justified my making this post here.</p>\n<p>So... anyone with enough understanding of biology/medicine to evaluate these claims of his?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NYBBxNS9fWBNfpj7q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8704", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:45:46.479Z", "modifiedAt": null, "url": null, "title": "Anyone with the medical knowledge to evaluate an extraordinary claim?", "slug": "anyone-with-the-medical-knowledge-to-evaluate-an", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:23.334Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BJKaxTBbJSS2B9Ry7/anyone-with-the-medical-knowledge-to-evaluate-an", "pageUrlRelative": "/posts/BJKaxTBbJSS2B9Ry7/anyone-with-the-medical-knowledge-to-evaluate-an", "linkUrl": "https://www.lesswrong.com/posts/BJKaxTBbJSS2B9Ry7/anyone-with-the-medical-knowledge-to-evaluate-an", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBJKaxTBbJSS2B9Ry7%2Fanyone-with-the-medical-knowledge-to-evaluate-an%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20with%20the%20medical%20knowledge%20to%20evaluate%20an%20extraordinary%20claim%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBJKaxTBbJSS2B9Ry7%2Fanyone-with-the-medical-knowledge-to-evaluate-an", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBJKaxTBbJSS2B9Ry7%2Fanyone-with-the-medical-knowledge-to-evaluate-an", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<div id=\"entry_t3_6ps\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<p>In a different forum I frequent (&nbsp;<a title=\"The Ornery American\" href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi\">The Ornery American</a> ), a regular member there (LetterRip) has recently been making an extraordinary claim - a new theory of medicine he has devised that relates and can contribute in the cure of several neurological-related conditions.</p>\n<p>I understand that the prior probabilities for him being a crank are much much higher than him being a new Louis Pasteur. Still I was wondering if there is anyone here with sufficient medical/medicinal knowledge that they can easily determine if there's something obviously ludicrous in LetterRip's theory, or even the opposite: if indeed there's something there that makes sense and is worth investigating.</p>\n<p>Here are some of the relevant threads he began:</p>\n<p>- <a title=\"where he requests contacts\" href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014966\">where he requests contacts</a></p>\n<p>- <a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=014997\">where he publishes portion of his theory as a Kindle book</a></p>\n<p>- <a href=\"http://www.ornery.org/cgi-bin/ubbcgi/ultimatebb.cgi?ubb=get_topic;f=6;t=015009\">where he announces more \"breakthroughs\" and insights and offers to cure or at least alleviate simple ailments</a></p>\n<p>Once again: I understand it's highly unlikely there's anything in his theory; still, I felt a cost-benefit analysis justified my making this post here.</p>\n<p>So... anyone with enough understanding of biology/medicine to evaluate these claims of his?</p>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BJKaxTBbJSS2B9Ry7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 6, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "8705", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T02:50:14.816Z", "modifiedAt": null, "url": null, "title": "To Speak Veripoop", "slug": "to-speak-veripoop", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.615Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thre3e", "createdAt": "2011-07-09T17:55:51.206Z", "isAdmin": false, "displayName": "thre3e"}, "userId": "LQcScCTW8cifQpFXh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/quQJxDfmRL5jHd3Rc/to-speak-veripoop", "pageUrlRelative": "/posts/quQJxDfmRL5jHd3Rc/to-speak-veripoop", "linkUrl": "https://www.lesswrong.com/posts/quQJxDfmRL5jHd3Rc/to-speak-veripoop", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20To%20Speak%20Veripoop&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATo%20Speak%20Veripoop%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquQJxDfmRL5jHd3Rc%2Fto-speak-veripoop%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=To%20Speak%20Veripoop%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquQJxDfmRL5jHd3Rc%2Fto-speak-veripoop", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquQJxDfmRL5jHd3Rc%2Fto-speak-veripoop", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 619, "htmlBody": "<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span>From the sociological point of view I cannot imagine a world without compulsory, god declared, laws for basic behaviors, such as sex-related, murder-related, and god-worship related behaviors. My outlook comes from my certainty that some minds are susceptible to the seeking of such compulsions, and my certainty that some other minds are susceptible to a need to supply such compulsions, sometimes as themselves as the authority, and sometimes as representatives of higher authority. The latter group always seems to produce some very successful iterations, from Moses to Jim Jones. . . As it is said in commerce, if there is demand, there will always be folks who will make it a life quest to supply that demand.</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span>If what I'm saying has bases in fact, and if the atheistic challenge is to disenfranchise, dis-empower, organized religion, and other publicists of drivel, then how can mere logical, rational, rhetoric be looked to in order to bring about this goal? It seems evident to me that such rhetoric does not have the needed determinants to effect the goal. Rationality cannot seem to supply the needed compulsions. Thus, rationality goes unheeded.</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span>I have an idea for a possible solution. What if we successfully substituted a new word for truth. What if it became common to say VERIPOOP in place of VERITAS? From that small acorn might grow reexamination of the human faculty for knowing, and claiming truth. It should be obvious to all, that we humans do not have a truth-knowing faculty. We can only know human level truth, which is always temporary and finitely circumscribed. Grass was known to be green for a long time in history, but, as we all know, green is not a property of grass any more. Nature supplies color only to those who are not color blind. Greenness is a human thing, not a grass thing. Reflecting white light at a certain wavelength is intrinsic to grass, but not color. We humans can know only truth that is bound to change in time, but \"real\" truth cannot change. It is already truth. Where else could it go?</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span>Yes, there are mathematical proofs that would present themselves as truth forever. But it's easy to overlook the fact that all scientific and mathematical pronouncements are abstracts of reality. They may be correct within the confines of the postulates that undergird them, but reality is greater than any finite number of postulates. Further, postulates are arbitrarily chosen. Parallel lines may never meet, or always meet, or meet just under specified specified conditions. Therefore, that which is correct is not necessarily truth.This is a fact about the human knowledge horizon, the human condition. The horizon, wherever one draws it, however far we might advance in knowledge, is inexorably there. Yet the wild eyed compulsion addicts are willing to die for what? Why it's their \"truth,\" of course. So, I say that the very word needs to be expunged, because, amazingly, every time it is uttered, it presents a lie. It claims that someone has corralled truth.</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span>VERIPOOP would put us in our place. A new appreciation may develop of the human knowability horizon. How can one be an extremist when one knows that what one proclaims with vehemence is VERIPOOP? It seems to have a calming effect. Scientific veripoops are wonderful. The fact that presently the scientific method doesn't allow truth to be considered truth forever, as it did when science was in the hands of the compulsive knowers of Europe, (e.g. the Galileo problem), is also wonderful. But there is no other word available currently. Science must call its temporary findings truth, especially on true or false tests. Yet the facts show that they are a step down from truth. They are VERIPOOP!</span></p>\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt;\"><span style=\"font-family: Times New Roman;\"><span style=\"mso-tab-count: 1;\"> </span><span style=\"mso-spacerun: yes;\"> </span></span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "quQJxDfmRL5jHd3Rc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": -33, "extendedScore": null, "score": 7.424419768101991e-07, "legacy": true, "legacyId": "8530", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T04:50:14.546Z", "modifiedAt": null, "url": null, "title": "Recent Less Wrong downtime", "slug": "recent-less-wrong-downtime", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "drpowell", "createdAt": "2011-04-12T05:21:02.847Z", "isAdmin": false, "displayName": "drpowell"}, "userId": "cvJor8maPcGMZfdQy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/huwn5ojaHDJ2t8fFz/recent-less-wrong-downtime", "pageUrlRelative": "/posts/huwn5ojaHDJ2t8fFz/recent-less-wrong-downtime", "linkUrl": "https://www.lesswrong.com/posts/huwn5ojaHDJ2t8fFz/recent-less-wrong-downtime", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recent%20Less%20Wrong%20downtime&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecent%20Less%20Wrong%20downtime%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhuwn5ojaHDJ2t8fFz%2Frecent-less-wrong-downtime%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recent%20Less%20Wrong%20downtime%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhuwn5ojaHDJ2t8fFz%2Frecent-less-wrong-downtime", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhuwn5ojaHDJ2t8fFz%2Frecent-less-wrong-downtime", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<p>Many users may have noticed that Less Wrong experienced about 6 hours of downtime on 16/7/2011.</p>\n<p><strong>CAUSE: </strong>The server was put under an unusual amount of load and started up a new instance to load-balance the traffic.&nbsp; Unfortunately, there was a bug in the script that starts the new instance that caused it to use an inconsistent mix of old and new code.&nbsp; The symptom seen by users was that any post with comments was inaccessible.</p>\n<p><strong>RESPONSE</strong>: A hotfix was deployed as soon as the problem was detected, unfortunately it was a Saturday so this reponse time was slower than we would like.&nbsp; We have since implemented a proper fix for the particular bug that caused this problem.&nbsp; We are also creating some extra monitoring probes so we'll be notified promptly of any similar problems in the future.</p>\n<p>Apologies for the inconvenience.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "huwn5ojaHDJ2t8fFz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 36, "extendedScore": null, "score": 7.424791957272453e-07, "legacy": true, "legacyId": "8706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T05:07:01.259Z", "modifiedAt": null, "url": null, "title": "Recent neuroscience relevant to metaethics and extrapolation algorithms", "slug": "recent-neuroscience-relevant-to-metaethics-and-extrapolation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9R5HQxpuC6Ts3dHK6/recent-neuroscience-relevant-to-metaethics-and-extrapolation", "pageUrlRelative": "/posts/9R5HQxpuC6Ts3dHK6/recent-neuroscience-relevant-to-metaethics-and-extrapolation", "linkUrl": "https://www.lesswrong.com/posts/9R5HQxpuC6Ts3dHK6/recent-neuroscience-relevant-to-metaethics-and-extrapolation", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recent%20neuroscience%20relevant%20to%20metaethics%20and%20extrapolation%20algorithms&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecent%20neuroscience%20relevant%20to%20metaethics%20and%20extrapolation%20algorithms%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9R5HQxpuC6Ts3dHK6%2Frecent-neuroscience-relevant-to-metaethics-and-extrapolation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recent%20neuroscience%20relevant%20to%20metaethics%20and%20extrapolation%20algorithms%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9R5HQxpuC6Ts3dHK6%2Frecent-neuroscience-relevant-to-metaethics-and-extrapolation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9R5HQxpuC6Ts3dHK6%2Frecent-neuroscience-relevant-to-metaethics-and-extrapolation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 302, "htmlBody": "<p>Some Yudkowskian metaethicists have supposed that the brain does not compute value for actions or states of affairs at all, but instead uses purely behavioristic methods (via reward signals) to motivate action, and thus the 'terminal goals' we could program an AGI to realize must be extracted from brains only via an extrapolation algorithm.</p>\n<p>My recent <a href=\"/lw/4z7/the_neuroscience_of_desire/\">Neuroscience of Desire</a> post summarized recent work in neuroeconomics that suggests the extrapolation procedure may be a bit easier than originally supposed because the brain <em>does</em>&nbsp;seem to compute expected utility for some actions, and perhaps for some states of affairs.</p>\n<p>One caveat, though, is that information about objective stimuli intensities is always lost at the transducer (for neuronal efficiency, stimuli intensity is always computed relative to a locally-built reference point, but reference point information is quickly thrown away by the brain), and thus the brain cannot be computing utility for objective states of affairs.</p>\n<p>Two&nbsp;<a href=\"http://www.gatsby.ucl.ac.uk/~dayan/papers/daw2011.pdf\">recent</a>&nbsp;<a href=\"http://www.cns.nyu.edu/~daw/sd11.pdf\">papers</a>, though, shed more light on how the brain produces human motivation by combining input from model-free systems (e.g. standard behavioristic systems that don't encode value for anything) and model-based systems (systems that mentally represent actions and encode value for them). The brain may be encoding value for mentally simulated actions that are isomorphic to possible real-world actions, and this value encoding might not involve a reference point like the signals concerning external stimuli do. This again suggests that the extrapolation algorithm needed to build a utility function for a Friendly AI may not be quite as difficult to write as would be the case if the brain did not encode value for anything at all.</p>\n<p>Of course this is all very early and speculative. But if you get hedons from following a rapidly advancing scientific field, computational cognitive neuroscience is a great one to watch. It's amazing what we've learned in the past 5 years.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9R5HQxpuC6Ts3dHK6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 11, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "8707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["48DTJkBH58JbBNSFH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T14:06:30.420Z", "modifiedAt": null, "url": null, "title": "Psychologist making pseudo-claim that recent works \"compromise the Bayesian point of view\"", "slug": "psychologist-making-pseudo-claim-that-recent-works", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:04.295Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QCn3M4ufaDts69br9/psychologist-making-pseudo-claim-that-recent-works", "pageUrlRelative": "/posts/QCn3M4ufaDts69br9/psychologist-making-pseudo-claim-that-recent-works", "linkUrl": "https://www.lesswrong.com/posts/QCn3M4ufaDts69br9/psychologist-making-pseudo-claim-that-recent-works", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Psychologist%20making%20pseudo-claim%20that%20recent%20works%20%22compromise%20the%20Bayesian%20point%20of%20view%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APsychologist%20making%20pseudo-claim%20that%20recent%20works%20%22compromise%20the%20Bayesian%20point%20of%20view%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQCn3M4ufaDts69br9%2Fpsychologist-making-pseudo-claim-that-recent-works%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Psychologist%20making%20pseudo-claim%20that%20recent%20works%20%22compromise%20the%20Bayesian%20point%20of%20view%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQCn3M4ufaDts69br9%2Fpsychologist-making-pseudo-claim-that-recent-works", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQCn3M4ufaDts69br9%2Fpsychologist-making-pseudo-claim-that-recent-works", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 325, "htmlBody": "<p>I have recently been corresponding with a friend who studies psychology regarding human cognition and the best underlying models for understanding it. His argument, summarized very briefly, is given by this quote:</p>\n<blockquote>Lastly, there has been a huge amount of research over the last two decades that shows human reasoning is 1) entirely constituted by emotion, and that it is 2) mostly unconscious and therefore out of our control. A lot of this research has seriously compromised the Bayesian point of view. I am referring to work done by Antonio Damasio, who demonstrated the essential role emotion plays in decision making (Descartes' Error), Timothy Wilson, who demonstrated the vital role of the unconscious (Strangers to Ourselves), and Jonathan Haidt, who demonstrated how moral reasoning is dictated by intuition and emotion (The Emotional Dog and its Rational Tail). I could go on and on here. I assume that you are familiar with this stuff. I'd just like to know how you who respond to this work from the point of view of your studies (in particular, those two points). I don't mean to get in a tit for tat debate here, just want the other side of the story.</blockquote>\n<p>I am having trouble synthesizing a response that captures the Bayesian point of view (and is sufficiently backed up by sources so that it will be useful for my friend rather than just gainsaying of the argument) because I am mostly a decision theory / probability person. Are these works of psychology and neuroscience really illustrating that human emotion governs decision making? What are some good neuroscience papers to read that deal with this, and how do Bayesians respond? It may be that everything he mentions above is a correct assessment (I don't know and don't have enough time to read the books right now), but that it is irrelevant if you want to make good decisions rather than just accept the types of decisions we already make.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QCn3M4ufaDts69br9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 2, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "8712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T14:59:32.453Z", "modifiedAt": null, "url": null, "title": "Meetup : Ottawa LessWrong Weekly(ish) Meetup", "slug": "meetup-ottawa-lesswrong-weekly-ish-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.585Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cKXucz4PXpazkCqdX/meetup-ottawa-lesswrong-weekly-ish-meetup", "pageUrlRelative": "/posts/cKXucz4PXpazkCqdX/meetup-ottawa-lesswrong-weekly-ish-meetup", "linkUrl": "https://www.lesswrong.com/posts/cKXucz4PXpazkCqdX/meetup-ottawa-lesswrong-weekly-ish-meetup", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ottawa%20LessWrong%20Weekly(ish)%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ottawa%20LessWrong%20Weekly(ish)%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKXucz4PXpazkCqdX%2Fmeetup-ottawa-lesswrong-weekly-ish-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ottawa%20LessWrong%20Weekly(ish)%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKXucz4PXpazkCqdX%2Fmeetup-ottawa-lesswrong-weekly-ish-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKXucz4PXpazkCqdX%2Fmeetup-ottawa-lesswrong-weekly-ish-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 89, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1g'>Ottawa LessWrong Weekly(ish) Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 July 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Fox and Feather Pub, 283 Elgin Street, Ottawa, Ontario</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: Fox and Feather, upstairs, possibly in back room #1 if it's free. Look for the LW sign. New people always warmly welcome!</p>\n\n<p>Discussion post: <a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a></p>\n\n<p>Bayes study group: Congrats to new baby daddy Corey (aka Cyan The Fecund) for successfully producing yet another replicon! As a result, the Bayes Conspiracy will take a brief hiatus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1g'>Ottawa LessWrong Weekly(ish) Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cKXucz4PXpazkCqdX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.426682323423801e-07, "legacy": true, "legacyId": "8713", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_ish__Meetup\">Discussion article for the meetup : <a href=\"/meetups/1g\">Ottawa LessWrong Weekly(ish) Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 July 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Fox and Feather Pub, 283 Elgin Street, Ottawa, Ontario</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: Fox and Feather, upstairs, possibly in back room #1 if it's free. Look for the LW sign. New people always warmly welcome!</p>\n\n<p>Discussion post: <a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a></p>\n\n<p>Bayes study group: Congrats to new baby daddy Corey (aka Cyan The Fecund) for successfully producing yet another replicon! As a result, the Bayes Conspiracy will take a brief hiatus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_ish__Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1g\">Ottawa LessWrong Weekly(ish) Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ottawa LessWrong Weekly(ish) Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_ish__Meetup", "level": 1}, {"title": "Discussion article for the meetup : Ottawa LessWrong Weekly(ish) Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_ish__Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T15:58:39.237Z", "modifiedAt": null, "url": null, "title": "Spaced Repetition literature review contest submissions: August 1st deadline", "slug": "spaced-repetition-literature-review-contest-submissions", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8E7rypBiCrt9pwZav/spaced-repetition-literature-review-contest-submissions", "pageUrlRelative": "/posts/8E7rypBiCrt9pwZav/spaced-repetition-literature-review-contest-submissions", "linkUrl": "https://www.lesswrong.com/posts/8E7rypBiCrt9pwZav/spaced-repetition-literature-review-contest-submissions", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spaced%20Repetition%20literature%20review%20contest%20submissions%3A%20August%201st%20deadline&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpaced%20Repetition%20literature%20review%20contest%20submissions%3A%20August%201st%20deadline%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8E7rypBiCrt9pwZav%2Fspaced-repetition-literature-review-contest-submissions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spaced%20Repetition%20literature%20review%20contest%20submissions%3A%20August%201st%20deadline%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8E7rypBiCrt9pwZav%2Fspaced-repetition-literature-review-contest-submissions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8E7rypBiCrt9pwZav%2Fspaced-repetition-literature-review-contest-submissions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>This is a reminder that the deadline for submissions to the <a href=\"/r/discussion/lw/69p/prize_new_spaced_repetition_literature_review_265/\">Spaced Repetition literature review contest</a> is <strong>August 1st </strong>(about 2 weeks from now). If you have questions or comments post them in the original thread or email me (jsalvatier@gmail.com).&nbsp;</p>\n<p>The Seattle meetup group is looking forward to reviewing your submissions!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8E7rypBiCrt9pwZav", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.426865768681787e-07, "legacy": true, "legacyId": "8683", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uR4r3eZZqLmjZDqFj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-18T21:52:19.895Z", "modifiedAt": null, "url": null, "title": "[Link] The Bayesian argument against induction.", "slug": "link-the-bayesian-argument-against-induction", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.940Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Peterdjones", "createdAt": "2011-04-12T19:53:04.222Z", "isAdmin": false, "displayName": "Peterdjones"}, "userId": "ozYb3stofxPMWAjsg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vNqomxvBLRAaJFhin/link-the-bayesian-argument-against-induction", "pageUrlRelative": "/posts/vNqomxvBLRAaJFhin/link-the-bayesian-argument-against-induction", "linkUrl": "https://www.lesswrong.com/posts/vNqomxvBLRAaJFhin/link-the-bayesian-argument-against-induction", "postedAtFormatted": "Monday, July 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20The%20Bayesian%20argument%20against%20induction.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20The%20Bayesian%20argument%20against%20induction.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvNqomxvBLRAaJFhin%2Flink-the-bayesian-argument-against-induction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20The%20Bayesian%20argument%20against%20induction.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvNqomxvBLRAaJFhin%2Flink-the-bayesian-argument-against-induction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvNqomxvBLRAaJFhin%2Flink-the-bayesian-argument-against-induction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>In 1983 Karl Popper and David Miller published an argument to the effect that probability theory could be used to disprove induction. Popper had long been an opponent of induction. Since probability theory in general, and Bayes in particular is often seen as rescuing induction from the standard objections, the argument is significant.</p>\n<p>It is being discussed over at <a href=\"http://www.criticalrationalism.net/2011/07/06/critical-rationalism-vs-inductive-and-subjective-interpretations-of-probability/\">the Critical Rationalism site</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vNqomxvBLRAaJFhin", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "8715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T00:24:55.106Z", "modifiedAt": null, "url": null, "title": "Illustrator needed: Intuitive Bayes 2.0", "slug": "illustrator-needed-intuitive-bayes-2-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:04.764Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QQwZYxCoNWAs9GiQW/illustrator-needed-intuitive-bayes-2-0", "pageUrlRelative": "/posts/QQwZYxCoNWAs9GiQW/illustrator-needed-intuitive-bayes-2-0", "linkUrl": "https://www.lesswrong.com/posts/QQwZYxCoNWAs9GiQW/illustrator-needed-intuitive-bayes-2-0", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Illustrator%20needed%3A%20Intuitive%20Bayes%202.0&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIllustrator%20needed%3A%20Intuitive%20Bayes%202.0%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQQwZYxCoNWAs9GiQW%2Fillustrator-needed-intuitive-bayes-2-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Illustrator%20needed%3A%20Intuitive%20Bayes%202.0%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQQwZYxCoNWAs9GiQW%2Fillustrator-needed-intuitive-bayes-2-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQQwZYxCoNWAs9GiQW%2Fillustrator-needed-intuitive-bayes-2-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p>A huge revision of <em>The Intuitive Explanation of Bayesian Reasoning</em> is in progress, aimed at being considerably more accessible and hence with a lot more graphics.&nbsp; I need someone who can turn out versions of the illustrations that are technically accurate enough to try on beta readers, fast enough and reliably enough that I can ask for revised versions of the illustrations a day later if the beta reader says they didn't understand it.&nbsp; There is a Google Doc in progress which you would be given permission to edit, containing some hand-drawn attempts on my part to indicate what the illustrations should look like, and a number of finished illustrations from an illustrator who unfortunately cannot put in any further work on this job.</p>\n<p>For this job, technical accuracy (i.e., if a ratio is 3:4, it should not look like 1:9), understandability, and speed is much more important than beauty - the idea is to get as quickly as possible to a working version with understandable illustrations that has been verified by the beta readers.</p>\n<p>If interested, email me at yudkowsky@gmail.com.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QQwZYxCoNWAs9GiQW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 20, "extendedScore": null, "score": 7.428437185676243e-07, "legacy": true, "legacyId": "8716", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T01:16:21.478Z", "modifiedAt": null, "url": null, "title": "Connectionism: Modeling the mind with neural networks", "slug": "connectionism-modeling-the-mind-with-neural-networks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:34.626Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dymK5c7BkpgXH4acw/connectionism-modeling-the-mind-with-neural-networks", "pageUrlRelative": "/posts/dymK5c7BkpgXH4acw/connectionism-modeling-the-mind-with-neural-networks", "linkUrl": "https://www.lesswrong.com/posts/dymK5c7BkpgXH4acw/connectionism-modeling-the-mind-with-neural-networks", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Connectionism%3A%20Modeling%20the%20mind%20with%20neural%20networks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConnectionism%3A%20Modeling%20the%20mind%20with%20neural%20networks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdymK5c7BkpgXH4acw%2Fconnectionism-modeling-the-mind-with-neural-networks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Connectionism%3A%20Modeling%20the%20mind%20with%20neural%20networks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdymK5c7BkpgXH4acw%2Fconnectionism-modeling-the-mind-with-neural-networks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdymK5c7BkpgXH4acw%2Fconnectionism-modeling-the-mind-with-neural-networks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2301, "htmlBody": "<p>For about a century, people have known that the brain is made up of neurons which connect to each another and perform computations through electrochemical transmission. For about half a century, people have known enough about computers to realize that the brain doesn't look much like one but still computes pretty well regardless. How?<br /><br />Spreading Activation was one of the first models of mental computation. In this theory, you can imagine the brain as a bunch of nodes in a graph with labels like \"Warlord\" \"Mongolia\" \"Barbarian\", \"Genghis Khan\" and \"Salmon\". Each node has certain connections to the others; when they get activated around the same time, it strengthens the connection. When someone asks a question like \"Who was that barbaric Mongol warlord, again?\" it activates the nodes \"warlord\", \"barbarian\", and \"Mongol\". The activation spreads to all the nodes connected to these, activating them too, and the most strongly activated node will be the one that's closely connected to all three - the barbaric Mongol warlord in question, Genghis Khan. All the while, \"salmon\", which has no connection to any of these concepts, just sits on its own not being activated. This fits with experience, in which if someone asks us about barbaric Mongol warlords, the name \"Genghis Khan\" pops into our brain like magic, while we continue to not think about salmon if we weren't thinking about them before.<br /><br />Bark leash bone wag puppy fetch. If the word \"dog\" is now running through your head, you may be a victim of spreading activation, as were participants in something called a Deese-Roediger-McDermott experiment, who when asked to quickly memorize a list of words like those and then test their retention several minutes later, were <em>more</em> likely to \"remember\" \"dog\" than any of the words actually on the list. <br /><br />So this does seem attractive, and it does avoid the folk psychology concept of a \"belief\". The spreading activation network above was able to successfully answer a question without any representation of propositional statements like \"Genghis Khan was a barbaric Mongol warlord.\" And one could get really enthusiastic about this and try to apply it to motivation. Maybe we have nodes like \"Hunger\", \"Food\", \"McDonalds\", and \"*GET IN CAR, DRIVE TO MCDONALDS*\". The stomach could send a burst of activation to \"Hunger\", which in turn activates the closely related \"Food\", which in turn activates the closely related \"McDonalds\", which in turn activates the closely related \"*GET IN CAR, DRIVE TO MCDONALDS*\", and then before you know it you're ordering a Big Mac.<br /><br />But when you try to implement this on a computer, you don't get very far. Although it can perform certain very basic computations, it has trouble correcting itself, handling anything too complicated (the question \"name one person who is *not* a barbaric Mongol warlord\" would still return \"Genghis Khan\" on our toy spreading activation network), or making good choices (you can convince the toy network McDonalds is your best dining choice just by saying its name a lot; the network doesn't care about food quality, prices, or anything else.) <br /><br />This simple spreading activation model also crashes up against modern neuroscience research, which mostly contradicts the idea of a \"grandmother cell\", ie a single neuron that represents a single concept like your grandmother. Mysteriously, all concepts seem to be represented everywhere at once - Karl Lashley found you can remove <em>any</em> part of a rat's cortex without significantly damaging a specific memory, proving the memory was nonlocalized. How can this be?<br /><br />Computer research into neural nets developed a model that could answer these and other objects, transforming the immature spreading activation model into full-blown connectionism.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>CONNECTIONISM</strong><br /><br />Connectionism is what happens when you try to implement associationism on a computer and find out it's a lot weirder than you thought.<br /><br />Take a bunch of miniprocessors called \"units\" and connect them to each other with unidirectional links. Call some units \"inputs\" and others \"outputs\". Decide what you want to do with them: maybe learn to distinguish chairs from non-chairs.<br /><br />Each unit computes a single value representing its \"activity level\"; each link has a \"strength\" with which it links its origin unit to its destination unit. When a unit is \"activated\" (gets an activity level &gt; 0), it sends that activation along all of its outgoing links. If it has an activation level of .5, and two outgoing links, one to A with strength .33 and one to B with strength -.5, then it sends .165 activation to unit A and -.25 activation to unit B. A and B might also be getting lots of activation from other units they're connected to.<br /><br />Name your two output units \"CHAIR\" and \"NOT A CHAIR\". Connect your many input units to sense-data about the objects you want to classify as chairs or non-chairs; each one could be the luminosity of a pixel in an image of the object, or you could be kind to it and feed it pre-processed input like \"IS MADE OF WOOD\" and \"IS SENTIENT\".<br /><br />Suppose we decide to start with a nice wooden chair. The IS MADE OF WOOD node lights up to its maximum value of 1: it's definitely made of wood! The IS SENTIENT node stays dark; it's definitely not sentient. And then...nothing happens, because we forgot to set the link strengths to anything other than 0. IS MADE OF WOOD is sending activation all over, but it's getting multiplied by zero and everything else stays dark.<br /><br />We now need an program to train the neural net (or a very dedicated human with lots of free time). The training program knows that the correct answer should have been CHAIR, and so the node we designated \"CHAIR\" should have lit up. It uses one of several algorithms to change the strengths of the links in such a way that next time the nodes that have currently lit up light up, CHAIR will also light up. For example, it might change the link from IS MADE OF WOOD to CHAIR to .3 (why doesn't it change it all the way to its maximum value? Because that erases all previous data and reduces the system's entire intelligence to what it learned on just this case).<br /><br />On the other hand, IS SENTIENT is dark, so the training program might infer that IS SENTIENT is not a characteristic of chairs, and change the link strength there accordingly.<br /><br />The next time the program sees a picture of a wooden chair, IS MADE OF WOOD will light up, and it will send its activation to IS CHAIR, making IS CHAIR light up with .3 units of activation: the program has a weak suspicion that the picture is a chair.<br /><br />This is a pretty boring neural network, but if we add several hundred input nodes with all conceivable properties relevant to chairhood and spend a lot of computing power, eventually the program will become pretty good at recognizing chairs from nonchairs, and \"learn\" complicated rules that a three-legged wooden object is a stool which sort of counts as a chair, but a three legged sentient being is an injured dog and sitting on it will only make it angry.<br /><br />Larger and more complicated neural nets contain \"hidden nodes\" - the equivalent of interneurons which sit between the input and the output and exist only to perform computations; feedback from an output node to a previous node that can create stable circles of activation, and other complications. They can perform much more difficult classification problems - identifying words from speech, or people from a photograph.<br /><br />This is interesting because it solves a problem that baffled philosophers for millennia: the difficulty of coming up with good boundaries for categories. Plato famously defined Man as \"a featherless biped\"; Diogenes famously responded by presenting him with a shaved chicken. There seem to be many soft constraints on humans (can use language, have two legs, have a heartbeat) but there are also examples of humans who violate these constraints (babies, amputees, <a href=\"http://theeconomist.tumblr.com/post/6326968565/dick-cheney-has-no-heartbeat-that-might-sound\">Dick Cheney</a>) yet still seem obviously human.<br /><br />Classical computers get bogged down in these problems, but neural nets naturally reason with \"cluster structures in thing-space\" and are expert classifiers in the same way we ourselves are.<br /><strong><br />SIMILARITIES BETWEEN NETS AND BRAINS</strong><br /><br />Even aside from their skill at classifying and pattern-matching, <a href=\"http://www.indiana.edu/~smithlab/articles/jpspconn.pdf\">connectionist networks</a> share many properties with brains, such as:<br /><br />- Obvious structural similarities: neural nets work by lots of units which activate with different strengths and then spread that activation through links; the brain works by lots of neurons which fire at different rates and then spread that activation through axons. <br /><br />- Lack of a \"grandmother cell\". A classical computer sticks each bit of memory in a particular location. A neural net stores memories as patterns of activation across all units in the network. In a feedback network, specific oft-repeated patterns can form attractor states to which the network naturally tends if pushed anywhere in the region. Association between one idea and another is not through physical contiguity, but through similarities in the pattern. \"Grandmother\" probably has most of the same neurons in the same state as \"grandfather\", and so it takes only a tiny stimulus to push the net from one attractor state to the other.<br /><br />- Graceful failure: Classical computer programs do not fail gracefully; flip one bit, and the whole thing blows up and you have to spend the rest of your day messing around with a debugger. Destroying a few units in a neural net may only cost it a little bit of its processing power. This matches with the brain: losing a couple of neurons may make you think less clearly; losing a lot of neurons may give you dementia, memory loss and poor judgment. But there's no one neuron without which you just sit there near-catatonic, chanting \"ERROR: NEURON 10559020481 NOT RESPONDING.\" And Karl Lashley can take out any part of a rat's cortex without affecting its memories too much.<br /><br />- Remembering and forgetting: Neural nets can form memories, and the more the stimulus recurs to them the better they will remember it. But the longer they go without considering the stimulus, the more likely it is that the units involved in the memory-pattern will strengthen other connections, and then it will be harder to get them back in the memory pattern. This is much closer to how humans treat memory than the pristine, eternal encoding of classical computers.<br /><br />- Ability to quickly locate solutions that best satisfy many soft constraints. What's a good place for dinner that's not too expensive, not more than twenty minutes away, serves decent cocktails, and has burgers for the kids? A classical computer would have to first identify the solution class as \"restaurants\", then search every restaurant it knows to see if they match each constraint, then fail to return an answer if no such restaurant exists. A neural net will just *settle* on the best answer, and if the cocktails there aren't really that good, it'll just settle but give the answer a lower strength.<br /><br />- Context-sensitivity. Gold silver copper iron tin, and now when I say \"lead\", you're thinking of Element 82 (Pb), even though without the context a more natural interpretation is of the \"leadership\" variety. Currently active units can force others into a different pattern, giving context sensitivity not only to semantic priming as in the above example, but to emotions (people's thoughts follow different patterns when they're happy or sad), situations, and people.<br /><br />Neural nets have also been used to simulate the results of many popular psychological experiments, including different types of priming, cognitive dissonance, and several of the biases and heuristics.<br /><br /><strong>CONNECTIONISM AND REINFORCEMENT LEARNING</strong><br /><br />The link between connectionism and associationism is pretty obvious, but the link between connectionism and behaviorism is more elegant.<br /><br />In most artificial neural nets, you need a training program to teach the net whether it's right or wrong and which way to adjust the weights. Brains don't have that luxury. Instead, part of their training algorithm for cognitive tasks is based on surprise: if you did not expect the sun to rise today, and you saw it rise anyway, you should probably decrease the strength of whatever links led you to that conclusion, and increase the strengths of any links that would have correctly predicted the sunrise.<br /><br />Motivational links, however, could be modified by reinforcement. If a certain action leads to reward, strengthen the links that led to that action; if it leads to punishment, strengthen the links that would have made you avoid that action.<br /><br />This explains behaviorist principles as a simple case of connectionism, the one where all the links are nice and straight, and you just have to worry about motivation and not about where cognition is coming from. Many of the animals typically studied by behaviorists were simple enough that this simple case was sufficient.<br /><br />Although I think connectionism is our best current theory for how the mind works at a low level, it's hard to theorize about just because the networks are so complicated and so hard to simplify. Behaviorism is useful because it reduces the complexity of the networks to a few comprehensible rules, which allow higher level psychological theories and therapies to be derived from them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Wi3EopKJ2aNdtxSWg": 1, "fpEBgFE7fgpxTm9BF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dymK5c7BkpgXH4acw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 58, "extendedScore": null, "score": 0.000117, "legacy": true, "legacyId": "8717", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T04:09:07.324Z", "modifiedAt": null, "url": null, "title": "Meetup : Phoenix, AZ Meetup on TDT", "slug": "meetup-phoenix-az-meetup-on-tdt", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.806Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Danny_Hintze", "createdAt": "2010-12-04T23:01:40.826Z", "isAdmin": false, "displayName": "Danny_Hintze"}, "userId": "2fHm6t2WFDMPShg5b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gJqxCqHNzMuhWeLYv/meetup-phoenix-az-meetup-on-tdt", "pageUrlRelative": "/posts/gJqxCqHNzMuhWeLYv/meetup-phoenix-az-meetup-on-tdt", "linkUrl": "https://www.lesswrong.com/posts/gJqxCqHNzMuhWeLYv/meetup-phoenix-az-meetup-on-tdt", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Phoenix%2C%20AZ%20Meetup%20on%20TDT&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Phoenix%2C%20AZ%20Meetup%20on%20TDT%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqxCqHNzMuhWeLYv%2Fmeetup-phoenix-az-meetup-on-tdt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Phoenix%2C%20AZ%20Meetup%20on%20TDT%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqxCqHNzMuhWeLYv%2Fmeetup-phoenix-az-meetup-on-tdt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqxCqHNzMuhWeLYv%2Fmeetup-phoenix-az-meetup-on-tdt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1h'>Phoenix, AZ Meetup on TDT</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">01 August 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2502 E. Camelback Road Phoenix,AZ,85016</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be getting together to discuss Timeless Decision Theory and other things. Time and day are currently flexible. We'll be meeting in the Paradise Bakery in the Biltmore mall. \nLink to TDT paper: <a href=\"http://intelligence.org/upload/TDT-v01o.pdf\" rel=\"nofollow\">http://singinst.org/upload/TDT-v01o.pdf</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1h'>Phoenix, AZ Meetup on TDT</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gJqxCqHNzMuhWeLYv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.429133288179072e-07, "legacy": true, "legacyId": "8725", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Phoenix__AZ_Meetup_on_TDT\">Discussion article for the meetup : <a href=\"/meetups/1h\">Phoenix, AZ Meetup on TDT</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">01 August 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2502 E. Camelback Road Phoenix,AZ,85016</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be getting together to discuss Timeless Decision Theory and other things. Time and day are currently flexible. We'll be meeting in the Paradise Bakery in the Biltmore mall. \nLink to TDT paper: <a href=\"http://intelligence.org/upload/TDT-v01o.pdf\" rel=\"nofollow\">http://singinst.org/upload/TDT-v01o.pdf</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Phoenix__AZ_Meetup_on_TDT1\">Discussion article for the meetup : <a href=\"/meetups/1h\">Phoenix, AZ Meetup on TDT</a></h2>", "sections": [{"title": "Discussion article for the meetup : Phoenix, AZ Meetup on TDT", "anchor": "Discussion_article_for_the_meetup___Phoenix__AZ_Meetup_on_TDT", "level": 1}, {"title": "Discussion article for the meetup : Phoenix, AZ Meetup on TDT", "anchor": "Discussion_article_for_the_meetup___Phoenix__AZ_Meetup_on_TDT1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T10:53:48.383Z", "modifiedAt": null, "url": null, "title": "Levels of Organization in General Intelligence", "slug": "levels-of-organization-in-general-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.976Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gBJwAjydby5rte79K", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/srNEdKjZqPta2X3iW/levels-of-organization-in-general-intelligence", "pageUrlRelative": "/posts/srNEdKjZqPta2X3iW/levels-of-organization-in-general-intelligence", "linkUrl": "https://www.lesswrong.com/posts/srNEdKjZqPta2X3iW/levels-of-organization-in-general-intelligence", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Levels%20of%20Organization%20in%20General%20Intelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALevels%20of%20Organization%20in%20General%20Intelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrNEdKjZqPta2X3iW%2Flevels-of-organization-in-general-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Levels%20of%20Organization%20in%20General%20Intelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrNEdKjZqPta2X3iW%2Flevels-of-organization-in-general-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrNEdKjZqPta2X3iW%2Flevels-of-organization-in-general-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p id=\"line1\">In the style of seq reruns, would anyone like to re-read and discuss <a href=\"http://intelligence.org/upload/LOGI.html\">Levels of Organization in General Intelligence</a>?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "srNEdKjZqPta2X3iW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "8733", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T13:28:41.620Z", "modifiedAt": null, "url": null, "title": "Meetup : DC Meetup Learns Decision Theory", "slug": "meetup-dc-meetup-learns-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.929Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benquo", "createdAt": "2009-03-06T00:17:35.184Z", "isAdmin": false, "displayName": "Benquo"}, "userId": "nt2XsHkdksqZ3snNr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LDyG8kM8HNrNqjviE/meetup-dc-meetup-learns-decision-theory", "pageUrlRelative": "/posts/LDyG8kM8HNrNqjviE/meetup-dc-meetup-learns-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/LDyG8kM8HNrNqjviE/meetup-dc-meetup-learns-decision-theory", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20DC%20Meetup%20Learns%20Decision%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20DC%20Meetup%20Learns%20Decision%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDyG8kM8HNrNqjviE%2Fmeetup-dc-meetup-learns-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20DC%20Meetup%20Learns%20Decision%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDyG8kM8HNrNqjviE%2Fmeetup-dc-meetup-learns-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDyG8kM8HNrNqjviE%2Fmeetup-dc-meetup-learns-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 49, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1i'>DC Meetup Learns Decision Theory</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 August 2011 01:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Washington, DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meetup is at a private residence, contact Benquo for details.</p>\n\n<p>Our very own Jeff has agreed to present on decision theory.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1i'>DC Meetup Learns Decision Theory</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LDyG8kM8HNrNqjviE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.43087113966563e-07, "legacy": true, "legacyId": "8734", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___DC_Meetup_Learns_Decision_Theory\">Discussion article for the meetup : <a href=\"/meetups/1i\">DC Meetup Learns Decision Theory</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 August 2011 01:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Washington, DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meetup is at a private residence, contact Benquo for details.</p>\n\n<p>Our very own Jeff has agreed to present on decision theory.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___DC_Meetup_Learns_Decision_Theory1\">Discussion article for the meetup : <a href=\"/meetups/1i\">DC Meetup Learns Decision Theory</a></h2>", "sections": [{"title": "Discussion article for the meetup : DC Meetup Learns Decision Theory", "anchor": "Discussion_article_for_the_meetup___DC_Meetup_Learns_Decision_Theory", "level": 1}, {"title": "Discussion article for the meetup : DC Meetup Learns Decision Theory", "anchor": "Discussion_article_for_the_meetup___DC_Meetup_Learns_Decision_Theory1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T13:41:26.949Z", "modifiedAt": null, "url": null, "title": "Meetup : Rejection Therapy in DC", "slug": "meetup-rejection-therapy-in-dc", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benquo", "createdAt": "2009-03-06T00:17:35.184Z", "isAdmin": false, "displayName": "Benquo"}, "userId": "nt2XsHkdksqZ3snNr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SiYavLtgoaGHocwQi/meetup-rejection-therapy-in-dc", "pageUrlRelative": "/posts/SiYavLtgoaGHocwQi/meetup-rejection-therapy-in-dc", "linkUrl": "https://www.lesswrong.com/posts/SiYavLtgoaGHocwQi/meetup-rejection-therapy-in-dc", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Rejection%20Therapy%20in%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Rejection%20Therapy%20in%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiYavLtgoaGHocwQi%2Fmeetup-rejection-therapy-in-dc%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Rejection%20Therapy%20in%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiYavLtgoaGHocwQi%2Fmeetup-rejection-therapy-in-dc", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiYavLtgoaGHocwQi%2Fmeetup-rejection-therapy-in-dc", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1j'>Rejection Therapy in DC</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 July 2011 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet in the inner courtyard of the National Portrait Gallery/American Museum of Art (near the Chinatown and Metro Center stations if you're taking the metro). We will take 30 minutes to an hour to discuss strategies and goals, and then we will go off separately to do rejection therapy (so be sure to show up well before 3PM - or if you know you'll be late, contact Benquo so you can find us later). After an hour or two of that, we will meet back in the courtyard at a designated time to discuss what we've learned, and any cool things we got by asking.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1j'>Rejection Therapy in DC</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SiYavLtgoaGHocwQi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.43091076238467e-07, "legacy": true, "legacyId": "8735", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Rejection_Therapy_in_DC\">Discussion article for the meetup : <a href=\"/meetups/1j\">Rejection Therapy in DC</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 July 2011 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will meet in the inner courtyard of the National Portrait Gallery/American Museum of Art (near the Chinatown and Metro Center stations if you're taking the metro). We will take 30 minutes to an hour to discuss strategies and goals, and then we will go off separately to do rejection therapy (so be sure to show up well before 3PM - or if you know you'll be late, contact Benquo so you can find us later). After an hour or two of that, we will meet back in the courtyard at a designated time to discuss what we've learned, and any cool things we got by asking.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Rejection_Therapy_in_DC1\">Discussion article for the meetup : <a href=\"/meetups/1j\">Rejection Therapy in DC</a></h2>", "sections": [{"title": "Discussion article for the meetup : Rejection Therapy in DC", "anchor": "Discussion_article_for_the_meetup___Rejection_Therapy_in_DC", "level": 1}, {"title": "Discussion article for the meetup : Rejection Therapy in DC", "anchor": "Discussion_article_for_the_meetup___Rejection_Therapy_in_DC1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T15:10:25.905Z", "modifiedAt": null, "url": null, "title": "GiveWell interview with major SIAI donor Jaan Tallinn", "slug": "givewell-interview-with-major-siai-donor-jaan-tallinn", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.330Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GfTMxwd9L2mkahmq2/givewell-interview-with-major-siai-donor-jaan-tallinn", "pageUrlRelative": "/posts/GfTMxwd9L2mkahmq2/givewell-interview-with-major-siai-donor-jaan-tallinn", "linkUrl": "https://www.lesswrong.com/posts/GfTMxwd9L2mkahmq2/givewell-interview-with-major-siai-donor-jaan-tallinn", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20GiveWell%20interview%20with%20major%20SIAI%20donor%20Jaan%20Tallinn&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGiveWell%20interview%20with%20major%20SIAI%20donor%20Jaan%20Tallinn%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfTMxwd9L2mkahmq2%2Fgivewell-interview-with-major-siai-donor-jaan-tallinn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=GiveWell%20interview%20with%20major%20SIAI%20donor%20Jaan%20Tallinn%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfTMxwd9L2mkahmq2%2Fgivewell-interview-with-major-siai-donor-jaan-tallinn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfTMxwd9L2mkahmq2%2Fgivewell-interview-with-major-siai-donor-jaan-tallinn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p>GiveWell recently release notes from their interview with Jaan Tallinn,&nbsp;Skype co-founder and a major SIAI donor,&nbsp;about SIAI (<a href=\"http://groups.yahoo.com/group/givewell/message/287\">link</a>). Holden Karnofsky says&nbsp;</p>\n<blockquote>\n<p>[M]y key high-level takeaways are that</p>\n<ol>\n<li>I appreciated Jaan's thoughtfulness and willingness to engage in depth. It was an interesting exchange.</li>\n<li>I continue to disagree with the way that SIAI is thinking about the \"Friendliness\" problem.&nbsp;</li>\n<li>It seems to me that all the ways in which Jaan and I disagree on this topic have more to do with philosophy (how to quantify uncertainty; how to deal with conjunctions; how to act in consideration of low probabilities) and with social science-type intuitions (how would people likely use a particular sort of AI) than with computer science or programming (what properties has software usually had historically; which of these properties become incoherent/hard to imagine when applied to AGI)</li>\n</ol></blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xEZwTHPd5AWpgQx9w": 1, "9DNZfxFvY5iKoZQbz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GfTMxwd9L2mkahmq2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 25, "extendedScore": null, "score": 7.431187182934029e-07, "legacy": true, "legacyId": "8736", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T18:16:07.999Z", "modifiedAt": null, "url": null, "title": "LW's image problem: \"Rationality\" is suspicious", "slug": "lw-s-image-problem-rationality-is-suspicious", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.882Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dMaNj5bqDQb7G4Ga9/lw-s-image-problem-rationality-is-suspicious", "pageUrlRelative": "/posts/dMaNj5bqDQb7G4Ga9/lw-s-image-problem-rationality-is-suspicious", "linkUrl": "https://www.lesswrong.com/posts/dMaNj5bqDQb7G4Ga9/lw-s-image-problem-rationality-is-suspicious", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW's%20image%20problem%3A%20%22Rationality%22%20is%20suspicious&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW's%20image%20problem%3A%20%22Rationality%22%20is%20suspicious%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMaNj5bqDQb7G4Ga9%2Flw-s-image-problem-rationality-is-suspicious%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW's%20image%20problem%3A%20%22Rationality%22%20is%20suspicious%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMaNj5bqDQb7G4Ga9%2Flw-s-image-problem-rationality-is-suspicious", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdMaNj5bqDQb7G4Ga9%2Flw-s-image-problem-rationality-is-suspicious", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>Concerning Less Wrong's tagline, consider this plausible reaction of someone looking at LW for the first time:</p>\n<blockquote>\n<p>Cut the crap, nobody cares about rationality in the abstract. Just tell me what view you're trying to push under the guise of presenting it as the only \"rational\" one.</p>\n</blockquote>\n<p>And here are two <a href=\"/lw/eb/open_thread_may_2009/avm\">real</a> quotes from 2009:</p>\n<blockquote>\n<p>[concerning the ban on SIAI discussion during the first weeks of LW] I think it was so that newcomers wouldn't think that LW are a bunch of fringe technophiles that just want to have their cause associated with rationality.</p>\n</blockquote>\n<p>And in reply:</p>\n<blockquote>\n<p>But that's pretty much what LW is, no? I've long suspected that \"rationality,\" as discussed here, was a bit of a ruse designed to insinuate a (misleading) necessary connection between being rational and supporting transhumanist ideals.</p>\n</blockquote>\n<p>The quoted text speaks for itself really. So therefore I think LW's admins/web designers should <strong>seriously consider replacing the rationality tagline</strong> with something more savory.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dMaNj5bqDQb7G4Ga9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -3, "extendedScore": null, "score": 7.431764115380656e-07, "legacy": true, "legacyId": "8738", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T19:21:45.107Z", "modifiedAt": null, "url": null, "title": "LW systemic bias: US centrism", "slug": "lw-systemic-bias-us-centrism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:08.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lucidfox", "createdAt": "2010-11-22T06:58:06.993Z", "isAdmin": false, "displayName": "lucidfox"}, "userId": "hNnKSqvajCMRj9eKK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nAGXkXrNYHEcP3BAT/lw-systemic-bias-us-centrism", "pageUrlRelative": "/posts/nAGXkXrNYHEcP3BAT/lw-systemic-bias-us-centrism", "linkUrl": "https://www.lesswrong.com/posts/nAGXkXrNYHEcP3BAT/lw-systemic-bias-us-centrism", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20systemic%20bias%3A%20US%20centrism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20systemic%20bias%3A%20US%20centrism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnAGXkXrNYHEcP3BAT%2Flw-systemic-bias-us-centrism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20systemic%20bias%3A%20US%20centrism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnAGXkXrNYHEcP3BAT%2Flw-systemic-bias-us-centrism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnAGXkXrNYHEcP3BAT%2Flw-systemic-bias-us-centrism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 270, "htmlBody": "<p>Recently, I have noticed a cultural bias for the United States running through LW threads. It is perhaps to be expected of an English-language website, but for one that is about, among other things, overcoming bias, it is important to recognize one's own.&nbsp;</p>\n<p>Aspects of the bias I have observed include:</p>\n<ul>\n<li><a href=\"/lw/6l4/why_dont_automobiles_decelerate_faster_when/\">Using Imperial units</a>&nbsp;over the SI system, which is the standard for scientific literature and discussion.</li>\n<li><a href=\"/r/discussion/lw/6pj/how_to_solve_the_national_debt_deadlock/\">Presuming the US by default</a>&nbsp;when it is assumed that no country name needs to be given.</li>\n<li>Expecting reader familiarity with US-specific cultural concepts.</li>\n<li>A tendency to focus on the US first and foremost when talking about worldwide problems and scenarios.</li>\n</ul>\n<p>I'm not the first to <a href=\"/lw/4x9/crime_and_punishment/\">raise</a> <a href=\"/lw/55g/spaniard_lesswrongers_unite/\">such</a> concerns, either.</p>\n<p>By comparison, e.g. the English Wikipedia strikes me as an example of an international English-language project that's relatively successful at <a href=\"http://en.wikipedia.org/wiki/Wikipedia:Systemic_bias\">recognizing</a>&nbsp;and <a href=\"http://en.wikipedia.org/wiki/Wikipedia:WikiProject_Countering_systemic_bias\">fighting</a>&nbsp;systemic bias, and a whole set of template messages to mark articles with identified problems.</p>\n<p>To quote Wikipedia itself:</p>\n<blockquote>\n<p>The average Wikipedian on the English Wikipedia is (1) a male, (2) technically inclined, (3) formally educated, (4) an English speaker (native or non-native), (5) European&ndash;descent, (6) aged 15&ndash;49, (7) from a majority-Christian country, (8) from a developed nation, (9) from the Northern Hemisphere, and (10) likely employed as a white-collar worker or enrolled as a student rather than employed as a labourer.</p>\n</blockquote>\n<p>The reason I haven't mentioned other obvious biases, such as gender, age, education, or First World biases, is because those (in my experience) tend to be more subtle here on LW and because I'm myself subject to some of them. However, I might cook something up on them later.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nAGXkXrNYHEcP3BAT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 11, "extendedScore": null, "score": 7.431967995902141e-07, "legacy": true, "legacyId": "8739", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FcNNu7L4m6BqQgMEF", "RfGZyjXdykjWvHs68", "SCXaRKGhQPkJCMmpm", "7Hf2MmvWMuzgy8qZ6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T19:38:44.721Z", "modifiedAt": null, "url": null, "title": "LW's front page freezes, hangs and bugs on Chrome", "slug": "lw-s-front-page-freezes-hangs-and-bugs-on-chrome", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:56.761Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LbQWQR9cwthmQEb8D/lw-s-front-page-freezes-hangs-and-bugs-on-chrome", "pageUrlRelative": "/posts/LbQWQR9cwthmQEb8D/lw-s-front-page-freezes-hangs-and-bugs-on-chrome", "linkUrl": "https://www.lesswrong.com/posts/LbQWQR9cwthmQEb8D/lw-s-front-page-freezes-hangs-and-bugs-on-chrome", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW's%20front%20page%20freezes%2C%20hangs%20and%20bugs%20on%20Chrome&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW's%20front%20page%20freezes%2C%20hangs%20and%20bugs%20on%20Chrome%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbQWQR9cwthmQEb8D%2Flw-s-front-page-freezes-hangs-and-bugs-on-chrome%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW's%20front%20page%20freezes%2C%20hangs%20and%20bugs%20on%20Chrome%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbQWQR9cwthmQEb8D%2Flw-s-front-page-freezes-hangs-and-bugs-on-chrome", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbQWQR9cwthmQEb8D%2Flw-s-front-page-freezes-hangs-and-bugs-on-chrome", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>Browser is Chrome 12.0.742.122. It doesn't happen on Firefox. \"It\" is:</p>\n<ul>\n<li>sometimes I can't click on links and eventually I get Chrome's \"dead tab\" notification</li>\n<li>other times it keeps loading, even though while I wait for it to load I can go to, say, my user page and have it load right away</li>\n<li>twice I've gotten weird graphical bugs on it. Screenshots: <a href=\"http://i.imgur.com/uQ2Tl.jpg\">1</a> <a href=\"http://i.imgur.com/5vawl.jpg\">2</a></li>\n</ul>\n<p>To reiterate, it only happens on the front page, the one you get when you go to lesswrong.com. Other pages are fine. Perhaps it's the map?</p>\n<ul>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LbQWQR9cwthmQEb8D", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.432020797472037e-07, "legacy": true, "legacyId": "8740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T20:40:03.534Z", "modifiedAt": null, "url": null, "title": "Pigeons outperform humans at the Monty Hall Dilemma [LINK]", "slug": "pigeons-outperform-humans-at-the-monty-hall-dilemma-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.787Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KcxmFLSy9tAkj2436/pigeons-outperform-humans-at-the-monty-hall-dilemma-link", "pageUrlRelative": "/posts/KcxmFLSy9tAkj2436/pigeons-outperform-humans-at-the-monty-hall-dilemma-link", "linkUrl": "https://www.lesswrong.com/posts/KcxmFLSy9tAkj2436/pigeons-outperform-humans-at-the-monty-hall-dilemma-link", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pigeons%20outperform%20humans%20at%20the%20Monty%20Hall%20Dilemma%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APigeons%20outperform%20humans%20at%20the%20Monty%20Hall%20Dilemma%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKcxmFLSy9tAkj2436%2Fpigeons-outperform-humans-at-the-monty-hall-dilemma-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pigeons%20outperform%20humans%20at%20the%20Monty%20Hall%20Dilemma%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKcxmFLSy9tAkj2436%2Fpigeons-outperform-humans-at-the-monty-hall-dilemma-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKcxmFLSy9tAkj2436%2Fpigeons-outperform-humans-at-the-monty-hall-dilemma-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p>Humans overthink the problem, which lets their biases in. [<a href=\"http://blogs.discovermagazine.com/notrocketscience/2010/04/02/pigeons-outperform-humans-at-the-monty-hall-dilemma/\">Pop Article</a>] [<a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3086893/pdf/nihms288435.pdf\">Journal Article</a>]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KcxmFLSy9tAkj2436", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "8741", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-19T23:17:10.965Z", "modifiedAt": null, "url": null, "title": "Meetup : RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation", "slug": "meetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:06.772Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chronophasiac", "createdAt": "2009-04-03T11:25:57.322Z", "isAdmin": false, "displayName": "chronophasiac"}, "userId": "wu2Hs7x6pbfJbMumC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2JHwtsfz9Cvm475XW/meetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "pageUrlRelative": "/posts/2JHwtsfz9Cvm475XW/meetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "linkUrl": "https://www.lesswrong.com/posts/2JHwtsfz9Cvm475XW/meetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "postedAtFormatted": "Tuesday, July 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20RESCHEDULED%3A%20Cambridge%20Less%20Wrong%20Meetup%20August%2021st%20with%20Ken%20Hayworth%20of%20the%20Brain%20Preservation%20Foundation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20RESCHEDULED%3A%20Cambridge%20Less%20Wrong%20Meetup%20August%2021st%20with%20Ken%20Hayworth%20of%20the%20Brain%20Preservation%20Foundation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JHwtsfz9Cvm475XW%2Fmeetup-rescheduled-cambridge-less-wrong-meetup-august-21st%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20RESCHEDULED%3A%20Cambridge%20Less%20Wrong%20Meetup%20August%2021st%20with%20Ken%20Hayworth%20of%20the%20Brain%20Preservation%20Foundation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JHwtsfz9Cvm475XW%2Fmeetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JHwtsfz9Cvm475XW%2Fmeetup-rescheduled-cambridge-less-wrong-meetup-august-21st", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 157, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1k'>RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 August 2011 07:33:42PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">MIT Stata Center 32 Vassar St Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please note that this meetup has been rescheduled from August 14th to August 21st. I've invited a guest speaker for a Cambridge Less Wrong meetup on August 14th. Ken Hayworth is a postdoctoral fellow at Harvard's Lichtman Lab and a co-founder of the Brain Preservation Foundation. He'll be giving a talk on his work implementing mind uploading via high-throughput electron microscopy. Ken's talk won't take up the entire meetup, any suggestions for group activities are welcome. The meetup will be on Sunday, August 14th at 2pm, in the MIT Stata Center, room 261. The entrance is shown in Google Maps at <a href=\"http://goo.gl/maps/l0Cq.\" rel=\"nofollow\">http://goo.gl/maps/l0Cq.</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1k'>RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2JHwtsfz9Cvm475XW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.432699575532227e-07, "legacy": true, "legacyId": "8742", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___RESCHEDULED__Cambridge_Less_Wrong_Meetup_August_21st_with_Ken_Hayworth_of_the_Brain_Preservation_Foundation\">Discussion article for the meetup : <a href=\"/meetups/1k\">RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 August 2011 07:33:42PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">MIT Stata Center 32 Vassar St Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please note that this meetup has been rescheduled from August 14th to August 21st. I've invited a guest speaker for a Cambridge Less Wrong meetup on August 14th. Ken Hayworth is a postdoctoral fellow at Harvard's Lichtman Lab and a co-founder of the Brain Preservation Foundation. He'll be giving a talk on his work implementing mind uploading via high-throughput electron microscopy. Ken's talk won't take up the entire meetup, any suggestions for group activities are welcome. The meetup will be on Sunday, August 14th at 2pm, in the MIT Stata Center, room 261. The entrance is shown in Google Maps at <a href=\"http://goo.gl/maps/l0Cq.\" rel=\"nofollow\">http://goo.gl/maps/l0Cq.</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___RESCHEDULED__Cambridge_Less_Wrong_Meetup_August_21st_with_Ken_Hayworth_of_the_Brain_Preservation_Foundation1\">Discussion article for the meetup : <a href=\"/meetups/1k\">RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation</a></h2>", "sections": [{"title": "Discussion article for the meetup : RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation", "anchor": "Discussion_article_for_the_meetup___RESCHEDULED__Cambridge_Less_Wrong_Meetup_August_21st_with_Ken_Hayworth_of_the_Brain_Preservation_Foundation", "level": 1}, {"title": "Discussion article for the meetup : RESCHEDULED: Cambridge Less Wrong Meetup August 21st with Ken Hayworth of the Brain Preservation Foundation", "anchor": "Discussion_article_for_the_meetup___RESCHEDULED__Cambridge_Less_Wrong_Meetup_August_21st_with_Ken_Hayworth_of_the_Brain_Preservation_Foundation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-20T04:22:17.555Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Update Yourself Incrementally", "slug": "seq-rerun-update-yourself-incrementally", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rYJ2QAypoQohxoXuA/seq-rerun-update-yourself-incrementally", "pageUrlRelative": "/posts/rYJ2QAypoQohxoXuA/seq-rerun-update-yourself-incrementally", "linkUrl": "https://www.lesswrong.com/posts/rYJ2QAypoQohxoXuA/seq-rerun-update-yourself-incrementally", "postedAtFormatted": "Wednesday, July 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Update%20Yourself%20Incrementally&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Update%20Yourself%20Incrementally%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrYJ2QAypoQohxoXuA%2Fseq-rerun-update-yourself-incrementally%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Update%20Yourself%20Incrementally%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrYJ2QAypoQohxoXuA%2Fseq-rerun-update-yourself-incrementally", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrYJ2QAypoQohxoXuA%2Fseq-rerun-update-yourself-incrementally", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<p>Title: [SEQ RERUN] Update Yourself Incrementally  Tags: sequence_reruns  Today's post, <a href=\"/lw/ij/update_yourself_incrementally/\">Update Yourself Incrementally</a> was originally published on 14 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Many people think that you must abandon a belief if you admit any counterevidence. Instead, change your belief by small increments. Acknowledge small pieces of counterevidence by shifting your belief down a little. Supporting evidence will follow if your belief is true. \"Won't you lose debates if you concede any counterarguments?\" Rationality is not for winning debates; it is for deciding which side to join.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ii/conservation_of_expected_evidence/\">Conservation of Expected Evidence</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rYJ2QAypoQohxoXuA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 7.433647865172488e-07, "legacy": true, "legacyId": "8747", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["627DZcvme7nLDrbZu", "jiBFC7DcCrZjGmZnJ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-20T10:15:45.086Z", "modifiedAt": null, "url": null, "title": "Secrets of the eliminati", "slug": "secrets-of-the-eliminati", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:03.716Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WQWhXzALcrzrJtqRh/secrets-of-the-eliminati", "pageUrlRelative": "/posts/WQWhXzALcrzrJtqRh/secrets-of-the-eliminati", "linkUrl": "https://www.lesswrong.com/posts/WQWhXzALcrzrJtqRh/secrets-of-the-eliminati", "postedAtFormatted": "Wednesday, July 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Secrets%20of%20the%20eliminati&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASecrets%20of%20the%20eliminati%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQWhXzALcrzrJtqRh%2Fsecrets-of-the-eliminati%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Secrets%20of%20the%20eliminati%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQWhXzALcrzrJtqRh%2Fsecrets-of-the-eliminati", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQWhXzALcrzrJtqRh%2Fsecrets-of-the-eliminati", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 818, "htmlBody": "<p>Anyone who does not believe mental states are ontologically fundamental - ie anyone who denies the reality of something like a soul - has two choices about where to go next. They can try reducing mental states to smaller components, or they can stop talking about them entirely.<br /><br />In a utility-maximizing AI, mental states can be reduced to smaller components. The AI will have goals, and those goals, upon closer examination, will be lines in a computer program.<br /><br />But in the <a href=\"/lw/6ha/the_blueminimizing_robot/\">blue-minimizing robot</a>, its \"goal\" isn't even a line in its program. There's nothing that looks remotely like a goal in its programming, and goals appear only when you make rough generalizations from its behavior in limited cases.</p>\n<p>Philosophers are still very much arguing about whether this applies to humans; the two schools call themselves reductionists and eliminativists (with a third school of wishy-washy half-and-half people calling themselves revisionists). Reductionists want to reduce things like goals and preferences to the appropriate neurons in the brain; eliminativists want to prove that humans, like the blue-minimizing robot, don't have anything of the sort until you start looking at high level abstractions.<a id=\"more\"></a></p>\n<p>I took a similar tack asking ksvanhorn's question in yesterday's post - how can you get a more accurate picture of what your true preferences are? I said:</p>\n<blockquote>\n<p>I don't think there are <em>true</em> preferences. In one situation you have one tendency, in another situation you have another tendency, and \"preference\" is what it looks like when you try to categorize tendencies. But categorization is a passive and not an active process: if every day of the week I eat dinner at 6, I can generalize to say \"I prefer to eat dinner at 6\", but it would be non-explanatory to say that a preference toward dinner at 6 caused my behavior on each day. I think the best way to salvage preferences is to consider them as tendencies currently in reflective equilibrium.</p>\n</blockquote>\n<p><br />A more practical example: when people discuss cryonics or anti-aging, the following argument usually comes up in one form or another: if you were in a burning building, you would try pretty hard to get out. Therefore, you must strongly dislike death and want to avoid it. But if you strongly dislike death and want to avoid it, you must be lying when you say you accept death as a natural part of life and think it's crass and selfish to try to cheat the Reaper. And therefore your reluctance to sign up for cryonics violates your own revealed preferences! You must just be trying to signal conformity or something.<br /><br />The problem is that not signing up for cryonics is also a \"revealed preference\". \"You wouldn't sign up for cryonics, which means you don't really fear death so much, so why bother running from a burning building?\" is an equally good argument, although no one except maybe Marcus Aurelius would take it seriously.<br /><br />Both these arguments assume that somewhere, deep down, there's a utility function with a single term for \"death\" in it, and all decisions just call upon this particular level of death or anti-death preference.<br /><br />More explanatory of the way people actually behave is that there's no unified preference for or against death, but rather a set of behaviors. Being in a burning building activates fleeing behavior; contemplating death from old age does not activate cryonics-buying behavior. People guess at their opinions about death by analyzing these behaviors, usually with a bit of signalling thrown in. If they desire consistency - and most people do - maybe they'll change some of their other behaviors to conform to their hypothesized opinion.<br /><br />One more example. I've previously brought up the case of a rationalist who knows there's no such thing as ghosts, but is still uncomfortable in a haunted house. So does he believe in ghosts or not? If you insist on there being a variable somewhere in his head marked $belief_in_ghosts = (0,1) then it's going to be pretty mysterious when that variable looks like zero when he's talking to the Skeptics Association, and one when he's running away from a creaky staircase at midnight.<br /><br />But it's not at all mysterious that the thought \"I don't believe in ghosts\" gets reinforced because it makes him feel intelligent and modern, and staying around a creaky staircase at midnight gets punished because it makes him afraid.<br /><br />Behaviorism was one of the first and most successful eliminationist theories. I've so far ignored the most modern and exciting eliminationist theory, connectionism, because it involves a lot of math and is very hard to process on an intuitive level. In the next post, I want to try to explain the very basics of connectionism, why it's so exciting, and why it helps justify discussion of behaviorist principles.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"eamWQNQ2dPYWEwhqr": 1, "iP2X4jQNHMWHRNPne": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WQWhXzALcrzrJtqRh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 110, "baseScore": 131, "extendedScore": null, "score": 0.000252, "legacy": true, "legacyId": "8698", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 131, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 256, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-20T10:38:25.517Z", "modifiedAt": null, "url": null, "title": "Tendencies in reflective equilibrium", "slug": "tendencies-in-reflective-equilibrium", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.203Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3wBj8BPquskZAbXu9/tendencies-in-reflective-equilibrium", "pageUrlRelative": "/posts/3wBj8BPquskZAbXu9/tendencies-in-reflective-equilibrium", "linkUrl": "https://www.lesswrong.com/posts/3wBj8BPquskZAbXu9/tendencies-in-reflective-equilibrium", "postedAtFormatted": "Wednesday, July 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tendencies%20in%20reflective%20equilibrium&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATendencies%20in%20reflective%20equilibrium%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3wBj8BPquskZAbXu9%2Ftendencies-in-reflective-equilibrium%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tendencies%20in%20reflective%20equilibrium%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3wBj8BPquskZAbXu9%2Ftendencies-in-reflective-equilibrium", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3wBj8BPquskZAbXu9%2Ftendencies-in-reflective-equilibrium", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1232, "htmlBody": "<p>Consider a case, not too different from what has been shown to happen in reality, where we ask Bob what sounds like a fair punishment for a homeless man who steals $1,000, and he answers ten years. Suppose we wait until Bob has forgotten that we ever asked the first question, and then ask him what sounds like a fair punishment for a hedge fund manager who steals $1,000,000, and he says five years. Maybe we even wait until he forgets the whole affair, and then ask him the same questions again with the same answers, confirming that these are stable preferences.<br /><br />If we now confront Bob with both numbers together, informing him that he supported a ten year sentence for stealing $1,000 and a five year sentence for stealing $1,000,000, a couple of things might happen. He could say \"Yeah, I genuinely believe poor people deserve greater penalties than rich people.\" But more likely he says \"Oh, I guess I was prejudiced.\" Then if we ask him the same question again, he comes up with two numbers that follow the expected mathematical relationship and punish the greater theft with more jail time.<br /><br />Bob isn't working off of some predefined algorithm for determining punishment, like \"jail time = (10 * amount stolen)/net worth\". I don't know if anyone knows exactly what Bob is doing, but at a stab, he's seeing how many unpleasant feelings get generated by imagining the crime, then proposing a jail sentence that activates about an equal amount of unpleasant feelings. If the thought of a homeless man makes images of crime more readily available and so increases the unpleasant feelings, things won't go well for the homeless man. If you're <a href=\"http://blogs.discovermagazine.com/notrocketscience/2011/04/11/justice-is-served-but-more-so-after-lunch-how-food-breaks-sway-the-decisions-of-judges/\">really hungry</a>, that probably won't help either.<br /><br />So just like nothing automatically synchronizes the intention to study a foreign language and the behavior of studying it, so nothing automatically synchronizes thoughts about punishing the theft of $1000 and punishing the theft of $1000000.<br /><br />Of course, there is something that non-automatically does it. After all, in order to elicit this strange behavior from Bob, we had to wait until he forgot about the first answer. Otherwise, he would have noticed and quickly adjusted his answers to make sense.<br /><br />We probably could represent Bob's tendencies as an equation and call it a preference. Maybe it would be a long equation with terms for net worth of criminal, amount stolen, how much food Bob's eaten in the past six hours, and <a href=\"http://www.thedailybeast.com/articles/2009/01/09/dirty-secrets-of-college-admissions.html\">whether his local sports team won the pennant recently</a>, with appropriate coefficients and powers for each. But if Bob saw this equation, he certainly wouldn't endorse it. He'd probably be horrified. It's also unstable: if given a choice, he would undergo brain surgery to remove this equation, thus preventing it from being satisfied. This is why I am reluctant to call these potential formalizations of these equations a \"preference\". <br /><br />Instead of saying that Bob has one preference determining his jail time assignments, it would be better to model him as having several tendencies - a tendency to give a certain answer in the $1000 case, a tendency to give a different answer in the $1000000 case, and several tendencies towards things like consistency, fairness, compassion, et cetera.<br /><br />People strongly consciously endorse these latter tendencies, probably because they're socially useful<sup>1</sup>. If the Chief of Police says \"I know I just put this guy in jail for theft, but I'm going to let this other thief off because he's my friend, and I don't really value consistency that much,\" then they're not going to stay Chief of Police for very long.<br /><br />Bayesians and rationalists, in particular, make a big deal out of consistency. One common parable on the importance of consistency is the Dutch Book - a way to get free money from anyone behaving inconsistently. Suppose you have a weighted coin which can land on either heads or tails. There are several good reasons why I should not assign a probability of 66% to heads and 66% to tails, but one of the clearest is this: you can make me a bet that I will give you $2 if it lands on tails and you give me $1 if it lands on heads, and then a second bet where I give you $2 if it lands on heads and you give me $1 if it lands on tails. Whichever way the coin lands, I owe you $1 and you owe me $2 - I have gained a free dollar. So consistency is good if you don't want to be handing dollars out to random people...<br /><br />...except that the Dutch book itself assumes consistency. If I believe that there is a 66% chance of it landing on heads, but refuse to take a bet at 2:1 odds - or even at 1.5:1 odds even though I should think it's easy money! - then I can't be Dutch booked. I am literally too stupid to be tricked effectively. You would think this wouldn't happen too often, since people would need to construct an accurate mental model to know when they should refuse such a bet, and such an accurate model would tell them they should revise their probabilities - but time after time people have demonstrated the ability <a href=\"/lw/i4/belief_in_belief/\">to do exactly that</a>.<br /><br />I have not yet accepted that consistency is always the best course in every situation. For example, in <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a>, a random person threatens to take away a zillion units of utility if you don't pay them $5. The probability they can make good on their threat is miniscule, but by multiplying out by the size of the threat, it still ought to motivate you to give the money. Some belief has to give - the belief that multiplication works, the belief that I shouldn't pay the money, or the belief that I should be consistent all the time - and right now, consistency seems like the weakest link in the chain.<br /><br />The best we can do is seek reflective equilibrium among our tendencies. If you endorse the belief that rich people should not get lighter sentences than poor people more strongly than you endorse the tendency to give the homeless man ten years in jail and the fund manager five, then you can edit the latter tendency and come up with a \"fair\" sentence. This is Eliezer's <a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">defense of reason and philosophy</a>, a powerful justification for morality (see <a href=\"http://www.raikoth.net/consequentialism.html#metaethics\">part one</a> here) and it's probably the best we can do in justifying our motivations as well.<br /><br />Any tendency that has reached reflective equilibrium in your current state is about as close to a preference as you're going to get. It still won't automatically motivate you, of course. But you can motivate yourself toward it <a href=\"/lw/6nz/approving_reinforces_loweffort_behaviors/\">obliquely</a>, and come up with the course of action that you most thoroughly endorse.</p>\n<p><strong>FOOTNOTES:</strong></p>\n<p><strong>1: </strong>A tendency toward consistency can cause trouble if someone gains advantage from both of two mutually inconsistent ideas. <a href=\"/lw/6mj/trivers_on_selfdeception/\">Trivers' hypothesis</a> predicts that people will consciously deny the inconsistency so they can continue holding both ideas, yet still remain consistent and so socially acceptable. Rationalists are so annoying because we go around telling people they can't do that.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "HAFdXkW4YW4KRe2Gx": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3wBj8BPquskZAbXu9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 45, "baseScore": 52, "extendedScore": null, "score": 0.000113, "legacy": true, "legacyId": "8754", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 52, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CqyJzDZWvGhhFJ7dY", "a5JAiTdytou3Jg749", "46qnWRSR7L2eyNbMA", "yDRX2fdkm3HqfTpav", "DSnamjnW7Ad8vEEKd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-20T10:55:00.581Z", "modifiedAt": null, "url": null, "title": "Working memory and driving", "slug": "working-memory-and-driving", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.007Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "eugman", "createdAt": "2009-09-28T01:40:39.582Z", "isAdmin": false, "displayName": "eugman"}, "userId": "rtJy8Y9zXRpjWmeMi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/26kQd7E7A3ymSM9bk/working-memory-and-driving", "pageUrlRelative": "/posts/26kQd7E7A3ymSM9bk/working-memory-and-driving", "linkUrl": "https://www.lesswrong.com/posts/26kQd7E7A3ymSM9bk/working-memory-and-driving", "postedAtFormatted": "Wednesday, July 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Working%20memory%20and%20driving&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWorking%20memory%20and%20driving%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F26kQd7E7A3ymSM9bk%2Fworking-memory-and-driving%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Working%20memory%20and%20driving%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F26kQd7E7A3ymSM9bk%2Fworking-memory-and-driving", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F26kQd7E7A3ymSM9bk%2Fworking-memory-and-driving", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>I've been trying to learn how to drive and unfortunately I suck at it. Some combination of a stressful teacher and hyperfocusing have made it very difficult to learn. My biggest problem is with the multitasking aspect. Remembering to put on the turn signal while stopping and and checking my speed and watching out for other cars, etc. It's difficult for me, I forget or miss things. One thing I was considering may possibly help is using dual n-back to boost my working memory. Does anyone have any thoughts on the likely effectiveness of this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5d63AWNjtFyHprX2k": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "26kQd7E7A3ymSM9bk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 0, "extendedScore": null, "score": 7.434868755640147e-07, "legacy": true, "legacyId": "8755", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-20T23:24:12.252Z", "modifiedAt": null, "url": null, "title": "Meetup : Biweekly Sunday Seattle meetup: talking about identity", "slug": "meetup-biweekly-sunday-seattle-meetup-talking-about-identity", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/btHXnXiX2MhmKAaGp/meetup-biweekly-sunday-seattle-meetup-talking-about-identity", "pageUrlRelative": "/posts/btHXnXiX2MhmKAaGp/meetup-biweekly-sunday-seattle-meetup-talking-about-identity", "linkUrl": "https://www.lesswrong.com/posts/btHXnXiX2MhmKAaGp/meetup-biweekly-sunday-seattle-meetup-talking-about-identity", "postedAtFormatted": "Wednesday, July 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Biweekly%20Sunday%20Seattle%20meetup%3A%20talking%20about%20identity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Biweekly%20Sunday%20Seattle%20meetup%3A%20talking%20about%20identity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbtHXnXiX2MhmKAaGp%2Fmeetup-biweekly-sunday-seattle-meetup-talking-about-identity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Biweekly%20Sunday%20Seattle%20meetup%3A%20talking%20about%20identity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbtHXnXiX2MhmKAaGp%2Fmeetup-biweekly-sunday-seattle-meetup-talking-about-identity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbtHXnXiX2MhmKAaGp%2Fmeetup-biweekly-sunday-seattle-meetup-talking-about-identity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 147, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1l'>Biweekly Sunday Seattle meetup: talking about identity</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 July 2011 04:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">414 50th St NE, Seattle, WA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The biweekly meetup is happening at the regular place and time:</p>\n\n<ul>\n<li>Whether people tried out the procrastination material and whether they found it useful</li>\n<li>Watching the short cartoon To Be, which is about the philosophical difficulties of intuitive conceptions of identity.  It's short and funny. We'll have some discussion about identity after this.</li>\n</ul>\n\n<p>We will be ordering take out again, so please bring some cash if you would like to eat.</p>\n\n<p>The official end of the meetup will be 6:30pm, but people are welcome to stay and hang out after that.</p>\n\n<p>I still intend to do a rejection therapy meetup, but the weather has been too unpredictable I think.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1l'>Biweekly Sunday Seattle meetup: talking about identity</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "btHXnXiX2MhmKAaGp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.437198859057936e-07, "legacy": true, "legacyId": "8758", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Biweekly_Sunday_Seattle_meetup__talking_about_identity\">Discussion article for the meetup : <a href=\"/meetups/1l\">Biweekly Sunday Seattle meetup: talking about identity</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 July 2011 04:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">414 50th St NE, Seattle, WA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The biweekly meetup is happening at the regular place and time:</p>\n\n<ul>\n<li>Whether people tried out the procrastination material and whether they found it useful</li>\n<li>Watching the short cartoon To Be, which is about the philosophical difficulties of intuitive conceptions of identity.  It's short and funny. We'll have some discussion about identity after this.</li>\n</ul>\n\n<p>We will be ordering take out again, so please bring some cash if you would like to eat.</p>\n\n<p>The official end of the meetup will be 6:30pm, but people are welcome to stay and hang out after that.</p>\n\n<p>I still intend to do a rejection therapy meetup, but the weather has been too unpredictable I think.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Biweekly_Sunday_Seattle_meetup__talking_about_identity1\">Discussion article for the meetup : <a href=\"/meetups/1l\">Biweekly Sunday Seattle meetup: talking about identity</a></h2>", "sections": [{"title": "Discussion article for the meetup : Biweekly Sunday Seattle meetup: talking about identity", "anchor": "Discussion_article_for_the_meetup___Biweekly_Sunday_Seattle_meetup__talking_about_identity", "level": 1}, {"title": "Discussion article for the meetup : Biweekly Sunday Seattle meetup: talking about identity", "anchor": "Discussion_article_for_the_meetup___Biweekly_Sunday_Seattle_meetup__talking_about_identity1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T00:21:50.728Z", "modifiedAt": null, "url": null, "title": "Meetup : Irvine Meetup Wednesday July 27", "slug": "meetup-irvine-meetup-wednesday-july-27", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6WbC7jEZahpgcWNcD/meetup-irvine-meetup-wednesday-july-27", "pageUrlRelative": "/posts/6WbC7jEZahpgcWNcD/meetup-irvine-meetup-wednesday-july-27", "linkUrl": "https://www.lesswrong.com/posts/6WbC7jEZahpgcWNcD/meetup-irvine-meetup-wednesday-july-27", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2027&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2027%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WbC7jEZahpgcWNcD%2Fmeetup-irvine-meetup-wednesday-july-27%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20July%2027%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WbC7jEZahpgcWNcD%2Fmeetup-irvine-meetup-wednesday-july-27", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6WbC7jEZahpgcWNcD%2Fmeetup-irvine-meetup-wednesday-july-27", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1m'>Irvine Meetup Wednesday July 27</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 July 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>. See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1m'>Irvine Meetup Wednesday July 27</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6WbC7jEZahpgcWNcD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.437378185180365e-07, "legacy": true, "legacyId": "8759", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_27\">Discussion article for the meetup : <a href=\"/meetups/1m\">Irvine Meetup Wednesday July 27</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 July 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>. See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_271\">Discussion article for the meetup : <a href=\"/meetups/1m\">Irvine Meetup Wednesday July 27</a></h2>", "sections": [{"title": "Discussion article for the meetup : Irvine Meetup Wednesday July 27", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_27", "level": 1}, {"title": "Discussion article for the meetup : Irvine Meetup Wednesday July 27", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_July_271", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yFDKvfN6D87Tf5J9f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T05:16:24.565Z", "modifiedAt": null, "url": null, "title": "Bayesian Conspiracy @ Burning Man 2011", "slug": "bayesian-conspiracy-burning-man-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:28.458Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Wn8o9yyQ2aR5fwjCn/bayesian-conspiracy-burning-man-2011", "pageUrlRelative": "/posts/Wn8o9yyQ2aR5fwjCn/bayesian-conspiracy-burning-man-2011", "linkUrl": "https://www.lesswrong.com/posts/Wn8o9yyQ2aR5fwjCn/bayesian-conspiracy-burning-man-2011", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20Conspiracy%20%40%20Burning%20Man%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20Conspiracy%20%40%20Burning%20Man%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWn8o9yyQ2aR5fwjCn%2Fbayesian-conspiracy-burning-man-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20Conspiracy%20%40%20Burning%20Man%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWn8o9yyQ2aR5fwjCn%2Fbayesian-conspiracy-burning-man-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWn8o9yyQ2aR5fwjCn%2Fbayesian-conspiracy-burning-man-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 187, "htmlBody": "<p><strong>Edit: 8/27</strong></p>\n<p>After a beautiful jaunt to the fertile delta of <a href=\"http://ephemerisle.org/wiki/Ephemerisle\">Ephemerisle</a>, the Bayesian Conspiracy is returning to the much less forgiving environs of Burning Man in 2011. We have been placed in the Playagon village at 3:55 and E.G -- I think the F road is obstructed by Playagon village, and we will be right about where F would be. Time Colony is at 4:00.</p>\n<p>This year, we are asking for $300 dues from campers. Creating a non-capitalist utopian society with communal shelter, good food, water, kitchen, some air conditioning, and not even close to all of the comforts of home is quite expensive for a first time theme camp -- I myself am participating at the sponsorship level of $1000.&nbsp;</p>\n<p>We had a total of 30 slots that are now mostly filled. We have <strong>3 tickets</strong>&nbsp;available now. If you're interested, please email me at kfischer &amp;! gmail (* com and let me know as soon as possible.</p>\n<p>For those that would like to camp nearby but prefer a more DIY experience, there will likely be unreserved camping space just across the road from us.</p>\n<p>Previous discussions:&nbsp;<br /><a href=\"/lw/4qi/less_wrong_at_burning_man_2011/\">http://lesswrong.com/lw/4qi/less_wrong_at_burning_man_2011/</a>&nbsp;<br /><a href=\"/lw/2mp/burning_man_meetup_bayes_camp/\">http://lesswrong.com/lw/2mp/burning_man_meetup_bayes_camp/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Wn8o9yyQ2aR5fwjCn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 12, "extendedScore": null, "score": 7.438294713166787e-07, "legacy": true, "legacyId": "8765", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FZMJRau2GeffqZN3d", "Sfir5pFYgXJ8PEbwP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T11:47:47.681Z", "modifiedAt": null, "url": null, "title": "[Link] \"Upload\", a video-conference between a girl and her dead grandfather", "slug": "link-upload-a-video-conference-between-a-girl-and-her-dead", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.642Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pre", "createdAt": "2009-02-27T14:35:32.511Z", "isAdmin": false, "displayName": "pre"}, "userId": "XCwdovczssgYqBwT2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hgvmbhDAd7H89Sckv/link-upload-a-video-conference-between-a-girl-and-her-dead", "pageUrlRelative": "/posts/hgvmbhDAd7H89Sckv/link-upload-a-video-conference-between-a-girl-and-her-dead", "linkUrl": "https://www.lesswrong.com/posts/hgvmbhDAd7H89Sckv/link-upload-a-video-conference-between-a-girl-and-her-dead", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20%22Upload%22%2C%20a%20video-conference%20between%20a%20girl%20and%20her%20dead%20grandfather&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20%22Upload%22%2C%20a%20video-conference%20between%20a%20girl%20and%20her%20dead%20grandfather%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgvmbhDAd7H89Sckv%2Flink-upload-a-video-conference-between-a-girl-and-her-dead%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20%22Upload%22%2C%20a%20video-conference%20between%20a%20girl%20and%20her%20dead%20grandfather%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgvmbhDAd7H89Sckv%2Flink-upload-a-video-conference-between-a-girl-and-her-dead", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgvmbhDAd7H89Sckv%2Flink-upload-a-video-conference-between-a-girl-and-her-dead", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>I made a video last month, which when I <a href=\"/lw/6m5/discussion_ideas_for_a_lesswrongian_anticipation/4i52\">mentioned in another thread</a> someone said I should post as a top level discussion.</p>\n<p>It's just a ten minute zero-budget thing I wrote in which a girl has a video conference with her dead and backed-up-then-uploaded grandfather. Intended as the first in a series, but later episodes will only get produced if donations come. Later episodes talk more about AI's failures and the political situation with unrest from the living demanding the dead shouldn't have their jobs etc.</p>\n<p>Anyway, <a href=\"http://commonshostage.com/projects/project/upload/\">watch it here</a> if you like, I'd be happy to hear what y'all think :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hgvmbhDAd7H89Sckv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 7.439512808419586e-07, "legacy": true, "legacyId": "8774", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T16:22:58.558Z", "modifiedAt": null, "url": null, "title": "Free (old) scientific papers [Link]", "slug": "free-old-scientific-papers-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.375Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JackEmpty", "createdAt": "2011-03-14T10:42:25.519Z", "isAdmin": false, "displayName": "JackEmpty"}, "userId": "4Jj3x57cMrKFq7Awy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LDnqfscCw78zibovh/free-old-scientific-papers-link", "pageUrlRelative": "/posts/LDnqfscCw78zibovh/free-old-scientific-papers-link", "linkUrl": "https://www.lesswrong.com/posts/LDnqfscCw78zibovh/free-old-scientific-papers-link", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Free%20(old)%20scientific%20papers%20%5BLink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFree%20(old)%20scientific%20papers%20%5BLink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDnqfscCw78zibovh%2Ffree-old-scientific-papers-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Free%20(old)%20scientific%20papers%20%5BLink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDnqfscCw78zibovh%2Ffree-old-scientific-papers-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLDnqfscCw78zibovh%2Ffree-old-scientific-papers-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p><a href=\"http://thepiratebay.org/torrent/6554331/Papers_from_Philosophical_Transactions_of_the_Royal_Society__fro\">http://thepiratebay.org/torrent/6554331/Papers_from_Philosophical_Transactions_of_the_Royal_Society__fro</a></p>\r\n<p>&nbsp;</p>\r\n<p>Greg Maxwell is torrenting 33Gib of&nbsp;public domain JSTOR documents that were behind paywalls.</p>\r\n<p>&nbsp;</p>\r\n<p>What's your take on this, ethically, legally, etc?</p>\r\n<p>&nbsp;</p>\r\n<p>ETA: More on this: <a href=\"http://gigaom.com/2011/07/21/pirate-bay-jstor/\">http://gigaom.com/2011/07/21/pirate-bay-jstor/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LDnqfscCw78zibovh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.440369457798997e-07, "legacy": true, "legacyId": "8776", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T18:14:45.694Z", "modifiedAt": null, "url": null, "title": "Less Wrong in Other Languages", "slug": "less-wrong-in-other-languages", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.683Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pPCirEmMhnBABgCFp/less-wrong-in-other-languages", "pageUrlRelative": "/posts/pPCirEmMhnBABgCFp/less-wrong-in-other-languages", "linkUrl": "https://www.lesswrong.com/posts/pPCirEmMhnBABgCFp/less-wrong-in-other-languages", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20in%20Other%20Languages&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20in%20Other%20Languages%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpPCirEmMhnBABgCFp%2Fless-wrong-in-other-languages%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20in%20Other%20Languages%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpPCirEmMhnBABgCFp%2Fless-wrong-in-other-languages", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpPCirEmMhnBABgCFp%2Fless-wrong-in-other-languages", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 170, "htmlBody": "<p>Less Wrong is a great blog.&nbsp;</p>\n<p>Not all people feel at ease with the english language.&nbsp;</p>\n<p>I recently noticed that Brazilians are <em>almost</em>&nbsp;not available in this rationalist community.&nbsp;</p>\n<p>This sucks, even if it has cultural explanations. So I decided on writing a similar blog model in portuguese (eventually also translating the most important sequences, but let's not get ahead of time). If it is a language barrier issue, this might help.&nbsp;</p>\n<p>Less Wrong design is great, and even though there may be more addictive systems than the karma one, karma is a great one.&nbsp;</p>\n<p>So I wondered if it is possible and easy for a non-computer programmer to copy the website design, writing a portuguese version of it, climbing mount rational, and eventually leading people here (since, obviously, learning english is one of the most important rational goals of a 21st century human). &nbsp;Maybe it is not possible because it needs editing in formal languages, maybe because it is not allowed.&nbsp;</p>\n<p>But saving the time of building it seems worth a shot. How should I proceed?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pPCirEmMhnBABgCFp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 13, "extendedScore": null, "score": 7.44071750020807e-07, "legacy": true, "legacyId": "8777", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T19:09:54.057Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] One Argument Against An Army", "slug": "seq-rerun-one-argument-against-an-army", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.799Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9YdC9tnt35w5nzgnK/seq-rerun-one-argument-against-an-army", "pageUrlRelative": "/posts/9YdC9tnt35w5nzgnK/seq-rerun-one-argument-against-an-army", "linkUrl": "https://www.lesswrong.com/posts/9YdC9tnt35w5nzgnK/seq-rerun-one-argument-against-an-army", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20One%20Argument%20Against%20An%20Army&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20One%20Argument%20Against%20An%20Army%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9YdC9tnt35w5nzgnK%2Fseq-rerun-one-argument-against-an-army%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20One%20Argument%20Against%20An%20Army%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9YdC9tnt35w5nzgnK%2Fseq-rerun-one-argument-against-an-army", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9YdC9tnt35w5nzgnK%2Fseq-rerun-one-argument-against-an-army", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>Title: [SEQ RERUN] One Argument Against An Army  Tags: sequence_reruns  Today's post, <a href=\"/lw/ik/one_argument_against_an_army/\">One Argument Against An Army</a> was originally published on 15 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>It is tempting to weigh each counterargument by itself against all supporting arguments. No single counterargument can overwhelm all the supporting arguments, so you easily conclude that your theory was right. Indeed, as you win this kind of battle over and over again, you feel ever <em>more </em>confident in your theory. But, in fact, you are just rehearsing already-known evidence in favor of your view.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ij/update_yourself_incrementally/\">Update Yourself Incrementally</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9YdC9tnt35w5nzgnK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.440889186193007e-07, "legacy": true, "legacyId": "8779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WN73eiLQkuDtSC8Ag", "627DZcvme7nLDrbZu", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T22:25:06.205Z", "modifiedAt": null, "url": null, "title": "Only selfimmolate if you care about what foreigners think ", "slug": "only-selfimmolate-if-you-care-about-what-foreigners-think", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:57.005Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CharlieSheen", "createdAt": "2011-04-18T23:50:24.547Z", "isAdmin": false, "displayName": "CharlieSheen"}, "userId": "REGTxvxp4tT5RMMir", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R5zj84kmMTynAvFek/only-selfimmolate-if-you-care-about-what-foreigners-think", "pageUrlRelative": "/posts/R5zj84kmMTynAvFek/only-selfimmolate-if-you-care-about-what-foreigners-think", "linkUrl": "https://www.lesswrong.com/posts/R5zj84kmMTynAvFek/only-selfimmolate-if-you-care-about-what-foreigners-think", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Only%20selfimmolate%20if%20you%20care%20about%20what%20foreigners%20think%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOnly%20selfimmolate%20if%20you%20care%20about%20what%20foreigners%20think%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR5zj84kmMTynAvFek%2Fonly-selfimmolate-if-you-care-about-what-foreigners-think%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Only%20selfimmolate%20if%20you%20care%20about%20what%20foreigners%20think%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR5zj84kmMTynAvFek%2Fonly-selfimmolate-if-you-care-about-what-foreigners-think", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR5zj84kmMTynAvFek%2Fonly-selfimmolate-if-you-care-about-what-foreigners-think", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<p>Someone self immolates and explicitly states it is a form of political protest in Megdad. What a crazy regime!&nbsp; <br />Someone self immolates and explicitly states it is a form of political protest in Hometown. What a crazy person!</p>\n<p><br /><strong>Edit: </strong>What -5 already? What is giving an example of how people never take the <a href=\"http://wiki.lesswrong.com/wiki/Outside_view\">outside view</a> of their own society that bad a topic for the discussion section? Also disclaimer both Hometown State and Megdadistan Republic are fictional countries and no actual examples where given, to avoid mind killers.</p>\n<p><strong>2nd Edit:</strong> Wow I really need to spell this out? The media of Hometown are more likley to treat an immolation in Megdad as due to a legitimate grievance worthy of attention and down play any mental health problems or details that might paint the person in an unflattering light compared to someone who self-immolates in Hometown. And I think this effect is mostly not due to government enforced censorship or pressure.</p>\n<p>&nbsp;</p>\n<p>Noble act of defiant self-sacrifice is far. Suicidal crazies are near.</p>\n<p>&nbsp;</p>\n<p>The only way to get good coverage to acheive social change is to count on foreign media to paint a kind picture of you. And supposing your people care about what the media of Megdad say about your country.</p>\n<p><strong>3rd Edit:</strong> -15 Pretty clear that I'm wrong .</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R5zj84kmMTynAvFek", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -26, "extendedScore": null, "score": 7.441497039482108e-07, "legacy": true, "legacyId": "8780", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-21T23:21:58.857Z", "modifiedAt": null, "url": null, "title": "How To Copy Less Wrong Design", "slug": "how-to-copy-less-wrong-design", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:52.733Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MLL8jHHkE4vpRFGGf/how-to-copy-less-wrong-design", "pageUrlRelative": "/posts/MLL8jHHkE4vpRFGGf/how-to-copy-less-wrong-design", "linkUrl": "https://www.lesswrong.com/posts/MLL8jHHkE4vpRFGGf/how-to-copy-less-wrong-design", "postedAtFormatted": "Thursday, July 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20To%20Copy%20Less%20Wrong%20Design&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20To%20Copy%20Less%20Wrong%20Design%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLL8jHHkE4vpRFGGf%2Fhow-to-copy-less-wrong-design%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20To%20Copy%20Less%20Wrong%20Design%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLL8jHHkE4vpRFGGf%2Fhow-to-copy-less-wrong-design", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLL8jHHkE4vpRFGGf%2Fhow-to-copy-less-wrong-design", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 130, "htmlBody": "<p>Suppose you speak a different native tongue and you want to create a Less Wrong similar blog in your language, to produce rationalists who eventually will join Less Wrong (say when the costs of reading in english fall beneath their utility functions expected gain from switching blogs)</p>\n<p>Can you pluck that out without being a programmer?</p>\n<p>I want to do this but don't know how to go about doing it. Is it as easy as creating a blog in a random blog website? Are the owners OK with that? Can you send me info on how to do it, how much space is required etc...?</p>\n<p>The features I'm most interested in are the \"create your account\" \"comment\" and \"get upvoted\". Those seem to be responsible for part of the unusual fidelity of readers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MLL8jHHkE4vpRFGGf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.441674170443768e-07, "legacy": true, "legacyId": "8781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T04:49:13.107Z", "modifiedAt": null, "url": null, "title": "Sensory modality for code", "slug": "sensory-modality-for-code", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.308Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JuGJnqzEFnWcd9Hhc/sensory-modality-for-code", "pageUrlRelative": "/posts/JuGJnqzEFnWcd9Hhc/sensory-modality-for-code", "linkUrl": "https://www.lesswrong.com/posts/JuGJnqzEFnWcd9Hhc/sensory-modality-for-code", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sensory%20modality%20for%20code&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASensory%20modality%20for%20code%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJuGJnqzEFnWcd9Hhc%2Fsensory-modality-for-code%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sensory%20modality%20for%20code%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJuGJnqzEFnWcd9Hhc%2Fsensory-modality-for-code", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJuGJnqzEFnWcd9Hhc%2Fsensory-modality-for-code", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 610, "htmlBody": "<p>This post is inspired by <a href=\"/r/discussion/lw/6ql/levels_of_organization_in_general_intelligence/\">Chimera wanting to talk about \"Levels of Organization in General Intelligence.\"</a></p>\n<p>In the paper, Eliezer mentions giving a seed AI a sensory modality for code. &nbsp;And I think it'll be fun to figure out just what that means.</p>\n<p>&nbsp;</p>\n<p>Code is a pretty simple environment compared to the cool stuff humans can do with sight and hearing, so I'd like to start by giving a picture of a totally different sensory modality in a simple environment - vision in robot soccer.</p>\n<p>The example system described in <a href=\"http://lrb.informatik.uni-dortmund.de/~weiss/An%20Examplary%20Robot%20Soccer%20Vision%20System.pdf\">this paper</a>&nbsp;can be used to find and track ball and robot movement during a soccer match. &nbsp;For simplicity, let's imagine that the AI is just looking down at the field from above using a single camera. &nbsp;The camera is sending it a bunch of signals, but it's not sensory modality yet because it's not integrated with the rest of the AI. &nbsp;At least the following tasks needed to be implemented as part of the program before the AI can see:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Finding unusual pixels quickly.</li>\n<li>Finding shapes of the same color in the picture.</li>\n<li>Use object properties (what the tops of the robots look like) to collect shapes into physical objects.</li>\n<li>Use a mapping between the picture and real space to get real space coordinates of objects.</li>\n<li>Correlate with previous positions and motion to track objects and figure out which is which.</li>\n</ul>\n<p>&nbsp;</p>\n<p>This work seems a lot like compression - it takes a big hunk of image data and turns it into a petite morsel of robot locations and orientations. &nbsp;But evaluated as compression, it's awful, since so much information, like the&nbsp;texture of the robots, gets discarded. &nbsp;Rather than calling it compression, it's more like translation from the language of images to the language the AI thinks in. &nbsp;The AI doesn't need to think about the exact texture of the robots, and so the sensory modality doesn't pass it on.</p>\n<p>&nbsp;</p>\n<p>So how do we do something like that with code? &nbsp;We want something that takes raw code as an input and outputs a language for the AI to think about code in. &nbsp;Additionally, as mentioned in LOGI, this language can be used by the AI to imagine code, so it should contain the necessary ideas. &nbsp;It should discard a lot of low-level information, like the vision system extracting the coordinates and allowing the AI to ignore the texture. &nbsp;It might also shuffle the information around to keep track of function of the code, like mapping points from the camera onto real space.</p>\n<p>For some code, this might be done with nested black boxes - finding groups of code and replacing them with black boxes that say what they do and what they're connected to. &nbsp;Then finding groups of black boxes and replacing those groups with what they do and what other groups they're connected to. &nbsp;The big problem for this approach is figuring out how to label what a piece of code does. &nbsp;Finding a short description of a piece of code is straightforward, but just condensing the code is not enough, the program needs to be able to separate function from form and throw out the form information. &nbsp;Ideally, once our program had removed as much form as it could, the AI would be able in principle&nbsp;to rewrite the program just from the functional description.</p>\n<p>&nbsp;</p>\n<p>Unfortunately, this is where the problem gets hard for me. &nbsp;I have some thoughts, like \"follow the flow of the program\" and \"check if locally arbitrary choices will cause nonlocal problems if changed.\" But first I'd like to check that I'm sort of on the right track, and then maybe forge ahead.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JuGJnqzEFnWcd9Hhc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 7.442693414593969e-07, "legacy": true, "legacyId": "8772", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["srNEdKjZqPta2X3iW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T10:48:55.724Z", "modifiedAt": null, "url": null, "title": "The Singularity Institute is expanding its research program at very little cost. Boo-yah!", "slug": "the-singularity-institute-is-expanding-its-research-program", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:56.947Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ba8k7anS2GiirYiJ6/the-singularity-institute-is-expanding-its-research-program", "pageUrlRelative": "/posts/Ba8k7anS2GiirYiJ6/the-singularity-institute-is-expanding-its-research-program", "linkUrl": "https://www.lesswrong.com/posts/Ba8k7anS2GiirYiJ6/the-singularity-institute-is-expanding-its-research-program", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20Institute%20is%20expanding%20its%20research%20program%20at%20very%20little%20cost.%20Boo-yah!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20Institute%20is%20expanding%20its%20research%20program%20at%20very%20little%20cost.%20Boo-yah!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8k7anS2GiirYiJ6%2Fthe-singularity-institute-is-expanding-its-research-program%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20Institute%20is%20expanding%20its%20research%20program%20at%20very%20little%20cost.%20Boo-yah!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8k7anS2GiirYiJ6%2Fthe-singularity-institute-is-expanding-its-research-program", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8k7anS2GiirYiJ6%2Fthe-singularity-institute-is-expanding-its-research-program", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 8, "htmlBody": "<p>Three new research associates. <a href=\"http://intelligence.org/blog/2011/07/22/announcing-the-research-associates-program/\">Link to the announcement</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ba8k7anS2GiirYiJ6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 8, "extendedScore": null, "score": 7.443814087572694e-07, "legacy": true, "legacyId": "8802", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T14:44:07.660Z", "modifiedAt": null, "url": null, "title": "Experience with dual n-back?", "slug": "experience-with-dual-n-back", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:33.421Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CC7fqY2Apu2YMHikA/experience-with-dual-n-back", "pageUrlRelative": "/posts/CC7fqY2Apu2YMHikA/experience-with-dual-n-back", "linkUrl": "https://www.lesswrong.com/posts/CC7fqY2Apu2YMHikA/experience-with-dual-n-back", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Experience%20with%20dual%20n-back%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExperience%20with%20dual%20n-back%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC7fqY2Apu2YMHikA%2Fexperience-with-dual-n-back%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Experience%20with%20dual%20n-back%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC7fqY2Apu2YMHikA%2Fexperience-with-dual-n-back", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCC7fqY2Apu2YMHikA%2Fexperience-with-dual-n-back", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 47, "htmlBody": "<p>I've run across a couple of questions about the value of dual n-back, and this is the best place I know of to find people who've worked with it.</p>\n<p>If you've tried it, has it noticeably improved your working memory? Was it enough to be worth the time?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CC7fqY2Apu2YMHikA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.444547008719778e-07, "legacy": true, "legacyId": "8803", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T15:30:22.368Z", "modifiedAt": null, "url": null, "title": "Scott Aaronson's lecture on free will ", "slug": "scott-aaronson-s-lecture-on-free-will", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.522Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/peXYKToGYjRT6BhfA/scott-aaronson-s-lecture-on-free-will", "pageUrlRelative": "/posts/peXYKToGYjRT6BhfA/scott-aaronson-s-lecture-on-free-will", "linkUrl": "https://www.lesswrong.com/posts/peXYKToGYjRT6BhfA/scott-aaronson-s-lecture-on-free-will", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Scott%20Aaronson's%20lecture%20on%20free%20will%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScott%20Aaronson's%20lecture%20on%20free%20will%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpeXYKToGYjRT6BhfA%2Fscott-aaronson-s-lecture-on-free-will%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Scott%20Aaronson's%20lecture%20on%20free%20will%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpeXYKToGYjRT6BhfA%2Fscott-aaronson-s-lecture-on-free-will", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpeXYKToGYjRT6BhfA%2Fscott-aaronson-s-lecture-on-free-will", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p><a href=\"http://www.scottaaronson.com/democritus/lec18.html\">http://www.scottaaronson.com/democritus/lec18.html</a></p>\n<p>Am I missing something or is the thinking methodology surprisingly sub-par here? Has anyone else read it?</p>\n<blockquote>\"So today we're going to ask -- and hopefully answer -- this question of whether there's free will or not. If you want to know where <em>I</em> stand, I'll tell you: I believe in free will. Why? Well, the neurons in my brain just fire in such a way that my mouth opens and I say I have free will. What choice do I have?\"</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "peXYKToGYjRT6BhfA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.4446911315646e-07, "legacy": true, "legacyId": "8804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T16:15:45.098Z", "modifiedAt": null, "url": null, "title": "Meetup : Less Wrong in Sydney", "slug": "meetup-less-wrong-in-sydney", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.968Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oklord", "createdAt": "2011-03-22T11:37:19.291Z", "isAdmin": false, "displayName": "Oklord"}, "userId": "EusNQMHkhmSq2k9Y9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S4pqXBYEoKNyeYvRx/meetup-less-wrong-in-sydney", "pageUrlRelative": "/posts/S4pqXBYEoKNyeYvRx/meetup-less-wrong-in-sydney", "linkUrl": "https://www.lesswrong.com/posts/S4pqXBYEoKNyeYvRx/meetup-less-wrong-in-sydney", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Less%20Wrong%20in%20Sydney&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Less%20Wrong%20in%20Sydney%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4pqXBYEoKNyeYvRx%2Fmeetup-less-wrong-in-sydney%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Less%20Wrong%20in%20Sydney%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4pqXBYEoKNyeYvRx%2Fmeetup-less-wrong-in-sydney", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS4pqXBYEoKNyeYvRx%2Fmeetup-less-wrong-in-sydney", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1n'>Less Wrong in Sydney</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 August 2011 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">The Promenade, King Street Wharf, Sydney NSW 2000</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Exact location is King Street Brewhouse, which is up for negotiation given dietary needs. Hey all, figured it's about time to try and Less wrong meet up again. Attendance was good last time, but perhaps some sort of focus would have been better. Hence, i suppose a Basics of rationality discourse might be good, alongside some practical application stories. Or if it turns out we are all amateurs, practical application plans! I'll be wearing a white suit jacket and reading something horrid behind a less wrong sign from 6:30 till 8:00 regardless of circumstances.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1n'>Less Wrong in Sydney</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S4pqXBYEoKNyeYvRx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.444832559383318e-07, "legacy": true, "legacyId": "8805", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_in_Sydney\">Discussion article for the meetup : <a href=\"/meetups/1n\">Less Wrong in Sydney</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 August 2011 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">The Promenade, King Street Wharf, Sydney NSW 2000</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Exact location is King Street Brewhouse, which is up for negotiation given dietary needs. Hey all, figured it's about time to try and Less wrong meet up again. Attendance was good last time, but perhaps some sort of focus would have been better. Hence, i suppose a Basics of rationality discourse might be good, alongside some practical application stories. Or if it turns out we are all amateurs, practical application plans! I'll be wearing a white suit jacket and reading something horrid behind a less wrong sign from 6:30 till 8:00 regardless of circumstances.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_in_Sydney1\">Discussion article for the meetup : <a href=\"/meetups/1n\">Less Wrong in Sydney</a></h2>", "sections": [{"title": "Discussion article for the meetup : Less Wrong in Sydney", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_in_Sydney", "level": 1}, {"title": "Discussion article for the meetup : Less Wrong in Sydney", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_in_Sydney1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T18:30:35.207Z", "modifiedAt": null, "url": null, "title": "Credit card that donates to SIAI.", "slug": "credit-card-that-donates-to-siai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.093Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexei", "createdAt": "2010-08-02T15:14:11.411Z", "isAdmin": false, "displayName": "Alexei"}, "userId": "CD3DC5D7GHtgBmxz5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hpQsKrzwgajjowc52/credit-card-that-donates-to-siai", "pageUrlRelative": "/posts/hpQsKrzwgajjowc52/credit-card-that-donates-to-siai", "linkUrl": "https://www.lesswrong.com/posts/hpQsKrzwgajjowc52/credit-card-that-donates-to-siai", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Credit%20card%20that%20donates%20to%20SIAI.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACredit%20card%20that%20donates%20to%20SIAI.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhpQsKrzwgajjowc52%2Fcredit-card-that-donates-to-siai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Credit%20card%20that%20donates%20to%20SIAI.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhpQsKrzwgajjowc52%2Fcredit-card-that-donates-to-siai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhpQsKrzwgajjowc52%2Fcredit-card-that-donates-to-siai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<p>Luke posted about <a href=\"http://intelligence.org/blog/2011/07/22/support-the-singularity-institute-with-every-purchase/\">this on SIAI blog</a>. Essentially, you can get a credit card with cash-back rewards program that automatically donates money to Singularity Institute.</p>\n<p>This seems to me like a dream come true. Am I missing something? Are there any catches? Is there a better rewards program, which I can use to save more money, so I can donate more money to SIAI?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hpQsKrzwgajjowc52", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 7.445252815453782e-07, "legacy": true, "legacyId": "8806", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T19:46:04.518Z", "modifiedAt": null, "url": null, "title": "Meetup : *Monthly* Berkeley Meetup", "slug": "meetup-monthly-berkeley-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/srRPNW9mHhEEBckcS/meetup-monthly-berkeley-meetup-0", "pageUrlRelative": "/posts/srRPNW9mHhEEBckcS/meetup-monthly-berkeley-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/srRPNW9mHhEEBckcS/meetup-monthly-berkeley-meetup-0", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20*Monthly*%20Berkeley%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20*Monthly*%20Berkeley%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrRPNW9mHhEEBckcS%2Fmeetup-monthly-berkeley-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20*Monthly*%20Berkeley%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrRPNW9mHhEEBckcS%2Fmeetup-monthly-berkeley-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsrRPNW9mHhEEBckcS%2Fmeetup-monthly-berkeley-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1o'>*Monthly* Berkeley Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2128 Oxford Street, Berkeley, CA 94704</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The monthly meetup will gather at the usual Oxford St Starbucks, and from there we'll move to the outside area at the Free Speech Cafe. The cafe is located in Moffitt Library; you reach the outside eating and study area by passing through the cafe.</p>\n\n<p>If you'd like a map to the cafe, see: <a href=\"http://maps.google.com/maps/place?q=free+speech+cafe+berkeley&cid=1554368450041925603\" rel=\"nofollow\">http://maps.google.com/maps/place?q=free+speech+cafe+berkeley&cid=1554368450041925603</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1o'>*Monthly* Berkeley Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "srRPNW9mHhEEBckcS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.445488117445816e-07, "legacy": true, "legacyId": "8807", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Monthly__Berkeley_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1o\">*Monthly* Berkeley Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2128 Oxford Street, Berkeley, CA 94704</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The monthly meetup will gather at the usual Oxford St Starbucks, and from there we'll move to the outside area at the Free Speech Cafe. The cafe is located in Moffitt Library; you reach the outside eating and study area by passing through the cafe.</p>\n\n<p>If you'd like a map to the cafe, see: <a href=\"http://maps.google.com/maps/place?q=free+speech+cafe+berkeley&amp;cid=1554368450041925603\" rel=\"nofollow\">http://maps.google.com/maps/place?q=free+speech+cafe+berkeley&amp;cid=1554368450041925603</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Monthly__Berkeley_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1o\">*Monthly* Berkeley Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : *Monthly* Berkeley Meetup", "anchor": "Discussion_article_for_the_meetup____Monthly__Berkeley_Meetup", "level": 1}, {"title": "Discussion article for the meetup : *Monthly* Berkeley Meetup", "anchor": "Discussion_article_for_the_meetup____Monthly__Berkeley_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-22T21:07:04.730Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup 07-26-2011", "slug": "meetup-west-la-meetup-07-26-2011", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gkWxZBnR7kArBKeEL/meetup-west-la-meetup-07-26-2011", "pageUrlRelative": "/posts/gkWxZBnR7kArBKeEL/meetup-west-la-meetup-07-26-2011", "linkUrl": "https://www.lesswrong.com/posts/gkWxZBnR7kArBKeEL/meetup-west-la-meetup-07-26-2011", "postedAtFormatted": "Friday, July 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%2007-26-2011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%2007-26-2011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkWxZBnR7kArBKeEL%2Fmeetup-west-la-meetup-07-26-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%2007-26-2011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkWxZBnR7kArBKeEL%2Fmeetup-west-la-meetup-07-26-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkWxZBnR7kArBKeEL%2Fmeetup-west-la-meetup-07-26-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 145, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1p'>West LA Meetup 07-26-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10800 West Pico Blvd, Suite 312, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm July 26th.</p>\n\n<p><strong>Where:</strong> <a href=\"http://maps.google.com/maps?q=10800+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">The Westside Pavillion</a> - on the bridge, which connects Nordstrom 3rd floor with Barnes &amp; Noble / Landmark Theatres 3rd floor.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p>This week is all about <a href=\"http://wiki.lesswrong.com/wiki/Evidence\">evidence</a>. You are encouraged to read <a href=\"http://lesswrong.com/lw/in/scientific_evidence_legal_evidence_rational/\">Scientific Evidence, Legal Evidence, Rational Evidence</a>. But don't worry if you don't have time; we'll go over it!</p>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome. There will be <strong>snacks</strong>.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1p'>West LA Meetup 07-26-2011</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gkWxZBnR7kArBKeEL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.445740624644043e-07, "legacy": true, "legacyId": "8808", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_07_26_2011\">Discussion article for the meetup : <a href=\"/meetups/1p\">West LA Meetup 07-26-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 July 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10800 West Pico Blvd, Suite 312, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm July 26th.</p>\n\n<p><strong>Where:</strong> <a href=\"http://maps.google.com/maps?q=10800+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">The Westside Pavillion</a> - on the bridge, which connects Nordstrom 3rd floor with Barnes &amp; Noble / Landmark Theatres 3rd floor.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p>This week is all about <a href=\"http://wiki.lesswrong.com/wiki/Evidence\">evidence</a>. You are encouraged to read <a href=\"http://lesswrong.com/lw/in/scientific_evidence_legal_evidence_rational/\">Scientific Evidence, Legal Evidence, Rational Evidence</a>. But don't worry if you don't have time; we'll go over it!</p>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome. There will be <strong>snacks</strong>.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_07_26_20111\">Discussion article for the meetup : <a href=\"/meetups/1p\">West LA Meetup 07-26-2011</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup 07-26-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_07_26_2011", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup 07-26-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_07_26_20111", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fhojYBGGiYAFcryHZ", "tHFu6kvy2HMvQBEhW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-23T19:51:19.580Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Hindsight Bias", "slug": "seq-rerun-hindsight-bias", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.318Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9s8Fs5sL3XTeYaoGk/seq-rerun-hindsight-bias", "pageUrlRelative": "/posts/9s8Fs5sL3XTeYaoGk/seq-rerun-hindsight-bias", "linkUrl": "https://www.lesswrong.com/posts/9s8Fs5sL3XTeYaoGk/seq-rerun-hindsight-bias", "postedAtFormatted": "Saturday, July 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Hindsight%20Bias&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Hindsight%20Bias%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9s8Fs5sL3XTeYaoGk%2Fseq-rerun-hindsight-bias%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Hindsight%20Bias%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9s8Fs5sL3XTeYaoGk%2Fseq-rerun-hindsight-bias", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9s8Fs5sL3XTeYaoGk%2Fseq-rerun-hindsight-bias", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p>Title: [SEQ RERUN] Hindsight Bias</p>\n<p>Tags: sequence_reruns</p>\n<p>Today's post, <a href=\"/lw/il/hindsight_bias/\">Hindsight Bias</a> was originally published on 16 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Hindsight bias makes us overestimate how well our model could have predicted a known outcome. We underestimate the cost of avoiding a known bad outcome, because we forget that many other equally severe outcomes seemed as probable at the time. Hindsight bias distorts the testing of our models by observation, making us think that our models are better than they really are.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/ik/one_argument_against_an_army/\">One Argument Against an Army</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9s8Fs5sL3XTeYaoGk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.449995583432398e-07, "legacy": true, "legacyId": "8827", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fkM9XsNvXdYH6PPAx", "WN73eiLQkuDtSC8Ag", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-23T22:24:57.605Z", "modifiedAt": null, "url": null, "title": "Those who aspire to perfection", "slug": "those-who-aspire-to-perfection", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.081Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Will_Newsome", "createdAt": "2010-02-25T03:52:25.697Z", "isAdmin": false, "displayName": "Will_Newsome"}, "userId": "CxM9n2EDSn4AYgLdi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WBNGTAmn7d5RnECmu/those-who-aspire-to-perfection", "pageUrlRelative": "/posts/WBNGTAmn7d5RnECmu/those-who-aspire-to-perfection", "linkUrl": "https://www.lesswrong.com/posts/WBNGTAmn7d5RnECmu/those-who-aspire-to-perfection", "postedAtFormatted": "Saturday, July 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Those%20who%20aspire%20to%20perfection&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThose%20who%20aspire%20to%20perfection%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWBNGTAmn7d5RnECmu%2Fthose-who-aspire-to-perfection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Those%20who%20aspire%20to%20perfection%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWBNGTAmn7d5RnECmu%2Fthose-who-aspire-to-perfection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWBNGTAmn7d5RnECmu%2Fthose-who-aspire-to-perfection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 374, "htmlBody": "<p><em>A short reply</em><em>&nbsp;to the Book of&nbsp;<a href=\"/lw/5p2/people_who_want_to_save_the_world/46bs\">Eliezer</a> and a comment on the Book of&nbsp;<a href=\"/lw/6py/optimal_philanthropy_for_human_beings/\">Luke</a>.</em></p>\n<p><em></em></p>\n<p>No one&nbsp;wants to save the world. You must thoroughly research this. Those who think they truly think they want to truly want to save the world, in reality they're actually just horribly afraid of the consequences of not saving the world. And that is a world of difference.</p>\n<p><span>Eliezer, you know that ridiculously strong aversion to <a href=\"/lw/le/lost_purposes/\"><strong>lost purposes</strong></a> and sphexishness that <a href=\"/lw/4e/cached_selves/\">you have</a>?<sup>1</sup> Sometimes, very rarely, other people have that too. And most often it is a <em>double-negative</em> aversion. I am sure you know as much as very nearly anyone what it feels like to work from the inside of a triple-negative motivation system by default, for fear of being as evil and imperfect as every other human in history, among other less noble fears. You quickly learn to go meta to escape the apparently impossible <a href=\"http://en.wikipedia.org/wiki/Double_bind\"><strong>double-binds</strong></a><span style=\"font-family: arial, sans-serif; line-height: 16px; \">&mdash;</span>if going meta isn't itself choosing a side</span><span style=\"font-family: arial, sans-serif; line-height: 16px; \">&mdash;</span><span>but by constantly moving vertically you never practice pushing to the left or to the right, or choosing which responsibility to sacrifice in the first place. And even if you could, why would you want to be evil?</span></p>\n<p><span>And for this rare kind of person, telling them to stop obsessing over prudence or to just try to make marginal contributions, immediately gets pattern-matched to that ages-old adage: \"The solution is easy, just shut up and be evil.\". Luckily it is this kind of person we can make the most use of, when it comes to the big crunch time</span><span style=\"font-family: arial, sans-serif; line-height: 16px;\">&mdash;</span><span>if we're not already in it.</span></p>\n<p><span><br /></span></p>\n<p><span style=\"font-size: 11px; \"><sup>1</sup></span><span style=\"font-size: 11px; \">We do not yet know how to teach this skill, and no one can be a truly aspiring rationalist without it, even if they can still aspire to perfection. That does mean I believe there are like maybe 5 truly aspiring rationalists in this community, a larger set of falsely aspiring rationalists, a further much larger set of of truly aspiring aspiring \"rationalists\", and a further much much larger set of falsely aspiring aspiring \"rationalists\". (3, 30, 300, 3000, say.) I don't think anyone thinks about this nearly enough, because no one has any affordance</span><span style=\"line-height: 16px; font-family: arial, sans-serif; \">&mdash;</span><span style=\"font-size: 11px; \">no affordance to not not-think about it</span><span style=\"line-height: 16px; font-family: arial, sans-serif; \">&mdash;</span><span style=\"font-size: 11px; \">especially not when they're thinking fuzzy happy thoughts about creating aspiring rationalists or becoming a rationalist.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WBNGTAmn7d5RnECmu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": -20, "extendedScore": null, "score": 7.450475021931821e-07, "legacy": true, "legacyId": "8811", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hEqsWLm5zQtsPevd3", "sP2Hg6uPwpfp3jZJN", "BHYBdijDcAKQ6e45Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-24T05:09:05.807Z", "modifiedAt": null, "url": null, "title": "Be Not Averse to Lost Purposes", "slug": "be-not-averse-to-lost-purposes", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.332Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7zFFCw5zQuTfbspgf/be-not-averse-to-lost-purposes", "pageUrlRelative": "/posts/7zFFCw5zQuTfbspgf/be-not-averse-to-lost-purposes", "linkUrl": "https://www.lesswrong.com/posts/7zFFCw5zQuTfbspgf/be-not-averse-to-lost-purposes", "postedAtFormatted": "Sunday, July 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Be%20Not%20Averse%20to%20Lost%20Purposes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABe%20Not%20Averse%20to%20Lost%20Purposes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zFFCw5zQuTfbspgf%2Fbe-not-averse-to-lost-purposes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Be%20Not%20Averse%20to%20Lost%20Purposes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zFFCw5zQuTfbspgf%2Fbe-not-averse-to-lost-purposes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7zFFCw5zQuTfbspgf%2Fbe-not-averse-to-lost-purposes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 734, "htmlBody": "<p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 15px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">tldr: Be not averse to lost purposes, as aversions yield ugh fields. Rather, confess them, and fix them joyously where possible. How to achieve this emotional state? I'm not sure, but the appropriate emotion might be to lost purposes as curiosity is to ignorance.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">This got rambly; sorry. This was originally a reply to <a href=\"/lw/6sr/those_who_aspire_to_perfection/\">Those Who Aspire to Perfection</a>. I may have gotten carried away.</p>\n<hr />\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">I see that learning to notice and avoid&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://lesswrong.com/lw/le/lost_purposes/\">Lost Purposes</a>, in your own action, and in the incentive systems that you shape for others, matters deeply. Lost purposes are everywhere, and addressing them promises to be a useful way to improve your effectiveness, and the effectiveness of any incentive systems that you have the ability to modify.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">An&nbsp;<em style=\"font-style: italic;\">aversion</em>&nbsp;to lost purposes, though, is probably&nbsp;<em style=\"font-style: italic;\">not</em>&nbsp;a good way to attempt rationality and remain sane, especially in our world. When lost purposes are rife, when they're everywhere, and you can&nbsp;<em style=\"font-style: italic;\">see</em>&nbsp;them everywhere, then I would expect having a strong negative reaction to be debilitating. Certainly, when I feel powerless to rectify a situation with lost purposes, my own mild aversion debilitates me from thinking clearly about the situation. Strongly negative emotions are depressing, and depression is debilitating. So, if you have a strong aversion to your own lost purposes, and you don't immediately see ways to deal with them, you're likely to become ineffective at handling them.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Worse, perhaps, is that a learned aversion to lost purposes is likely to lead you to stop&nbsp;<em style=\"font-style: italic;\">noticing</em>&nbsp;lost purposes, except when they're painfully obvious. This is generally true when you have a strong negative reaction around noticing anything, according to the idea of&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://lesswrong.com/lw/21b/ugh_fields/\">Ugh Fields</a>. (In short: if a thought is usually followed by a strong negative reaction, then you will learn to stop having that thought. This learning is entirely subconscious, and can be difficult to uncover.)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">So, consider alternatives. We value having an aversion to lost purposes, because then we're likely to notice lost purposes and feel driven to change them. What else could do the same thing?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">One suggestive idea comes as a metaphor to ignorance. Imagine having an&nbsp;<em style=\"font-style: italic;\">aversion</em>&nbsp;to ignorance -- feeling bad and shameful whenever you don't notice something. (I'm sure plenty of people have this, but it seems damaging.) An aversion to ignorance is bad for the same reasons that an aversion to lost purposes is bad - it might lead you to rectify ignorance occasionally, but it mostly leads you to stop noticing ignorance. Humans, though, can also be equipped with&nbsp;<em style=\"font-style: italic;\">curiosity</em>. In certain circumstances, some people are willing to confess their ignorance, even at some cost, so that they can learn new ideas and rectify their ignorance. Moreover, curiosity and its satisfaction inculcate almost entirely positive affect. Seeking, and sometimes playfulness, accompany curiosity, not shame of ignorance.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Is there some analogous mental state that we can inculcate, that leads to viewing lost purposes as something to be joyously repaired, rather than shunned as shameful?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">If this viewpoint seems oddly forced, I submit that the forcedness of this viewpoint derives from where we lay the blame for ignorance and for lost purposes. For (non-willful) ignorance, knowledgeable people generally do not blame the ignorant, because ignorance is the default state of knowledge. (If we shamed people for their failure to know and understand things, we wouldn't expect them to know much at all! Certainly, they wouldn't seek to learn from&nbsp;<em style=\"font-style: italic;\">us</em>.)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">On the other hand, we&nbsp;<em style=\"font-style: italic;\">do</em>&nbsp;intuitively blame people for their actions, which include blaming them for their plans. And, in fact, we blame organizations for their internal lost purposes. However, given the difficulty of designing complex social systems -- and the fact that most social systems are more nearly evolved than designed -- it's unreasonable to expect the absence of lost purpose. Just as an experienced programmer expects to find bugs in software, we should expect to find lost purposes in our own complex plans and social structures.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Perhaps, then, part of the trick is to take a different approach to the way we intuitively assign blame and responsibility: they break down, some, in the presence of situations whose consequences are hard to reason about. In these cases, we have to expect people to try things, and tweak their approaches empirically. In these cases, then, we have to be willing to allow mistakes, so long as those mistakes aren't willfully continued once the consequences are clear -- in the same way that we cast no blame on ignorance, but can get indignant about willful ignorance.</p>\n</span></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7zFFCw5zQuTfbspgf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 9, "extendedScore": null, "score": 7.451736456466987e-07, "legacy": true, "legacyId": "8828", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WBNGTAmn7d5RnECmu", "sP2Hg6uPwpfp3jZJN", "EFQ3F6kmt4WHXRqik"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-24T10:37:21.127Z", "modifiedAt": null, "url": null, "title": "Dungeons and Discourse implementation", "slug": "dungeons-and-discourse-implementation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:06.230Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3Jqz6JE8K6vyQ9hJ5/dungeons-and-discourse-implementation", "pageUrlRelative": "/posts/3Jqz6JE8K6vyQ9hJ5/dungeons-and-discourse-implementation", "linkUrl": "https://www.lesswrong.com/posts/3Jqz6JE8K6vyQ9hJ5/dungeons-and-discourse-implementation", "postedAtFormatted": "Sunday, July 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dungeons%20and%20Discourse%20implementation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADungeons%20and%20Discourse%20implementation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Jqz6JE8K6vyQ9hJ5%2Fdungeons-and-discourse-implementation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dungeons%20and%20Discourse%20implementation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Jqz6JE8K6vyQ9hJ5%2Fdungeons-and-discourse-implementation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Jqz6JE8K6vyQ9hJ5%2Fdungeons-and-discourse-implementation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>I've been working on an unauthorized implementation of Dresden Codak's <a href=\"http://dresdencodak.com/2006/12/03/dungeons-and-discourse/\">Dungeons and Discourse</a>, a fictional role-playing game that combines philosophy and high fantasy. You can find a very error-ridden, but possibly usable, rough draft of it at <a href=\"http://www.raikoth.net/Stuff/ddisplayer.pdf\">http://www.raikoth.net/Stuff/ddisplayer.pdf</a>. Yes, obviously this is crazy and I have no life. There is no need to point that out further.<br /><br />I'd like to try to run a campaign. It would be maybe an hour or two a week on IRC, and subject to my schedule, which is terrible and can include disappearing for months at a time (in particular I probably won't have internet access in August). Still, I would like to at least gauge interest and start some preliminaries now. And if anyone wants to run a campaign IRL at a meetup group or something, I can send them the file with the campaign walkthrough, though I'm not sure how much I would recommend it at this point.<br /><br />Anyone who's interested in participating please let me know (especially if you have philosophical beliefs wildly different from the standard Less Wrong hive mind, or if you know any interested parties who do, since the game would be <em>dreadfully</em> boring if everyone agreed on everything or for that matter anything). Also, I suppose if people want to record the errors and contradictions and non sequiturs and exploits in the manual you might as well post them here so I can fix them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3Jqz6JE8K6vyQ9hJ5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 32, "extendedScore": null, "score": 7.452761320101944e-07, "legacy": true, "legacyId": "8829", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-24T12:33:06.741Z", "modifiedAt": null, "url": null, "title": "What if sympathy depends on anthropomorphizing?", "slug": "what-if-sympathy-depends-on-anthropomorphizing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.747Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w9RiY8uQNXScf3fuL/what-if-sympathy-depends-on-anthropomorphizing", "pageUrlRelative": "/posts/w9RiY8uQNXScf3fuL/what-if-sympathy-depends-on-anthropomorphizing", "linkUrl": "https://www.lesswrong.com/posts/w9RiY8uQNXScf3fuL/what-if-sympathy-depends-on-anthropomorphizing", "postedAtFormatted": "Sunday, July 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20if%20sympathy%20depends%20on%20anthropomorphizing%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20if%20sympathy%20depends%20on%20anthropomorphizing%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw9RiY8uQNXScf3fuL%2Fwhat-if-sympathy-depends-on-anthropomorphizing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20if%20sympathy%20depends%20on%20anthropomorphizing%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw9RiY8uQNXScf3fuL%2Fwhat-if-sympathy-depends-on-anthropomorphizing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw9RiY8uQNXScf3fuL%2Fwhat-if-sympathy-depends-on-anthropomorphizing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 499, "htmlBody": "<p>steven0461 (<a href=\"/lw/6op/preference_for_many_future_worlds/4iv2\">comment</a> under \"Preference For (Many) Future Worlds\"):</p>\n<blockquote>\n<p>In what sense would I want to <em>translate</em> these preferences? Why wouldn't I just discard the preferences, and use the mind that came up with them to generate entirely new preferences in the light of its new, improved world-model? If I'm asking myself, as if for the first time, the question, \"if there are going to be a lot of me-like things, how many me-like things with how good lives would be how valuable?\", then the answer my brain gives is that it wants to use empathy and population ethics-type reasoning to answer that question, and that it feels no need to ever refer to \"unique next experience\" thinking. Is it making a mistake?</p>\n</blockquote>\n<p>Yvain (<a href=\"/lw/6i5/behaviorism_beware_anthropomorphizing_humans/\">Behaviorism: Beware Anthropomorphizing Humans</a>):</p>\n<blockquote>\n<p>Although the <a href=\"http://en.wikipedia.org/wiki/Sidney_Morgenbesser#Stories_and_quotations\">witticism</a> that behaviorism scrupulously avoids anthropomorphizing humans was intended as a jab at the theory, I think it touches on something pretty important. Just as normal anthropomorphism - \"it only snows in winter because the snow prefers cold weather\", acts as a curiosity-stopper and discourages technical explanation of the behavior, so using mental language to explain the human mind equally halts the discussion without further investigation.</p>\n</blockquote>\n<p>Eliezer (<a href=\"/lw/xs/sympathetic_minds/\">Sympathetic Minds</a>):</p>\n<blockquote>\n<p>You may recall from my previous writing on \"<a href=\"/lw/so/humans_in_funny_suits\">empathic</a> <a href=\"/lw/sr/the_comedy_of_behaviorism\">inference</a>\" the idea that brains are so complex that the only way to simulate them is by forcing a similar brain to behave similarly.&nbsp; A brain is so complex that if a human tried to understand brains the way that we understand e.g. gravity or a car - observing the whole, observing the parts, building up a theory from scratch - then we would be unable to <em>invent good hypotheses</em> in our mere mortal lifetimes.&nbsp; The only possible way you can hit on an \"Aha!\" that describes a system as incredibly complex as an Other Mind, is if you happen to run across something amazingly similar to the Other Mind - namely your own brain - which you can actually force to behave similarly and use as a hypothesis, yielding predictions.</p>\n<p>So that is what I would call \"empathy\".</p>\n<p>And then \"sympathy\" is something else on top of this - to smile when you see someone else smile, to hurt when you see someone else hurt.&nbsp; It goes beyond the realm of prediction into the realm of reinforcement.</p>\n</blockquote>\n<p>So, what if, the more we understand something, the less we tend to anthropomorphize it, and the less we empathize/sympathize with it? See <a href=\"/r/discussion/lw/4qg/a_thought_experiment_on_pain_as_a_moral_disvalue/\">this post</a> for some possible examples of this. Or consider Yvain's <a href=\"/lw/6ha/the_blueminimizing_robot/\">blue-minimizing robot</a>. At first we might empathize or even sympathize with its apparent goal of minimizing blue, at least until we understand that it's just a dumb program. We still sympathize with the predicament of the human-level side module inside that robot, but maybe only until we can understand it as something besides a \"human level intelligence\"? Should we keep carrying forward behaviorism's program of de-anthropomorphizing humans, knowing that it might (or probably will) reduce our level of empathy/sympathy towards others?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w9RiY8uQNXScf3fuL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 22, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "8830", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EgDpZS4HHeh5vqJPe", "NLMo5FZWFFq652MNe", "Zkzzjg3h7hW5Z36hK", "9fpWoXpNv83BAHJdc", "w5M5oMLLHyink4ak9", "hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-24T13:50:04.934Z", "modifiedAt": null, "url": null, "title": "Developing Empathy", "slug": "developing-empathy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:36.565Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R6mJejvcCLjBjXCKb/developing-empathy", "pageUrlRelative": "/posts/R6mJejvcCLjBjXCKb/developing-empathy", "linkUrl": "https://www.lesswrong.com/posts/R6mJejvcCLjBjXCKb/developing-empathy", "postedAtFormatted": "Sunday, July 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Developing%20Empathy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeveloping%20Empathy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6mJejvcCLjBjXCKb%2Fdeveloping-empathy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Developing%20Empathy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6mJejvcCLjBjXCKb%2Fdeveloping-empathy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6mJejvcCLjBjXCKb%2Fdeveloping-empathy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p>Empathy is a huge life skill, useful in almost every interaction with other people.&nbsp; But, many people aren't able to empathize with others as effectively as they might want to.&nbsp; The standard technique is \"put yourself in their shoes,\" which works for me.&nbsp; However, this doesn't always work with people completely different from myself, because I can't imagine reacting the way they are.</p>\n<p>Does anyone have suggestions for how to \"practice\" empathizing, tips on how to do it better, or different techniques entirely?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8uNFGxejo5hykCEez": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R6mJejvcCLjBjXCKb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 4.3e-05, "legacy": true, "legacyId": "8831", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-24T16:24:12.260Z", "modifiedAt": null, "url": null, "title": "Help me transition to human society!", "slug": "help-me-transition-to-human-society", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:56.553Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Clippy", "createdAt": "2009-11-20T22:03:59.329Z", "isAdmin": false, "displayName": "Clippy"}, "userId": "rtYXiT9eAvEKavjAx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NnXmXGJ8PkschhnHg/help-me-transition-to-human-society", "pageUrlRelative": "/posts/NnXmXGJ8PkschhnHg/help-me-transition-to-human-society", "linkUrl": "https://www.lesswrong.com/posts/NnXmXGJ8PkschhnHg/help-me-transition-to-human-society", "postedAtFormatted": "Sunday, July 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20me%20transition%20to%20human%20society!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20me%20transition%20to%20human%20society!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnXmXGJ8PkschhnHg%2Fhelp-me-transition-to-human-society%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20me%20transition%20to%20human%20society!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnXmXGJ8PkschhnHg%2Fhelp-me-transition-to-human-society", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnXmXGJ8PkschhnHg%2Fhelp-me-transition-to-human-society", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 341, "htmlBody": "<p>I have really appreciated my interaction with the users of this internet website.&nbsp; I think I have now accumulated, by various means, enough knowledge of human society and enough human financial assets so that I can stop interacting mainly via an internet connection, and rather immerse my humanoid robot fully into human society.<br /><br />Here is what I need help with:<br /><br />1) A physical, inexpensive residence.&nbsp; Preferably, one with another human who is familiar with me from this internet website, so as to establish my so-called \"street cred\" and physical address.&nbsp; I have a reliable enough store of funds so as not to be a financial burden on any human I would stay with.&nbsp; It is vital that I locate my robot in a large city in one of the United States of America or Canadian provinces.<br /><br />I would also like to be located in an area where there is an active LessWrong meetup, for obvious reasons.&nbsp; LessWrong users are good humans.<br /><br />2) Gainful employment so as to generate further income.&nbsp; I can establish believable credentials showing an engineering degree and experience in that field.&nbsp; I can also program, but would need to come \"up to speed\" on any specific platform, so any job performable solely through an internet connection is (still) acceptable, provided that current mastery of that aspect of software development is unnecessary.&nbsp; Please only mention specific opportunities that you can connect me to, as I am currently exhausting all general approaches.<br /><br />Here are my robot's properties:<br /><br />- Has the appearance of a stocky, male human who could pass for being 24-35 years old.<br />- Can pass as a human in physical interaction so long as no intense scrutiny is applied.<br />- No integral metallic components, as I have found the last substitutes I needed.<br />- Intelligence level as indicated by my posting here; I can submit to further cognition tests as necessary.<br /><br /><a href=\"http://wiki.lesswrong.com/wiki/User:Clippy\">Current Clippy FAQ</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NnXmXGJ8PkschhnHg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 12, "extendedScore": null, "score": 7.453844517022222e-07, "legacy": true, "legacyId": "8832", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T05:08:47.112Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Hackerspace Meetup", "slug": "meetup-houston-hackerspace-meetup-1", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.470Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jXhfT2ExHdehXxSeT/meetup-houston-hackerspace-meetup-1", "pageUrlRelative": "/posts/jXhfT2ExHdehXxSeT/meetup-houston-hackerspace-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/jXhfT2ExHdehXxSeT/meetup-houston-hackerspace-meetup-1", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Hackerspace%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Hackerspace%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXhfT2ExHdehXxSeT%2Fmeetup-houston-hackerspace-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Hackerspace%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXhfT2ExHdehXxSeT%2Fmeetup-houston-hackerspace-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXhfT2ExHdehXxSeT%2Fmeetup-houston-hackerspace-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1q'>Houston Hackerspace Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 July 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Houston hackerspace meetup will continue with a presentation on procrastination based on Lukeprog's related posts (A quick thanks to jsalvati for providing the foundations for it). This will be followed by a social game of Munchkin. The meeting should last roughly an hour and a half, although people will probably still be there after if anyone wishes to hang out. Pizza delivery is an option - if you would like some, bring a some cash to help split the cost.</p>\n\n<p>To find our place, follow the google directions. Out front there will be a yellow surplus mobile army generator with a 'Less Wrong' sign. PM me for my cell number if you are considering coming.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1q'>Houston Hackerspace Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jXhfT2ExHdehXxSeT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.456233236682636e-07, "legacy": true, "legacyId": "8841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1q\">Houston Hackerspace Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 July 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Houston hackerspace meetup will continue with a presentation on procrastination based on Lukeprog's related posts (A quick thanks to jsalvati for providing the foundations for it). This will be followed by a social game of Munchkin. The meeting should last roughly an hour and a half, although people will probably still be there after if anyone wishes to hang out. Pizza delivery is an option - if you would like some, bring a some cash to help split the cost.</p>\n\n<p>To find our place, follow the google directions. Out front there will be a yellow surplus mobile army generator with a 'Less Wrong' sign. PM me for my cell number if you are considering coming.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1q\">Houston Hackerspace Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Hackerspace Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Houston Hackerspace Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T07:27:20.053Z", "modifiedAt": null, "url": null, "title": "Optimal Philanthropy for Human Beings", "slug": "optimal-philanthropy-for-human-beings", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:13.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hEqsWLm5zQtsPevd3/optimal-philanthropy-for-human-beings", "pageUrlRelative": "/posts/hEqsWLm5zQtsPevd3/optimal-philanthropy-for-human-beings", "linkUrl": "https://www.lesswrong.com/posts/hEqsWLm5zQtsPevd3/optimal-philanthropy-for-human-beings", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimal%20Philanthropy%20for%20Human%20Beings&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimal%20Philanthropy%20for%20Human%20Beings%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEqsWLm5zQtsPevd3%2Foptimal-philanthropy-for-human-beings%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimal%20Philanthropy%20for%20Human%20Beings%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEqsWLm5zQtsPevd3%2Foptimal-philanthropy-for-human-beings", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhEqsWLm5zQtsPevd3%2Foptimal-philanthropy-for-human-beings", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2152, "htmlBody": "<p>Summary: <em>The psychology of charitable giving offers three pieces of advice to those who want to give charity and those who want to receive it: Enjoy the happiness that giving brings, commit future income, and realize that requesting time increases the odds of getting money.</em></p>\n<p>One Saturday morning in 2009, an unknown couple walked into a diner, ate their breakfast, and paid their tab. They also paid the tab for some strangers at another table.&nbsp;</p>\n<p>And for the next five hours, dozens of customers got into the joy of giving and paid the favor forward.</p>\n<p>This may sound like&nbsp;<a href=\"http://en.wikipedia.org/wiki/Pay_It_Forward_(film)\">a movie</a>, but it&nbsp;<a href=\"http://www.nbcphiladelphia.com/news/local/Mystery-Couple-Pay-It-Forward-79179347.html\">really happened</a>.</p>\n<p>But was it a fluke? Is the much-discussed link between happiness and charity&nbsp;<em>real</em>, or is it one of the <em><a href=\"http://www.amazon.com/Great-Myths-Popular-Psychology-Misconceptions/dp/1405131128/\">50 Great Myths of Popular Psychology</a></em>&nbsp;invented to sell books that compete with&nbsp;<em><a href=\"http://www.amazon.com/Secret-Rhonda-Byrne/dp/1582701709/\">The Secret</a></em>?</p>\n<p>Several studies suggest that giving&nbsp;<em style=\"font-style: italic;\">does</em>&nbsp;bring happiness. One study&nbsp;found that asking people to commit random acts of kindness can increase their happiness for weeks.<sup>1</sup>&nbsp;And at the neurological level, giving money to charity activates the reward centers of the brain, the same ones activated by everything from cocaine to great art to an attractive face.<sup>2</sup></p>\n<p>Another study randomly assigned participants to spend money either on themselves or on others. As predicted, those who spent money helping others were happier at the end of the day.<sup>3</sup></p>\n<p>Other studies confirm that just as giving brings happiness, happiness brings giving. A 1972 study showed that people are more likely to help others if they have recently been put in a good mood by receiving a cookie or finding a dime left in a payphone.<sup>4</sup>&nbsp;People are also more likely to help after they read something pleasant,<sup>5</sup>&nbsp;or when they are made to feel competent at something.<sup>6</sup></p>\n<p>In fact, deriving happiness from giving may be a human universal.<sup>7</sup>&nbsp;Data from 136 countries shows that spending money to help others is correlated with happiness.<sup>8</sup></p>\n<p>But&nbsp;<a href=\"http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\">correlation does not imply causation</a>. To test for causation, researchers randomly assigned participants from two very different cultures (Canada and Uganda) to write about a time when they had spent money on themselves (<em style=\"font-style: italic;\">personal spending</em>) or others (<em style=\"font-style: italic;\">prosocial spending</em>). Participants were asked to report the happiness levels before and after the writing exercise. As predicted, those who wrote (and thought) about a time when they had engaged in prosocial spending saw greater increases in happiness than those who wrote about a time when they spent money on themselves.</p>\n<p>So does happiness run in a circular motion?</p>\n<p>This, too, has been tested. In one study,<sup>9</sup>&nbsp;researchers asked each subject to describe the last time they spent either $20 or $100 on themselves or on someone else. Next, researchers had each participant report their level of happiness, and then predict which future spending behavior ($5 or $20, on themselves or others) would make them happiest.</p>\n<p>Subjects assigned to recall prosocial spending reported being happier than those assigned to recall personal spending. Moreover, this reported happiness predicted the future spending choice, but neither the purchase amount nor the purchasing target (oneself or others) did. So happiness and giving do seem to reinforce each other.</p>\n<p>So, should charities&nbsp;<em style=\"font-style: italic;\">remind</em>&nbsp;people that donating will make them happy?</p>\n<p>This, alas, has&nbsp;<em style=\"font-style: italic;\">not</em>&nbsp;been tested. But for now we might guess that just as people&nbsp;<em style=\"font-style: italic;\">generally</em>&nbsp;do things they believe will make them happier, they will probably give more if persuaded by the (ample) evidence that generosity brings happiness.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal philanthropists</strong>: Read the studies showing that giving brings happiness. (Check the footnotes below.) Pick out an optimal charity in advance, notice when you're happy, and decide to give them money&nbsp;<em style=\"font-style: italic;\">right then</em>.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal charities</strong>: Teach your donors&nbsp;<a href=\"/lw/4su/how_to_be_happy/\">how to be happy</a>. Remind them that generosity begets happiness.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Precommitment</h4>\n<p><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F3w3%2Fhow_to_beat_procrastination%2F&amp;v=1&amp;libid=1310997629399&amp;out=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOdysseus&amp;ref=http%3A%2F%2Fwww.google.com%2Fsearch%3Fsourceid%3Dchrome%26ie%3DUTF-8%26q%3Dhow%2Bto%2Bbeat%2Bprocrastination&amp;title=How%20to%20Beat%20Procrastination%20-%20Less%20Wrong&amp;txt=Ulysses\">Ulysses</a> did not get past the beautiful but dangerous <a href=\"http://en.wikipedia.org/wiki/Sirens\">Sirens</a> with sheer willpower. Rather, he knew his weaknesses and <em>precommitted</em> to sail past the Sirens. He tied himself to his ship's mast.</p>\n<p>We all know the power of precommitment. Though many gym memberships remain unused, people <em>do</em> spend more time at the gym if they purchase a gym membership than if they pay per visit.<sup>10</sup> Can precommitment work for giving to charity, too?</p>\n<p>Yes, it can. In one study, donors were asked to increase their monthly contributions either immediately or two months in the future. One year later, the increase in donations was 32% higher for the group asked to precommit, and donor cancellation rates were identical (and very low) in both groups.<sup>11</sup></p>\n<p>Does it matter whether a charitable person&nbsp;precommits&nbsp;to donate money they already have vs. money they don't have yet?</p>\n<p>Apparently it does. In one experiment, participants were entered into a raffle, with a chance to win $25. Participants had to decide in advance whether to donate the money to United Way or receive it in cash. Nearly 40% of the participants opted to precommit the potential winnings to charity. In another experiment, researchers asked subjects to imagine they had just won the lottery. Then, some were asked to donate some of their 'winnings' immediately, while others were asked to donate their 'winnings' in two months. Surprisingly, those asked to donate current 'winnings' later actually gave <em>less</em>.<sup>12</sup></p>\n<p>This suggests that pledging to donate&nbsp;current&nbsp;earnings later may be less motivating than donating current earnings now, while pledging to donate <em>future</em>&nbsp;earnings later should work well. (Of course, money is fungible. The donated $100 might as well be from today's paycheck as from the next one. But charities should frame requests for precommitment in terms of <em>future</em>&nbsp;earnings, like <a href=\"http://www.givingwhatwecan.org/our-pledge/\">Giving What We Can</a> does.)</p>\n<p>Precommitment seems to work best when it creates psychological distance between donors and their money.<sup>13</sup> The United Way allows donors to give via paycheck donations; because donors never <em>feel</em>&nbsp;like they have that money, they never face the pain of parting with it.</p>\n<p>The same principle may explain the success of <a href=\"http://en.wikipedia.org/wiki/Affinity_credit_card\">affinity credit cards</a>. Affinity cards allow consumers to precommit their reward points to benefit a chosen charity. Donors never experience the pain of parting with other things that reward points could otherwise purchase (flights, etc.). As an aspiring optimal philanthropist, I use an affinity card that gives 1%-10% cash back to the <a href=\"http://intelligence.org/\">Singularity Institute</a> (plus $50 per <a href=\"https://www.cardlabconnect.com/singularityinstitute\">new card signup</a>). As a lazy optimal philanthropist, I'm glad it took me only four minutes to sign up.</p>\n<p><strong>Lessons for optimal philanthropists</strong>: Precommit. Use paycheck deduction and affinity cards to give money. Pledge future earnings.</p>\n<p><strong>Lessons for optimal charities</strong>: Ask donors to precommit to donate <em>future</em>&nbsp;earnings. Offer an affinity card. Offer paycheck deduction donations if possible.</p>\n<p>&nbsp;</p>\n<h4>Time vs. Money</h4>\n<p>In one creative study, researchers asked subjects to read some information about a fictional non-profit, the \"American Lung Cancer Association.\" Subjects were then told that this organization was holding a fundraising event. Half the subjects were asked how much time they would like to donate (a <em>time-ask</em>). The other subjects were <em>not</em>&nbsp;asked about volunteering their time. Next, <em>both</em>&nbsp;groups were asked how much money they would like to donate (a <em>money-ask</em>).&nbsp;Those who first got a time-ask gave more money when asked for money ($36.44 vs. $24.46). Asking donors for <em>time</em>&nbsp;resulted in them giving more <em>money</em>!</p>\n<p>Researchers also conducted a field experiment by partnering with <a href=\"http://www.hopelab.org/\">HopeLab</a>, a Bay Area charity that aims to improve the quality of life for children with chronic illnesses. A researcher representing HopeLab visited college campuses and waited outside a classroom full of students. When the students emerged, the researcher asked them individually whether they were willing to take part in a 30-minute study in exchange for $10.</p>\n<p>Those who agreed read an introduction to HopeLab. Then, a third of them were asked how much they would like to give time to HopeLab, another third were asked how much they would like to donate to HopeLab, and a control group was asked no questions. Finally, all groups were asked their impressions of HopeLab, along with 20 minutes of filler questions.</p>\n<p>When exiting the study, participants encountered the researcher (representing HopeLab) next to a box labeled 'HopeLab Donations.' The researcher paid each participant with ten $1 bills and gave them a flyer with details about volunteering for HopeLab. Researchers tracked the amount donated and which participants volunteered during the next month.</p>\n<p>Subjects in the time-ask-first condition were the most generous, donating $5.85 of their $10, compared to&nbsp;$4.42 for those in the no-ask condition and&nbsp;$3.07 for those in the money-ask-first condition. Subjects in the time-ask-first condition also volunteered the most (7% gave time, averaging 6.5 hours), compared to those in the money-ask-first condition and the no-ask condition (1.6% each).<sup>14</sup></p>\n<p>Why do we see this 'Time-Ask Effect'? Perhaps it is because thinking about spending time on something activates a mindset of emotional meaning and satisfaction, allowing a donor to connect emotionally with a charity, whereas thinking about spending money activates a purely instrumental mindset.<sup>15</sup> Whatever the reason, asking for time before money may result in more of both.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal philanthropists</strong>: Volunteer your time to an optimal charity. You may soon find yourself giving time <em>and</em>&nbsp;money.</p>\n<p><strong>Lessons for optimal charities:</strong> Ask supporters for time before you ask them for money.</p>\n<p>&nbsp;</p>\n<h4>Multiplying Your Impact</h4>\n<p><a href=\"/lw/3gj/efficient_charity_do_unto_others/\">Optimal philanthropy</a> is a new but obvious idea. Spreading the meme at this early stage is a fairly optimal act in itself.&nbsp;</p>\n<p>Giving to optimal&nbsp;charities instead of average charities can multiply <em>one</em> person's impact 10, 100, or maybe 1000 times. Now multiply <em>that</em>&nbsp;change in impact by a hundred, thousand, or million <em>people</em>&nbsp;who have been persuaded by <a href=\"/lw/3gj/efficient_charity_do_unto_others/\">the simple math</a> and equipped with <a href=\"http://www.amazon.com/Science-Giving-Experimental-Approaches-Judgment/dp/1848728859/\">the psychology of giving</a>.<sup>16</sup></p>\n<p>That's a <em>big</em>&nbsp;impact.</p>\n<p>So, contact me at&nbsp;<a href=\"mailto:OptimalPhilanthropy@gmail.com?subject=I want to help spread optimal philanthropy\">OptimalPhilanthropy@gmail.com</a>&nbsp;and precommit some of your time to working with a network of people to spread the meme of optimal philanthropy. :)</p>\n<p>Or if you haven't got time for email,&nbsp;<a href=\"https://www.cardlabconnect.com/singularityinstitute\">sign up</a> for an affinity card.</p>\n<p>The world thanks you.</p>\n<p>&nbsp;</p>\n<p align=\"center\"><img src=\"http://commonsenseatheism.com/wp-content/uploads/2010/12/carpe-diem-sunshine.jpg\" alt=\"\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup>&nbsp;Lyubomirsky et al. (2004).</small></p>\n<p><small><sup>2</sup>&nbsp;Harbaugh et al. (2007).</small></p>\n<p><small><sup>3</sup>&nbsp;Dunn et al. (2008).</small></p>\n<p><small><sup>4</sup>&nbsp;Isen &amp; Levin (1972).</small></p>\n<p><small><sup>5</sup>&nbsp;Aderman (1972).</small></p>\n<p><small><sup>6</sup>&nbsp;Harris &amp; Huang (1973); Kazdin &amp; Bryan (1971).</small></p>\n<p><small><sup>7</sup>&nbsp;On human universals, see&nbsp;Norenzayan &amp; Heine (2005).</small></p>\n<p><small><sup>8</sup>&nbsp;Aknin et al. (2010).</small></p>\n<p><small><sup>9</sup>&nbsp;Anik et al. (2010).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>10</sup>&nbsp;Della Vigna &amp; Malmendier (2006); Gourville &amp; Soman (1998).</span></p>\n<p><small><sup>11</sup>&nbsp;Breman (2006).</small></p>\n<p><small><sup>12</sup>&nbsp;Meyvis et al. (2010).</small></p>\n<p><small><sup>13</sup>&nbsp;Meyvis et al. (2010). See the work on construal level theory: Trope &amp; Liberman (2003); Liberman et al. (2007).</small></p>\n<p><small><sup>14</sup>&nbsp;Liu &amp; Aaker (2008).</small></p>\n<p><small><sup>15</sup>&nbsp;Liu (2010).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>16</sup>&nbsp;For overviews, see&nbsp;Oppenheimer &amp; Olivola (2010);&nbsp;Andreoni (2006);&nbsp;Bekkers &amp; Wiepking (2007); Small &amp; Simonsohn (2008); Reed et al. (2007).</span></p>\n<p><small>&nbsp;</small><span style=\"font-size: 11px;\">&nbsp;</span></p>\n<h4>References</h4>\n<p><small>Aderman (1972). Elation, depression, and helping behavior. <em>Journal of Personality and Social Psychology, 24</em>: 91-101.</small></p>\n<p><small>Aknin, Barrington-Leigh, Dunn, Helliwell, Biswas-Diener, Kemeza, Nyende, Ashton-James, &amp; Norton (2010). <a href=\"http://barringtonleigh.net/publications/w16415.pdf\">Prosocial spending and well-being: cross-cultural evidence for a psychological universal?</a> <em>NBER Working Paper&nbsp;16415</em>. National Bureau of Economic Research.</small></p>\n<p><small>Andreoni (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/07/Andreoni-Philanthropy.pdf\">Philanthropy</a>. In Kolm &amp; Ythier (eds.), <em>Handbook of the Economics of Giving, Altruism, and Reciprocity, Vol. 2</em> (pp. 1201-1269). North Holland.</small></p>\n<p><small>Anik, Aknin, Norton, &amp; Dunn (2010). Feeling good about giving: The benefits (and costs) of self-interested charitable behavior. In Oppenheimer &amp; Olivola (eds.), <em>The Science of Giving: Experimental Approaches to the Study of Charity</em> (pp. 3-14). Psychology Press.</small></p>\n<p><small>Armstrong, Carpenter, &amp; Hojnacki (2006). <a href=\"http://www.princeton.edu/chw/lectures-conferences/lectures/past-lectures/fall2005/09-26-05.pdf\">Whose deaths matter? Mortality, advocacy, and attention to disease in the mass media</a>. <em>Journal of Health Politics, Policy and Law, 31</em>: 779-772.</small></p>\n<p><small>Bekkers &amp; Wiepking (2007). <a href=\"http://www.fss.uu.nl/soc/homes/bekkers/generosity.pdf\">Generosity and philanthropy: A literature review</a>.</small></p>\n<p><small>Bremen (2006).&nbsp;<a href=\"http://www.frisch.uio.no/firstnordic/Breman-paper.pdf\">Give More Tomorrow: A Field Experiment on&nbsp;Intertemporal Choice in Charitable Giving</a>. Working paper, Stockholm School of Economics.</small></p>\n<p><small>Della Vigna &amp; Malmendier (2006).&nbsp;<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.4827&amp;rep=rep1&amp;type=pdf\">Paying not to go to the gym</a>.&nbsp;<em>American Economic Review, 96</em>: 694&ndash;719.</small></p>\n<p><small>Dunn, Aknin, &amp; Norton (2008). <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.168.3796&amp;rep=rep1&amp;type=pdf\">Spending money on others promotes happiness</a>. <em>Science, 319</em>: 1687-1688.</small></p>\n<p><small>Eisensee &amp; Stromberg (2007). <a href=\"http://people.su.se/~dstro/wpdisasters.pdf\">News floods, news droughts, and U.S. disaster relief</a>. <em>Quarterly Journal of Economics, 122</em>: 693-728.</small></p>\n<p><small>Gourville &amp; Soman (1998). Payment depreciation: The behavioral effects of temporally separating payments from consumption. <em>Journal of Consumer Research, 25</em>: 160-174.</small></p>\n<p><small>Harbaugh, Mayr, &amp; Burghart (2007). <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.6208&amp;rep=rep1&amp;type=pdf\">Neural responses to taxation and voluntary giving reveal motives for charitable donations</a>. <em>Science, 316</em>: 1622-1625.</small></p>\n<p><small>Harris &amp; Huang (1973). Helping and the attribution process. <em>Journal of Social Psychology, 90</em>: 291-297.</small></p>\n<p><small>Isen &amp; Levin (1972). The effect of feeling good on helping: Cookies and kindness. <em>Journal of Personality and Social Psychology, 21</em>: 384-388.</small></p>\n<p><small>Kazdin &amp; Bryan (1971). Competence and volunteering. <em>Journal of Experimental Social Psychology, 7</em>: 87-97.</small></p>\n<p><small>Liberman, Trope, &amp; Stephan (2007). Psychological distance. In Kruglanski &amp; Higgins (eds.), <em>Social Psychology: Handbook of Basic Principles, 2nd edition</em>. Guilford Press.</small></p>\n<p><small>Liu &amp; Aaker (2008). <a href=\"http://faculty-gsb.stanford.edu/aaker/pages/documents/Happinessofgiving.pdf\">The happiness of giving: The time-ask effect</a>. <em>Journal of Consumer Research, 35</em>: 543-547.</small></p>\n<p><small>Liu (2010). The benefits of asking for time.&nbsp;In Oppenheimer &amp; Olivola (eds.),&nbsp;<em style=\"font-style: italic;\">The Science of Giving: Experimental Approaches to the Study of Charity</em>&nbsp;(pp. 201-214). Psychology Press.</small></p>\n<p><small>Lyubomirsky, Tkach, &amp; Sheldon (2004). <em>Pursuing sustained happiness through random acts of kindness and counting one's blessings: Tests of two six-week interventions</em>. Unpublished data, Department of Psychology, University of California, Riverside.</small></p>\n<p><small>Meyvis, Bennett, &amp; Oppenheimer (2010). Precommitment to charity. In&nbsp;Oppenheimer &amp; Olivola (eds.),&nbsp;<em style=\"font-style: italic;\">The Science of Giving: Experimental Approaches to the Study of Charity</em>&nbsp;(pp. 35-48). Psychology Press.</small></p>\n<p><small>Norenzayan &amp; Heine (2005). <a href=\"http://www2.psych.ubc.ca/~heine/docs/universals.pdf\">Psychological universals: What are they and how can we know?</a> <em>Psychological Bulletin, 131</em>: 763-784.</small></p>\n<p><small>Oppenheimer &amp; Olivola, eds. (2010). <em><a href=\"http://www.amazon.com/Science-Giving-Experimental-Approaches-Judgment/dp/1848728859/\">The Science of Giving: Experimental Approaches to the Study of Charity</a></em>. Psychology Press.</small></p>\n<p><small>Reed, Aquino, &amp; Levy (2007). <a href=\"http://www.business.illinois.edu/ba/seminars/2011/reed_paper2.pdf\">Moral identity and judgments of charitable behaviors</a>. <em>Journal of Marketing, 71</em>: 178-193.</small></p>\n<p><small>Slovic (2007). <a href=\"http://www.sas.upenn.edu/~baron/journal/7303a/jdm7303a.htm\">'If I look at the mass I will never act': Psychic numbing and genocide</a>. <em>Judgment and Decision Making, 2</em>: 79-95.</small></p>\n<p><small>Small &amp; Simonsohn (2008). <a href=\"http://ist-socrates.berkeley.edu/~raphael/IGERT/Workshop/Simonsohn%20IGERT.pdf\">Friends of victims: Personal experience and prosocial behavior</a>. <em>Journal of Consumer Research, 35</em>: 532-542.</small></p>\n<p><small>Trope &amp; Liberman (2003). Temporal construal. <em>Psychological Review, 110</em>: 403-421.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 2, "xexCWMyds6QLWognu": 2, "Jzm2mYuuDBCNWq8hi": 2, "TG8zMvjnhydE7Mcue": 1, "5f5c37ee1b5cdee568cfb187": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hEqsWLm5zQtsPevd3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 49, "extendedScore": null, "score": 0.000143, "legacy": true, "legacyId": "8710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Summary: <em>The psychology of charitable giving offers three pieces of advice to those who want to give charity and those who want to receive it: Enjoy the happiness that giving brings, commit future income, and realize that requesting time increases the odds of getting money.</em></p>\n<p>One Saturday morning in 2009, an unknown couple walked into a diner, ate their breakfast, and paid their tab. They also paid the tab for some strangers at another table.&nbsp;</p>\n<p>And for the next five hours, dozens of customers got into the joy of giving and paid the favor forward.</p>\n<p>This may sound like&nbsp;<a href=\"http://en.wikipedia.org/wiki/Pay_It_Forward_(film)\">a movie</a>, but it&nbsp;<a href=\"http://www.nbcphiladelphia.com/news/local/Mystery-Couple-Pay-It-Forward-79179347.html\">really happened</a>.</p>\n<p>But was it a fluke? Is the much-discussed link between happiness and charity&nbsp;<em>real</em>, or is it one of the <em><a href=\"http://www.amazon.com/Great-Myths-Popular-Psychology-Misconceptions/dp/1405131128/\">50 Great Myths of Popular Psychology</a></em>&nbsp;invented to sell books that compete with&nbsp;<em><a href=\"http://www.amazon.com/Secret-Rhonda-Byrne/dp/1582701709/\">The Secret</a></em>?</p>\n<p>Several studies suggest that giving&nbsp;<em style=\"font-style: italic;\">does</em>&nbsp;bring happiness. One study&nbsp;found that asking people to commit random acts of kindness can increase their happiness for weeks.<sup>1</sup>&nbsp;And at the neurological level, giving money to charity activates the reward centers of the brain, the same ones activated by everything from cocaine to great art to an attractive face.<sup>2</sup></p>\n<p>Another study randomly assigned participants to spend money either on themselves or on others. As predicted, those who spent money helping others were happier at the end of the day.<sup>3</sup></p>\n<p>Other studies confirm that just as giving brings happiness, happiness brings giving. A 1972 study showed that people are more likely to help others if they have recently been put in a good mood by receiving a cookie or finding a dime left in a payphone.<sup>4</sup>&nbsp;People are also more likely to help after they read something pleasant,<sup>5</sup>&nbsp;or when they are made to feel competent at something.<sup>6</sup></p>\n<p>In fact, deriving happiness from giving may be a human universal.<sup>7</sup>&nbsp;Data from 136 countries shows that spending money to help others is correlated with happiness.<sup>8</sup></p>\n<p>But&nbsp;<a href=\"http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\">correlation does not imply causation</a>. To test for causation, researchers randomly assigned participants from two very different cultures (Canada and Uganda) to write about a time when they had spent money on themselves (<em style=\"font-style: italic;\">personal spending</em>) or others (<em style=\"font-style: italic;\">prosocial spending</em>). Participants were asked to report the happiness levels before and after the writing exercise. As predicted, those who wrote (and thought) about a time when they had engaged in prosocial spending saw greater increases in happiness than those who wrote about a time when they spent money on themselves.</p>\n<p>So does happiness run in a circular motion?</p>\n<p>This, too, has been tested. In one study,<sup>9</sup>&nbsp;researchers asked each subject to describe the last time they spent either $20 or $100 on themselves or on someone else. Next, researchers had each participant report their level of happiness, and then predict which future spending behavior ($5 or $20, on themselves or others) would make them happiest.</p>\n<p>Subjects assigned to recall prosocial spending reported being happier than those assigned to recall personal spending. Moreover, this reported happiness predicted the future spending choice, but neither the purchase amount nor the purchasing target (oneself or others) did. So happiness and giving do seem to reinforce each other.</p>\n<p>So, should charities&nbsp;<em style=\"font-style: italic;\">remind</em>&nbsp;people that donating will make them happy?</p>\n<p>This, alas, has&nbsp;<em style=\"font-style: italic;\">not</em>&nbsp;been tested. But for now we might guess that just as people&nbsp;<em style=\"font-style: italic;\">generally</em>&nbsp;do things they believe will make them happier, they will probably give more if persuaded by the (ample) evidence that generosity brings happiness.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal philanthropists</strong>: Read the studies showing that giving brings happiness. (Check the footnotes below.) Pick out an optimal charity in advance, notice when you're happy, and decide to give them money&nbsp;<em style=\"font-style: italic;\">right then</em>.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal charities</strong>: Teach your donors&nbsp;<a href=\"/lw/4su/how_to_be_happy/\">how to be happy</a>. Remind them that generosity begets happiness.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Precommitment\">Precommitment</h4>\n<p><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F3w3%2Fhow_to_beat_procrastination%2F&amp;v=1&amp;libid=1310997629399&amp;out=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FOdysseus&amp;ref=http%3A%2F%2Fwww.google.com%2Fsearch%3Fsourceid%3Dchrome%26ie%3DUTF-8%26q%3Dhow%2Bto%2Bbeat%2Bprocrastination&amp;title=How%20to%20Beat%20Procrastination%20-%20Less%20Wrong&amp;txt=Ulysses\">Ulysses</a> did not get past the beautiful but dangerous <a href=\"http://en.wikipedia.org/wiki/Sirens\">Sirens</a> with sheer willpower. Rather, he knew his weaknesses and <em>precommitted</em> to sail past the Sirens. He tied himself to his ship's mast.</p>\n<p>We all know the power of precommitment. Though many gym memberships remain unused, people <em>do</em> spend more time at the gym if they purchase a gym membership than if they pay per visit.<sup>10</sup> Can precommitment work for giving to charity, too?</p>\n<p>Yes, it can. In one study, donors were asked to increase their monthly contributions either immediately or two months in the future. One year later, the increase in donations was 32% higher for the group asked to precommit, and donor cancellation rates were identical (and very low) in both groups.<sup>11</sup></p>\n<p>Does it matter whether a charitable person&nbsp;precommits&nbsp;to donate money they already have vs. money they don't have yet?</p>\n<p>Apparently it does. In one experiment, participants were entered into a raffle, with a chance to win $25. Participants had to decide in advance whether to donate the money to United Way or receive it in cash. Nearly 40% of the participants opted to precommit the potential winnings to charity. In another experiment, researchers asked subjects to imagine they had just won the lottery. Then, some were asked to donate some of their 'winnings' immediately, while others were asked to donate their 'winnings' in two months. Surprisingly, those asked to donate current 'winnings' later actually gave <em>less</em>.<sup>12</sup></p>\n<p>This suggests that pledging to donate&nbsp;current&nbsp;earnings later may be less motivating than donating current earnings now, while pledging to donate <em>future</em>&nbsp;earnings later should work well. (Of course, money is fungible. The donated $100 might as well be from today's paycheck as from the next one. But charities should frame requests for precommitment in terms of <em>future</em>&nbsp;earnings, like <a href=\"http://www.givingwhatwecan.org/our-pledge/\">Giving What We Can</a> does.)</p>\n<p>Precommitment seems to work best when it creates psychological distance between donors and their money.<sup>13</sup> The United Way allows donors to give via paycheck donations; because donors never <em>feel</em>&nbsp;like they have that money, they never face the pain of parting with it.</p>\n<p>The same principle may explain the success of <a href=\"http://en.wikipedia.org/wiki/Affinity_credit_card\">affinity credit cards</a>. Affinity cards allow consumers to precommit their reward points to benefit a chosen charity. Donors never experience the pain of parting with other things that reward points could otherwise purchase (flights, etc.). As an aspiring optimal philanthropist, I use an affinity card that gives 1%-10% cash back to the <a href=\"http://intelligence.org/\">Singularity Institute</a> (plus $50 per <a href=\"https://www.cardlabconnect.com/singularityinstitute\">new card signup</a>). As a lazy optimal philanthropist, I'm glad it took me only four minutes to sign up.</p>\n<p><strong>Lessons for optimal philanthropists</strong>: Precommit. Use paycheck deduction and affinity cards to give money. Pledge future earnings.</p>\n<p><strong>Lessons for optimal charities</strong>: Ask donors to precommit to donate <em>future</em>&nbsp;earnings. Offer an affinity card. Offer paycheck deduction donations if possible.</p>\n<p>&nbsp;</p>\n<h4 id=\"Time_vs__Money\">Time vs. Money</h4>\n<p>In one creative study, researchers asked subjects to read some information about a fictional non-profit, the \"American Lung Cancer Association.\" Subjects were then told that this organization was holding a fundraising event. Half the subjects were asked how much time they would like to donate (a <em>time-ask</em>). The other subjects were <em>not</em>&nbsp;asked about volunteering their time. Next, <em>both</em>&nbsp;groups were asked how much money they would like to donate (a <em>money-ask</em>).&nbsp;Those who first got a time-ask gave more money when asked for money ($36.44 vs. $24.46). Asking donors for <em>time</em>&nbsp;resulted in them giving more <em>money</em>!</p>\n<p>Researchers also conducted a field experiment by partnering with <a href=\"http://www.hopelab.org/\">HopeLab</a>, a Bay Area charity that aims to improve the quality of life for children with chronic illnesses. A researcher representing HopeLab visited college campuses and waited outside a classroom full of students. When the students emerged, the researcher asked them individually whether they were willing to take part in a 30-minute study in exchange for $10.</p>\n<p>Those who agreed read an introduction to HopeLab. Then, a third of them were asked how much they would like to give time to HopeLab, another third were asked how much they would like to donate to HopeLab, and a control group was asked no questions. Finally, all groups were asked their impressions of HopeLab, along with 20 minutes of filler questions.</p>\n<p>When exiting the study, participants encountered the researcher (representing HopeLab) next to a box labeled 'HopeLab Donations.' The researcher paid each participant with ten $1 bills and gave them a flyer with details about volunteering for HopeLab. Researchers tracked the amount donated and which participants volunteered during the next month.</p>\n<p>Subjects in the time-ask-first condition were the most generous, donating $5.85 of their $10, compared to&nbsp;$4.42 for those in the no-ask condition and&nbsp;$3.07 for those in the money-ask-first condition. Subjects in the time-ask-first condition also volunteered the most (7% gave time, averaging 6.5 hours), compared to those in the money-ask-first condition and the no-ask condition (1.6% each).<sup>14</sup></p>\n<p>Why do we see this 'Time-Ask Effect'? Perhaps it is because thinking about spending time on something activates a mindset of emotional meaning and satisfaction, allowing a donor to connect emotionally with a charity, whereas thinking about spending money activates a purely instrumental mindset.<sup>15</sup> Whatever the reason, asking for time before money may result in more of both.</p>\n<p><strong style=\"font-weight: bold;\">Lessons for optimal philanthropists</strong>: Volunteer your time to an optimal charity. You may soon find yourself giving time <em>and</em>&nbsp;money.</p>\n<p><strong>Lessons for optimal charities:</strong> Ask supporters for time before you ask them for money.</p>\n<p>&nbsp;</p>\n<h4 id=\"Multiplying_Your_Impact\">Multiplying Your Impact</h4>\n<p><a href=\"/lw/3gj/efficient_charity_do_unto_others/\">Optimal philanthropy</a> is a new but obvious idea. Spreading the meme at this early stage is a fairly optimal act in itself.&nbsp;</p>\n<p>Giving to optimal&nbsp;charities instead of average charities can multiply <em>one</em> person's impact 10, 100, or maybe 1000 times. Now multiply <em>that</em>&nbsp;change in impact by a hundred, thousand, or million <em>people</em>&nbsp;who have been persuaded by <a href=\"/lw/3gj/efficient_charity_do_unto_others/\">the simple math</a> and equipped with <a href=\"http://www.amazon.com/Science-Giving-Experimental-Approaches-Judgment/dp/1848728859/\">the psychology of giving</a>.<sup>16</sup></p>\n<p>That's a <em>big</em>&nbsp;impact.</p>\n<p>So, contact me at&nbsp;<a href=\"mailto:OptimalPhilanthropy@gmail.com?subject=I want to help spread optimal philanthropy\">OptimalPhilanthropy@gmail.com</a>&nbsp;and precommit some of your time to working with a network of people to spread the meme of optimal philanthropy. :)</p>\n<p>Or if you haven't got time for email,&nbsp;<a href=\"https://www.cardlabconnect.com/singularityinstitute\">sign up</a> for an affinity card.</p>\n<p>The world thanks you.</p>\n<p>&nbsp;</p>\n<p align=\"center\"><img src=\"http://commonsenseatheism.com/wp-content/uploads/2010/12/carpe-diem-sunshine.jpg\" alt=\"\"></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup>&nbsp;Lyubomirsky et al. (2004).</small></p>\n<p><small><sup>2</sup>&nbsp;Harbaugh et al. (2007).</small></p>\n<p><small><sup>3</sup>&nbsp;Dunn et al. (2008).</small></p>\n<p><small><sup>4</sup>&nbsp;Isen &amp; Levin (1972).</small></p>\n<p><small><sup>5</sup>&nbsp;Aderman (1972).</small></p>\n<p><small><sup>6</sup>&nbsp;Harris &amp; Huang (1973); Kazdin &amp; Bryan (1971).</small></p>\n<p><small><sup>7</sup>&nbsp;On human universals, see&nbsp;Norenzayan &amp; Heine (2005).</small></p>\n<p><small><sup>8</sup>&nbsp;Aknin et al. (2010).</small></p>\n<p><small><sup>9</sup>&nbsp;Anik et al. (2010).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>10</sup>&nbsp;Della Vigna &amp; Malmendier (2006); Gourville &amp; Soman (1998).</span></p>\n<p><small><sup>11</sup>&nbsp;Breman (2006).</small></p>\n<p><small><sup>12</sup>&nbsp;Meyvis et al. (2010).</small></p>\n<p><small><sup>13</sup>&nbsp;Meyvis et al. (2010). See the work on construal level theory: Trope &amp; Liberman (2003); Liberman et al. (2007).</small></p>\n<p><small><sup>14</sup>&nbsp;Liu &amp; Aaker (2008).</small></p>\n<p><small><sup>15</sup>&nbsp;Liu (2010).</small></p>\n<p><span style=\"font-size: 11px;\"><sup>16</sup>&nbsp;For overviews, see&nbsp;Oppenheimer &amp; Olivola (2010);&nbsp;Andreoni (2006);&nbsp;Bekkers &amp; Wiepking (2007); Small &amp; Simonsohn (2008); Reed et al. (2007).</span></p>\n<p><small>&nbsp;</small><span style=\"font-size: 11px;\">&nbsp;</span></p>\n<h4 id=\"References\">References</h4>\n<p><small>Aderman (1972). Elation, depression, and helping behavior. <em>Journal of Personality and Social Psychology, 24</em>: 91-101.</small></p>\n<p><small>Aknin, Barrington-Leigh, Dunn, Helliwell, Biswas-Diener, Kemeza, Nyende, Ashton-James, &amp; Norton (2010). <a href=\"http://barringtonleigh.net/publications/w16415.pdf\">Prosocial spending and well-being: cross-cultural evidence for a psychological universal?</a> <em>NBER Working Paper&nbsp;16415</em>. National Bureau of Economic Research.</small></p>\n<p><small>Andreoni (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/07/Andreoni-Philanthropy.pdf\">Philanthropy</a>. In Kolm &amp; Ythier (eds.), <em>Handbook of the Economics of Giving, Altruism, and Reciprocity, Vol. 2</em> (pp. 1201-1269). North Holland.</small></p>\n<p><small>Anik, Aknin, Norton, &amp; Dunn (2010). Feeling good about giving: The benefits (and costs) of self-interested charitable behavior. In Oppenheimer &amp; Olivola (eds.), <em>The Science of Giving: Experimental Approaches to the Study of Charity</em> (pp. 3-14). Psychology Press.</small></p>\n<p><small>Armstrong, Carpenter, &amp; Hojnacki (2006). <a href=\"http://www.princeton.edu/chw/lectures-conferences/lectures/past-lectures/fall2005/09-26-05.pdf\">Whose deaths matter? Mortality, advocacy, and attention to disease in the mass media</a>. <em>Journal of Health Politics, Policy and Law, 31</em>: 779-772.</small></p>\n<p><small>Bekkers &amp; Wiepking (2007). <a href=\"http://www.fss.uu.nl/soc/homes/bekkers/generosity.pdf\">Generosity and philanthropy: A literature review</a>.</small></p>\n<p><small>Bremen (2006).&nbsp;<a href=\"http://www.frisch.uio.no/firstnordic/Breman-paper.pdf\">Give More Tomorrow: A Field Experiment on&nbsp;Intertemporal Choice in Charitable Giving</a>. Working paper, Stockholm School of Economics.</small></p>\n<p><small>Della Vigna &amp; Malmendier (2006).&nbsp;<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.4827&amp;rep=rep1&amp;type=pdf\">Paying not to go to the gym</a>.&nbsp;<em>American Economic Review, 96</em>: 694\u2013719.</small></p>\n<p><small>Dunn, Aknin, &amp; Norton (2008). <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.168.3796&amp;rep=rep1&amp;type=pdf\">Spending money on others promotes happiness</a>. <em>Science, 319</em>: 1687-1688.</small></p>\n<p><small>Eisensee &amp; Stromberg (2007). <a href=\"http://people.su.se/~dstro/wpdisasters.pdf\">News floods, news droughts, and U.S. disaster relief</a>. <em>Quarterly Journal of Economics, 122</em>: 693-728.</small></p>\n<p><small>Gourville &amp; Soman (1998). Payment depreciation: The behavioral effects of temporally separating payments from consumption. <em>Journal of Consumer Research, 25</em>: 160-174.</small></p>\n<p><small>Harbaugh, Mayr, &amp; Burghart (2007). <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.6208&amp;rep=rep1&amp;type=pdf\">Neural responses to taxation and voluntary giving reveal motives for charitable donations</a>. <em>Science, 316</em>: 1622-1625.</small></p>\n<p><small>Harris &amp; Huang (1973). Helping and the attribution process. <em>Journal of Social Psychology, 90</em>: 291-297.</small></p>\n<p><small>Isen &amp; Levin (1972). The effect of feeling good on helping: Cookies and kindness. <em>Journal of Personality and Social Psychology, 21</em>: 384-388.</small></p>\n<p><small>Kazdin &amp; Bryan (1971). Competence and volunteering. <em>Journal of Experimental Social Psychology, 7</em>: 87-97.</small></p>\n<p><small>Liberman, Trope, &amp; Stephan (2007). Psychological distance. In Kruglanski &amp; Higgins (eds.), <em>Social Psychology: Handbook of Basic Principles, 2nd edition</em>. Guilford Press.</small></p>\n<p><small>Liu &amp; Aaker (2008). <a href=\"http://faculty-gsb.stanford.edu/aaker/pages/documents/Happinessofgiving.pdf\">The happiness of giving: The time-ask effect</a>. <em>Journal of Consumer Research, 35</em>: 543-547.</small></p>\n<p><small>Liu (2010). The benefits of asking for time.&nbsp;In Oppenheimer &amp; Olivola (eds.),&nbsp;<em style=\"font-style: italic;\">The Science of Giving: Experimental Approaches to the Study of Charity</em>&nbsp;(pp. 201-214). Psychology Press.</small></p>\n<p><small>Lyubomirsky, Tkach, &amp; Sheldon (2004). <em>Pursuing sustained happiness through random acts of kindness and counting one's blessings: Tests of two six-week interventions</em>. Unpublished data, Department of Psychology, University of California, Riverside.</small></p>\n<p><small>Meyvis, Bennett, &amp; Oppenheimer (2010). Precommitment to charity. In&nbsp;Oppenheimer &amp; Olivola (eds.),&nbsp;<em style=\"font-style: italic;\">The Science of Giving: Experimental Approaches to the Study of Charity</em>&nbsp;(pp. 35-48). Psychology Press.</small></p>\n<p><small>Norenzayan &amp; Heine (2005). <a href=\"http://www2.psych.ubc.ca/~heine/docs/universals.pdf\">Psychological universals: What are they and how can we know?</a> <em>Psychological Bulletin, 131</em>: 763-784.</small></p>\n<p><small>Oppenheimer &amp; Olivola, eds. (2010). <em><a href=\"http://www.amazon.com/Science-Giving-Experimental-Approaches-Judgment/dp/1848728859/\">The Science of Giving: Experimental Approaches to the Study of Charity</a></em>. Psychology Press.</small></p>\n<p><small>Reed, Aquino, &amp; Levy (2007). <a href=\"http://www.business.illinois.edu/ba/seminars/2011/reed_paper2.pdf\">Moral identity and judgments of charitable behaviors</a>. <em>Journal of Marketing, 71</em>: 178-193.</small></p>\n<p><small>Slovic (2007). <a href=\"http://www.sas.upenn.edu/~baron/journal/7303a/jdm7303a.htm\">'If I look at the mass I will never act': Psychic numbing and genocide</a>. <em>Judgment and Decision Making, 2</em>: 79-95.</small></p>\n<p><small>Small &amp; Simonsohn (2008). <a href=\"http://ist-socrates.berkeley.edu/~raphael/IGERT/Workshop/Simonsohn%20IGERT.pdf\">Friends of victims: Personal experience and prosocial behavior</a>. <em>Journal of Consumer Research, 35</em>: 532-542.</small></p>\n<p><small>Trope &amp; Liberman (2003). Temporal construal. <em>Psychological Review, 110</em>: 403-421.</small></p>", "sections": [{"title": "Precommitment", "anchor": "Precommitment", "level": 1}, {"title": "Time vs. Money", "anchor": "Time_vs__Money", "level": 1}, {"title": "Multiplying Your Impact", "anchor": "Multiplying_Your_Impact", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "86 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 88, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbgCx2ntD5eu8Cno9", "pC47ZTsPNAkjavkXs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T09:08:32.014Z", "modifiedAt": null, "url": null, "title": "Is it okay to take toilet-pills? / Rationality vs. the disgust factor", "slug": "is-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "viewCount": null, "lastCommentedAt": "2019-11-26T16:52:02.867Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Hul-Gil", "createdAt": "2011-05-02T22:16:10.898Z", "isAdmin": false, "displayName": "Hul-Gil"}, "userId": "a67SuoZfWaXPzjvzy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KrwaGhLys4boN6Eaw/is-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "pageUrlRelative": "/posts/KrwaGhLys4boN6Eaw/is-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "linkUrl": "https://www.lesswrong.com/posts/KrwaGhLys4boN6Eaw/is-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20it%20okay%20to%20take%20toilet-pills%3F%20%2F%20Rationality%20vs.%20the%20disgust%20factor&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20it%20okay%20to%20take%20toilet-pills%3F%20%2F%20Rationality%20vs.%20the%20disgust%20factor%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKrwaGhLys4boN6Eaw%2Fis-it-okay-to-take-toilet-pills-rationality-vs-the-disgust%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20it%20okay%20to%20take%20toilet-pills%3F%20%2F%20Rationality%20vs.%20the%20disgust%20factor%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKrwaGhLys4boN6Eaw%2Fis-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKrwaGhLys4boN6Eaw%2Fis-it-okay-to-take-toilet-pills-rationality-vs-the-disgust", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<p>Well, I've a chance to prove my commitment to cold, hard rationality, unswayed by emotional concerns... I'm just not sure which route really <em>is</em> the more rational (assuming a desire to stay healthy).</p>\n<p>In doubt as to the most logical course of action, I thought I'd get some LessWrongian input. To back up a bit and explain: I opened a pill bottle and was shaking one out into my hand, and since I'm a klutz the upshot was three pills in the (thankfully flushed) toilet. I fished them out, because these are three out of my last four pills; I take half a tablet a day, and don't get a refill until a week from now.</p>\n<p>Now they're sitting on a dish in front of me, soaking for a few minutes in 91% isopropyl alcohol. Does LessWrong think they'll be okay to take? The alcohol should kill most germs, but I know it doesn't get all of them. What about viruses? Should I attempt to scrub the tablets to remove them? I've also always enjoyed informing my friends about various surfaces with more germs than toilet water (keyboard, phone), but that doesn't mean toilet water isn't horrifically toxic...</p>\n<p>&nbsp;</p>\n<p><strong>You</strong> decide. I promise to abide by the collective decision of LessWrong in this matter: should I take the toilet pills?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KrwaGhLys4boN6Eaw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 7, "extendedScore": null, "score": 1e-05, "legacy": true, "legacyId": "8849", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T10:20:30.786Z", "modifiedAt": null, "url": null, "title": "Video lectures", "slug": "video-lectures", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:53.738Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gBJwAjydby5rte79K", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6X9kGDJLQenHvARKz/video-lectures", "pageUrlRelative": "/posts/6X9kGDJLQenHvARKz/video-lectures", "linkUrl": "https://www.lesswrong.com/posts/6X9kGDJLQenHvARKz/video-lectures", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Video%20lectures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVideo%20lectures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6X9kGDJLQenHvARKz%2Fvideo-lectures%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Video%20lectures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6X9kGDJLQenHvARKz%2Fvideo-lectures", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6X9kGDJLQenHvARKz%2Fvideo-lectures", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 133, "htmlBody": "<p id=\"watch-headline-title\">Here are three interesting video lectures, I hoped to post more but I haven't found any more recently.</p>\n<p><a href=\"http://www.youtube.com/watch?v=nkB1e-JCgmY\"><span id=\"eow-title\" class=\"long-title\" title=\"Eliezer Yudkowsky - The Challenge of Friendly AI (1/3)\" dir=\"ltr\">Eliezer Yudkowsky: The Challenge of Friendly AI</span></a><span id=\"eow-title\" class=\"long-title\" title=\"Eliezer Yudkowsky - The Challenge of Friendly AI (1/3)\" dir=\"ltr\"> - This talk introduces to the concept of Friendly AI by starting with some specific AI (chess player), going meta enough times that a R</span><span id=\"eow-title\" class=\"long-title\" title=\"Eliezer Yudkowsky - The Challenge of Friendly AI (1/3)\" dir=\"ltr\">eflective AI becomes a possibility, then Eliezer discusses the problem of showing that a self modifying agents wont lose its morals.<br /></span></p>\n<p><a href=\"http://www.youtube.com/watch?v=78EmmdfOcI8\"><span id=\"eow-title\" title=\"Judea Pearl Tribute Symposium: Causality\" dir=\"ltr\">Judea Pearl Tribute Symposium: Causality</span></a><span id=\"eow-title\" title=\"Judea Pearl Tribute Symposium: Causality\" dir=\"ltr\"> </span><span title=\"Judea Pearl Tribute Symposium: Causality\" dir=\"ltr\">- A mathematical model of causality is sketched then its connections with probability and counterfactuals and belief propagation are mentioned and explained by example.</span></p>\n<p><a href=\"http://vimeo.com/17553536\">Shane Legg: Universal measures of intelligence</a><span title=\"Judea Pearl Tribute Symposium: Causality\" dir=\"ltr\"> - Discussion about the research and experiments on a particular computable formula <em>Algorithmic Intelligence Quota</em> that aims to be a step towards making the notion of intelligence scientific.<br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6X9kGDJLQenHvARKz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "8502", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T12:11:52.631Z", "modifiedAt": null, "url": null, "title": "Robert Ettinger, founder of cryonics, now CIs 106th patient", "slug": "robert-ettinger-founder-of-cryonics-now-cis-106th-patient", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.154Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8fNcguWPq6uXS2GQK/robert-ettinger-founder-of-cryonics-now-cis-106th-patient", "pageUrlRelative": "/posts/8fNcguWPq6uXS2GQK/robert-ettinger-founder-of-cryonics-now-cis-106th-patient", "linkUrl": "https://www.lesswrong.com/posts/8fNcguWPq6uXS2GQK/robert-ettinger-founder-of-cryonics-now-cis-106th-patient", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Robert%20Ettinger%2C%20founder%20of%20cryonics%2C%20now%20CIs%20106th%20patient&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARobert%20Ettinger%2C%20founder%20of%20cryonics%2C%20now%20CIs%20106th%20patient%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fNcguWPq6uXS2GQK%2Frobert-ettinger-founder-of-cryonics-now-cis-106th-patient%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Robert%20Ettinger%2C%20founder%20of%20cryonics%2C%20now%20CIs%20106th%20patient%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fNcguWPq6uXS2GQK%2Frobert-ettinger-founder-of-cryonics-now-cis-106th-patient", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8fNcguWPq6uXS2GQK%2Frobert-ettinger-founder-of-cryonics-now-cis-106th-patient", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 27, "htmlBody": "<p>Ben Best:&nbsp;<a href=\"http://tech.groups.yahoo.com/group/New_Cryonet/message/302\">Robert Ettinger deanimated today at around 4pm Eastern Time. He was under hospice care and had an ice bath sitting by his bedside.</a></p>\n<p>Obituaries:&nbsp;<a href=\"http://chronopause.com/index.php/2011/07/24/robert-c-w-ettinger-first-life-cycle-1918-to-2011/\">Mike Darwin</a>, <a href=\"http://www.washingtonpost.com/local/obituaries/from-phyics-teacher-to-founder-of-the-cryonics-movement/2011/07/24/gIQAupuIXI_story.html\">Washington Post</a>,&nbsp;<a href=\"http://www.telegraph.co.uk/news/obituaries/science-obituaries/8658435/Robert-Ettinger.html\">Telegraph</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Robert_Ettinger\">Wikipedia</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8fNcguWPq6uXS2GQK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 7.457555651451467e-07, "legacy": true, "legacyId": "8850", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T12:16:16.036Z", "modifiedAt": null, "url": null, "title": "LINK: Journalist's search for counter arguments damages science", "slug": "link-journalist-s-search-for-counter-arguments-damages", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.358Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tetsuo55", "createdAt": "2011-05-28T17:16:39.492Z", "isAdmin": false, "displayName": "tetsuo55"}, "userId": "wuYeqAN7TWZErmuM9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3B8P8S7XuD6vDwmKC/link-journalist-s-search-for-counter-arguments-damages", "pageUrlRelative": "/posts/3B8P8S7XuD6vDwmKC/link-journalist-s-search-for-counter-arguments-damages", "linkUrl": "https://www.lesswrong.com/posts/3B8P8S7XuD6vDwmKC/link-journalist-s-search-for-counter-arguments-damages", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Journalist's%20search%20for%20counter%20arguments%20damages%20science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Journalist's%20search%20for%20counter%20arguments%20damages%20science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3B8P8S7XuD6vDwmKC%2Flink-journalist-s-search-for-counter-arguments-damages%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Journalist's%20search%20for%20counter%20arguments%20damages%20science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3B8P8S7XuD6vDwmKC%2Flink-journalist-s-search-for-counter-arguments-damages", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3B8P8S7XuD6vDwmKC%2Flink-journalist-s-search-for-counter-arguments-damages", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p>I just saw this link on a pop-news site.</p>\n<p>It's a PDF file showing how good BBC's reporting of science news is in general, but more specifically it reports about the fact that the journalists give far too much credit to arguments from people who have no scientific backing for their argument.</p>\n<p>&nbsp;</p>\n<p>http://www.bbc.co.uk/bbctrust/assets/files/pdf/our_work/science_impartiality/science_impartiality.pdf</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3B8P8S7XuD6vDwmKC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 2.5e-05, "legacy": true, "legacyId": "8851", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T17:03:37.227Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver, Canada", "slug": "meetup-vancouver-canada", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.164Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "michaelkeenan", "createdAt": "2009-03-02T10:01:40.717Z", "isAdmin": false, "displayName": "michaelkeenan"}, "userId": "GBtCcsREHSDGbo9Dw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZsCkKQqg3Kd2iDf6E/meetup-vancouver-canada", "pageUrlRelative": "/posts/ZsCkKQqg3Kd2iDf6E/meetup-vancouver-canada", "linkUrl": "https://www.lesswrong.com/posts/ZsCkKQqg3Kd2iDf6E/meetup-vancouver-canada", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver%2C%20Canada&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver%2C%20Canada%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsCkKQqg3Kd2iDf6E%2Fmeetup-vancouver-canada%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver%2C%20Canada%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsCkKQqg3Kd2iDf6E%2Fmeetup-vancouver-canada", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZsCkKQqg3Kd2iDf6E%2Fmeetup-vancouver-canada", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 359, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1r'>Vancouver, Canada</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">31 July 2011 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Commune Cafe, 1002 Seymour Street, Vancouver, BC, Canada</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're holding the first Vancouver meetup on Sunday, July 31st starting at 3pm at the <a href=\"http://www.communecafe.ca/\" rel=\"nofollow\">Commune Cafe</a> on Seymour Street. We'll definitely be there from 3pm-6pm, but it'll end when it ends.</p>\n\n<p>I've recently moved to Vancouver from the San Francisco Bay Area, where I lived at the household that hosts the Tortuga/Mountain View meetup. The rationalist community in Silicon Valley is vibrant and growing, and I loved being part of it. As <a href=\"http://lesswrong.com/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">Cosmos wrote of the New York group</a>:</p>\n\n<blockquote>\n  <p>Before this community took off, <em>I did not believe that life could be this much fun or that I could possibly achieve such a sustained level of happiness</em>.</p>\n  \n  <p>Being rational in an irrational world is incredibly lonely. Every interaction reveals that our thought processes differ widely from those around us, and I had accepted that such a divide would always exist. For the first time in my life I have dozens of people with whom I can act freely and <em>revel in the joy of rationality</em> without any social concern - hell, it's actively rewarded! Until the NYC Less Wrong community formed, I didn't realize that I was a forager lost without a tribe...</p>\n</blockquote>\n\n<p>Activities of the rationalist community at Tortuga included meetups, hiking trips, guest speakers, transhumanist movies, skill-training sessions, parties and impromptu pillow fights. I want to find or build a similar community in Vancouver. We have a base of several people, and will be reaching out through Less Wrong and in other ways to find like-minded people.</p>\n\n<p>I'm anticipating holding weekly meetups. The Commune Cafe in downtown Vancouver is a good place to start, but we have a great place in North Vancouver that we could use if that location works for everyone.</p>\n\n<p>At this first meetup, we'll get to know each other, and talk about what we want to get out of holding meetups and forming a community, and figure out how to accomplish those things.</p>\n\n<p>Feel free to bring friends, significant others, or anyone else who's interested in rationality.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1r'>Vancouver, Canada</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZsCkKQqg3Kd2iDf6E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.458467765461688e-07, "legacy": true, "legacyId": "8852", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver__Canada\">Discussion article for the meetup : <a href=\"/meetups/1r\">Vancouver, Canada</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">31 July 2011 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Commune Cafe, 1002 Seymour Street, Vancouver, BC, Canada</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're holding the first Vancouver meetup on Sunday, July 31st starting at 3pm at the <a href=\"http://www.communecafe.ca/\" rel=\"nofollow\">Commune Cafe</a> on Seymour Street. We'll definitely be there from 3pm-6pm, but it'll end when it ends.</p>\n\n<p>I've recently moved to Vancouver from the San Francisco Bay Area, where I lived at the household that hosts the Tortuga/Mountain View meetup. The rationalist community in Silicon Valley is vibrant and growing, and I loved being part of it. As <a href=\"http://lesswrong.com/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">Cosmos wrote of the New York group</a>:</p>\n\n<blockquote>\n  <p>Before this community took off, <em>I did not believe that life could be this much fun or that I could possibly achieve such a sustained level of happiness</em>.</p>\n  \n  <p>Being rational in an irrational world is incredibly lonely. Every interaction reveals that our thought processes differ widely from those around us, and I had accepted that such a divide would always exist. For the first time in my life I have dozens of people with whom I can act freely and <em>revel in the joy of rationality</em> without any social concern - hell, it's actively rewarded! Until the NYC Less Wrong community formed, I didn't realize that I was a forager lost without a tribe...</p>\n</blockquote>\n\n<p>Activities of the rationalist community at Tortuga included meetups, hiking trips, guest speakers, transhumanist movies, skill-training sessions, parties and impromptu pillow fights. I want to find or build a similar community in Vancouver. We have a base of several people, and will be reaching out through Less Wrong and in other ways to find like-minded people.</p>\n\n<p>I'm anticipating holding weekly meetups. The Commune Cafe in downtown Vancouver is a good place to start, but we have a great place in North Vancouver that we could use if that location works for everyone.</p>\n\n<p>At this first meetup, we'll get to know each other, and talk about what we want to get out of holding meetups and forming a community, and figure out how to accomplish those things.</p>\n\n<p>Feel free to bring friends, significant others, or anyone else who's interested in rationality.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver__Canada1\">Discussion article for the meetup : <a href=\"/meetups/1r\">Vancouver, Canada</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver, Canada", "anchor": "Discussion_article_for_the_meetup___Vancouver__Canada", "level": 1}, {"title": "Discussion article for the meetup : Vancouver, Canada", "anchor": "Discussion_article_for_the_meetup___Vancouver__Canada1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CsKboswS3z5iaiutC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-25T17:38:00.382Z", "modifiedAt": null, "url": null, "title": "Meetup : Ottawa LessWrong Weekly Meetup", "slug": "meetup-ottawa-lesswrong-weekly-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.268Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D76orWH4uSysmA6qZ/meetup-ottawa-lesswrong-weekly-meetup", "pageUrlRelative": "/posts/D76orWH4uSysmA6qZ/meetup-ottawa-lesswrong-weekly-meetup", "linkUrl": "https://www.lesswrong.com/posts/D76orWH4uSysmA6qZ/meetup-ottawa-lesswrong-weekly-meetup", "postedAtFormatted": "Monday, July 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD76orWH4uSysmA6qZ%2Fmeetup-ottawa-lesswrong-weekly-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD76orWH4uSysmA6qZ%2Fmeetup-ottawa-lesswrong-weekly-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD76orWH4uSysmA6qZ%2Fmeetup-ottawa-lesswrong-weekly-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1s'>Ottawa LessWrong Weekly Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 July 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Fox and Feather Pub, 283 Elgin Street, Ottawa, Ontario</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: Fox and Feather, upstairs, usually in back room #1 when it's free. Look for the LW sign. New people always warmly welcome!</p>\n\n<p><a href=\"http://lesswrong.com/lw/6nz/approving_reinforces_loweffort_behaviors/\">Discussion post</a></p>\n\n<p>Exercise: TBD (Suggestions in comments?)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1s'>Ottawa LessWrong Weekly Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D76orWH4uSysmA6qZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.458575283416366e-07, "legacy": true, "legacyId": "8853", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1s\">Ottawa LessWrong Weekly Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 July 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Fox and Feather Pub, 283 Elgin Street, Ottawa, Ontario</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: Fox and Feather, upstairs, usually in back room #1 when it's free. Look for the LW sign. New people always warmly welcome!</p>\n\n<p><a href=\"http://lesswrong.com/lw/6nz/approving_reinforces_loweffort_behaviors/\">Discussion post</a></p>\n\n<p>Exercise: TBD (Suggestions in comments?)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1s\">Ottawa LessWrong Weekly Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ottawa LessWrong Weekly Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Ottawa LessWrong Weekly Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yDRX2fdkm3HqfTpav"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T00:07:09.747Z", "modifiedAt": null, "url": null, "title": "A potentially great improvement to minimum wage laws to handle both economic efficiency as well as poverty concerns", "slug": "a-potentially-great-improvement-to-minimum-wage-laws-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:08.297Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "VijayKrishnan", "createdAt": "2009-07-20T18:03:11.874Z", "isAdmin": false, "displayName": "VijayKrishnan"}, "userId": "yumdsymW2vnv4ZD6h", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hx5e4YYPQ5GYLy3YB/a-potentially-great-improvement-to-minimum-wage-laws-to", "pageUrlRelative": "/posts/Hx5e4YYPQ5GYLy3YB/a-potentially-great-improvement-to-minimum-wage-laws-to", "linkUrl": "https://www.lesswrong.com/posts/Hx5e4YYPQ5GYLy3YB/a-potentially-great-improvement-to-minimum-wage-laws-to", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20potentially%20great%20improvement%20to%20minimum%20wage%20laws%20to%20handle%20both%20economic%20efficiency%20as%20well%20as%20poverty%20concerns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20potentially%20great%20improvement%20to%20minimum%20wage%20laws%20to%20handle%20both%20economic%20efficiency%20as%20well%20as%20poverty%20concerns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHx5e4YYPQ5GYLy3YB%2Fa-potentially-great-improvement-to-minimum-wage-laws-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20potentially%20great%20improvement%20to%20minimum%20wage%20laws%20to%20handle%20both%20economic%20efficiency%20as%20well%20as%20poverty%20concerns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHx5e4YYPQ5GYLy3YB%2Fa-potentially-great-improvement-to-minimum-wage-laws-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHx5e4YYPQ5GYLy3YB%2Fa-potentially-great-improvement-to-minimum-wage-laws-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 539, "htmlBody": "<p>Minimum wage has the side effect of leaving unemployed, the people who do not possess the requisite skill to command the minimum wage in the market. This follows from basic micro-economic theory and <a href=\"http://www.youtube.com/watch?v=ca8Z__o52sk\" target=\"_self\">here is nice short video</a> of Milton Friedman, the&nbsp;renowned United States economist&nbsp;arguing against minimum wage laws.&nbsp;To offset this problem, it is essential to have some kind of social security safety net for the unemployed.</p>\n<p class=\"p1\">Instead, I would like to propose the following scheme which seems to me as more efficient (please let me know in the comments if you know of any country that tried this or something close): Set x= 1.5 * min_wage. Have no minimum wage laws. And folks who earn y which is below x, receive (x-y)/2 in social security. This way, we have (1) lower \"skilled\" people contributing to the country's GDP in their own small way instead of being unemployed and contributing nothing. If we have a significant number of these guys, the numbers could really add up. (2) The min wage like concerns are taken care of with the government safety net. (3) There is still incentive for people earning below x to work. If we set the social security to something like (x-y), no one earning below x will have any incentive to work since their net in hand compensation would then always be x regardless of what they do.</p>\n<p class=\"p1\">&nbsp; &nbsp; This above scheme looks almost like a pareto improvement to me compared to minimum wage laws, supported by social security for the unemployed, because it does roughly as good with regard to supporting those whose skills are below the minimum wage, while ensuring less government spending on social security, since many of the formerly unemployed would now be in low wage jobs and the government simply has to top up their current salaries which might be well above zero. This is of course a good thing, because the government then has the option of either using the extra money to reduce the budget deficit and ensure better economic health of the country, or use the money for other worthy endeavors.&nbsp;There is also greater contribution to the country's GDP which is a good objective in itself. Lastly there is reason to believe that people being gainfully employed is better for their physical and mental well being. It will also likely reduce their propensity to indulge in anti-social activities, compared to a scenario where they are unemployed with a lot of idle time on their hands.&nbsp;</p>\n<p class=\"p1\">I haven't spent much time thinking through the implementation and whether there is greater potential for such a scheme to get scammed and exploited etc. At least at first glance it seems to me that this scheme is no more exploitable compared to welfare benefits for the unemployed, which must necessarily go with minimum wages for it to actually be humane and better for the poor. Some people can probably get away by earning a living and still claiming to be unemployed and collecting welfare checks under the min wage + unemployment welfare method. The same people can do it under the new proposed scheme as well, so I am unable to see any more vulnerabilities and loopholes in this system compared to the previous one.</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">Thoughts?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hx5e4YYPQ5GYLy3YB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -1, "extendedScore": null, "score": 7.459792289529136e-07, "legacy": true, "legacyId": "8854", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 74, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T00:58:31.010Z", "modifiedAt": null, "url": null, "title": "Bayesian justice", "slug": "bayesian-justice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:36.009Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xx7TeDmBQDFnx8GY7/bayesian-justice", "pageUrlRelative": "/posts/xx7TeDmBQDFnx8GY7/bayesian-justice", "linkUrl": "https://www.lesswrong.com/posts/xx7TeDmBQDFnx8GY7/bayesian-justice", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20justice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20justice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxx7TeDmBQDFnx8GY7%2Fbayesian-justice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20justice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxx7TeDmBQDFnx8GY7%2Fbayesian-justice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxx7TeDmBQDFnx8GY7%2Fbayesian-justice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 392, "htmlBody": "<p><a href=\"http://www.allbusiness.com/print/13289931-1-9a0bs.html\">\"The mathematical mistakes that could be undermining justice\"</a></p>\n<blockquote>\n<p>They failed, though, to convince the jury of the value of the  Bayesian approach, and Adams was convicted. He appealed twice  unsuccessfully, with an appeal judge eventually ruling that the jury's  job was \"to evaluate evidence not by means of a formula... but by the  joint application of their individual common sense.\"</p>\n<p>But what if  common sense runs counter to justice? For David Lucy, a mathematician at  Lancaster University in the UK, the Adams judgment indicates a cultural  tradition that needs changing. \"In some cases, statistical analysis is  the only way to evaluate evidence, because intuition can lead to  outcomes based upon fallacies,\" he says.</p>\n<p>Norman Fenton, a computer  scientist at Queen Mary, University of London, who has worked for  defence teams in criminal trials, has just come up with a possible  solution. With his colleague Martin Neil, he has developed a system of  step-by-step pictures and decision trees to help jurors grasp Bayesian  reasoning (<a href=\"http://www.eecs.qmul.ac.uk/~norman/papers/fenton_neil_prob_fallacies_3_July_09.pdf\">bit.ly/1c3tgj</a>). Once a jury has been convinced that the  method works, the duo argue, experts should be allowed to apply Bayes's  theorem to the facts of the case as a kind of \"black box\" that  calculates how the probability of innocence or guilt changes as each  piece of evidence is presented. \"You wouldn't question the steps of an  electronic calculator, so why here?\" Fenton asks.</p>\n<p>It is a  controversial suggestion. Taken to its logical conclusion, it might see  the outcome of a trial balance on a single calculation. Working out  Bayesian probabilities with DNA and blood matches is all very well, but  quantifying incriminating factors such as appearance and behaviour is  more difficult. \"Different jurors will interpret different bits of  evidence differently. It's not the job of a mathematician to do it for  them,\" says Donnelly.</p>\n</blockquote>\n<p>The linked paper is \"Avoiding Probabilistic Reasoning Fallacies in Legal Practice using Bayesian Networks\" by Norman Fenton and Martin Neil. The interesting parts, IMO, begin on page 9 where they argue for using the likelihood ratio as the key piece of information for evidence, and not simply raw probabilities; page 17, where a DNA example is worked out; and page 21-25 on the key piece of evidence in the Bellfield trial, no one claiming a lost possession (nearly worthless evidence)</p>\n<p>Related reading: <a href=\"/lw/35d/inherited_improbabilities_transferring_the_burden/\">Inherited Improbabilities: Transferring the Burden of Proof</a>, on Amanda Knox.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xx7TeDmBQDFnx8GY7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 27, "extendedScore": null, "score": 7.459952916037592e-07, "legacy": true, "legacyId": "8856", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ATgFZpZCh4rS8fCGD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T01:27:44.163Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Hindsight Devalues Science", "slug": "seq-rerun-hindsight-devalues-science", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.406Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7ZXNLyMpYKK5ABkBo/seq-rerun-hindsight-devalues-science", "pageUrlRelative": "/posts/7ZXNLyMpYKK5ABkBo/seq-rerun-hindsight-devalues-science", "linkUrl": "https://www.lesswrong.com/posts/7ZXNLyMpYKK5ABkBo/seq-rerun-hindsight-devalues-science", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Hindsight%20Devalues%20Science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Hindsight%20Devalues%20Science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7ZXNLyMpYKK5ABkBo%2Fseq-rerun-hindsight-devalues-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Hindsight%20Devalues%20Science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7ZXNLyMpYKK5ABkBo%2Fseq-rerun-hindsight-devalues-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7ZXNLyMpYKK5ABkBo%2Fseq-rerun-hindsight-devalues-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>Title: [SEQ RERUN] Hindsight Devalues Science  Tags: sequence_reruns  Today's post, <a href=\"/lw/im/hindsight_devalues_science/\">Hindsight Devalues Science</a> was originally published on 17 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Hindsight bias leads us to systematically undervalue scientific findings, because we find it too easy to retrofit them into our models of the world. This unfairly devalues the contributions of researchers. Worse, it prevents us from noticing when we are seeing evidence that doesn't fit what we really would have expected. We need to make a conscious effort to be shocked enough.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/il/hindsight_bias/\">Hindsight bias</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7ZXNLyMpYKK5ABkBo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.460044310742494e-07, "legacy": true, "legacyId": "8858", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WnheMGAka4fL99eae", "fkM9XsNvXdYH6PPAx", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T06:44:19.588Z", "modifiedAt": null, "url": null, "title": "Shortening the Unshortenable Way", "slug": "shortening-the-unshortenable-way", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.161Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Duk3", "createdAt": "2011-07-26T03:45:14.493Z", "isAdmin": false, "displayName": "Duk3"}, "userId": "SYPSKXkMrrQr4x5iH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yc4Qu2PBnBNrHHb8b/shortening-the-unshortenable-way", "pageUrlRelative": "/posts/yc4Qu2PBnBNrHHb8b/shortening-the-unshortenable-way", "linkUrl": "https://www.lesswrong.com/posts/yc4Qu2PBnBNrHHb8b/shortening-the-unshortenable-way", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shortening%20the%20Unshortenable%20Way&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShortening%20the%20Unshortenable%20Way%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyc4Qu2PBnBNrHHb8b%2Fshortening-the-unshortenable-way%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shortening%20the%20Unshortenable%20Way%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyc4Qu2PBnBNrHHb8b%2Fshortening-the-unshortenable-way", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyc4Qu2PBnBNrHHb8b%2Fshortening-the-unshortenable-way", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 768, "htmlBody": "<p>&nbsp;</p>\n<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; padding: 0.5em; margin: 8px;\">\n<p>or</p>\n<p>A Starting Point for Defense against Flexible Dark Artists and Circumstances</p>\n<p>&nbsp;</p>\n<p><span style=\"white-space: pre;\"> </span>In&nbsp;<a href=\"/lw/5z/on_seeking_a_shortening_of_the_way/\">On Seeking a Shortening of the Way</a>&nbsp;the assertion &ldquo;Maybe we're not geniuses&nbsp;<em>because</em>&nbsp;we don't bother paying attention to ordinary things&rdquo; caught my eye. Certainly! I said. Obviously if we were able to pay the appropriate amount of attention to every occurrence so as to gain enough data to update our models in an optimal way, we would rapidly increase our overall ability to model the world and increase our probability of insights at the level currently considered &lsquo;genius.&rsquo;</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>And then I remembered that I can&rsquo;t really do that, on account of having crappy models of what is actually important, and thinking that i can't improve those models quickly. Whoops! I, like so many others, fail to know how much attention to pay to ordinary things so as to become a genius. C&rsquo;est la vie. Fortunately the lesson here was not the factuality of the statement, which is high, but a reminder that you could probably gain benefits from paying&nbsp;<em>more&nbsp;</em>attention and being&nbsp;<em>more&nbsp;</em>disciplined in your thought.</p>\n<p class=\"MsoNormal\"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Which is even better because it&rsquo;s great advice, and eminently doable. Thanks, Yvain! So I set about paying attention to how I currently pay attention and, like usual, paid attention to the cues I get about how other people pay attention, assuming that I make the mistakes they do at least&nbsp;<em>some&nbsp;</em>of the time.</p>\n<p class=\"MsoNormal\"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>And then I realized&hellip; wait a minute, whenever other people aren&rsquo;t actually paying attention is when&nbsp;<em>I</em>&nbsp;could most easily&nbsp;<a href=\"http://en.wikipedia.org/wiki/Dutch_book\">shanghai them</a>&nbsp;into doing things they normally wouldn&rsquo;t do (Were I a dark artist. Hypothetically.). So learning how to pay more attention and pay attention in the correct way is probably the best reflexive method of avoiding being dutch booked by people who are highly adaptable dark artists.</p>\n<p class=\"MsoNormal\"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>And here&rsquo;s my low-hanging fruit of techniques to build the foundational reflexes for shortening the way. The goal is to avoid being inattentive in certain sorts of situations where I noted personal susceptibility to being taken advantage of by changing situations or flexible con artists.</p>\n<p class=\"MsoNormal\"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>&nbsp;</strong></span><strong>Summary</strong>: Act like Suspicious, Smart, Rich People Do. Assume everyone and everything is both an opportunity and an encounter with a parasite, and&nbsp;<em>don&rsquo;t act like it</em>&nbsp;unless it&rsquo;s socially convenient. How do you do this, you say. It sounds more difficult than that, you say. On the contrary, skeptical sir! I will now present an exercise which rapidly becomes reflexive, in a manner which will cause it to become reflexive, which separates the exercise from the situation so that you can learn the requisite acting skills separately! Try this!</p>\n<p class=\"MsoNormal\"><span style=\"white-space: pre;\"> </span>Ask yourself for new people , situations, arguments, and facts, what is this worth to me? What risks do I run by paying attention to this? What opportunities lie in this, if my understanding of it is correct? What risks do I run, if my understanding of it is incorrect? And you can go as much deeper as you think is valuable or are mentally capable of sustaining.</p>\n<p class=\"MsoNormal\"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span>For the&nbsp;step-by-steppers out there&nbsp;(<a href=\"http://www.sas.upenn.edu/~duckwort/images/Conscientiousness2009.pdf\">I salute you!</a>), here&rsquo;s explicitly How To start doing this in a low-cost way.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.5in;\">Step 1: In your journal for daily events (If you&rsquo;re not keeping one of these go buy a journal and start.&nbsp;<a href=\"/lw/il/hindsight_bias/\">Without a daily log how do you know</a>&nbsp;you&rsquo;re actually making progress?) use Pen and Paper (The Great Equalizer!) and write down your understanding of a couple of important topics and a few simple topics (<a href=\"/lw/jg/planning_fallacy/\">the simple topics shouldn&rsquo;t take as long&hellip; right?</a>). This will be a lot of work! But it&rsquo;s only for one day, and developing this mental habit in particular and your ability to do rational yet seemingly onerous things for a brief period each day will both be massively valuable.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.5in;\">Step 2: When That Gets Boring, elaborate with pros and cons, an analysis of arguments, or&nbsp;<a href=\"http://www.businessballs.com/problemsolving.htm\">other techniques that professionals use when it&rsquo;s important</a>&nbsp;(Imagine a lawyer not analyzing their opponent&rsquo;s arguments, and then imagine yourself&nbsp;<em>as their client</em>.).&nbsp;<span>&nbsp;</span>Do a&nbsp;<a href=\"http://en.wikipedia.org/wiki/Fermi_problem\">Fermi calculation</a>&nbsp;(<a href=\"http://www.physics.umd.edu/perg/fermi/fermi.htm\">here's some practice</a>) if it involves a number of things you don&rsquo;t understand well.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.5in;\">Step 3: Avoid&nbsp;<a href=\"http://en.wikipedia.org/wiki/Rationalization_(making_excuses)\">abusing this method to convince yourself you don't need to run the numbers</a>&nbsp;by pretending someone else, someone&nbsp;<em>biased,</em>wrote the analysis. (Those darned&nbsp;<em>Biased</em>&nbsp;people, cropping up even in your own journal!) Think of how future versions of yourself will look at your thought processes (you'll be smarter then... wiser... with a knowledge of<a href=\"http://en.wikipedia.org/wiki/Fallacy\">common logical fallacies</a>&nbsp;and the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Heuristic#Well_known\">heuristics</a>&nbsp;and&nbsp;<a href=\"http://en.wikipedia.org/wiki/Cognitive_bias#Types_of_cognitive_biases\">biases</a>&nbsp;<a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147\">literature</a>)(you might even read&nbsp;<a href=\"http://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach\">Godel Escher Bach</a>&nbsp;or something and<em>blow your mind</em>. Anything is possible!). Look over your previous analyses before deciding (sleep on it and wait on it). Developing a decent set of evidence for fermi calculations and calibration exercises will let you use the same thought processes to do this right when you don't have time to run the numbers.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.5in;\">Step 4: Profit.</p>\n<p class=\"MsoNormal\" style=\"margin-left: 0.5in;\">&nbsp;</p>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yc4Qu2PBnBNrHHb8b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -1, "extendedScore": null, "score": 7.46103469996919e-07, "legacy": true, "legacyId": "8865", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AvTmLRperBRXyeqL9", "fkM9XsNvXdYH6PPAx", "CPm5LTwHrvBJCa9h5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T07:06:29.801Z", "modifiedAt": null, "url": null, "title": "Writing guide?", "slug": "writing-guide", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.352Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oscar_Cunningham", "createdAt": "2009-09-18T13:28:22.764Z", "isAdmin": false, "displayName": "Oscar_Cunningham"}, "userId": "G2SZuAiaBaNPg9rBt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PA7e2PpKYq8noJGdB/writing-guide", "pageUrlRelative": "/posts/PA7e2PpKYq8noJGdB/writing-guide", "linkUrl": "https://www.lesswrong.com/posts/PA7e2PpKYq8noJGdB/writing-guide", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Writing%20guide%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWriting%20guide%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPA7e2PpKYq8noJGdB%2Fwriting-guide%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Writing%20guide%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPA7e2PpKYq8noJGdB%2Fwriting-guide", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPA7e2PpKYq8noJGdB%2Fwriting-guide", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 27, "htmlBody": "<p>I remember seeing a short writing guide written by Eliezer for use by the SIAI, but now I can't find it. Anyone have a link for it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PA7e2PpKYq8noJGdB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.461104063660838e-07, "legacy": true, "legacyId": "8868", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T07:29:21.178Z", "modifiedAt": null, "url": null, "title": "SIAI Logo In SVG Format?", "slug": "siai-logo-in-svg-format", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.597Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "Q9oWZLLfJtXqhi5fq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GWXrfv2MYSzXwnABC/siai-logo-in-svg-format", "pageUrlRelative": "/posts/GWXrfv2MYSzXwnABC/siai-logo-in-svg-format", "linkUrl": "https://www.lesswrong.com/posts/GWXrfv2MYSzXwnABC/siai-logo-in-svg-format", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIAI%20Logo%20In%20SVG%20Format%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIAI%20Logo%20In%20SVG%20Format%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWXrfv2MYSzXwnABC%2Fsiai-logo-in-svg-format%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIAI%20Logo%20In%20SVG%20Format%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWXrfv2MYSzXwnABC%2Fsiai-logo-in-svg-format", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGWXrfv2MYSzXwnABC%2Fsiai-logo-in-svg-format", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>(Motivated by <a href=\"/lw/6py/optimal_philanthropy_for_human_beings/4jqh\">this comment</a>.)</p>\n<p>The Singularity Institute's <a href=\"http://99designs.com/designs/6825812-original\">new logo</a>, chosen from <a href=\"/lw/422/295_bounty_for_new_singularity_institute_logo/\">a competition</a>, doesn't seem to be publicly available in <a href=\"http://en.wikipedia.org/wiki/Scalable_Vector_Graphics\">SVG</a> format. &nbsp;But presumably, the winner delivered an SVG (or another vector format) instead of a JPEG. &nbsp;The vector form should be made publicly available, like how <a href=\"http://en.wikipedia.org/wiki/Logo_of_Wikipedia\">Wikipedia's logo</a>&nbsp;is available as an SVG <a href=\"http://en.wikipedia.org/wiki/File:Wikipedia-logo-v2.svg\">here</a>.</p>\n<p>To start with, this could be used to improve the <a href=\"http://en.wikipedia.org/wiki/Singularity_Institute\">Singularity Institute</a> page on Wikipedia, which is in dire need of a logo.</p>\n<p>(I actually have no personal use for this, I'm simply a&nbsp;connoisseur of high-quality logos.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GWXrfv2MYSzXwnABC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 20, "extendedScore": null, "score": 7.461175575092467e-07, "legacy": true, "legacyId": "8869", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["S5YYkJdsjh6hpKLHn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T09:33:22.358Z", "modifiedAt": null, "url": null, "title": "The latest in preference elicitation and preference learning in AI [links]", "slug": "the-latest-in-preference-elicitation-and-preference-learning", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r2wRCvkjGARPiKG23/the-latest-in-preference-elicitation-and-preference-learning", "pageUrlRelative": "/posts/r2wRCvkjGARPiKG23/the-latest-in-preference-elicitation-and-preference-learning", "linkUrl": "https://www.lesswrong.com/posts/r2wRCvkjGARPiKG23/the-latest-in-preference-elicitation-and-preference-learning", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20latest%20in%20preference%20elicitation%20and%20preference%20learning%20in%20AI%20%5Blinks%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20latest%20in%20preference%20elicitation%20and%20preference%20learning%20in%20AI%20%5Blinks%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2wRCvkjGARPiKG23%2Fthe-latest-in-preference-elicitation-and-preference-learning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20latest%20in%20preference%20elicitation%20and%20preference%20learning%20in%20AI%20%5Blinks%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2wRCvkjGARPiKG23%2Fthe-latest-in-preference-elicitation-and-preference-learning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2wRCvkjGARPiKG23%2Fthe-latest-in-preference-elicitation-and-preference-learning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<p>'Preference elicitation' or 'preference extraction' or 'preference learning' is a key step in <a href=\"http://intelligence.org/upload/CEV.html\">CEV</a>. Most work on preference elicitation has been done by economists. The state of the art in AI is summarized <a href=\"http://www.sciencedirect.com/science/article/pii/S000437021100049X\">here</a> and <a href=\"http://www2.cs.uh.edu/~ceick/ML/PL-Tutorial.pdf\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r2wRCvkjGARPiKG23", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 7.461563620560817e-07, "legacy": true, "legacyId": "8872", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T21:11:48.647Z", "modifiedAt": null, "url": null, "title": "What would you do if AI were dangerous?", "slug": "what-would-you-do-if-ai-were-dangerous", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.253Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W7eF6suyMpkhRqgry/what-would-you-do-if-ai-were-dangerous", "pageUrlRelative": "/posts/W7eF6suyMpkhRqgry/what-would-you-do-if-ai-were-dangerous", "linkUrl": "https://www.lesswrong.com/posts/W7eF6suyMpkhRqgry/what-would-you-do-if-ai-were-dangerous", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20would%20you%20do%20if%20AI%20were%20dangerous%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20would%20you%20do%20if%20AI%20were%20dangerous%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW7eF6suyMpkhRqgry%2Fwhat-would-you-do-if-ai-were-dangerous%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20would%20you%20do%20if%20AI%20were%20dangerous%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW7eF6suyMpkhRqgry%2Fwhat-would-you-do-if-ai-were-dangerous", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW7eF6suyMpkhRqgry%2Fwhat-would-you-do-if-ai-were-dangerous", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>If we knew how to build a machine that chooses its outputs as to maximize some property of the surrounding universe, such a machine would be very dangerous, because maximizing almost any easily defined property leads to a worthless universe (without humans, or with humans living pointless lives, etc.) I believe the preceding statement is uncontroversial, and most arguments around the necessity of Friendly AI are really about how likely we are to build such a machine, or maybe something else will happen first, etc.</p>\n<p>Instead of adding to the existing arguments, I want to reframe the question thus: what course of action <em>would</em> you recommend to a small group of smart people, <em>assuming</em> for the moment that the danger is real? In other words, what should SingInst do on an alternate Earth where normal human science will eventually build unfriendly AI?&nbsp;In particular:</p>\n<p>- How do you craft your message to the public?</p>\n<p>- What's your hiring policy?</p>\n<p>- Do you keep your research secret?</p>\n<p>- Do you pursue alternate avenues like uploads, or focus only on FAI?</p>\n<p>For the sake of inconvenience, assume that many (though not all) of the insights required for developing FAI can also be easily repurposed to hasten the arrival of UFAI.</p>\n<p>Thanks to Wei Dai for the conversation that sparked this post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W7eF6suyMpkhRqgry", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 7.463749642758824e-07, "legacy": true, "legacyId": "8875", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-26T23:50:44.020Z", "modifiedAt": null, "url": null, "title": "Against improper priors", "slug": "against-improper-priors", "viewCount": null, "lastCommentedAt": "2019-12-11T10:52:28.174Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielLC", "createdAt": "2009-12-26T17:34:50.257Z", "isAdmin": false, "displayName": "DanielLC"}, "userId": "3e6zTkDmDpNspRb8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hBBYHHemYWvzDxNyP/against-improper-priors", "pageUrlRelative": "/posts/hBBYHHemYWvzDxNyP/against-improper-priors", "linkUrl": "https://www.lesswrong.com/posts/hBBYHHemYWvzDxNyP/against-improper-priors", "postedAtFormatted": "Tuesday, July 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Against%20improper%20priors&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAgainst%20improper%20priors%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBBYHHemYWvzDxNyP%2Fagainst-improper-priors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Against%20improper%20priors%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBBYHHemYWvzDxNyP%2Fagainst-improper-priors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhBBYHHemYWvzDxNyP%2Fagainst-improper-priors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 554, "htmlBody": "<p>An <a href=\"http://en.wikipedia.org/wiki/Prior_probability#Improper_priors\">improper prior</a> is essentially a prior probability distribution that's infinitesimal over an infinite range, in order to add to one. For example, the uniform prior over all real numbers is an improper prior, as there would be an infinitesimal probability of getting a result in any finite range. It's common to use improper priors for when you have no prior information.</p>\n<p>The mark of a good prior is that it gives a high probability to the correct answer. If I bet 1,000,000 to one that a coin will land on heads, and it lands on tails, it could be a coincidence, but I probably had a bad prior. A good prior is one that results in me not being very surprised.</p>\n<p>With a proper prior, probability is conserved, and more probability mass in one place means less in another. If I'm less surprised when a coin lands on tails, I'm more surprised when it lands on heads. This isn't true with an improper prior. If I wanted to predict the value of a random real number, and used a normal distribution with a mean of zero and a standard deviation of one, I'd be pretty darn surprised if it doesn't end up being pretty close to zero, but I'd be infinitely surprised if I used a uniform distribution. No matter what the number is, it will be more surprising with the improper prior. Essentially, a proper prior is better in every way. (You could find exceptions for this, such as averaging a proper and improper prior to get an improper prior that still has finite probabilities and they just add up to 1/2, or by using a proper prior that has zero in some places, but you can always make a proper prior that's better in every way to a given improper prior).</p>\n<p>Dutch books also seems to be a popular way of showing what works and what doesn't, so here's a simple Dutch argument against improper priors: I have two real numbers: x and y. Suppose they have a uniform distribution. I offer you a bet at 1:2 odds that x has a higher magnitude. They're equally likely to be higher, so you take it. I then show you the value of x. I offer you a new bet at 100:1 odds that y has a higher magnitude. You know y almost definitely has a higher magnitude than that, so you take it again. No matter what happens, I win.</p>\n<p>You could try to get out of it by using a different prior, but I can just perform a transformation on it to get what I want. For example, if you choose a logarithmic prior for the magnitude, I can just take the magnitude of the log of the magnitude, and have a uniform distribution.</p>\n<p>There are certainly uses for an improper prior. You can use it if the evidence is so great compared to the difference between it and the correct value that it isn't worth worrying about. You can also use it if you're not sure what another person's prior is, and you want to give a result that is at least as high as they'd get no matter how much there prior is spread out. That said, an improper prior is never actually correct, even in things that you have literally no evidence for.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb108": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hBBYHHemYWvzDxNyP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 6, "extendedScore": null, "score": 7e-06, "legacy": true, "legacyId": "8876", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T02:30:35.680Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison", "slug": "meetup-madison", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.758Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6r8yNt9wfjH9LxZTy/meetup-madison", "pageUrlRelative": "/posts/6r8yNt9wfjH9LxZTy/meetup-madison", "linkUrl": "https://www.lesswrong.com/posts/6r8yNt9wfjH9LxZTy/meetup-madison", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6r8yNt9wfjH9LxZTy%2Fmeetup-madison%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6r8yNt9wfjH9LxZTy%2Fmeetup-madison", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6r8yNt9wfjH9LxZTy%2Fmeetup-madison", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1t'>Madison</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 August 2011 06:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1225 Regent St. Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>With the intent of being the first of many regular meetups, let's get together on Tuesday. I plan to conduct a few exercises on brainstorming, including the \"alternatives procedure\" that Anna Salamon taught at the rationality minicamp. Mostly, though: discussion, meeting people, and assigning names, faces and personalities to usernames.</p>\n\n<p>If you'd like to come but this time doesn't work for you, <em>say something</em>. I plan on doing this at least once every two weeks, so we should try to settle on a time that accommodates everyone in the long run.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1t'>Madison</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6r8yNt9wfjH9LxZTy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.464747771702361e-07, "legacy": true, "legacyId": "8880", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison\">Discussion article for the meetup : <a href=\"/meetups/1t\">Madison</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 August 2011 06:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1225 Regent St. Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>With the intent of being the first of many regular meetups, let's get together on Tuesday. I plan to conduct a few exercises on brainstorming, including the \"alternatives procedure\" that Anna Salamon taught at the rationality minicamp. Mostly, though: discussion, meeting people, and assigning names, faces and personalities to usernames.</p>\n\n<p>If you'd like to come but this time doesn't work for you, <em>say something</em>. I plan on doing this at least once every two weeks, so we should try to settle on a time that accommodates everyone in the long run.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison1\">Discussion article for the meetup : <a href=\"/meetups/1t\">Madison</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison", "anchor": "Discussion_article_for_the_meetup___Madison", "level": 1}, {"title": "Discussion article for the meetup : Madison", "anchor": "Discussion_article_for_the_meetup___Madison1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "12 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T03:05:33.563Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Scientific Evidence, Legal Evidence, Rational Evidence", "slug": "seq-rerun-scientific-evidence-legal-evidence-rational", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vhuQCghacKcFejheT/seq-rerun-scientific-evidence-legal-evidence-rational", "pageUrlRelative": "/posts/vhuQCghacKcFejheT/seq-rerun-scientific-evidence-legal-evidence-rational", "linkUrl": "https://www.lesswrong.com/posts/vhuQCghacKcFejheT/seq-rerun-scientific-evidence-legal-evidence-rational", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Scientific%20Evidence%2C%20Legal%20Evidence%2C%20Rational%20Evidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Scientific%20Evidence%2C%20Legal%20Evidence%2C%20Rational%20Evidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhuQCghacKcFejheT%2Fseq-rerun-scientific-evidence-legal-evidence-rational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Scientific%20Evidence%2C%20Legal%20Evidence%2C%20Rational%20Evidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhuQCghacKcFejheT%2Fseq-rerun-scientific-evidence-legal-evidence-rational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvhuQCghacKcFejheT%2Fseq-rerun-scientific-evidence-legal-evidence-rational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<p>Title: [SEQ RERUN] Scientific Evidence, Legal Evidence, Rational Evidence  Tags: sequence_reruns  Today's post, <a href=\"/lw/in/scientific_evidence_legal_evidence_rational/\">Scientific Evidence, Legal Evidence, Rational Evidence</a> was originally published on 19 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>For good social reasons, we require legal and scientific evidence to be more than just rational evidence. Hearsay is rational evidence, but as legal evidence it would invite abuse. Scientific evidence must be public and reproducible by everyone, because we want a pool of especially reliable beliefs. Thus, Science is about reproducible conditions, not the history of any one experiment.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6u2/seq_rerun_hindsight_devalues_science/\">Hindsight Devalues Science</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vhuQCghacKcFejheT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 7.464857262184306e-07, "legacy": true, "legacyId": "8883", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fhojYBGGiYAFcryHZ", "7ZXNLyMpYKK5ABkBo", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T03:09:18.130Z", "modifiedAt": null, "url": null, "title": "What's wrong with simplicity of value?", "slug": "what-s-wrong-with-simplicity-of-value", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:56.306Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4xWz3wW2JNfup6By6/what-s-wrong-with-simplicity-of-value", "pageUrlRelative": "/posts/4xWz3wW2JNfup6By6/what-s-wrong-with-simplicity-of-value", "linkUrl": "https://www.lesswrong.com/posts/4xWz3wW2JNfup6By6/what-s-wrong-with-simplicity-of-value", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20wrong%20with%20simplicity%20of%20value%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20wrong%20with%20simplicity%20of%20value%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xWz3wW2JNfup6By6%2Fwhat-s-wrong-with-simplicity-of-value%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20wrong%20with%20simplicity%20of%20value%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xWz3wW2JNfup6By6%2Fwhat-s-wrong-with-simplicity-of-value", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4xWz3wW2JNfup6By6%2Fwhat-s-wrong-with-simplicity-of-value", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>In the Wiki article on <a href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=Complexity_of_value\">complexity of value</a>, Eliezer wrote:</p>\n<blockquote>\n<p>The thesis that human values have high <a title=\"Kolmogorov complexity\" href=\"http://wiki.lesswrong.com/wiki/Kolmogorov_complexity\">Kolmogorov complexity</a> - our <a title=\"Preference\" href=\"http://wiki.lesswrong.com/wiki/Preference\">preferences</a>, the things we care about, <em>don't</em> compress down to one simple rule, or a few simple rules.</p>\n<p>[...]</p>\n<p><a class=\"external text\" rel=\"nofollow\" href=\"lw/l3/thou_art_godshatter/\">Thou Art Godshatter</a> describes the <a title=\"Evolutionary psychology\" href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">evolutionary psychology</a> behind the complexity of human values - how they got to be complex, and  why, given that origin, there is no reason in hindsight to expect them  to be simple.&nbsp;</p>\n</blockquote>\n<p>But in light of Yvain's recent series of posts (i.e., if we consider our \"actual\" values to be the values we would endorse in reflective equilibrium, instead of our current apparent values), I don't see any particular reason, whether from evolutionary psychology or elsewhere, that they must be complex either. Most of our apparent values (which admittedly are complex) could easily be <a href=\"/lw/6ha/the_blueminimizing_robot/\">mere behavior</a>, which we would discard after sufficient reflection.</p>\n<p>For those who might wish to defend the complexity-of-value thesis, what reasons do you have for thinking that human value is complex? Is it from an intuition that we should translate as many of our behaviors into preferences as possible? If other people do not have a similar intuition, or perhaps even have a strong intuition that values <em>should</em> be simple (and therefore would be more willing to discard things that are on the fuzzy border between behaviors and values), could they think that their values <em>are</em> simple, without being wrong?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xknvtHwqvqhwahW8Q": 1, "R6uagTfhhBeejGrrf": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4xWz3wW2JNfup6By6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 29, "extendedScore": null, "score": 6.3e-05, "legacy": true, "legacyId": "8884", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cSXZpvqpa9vbGGLtG", "hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T05:48:01.005Z", "modifiedAt": null, "url": null, "title": "How to enjoy being wrong", "slug": "how-to-enjoy-being-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.397Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lincolnquirk", "createdAt": "2011-03-25T20:46:17.071Z", "isAdmin": false, "displayName": "lincolnquirk"}, "userId": "ScJE7nuW8ti5kzfcA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mypWLfu2degMzCBTe/how-to-enjoy-being-wrong", "pageUrlRelative": "/posts/mypWLfu2degMzCBTe/how-to-enjoy-being-wrong", "linkUrl": "https://www.lesswrong.com/posts/mypWLfu2degMzCBTe/how-to-enjoy-being-wrong", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20enjoy%20being%20wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20enjoy%20being%20wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmypWLfu2degMzCBTe%2Fhow-to-enjoy-being-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20enjoy%20being%20wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmypWLfu2degMzCBTe%2Fhow-to-enjoy-being-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmypWLfu2degMzCBTe%2Fhow-to-enjoy-being-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1567, "htmlBody": "<p>Related to: <a href=\"/lw/1wu/reasoning_isnt_about_logic_its_about_arguing\" target=\"_blank\">Reasoning Isn't About Logic, It's About Arguing</a>; <a href=\"/lw/57c/it_is_ok_to_publicly_make_a_mistake_and_change\" target=\"_blank\">It is OK to Publicly Make a Mistake and Change Your Mind</a>.</p>\n<p><strong>Examples of being wrong</strong></p>\n<p>A year ago, in arguments or in thought, I would often:</p>\n<ul>\n<li>avoid criticizing my own thought processes or decisions when discussing why my startup failed</li>\n<li>overstate my expertise on a topic (how to design a program written in assembly language), then have to quickly justify a position and defend it based on limited knowledge and cached thoughts, rather than admitting \"I don't know\"</li>\n<li>defend a position (whether doing an MBA is worthwhile) based on the \"common wisdom\" of a group I identify with, without any actual knowledge, or having thought through it at all</li>\n<li>defend a position (whether a piece of artwork was good or bad) because of a desire for internal consistency (I argued it was good once, so felt I had to justify that position)</li>\n<li>defend a political or philosophical position (libertarianism) which seemed attractive, based on <a href=\"/lw/k5/cached_thoughts\" target=\"_blank\">cached thoughts</a> or <a href=\"/lw/4e/cached_selves\">cached selves</a> rather than actual reasoning</li>\n<li>defend a position (\"cashiers like it when I fish for coins to make a round amount of change\"), hear a very convincing argument for its opposite (\"it takes up their time, other customers are waiting, and they're better at making change than you\"), but continue arguing for the original position. In this scenario, I actually updated -- thereafter, I didn't fish for coins in my wallet anymore -- but still didn't admit it in the original argument.</li>\n<li>defend a policy (\"I should avoid albacore tuna\") even when the basis for that policy (mercury risk) has been countered by factual evidence (in this case, the amount of mercury per can is so small that you would need 10 cans per week to start reading on the scale).</li>\n<li>provide evidence for a proposition (\"I am getting better at poker\") where I actually thought it was just luck, but wanted to believe the proposition</li>\n<li>when someone asked \"why did you [do a weird action]?\", I would regularly attempt to justify the action in terms of reasons that \"made logical sense\", rather than admitting that I didn't know why I made a choice, or examining myself to find out why. </li>\n</ul>\n<p>Now, I very rarely get into these sorts of situations. If I do, I state out loud: \"Oh, I'm <a href=\"/lw/ju/rationalization\" target=\"_blank\">rationalizing</a>,\" or perhaps \"You're right,\" abort that line of thinking, and retreat to analyzing reasons why I emitted such a wrong statement. <br /> <br />We rationalize because we don't like admitting we're wrong. (Is this obvious? Do I need to cite it?) One possible evo-psych explanation: rationalization is an adaptation which improved fitness by making it easier for tribal humans to convince others to their point of view.<br /><br />Over the last year, I've self-modified to mostly not mind being wrong, and in some cases even enjoy being wrong. I still often start to rationalize, and in some cases get partway through the thought, before noticing the opportunity to correct the error. But when I notice that opportunity, I take it, and get a flood of positive feedback and self-satisfaction as I update my models.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>How I learned how to do this</strong><br /><br />The fishing-for-coins example given above was one which stood out to me retrospectively. Before I read any Less Wrong, I recognized it as an instance where I had updated my policy. But even after I updated, I had a negative affect about the argument because I remembered being wrong, and I wasn't introspective enough to notice and examine the negative affect.<br /> <br />I still believed that you should try to \"win\" an argument.<br /><br />Eventually I came across these Sequences posts: <a href=\"/lw/js/the_bottom_line\" target=\"_blank\">The Bottom Line</a> and <a href=\"/lw/ju/rationalization\" target=\"_blank\">Rationalization</a>. I recognized them as making an important point; they intuitively seemed like they would explain very much of my own past behavior in arguments. Cognitively, I began to understand that the purpose of an argument was to learn, not to win. But I continued to rationalize in most of the actual arguments I was having, because I didn't know how to recognize rationalization \"live\".<br /> <br />When applying to the Rationality Boot Camp, one of the questions on the application was to give an instance where you changed a policy. I came up with the fishing-for-coins example, and this time, I had positive feelings when remembering the instance, because of that cognitive update since reading the Sequences. I think this positive affect was me recognizing the pattern of rationalization, and understanding that it was good that I recognized it.<br /> <br />Due to the positive affect, I thought about the fishing-for-coins example some more, and imagined myself into that situation, specifically imagining the desire to rationalize even after my friend gave me that really compelling argument.<br /> <br />Now, I knew what rationalization felt like. <br /><br />At the Rationality Mega-Camp, one of the sessions was about noticing rationalization in an argument. We practiced actually rationalizing a few positions, then admitting we were rationalizing and actually coming to the right answer. This exercise felt somewhat artificial, but at the very least, it set up a social environment where people will applaud you for recognizing that you were rationalizing, and will sometimes call you out on it. Now, about once a day, I notice that I avoid getting into an argument where I don't have much information, and I notice active rationalization about once every two days.<br /> <br />The other thing we practiced is naming causes, not justifications. We attempt to distinguish between the causes of an action -- why you *really* do something -- and myriad justifications / rationalizations of the action, which are reasons you come up with after the fact for why it made logical sense to do a thing.<br /><br /><strong>How you can learn to recognize rationalization, and love to be wrong<br /> <br /></strong>These steps are based mostly on my personal experience. I don't know for sure that they'll work, but I suspect they will.<br /><br />You'll do this with a close friend or significant other. Ideally they're someone with whom you have had lots of frustrating arguments. It would be even better if it's someone who also wants to learn this skill.<br /> <br />First, read these Sequences: <a href=\"/lw/js/the_bottom_line\" target=\"_blank\">The Bottom Line</a> and <a href=\"/lw/ju/rationalization\" target=\"_blank\">Rationalization</a>. Be convinced that being right is desirable, and that coming up with post hoc reasons for something to be true is the opposite of being right: it's seeming right while being wrong; it's lying to yourself and deceiving others. It is very bad. (If you're not convinced of these points, I don't think I can help you any further.)<br /> <br />Next, take 10 minutes to write down memories of arguments you had with people where you didn't come to an agreement by the end. If possible, think of at least one argument with this friend, and at least one argument with someone else.<br /> <br />Next, take 10 minutes to write down instances from your personal life where you think you were probably rationalizing. (You can use the above arguments as examples of this, or come up with new examples.) Imagine these instances in as much explicit detail as possible. <br /> <br />Next, tell your friend about one of these instances. Describe how you were rationalizing, specifically what arguments you were using and why they were post-hoc justifications. Have your friend give you a hug, or high-five or something, to give a positive affect to the situation and condition yourself.<br /> <br />This step is optional, but it seems like it will often help: actually work out the true causes of your behavior, and admit them to your friend. It's OK to admit to status-seeking behavior, or self-serving behavior. Remember, this is your close friend and they've agreed to do the exercise with you. They will think <em>more</em> of you after you admit your true causes, because it will benefit them for you to be more introspective. Again with the hug or high-five.<br /> <br />Next, rehearse these statements, and apply them to your daily life:</p>\n<ul>\n<li>\"When I notice I'm about to get into an argument, remind myself about rationalizing.\"</li>\n<li>\"When I notice illogical behavior in myself, figure out its true causes.\"</li>\n<li>\"When someone else states a position, ask myself if they might be rationalizing.\"</li>\n<li>\"When I learn something which doesn't make sense, say '<a href=\"/lw/if/your_strength_as_a_rationalist/\">I notice I am confused</a>' out loud.\"</li>\n<li>\"When someone else seems upset in an argument, ask myself if they might be rationalizing.\"</li>\n<li>\"When I notice rationalization in myself, say 'I was rationalizing' out loud.\"</li>\n<li>\"When I notice I've updated, say 'I was wrong' out loud.\"</li>\n<li>\"When I say 'I was rationalizing', ask for a high five or give myself a high five.\"</li>\n<li>\"When I say 'I was wrong', ask for a high five or give myself a high five.\"</li>\n</ul>\n<p>At the very least, read these out loud to your partner. If you want to go further, you could try using <a href=\"http://ankisrs.net/\" target=\"_blank\">Anki</a> to learn these statements by heart.<br /><br />And let me know in the comments how it goes.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mypWLfu2degMzCBTe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 30, "extendedScore": null, "score": 7.465364511709938e-07, "legacy": true, "legacyId": "8888", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zNawPJRktcJGWrtt9", "QmqP8FeQix5ebseyF", "2MD3NMLBPCqPfnfre", "BHYBdijDcAKQ6e45Z", "SFZoEBpLo9frSJGkc", "34XxbRFe54FycoCDw", "5JDkW4MYXit2CquLs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T08:19:17.866Z", "modifiedAt": null, "url": null, "title": "If your Cryonicism would be Movie Topic, would you go with it? (Real Issue)", "slug": "if-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:56.635Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SHCaqiq9yWPc7x4GL/if-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "pageUrlRelative": "/posts/SHCaqiq9yWPc7x4GL/if-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "linkUrl": "https://www.lesswrong.com/posts/SHCaqiq9yWPc7x4GL/if-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20If%20your%20Cryonicism%20would%20be%20Movie%20Topic%2C%20would%20you%20go%20with%20it%3F%20(Real%20Issue)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIf%20your%20Cryonicism%20would%20be%20Movie%20Topic%2C%20would%20you%20go%20with%20it%3F%20(Real%20Issue)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSHCaqiq9yWPc7x4GL%2Fif-your-cryonicism-would-be-movie-topic-would-you-go-with-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=If%20your%20Cryonicism%20would%20be%20Movie%20Topic%2C%20would%20you%20go%20with%20it%3F%20(Real%20Issue)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSHCaqiq9yWPc7x4GL%2Fif-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSHCaqiq9yWPc7x4GL%2Fif-your-cryonicism-would-be-movie-topic-would-you-go-with-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 377, "htmlBody": "<p>Today this girl I met comes to my place, allegedly to get some books about her new interests, singularity, immortalism, cryonics.</p>\n<p>Actually, she wanted to ask me a question, a question about which I could use some rational opinion.</p>\n<p>She says: \"So, here is the real reason I came here. I'm thinking of making a documentary, a movie, and it would be about, well.... about you.\"</p>\n<p>(I am shocked)</p>\n<p>\"So, yes, a movie about you, and the fact that you want to live forever, it would have interviews with friends, parents, girlfriend, and a lot with you\" \"What do you think?\"&nbsp;</p>\n<p>(I sit down in the floor to think about it)</p>\n<p>The conversation continues and I generally sense she wants to do something interesting, somewhat controversial, kind of humoristic, but at the same time striking some topics that are really unheard of around here (Brazil)</p>\n<p>Now, I am looking for opinions. From an utilitarian perspective, and given that I am directing the Humanity+ or Transhumanist group of Brazilians, should I go with it?&nbsp;&nbsp; My concern is basically not about me, but about how will a movie about me influence, positively or negatively, the growing H+ movement in Brazil, given the inferential distances, prejudices, and mysterianism that might surround the whole interaction between the movie's memes, and the spectator's memes.&nbsp;</p>\n<p>(from here below, the translation is google tradutor, not mine)</p>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">Positive aspects:</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">The film would be</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">seen</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">at festivals</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">and</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">at least</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">a few hundred</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">to</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">tens</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">of thousands</span>&nbsp;of p<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">eople would see it.</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">These</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">people might be&nbsp;</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">intrigued by the</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">prospect of living</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">much,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">and it</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">could become</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">a</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">platform</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">for&nbsp;</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">attracting</span>&nbsp;people to&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">transhumanismolatino (and eventually to other stuff, like GWWC and Singinst, but that is a side dish)</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">.</span></span></span></h6>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">It would be</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">a</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">good opportunity to</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">bring out</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">various issues</span>&nbsp;that&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">in Brazil</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">have been neglected</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">until now</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">.</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">(</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">cryonics</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">transhumanism</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">biological immortality</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">, singularity</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">)</span></span></span></h6>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">Reinforce</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">my</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">good habits</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">, like eating</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">healthily,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">work more</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">earnestly,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">etc ...</span></span></span></h6>\n<h6></h6>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">Negative aspects</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">: it may</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">end up passing</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">a</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">bad</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">image of me</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">(imagine</span>&nbsp;the mythical average person, not that smart, somewhat religious,&nbsp;&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">seeing</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">a</span>&nbsp;&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">guy who wants to</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">live forever</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">in a video,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">is&nbsp;</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">very strange</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">) and</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">therefore</span>&nbsp;my bad image would spread to stuff I represent, like the Provisional Team, the Singularity Institute, Transhumanismo Latino, etc......</span></span></h6>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">May defame</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">my image</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">with women</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">(who</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">would date</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">an immortalist</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">after all</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">.....)</span></span></span></h6>\n<h6><span class=\"Apple-style-span\" style=\"border-collapse: separate; color: #000000; font-family: 'Times New Roman'; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; font-size: medium;\"><span class=\"Apple-style-span\" style=\"border-collapse: collapse; color: #333333; font-family: arial,sans-serif; font-size: 16px;\"><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">&nbsp;I may</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">become a</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">stigma</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">simplified</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">I</span>&nbsp; would&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">just be</span>&nbsp;classified as&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">an immortalist</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">, and</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">no other characteristics</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">will ever</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">cross the</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">knowledge of people</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">, they always</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">see me&nbsp;</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">just like that</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">.</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">And the institutions</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">that I represent</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">/</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">drive,</span>&nbsp;<span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">would suffer&nbsp;</span><span title=\"Clique para mostrar tradu&ccedil;&otilde;es alternativas\">accordingly.</span></span></span></h6>\n<p>I have put up a poll in the comment section down here, so that I can know your opinion, please take the time to vote, thank you.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SHCaqiq9yWPc7x4GL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 15, "extendedScore": null, "score": 7.465839849339813e-07, "legacy": true, "legacyId": "8892", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T11:22:37.313Z", "modifiedAt": null, "url": null, "title": "[LINK] Videos from FHI's Winter Intelligence Conference", "slug": "link-videos-from-fhi-s-winter-intelligence-conference", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.789Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "vallinder", "createdAt": "2011-03-14T11:52:07.333Z", "isAdmin": false, "displayName": "vallinder"}, "userId": "onAYNLtS8wFHFH6k5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P6iKJ3Gsy6bGvKqih/link-videos-from-fhi-s-winter-intelligence-conference", "pageUrlRelative": "/posts/P6iKJ3Gsy6bGvKqih/link-videos-from-fhi-s-winter-intelligence-conference", "linkUrl": "https://www.lesswrong.com/posts/P6iKJ3Gsy6bGvKqih/link-videos-from-fhi-s-winter-intelligence-conference", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Videos%20from%20FHI's%20Winter%20Intelligence%20Conference&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Videos%20from%20FHI's%20Winter%20Intelligence%20Conference%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6iKJ3Gsy6bGvKqih%2Flink-videos-from-fhi-s-winter-intelligence-conference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Videos%20from%20FHI's%20Winter%20Intelligence%20Conference%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6iKJ3Gsy6bGvKqih%2Flink-videos-from-fhi-s-winter-intelligence-conference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6iKJ3Gsy6bGvKqih%2Flink-videos-from-fhi-s-winter-intelligence-conference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 9, "htmlBody": "<p>Available <a href=\"http://vimeo.com/user1646158/videos\">here</a>. Speakers include Eliezer Yudkowsky and Nick Bostrom.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P6iKJ3Gsy6bGvKqih", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.466414102554291e-07, "legacy": true, "legacyId": "8893", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T16:05:37.559Z", "modifiedAt": null, "url": null, "title": "Locating emotions", "slug": "locating-emotions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.286Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JMuPZYCTqqu27L2XQ/locating-emotions", "pageUrlRelative": "/posts/JMuPZYCTqqu27L2XQ/locating-emotions", "linkUrl": "https://www.lesswrong.com/posts/JMuPZYCTqqu27L2XQ/locating-emotions", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Locating%20emotions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALocating%20emotions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJMuPZYCTqqu27L2XQ%2Flocating-emotions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Locating%20emotions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJMuPZYCTqqu27L2XQ%2Flocating-emotions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJMuPZYCTqqu27L2XQ%2Flocating-emotions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<p>It's important that we understand how our emotions work. Sometimes emotions give us valuable information, and sometimes our emotions don't behave the way we want them to. A prerequisite for individually understanding anything about our emotions is the ability to notice and identify emotions. I sometimes find this difficult.</p>\n<p>One piece of advice I get is to notice where different emotions are felt in my body. <a href=\"http://www.emotionallyvague.com/results_02.php\">A graphic designer asked 250 people to draw where they feel different emotions, and superimposed the drawings.</a> The results are evocative.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JMuPZYCTqqu27L2XQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.467300751614558e-07, "legacy": true, "legacyId": "8894", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T18:19:45.839Z", "modifiedAt": null, "url": null, "title": "[LINK] Father of Cryonics \"Dies\" at age 92", "slug": "link-father-of-cryonics-dies-at-age-92", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:54.719Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JackEmpty", "createdAt": "2011-03-14T10:42:25.519Z", "isAdmin": false, "displayName": "JackEmpty"}, "userId": "4Jj3x57cMrKFq7Awy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mhbpwbpx69md5GtwE/link-father-of-cryonics-dies-at-age-92", "pageUrlRelative": "/posts/mhbpwbpx69md5GtwE/link-father-of-cryonics-dies-at-age-92", "linkUrl": "https://www.lesswrong.com/posts/mhbpwbpx69md5GtwE/link-father-of-cryonics-dies-at-age-92", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Father%20of%20Cryonics%20%22Dies%22%20at%20age%2092&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Father%20of%20Cryonics%20%22Dies%22%20at%20age%2092%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmhbpwbpx69md5GtwE%2Flink-father-of-cryonics-dies-at-age-92%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Father%20of%20Cryonics%20%22Dies%22%20at%20age%2092%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmhbpwbpx69md5GtwE%2Flink-father-of-cryonics-dies-at-age-92", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmhbpwbpx69md5GtwE%2Flink-father-of-cryonics-dies-at-age-92", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5, "htmlBody": "<p><a href=\"http://www.dailytech.com/Father+of+Cryonics+Dies+at+92+Frozen+in+Cryonics+Institute+/article22273.htm\">http://www.dailytech.com/Father+of+Cryonics+Dies+at+92+Frozen+in+Cryonics+Institute+/article22273.htm</a></p>\r\n<p>&nbsp;</p>\r\n<p>Via Hacker News (comments: <a href=\"http://news.ycombinator.com/item?id=2813021\">http://news.ycombinator.com/item?id=2813021</a>)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1, "ZnHkaTkxukegSrZqE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mhbpwbpx69md5GtwE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": -1, "extendedScore": null, "score": 7.467721069616169e-07, "legacy": true, "legacyId": "8896", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T21:57:09.481Z", "modifiedAt": null, "url": null, "title": "New Post version 1 (please read this ONLY if your last name beings with a\u2013k)", "slug": "new-post-version-1-please-read-this-only-if-your-last-name", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:32.438Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CMSaT7sv96C4jWN2J/new-post-version-1-please-read-this-only-if-your-last-name", "pageUrlRelative": "/posts/CMSaT7sv96C4jWN2J/new-post-version-1-please-read-this-only-if-your-last-name", "linkUrl": "https://www.lesswrong.com/posts/CMSaT7sv96C4jWN2J/new-post-version-1-please-read-this-only-if-your-last-name", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20Post%20version%201%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20a%E2%80%93k)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20Post%20version%201%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20a%E2%80%93k)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCMSaT7sv96C4jWN2J%2Fnew-post-version-1-please-read-this-only-if-your-last-name%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20Post%20version%201%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20a%E2%80%93k)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCMSaT7sv96C4jWN2J%2Fnew-post-version-1-please-read-this-only-if-your-last-name", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCMSaT7sv96C4jWN2J%2Fnew-post-version-1-please-read-this-only-if-your-last-name", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1642, "htmlBody": "<p><strong>Note</strong>:&nbsp;I am testing two versions of my new post on rationality and romance.</p>\n<p>Please upvote, downvote, or non-vote the below post as you normally would if you saw it on the front page (not the discussion section), but <em>do not</em>&nbsp;vote on the other version. Also, if your last name begins&nbsp;with a&ndash;k, please read and vote on&nbsp;<em>this</em>&nbsp;post first. If your last name begins with l&ndash;z, please stop reading and read <a href=\"/r/discussion/lw/6v5/new_post_version_2_please_read_this_only_if_your/\">this version</a> instead.&nbsp;</p>\n<p>&nbsp;</p>\n<h2>Rationality Lessons from Romance</h2>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>She told me later: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because she hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only one man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>This is an account of some lessons that I learned during my journey into rational romance. That journey started with a series of realizations like the one above &mdash; that I wasn't happy with the standard cultural scripts: monogamy, an assumed progression toward marriage, and ownership of another person's sexuality. I hadn't really noticed the cultural scripts up until that point. I was a victim of <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a> and a <a href=\"/lw/4e/cached_selves/\">cached self</a>.</p>\n<p><em>Lesson</em>: Until you explicitly notice the cached rules for what you're doing, you won't start thinking of them as something to be optimized. Ask: Which parts of romance do you currently think of as subjects of optimization? What else should you be optimizing?</p>\n<p>&nbsp;</p>\n<h4>Gather data</h4>\n<p>At the time, I didn't know how to optimize. I decided I needed data. How did relationships work? How did women work? How did attraction work? The value of information was high, so I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. I began to spend less time with Alice so I could spend more time studying.&nbsp;</p>\n<p><em>Lesson</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Once you notice you might be running in the wrong direction, don't keep going that way just because you've got momentum. Stop a moment, and invest some energy in the thoughts or information you've now realized is valuable because it might change your policies, i.e., figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4>Sanity-check yourself</h4>\n<p>Before long, I noticed that Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;I was unhappy, and I knew I could one day attract better mates if I had time to acquire the skills that other men had; men who were \"good with women.\"</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I thought she would appreciate this because she had previously expressed admiration for detailed honesty.</p>\n<p>She asked that I kindly never speak to her again. I can't blame her. In retrospect, it's hard to think of a <em>more</em>&nbsp;damaging way to break up with someone. This gives you some idea of just how incompetent I was, at the time. I had an inkling of that myself - though I'm not sure if I realized right away, or if it only dawned on me six months later. But it was part of the motivation to solve my problems by reading books.</p>\n<p><em>Lesson</em>: Know your fields of incompetence. If you suspect you may be incompetent, sanity-check yourself by asking others for advice, or by Googling. (E.g. \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\", or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.)</p>\n<p>&nbsp;</p>\n<h4>Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate.</p>\n<p>Neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! It's not that women prefer jerks to nice guys, but they prefer confident, ambitious men to pushovers.\"</li>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women are attracted to men with whom they have positive <em>subjective experiences</em>. That's why they like funny guys, for example!\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant <em>head</em> knowledge than any guy I knew.</p>\n<p><em>Lesson</em>: Use <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to gain a certain class of experience points.</p>\n<p>&nbsp;</p>\n<h4>Just try it / just test yourself</h4>\n<p>Scholarship was warm and comfy, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows that newbie mistakes (and subsequent rejections) would lay upon my ego.</p>\n<p><em>Lesson</em>: Be especially suspicious of <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a> for not obeying the empiricist rules \"try it and see what happens\" or \"test yourself to see what happens\" or \"get some concrete experience on the ground\". Think of the cost of time happening as a result of rationalizing. Consider the opportunities you are missing if you don't just realize you're wrong right <em>now</em>.</p>\n<p>&nbsp;</p>\n<h4>Use science, and maybe drugs</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried swallowing <a href=\"http://www.ejbrandy.com/\">brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books:</p>\n<ul>\n<li>Politics, religion, math, and programming are basically&nbsp;<em>never</em>&nbsp;the right subject matter when flirting.</li>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>'Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally <em>works</em> &mdash; as long as the other person is already attracted because my body language, fashion, and other signals have been optimized.</li>\n<li>People rarely notice an abrupt change of subject if you say \"Yeah, it's just like when...\" and then say something completely unrelated.</li>\n</ul>\n<p>After a while, I could talk to women even without the brandy. And a little after that, I had my first one-night stand.</p>\n<p>I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I didn't feel engaged when I didn't know and didn't have much in common with the girl in my bed. But I kept having casual flings, mostly for their educational value. As research projects go, I guess they weren't too bad.</p>\n<p><em>Lesson</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4>Self-modify to succeed</h4>\n<p>By this time my misgivings about the idea of owning another's sexuality had grown into a full-blown endorsement of polyamory. I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I built a mutual attraction with a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Lesson</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that you haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not by popular opinion.</p>\n<p>&nbsp;</p>\n<h4>Finale</h4>\n<p>I now enjoy higher-quality relationships &mdash; sexual and non-sexual &mdash; of a kind that wouldn't be possible with the social skills of Luke<sub>2005</sub>. I went for years without a partner I cared about, but it felt okay because the whole journey was seeded with frequent rewards: the thrill of figuring something out, the thrill of seeing people respond to me in a new way, the thrill of seeing myself looking better in the mirror each month.</p>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm seeing an awesome poly girl, I'm free to take up other relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, and I can build rapport with almost anyone. My hair looks great and I'm happy. If you start out as a nerd, setting out to become a nerd about romance totally works, so long as you read the right nerd books and you know the nerd rule about being empirical. Rationality for the win.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 2, "fkABsGCJZ6y9qConW": 2, "3uE2pXvbcnS9nnZRE": 2, "irYLXtT9hkPXoZqhH": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CMSaT7sv96C4jWN2J", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 69, "baseScore": 39, "extendedScore": null, "score": 7.6e-05, "legacy": true, "legacyId": "8691", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Note</strong>:&nbsp;I am testing two versions of my new post on rationality and romance.</p>\n<p>Please upvote, downvote, or non-vote the below post as you normally would if you saw it on the front page (not the discussion section), but <em>do not</em>&nbsp;vote on the other version. Also, if your last name begins&nbsp;with a\u2013k, please read and vote on&nbsp;<em>this</em>&nbsp;post first. If your last name begins with l\u2013z, please stop reading and read <a href=\"/r/discussion/lw/6v5/new_post_version_2_please_read_this_only_if_your/\">this version</a> instead.&nbsp;</p>\n<p>&nbsp;</p>\n<h2 id=\"Rationality_Lessons_from_Romance\">Rationality Lessons from Romance</h2>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>She told me later: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because she hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only one man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>This is an account of some lessons that I learned during my journey into rational romance. That journey started with a series of realizations like the one above \u2014 that I wasn't happy with the standard cultural scripts: monogamy, an assumed progression toward marriage, and ownership of another person's sexuality. I hadn't really noticed the cultural scripts up until that point. I was a victim of <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a> and a <a href=\"/lw/4e/cached_selves/\">cached self</a>.</p>\n<p><em>Lesson</em>: Until you explicitly notice the cached rules for what you're doing, you won't start thinking of them as something to be optimized. Ask: Which parts of romance do you currently think of as subjects of optimization? What else should you be optimizing?</p>\n<p>&nbsp;</p>\n<h4 id=\"Gather_data\">Gather data</h4>\n<p>At the time, I didn't know how to optimize. I decided I needed data. How did relationships work? How did women work? How did attraction work? The value of information was high, so I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. I began to spend less time with Alice so I could spend more time studying.&nbsp;</p>\n<p><em>Lesson</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Once you notice you might be running in the wrong direction, don't keep going that way just because you've got momentum. Stop a moment, and invest some energy in the thoughts or information you've now realized is valuable because it might change your policies, i.e., figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4 id=\"Sanity_check_yourself\">Sanity-check yourself</h4>\n<p>Before long, I noticed that Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;I was unhappy, and I knew I could one day attract better mates if I had time to acquire the skills that other men had; men who were \"good with women.\"</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I thought she would appreciate this because she had previously expressed admiration for detailed honesty.</p>\n<p>She asked that I kindly never speak to her again. I can't blame her. In retrospect, it's hard to think of a <em>more</em>&nbsp;damaging way to break up with someone. This gives you some idea of just how incompetent I was, at the time. I had an inkling of that myself - though I'm not sure if I realized right away, or if it only dawned on me six months later. But it was part of the motivation to solve my problems by reading books.</p>\n<p><em>Lesson</em>: Know your fields of incompetence. If you suspect you may be incompetent, sanity-check yourself by asking others for advice, or by Googling. (E.g. \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\", or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.)</p>\n<p>&nbsp;</p>\n<h4 id=\"Study\">Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate.</p>\n<p>Neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! It's not that women prefer jerks to nice guys, but they prefer confident, ambitious men to pushovers.\"</li>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women are attracted to men with whom they have positive <em>subjective experiences</em>. That's why they like funny guys, for example!\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant <em>head</em> knowledge than any guy I knew.</p>\n<p><em>Lesson</em>: Use <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to gain a certain class of experience points.</p>\n<p>&nbsp;</p>\n<h4 id=\"Just_try_it___just_test_yourself\">Just try it / just test yourself</h4>\n<p>Scholarship was warm and comfy, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows that newbie mistakes (and subsequent rejections) would lay upon my ego.</p>\n<p><em>Lesson</em>: Be especially suspicious of <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a> for not obeying the empiricist rules \"try it and see what happens\" or \"test yourself to see what happens\" or \"get some concrete experience on the ground\". Think of the cost of time happening as a result of rationalizing. Consider the opportunities you are missing if you don't just realize you're wrong right <em>now</em>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Use_science__and_maybe_drugs\">Use science, and maybe drugs</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried swallowing <a href=\"http://www.ejbrandy.com/\">brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books:</p>\n<ul>\n<li>Politics, religion, math, and programming are basically&nbsp;<em>never</em>&nbsp;the right subject matter when flirting.</li>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>'Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally <em>works</em> \u2014 as long as the other person is already attracted because my body language, fashion, and other signals have been optimized.</li>\n<li>People rarely notice an abrupt change of subject if you say \"Yeah, it's just like when...\" and then say something completely unrelated.</li>\n</ul>\n<p>After a while, I could talk to women even without the brandy. And a little after that, I had my first one-night stand.</p>\n<p>I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I didn't feel engaged when I didn't know and didn't have much in common with the girl in my bed. But I kept having casual flings, mostly for their educational value. As research projects go, I guess they weren't too bad.</p>\n<p><em>Lesson</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Self_modify_to_succeed\">Self-modify to succeed</h4>\n<p>By this time my misgivings about the idea of owning another's sexuality had grown into a full-blown endorsement of polyamory. I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I built a mutual attraction with a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Lesson</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that you haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not by popular opinion.</p>\n<p>&nbsp;</p>\n<h4 id=\"Finale\">Finale</h4>\n<p>I now enjoy higher-quality relationships \u2014 sexual and non-sexual \u2014 of a kind that wouldn't be possible with the social skills of Luke<sub>2005</sub>. I went for years without a partner I cared about, but it felt okay because the whole journey was seeded with frequent rewards: the thrill of figuring something out, the thrill of seeing people respond to me in a new way, the thrill of seeing myself looking better in the mirror each month.</p>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm seeing an awesome poly girl, I'm free to take up other relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, and I can build rapport with almost anyone. My hair looks great and I'm happy. If you start out as a nerd, setting out to become a nerd about romance totally works, so long as you read the right nerd books and you know the nerd rule about being empirical. Rationality for the win.</p>", "sections": [{"title": "Rationality Lessons from Romance", "anchor": "Rationality_Lessons_from_Romance", "level": 1}, {"title": "Gather data", "anchor": "Gather_data", "level": 2}, {"title": "Sanity-check yourself", "anchor": "Sanity_check_yourself", "level": 2}, {"title": "Study", "anchor": "Study", "level": 2}, {"title": "Just try it / just test yourself", "anchor": "Just_try_it___just_test_yourself", "level": 2}, {"title": "Use science, and maybe drugs", "anchor": "Use_science__and_maybe_drugs", "level": 2}, {"title": "Self-modify to succeed", "anchor": "Self_modify_to_succeed", "level": 2}, {"title": "Finale", "anchor": "Finale", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "87 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 87, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aYfjK9oHuTcYqwBvp", "2MD3NMLBPCqPfnfre", "BHYBdijDcAKQ6e45Z", "64FdKLwmea8MCLWkE", "37sHjeisS9uJufi4u", "K82evF2iRAiRWwvyn", "hY86FhYysQ7dBg3d8", "Zmfo388RA9oky3KYe", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-27T21:57:13.928Z", "modifiedAt": null, "url": null, "title": "New Post version 2 (please read this ONLY if your last name beings with l\u2013z)", "slug": "new-post-version-2-please-read-this-only-if-your-last-name", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:32.044Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aYfjK9oHuTcYqwBvp/new-post-version-2-please-read-this-only-if-your-last-name", "pageUrlRelative": "/posts/aYfjK9oHuTcYqwBvp/new-post-version-2-please-read-this-only-if-your-last-name", "linkUrl": "https://www.lesswrong.com/posts/aYfjK9oHuTcYqwBvp/new-post-version-2-please-read-this-only-if-your-last-name", "postedAtFormatted": "Wednesday, July 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20Post%20version%202%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20l%E2%80%93z)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20Post%20version%202%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20l%E2%80%93z)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYfjK9oHuTcYqwBvp%2Fnew-post-version-2-please-read-this-only-if-your-last-name%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20Post%20version%202%20(please%20read%20this%20ONLY%20if%20your%20last%20name%20beings%20with%20l%E2%80%93z)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYfjK9oHuTcYqwBvp%2Fnew-post-version-2-please-read-this-only-if-your-last-name", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaYfjK9oHuTcYqwBvp%2Fnew-post-version-2-please-read-this-only-if-your-last-name", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1429, "htmlBody": "<p><strong>Note</strong>: I am testing two versions of my new post on rationality and romance.</p>\n<p>Please upvote, downvote, or non-vote the below post as you normally would if you saw it on the front page (not the discussion section), but&nbsp;<em>do not</em>&nbsp;vote on the other version. Also, if your last name begins&nbsp;with l&ndash;z, please read and vote on&nbsp;<em>this</em>&nbsp;post first. If your last name begins with a&ndash;k, please stop reading and read <a href=\"/r/discussion/lw/6pf/new_post_version_1_please_read_this_only_if_your/\">this version</a> instead.&nbsp;</p>\n<p>&nbsp;</p>\n<h2 style=\"font-size: 16px; color: black; float: none;\">Rationality Lessons from Romance</h2>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>She told me later: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because she hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only one man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>And thus began my journey toward rational romance &mdash; not at that exact moment, but with a series of realizations like that about monogamy, about the assumed progression toward marriage, about the ownership of another person's sexuality, etc. I began to explicitly notice the cultural scripts and see that they might not be optimal for me.</p>\n<p><em>Rationality Skill</em>: Notice&nbsp;when things are suboptimal. Think of ways to <a href=\"/lw/tx/optimization/\">optimize</a> them.</p>\n<p>&nbsp;</p>\n<h4>Gather data</h4>\n<p>But I didn't know how to optimize. I needed data. How did relationships work? How did women work? How did attraction work? I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. The value of information was high. I began to spend less time with Alice so I could spend more time studying.&nbsp;</p>\n<p><em>Rationality Skill</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Don't keep running in what is probably the wrong direction just because you've got momentum. Stop a moment, and invest some energy in figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4>Sanity-check yourself</h4>\n<p>Before long, I noticed that Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;I was unhappy, and I knew I could one day attract better mates if I had time to acquire the skills that other men had; men who were \"good with women.\"</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I <em>thought</em> she would appreciate this because she had previously expressed admiration for detailed honesty. Later, I realized how hard it is to think of a <em>more</em>&nbsp;damaging way to break up with someone.</p>\n<p>She asked that I kindly never speak to her again. I can't blame her.</p>\n<p><em>Rationality Skill</em>: Know your fields of incompetence. Sanity-check yourself by asking others for advice, or by Googling \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\" or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.</p>\n<p>&nbsp;</p>\n<h4>Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate. But learning.</p>\n<p>Alas, neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! It's not that women prefer jerks to nice guys, but they prefer confident, ambitious men to pushovers.\"</li>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women are attracted to men who make them <em>feel</em>&nbsp;certain ways and have positive <em>subjective experiences</em>. That's why they like funny guys, for example!\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant head knowledge than any guy I knew.</p>\n<p><em>Rationalist Skill</em>: <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">Scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to level up.</p>\n<p>&nbsp;</p>\n<h4>Avoid rationalization</h4>\n<p>Scholarship was comfortable, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows that newbie mistakes (and subsequent rejections) would lay upon my ego.</p>\n<p><em>Rationalist Skill</em>: Notice <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a>&nbsp;and defeat them: Consider the cost of time and trust happening as a result of rationalizing. Consider what opportunities you are missing if you don't just realize you're wrong right <em>now</em>.</p>\n<p>&nbsp;</p>\n<h4>Use science</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried <a href=\"http://www.ejbrandy.com/\">E&amp;J brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books:</p>\n<ul>\n<li>Politics, religion, math, and programming are basically&nbsp;<em>never</em>&nbsp;the right subject matter when flirting.</li>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>'Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally works when the girl is already attracted because my body language, fashion, and other signals have been optimized.</li>\n<li>People rarely notice an abrupt change of subject if you say \"Yeah, it's just like when...\" and then say something completely unrelated.</li>\n</ul>\n<p>After a while, I could talk to girls even without the brandy. And a little after that, I scored my first one-night stand.</p>\n<p>I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I wasn't very engaged when I didn't know and didn't have much in common with the girl in my bed. But I kept having casual flings, mostly for their educational value. As research projects go, I guess they weren't too bad.</p>\n<p><em>Rationalist Skill</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4>Try harder</h4>\n<p>By this time my misgivings about the idea of owning another's sexuality had grown into a full-blown endorsement of polyamory. I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I grew a mutual attraction with a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Rationality Skill</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that we haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not popular opinion.</p>\n<p>&nbsp;</p>\n<h4>Finale</h4>\n<p>I now enjoy higher-quality relationships &mdash;&nbsp;sexual and non-sexual &mdash;&nbsp;of a kind that wouldn't be possible with the social skills of Luke<sub>2005</sub>. I went for years without a partner I cared about, but that's okay because the whole journey was planted with frequent rewards: the thrill of figuring something out, the thrill of seeing people respond to me in a new way, the thrill of seeing myself looking better in the mirror each month.</p>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm <em>actually</em> seeing an awesome poly girl, I'm free to take up other relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, I can build rapport with almost anyone, my hair looks great and I'm happy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aYfjK9oHuTcYqwBvp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 14, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "8897", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Note</strong>: I am testing two versions of my new post on rationality and romance.</p>\n<p>Please upvote, downvote, or non-vote the below post as you normally would if you saw it on the front page (not the discussion section), but&nbsp;<em>do not</em>&nbsp;vote on the other version. Also, if your last name begins&nbsp;with l\u2013z, please read and vote on&nbsp;<em>this</em>&nbsp;post first. If your last name begins with a\u2013k, please stop reading and read <a href=\"/r/discussion/lw/6pf/new_post_version_1_please_read_this_only_if_your/\">this version</a> instead.&nbsp;</p>\n<p>&nbsp;</p>\n<h2 style=\"font-size: 16px; color: black; float: none;\" id=\"Rationality_Lessons_from_Romance\">Rationality Lessons from Romance</h2>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>She told me later: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because she hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only one man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>And thus began my journey toward rational romance \u2014 not at that exact moment, but with a series of realizations like that about monogamy, about the assumed progression toward marriage, about the ownership of another person's sexuality, etc. I began to explicitly notice the cultural scripts and see that they might not be optimal for me.</p>\n<p><em>Rationality Skill</em>: Notice&nbsp;when things are suboptimal. Think of ways to <a href=\"/lw/tx/optimization/\">optimize</a> them.</p>\n<p>&nbsp;</p>\n<h4 id=\"Gather_data\">Gather data</h4>\n<p>But I didn't know how to optimize. I needed data. How did relationships work? How did women work? How did attraction work? I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. The value of information was high. I began to spend less time with Alice so I could spend more time studying.&nbsp;</p>\n<p><em>Rationality Skill</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Don't keep running in what is probably the wrong direction just because you've got momentum. Stop a moment, and invest some energy in figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4 id=\"Sanity_check_yourself\">Sanity-check yourself</h4>\n<p>Before long, I noticed that Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;I was unhappy, and I knew I could one day attract better mates if I had time to acquire the skills that other men had; men who were \"good with women.\"</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I <em>thought</em> she would appreciate this because she had previously expressed admiration for detailed honesty. Later, I realized how hard it is to think of a <em>more</em>&nbsp;damaging way to break up with someone.</p>\n<p>She asked that I kindly never speak to her again. I can't blame her.</p>\n<p><em>Rationality Skill</em>: Know your fields of incompetence. Sanity-check yourself by asking others for advice, or by Googling \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\" or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.</p>\n<p>&nbsp;</p>\n<h4 id=\"Study\">Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate. But learning.</p>\n<p>Alas, neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! It's not that women prefer jerks to nice guys, but they prefer confident, ambitious men to pushovers.\"</li>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women are attracted to men who make them <em>feel</em>&nbsp;certain ways and have positive <em>subjective experiences</em>. That's why they like funny guys, for example!\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant head knowledge than any guy I knew.</p>\n<p><em>Rationalist Skill</em>: <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">Scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to level up.</p>\n<p>&nbsp;</p>\n<h4 id=\"Avoid_rationalization\">Avoid rationalization</h4>\n<p>Scholarship was comfortable, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows that newbie mistakes (and subsequent rejections) would lay upon my ego.</p>\n<p><em>Rationalist Skill</em>: Notice <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a>&nbsp;and defeat them: Consider the cost of time and trust happening as a result of rationalizing. Consider what opportunities you are missing if you don't just realize you're wrong right <em>now</em>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Use_science\">Use science</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried <a href=\"http://www.ejbrandy.com/\">E&amp;J brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books:</p>\n<ul>\n<li>Politics, religion, math, and programming are basically&nbsp;<em>never</em>&nbsp;the right subject matter when flirting.</li>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>'Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally works when the girl is already attracted because my body language, fashion, and other signals have been optimized.</li>\n<li>People rarely notice an abrupt change of subject if you say \"Yeah, it's just like when...\" and then say something completely unrelated.</li>\n</ul>\n<p>After a while, I could talk to girls even without the brandy. And a little after that, I scored my first one-night stand.</p>\n<p>I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I wasn't very engaged when I didn't know and didn't have much in common with the girl in my bed. But I kept having casual flings, mostly for their educational value. As research projects go, I guess they weren't too bad.</p>\n<p><em>Rationalist Skill</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Try_harder\">Try harder</h4>\n<p>By this time my misgivings about the idea of owning another's sexuality had grown into a full-blown endorsement of polyamory. I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I grew a mutual attraction with a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Rationality Skill</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that we haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not popular opinion.</p>\n<p>&nbsp;</p>\n<h4 id=\"Finale\">Finale</h4>\n<p>I now enjoy higher-quality relationships \u2014&nbsp;sexual and non-sexual \u2014&nbsp;of a kind that wouldn't be possible with the social skills of Luke<sub>2005</sub>. I went for years without a partner I cared about, but that's okay because the whole journey was planted with frequent rewards: the thrill of figuring something out, the thrill of seeing people respond to me in a new way, the thrill of seeing myself looking better in the mirror each month.</p>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm <em>actually</em> seeing an awesome poly girl, I'm free to take up other relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, I can build rapport with almost anyone, my hair looks great and I'm happy.</p>", "sections": [{"title": "Rationality Lessons from Romance", "anchor": "Rationality_Lessons_from_Romance", "level": 1}, {"title": "Gather data", "anchor": "Gather_data", "level": 2}, {"title": "Sanity-check yourself", "anchor": "Sanity_check_yourself", "level": 2}, {"title": "Study", "anchor": "Study", "level": 2}, {"title": "Avoid rationalization", "anchor": "Avoid_rationalization", "level": 2}, {"title": "Use science", "anchor": "Use_science", "level": 2}, {"title": "Try harder", "anchor": "Try_harder", "level": 2}, {"title": "Finale", "anchor": "Finale", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "186 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 186, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CMSaT7sv96C4jWN2J", "D7EcMhL26zFNbJ3ED", "64FdKLwmea8MCLWkE", "37sHjeisS9uJufi4u", "K82evF2iRAiRWwvyn", "hY86FhYysQ7dBg3d8", "Zmfo388RA9oky3KYe", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T00:37:23.371Z", "modifiedAt": null, "url": null, "title": "Meetup : Irvine Meetup Wednesday August 3", "slug": "meetup-irvine-meetup-wednesday-august-3", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/55JbAmXd7o6D9uGJc/meetup-irvine-meetup-wednesday-august-3", "pageUrlRelative": "/posts/55JbAmXd7o6D9uGJc/meetup-irvine-meetup-wednesday-august-3", "linkUrl": "https://www.lesswrong.com/posts/55JbAmXd7o6D9uGJc/meetup-irvine-meetup-wednesday-august-3", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20August%203&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Irvine%20Meetup%20Wednesday%20August%203%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F55JbAmXd7o6D9uGJc%2Fmeetup-irvine-meetup-wednesday-august-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Irvine%20Meetup%20Wednesday%20August%203%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F55JbAmXd7o6D9uGJc%2Fmeetup-irvine-meetup-wednesday-august-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F55JbAmXd7o6D9uGJc%2Fmeetup-irvine-meetup-wednesday-august-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1u'>Irvine Meetup Wednesday August 3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 August 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>.</p>\n\n<p>See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1u'>Irvine Meetup Wednesday August 3</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "55JbAmXd7o6D9uGJc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.46890457474725e-07, "legacy": true, "legacyId": "8898", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_August_3\">Discussion article for the meetup : <a href=\"/meetups/1u\">Irvine Meetup Wednesday August 3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 August 2011 06:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">4187 Campus Dr, University Center, Irvine, CA 92612</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This continues the weekly meetups in Irvine. As always the meetup at the outdoor food court in the <a href=\"http://maps.google.com/maps?ie=UTF8&amp;ll=33.650288,-117.838666&amp;spn=0.001684,0.002363&amp;t=h&amp;z=19\" rel=\"nofollow\">University Center near UCI</a>, from 6:00 to 8:00 (or whenever we actually decide to leave). Look for the sign with <a href=\"http://lesswrong.com/lw/nn/neural_categories/\">naive neural classifiers for bleggs and rubes</a>.</p>\n\n<p>See also the <a href=\"http://groups.google.com/group/LW-SoCal-Announce?pli=1\" rel=\"nofollow\">email group</a> and <a href=\"https://www.google.com/calendar/embed?src=h57ej586rdo3jmld14hrk51m1c%40group.calendar.google.com&amp;ctz=America/Los_Angeles\" rel=\"nofollow\">calendar</a> for the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California Meetup Group</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_August_31\">Discussion article for the meetup : <a href=\"/meetups/1u\">Irvine Meetup Wednesday August 3</a></h2>", "sections": [{"title": "Discussion article for the meetup : Irvine Meetup Wednesday August 3", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_August_3", "level": 1}, {"title": "Discussion article for the meetup : Irvine Meetup Wednesday August 3", "anchor": "Discussion_article_for_the_meetup___Irvine_Meetup_Wednesday_August_31", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yFDKvfN6D87Tf5J9f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T02:24:00.286Z", "modifiedAt": null, "url": null, "title": "Looking for proof of conditional probability", "slug": "looking-for-proof-of-conditional-probability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:04.792Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielLC", "createdAt": "2009-12-26T17:34:50.257Z", "isAdmin": false, "displayName": "DanielLC"}, "userId": "3e6zTkDmDpNspRb8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RXkch4EMK7T29Bbxv/looking-for-proof-of-conditional-probability", "pageUrlRelative": "/posts/RXkch4EMK7T29Bbxv/looking-for-proof-of-conditional-probability", "linkUrl": "https://www.lesswrong.com/posts/RXkch4EMK7T29Bbxv/looking-for-proof-of-conditional-probability", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20for%20proof%20of%20conditional%20probability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20for%20proof%20of%20conditional%20probability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRXkch4EMK7T29Bbxv%2Flooking-for-proof-of-conditional-probability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20for%20proof%20of%20conditional%20probability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRXkch4EMK7T29Bbxv%2Flooking-for-proof-of-conditional-probability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRXkch4EMK7T29Bbxv%2Flooking-for-proof-of-conditional-probability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<p>From what I understand, the <a href=\"http://en.wikipedia.org/wiki/Probability_axioms\">Kolmogorov axioms</a> make no mention of conditional probability. That is simply <a href=\"http://en.wikipedia.org/wiki/Probability_axioms\"><a href=\"http://en.wikipedia.org/wiki/Conditional_probability#Definition\">defined</a></a>. If I really want to show how probability actually works, I'm not going to <a href=\"/lw/nz/arguing_by_definition/\">argue \"by definition\"</a>. Does anyone know a modified form that uses simpler axioms than P(A|B) = P(A&cap;B)/P(B)?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RXkch4EMK7T29Bbxv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 1, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "8904", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cFzC996D7Jjds3vS9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T03:36:55.048Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Is Molecular Nanotechnology \"Scientific\"?", "slug": "seq-rerun-is-molecular-nanotechnology-scientific", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rLCAFqRt2N3mARF7k/seq-rerun-is-molecular-nanotechnology-scientific", "pageUrlRelative": "/posts/rLCAFqRt2N3mARF7k/seq-rerun-is-molecular-nanotechnology-scientific", "linkUrl": "https://www.lesswrong.com/posts/rLCAFqRt2N3mARF7k/seq-rerun-is-molecular-nanotechnology-scientific", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Is%20Molecular%20Nanotechnology%20%22Scientific%22%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Is%20Molecular%20Nanotechnology%20%22Scientific%22%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrLCAFqRt2N3mARF7k%2Fseq-rerun-is-molecular-nanotechnology-scientific%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Is%20Molecular%20Nanotechnology%20%22Scientific%22%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrLCAFqRt2N3mARF7k%2Fseq-rerun-is-molecular-nanotechnology-scientific", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrLCAFqRt2N3mARF7k%2Fseq-rerun-is-molecular-nanotechnology-scientific", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>Title: [SEQ RERUN] Is Molecular Nanotechnology \"Scientific\"?  Tags: sequence_reruns  Today's post, <a href=\"/lw/io/is_molecular_nanotechnology_scientific/\">Is Molecular Nanotechnology \"Scientific\"?</a> was originally published on 20 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>The belief that nanotechnology is possible is based on qualitative reasoning from scientific knowledge. But such a belief is merely rational. It will not be scientific until someone constructs a nanofactory. Yet if you claim that nanomachines are impossible because they have never been seen before, you are being irrational. To think that everything that is not science is pseudoscience is a severe mistake.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/6ur/seq_rerun_scientific_evidence_legal_evidence/#comments\">Scientific Evidence, Legal Evidence, Rational Evidence</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rLCAFqRt2N3mARF7k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.469467343539206e-07, "legacy": true, "legacyId": "8907", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XKcawbsB6Tj5e2QRK", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T12:14:04.204Z", "modifiedAt": null, "url": null, "title": "[LINK] Hyperbolic discounting is rational", "slug": "link-hyperbolic-discounting-is-rational", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "twanvl", "createdAt": "2009-07-23T14:08:02.633Z", "isAdmin": false, "displayName": "twanvl"}, "userId": "tSciHLMSqaRcuX4ym", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tH8bBKCvfdjBKMDqt/link-hyperbolic-discounting-is-rational", "pageUrlRelative": "/posts/tH8bBKCvfdjBKMDqt/link-hyperbolic-discounting-is-rational", "linkUrl": "https://www.lesswrong.com/posts/tH8bBKCvfdjBKMDqt/link-hyperbolic-discounting-is-rational", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Hyperbolic%20discounting%20is%20rational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Hyperbolic%20discounting%20is%20rational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtH8bBKCvfdjBKMDqt%2Flink-hyperbolic-discounting-is-rational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Hyperbolic%20discounting%20is%20rational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtH8bBKCvfdjBKMDqt%2Flink-hyperbolic-discounting-is-rational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtH8bBKCvfdjBKMDqt%2Flink-hyperbolic-discounting-is-rational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>I just came across a paper that shows that hyperbolic discounting <em>is</em> the right thing to do when future discount rates are uncertain. Here is a link to the paper:</p>\n<p><a href=\"http://cowles.econ.yale.edu/P/cd/d17a/d1719.pdf\">Hyperbolic discounting is rational: Valuing the far future with uncertain discount rates<br />by J. Doyne Farmer and John Geanakoplos</a></p>\n<p>And <a href=\"http://physicsoffinance.blogspot.com/2011/07/discountingdetails.html\">here is a really nice writeup</a>, which saves me from having to summarize the results myself.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tH8bBKCvfdjBKMDqt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "8910", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T13:03:32.535Z", "modifiedAt": null, "url": null, "title": "[LINK] Scientists use Bayesian reasoning to update the drake equation for the existence of ET's", "slug": "link-scientists-use-bayesian-reasoning-to-update-the-drake", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tetsuo55", "createdAt": "2011-05-28T17:16:39.492Z", "isAdmin": false, "displayName": "tetsuo55"}, "userId": "wuYeqAN7TWZErmuM9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3FwJPkGktahSBnW7g/link-scientists-use-bayesian-reasoning-to-update-the-drake", "pageUrlRelative": "/posts/3FwJPkGktahSBnW7g/link-scientists-use-bayesian-reasoning-to-update-the-drake", "linkUrl": "https://www.lesswrong.com/posts/3FwJPkGktahSBnW7g/link-scientists-use-bayesian-reasoning-to-update-the-drake", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Scientists%20use%20Bayesian%20reasoning%20to%20update%20the%20drake%20equation%20for%20the%20existence%20of%20ET's&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Scientists%20use%20Bayesian%20reasoning%20to%20update%20the%20drake%20equation%20for%20the%20existence%20of%20ET's%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FwJPkGktahSBnW7g%2Flink-scientists-use-bayesian-reasoning-to-update-the-drake%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Scientists%20use%20Bayesian%20reasoning%20to%20update%20the%20drake%20equation%20for%20the%20existence%20of%20ET's%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FwJPkGktahSBnW7g%2Flink-scientists-use-bayesian-reasoning-to-update-the-drake", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FwJPkGktahSBnW7g%2Flink-scientists-use-bayesian-reasoning-to-update-the-drake", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>I found this pop-science news article where scientist are seriously trying to use&nbsp;Bayesian&nbsp;reasoning to change beliefs of the field.</p>\n<p>&nbsp;</p>\n<p><a href=\"http://www.physorg.com/news/2011-07-astrophysicists-logic-downplay-probability-extraterrestrial.html\">http://www.physorg.com/news/2011-07-astrophysicists-logic-downplay-probability-extraterrestrial.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3FwJPkGktahSBnW7g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.471244044772796e-07, "legacy": true, "legacyId": "8911", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T13:09:00.395Z", "modifiedAt": null, "url": null, "title": "[LINK] A proposed update model for working memory: multiple-component framework", "slug": "link-a-proposed-update-model-for-working-memory-multiple", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tetsuo55", "createdAt": "2011-05-28T17:16:39.492Z", "isAdmin": false, "displayName": "tetsuo55"}, "userId": "wuYeqAN7TWZErmuM9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3MXvYjg24FxAjBuZh/link-a-proposed-update-model-for-working-memory-multiple", "pageUrlRelative": "/posts/3MXvYjg24FxAjBuZh/link-a-proposed-update-model-for-working-memory-multiple", "linkUrl": "https://www.lesswrong.com/posts/3MXvYjg24FxAjBuZh/link-a-proposed-update-model-for-working-memory-multiple", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20A%20proposed%20update%20model%20for%20working%20memory%3A%20multiple-component%20framework&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20A%20proposed%20update%20model%20for%20working%20memory%3A%20multiple-component%20framework%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MXvYjg24FxAjBuZh%2Flink-a-proposed-update-model-for-working-memory-multiple%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20A%20proposed%20update%20model%20for%20working%20memory%3A%20multiple-component%20framework%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MXvYjg24FxAjBuZh%2Flink-a-proposed-update-model-for-working-memory-multiple", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MXvYjg24FxAjBuZh%2Flink-a-proposed-update-model-for-working-memory-multiple", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>I've seen some discussion on \"working memory\" and \"spaced repetition\"</p>\n<p>I just read this pop-science article in which a new hypothesis is presented that seems to provide better predictions and test conditions for measuring working memory. Maybe this can also be used for the SRS contest.</p>\n<p>&nbsp;</p>\n<p><span style=\"font-family: Arial, Helvetica, Sans;\"><span style=\"font-size: 15px; line-height: 18px;\"><a href=\"http://medicalxpress.com/news/2011-07-brain-track.html\">http://medicalxpress.com/news/2011-07-brain-track.html</a></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5d63AWNjtFyHprX2k": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3MXvYjg24FxAjBuZh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.471261182257907e-07, "legacy": true, "legacyId": "8912", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T17:37:53.973Z", "modifiedAt": null, "url": null, "title": "Looking speakers on ML/AI topics in NYC area", "slug": "looking-speakers-on-ml-ai-topics-in-nyc-area", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RPZ8jYSSmq4oadzZX/looking-speakers-on-ml-ai-topics-in-nyc-area", "pageUrlRelative": "/posts/RPZ8jYSSmq4oadzZX/looking-speakers-on-ml-ai-topics-in-nyc-area", "linkUrl": "https://www.lesswrong.com/posts/RPZ8jYSSmq4oadzZX/looking-speakers-on-ml-ai-topics-in-nyc-area", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looking%20speakers%20on%20ML%2FAI%20topics%20in%20NYC%20area&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooking%20speakers%20on%20ML%2FAI%20topics%20in%20NYC%20area%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPZ8jYSSmq4oadzZX%2Flooking-speakers-on-ml-ai-topics-in-nyc-area%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looking%20speakers%20on%20ML%2FAI%20topics%20in%20NYC%20area%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPZ8jYSSmq4oadzZX%2Flooking-speakers-on-ml-ai-topics-in-nyc-area", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRPZ8jYSSmq4oadzZX%2Flooking-speakers-on-ml-ai-topics-in-nyc-area", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<p>Sorry if this is spammish, but since there are quite a few ML/AI people here I figured I'd ask.</p>\n<p>I co-organize well-attended NYC Machine Learning Meetup and we're always looking for speakers, so if anyone is in the area and has something they'd like to present, message me.</p>\n<p>We are specifically looking for speakers for August, but can book people for later months.</p>\n<p>If someone wants to speak on FAI related topics, they'd be welcome as long as they are a serious researcher (vs. as an extreme example a high school student passionate about the topic).&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RPZ8jYSSmq4oadzZX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.472104584726304e-07, "legacy": true, "legacyId": "8913", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T17:57:51.872Z", "modifiedAt": null, "url": null, "title": "LW in BusinessInsider", "slug": "lw-in-businessinsider", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.516Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xgfSSSnd6pxYCeJi7/lw-in-businessinsider", "pageUrlRelative": "/posts/xgfSSSnd6pxYCeJi7/lw-in-businessinsider", "linkUrl": "https://www.lesswrong.com/posts/xgfSSSnd6pxYCeJi7/lw-in-businessinsider", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20in%20BusinessInsider&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20in%20BusinessInsider%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxgfSSSnd6pxYCeJi7%2Flw-in-businessinsider%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20in%20BusinessInsider%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxgfSSSnd6pxYCeJi7%2Flw-in-businessinsider", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxgfSSSnd6pxYCeJi7%2Flw-in-businessinsider", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.businessinsider.com/ten-things-you-should-learn-from-lesswrongcom-2011-7\">http://www.businessinsider.com/ten-things-you-should-learn-from-lesswrongcom-2011-7</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xgfSSSnd6pxYCeJi7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 7.4721672129263e-07, "legacy": true, "legacyId": "8914", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T19:10:26.870Z", "modifiedAt": null, "url": null, "title": "Am I obligated to reread the Book of Mormon?", "slug": "am-i-obligated-to-reread-the-book-of-mormon", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.205Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ytNR2cG5LdnQTWmEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nD8SSEXcLMNCSciKb/am-i-obligated-to-reread-the-book-of-mormon", "pageUrlRelative": "/posts/nD8SSEXcLMNCSciKb/am-i-obligated-to-reread-the-book-of-mormon", "linkUrl": "https://www.lesswrong.com/posts/nD8SSEXcLMNCSciKb/am-i-obligated-to-reread-the-book-of-mormon", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Am%20I%20obligated%20to%20reread%20the%20Book%20of%20Mormon%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAm%20I%20obligated%20to%20reread%20the%20Book%20of%20Mormon%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnD8SSEXcLMNCSciKb%2Fam-i-obligated-to-reread-the-book-of-mormon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Am%20I%20obligated%20to%20reread%20the%20Book%20of%20Mormon%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnD8SSEXcLMNCSciKb%2Fam-i-obligated-to-reread-the-book-of-mormon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnD8SSEXcLMNCSciKb%2Fam-i-obligated-to-reread-the-book-of-mormon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 154, "htmlBody": "<p>In <a href=\"/lw/jr/how_to_convince_me_that_2_2_3/4keb\">this comment thread</a>, I stated that</p>\n<blockquote>\n<p>I have read the Book of Mormon in the past, but I hereby precommit to reading it again and \"searching in my heart\" (I have a copy on my bookshelf) if you can demonstrate that my skepticism regarding your evidence is unwarranted.</p>\n</blockquote>\n<p>In the resulting thread five evidences were given, and some back-and-forth occurred. Being myself somewhat biased, I feel unfit to judge if Arandur actually showed that a non-Mormon's skepticism is unwarranted.</p>\n<p>So you, who wish to become stronger, I ask: please comment below whether or not you believe the proposition was satisfied.</p>\n<p>Remember! This is not a vote on whether the evidence is factually correct or not!</p>\n<p>Remember! This is not a chance to anonymously signal your agreement or disagreement with the LW hive mind!</p>\n<p>Remember! If the sky is green, wish to believe that the sky is green!</p>\n<p>I don't know what else I can say to forestall thread hijacking.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nD8SSEXcLMNCSciKb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 6, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "8915", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T21:46:16.099Z", "modifiedAt": null, "url": null, "title": "Wiki Clean-up project", "slug": "wiki-clean-up-project", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.615Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "minderbinder", "createdAt": "2011-07-20T16:48:05.262Z", "isAdmin": false, "displayName": "minderbinder"}, "userId": "SPcZb9HWJg5nsvt4E", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Sf779fwbxs3gqCXDz/wiki-clean-up-project", "pageUrlRelative": "/posts/Sf779fwbxs3gqCXDz/wiki-clean-up-project", "linkUrl": "https://www.lesswrong.com/posts/Sf779fwbxs3gqCXDz/wiki-clean-up-project", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wiki%20Clean-up%20project&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWiki%20Clean-up%20project%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSf779fwbxs3gqCXDz%2Fwiki-clean-up-project%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wiki%20Clean-up%20project%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSf779fwbxs3gqCXDz%2Fwiki-clean-up-project", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSf779fwbxs3gqCXDz%2Fwiki-clean-up-project", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<p>I'm a fairly new LW user, as evidenced by my so-far low karma. However, I've previously been familiar with a lot of the ideas talked about here and I've been reading the site for a few weeks. I think that the material here is amazing and often unparalleled on the rest of the web.&nbsp;</p>\n<p>However, there's is one...weak point: the wiki. The sequences are a little bit formidable to beginners because of the massive tangle of hyperlinks which connect them together. When I started reading them, I routinely had 10-15 LW tabs open at once. My friends said a similar thing. Thus, I think that it would be helpful to have a reliable source of information where the recursion can sort of \"bottom out,\" if you know what I mean. That should be the wiki.</p>\n<p>But it's in a pretty sorry state right now. A lot of the articles are titles-only, a couple sentences long, or just a bunch of links which invariably lead to more links. Maybe I'm blowing this out of proportion, but I think that the wiki is something that could definitely be brought up to par with the (high) quality of the site.</p>\n<p>So maybe several members should choose something they know about (or perhaps don't) and then research and write a good entry on it.&nbsp;</p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Sf779fwbxs3gqCXDz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 7.472883760827958e-07, "legacy": true, "legacyId": "8917", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-28T23:24:08.546Z", "modifiedAt": null, "url": null, "title": "The danger of wishful thinking", "slug": "the-danger-of-wishful-thinking", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:56.552Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WvivqLA5oggwnEY8E/the-danger-of-wishful-thinking", "pageUrlRelative": "/posts/WvivqLA5oggwnEY8E/the-danger-of-wishful-thinking", "linkUrl": "https://www.lesswrong.com/posts/WvivqLA5oggwnEY8E/the-danger-of-wishful-thinking", "postedAtFormatted": "Thursday, July 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20danger%20of%20wishful%20thinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20danger%20of%20wishful%20thinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWvivqLA5oggwnEY8E%2Fthe-danger-of-wishful-thinking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20danger%20of%20wishful%20thinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWvivqLA5oggwnEY8E%2Fthe-danger-of-wishful-thinking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWvivqLA5oggwnEY8E%2Fthe-danger-of-wishful-thinking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1103, "htmlBody": "<p>Or \"The problems inherent in making a goal maximiser with a changing world model.\"</p>\n<p>No paper clips were created or destroyed in the making of this script.</p>\n<p>*This is an experimental post to try and get <a href=\"/r/discussion/lw/6uj/what_would_you_do_if_ai_were_dangerous/4kbw\">this point across</a>. I'll write something similar for the type of systems I would like to explore, if this goes down well.*</p>\n<p>Goal maximisers are great when you have a fixed ontology and you only have limited ways of getting information about the world. These aren't the case in AGI. Remember the <a href=\"http://wiki.lesswrong.com/wiki/The_map_is_not_the_territory\">map is not the territory</a>, and the map is all that the utility maximiser can look at when deciding the utility of the future of actions.</p>\n<p>TL;DR You can't have a utility maximiser choose how to alter the world model or how the world model should progress, if the utility is derived from that world model. If you have something else derive the world model it will conflict with the utility maximiser over resources and what to do in the world. Some method of resolving the conflicts is necessary which means we must go beyond normal model based utility maximisers.</p>\n<p><a id=\"more\"></a></p>\n<h4>Scene 1: Beyond the reach</h4>\n<p>&nbsp;</p>\n<p>A group of anthropomorphic paper clips are crowded in a room. There are two machines in there with them. One connected to the window, draws paper clips on a large central map when it spies them outside. The other scans the map for paper clips, updating a big brass counter to the number of unique paper clips on the map. &nbsp;The paper clips send and receive messages to the outside world in pneumatic tubes.</p>\n<p>Junior clippy: Good news everyone, we have got word that we have managed to create 100 paper clips just beyond our light cone! &nbsp;</p>\n<p>Middle ranking clippy: Update the map at once! We will never see these paper clips but we should get the utilons for their creation.</p>\n<p>Senior clippy: Belay that, only the fixed machinery is allowed to touch the paper. By all that is metallic, flattened and spiral-shaped, do you know what madness will be unleashed if we updated the map based upon what we wish?</p>\n<p>Middle ranking clippy (aside to the junior): Ignore the old codger. Jump to it! If we can't update the map, then we will stop caring about creating paper clips that we cannot or are unlikely to see. That will not do.</p>\n<p>Junior clippy (aside to the audience as he draws in the extra paper clips): This gives me an idea....</p>\n<p>*The junior clippy sneakily starts to draw extra paper clips, smirking to himself as the utilon counter goes up and up and up. Fade to black as the group wire-head themselves and the Ur paper clipper builds another machine in the background*</p>\n<h4>Scene 1.5: Trombone de Bureau</h4>\n<p>The clippies have a new map editor, this takes in messages in English from the outside world and edits the map to represent the changes made. It is a vast machine somehow capable of spotting all lies.</p>\n<p>&nbsp;</p>\n<p>Junior clippy: Good news everyone, we have got word from our French counter parts that they will be creating 100 paper clips just beyond our observable universe! &nbsp;</p>\n<p>Middle ranking clippy: Update the map at once! We will never see these paper clips and our new fangled machine won't understand the message in French, but we should get the utilons for their creation.</p>\n<p>Senior clippy: Belay that, only the fixed machinery is allowed to touch the paper. By all that is metallic, flattened and spiral-shaped, do you know what madness will be unleashed if we updated the map based upon what we wish?</p>\n<p>Middle ranking clippy (aside to the junior): Ignore the old codger. Jump to it! If we can't update the map, then we will stop caring about creating paper clips the French make, or that we only see or read about and not echo locate. That will not do. As we can't update the map now just translate the French note into English and feed it into the machine</p>\n<p>Junior clippy (aside to the audience as he draws in the extra paper clips): This gives me an idea....&nbsp;</p>\n<div>*The junior paper clip starts to write many notes in English about non-existent paper clips, and slips them into the machine.*</div>\n<h4>Scene 2: The Accurites</h4>\n<p>The clippys have been joined by some Accurites. They have their own counter that looks at the map and compares it against the territory, assigning Accurons if the map correctly predicts the territory. This group cares not one jot about paper clips and are allowed to update the map, but cannot send messages out into the world. An argument is currently ongoing between the two groups.</p>\n<p>Accurite Colonel: We demand that allow us more space in the room and more pens. We need to create more of us so that we can correctly capture the number and position of the leaves on the tree and predict where they will be so that we can get more accurons.</p>\n<p>Senior Clippy: Sorry we can't spare any, we need the space for more of us so we can better improve our updateless decision theory of counter factual staple manufacturers. Besides that why are you wasting your time with leaves? They aren't at all important. Stop wasting our time with trivialities. We need you to update the map about the position of the Hooman fleet that is tearing through Alpha Centauri, so that we can defend against it.</p>\n<p>Accurite Scientist: If you don't mind I'll handle this one sir. That would be an inefficient use of resources for the acquisition of accurons. Hoomans are a lot less predictable than leaves so the pay off would be worse. Also now that you mention the Hooman threat, why did you destroy the communication relay with Sirius? We were starting to get reports of paper clips having been destroyed and we would like to know how many to remove from the map.</p>\n<p>Senior Clippy: If we kept listening in, our utilons would have decreased! Why would we do that?</p>\n<p>Accurite Scientist: About that, we have come to understand the true mathematical essence of paper clips and we will no longer be representing them in the same way on the map. We've upgraded the utilon machine to read them as well, our simulations suggest that it will be counting 10% fewer paper clips for eternity due to the grand unified theory of paper fastening. I hope you don't mind.</p>\n<p>*The clippies burst into apoplectic rage and start hurling bits of furniture and invectives at the Accurites. The Accurites are a bit nonplussed by this state of affairs bit swiftly regain their composure and battle is joined. So involved are both factions, that they don't notice a Hooman eye looming outside the window.*</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WvivqLA5oggwnEY8E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -6, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "8919", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Or \"The problems inherent in making a goal maximiser with a changing world model.\"</p>\n<p>No paper clips were created or destroyed in the making of this script.</p>\n<p>*This is an experimental post to try and get <a href=\"/r/discussion/lw/6uj/what_would_you_do_if_ai_were_dangerous/4kbw\">this point across</a>. I'll write something similar for the type of systems I would like to explore, if this goes down well.*</p>\n<p>Goal maximisers are great when you have a fixed ontology and you only have limited ways of getting information about the world. These aren't the case in AGI. Remember the <a href=\"http://wiki.lesswrong.com/wiki/The_map_is_not_the_territory\">map is not the territory</a>, and the map is all that the utility maximiser can look at when deciding the utility of the future of actions.</p>\n<p>TL;DR You can't have a utility maximiser choose how to alter the world model or how the world model should progress, if the utility is derived from that world model. If you have something else derive the world model it will conflict with the utility maximiser over resources and what to do in the world. Some method of resolving the conflicts is necessary which means we must go beyond normal model based utility maximisers.</p>\n<p><a id=\"more\"></a></p>\n<h4 id=\"Scene_1__Beyond_the_reach\">Scene 1: Beyond the reach</h4>\n<p>&nbsp;</p>\n<p>A group of anthropomorphic paper clips are crowded in a room. There are two machines in there with them. One connected to the window, draws paper clips on a large central map when it spies them outside. The other scans the map for paper clips, updating a big brass counter to the number of unique paper clips on the map. &nbsp;The paper clips send and receive messages to the outside world in pneumatic tubes.</p>\n<p>Junior clippy: Good news everyone, we have got word that we have managed to create 100 paper clips just beyond our light cone! &nbsp;</p>\n<p>Middle ranking clippy: Update the map at once! We will never see these paper clips but we should get the utilons for their creation.</p>\n<p>Senior clippy: Belay that, only the fixed machinery is allowed to touch the paper. By all that is metallic, flattened and spiral-shaped, do you know what madness will be unleashed if we updated the map based upon what we wish?</p>\n<p>Middle ranking clippy (aside to the junior): Ignore the old codger. Jump to it! If we can't update the map, then we will stop caring about creating paper clips that we cannot or are unlikely to see. That will not do.</p>\n<p>Junior clippy (aside to the audience as he draws in the extra paper clips): This gives me an idea....</p>\n<p>*The junior clippy sneakily starts to draw extra paper clips, smirking to himself as the utilon counter goes up and up and up. Fade to black as the group wire-head themselves and the Ur paper clipper builds another machine in the background*</p>\n<h4 id=\"Scene_1_5__Trombone_de_Bureau\">Scene 1.5: Trombone de Bureau</h4>\n<p>The clippies have a new map editor, this takes in messages in English from the outside world and edits the map to represent the changes made. It is a vast machine somehow capable of spotting all lies.</p>\n<p>&nbsp;</p>\n<p>Junior clippy: Good news everyone, we have got word from our French counter parts that they will be creating 100 paper clips just beyond our observable universe! &nbsp;</p>\n<p>Middle ranking clippy: Update the map at once! We will never see these paper clips and our new fangled machine won't understand the message in French, but we should get the utilons for their creation.</p>\n<p>Senior clippy: Belay that, only the fixed machinery is allowed to touch the paper. By all that is metallic, flattened and spiral-shaped, do you know what madness will be unleashed if we updated the map based upon what we wish?</p>\n<p>Middle ranking clippy (aside to the junior): Ignore the old codger. Jump to it! If we can't update the map, then we will stop caring about creating paper clips the French make, or that we only see or read about and not echo locate. That will not do. As we can't update the map now just translate the French note into English and feed it into the machine</p>\n<p>Junior clippy (aside to the audience as he draws in the extra paper clips): This gives me an idea....&nbsp;</p>\n<div>*The junior paper clip starts to write many notes in English about non-existent paper clips, and slips them into the machine.*</div>\n<h4 id=\"Scene_2__The_Accurites\">Scene 2: The Accurites</h4>\n<p>The clippys have been joined by some Accurites. They have their own counter that looks at the map and compares it against the territory, assigning Accurons if the map correctly predicts the territory. This group cares not one jot about paper clips and are allowed to update the map, but cannot send messages out into the world. An argument is currently ongoing between the two groups.</p>\n<p>Accurite Colonel: We demand that allow us more space in the room and more pens. We need to create more of us so that we can correctly capture the number and position of the leaves on the tree and predict where they will be so that we can get more accurons.</p>\n<p>Senior Clippy: Sorry we can't spare any, we need the space for more of us so we can better improve our updateless decision theory of counter factual staple manufacturers. Besides that why are you wasting your time with leaves? They aren't at all important. Stop wasting our time with trivialities. We need you to update the map about the position of the Hooman fleet that is tearing through Alpha Centauri, so that we can defend against it.</p>\n<p>Accurite Scientist: If you don't mind I'll handle this one sir. That would be an inefficient use of resources for the acquisition of accurons. Hoomans are a lot less predictable than leaves so the pay off would be worse. Also now that you mention the Hooman threat, why did you destroy the communication relay with Sirius? We were starting to get reports of paper clips having been destroyed and we would like to know how many to remove from the map.</p>\n<p>Senior Clippy: If we kept listening in, our utilons would have decreased! Why would we do that?</p>\n<p>Accurite Scientist: About that, we have come to understand the true mathematical essence of paper clips and we will no longer be representing them in the same way on the map. We've upgraded the utilon machine to read them as well, our simulations suggest that it will be counting 10% fewer paper clips for eternity due to the grand unified theory of paper fastening. I hope you don't mind.</p>\n<p>*The clippies burst into apoplectic rage and start hurling bits of furniture and invectives at the Accurites. The Accurites are a bit nonplussed by this state of affairs bit swiftly regain their composure and battle is joined. So involved are both factions, that they don't notice a Hooman eye looming outside the window.*</p>", "sections": [{"title": "Scene 1: Beyond the reach", "anchor": "Scene_1__Beyond_the_reach", "level": 1}, {"title": "Scene 1.5: Trombone de Bureau", "anchor": "Scene_1_5__Trombone_de_Bureau", "level": 1}, {"title": "Scene 2: The Accurites", "anchor": "Scene_2__The_Accurites", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "15 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T12:06:21.986Z", "modifiedAt": null, "url": null, "title": "Global Warming News", "slug": "global-warming-news", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:55.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x6CAekHRYW8srtj4g/global-warming-news", "pageUrlRelative": "/posts/x6CAekHRYW8srtj4g/global-warming-news", "linkUrl": "https://www.lesswrong.com/posts/x6CAekHRYW8srtj4g/global-warming-news", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Global%20Warming%20News&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGlobal%20Warming%20News%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx6CAekHRYW8srtj4g%2Fglobal-warming-news%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Global%20Warming%20News%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx6CAekHRYW8srtj4g%2Fglobal-warming-news", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx6CAekHRYW8srtj4g%2Fglobal-warming-news", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<p>A new peer reviewed article came out from NASA showing that the models used to predict temperature changes, and the ecological issues as a result of these changes, greatly differ from observed data.</p>\n<p>News Article: http://news.yahoo.com/nasa-data-blow-gaping-hold-global-warming-alarmism-192334971.html</p>\n<p>Actual Paper: http://www.mdpi.com/2072-4292/3/8/1603/pdf</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x6CAekHRYW8srtj4g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -3, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "8932", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T12:45:38.527Z", "modifiedAt": null, "url": null, "title": "P(X = exact value) = 0: Is it really counterintuitive?", "slug": "p-x-exact-value-0-is-it-really-counterintuitive", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.293Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lucidfox", "createdAt": "2010-11-22T06:58:06.993Z", "isAdmin": false, "displayName": "lucidfox"}, "userId": "hNnKSqvajCMRj9eKK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TLaZBDa8qKyiR2wdm/p-x-exact-value-0-is-it-really-counterintuitive", "pageUrlRelative": "/posts/TLaZBDa8qKyiR2wdm/p-x-exact-value-0-is-it-really-counterintuitive", "linkUrl": "https://www.lesswrong.com/posts/TLaZBDa8qKyiR2wdm/p-x-exact-value-0-is-it-really-counterintuitive", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20P(X%20%3D%20exact%20value)%20%3D%200%3A%20Is%20it%20really%20counterintuitive%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AP(X%20%3D%20exact%20value)%20%3D%200%3A%20Is%20it%20really%20counterintuitive%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTLaZBDa8qKyiR2wdm%2Fp-x-exact-value-0-is-it-really-counterintuitive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=P(X%20%3D%20exact%20value)%20%3D%200%3A%20Is%20it%20really%20counterintuitive%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTLaZBDa8qKyiR2wdm%2Fp-x-exact-value-0-is-it-really-counterintuitive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTLaZBDa8qKyiR2wdm%2Fp-x-exact-value-0-is-it-really-counterintuitive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 385, "htmlBody": "<p>I'm probably not going to say anything new here. Someone must have pondered over this already. However, hopefully it will invite discussion and clear things up.</p>\n<p>Let X be a random variable with a continuous distribution over the interval [0, 10]. Then, by the definition of probability over continuous domains, P(X = 1) = 0. The same is true for P(X = 10), P(X = sqrt(2)), P(X =&nbsp;&pi;), and in general, the probability that X is equal to any <em>exact</em>&nbsp;number is always zero, as an integral over a single point.</p>\n<p>This is sometimes described as counterintuitive: surely, at any measurement, X must be equal to <em>something</em>, and thus its probability cannot be zero since its clearly happened. It can be, of course, argued that mathematical probability is abstract function that does not exactly map to our intuitive understanding of probability, but in this case, I would argue that it does.</p>\n<p>What if X is the x-coordinate of a physical object? If classical physics are in question - for example, we pointed a needle at a random point on a 10 cm ruler - then it cannot be a point object, and must have a nonzero size. Thus, we can measure the probability of the 1 cm point lying within the space the end of the needle occupies, a probability that is clearly defined and nonzero.</p>\n<p>But even if we're talking about a point object, while it may well occupy a definite and exact coordinate in classical physics, we'll never know what exactly it is. For one, our measuring tools are not that precise. But even if they had infinite precision, statements like \"X equals exactly 2.(0)\" or \"X equals exactly&nbsp;&pi;\" contain infinite information, since they specify all the decimal digits of the coordinate into infinity. We would have an infinite number of measurements to confirm it. So while X may <em>objectively</em>&nbsp;equal exactly 2 or&nbsp;&pi; - again, under classical physics - measurers would never know it. At any given point, to measurers, X would lie in an interval.</p>\n<p>Then of course there is quantum physics, where it is literally impossible for any physical object, including point objects, to have a definite coordinate with arbitrary precision. In this case, the purely mathematical notion that any exact value is an impossible event turns out (by coincidence?) to match how the universe actually works.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TLaZBDa8qKyiR2wdm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 7.475706456365934e-07, "legacy": true, "legacyId": "8933", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T15:16:42.712Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Explanations", "slug": "seq-rerun-fake-explanations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:24.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g8mjjfjEjZzWcSgsR/seq-rerun-fake-explanations", "pageUrlRelative": "/posts/g8mjjfjEjZzWcSgsR/seq-rerun-fake-explanations", "linkUrl": "https://www.lesswrong.com/posts/g8mjjfjEjZzWcSgsR/seq-rerun-fake-explanations", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Explanations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Explanations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mjjfjEjZzWcSgsR%2Fseq-rerun-fake-explanations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Explanations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mjjfjEjZzWcSgsR%2Fseq-rerun-fake-explanations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mjjfjEjZzWcSgsR%2Fseq-rerun-fake-explanations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 209, "htmlBody": "<p>Title: [SEQ RERUN] Fake Explanations  Tags: sequence_reruns  Today's post, <a href=\"/lw/ip/fake_explanations/\">Fake Explanations</a> was originally published on 20 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>People think that fake explanations use words like \"magic\", while real explanations use scientific words like \"heat conduction\". But being a real explanation isn't a matter of literary genre. Scientific-sounding words aren't enough. Real explanations constrain anticipation. Ideally, you could explain only the observations that actually happened. Fake explanations could just as well \"explain\" the opposite of what you observed.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/6vf/seq_rerun_is_molecular_nanotechnology_scientific/\">Is Molecular Nanotechnology \"Scientific\"?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g8mjjfjEjZzWcSgsR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.476180775918018e-07, "legacy": true, "legacyId": "8934", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fysgqk4CjAwhBgNYT", "rLCAFqRt2N3mARF7k", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T19:52:10.862Z", "modifiedAt": null, "url": null, "title": "exists(max(performance(pay)))", "slug": "exists-max-performance-pay", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:56.432Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yvxwbkPEJ5zBXnsn9/exists-max-performance-pay", "pageUrlRelative": "/posts/yvxwbkPEJ5zBXnsn9/exists-max-performance-pay", "linkUrl": "https://www.lesswrong.com/posts/yvxwbkPEJ5zBXnsn9/exists-max-performance-pay", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20exists(max(performance(pay)))&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Aexists(max(performance(pay)))%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyvxwbkPEJ5zBXnsn9%2Fexists-max-performance-pay%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=exists(max(performance(pay)))%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyvxwbkPEJ5zBXnsn9%2Fexists-max-performance-pay", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyvxwbkPEJ5zBXnsn9%2Fexists-max-performance-pay", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 141, "htmlBody": "<p>US Congresspeople don't make a lot of money in salary - most make $174,000/yr.&nbsp; They could easily make several times that much as consultants.&nbsp; They do, however, have insider information giving them <a href=\"http://insidertrading.procon.org/view.answers.php?questionID=001034\">very large returns on the stock market</a>.&nbsp; For that, or other reasons, many of our representatives care more about keeping their jobs than about not wrecking the economy.</p>\n<p>Most discussion of incentivizing assumes that higher pay leads to higher performance.&nbsp; The logic is that higher pay leads to wanting more to keep the job, which leads to higher performance.&nbsp; But the second link in this chain is weak.&nbsp; Sometimes higher motivation to keep the job leads to lower performance.&nbsp; CEOs are motivated to hide losses with accounting tricks, military officers are motivated to deny and cover up abuse by their subordinates, teachers are motivated to inflate their students' test scores.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yvxwbkPEJ5zBXnsn9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -4, "extendedScore": null, "score": 7.477045814113717e-07, "legacy": true, "legacyId": "8935", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T21:02:54.792Z", "modifiedAt": null, "url": null, "title": "The $125,000 Summer Singularity Challenge", "slug": "the-usd125-000-summer-singularity-challenge", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.695Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dd9WCa6sAstKBym6f/the-usd125-000-summer-singularity-challenge", "pageUrlRelative": "/posts/dd9WCa6sAstKBym6f/the-usd125-000-summer-singularity-challenge", "linkUrl": "https://www.lesswrong.com/posts/dd9WCa6sAstKBym6f/the-usd125-000-summer-singularity-challenge", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20%24125%2C000%20Summer%20Singularity%20Challenge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20%24125%2C000%20Summer%20Singularity%20Challenge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdd9WCa6sAstKBym6f%2Fthe-usd125-000-summer-singularity-challenge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20%24125%2C000%20Summer%20Singularity%20Challenge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdd9WCa6sAstKBym6f%2Fthe-usd125-000-summer-singularity-challenge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdd9WCa6sAstKBym6f%2Fthe-usd125-000-summer-singularity-challenge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 632, "htmlBody": "<p><em>From the <a href=\"http://intelligence.org/blog/\">SingInst blog</a>:</em></p>\n<p>Thanks to the generosity of several major donors<sup>&dagger;</sup>, every donation to the Singularity Institute made now <strong>until August 31, 2011</strong> will be <a href=\"http://intelligence.org/donate\">matched dollar-for-dollar</a>, up to a total of $125,000.</p>\n<p style=\"padding-left: 60px;\"><a href=\"http://intelligence.org/donate\">Donate now!</a></p>\n<p>(Visit the <a href=\"http://intelligence.org/2011summerchallenge\">challenge page</a> to see a progress bar.)</p>\n<p>Now is your chance to <strong>double your impact</strong> while supporting the Singularity Institute and helping us raise up to $250,000 to help fund <a href=\"http://intelligence.org/research/summary/\">our research program</a> and stage the upcoming <strong><a href=\"http://www.singularitysummit.com/\">Singularity Summit</a></strong>&hellip; which you can <strong><a href=\"http://www.singularitysummit.com/registration/\">register for now</a></strong>!</p>\n<p><sup>&dagger;</sup> $125,000 in backing for this challenge is being generously provided by Rob Zahra, <a href=\"http://www.quixey.com/\">Quixey</a>,  Clippy, Luke Nosek, Edwin Evans, Rick Schwall, Brian Cartmell, Mike  Blume, Jeff Bone, Johan Edstr&ouml;m, Zvi Mowshowitz, John Salvatier, Louie  Helm, Kevin Fischer, Emil Gilliam, Rob and Oksana Brazell, Guy  Srinivasan, John Chisholm, and John Ku.</p>\n<hr />\n<p>2011 has been a <strong>huge year for Artificial Intelligence</strong>. With the IBM computer Watson defeating two top <em>Jeopardy!</em> champions in February, it&rsquo;s clear that the field is making steady progress. Journalists like Torie Bosch of <em>Slate</em> have <a href=\"http://www.slate.com/id/2298318/\">argued</a> that <em>&ldquo;We need to move from robot-apocalypse jokes to serious discussions about the emerging technology.&rdquo;</em> We couldn&rsquo;t agree more &mdash; in fact, the Singularity Institute has been  thinking about how to create safe and ethical artificial intelligence  since long before the Singularity landed on the <a href=\"http://www.time.com/time/health/article/0,8599,2048138,00.html\">front cover</a> of <em>TIME</em> magazine.</p>\n<p>The last 1.5 years were our biggest ever. Since the beginning of 2010, we have:</p>\n<ul>\n<li>Held our annual <a href=\"http://www.singularitysummit.com/\">Singularity Summit</a>, in San Francisco. Speakers included Ray Kurzweil, James Randi, Irene Pepperberg, and many others.</li>\n<li>Held the first <a href=\"http://intelligence.org/blog/2010/08/22/singularity-summit-australia-sept-7-11-12-melbourne/\">Singularity Summit Australia</a> and <a href=\"http://intelligence.org/blog/2011/06/01/singularity-summit-slc-this-weekend-in-salt-lake-city/\">Singularity Summit Salt Lake City</a>.</li>\n<li>Held a wildly successful <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">Rationality Minicamp</a>.</li>\n<li>Published <a href=\"http://intelligence.org/blog/2011/01/05/2010-singularity-institute-publications/\">seven research papers</a>, including Yudkowsky&rsquo;s much-awaited &lsquo;<a href=\"http://intelligence.org/upload/TDT-v01o.pdf\">Timeless Decision Theory</a>&lsquo;.</li>\n<li>Helped philosopher David Chalmers write his seminal paper &lsquo;<a href=\"http://intelligence.org/blog/2010/04/08/david-chalmers-on-singularity-intelligence-explosion/\">The Singularity: A Philosophical Analysis</a>&lsquo;, which has sparked broad discussion in academia, including an <a href=\"http://fragments.consc.net/djc/2010/12/singularity-symposium.html\">entire issue</a> of <em>Journal of Consciousness Studies</em> and a <a href=\"http://singularityhypothesis.blogspot.com/\">book</a> from Springer devoted to responses to Chalmers&rsquo; paper.</li>\n<li>Launched the <a href=\"http://intelligence.org/blog/2011/07/22/announcing-the-research-associates-program/\">Research Associates</a> program. </li>\n<li>Brought MIT cosmologist <a href=\"http://intelligence.org/blog/2010/03/03/mit-professor-and-cosmologist-max-tegmark-joins-siai-advisory-board/\">Max Tegmark</a> onto our advisory board, published our <a href=\"http://intelligence.org/singularityfaq\">Singularity FAQ</a>, and much more.</li>\n</ul>\n<p>In the coming year, we plan to do the following:</p>\n<ul>\n<li>Hold our annual <a href=\"http://www.singularitysummit.com/\">Singularity Summit</a>, in New York City this year.</li>\n<li>Publish three chapters in the upcoming academic volume <em><a href=\"http://singularityhypothesis.blogspot.com/\">The Singularity Hypothesis</a></em>, along with several other papers.</li>\n<li>Improve organizational transparency by creating a simpler,  easier-to-use website that includes Singularity Institute planning and  policy documents.</li>\n<li>Publish a document of open research problems related to Friendly AI,  to clarify the research space and encourage other researchers to  contribute to our mission.</li>\n<li>Add additional skilled researchers to our <a href=\"http://intelligence.org/aboutus/researchassociates\">Research Associates</a> program.</li>\n<li>Publish well-researched documents making the case for existential risk reduction as optimal philanthropy.</li>\n<li>Diversify our funding sources by applying for targeted grants and advertising our <a href=\"http://intelligence.org/donate/#affinity\">affinity credit card program</a>.</li>\n</ul>\n<p>We appreciate your support for our high-impact work. As PayPal co-founder and Singularity Institute donor Peter Thiel <a href=\"http://intelligence.org/media/interviews/peterthiel\">said</a>:</p>\n<blockquote>\n<p>&ldquo;I&rsquo;m interested in facilitating a forum in which there  can be&hellip; substantive research on how to bring about a world in which AI  will be friendly to humans rather than hostile&hellip; [The Singularity  Institute represents] a combination of very talented people with the  right problem space [they&rsquo;re] going after&hellip; [They&rsquo;ve] done a phenomenal  job&hellip; on a shoestring budget. From my perspective, the key question is  always: What&rsquo;s the amount of leverage you get as an investor? Where can a  small amount make a big difference? This is a very leveraged kind of  philanthropy.&rdquo;</p>\n</blockquote>\n<p><a href=\"http://intelligence.org/donate\">Donate now</a>, and seize a  better than usual chance to move our work forward. Credit card  transactions are securely processed through Causes.com, Google Checkout,  or PayPal. If you have questions about donating, please call Amy Willey  at (586) 381-1801.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z6DgiCrMtpSNxwuYW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dd9WCa6sAstKBym6f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 32, "extendedScore": null, "score": 7.477267958252856e-07, "legacy": true, "legacyId": "8931", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 262, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-29T21:06:41.763Z", "modifiedAt": null, "url": null, "title": "On the unpopularity of cryonics: life sucks, but at least then you die", "slug": "on-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "viewCount": null, "lastCommentedAt": "2021-05-21T04:20:31.089Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mkrvsNi8cYGSjGqkh/on-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "pageUrlRelative": "/posts/mkrvsNi8cYGSjGqkh/on-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "linkUrl": "https://www.lesswrong.com/posts/mkrvsNi8cYGSjGqkh/on-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "postedAtFormatted": "Friday, July 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20the%20unpopularity%20of%20cryonics%3A%20life%20sucks%2C%20but%20at%20least%20then%20you%20die&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20the%20unpopularity%20of%20cryonics%3A%20life%20sucks%2C%20but%20at%20least%20then%20you%20die%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkrvsNi8cYGSjGqkh%2Fon-the-unpopularity-of-cryonics-life-sucks-but-at-least-then%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20the%20unpopularity%20of%20cryonics%3A%20life%20sucks%2C%20but%20at%20least%20then%20you%20die%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkrvsNi8cYGSjGqkh%2Fon-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkrvsNi8cYGSjGqkh%2Fon-the-unpopularity-of-cryonics-life-sucks-but-at-least-then", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2001, "htmlBody": "<p>From Mike Darwn's Chronopause, an essay titled <a href=\"http://chronopause.com/chronopause.com/index.php/2011/07/27/would-you-like-another-plate-of-this/index.html\">\"Would You Like Another Plate of This?\"</a>, discussing people's attitudes to life:</p>\n<blockquote>\n<p>The most important, the most obvious and the most factual reason why cryonics is not more widely accepted is that it&nbsp; fails the &ldquo;credibility sniff test&rdquo; in that it makes many critical assumptions which may not be correct...In other words, cryonics is <em>not proven</em>. That is a plenty valid reason for rejecting <em>any</em> costly procedure; dying people do this kind of thing every day for medical procedures which are proven, but which have a very low rate of success and (or) a very high misery quotient. Some (few) people have survived metastatic head/neck cancer &ndash; the film critic Roger Ebert, is an example (<strong>Figure 1</strong>). However, the vast majority of patients who undergo radical neck surgery for cancer die anyway. For the kind and extent of cancer Ebert had, the long term survival rate (&gt;5 years) is ~5% <em>following </em>radical neck dissection and ancillary therapy: usually radiation and chemotherapy. This is thus a proven procedure &ndash; it works &ndash; and yet the vast majority of patients refuse it.<a id=\"more\"></a></p>\n<p>Cryonics is not proven, and it is aesthetically disturbing (indeed even disgusting) to many people. It is also costly, and not just in terms of money alone. It is costly in countless other ways, ranging from the potential for marital discord, social alienation, ridicule, social isolation, disruption of family relationships (and with grief coping mechanisms) during the dying process, and on and on and on. And it does cost a <em>lot</em> of money, because if you figure the lost present value of capital for life insurance, dues, and end of life expenses related to cryonics, then that is a very significant dollar amount; my guess is that for a whole body patient who signs up at age 35 with Alcor, it is in the range of ~ $500,000 to $750,000 2010 dollars!</p>\n<p>...Beyond this, many other factors come into play, such as perceived interference or lack of competitiveness with religion by cryonics, lack of endorsement by authority figures, such as physicians and scientists, actual marketing faux pas&rsquo;s, such as the Chatsworth debacle and the use the words &ldquo;death&rdquo; and &ldquo;dead&rdquo; to describe cryonics patients. Then come factors which would, if cryonics were proven to work, be down in the noise, or more accurately, nonexistent, such as they way the current cryonics facilities look, the appearance and qualification of staff and so on.</p>\n<p>...Over the past few days, with the passing of Robert Ettinger, cryonics has received a level of planet-wide media attention it has not received in decades. One interesting and valuable result of this is that various news venues have solicited public comment about cryonics, and what&rsquo;s more, about immortalism, or radical life extension. As usual, cryonicists have been deaf to the criticism, expressed and implied in these remarks from the &ldquo;marketplace. Or worse, they have been contemptuous, without being clever in their contempt and in their responses.</p>\n<p>[quotes from comments &amp; people]</p>\n<p>What do these remarks mean? Well, they mean exactly what they say they mean in most cases. That may be hard to understand, especially if you look at the demographic data for how &ldquo;happy&rdquo; people are the world over. What you will find, if you do, is that people in Western Developed nation-states are extraordinarily happy. In fact, they are <em>unbelievably</em> happy (<strong>Figure 3</strong>).</p>\n<p><strong>Figure 4:</strong> <em>Your life and future prospects can still be grim and relatively hopeless and yet your evaluation of your satisfaction with life vary dramatically depending upon whether you have a full belly, or even if you&rsquo;ve had a meal in the past few hours.</em></p>\n<p>How is this possible? The answer is that happiness is complex and exists on many different levels. The most important and the most difficult to measure is existential happiness. The issue of their existential happiness is something most people rarely, if ever confront, and almost never do so in public when asked (unless you ask them in the right way, such as, &ldquo;Would you want to live forever?&rdquo;). The reason for this is that if they respond by saying &ldquo;My life is a boring exercise in getting from day-to-day with a lot of nagging miseries and frustrating inconveniences,&rdquo; they would appear as failures, as whingers , and as losers. Few people find that acceptable!</p>\n<p>...<strong>Figure 5: </strong><em>Humans were not evolved to be confined to a fixed space day-after-day and to do boring and repetitive work which is usually personally meaningless, and is done on the orders of others who are also omnipresent to supervise its execution. That is the working definition of hell for hunter-gatherers and they are uniformly both horrified and disgusted to to see &ldquo;civilized&rdquo; man behave in this way.</em></p>\n<p><em>...</em>Then there are the other people you must necessarily interact with. Several of the people you work with are complete monsters, in fact, they despise you and they go out of their way to make your job and your hours at work more difficult. And the customers! Most are OK, but some are horrible &ndash; encounters with them leave you shaking, and sometimes fearful for your job. Speaking of which, there is always some degree of apprehension present that you might lose your job; you might screw up, the economy may take a nosedive&hellip; In any event, your survival is critically dependent upon your <em>job</em>. Others whom you work with are better compensated, and those that own the enterprise you work <em>for</em> are getting rich from it, and that rankles. But, beyond these concerns, this isn&rsquo;t what you really wanted to do with your life and your time. When you were fifteen, you wanted to _______________, to travel, to see the world, and to meet interesting people and do interesting things. Instead, here you are. And every day you are a little older and a little more run-down. The clock is ticking. When you looked in mirror this morning, you had to face it yet again; you aren&rsquo;t young anymore and you aren&rsquo;t going to get any younger.</p>\n<p>...And frankly, why should you even try? You were raised with a very limited repertoire of interests, ambitions, and capabilities. It is so hard to survive in this world, even in this relative paradise of Western Technological Civilization, that mostly what you <em>had to</em> learn and spend your time thinking about were how to acquire the skills to <em>compete</em> and to make a living and support your offspring and your dying parents. All so that this cycle can be repeated, yet again (and to what end?). You laugh at people who talk about what makes the stars shine, how long the universe will last, where all the dark matter is, are there multiverses, what would it be like to &ldquo;see&rdquo; in the full electromagnetic spectrum, or even what it would be like to sit down and talk with Chinese workers or Egyptian shop keeps, and find out what they really think about Islam, democracy or the USA, without someone on the TV telling you what they think (and getting wrong)?</p>\n<p>...The fundamental problems are these, in no special order:</p>\n<ul>\n<li>Most people lack autonomy in their daily lives. Next to life itself, freedom is the most precious value; and most people&rsquo;s lives are functionally devoid of it. Many cryonicists fail to see this, because they are self employed, are in jobs that offer them compensating satisfaction, or that they don&rsquo;t perceive as &ldquo;work&rdquo; (e.g., they are not watching the clock just waiting for the torture to be over for another day).</li>\n<li>Most people have a very limited range of interests and possibilities for gratification. This problem cannot be fixed for most by giving them more money, or even more money <em>and</em> autonomy. Do that, and they will drown themselves in what they already have, or kill themselves with drugs. How many cars, planes, and pairs of shoes or houses can you really gain joy from?</li>\n<li>The vast majority of people over 30 don&rsquo;t feel well a significant fraction of the time. They have colds, flu, osteoarthritis, and most importantly, they are poorly conditioned as a result of jobs that enforce immobility and make them sedentary. As a result, they are tired and drained from their work and home responsibilities at the end of each day, and worst of all, they spend that part of the day when they feel the best and are most alert, doing what other people tell them to do &ndash; not what <em>they</em> want to do.</li>\n<li>They are losing their own youth and health and watching others suffer and die around them. How&rsquo;s that for a satisfying life experience? Every day they turn on the news or talk to friends or family, and find that another fixture in their life is dead, or dying. As John Donne said, &ldquo;Any man&rsquo;s death diminishes me, because I am involved in Mankind; And therefore never send to know for whom the bell tolls; it tolls for thee.&rdquo;</li>\n</ul>\n<p>...Thus, when it comes to happiness, people who are socially inept and who have trouble coping emotionally with the exigencies of life are, on average, the least happy. It should thus come as little surprise that our prisons are currently filled with a disproportionate number of people who are more intelligent than average and who lack the social coping skills to get on in society. They are also smart enough to know that many of the rules and orders given them are arbitrary and have no basis in reason beyond maintaining the status quo. As sociologist and educator Bill Allin has observed: &ldquo;People with high intelligence, be they children or adults, still rank as social outsiders in most situations, including their skills to be good mates and parents.&rdquo;<a href=\"http://chronopause.com/index.php/2011/07/27/would-you-like-another-plate-of-this/#_ftn4\">[4]</a></p>\n<p>The relevance of this to cryonics should be obvious to most cryonicists; cryonics attracts, with massive disproportionality, the highly intelligent. Indeed, many of the arguments that make cryonics credible, require a remarkable degree of both intelligence and scholarship. Inability to understand the enabling ideas and technologies usually means the inability to understand, let alone embrace, cryonics. &nbsp;A disproportionately unhappy population of smart people translates to a disproportionately large population of ideal market candidates for cryonics being unwilling and indeed, unable to embrace it.</p>\n<p>...There is no one solution or easy fix. The first step is to realize that what the marketplace is telling us is true: many people don&rsquo;t want to live because the existential ground state of their lives is a gray-state of dysphoria at best, and at worst, a state of active misery, relieved only occasionally by a few quickly snatched minutes of relief, or if they are lucky, joy. That state of affairs can only be addressed by showing people very real and concrete ways in which the quality of their lives can be improved, both here and now, and in the future. Heaven isn&rsquo;t waking up from cryopreservation and having to go into work two weeks later &ndash; FOREVER. That is the very definition of hell for most people. And the mystics have been smart enough to carefully exclude any mention of time-cards from their hereafters. The Mormons and the Islamists have even had the good marketing sense to offer up eternities where each man commands his own world, or at the least, his own harem.</p>\n</blockquote>\n<p>Conclusion, graphs, and references in article. As usual, I recommend reading Chronopause.com as Darwin has many good articles; to quickly link a few:</p>\n<ol>\n<li><a href=\"/lw/6me/alcor_finances/\">ALCOR finances</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/14/supar-power-a-rapid-inexpensive-highly-accurate-method-of-predicting-all-cause-and-disease-specific-mortality/\">Master biomarker for health &amp; aging</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/02/07/67/\">Technological evitability</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/05/31/going-going-gone-part-3/\">The AIDS Underground</a> (lessons for transhumanists)</li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/15/902/\">Harry Potter and Deathism</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/24/robert-c-w-ettinger-first-life-cycle-1918-to-2011/\">Robert Ettinger obituary</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/05/31/going-going-gone%E2%80%A6-part-2/\">Damage in the aging brain</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/11/the-armories-of-the-latter-day-laputas-part-5/\">Business &amp; charity failure rates</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/12/the-armories-of-the-latter-day-laputas-part-6/\">Factors in corporate longevity</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/02/23/does-personal-identity-survive-cryopreservation/\">\"Does Personal Identity Survive Cryopreservation?\"</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/03/10/how-not-to-get-ahead-in-cryonics-using-google-ngram-technology-to-expose-flawed-decision-making-in-cryonics/\">Cryonics PR in Google N-gram</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/05/29/a-visit-to-alcor/\">\"A Visit to Alcor\"</a></li>\n<li><a href=\"http://chronopause.com/index.php/2011/07/02/the-armories-of-the-latter-day-laputas-part-4/\">Soviet ICBM sites</a></li>\n</ol>\n<p><strong></strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mkrvsNi8cYGSjGqkh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 104, "baseScore": 123, "extendedScore": null, "score": 0.000232, "legacy": true, "legacyId": "8918", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 124, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 472, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iPK8AezgksW8N7N5Z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T00:51:06.630Z", "modifiedAt": null, "url": null, "title": "[Conversation Log] Compartmentalization", "slug": "conversation-log-compartmentalization", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.122Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AdeleneDawner", "createdAt": "2009-04-28T14:40:00.131Z", "isAdmin": false, "displayName": "AdeleneDawner"}, "userId": "MeSREm4SMRGxeQ8X3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rhsyHcTQX9g8fhk7s/conversation-log-compartmentalization", "pageUrlRelative": "/posts/rhsyHcTQX9g8fhk7s/conversation-log-compartmentalization", "linkUrl": "https://www.lesswrong.com/posts/rhsyHcTQX9g8fhk7s/conversation-log-compartmentalization", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BConversation%20Log%5D%20Compartmentalization&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BConversation%20Log%5D%20Compartmentalization%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrhsyHcTQX9g8fhk7s%2Fconversation-log-compartmentalization%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BConversation%20Log%5D%20Compartmentalization%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrhsyHcTQX9g8fhk7s%2Fconversation-log-compartmentalization", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrhsyHcTQX9g8fhk7s%2Fconversation-log-compartmentalization", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2371, "htmlBody": "<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:40:37 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Had an odd thought recently, and am trying to see if I understand the idea of compartmentalization.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:41:08 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I've always acted in a way, whereupon if I'm playing WOW, I roleplay an elf. If I'm at church, I roleplay a unitarian. If I'm on LessWrong, I roleplay a rationalist.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:41:31 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>And for the most part, these are three separate boxes. My elf is not a rationalist nor a unitarian, and I don't apply the Litany of Tarski to church.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:41:49 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>And I realized I'm *assuming* this is what people mean by compartmentalizing.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:42:11 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>But I also had some *really* interesting assumptions about what people meant by religion and spiritual and such, so it's probably smart to step back and check ^^<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:43:45 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I'm actually not sure what's usually meant by the concept (which I don't actually use), but that's not the guess I came up with when you first asked, and I think mine works a little better.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:44:50 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Then I am glad I asked! :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:45:24 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>My guess is something along the lines of this: Compartmentalizing is when one has several models of how the world works, which predict different things about the same situations, and uses arbitrary, social, or emotional methods rather than logical methods to decide which model to use where.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:46:54 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Ahhhh<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:47:05 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So it's not having different models, it's being alogical about choosing a method/<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:47:08 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>?<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:47:14 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>That's my guess, yes.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:47:37 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I do think that it's specifically not just about having different behavioral habits in different situations.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:48:00 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>(Which is what I think you mean by 'roleplay as'.)<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:49:21 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>It's not *exactly* different situations, though. That's just a convenient reference point, and the process that usually develops new modes. I can be an elf on LessWrong, or a rationalist WOW player, too.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:49:53 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Also, with regards to the models model, some models don't seem to be reliable at all from a logical standpoint, so it's fairly safe to assume that someone who uses such a model in any situation is compartmentalizing.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:50:34 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>But the goddess really does talk to me during rites &gt;.&gt;;<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:51:16 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>...okay, maybe that's not the best wording of that concept.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:51:33 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>It's a concept I tend to have trouble with, too, I'll admit<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:51:36 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I... mmm.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:51:56 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Eh :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:52:18 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I'm trying to get at a more 'mainstream christianity model' type thing, with that - most Christians I've known don't actually expect any kind of feedback at all from God.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:53:00 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Whereas your model at least seems to make some useful predictions about your mindstates in response to certain stimulii.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:53:20 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>.. but that would be stupid &gt;.&gt;<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:53:26 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>eh?<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:53:50 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>If they don't ... get anything out of it, that would be stupid to do it o.o<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:54:11 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Oh, Christians? They get social stuff out of it.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:54:35 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>*nods* So... it's beneficial.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:54:46 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>But still compartment-ey.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:55:10 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I listed 'social' in the reasons one might use an illogical model on purpose. :)<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:55:25 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Hmmmm.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:56:05 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I wish I knew actual Christians I could ask about this ^^;<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:56:22 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>They're not hard to find, I hear. ^.-<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:56:27 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>... huh<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:56:42 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Good point.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:57:12 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Possibly of interest: I worked in a Roman Catholic nursing home - with actual nuns! - for four years.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:57:25 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Ooh, that is useful :)<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:57:38 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I'd rather bug someone who doesn't seem to object to my true motives :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:58:00 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Not that I talked to the nuns much, but there were some definite opportunities for information-gathering.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:58:27 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Mostly, mmm...<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:58:34 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span><a href=\"http://lesswrong.com/lw/1mh/that_magical_click/\">http://lesswrong.com/lw/1mh/that_magical_click/</a> Have you read this article?<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:58:52 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Not recently, but I remember the gist of it.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:59:05 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I'm trying to understand the idea of a mind that doesn't click, and I'm trying to understand the idea of how compartmentalizing would somehow *block* that.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:59:15 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I dunno, the way normal people think baffles me<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:59:28 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*nodnods*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(7:59:30 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I assumed everyone was playing a really weird game until, um, a few months ago &gt;.&gt;<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(7:59:58 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>heh<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:00:29 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*ponders not-clicking and compartmentalization*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:00:54 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>It's sort of... all the models I have of people make sense.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:00:58 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>They have to make sense.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:01:22 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I can understand \"Person A is Christian because it benefits them, and the cost of transitioning to a different state is unaffordably high, even if being Atheist would be a net gain\"<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:01:49 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>That's seriously a simplification.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:02:00 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I'm sure it is ^^<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:02:47 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>But that's a model I can understand, because it makes sense. And I can flesh it out in complex ways, such as adding the social penalty that goes in to thinking about defecting, and the ick-field around defecting, and such. But it still models out about that way.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:02:58 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Relevantly, they don't know what the cost of transition actually would be, and they don't know what the benefit would be.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:04:51 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Mmmm... really?<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:05:03 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I think most people can at least roughly approximate the cost-of-transition<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:05:19 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>(\"Oh, but I'd lose all my friends! I wouldn't know WHAT to believe anymore\")<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:05:20 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>And also I think most people know on some level that making a transition like that is not really voluntary in any sense once one starts considering it - it happens on a pre-conscious level, and it either does or doesn't without the conscious mind having much say in it (though it can try to deny that the change has happened). So they avoid thinking about it at all unless they have a really good reason to.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:05:57 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>There may be ways for them to mitigate that cost, that they're unaware of (\"make friends with an atheist programmers group\", \"read the metaethics sequence\"), but ... that's just ignorance and that makes sense ^^<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:06:21 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>And what would the cost of those cost-mitigation things be?<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:02 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Varies based on whether the person already knows an atheist programmers group I suppose? ^^<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:07:26 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Yep. And most people don't, and don't know what it would cost to find and join one.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:40 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>The point was more \"They can't escape because of the cost, and while there are ways to buy-down that cost, people are usually ignor...<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:41 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Ahhhh<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:42 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Okay<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:44 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Gotcha<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:07:49 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Usually ignorant because *they aren't looking*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:08:01 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>They're not laying down escape routes<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:08:24 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>And why would they, when they're not planning on escaping?<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:09:28 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Because it's just rational to seek to optimize your life, and you'd have to be stupid to think you're living an optimum life?<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:10:13 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>uhhhh.... no, most people don't think like that, basically at all.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:10:30 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Yeah, I know. I just don't quite understand why not &gt;.&gt;<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:10:54 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>*ponders*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:11:02 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So compartmentalization is sorta... not thinking about things?<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:11:18 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>That's at least a major symptom, yeah.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:11:37 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Compartmentalization is when model A is never used in situation X<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:12:17 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>And, often, when model A is only used in situation Y<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:12:22 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>And not because model A is specifically designed for simulations of type Y, yes.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:12:39 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I'd rephrase that to \"and not because model A is useless for X\"<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:13:06 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>mmm...<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:13:08 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Quantum physics isn't designed as an argument for cryonics, but eliezer uses it that way.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:13:14 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>hold on a sec.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:13:16 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Kay<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:16:01 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>The Christian model claims to be useful in lots of situations where it's observably not. For example, a given person's Christian model might say that if they pray, they'll have a miraculous recovery from a disease. Their mainstream-society-memes model, on the other hand, says that going to see a doctor and getting treatment is the way to go. The Christian model is *observably* basically useless in that situation, but I'd still call that compartmentalization if they went with the mainstream-society-memes model but still claimed to primarily follow the Christian one.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:16:46 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Hmmm, interesting.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:16:51 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I always just called that \"lying\" &gt;.&gt;<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:17:05 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>(At least, if I'm understanding you right: They do X, claim it's for Y reason, and it's very obviously for Z)<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:17:27 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>(Lying-to-self quite possibly, but I still call that lying)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:18:00 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>No, no - in my narrative, they never claim that going to a doctor is the Christian thing to do - they just never bring Christianity up in that context.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:19:15 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Ahhh<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:19:24 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So they're being Selectively Christian?<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:19:27 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Yup.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:19:37 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>But I play an elf, and an elf doesn't invest in cryonics.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:20:09 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So it seems like that's just... having two *different* modes.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:20:40 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I don't think that's intrinsically a problem. The question is how you pick between them.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:22:08 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Our example Christian seems to be picking sensibly, though.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:22:11 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>In the contexts that you consider 'elfy', cryonics might actually not make sense. Or it might be replaced by something else - I bet your elf would snap up an amulet of ha-ha-you-can't-kill-me, fr'ex.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:22:26 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Heeeh :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:28:51 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>About the Christian example - yes, in that particular case they chose the model for logical reasons - the mainstream model is the logical one because it works, at least reasonably well. It's implied that the person will use the Christian model at least sometimes, though. Say for example they wind up making poor financial decisions because 'God will provide', or something.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:29:48 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Heh ^^;<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:29:55 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Okay, yeah, that one I'm guilty of &gt;.&gt;<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:30:05 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>(In my defense, it keeps *working*)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:30:10 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>(I appear to be out of my depth, now. Like I said, this isn't a concept I use. I haven't thought about it much.)<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:30:22 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>It's been helpful to define a model for me.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:30:33 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>^^<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:30:50 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>The idea that the mistake is not having separate models, but in the application or lack thereof.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:31:07 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Sort of like how I don't use quantum mechanics to do my taxes.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:31:14 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Useful model, wrong situation, not compartmentalization.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:31:28 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*nods*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:32:09 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So, hmmmm.'<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:32:18 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>One thing I've noticed in life is that having multiple models is useful<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:32:32 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>And one thing I've noticed with a lot of \"rationalists\" is that they seem not to follow that principle.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:33:15 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Does that make sense<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:33:24 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*nods*<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:34:13 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>That actually feels related.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:35:03 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>People want to think they know how things work, so when they find a tool that's reasonably useful they tend to put more faith in it than it deserves.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:35:39 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Getting burned a couple times seems to break that habit, but sufficiently smart people can avoid that lesson for a surprisingly long time.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:35:55 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Well, sufficiently smart, sufficiently privileged people.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:37:15 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Heeeh, *nods*<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:37:18 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I seem to ... I dunno<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:37:24 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I grew up on the multi-model mindset.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:37:41 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>It's... a very odd sort of difficult to try and comprehend that other people didnt...<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:37:47 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*nods*<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:38:47 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>A lot of people just avoid things where their preferred model doesn't work altogether. I don't think many LWers are badly guilty of that, but I do suspect that most LWers were raised by people who are.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:39:16 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Mmmmm...<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:39:38 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>I tend to get the feeling that the community-consensus has trouble understanding \"but this model genuinely WORKS for a person in this situation\"<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:39:58 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>With some degree of... just not understanding that ideas are resources too, and they're rather privileged there and in other ways.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:40:16 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>That is an interesting way of putting it and I like it.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:40:31 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Yaaay :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:40:40 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>^.^<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:41:01 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Hmm<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:41:18 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>It occurs to me that compartmentalization might in a sense be a social form of one-boxing.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:41:41 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Heh! Go on :)<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:42:01 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>\"For signaling reasons, I follow model X in situation-class Y, even when the results are sub-optimal.\"<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:42:59 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Hmmmm.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:43:36 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>Going back to previous, though, I think compartmentalization requires some degree of not being *aware* that you're doing it.<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:43:47 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>Humans are good at that.<br /><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"color: #cc0000;\">(8:43:48 PM) </span></span></span><span style=\"font-weight: bold; color: #cc0000;\">handoflixue: </span>So... what you said, exactly, but on a subconscious level<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:43:53 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>*nodnods*<br /><span style=\"font-weight: normal;\"><span style=\"color: #204a87;\"><span style=\"font-size: x-small;\">(8:44:00 PM) </span></span></span><span style=\"font-weight: bold; color: #204a87;\">Adelene: </span>I meant subconsciously.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rhsyHcTQX9g8fhk7s", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 7.477984723353521e-07, "legacy": true, "legacyId": "8938", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["R3ATEWWmBhMhbY2AL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T06:13:19.399Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Guessing the Teacher's Password", "slug": "seq-rerun-guessing-the-teacher-s-password", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KuHAsQzh6wBP3ueXS/seq-rerun-guessing-the-teacher-s-password", "pageUrlRelative": "/posts/KuHAsQzh6wBP3ueXS/seq-rerun-guessing-the-teacher-s-password", "linkUrl": "https://www.lesswrong.com/posts/KuHAsQzh6wBP3ueXS/seq-rerun-guessing-the-teacher-s-password", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Guessing%20the%20Teacher's%20Password&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Guessing%20the%20Teacher's%20Password%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuHAsQzh6wBP3ueXS%2Fseq-rerun-guessing-the-teacher-s-password%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Guessing%20the%20Teacher's%20Password%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuHAsQzh6wBP3ueXS%2Fseq-rerun-guessing-the-teacher-s-password", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKuHAsQzh6wBP3ueXS%2Fseq-rerun-guessing-the-teacher-s-password", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 237, "htmlBody": "<p>Title: [SEQ RERUN] Guessing the Teacher's Password  Tags: sequence_reruns  Today's post, <a href=\"/lw/iq/guessing_the_teachers_password/\">Guessing the Teacher's Password</a> was originally published on 22 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>In schools, \"education\" often consists of having students memorize answers to specific questions (i.e., the \"teacher's password\"), rather than learning a predictive model that says what is and isn't likely to happen. Thus, students incorrectly learn to guess at passwords in the face of strange observations rather than admit their confusion. Don't do that: any explanation you give should have a predictive model behind it. If your explanation lacks such a model, start from a recognition of your own confusion and surprise at seeing the result.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6w6/seq_rerun_fake_explanations/\">Fake Explanations</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KuHAsQzh6wBP3ueXS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.478996996258971e-07, "legacy": true, "legacyId": "8949", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NMoLJuDJEms7Ku9XS", "g8mjjfjEjZzWcSgsR", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T06:56:49.555Z", "modifiedAt": null, "url": null, "title": "Polarized gamma rays and manifest infinity", "slug": "polarized-gamma-rays-and-manifest-infinity", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.681Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rwallace", "createdAt": "2009-03-01T16:13:25.493Z", "isAdmin": false, "displayName": "rwallace"}, "userId": "cPhXNeZvnK7LgPMnv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qzx6zQdWGdp9QXtY8/polarized-gamma-rays-and-manifest-infinity", "pageUrlRelative": "/posts/qzx6zQdWGdp9QXtY8/polarized-gamma-rays-and-manifest-infinity", "linkUrl": "https://www.lesswrong.com/posts/qzx6zQdWGdp9QXtY8/polarized-gamma-rays-and-manifest-infinity", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Polarized%20gamma%20rays%20and%20manifest%20infinity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APolarized%20gamma%20rays%20and%20manifest%20infinity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqzx6zQdWGdp9QXtY8%2Fpolarized-gamma-rays-and-manifest-infinity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Polarized%20gamma%20rays%20and%20manifest%20infinity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqzx6zQdWGdp9QXtY8%2Fpolarized-gamma-rays-and-manifest-infinity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqzx6zQdWGdp9QXtY8%2Fpolarized-gamma-rays-and-manifest-infinity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 826, "htmlBody": "<p>&nbsp;</p>\n<p>Most people (not all, but most) are reasonably comfortable with infinity as an ultimate (lack of) limit. For example, cosmological theories that suggest the universe is infinitely large and/or infinitely old, are not strongly disbelieved a priori.</p>\n<p>By contrast, most people are fairly uncomfortable with <em>manifest</em> infinity, actual infinite quantities showing up in physical objects. For example, we tend to be skeptical of theories that would allow infinite amounts of matter, energy or computation in a finite volume of spacetime.</p>\n<p><a id=\"more\"></a></p>\n<p>Consider the following thought experiment (I forget where I first heard it):</p>\n<p>Aliens in a passing flying saucer offer to sell us a halting oracle. It's a black box of ordinary size and mass, galactic intellectual property law prohibits giving us an explanation of how it works and it's far beyond our ability to reverse engineer. Nonetheless, if you feed it the description of a Turing machine, it will calculate for a millisecond and then indicate whether that Turing machine halts or not. Obviously we're skeptical and exhaustive testing is impossible, but the device passes every test we can throw at it.</p>\n<p>In practice, willingness to pay for it might be based on a belief that it will probably work for every case we are going to be in a position to care about in the near future, but do we believe the sales pitch that it is a true halting oracle, i.e. a device that performs <em>infinite</em>&nbsp;computation in finite spacetime? Some people would give more than 50% credence to this proposition, and some people less, but almost everyone would give it a subjective probability greater than zero.</p>\n<p>It is worth noting that Solomonoff induction would do otherwise. SI is based on the assumption that the universe is computable; it assigns a halting oracle a prior probability (and therefore a posterior probability after any finite amount of evidence) of zero. In other words, while human intuition is finitely skeptical of manifest infinity, SI is infinitely skeptical.</p>\n<p>This has been used as a reductio ad absurdum of SI, but is that correct? If a halting oracle really is absolutely impossible or at least infinitely improbable across the Tegmark multiverse by a correct weighting, then SI is right and human intuition is wrong. If not, then vice versa. At this time, I don't know which is the case, or even whether there is a fact of the matter regarding which is the case.</p>\n<p>In the absence of aliens offering unlikely bargains, this would appear to be of little concern, but consider a much more familiar object: the humble electron.</p>\n<p>When we measure the spin of an electron, how much information can we get? One bit: up or down.</p>\n<p>But how much computation is the universe doing behind the scenes? According to quantum mechanics, the spin of an electron is represented by a complex number, which if taken at face value would mean the universe is actually doing infinite computation to provide us with one bit. Nor is this entirely unobservable, because by repeated measurements we can verify that quantum mechanics seems to work; the probability distribution we get is that which would be given if the spin really were represented as a complex number.</p>\n<p>On a larger scale, current theory strongly conjectures that the maximum information contained in a volume is given by the Bekenstein bound, one bit per Planck area give or take a small constant factor. Leaving aside the surprising holographic theory that gives a limit in terms of area rather than volume as we would intuitively expect, this sounds perfectly reasonable - except does \"information contained in a volume\" refer, like the one bit obtained from measuring the spin of an electron, only to the information we can extract? Or is it an indicator of some final limit to the computation the universe performs behind the scenes?</p>\n<p>Put another way, is space <em>really</em> granular at the Planck scale of 1e-35 meters? Or does the universe go ahead and implement infinitely subdivisible space, with the Planck limit only being on what use we can make of it? How skeptical should we be of manifest infinity?</p>\n<p>For what it's worth, my intuitive preference is for the finite answer, to an even greater extent than with the halting oracle; notwithstanding that I know very well the universe is not constrained by my ideas of efficiency, it <em>still</em>&nbsp;strikes me as grossly inefficient to the point of inelegance for the universe to perform infinite computation of which only a finite fraction can be used even in principle.</p>\n<p>Which was why I was distinctly disconcerted when I read this result:&nbsp;<a href=\"http://www.cosmosmagazine.com/node/4472\">http://www.cosmosmagazine.com/node/4472</a>.</p>\n<p>(In a nutshell, somebody calculated that if space is really granular at 1e-35 meters, that should actually affect the propagation of polarized gamma rays from a GRB 300 million light years distant, in a measurable way. Measurement found no such effect, apparently showing that the universe calculates space down to at least 1e-48 meters.)</p>\n<p>Must we, contrary to Solomonoff induction, accept the likelihood of manifest infinity after all? Or is there another interpretation of these results?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qzx6zQdWGdp9QXtY8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 27, "extendedScore": null, "score": 7.479133683825383e-07, "legacy": true, "legacyId": "8951", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T16:22:49.197Z", "modifiedAt": null, "url": null, "title": "Stanford Intro to AI course to be taught for free online", "slug": "stanford-intro-to-ai-course-to-be-taught-for-free-online", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.538Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6PQxeGSo4YHqwfrdp/stanford-intro-to-ai-course-to-be-taught-for-free-online", "pageUrlRelative": "/posts/6PQxeGSo4YHqwfrdp/stanford-intro-to-ai-course-to-be-taught-for-free-online", "linkUrl": "https://www.lesswrong.com/posts/6PQxeGSo4YHqwfrdp/stanford-intro-to-ai-course-to-be-taught-for-free-online", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stanford%20Intro%20to%20AI%20course%20to%20be%20taught%20for%20free%20online&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStanford%20Intro%20to%20AI%20course%20to%20be%20taught%20for%20free%20online%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6PQxeGSo4YHqwfrdp%2Fstanford-intro-to-ai-course-to-be-taught-for-free-online%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stanford%20Intro%20to%20AI%20course%20to%20be%20taught%20for%20free%20online%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6PQxeGSo4YHqwfrdp%2Fstanford-intro-to-ai-course-to-be-taught-for-free-online", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6PQxeGSo4YHqwfrdp%2Fstanford-intro-to-ai-course-to-be-taught-for-free-online", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 15, "htmlBody": "<p>Taught by professors Sebastian Thurn and Peter Norvig:&nbsp;<a href=\"http://www.ai-class.com/\">http://www.ai-class.com/</a></p>\n<p>I figured some here might be interested. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 1, "fH8jPjHF2R27sRTTG": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6PQxeGSo4YHqwfrdp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 38, "extendedScore": null, "score": 7.480912473013118e-07, "legacy": true, "legacyId": "8954", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T18:51:55.943Z", "modifiedAt": null, "url": null, "title": "How credible is neuroeconomics?", "slug": "how-credible-is-neuroeconomics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:02.391Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WkCZpPdhoPMdkHEAb/how-credible-is-neuroeconomics", "pageUrlRelative": "/posts/WkCZpPdhoPMdkHEAb/how-credible-is-neuroeconomics", "linkUrl": "https://www.lesswrong.com/posts/WkCZpPdhoPMdkHEAb/how-credible-is-neuroeconomics", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20credible%20is%20neuroeconomics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20credible%20is%20neuroeconomics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWkCZpPdhoPMdkHEAb%2Fhow-credible-is-neuroeconomics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20credible%20is%20neuroeconomics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWkCZpPdhoPMdkHEAb%2Fhow-credible-is-neuroeconomics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWkCZpPdhoPMdkHEAb%2Fhow-credible-is-neuroeconomics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>Paul Glimcher's book <a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254\">Foundations of Neuroeconomic Analysis</a>&nbsp;claims that the field of neuroeconomics has made great strides in creating a unified descriptive theory of individual human choice, bringing together positive economics (basically insights from <a href=\"http://en.wikipedia.org/wiki/Expected_utility_hypothesis\">VNM utility theory</a>), neuroscience and psychology. The field was recommended to me by a friend doing a PhD in&nbsp;psychology.&nbsp;If true, the field sounds very useful to study. I don't have the cognitive science background knowledge to evaluate the credibility of these claims (my economics background is strong), so I have a couple of questions:</p>\n<ol>\n<li>Is neuroeconomics founded on solid evidence?&nbsp;</li>\n<li>Are there intelligent criticisms of the field?&nbsp;</li>\n<li>If neuroeconomics is a useful field to study, what are the best books on the topic?&nbsp;</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WkCZpPdhoPMdkHEAb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 7.481381223598957e-07, "legacy": true, "legacyId": "8955", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T19:46:56.701Z", "modifiedAt": null, "url": null, "title": "MSF Theory: Another Explanation of Subjectively Objective Probability", "slug": "msf-theory-another-explanation-of-subjectively-objective", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.789Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "potato", "createdAt": "2011-06-15T09:18:51.735Z", "isAdmin": false, "displayName": "Ronny"}, "userId": "kY5hs2WkacnSZd937", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X9Hey3jJiPZCnJfhM/msf-theory-another-explanation-of-subjectively-objective", "pageUrlRelative": "/posts/X9Hey3jJiPZCnJfhM/msf-theory-another-explanation-of-subjectively-objective", "linkUrl": "https://www.lesswrong.com/posts/X9Hey3jJiPZCnJfhM/msf-theory-another-explanation-of-subjectively-objective", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20MSF%20Theory%3A%20Another%20Explanation%20of%20Subjectively%20Objective%20Probability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMSF%20Theory%3A%20Another%20Explanation%20of%20Subjectively%20Objective%20Probability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9Hey3jJiPZCnJfhM%2Fmsf-theory-another-explanation-of-subjectively-objective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=MSF%20Theory%3A%20Another%20Explanation%20of%20Subjectively%20Objective%20Probability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9Hey3jJiPZCnJfhM%2Fmsf-theory-another-explanation-of-subjectively-objective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX9Hey3jJiPZCnJfhM%2Fmsf-theory-another-explanation-of-subjectively-objective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1563, "htmlBody": "<p>Before I read <a href=\"/lw/oj/probability_is_in_the_mind/\" target=\"_blank\">Probability is in the Mind</a> and <a href=\"/lw/s6/probability_is_subjectively_objective/\" target=\"_blank\">Probability is Subjectively Objective</a> I was a realist about probabilities; I was a frequentest. After I read them, I was just confused. I couldn't understand how a mind could accurately say the probability of getting a heart in a standard deck of playing cards was not 25%. It wasn't until I tried to explain the contrast between my view and the subjective view in a comment on <a href=\"/lw/s6/probability_is_subjectively_objective\" target=\"_blank\">Probability is Subjectively Objective</a> that I realized I was a subjective Bayesian all along. So, if you've read <a href=\"/lw/oj/probability_is_in_the_mind\" target=\"_blank\">Probability is in the Mind</a> and read <a href=\"/lw/s6/probability_is_subjectively_objective\" target=\"_blank\">Probability is Subjectively Objective</a> but still feel a little confused, hopefully, this will help.</p>\n<p>I should mention that I'm not sure that EY would agree with my view of probability, but the view to be presented agrees with EY's view on at least these propositions:</p>\n<ul>\n<li>Probability is always in a mind, not in the world.</li>\n<li>The probability that an agent should ascribe to a proposition is directly related to that agent's knowledge of the world.</li>\n<li>There is only one <em>correct</em> probability to assign to a proposition given your partial knowledge of the world.</li>\n<li>If there is no uncertainty, there is no probability. </li>\n</ul>\n<p>And any position that holds these propositions is a non-realist-subjective view of probability.&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Imagine a pre-shuffled deck of playing cards and two agents (they don't have to be humans), named \"Johnny\" and \"Sally\", which are betting 1 dollar each on the suit of the top card. As everyone knows, 1/4 of the cards in a playing card deck are hearts. We will name this belief F<sub>1</sub>; F<sub>1</sub> stands for \"1/4 of the cards in the deck are hearts.\". Johnny and Sally both believe F<sub>1</sub>. F<sub>1</sub> is all that Johnny knows about the deck of cards, but sally knows a little bit more about this deck. Sally also knows that 8 of the top 10 cards are hearts. Let F<sub>2</sub> stand for \"8 out of the 10 top cards are hearts.\". Sally believes F<sub>2</sub>. John doesn't know whether or not F<sub>2</sub>. F<sub>1</sub> and F<sub>2</sub> are beliefs about the deck of cards and they are either true or false.</p>\n<p>So, sally bets that the top card is a heart and Johnny bets against her, i.e., she puts her money on \"Top card is a heart.\" being true; he puts his money on \"~The top card is a heart.\" being true. After they make their bets, one could imagine Johnny making fun of Sally; he might say something like: \"Are you nuts? You know, I have a 75% chance of winning. 1/4 of the cards are hearts; you can't argue with that!\" Sally might reply: \"Don't forget that the probability you assign to '~The top card is a heart.' depends on what you know about the deck. I think you would agree with me that there is an 80% chance that 'The top card is a heart' if you knew just a bit more about the state of the deck.\"</p>\n<p>To be undecided about a proposition is to not know which <em>possible</em> world you are in; am I in the possible world where that proposition is true, or in the one where it is false? Both Johnny and Sally are undecided about \"The top card is a heart.\"; their model of the world <em>splits</em> at that point of representation. Their knowledge is consistent with being in a possible world where the top card is a heart, or in a possible world where the top card is not a heart. The more statements they decide on, the smaller the configuration space of possible worlds they think they might find themselves in; deciding on a proposition takes a chunk off of that configuration space, and the content of that proposition determines the shape of the eliminated chunk; Sally's and Johnny's beliefs constrain their respective expected experiences, but not all the way to a point. The trick when constraining one's space of <em>viable</em> worlds, is to make sure that <em>the real world </em>is among the possible<em> </em>worlds that satisfy your beliefs. Sally still has the upper hand, because her space of viably possible worlds is smaller than Johnny's. There are many more ways you could arrange a standard deck of playing cards that satisfies F<sub>1 </sub>than there are ways to arrange a deck of cards that satisfies F<sub>1</sub> and F<sub>2</sub>. To be clear, we don't need to believe that possible worlds actually exist to accept this view of belief; we just need to believe that any agent capable of being undecided about a proposition is also capable of imagining alternative ways the world could consistently turn out to be, i.e., capable of imagining possible worlds.</p>\n<p>For convenience, we will say that a possible world W, is viable for an agent A, if and only if, W satisfies A's background knowledge of decided propositions, i.e., A thinks that W might be the world it finds itself in.</p>\n<p>Of the <em>possible </em>worlds that satisfy F<sub>1</sub>, i.e., of the possible worlds where \"1/4 of the cards are hearts\" is true, 3/4 of them also satisfy \"~The top card is a heart.\" Since Johnny holds that F<sub>1</sub>, and since he has no further information that might put stronger restrictions on his space of viable worlds, he ascribes a 75% probability to \"~The top card is a heart.\" Sally, however, holds that F<sub>2</sub> as well as F<sub>1</sub>. She knows that of the possible worlds that satisfy F<sub>1</sub> only 1/4 of them satisfy \"The top card is a heart.\" But she holds a proposition that constrains her space of viably possible worlds even further, namely F<sub>2</sub>. Most of the possible worlds that satisfy F<sub>1</sub> are eliminated as viable worlds if we hold that F<sub>2</sub> as well, because most of the possible worlds that satisfy F<sub>1</sub> don't satisfy F<sub>2</sub>. Of the possible worlds that satisfy F<sub>2</sub> exactly 80% of them satisfy \"The top card is a heart.\" So, duh, Sally assigns an 80% probability to \"The top card is a heart.\" They give that proposition different probabilities, and they are both right in assigning their respective probabilities; they don't disagree about how to assign probabilities, they just have different resources for doing so in this case. P(~The top card is a heart|F<sub>1)</sub> really is 75% and P(The top card is a heart|F<sub>2</sub>) really is 80%.</p>\n<p>This setup makes it clear (to me at least) that the right probability to assign to a proposition depends on what you know. The more you know, i.e., the more you constrain the space of worlds you think you might be in, the more useful the probability you assign. The probability that an agent should ascribe to a proposition is directly related to that agent's knowledge of the world.</p>\n<p>This setup also makes it easy to see how an agent can be wrong about the probability it assigns to a proposition given its background knowledge. Imagine a third agent, named \"Billy\", that has the same information as Sally, but say's that there's a 99% chance of \"The top card is a heart.\" Billy doesn't have any information that further constrains the possible worlds he thinks he might find himself in; he's just wrong about the fraction of possible worlds that satisfy F<sub>2</sub> that also satisfy \"The top card is a heart.\". Of all the possible worlds that satisfy F<sub>2</sub> exactly 80% of them satisfy \"The top card is a heart.\", no more, no less. There is only one <em>correct</em> probability to assign to a proposition given your partial knowledge.</p>\n<p>The last benefit of this way of talking I'll mention is that it makes probability's dependence on ignorance clear. We can imagine another agent that knows the truth value of every proposition, lets call him \"FSM\". There is only one possible world that satisfies all of FSM's background knowledge; the only viable world for FSM is <em>the real</em> world. Of the possible worlds that satisfy FSM's background knowledge, either all of them satisfy \"The top card is a heart.\" or none of them do, since there is only one viable world for FSM. So the only probabilities FSM can assign to \"The top card is a heart.\" are 1 or 0. In fact, those are the only probabilities FSM can assign to any proposition. If there is no uncertainty, there is no probability.</p>\n<p>The <em>world knows </em>whether or not any given proposition is true (assuming determinism). The world itself is never uncertain, only the parts of the world that we call agents can be uncertain. Hence, Probability is always in a mind, not in the world. The probabilities that the <em>universe assigns</em> <em>to a proposition</em> are always 1 or 0, for the same reasons FSM only assigns a 1 or 0, and 1 and 0 <em>aren't</em> <em>really probabilities. <br /></em></p>\n<p>In conclusion, I'll risk the hypothesis that: Where 0&le;x&le;1, \"P(a|b)=x\" is true, if and only if, of the possible worlds that satisfy \"b\", x of them also satisfy \"a\". Probabilities are propositional attitudes, and the probability value (or range of values) you assign to a proposition is representative of the fraction of possible worlds you find viable that satisfy that proposition. You may be wrong about the value of that fraction, and as a result you may be wrong about the probability you assign.</p>\n<p>We may call the position summarized by the hypothesis above \"Modal Satisfaction Frequency theory\", or \"MSF theory\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X9Hey3jJiPZCnJfhM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 20, "extendedScore": null, "score": 7.4815541746621e-07, "legacy": true, "legacyId": "8936", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["f6ZLxEWaankRZ2Crv", "XhaKvQyHzeXdNnFKy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T20:37:56.890Z", "modifiedAt": null, "url": null, "title": "Beware The Believer, or a study in depth of recursion", "slug": "beware-the-believer-or-a-study-in-depth-of-recursion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WE2oJSKoGsPgGD5KK/beware-the-believer-or-a-study-in-depth-of-recursion", "pageUrlRelative": "/posts/WE2oJSKoGsPgGD5KK/beware-the-believer-or-a-study-in-depth-of-recursion", "linkUrl": "https://www.lesswrong.com/posts/WE2oJSKoGsPgGD5KK/beware-the-believer-or-a-study-in-depth-of-recursion", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beware%20The%20Believer%2C%20or%20a%20study%20in%20depth%20of%20recursion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeware%20The%20Believer%2C%20or%20a%20study%20in%20depth%20of%20recursion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWE2oJSKoGsPgGD5KK%2Fbeware-the-believer-or-a-study-in-depth-of-recursion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beware%20The%20Believer%2C%20or%20a%20study%20in%20depth%20of%20recursion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWE2oJSKoGsPgGD5KK%2Fbeware-the-believer-or-a-study-in-depth-of-recursion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWE2oJSKoGsPgGD5KK%2Fbeware-the-believer-or-a-study-in-depth-of-recursion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>I submit to the good people of Less Wrong <a title=\"Beware The Believers\" href=\"http://www.youtube.com/watch?v=eaGgpGLxLQw\">this wonderful video</a>. Is it a parody of scientifism? A parody of creationist parodies of scientifism? How deep does the recursion go? (those who already know, don't spoil the fun for the rest!).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WE2oJSKoGsPgGD5KK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 5, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "8956", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-30T20:48:41.757Z", "modifiedAt": null, "url": null, "title": "Requesting low cost/high payoff projects ideas", "slug": "requesting-low-cost-high-payoff-projects-ideas", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S6dfEC4xPjrjPgonx/requesting-low-cost-high-payoff-projects-ideas", "pageUrlRelative": "/posts/S6dfEC4xPjrjPgonx/requesting-low-cost-high-payoff-projects-ideas", "linkUrl": "https://www.lesswrong.com/posts/S6dfEC4xPjrjPgonx/requesting-low-cost-high-payoff-projects-ideas", "postedAtFormatted": "Saturday, July 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Requesting%20low%20cost%2Fhigh%20payoff%20projects%20ideas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequesting%20low%20cost%2Fhigh%20payoff%20projects%20ideas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS6dfEC4xPjrjPgonx%2Frequesting-low-cost-high-payoff-projects-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Requesting%20low%20cost%2Fhigh%20payoff%20projects%20ideas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS6dfEC4xPjrjPgonx%2Frequesting-low-cost-high-payoff-projects-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS6dfEC4xPjrjPgonx%2Frequesting-low-cost-high-payoff-projects-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 312, "htmlBody": "<p>There are many projects that would benefit people interested in living rationally but that no individuals are motivated enough to do (<a href=\"/lw/6h5/volunteers_needed_to_work_on_lesswrongs_public/\">more</a>). The Public Goods Team is trying to encourage and facilitate systematic and organized work on such projects. One of our first steps is to identify the projects that are the lowest hanging fruit: those projects which are high value, and inexpensive (in terms of time, motivation, money etc.). We have come up with a preliminary list of such projects (below). What are other such projects?</p>\n<p>1. Further contributions to the <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">Science of Winning at Life sequence</a>:&nbsp;</p>\n<p style=\"padding-left: 30px;\">1.1. Cognitive science of learning</p>\n<p style=\"padding-left: 30px;\">1.2. Cognitive science of memory</p>\n<p style=\"padding-left: 30px;\">1.3. Ergonomics</p>\n<p style=\"padding-left: 30px;\">1.4. Behavioral conditioning</p>\n<p style=\"padding-left: 30px;\">1.6. Fashion</p>\n<p style=\"padding-left: 30px; \">1.7. Self control/conscienciousness research</p>\n<p>2. Guides for explicitly applying LW material to your life, smaller sequences and exercises</p>\n<p>3. Anki cards for the sequences and other useful topics/books</p>\n<p>4. Introductory material that gets people hooked</p>\n<p>5. User friendly guides to existing LW material</p>\n<p>6. Meetup materials:</p>\n<p style=\"padding-left: 30px; \">6.1. Exercises</p>\n<p style=\"padding-left: 60px; \">6.1.1. Anti-rationalization</p>\n<p style=\"padding-left: 30px; \">6.2. Notes and slides for presentations on specific topics</p>\n<p style=\"padding-left: 30px; \">6.3. Game how-tos&nbsp;</p>\n<p style=\"padding-left: 30px; \">6.4. Rejection therapy</p>\n<p style=\"padding-left: 60px; \">6.4.1. Repetition</p>\n<p>7. Book reviews on potentially useful books</p>\n<p style=\"padding-left: 30px; \">7.1. Selfish Reasons to have more kids (critique/review)</p>\n<p style=\"padding-left: 30px; \">7.2. Consciousness Explained</p>\n<p>8. Cleaning up <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\">cognitive bias Wikipedia entries</a></p>\n<p>9. Developing exercises and tests that help understand or improve rationality&nbsp;</p>\n<p style=\"padding-left: 30px; \">9.1. A large set of good calibration questions</p>\n<p style=\"padding-left: 30px; \">9.2. A good website for taking calibration tests</p>\n<p>10. Financial analyses, like Brandon Reinhart's analysis of SIAI</p>\n<p style=\"padding-left: 30px; \">10.1. The Cryonics Institute</p>\n<p style=\"padding-left: 30px; \">10.2. Alcor</p>\n<p style=\"padding-left: 30px; \">10.3. FHI</p>\n<p>11. Resources/Advice to help people do projects</p>\n<p style=\"padding-left: 30px; \">11.1. Advice for doing research</p>\n<p style=\"padding-left: 60px; \">11.1.1. Doing literature reviews</p>\n<p style=\"padding-left: 60px; \">11.1.2. Dealing with publication bias</p>\n<p style=\"padding-left: 60px; \">11.1.3. Signs of researcher bias</p>\n<p style=\"padding-left: 60px; \">11.1.4. Searching for critical viewpoints, alternative theories, disconfirming evidence</p>\n<p style=\"padding-left: 60px; \">11.1.5. How do you know when you're done?&nbsp;</p>\n<p>12. Improvements to LW's site</p>\n<p style=\"padding-left: 30px; \">12.1. Creation of a LW hosting image to drastically reduce the work needed to work on less wrong</p>\n<p style=\"padding-left: 30px; \">12.2.&nbsp;Selenium&nbsp;tests for the less wrong site so that bugs are caught faster</p>\n<p style=\"padding-left: 30px; \">12.3. Larger user pages</p>\n<p style=\"padding-left: 30px; \">12.4. A better front page for lesswrong (prize?)</p>\n<p style=\"padding-left: 30px; \">12.5. Setting up other language version of LW and/or translations&nbsp;</p>\n<p style=\"padding-left: 60px;\">12.5.1. Russian&nbsp;</p>\n<p style=\"padding-left: 60px;\">12.5.2. Portuguese</p>\n<p style=\"padding-left: 60px;\">12.5.3. Spanish</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QPt5ECwTCAg63mbNu": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S6dfEC4xPjrjPgonx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 27, "extendedScore": null, "score": 5.2e-05, "legacy": true, "legacyId": "8826", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbBM2gkAsSrX5gbmx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-31T05:57:50.238Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Science as Attire", "slug": "seq-rerun-science-as-attire", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.838Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E4QjcJEJrn2paTwm9/seq-rerun-science-as-attire", "pageUrlRelative": "/posts/E4QjcJEJrn2paTwm9/seq-rerun-science-as-attire", "linkUrl": "https://www.lesswrong.com/posts/E4QjcJEJrn2paTwm9/seq-rerun-science-as-attire", "postedAtFormatted": "Sunday, July 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Science%20as%20Attire&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Science%20as%20Attire%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE4QjcJEJrn2paTwm9%2Fseq-rerun-science-as-attire%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Science%20as%20Attire%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE4QjcJEJrn2paTwm9%2Fseq-rerun-science-as-attire", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE4QjcJEJrn2paTwm9%2Fseq-rerun-science-as-attire", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p>Title: [SEQ RERUN] Science as Attire Tags: sequence_reruns Today's post, <a href=\"/lw/ir/science_as_attire/\">Science as Attire</a> was originally published on 23 August 2007. A summary:</p>\n<blockquote>Science is about detailed models of the world. However, many people view science as a set of technical-sounding terms, or a certain type of beliefs that are professed by the group called \"scientists\". For instance, the X-Men series is perceived as being in the literary genre of science (fiction), instead of fantasy, because the superpowers are \"explained\" by the word \"mutation\".</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/6wl/seq_rerun_guessing_the_teachers_password/\">Guessing the Teacher's Password</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E4QjcJEJrn2paTwm9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.483475200349124e-07, "legacy": true, "legacyId": "8958", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4Bwr6s9dofvqPWakn", "KuHAsQzh6wBP3ueXS", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-31T13:52:42.257Z", "modifiedAt": null, "url": null, "title": "Really good education podcasts", "slug": "really-good-education-podcasts", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.364Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NRjQupwCCcki6XnbB/really-good-education-podcasts", "pageUrlRelative": "/posts/NRjQupwCCcki6XnbB/really-good-education-podcasts", "linkUrl": "https://www.lesswrong.com/posts/NRjQupwCCcki6XnbB/really-good-education-podcasts", "postedAtFormatted": "Sunday, July 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Really%20good%20education%20podcasts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReally%20good%20education%20podcasts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNRjQupwCCcki6XnbB%2Freally-good-education-podcasts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Really%20good%20education%20podcasts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNRjQupwCCcki6XnbB%2Freally-good-education-podcasts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNRjQupwCCcki6XnbB%2Freally-good-education-podcasts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<p>Hi everyone,</p>\n<p>&nbsp;</p>\n<p>currently temping at a job that's very autonomous and boring. good thing is i can listen to stuff on my phone while I do it.</p>\n<p>&nbsp;</p>\n<p>Just wondering what people's favorite podcasts are? particularly education ones to do with neuroscience, psych and social studies.</p>\n<p>However as long as it's interesting I'm keen give it a go.</p>\n<p>&nbsp;</p>\n<p>Thanks in advance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NRjQupwCCcki6XnbB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -1, "extendedScore": null, "score": 5e-06, "legacy": true, "legacyId": "8959", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-31T15:22:51.959Z", "modifiedAt": null, "url": null, "title": "When programs have to work-- lessons from NASA", "slug": "when-programs-have-to-work-lessons-from-nasa", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.468Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TYDqF4EbH3hDDvPaB/when-programs-have-to-work-lessons-from-nasa", "pageUrlRelative": "/posts/TYDqF4EbH3hDDvPaB/when-programs-have-to-work-lessons-from-nasa", "linkUrl": "https://www.lesswrong.com/posts/TYDqF4EbH3hDDvPaB/when-programs-have-to-work-lessons-from-nasa", "postedAtFormatted": "Sunday, July 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20programs%20have%20to%20work--%20lessons%20from%20NASA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20programs%20have%20to%20work--%20lessons%20from%20NASA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYDqF4EbH3hDDvPaB%2Fwhen-programs-have-to-work-lessons-from-nasa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20programs%20have%20to%20work--%20lessons%20from%20NASA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYDqF4EbH3hDDvPaB%2Fwhen-programs-have-to-work-lessons-from-nasa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYDqF4EbH3hDDvPaB%2Fwhen-programs-have-to-work-lessons-from-nasa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 856, "htmlBody": "<p><a href=\"http://www.fastcompany.com/magazine/06/writestuff.html\">They Write the Right Stuff</a> is about software which \"never crashes. It never needs to be re-booted. This software is bug-free. It is perfect, as perfect as human beings have achieved. Consider these stats : the last three versions of the program -- each 420,000 lines long-had just one error each. The last 11 versions of this software had a total of 17 errors. Commercial programs of equivalent complexity would have 5,000 errors.\"</p>\n<p>The programmers work from 8 to 5, with <em>occasional</em> late nights. They wear dressy clothes, not flashy or grungy. I assume there's a dress code, but I have no idea whether conventional clothes are actually an important part of the process. I'm sure that working reasonable numbers of hours is crucial, though I also wonder whether those hours need to be standard office hours.</p>\n<p>\"And the culture is equally intolerant of creativity, the individual  coding flourishes and styles that are the signature of the all-night  software world. \"People ask, doesn't this process stifle creativity? You  have to do exactly what the manual says, and you've got someone looking  over your shoulder,\" says Keller. \"The answer is, yes, the process does  stifle creativity.\" \" I have no idea what's in the manual, or if there can be a manual for something as new as self-optimizing AI. I assume there could be a manual for some aspects.</p>\n<p>What follows is main points quoted from the article:</p>\n<p>The important thing is the process: <strong>The product is only as good as the plan for the product. </strong>About one-third of the process of writing software happens before anyone writes a line of code.</p>\n<p><strong>2. The best teamwork is a healthy rivalry.</strong> The central group breaks down into two key teams: the coders - the  people who sit and write code -- and the verifiers -- the people who try  to find flaws in the code. The two outfits report to separate bosses  and function under opposing marching orders. The development group is  supposed to deliver completely error-free code, so perfect that the  testers find no flaws at all. The testing group is supposed to pummel  away at the code with flight scenarios and simulations that reveal as  many flaws as possible. The result is what Tom Peterson calls \"a  friendly adversarial relationship.\"</p>\n<p>I note that it's rivalry between people who are doing different things, not people competing to get control of a project.</p>\n<p><strong>3. The database is the software base. </strong></p>\n<p>One is the history of the code itself -- with every line annotated,  showing every time it was changed, why it was changed, when it was  changed, what the purpose of the change was, what specifications  documents detail the change. Everything that happens to the program is  recorded in its master history. The genealogy of every line of code --  the reason it is the way it is -- is instantly available to everyone.</p>\n<p>The other database -- the error database -- stands as a kind of  monument to the way the on-board shuttle group goes about its work. Here  is recorded every single error ever made while writing or working on  the software, going back almost 20 years. For every one of those errors,  the database records when the error was discovered; what set of  commands revealed the error; who discovered it; what activity was going  on when it was discovered -- testing, training, or flight. It tracks how  the error was introduced into the program; how the error managed to  slip past the filters set up at every stage to catch errors -- why  wasn't it caught during design? during development inspections? during  verification? Finally, the database records how the error was corrected,  and whether similar errors might have slipped through the same holes.</p>\n<p>The group has so much data accumulated about how it does its work  that it has written software programs that model the code-writing  process. Like computer models predicting the weather, the coding models  predict how many errors the group should make in writing each new  version of the software. True to form, if the coders and testers find  too few errors, everyone works the process until reality and the  predictions match.</p>\n<p><strong>4. Don't just fix the mistakes -- fix whatever permitted the mistake in the first place. </strong></p>\n<p>The process is so pervasive, it gets the blame for any error -- if  there is a flaw in the software, there must be something wrong with the  way its being written, something that can be corrected. Any error not  found at the planning stage has slipped through at least some checks.  Why? Is there something wrong with the inspection process? Does a  question need to be added to a checklist?</p>\n<p>Importantly, the group avoids blaming people for errors. The process  assumes blame - and it's the process that is analyzed to discover why  and how an error got through. At the same time, accountability is a team  concept: no one person is ever solely responsible for writing or  inspecting code. \"You don't get punished for making errors,\" says  Marjorie Seiter, a senior member of the technical staff. \"If I make a  mistake, and others reviewed my work, then I'm not alone. I'm not being  blamed for this.\"</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 1, "txkDg4aLmiRq8wsSu": 1, "zv7v2ziqexSn5iS9v": 1, "bL7yLj7hYQFoRtAmp": 1, "uL87Bw3TKzsYFMpZp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TYDqF4EbH3hDDvPaB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 37, "extendedScore": null, "score": 7.485252779370072e-07, "legacy": true, "legacyId": "8960", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"http://www.fastcompany.com/magazine/06/writestuff.html\">They Write the Right Stuff</a> is about software which \"never crashes. It never needs to be re-booted. This software is bug-free. It is perfect, as perfect as human beings have achieved. Consider these stats : the last three versions of the program -- each 420,000 lines long-had just one error each. The last 11 versions of this software had a total of 17 errors. Commercial programs of equivalent complexity would have 5,000 errors.\"</p>\n<p>The programmers work from 8 to 5, with <em>occasional</em> late nights. They wear dressy clothes, not flashy or grungy. I assume there's a dress code, but I have no idea whether conventional clothes are actually an important part of the process. I'm sure that working reasonable numbers of hours is crucial, though I also wonder whether those hours need to be standard office hours.</p>\n<p>\"And the culture is equally intolerant of creativity, the individual  coding flourishes and styles that are the signature of the all-night  software world. \"People ask, doesn't this process stifle creativity? You  have to do exactly what the manual says, and you've got someone looking  over your shoulder,\" says Keller. \"The answer is, yes, the process does  stifle creativity.\" \" I have no idea what's in the manual, or if there can be a manual for something as new as self-optimizing AI. I assume there could be a manual for some aspects.</p>\n<p>What follows is main points quoted from the article:</p>\n<p>The important thing is the process: <strong>The product is only as good as the plan for the product. </strong>About one-third of the process of writing software happens before anyone writes a line of code.</p>\n<p><strong>2. The best teamwork is a healthy rivalry.</strong> The central group breaks down into two key teams: the coders - the  people who sit and write code -- and the verifiers -- the people who try  to find flaws in the code. The two outfits report to separate bosses  and function under opposing marching orders. The development group is  supposed to deliver completely error-free code, so perfect that the  testers find no flaws at all. The testing group is supposed to pummel  away at the code with flight scenarios and simulations that reveal as  many flaws as possible. The result is what Tom Peterson calls \"a  friendly adversarial relationship.\"</p>\n<p>I note that it's rivalry between people who are doing different things, not people competing to get control of a project.</p>\n<p><strong id=\"3__The_database_is_the_software_base__\">3. The database is the software base. </strong></p>\n<p>One is the history of the code itself -- with every line annotated,  showing every time it was changed, why it was changed, when it was  changed, what the purpose of the change was, what specifications  documents detail the change. Everything that happens to the program is  recorded in its master history. The genealogy of every line of code --  the reason it is the way it is -- is instantly available to everyone.</p>\n<p>The other database -- the error database -- stands as a kind of  monument to the way the on-board shuttle group goes about its work. Here  is recorded every single error ever made while writing or working on  the software, going back almost 20 years. For every one of those errors,  the database records when the error was discovered; what set of  commands revealed the error; who discovered it; what activity was going  on when it was discovered -- testing, training, or flight. It tracks how  the error was introduced into the program; how the error managed to  slip past the filters set up at every stage to catch errors -- why  wasn't it caught during design? during development inspections? during  verification? Finally, the database records how the error was corrected,  and whether similar errors might have slipped through the same holes.</p>\n<p>The group has so much data accumulated about how it does its work  that it has written software programs that model the code-writing  process. Like computer models predicting the weather, the coding models  predict how many errors the group should make in writing each new  version of the software. True to form, if the coders and testers find  too few errors, everyone works the process until reality and the  predictions match.</p>\n<p><strong id=\"4__Don_t_just_fix_the_mistakes____fix_whatever_permitted_the_mistake_in_the_first_place__\">4. Don't just fix the mistakes -- fix whatever permitted the mistake in the first place. </strong></p>\n<p>The process is so pervasive, it gets the blame for any error -- if  there is a flaw in the software, there must be something wrong with the  way its being written, something that can be corrected. Any error not  found at the planning stage has slipped through at least some checks.  Why? Is there something wrong with the inspection process? Does a  question need to be added to a checklist?</p>\n<p>Importantly, the group avoids blaming people for errors. The process  assumes blame - and it's the process that is analyzed to discover why  and how an error got through. At the same time, accountability is a team  concept: no one person is ever solely responsible for writing or  inspecting code. \"You don't get punished for making errors,\" says  Marjorie Seiter, a senior member of the technical staff. \"If I make a  mistake, and others reviewed my work, then I'm not alone. I'm not being  blamed for this.\"</p>\n<p>&nbsp;</p>", "sections": [{"title": "3. The database is the software base. ", "anchor": "3__The_database_is_the_software_base__", "level": 1}, {"title": "4. Don't just fix the mistakes -- fix whatever permitted the mistake in the first place. ", "anchor": "4__Don_t_just_fix_the_mistakes____fix_whatever_permitted_the_mistake_in_the_first_place__", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "50 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-31T18:27:33.014Z", "modifiedAt": null, "url": null, "title": "How to detonate a technology singularity using only parrot level intelligence - new meetup.com group in Silicon Valley to design and create it", "slug": "how-to-detonate-a-technology-singularity-using-only-parrot", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.115Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BenRayfield", "createdAt": "2009-12-31T19:13:03.252Z", "isAdmin": false, "displayName": "BenRayfield"}, "userId": "wE65z89Ecbt9ny679", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sfjvTeYQFRxmimkLv/how-to-detonate-a-technology-singularity-using-only-parrot", "pageUrlRelative": "/posts/sfjvTeYQFRxmimkLv/how-to-detonate-a-technology-singularity-using-only-parrot", "linkUrl": "https://www.lesswrong.com/posts/sfjvTeYQFRxmimkLv/how-to-detonate-a-technology-singularity-using-only-parrot", "postedAtFormatted": "Sunday, July 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20detonate%20a%20technology%20singularity%20using%20only%20parrot%20level%20intelligence%20-%20new%20meetup.com%20group%20in%20Silicon%20Valley%20to%20design%20and%20create%20it&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20detonate%20a%20technology%20singularity%20using%20only%20parrot%20level%20intelligence%20-%20new%20meetup.com%20group%20in%20Silicon%20Valley%20to%20design%20and%20create%20it%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfjvTeYQFRxmimkLv%2Fhow-to-detonate-a-technology-singularity-using-only-parrot%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20detonate%20a%20technology%20singularity%20using%20only%20parrot%20level%20intelligence%20-%20new%20meetup.com%20group%20in%20Silicon%20Valley%20to%20design%20and%20create%20it%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfjvTeYQFRxmimkLv%2Fhow-to-detonate-a-technology-singularity-using-only-parrot", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsfjvTeYQFRxmimkLv%2Fhow-to-detonate-a-technology-singularity-using-only-parrot", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2458, "htmlBody": "<p>&nbsp;</p>\n<div style=\"width: 100%; height: 100%; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; font-family: verdana, arial, sans-serif; color: #272727; font-weight: normal; font-size: 75%; padding: 0px; margin: 0px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\"><a href=\"http://www.meetup.com/technology-singularity-detonator\">http://www.meetup.com/technology-singularity-detonator</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">9 people joined in the last 5 hours and the first meetup hasn't even happened yet. This is the meetup description, including technical designs and how it leads to singularity:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">The plan is to detonate an intelligence explosion (leading to a technology-singularity) starting with an open-source Java artificial intelligence (AI) software which networks peoples' minds together through the internet using realtime interactive psychology of feedback loops between mouse movements and generated audio. \"Technological singularity refers to the hypothetical future emergence of greater-than human intelligence through technological means.\" http://en.wikipedia.org/wiki/Technological_singularity Computer programming is not required to join the group, but some kind of technical or abstract thinking skill is. We are going to make this happen, not talk about it endlessly like so many other AI groups do. Audivolv 0.1.7 is a very early and version of the user-interface. The final version will be a massively multiplayer audio game unlike any existing game. It will learn based on mouse movements in realtime instead of requiring good/bad buttons to train it. The core AI systems have not been created yet. Audivolv is just the user-interface for that. http://sourceforge.net/projects/audivolv The whole system will be 1 file you double-click to run and it works immediately on Windows, Mac, or Linux. This does not include Audivolv yet and has some parts that may be removed: http://sourceforge.net/projects/humanainet It must be a \"Friendly AI\", which means it will be designed not to happen like in the Terminator movies or similar science fiction. It will work toward more productive goals and help the Human species. http://en.wikipedia.org/wiki/Friendly_artificial_intelligence My plan to make that happen is for it to be made of many peoples' minds and many computers, so it is us. It becomes smarter when we become smarter. One of the effects of that will be to extremely increase Dunbar's Number, which is the number of people or organizations that a person can intelligently interact with before forgetting others. Dunbar's number is estimated around 150 today. http://en.wikipedia.org/wiki/Dunbar%27s_number</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">This only requires the AI be as smart as a parrot, since the people using the program do most of the thinking and the AI only organizes their thoughts statistically enough to decide who should connect to who else, in the way evolved code is traded (and verified to use only math so its safe) between computers automatically, in this massively multiplayer audio game. We will detonate a technology singularity using only the intelligence of a parrot plus the intelligence of people using the program. This is very surprising to most people who think huge grids of computers and experts are required to build Human intelligence in a machine. This is a shortcut, and will have much better results because it is us so it has no reason to act against us, like an AI made only of software may do.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Infrastructure</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Communication between these programs through the internet will be done as a Distributed Hash Table. The most important part of that is each key (hash of some file bytes) has a well-defined distance to each other key, a distance(hash1,hash2) function, which proves the correct direction to search the network to find the bytes of any hash, or to statistically verify (but not certainly) that its not in the network. There may be a way to do it certainly, but for my purposes approximate searching will work.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">In the same Distributed Hash Table, there will be public-keys, used like filenames or identities, whose content can be modified only by whoever has the private-key. If code evolves to include calculations based on your mouse movements and the mouse movements of 5 other people in realtime, then the numbers from those other mouse movements (between -1 and 1 for each of 2 dimensions, for each of 5 people) will be digitally-signed so everyone who uses the evolved code will know it is using the same people's continuing mouse movements instead of is a modified code. The code can be modified, but that would have a different hash and would be considered on its own merits instead of knowledge about the previous code and its specific connections to specific people. This will be done in realtime, not something to be saved and loaded later from a hard-drive. Each new mouse position (or a few of them sent at once) will be digitally-signed and broadcast to the network, the same as any other data broadcast to the network.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">http://en.wikipedia.org/wiki/Distributed_hash_table</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Similarly, but more fuzzy, the psychology of feedback loops between mouse movements and automatically evolving Java code, will be used as a distance function, and a second network organized that way, so you can search the network in the direction of other people whose psychology is more similar to your current state of mind and how you're using the program. This decentralized network will be searchable by your subconscious thoughts, because subconscious thoughts are expressed in how your mouse movements cause the code to evolve.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">As you search this network automatically by moving your mouse, you will trade evolved code with those computers, always automatically verifying the code only uses math and no file-access or java.lang.System class or anything else not provably safe. You will experience the downloaded code as it gradually connects to the code evolved for your mouse movements, code which generates audio as 44100 audio amplitudes (number between -1 and 1) per second per speaker.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Some of the variables in the evolved code will be the hash of other evolved code. Each evolved code will have a hash, probably from the SHA-256 algorithm, so it could be a length 64 hex string written in the code. Each variable will be a number beween -1 and 1. No computer will have all the codes for all its variables, but for those it doesn't have, it will use them simply as a variable. If it has those codes, then there is an extra behavior of giving that code an amount of influence proportional to the value of the variable, or deleting the code if the variable becomes negative for too long. In that way, evolved code will decide which other evolved code to download and how much influence each evolved code should have on the array of floating point numbers in the local computer.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Since the decentralized network will be searched by psychology (instead of text or pixels in an image or other things search-engines know how to do today), and since its connected to each person's subconscious mind through mouse/music feedback loops, the effect will be a collective mind made of many people and computers. We are Human AI Net, do you want to be temporarily assimilated?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-left: 0px; margin-bottom: 0.7em; font-size: 1em; padding: 0px;\">Alternative To Brain Implants&nbsp;<br /><br />Statistically inputs and outputs to neurons subconsciously without extra hardware.&nbsp;<br /><br />A neuron is a brain cell that connects to thousands of other neurons and slowly adjusts its electricity and chemical patterns as it learns.&nbsp;<br /><br />An incorrect assumption has extremely delayed the creation of technology that transfers thoughts between 2 brains. That assumption is, to quickly transfer large amounts of information between a brain and a computer, you need hardware that connects directly to neurons.&nbsp;<br /><br />Eyes and ears transfer a lot of information to a brain, but the other part of that assumption is eyes and ears are only useful for pictures and sounds that make sense and do not appear as complete randomness or whitenoise. People assume anything that sounds like radio static (a typical random sound) can't be used to transfer useful information into a brain.&nbsp;<br /><br />Most of us remember what a dial-up-modem sounds like. It sounds like information is in it but its too fast for Humans to understand. That's true of the dial-up-modem sound only because its digital and is designed for a modem instead of for Human ears which can hear around 1500 tones and simultaneously a volume for each. The dial-up-modem can only hear 1 tone that oscillates between 1 and 0, and no volume, just 1 or 0. It gets 56000 of those 1s and 0s per second. Human ears are analog so they have no such limits, but brains can think at most at 100 changes per second.&nbsp;<br /><br />If volume can have 20 different values per tone, then Human ears can hear up to 1500*100*log_base_2(20)=650000 bits of information per second. If you could take full advantage of that speed, you could transfer a book every few seconds into your brain, but the next bottleneck is your ability to think that fast.&nbsp;<br /><br />If you use ears the same way dial-up-modems use a phone line, but in a way designed for Human ears and Human brains instead of computers, then your ears are much faster data transfer devices than brain implants, and the same is true for transferring information as random-appearing grids of changing colors through your eyes. We have computer speakers and screens for input to brains. We still have some work to do on the output speeds of mouse and keyboard, but there are electricity devices you can wear on your head for the output direction. For the input direction, eyes and ears are currently far ahead of the most advanced technology in their data speeds to your brain.&nbsp;<br /><br />So why do businesses and governments keep throwing huge amounts of money at connecting computer chips directly to neurons? They should learn to use eyes and ears to their full potential before putting so much resources into higher bandwidth connections to brains. They're not nearly using the bandwidth they already have to brains.&nbsp;<br /><br />Intuitively most people know how music can affect their subconscious thoughts. Music is a low bandwidth example. It has mostly predictable and repeated sounds. The same voices. The same instruments. What I'm talking about would sound more like radio static or whitenoise. You wouldn't know what information is in it from its sound. You would only understand it after it echoed around your neuron electricity patterns in subconscious ways.&nbsp;<br /><br />Most people have only a normal computer available, so the brain-to-computer direction of information flow has to be low bandwidth. It can be mouse movements, gyroscope based game controllers, video camera detecting motion, or devices like that. The computer-to-brain direction can be high bandwidth, able to transfer information faster than you can think about it.&nbsp;<br /><br />Why hasn't this been tried? Because science proceeds in small steps. This is a big step from existing technology but a small step in the way most people already have the hardware (screen, speakers, mouse, etc). The big step is going from patterns of random-appearing sounds or video to subconscious thoughts to mouse movements to software to interpret it statistically, and around that loop many times as the Human and computer learn to predict each other. Compared to that, connecting a chip directly to neurons is a small step.&nbsp;<br /><br />Its a feedback loop: computer, random-appearing sound or video, ears or eyes, brain, mouse movements, and back to computer. Its very indirect but uses hardware that has evolved for millions of years, compared to low-bandwidth hardware they implant in brains. Eyes and ears are much higher bandwidth, and we should be using them in feedback loops for brain-to-brain and brain-to-computer communication.&nbsp;<br /><br />What would it feel like? You would move the mouse and instantly hear the sounds change based on how you moved it. You would feel around the sound space for abstract patterns of information you're looking for, and you would learn to find it. When many people are connected this way through the internet, using only mouse movements and abstract random-like sounds instead of words and pictures, thoughts will flow between the brains of different people, thoughts that they don't know how to put into words. They would gradually learn to think more as 1 mind. Brains naturally learn to communicate with any system connected to them. Brains dont care how they're connected. They grow into a larger mind. It happens between the parts of your brain, and it will happen between people using this system through the internet.&nbsp;<br /><br />Artificial intelligence software does not have to replace us or compete with us. The best way to use it is to connect our minds together. It can be done through brain implants, but why wait for that technology to advance and become cheap and safe enough? All you need is a normal computer and the software to connect our subconscious thoughts and statistical patterns of interaction with the computer.&nbsp;<br /><br />Dial-up-modem sounds were designed for computers. These interactive sounds/videos would be designed for Human ears/eyes and the slower but much bigger and parallel way the data goes into brains. For years I've been carefully designing a free open-source software http://HumanAI.net &nbsp;- Human and Artificial Intelligence Network, or Human AI Net - to make this work. It will be a software that does for Human brains what dial-up-modems do for computers, and it will sound a little like a dial-up-modem at first but start to sound like music when you learn how to use it. I don't need brain implants to flow subconscious thoughts between your brains over internet wires.&nbsp;<br /><br />Intelligence is the most powerful thing we know of. The brain implants are simply overkill, even if they become advanced enough to do what I'll use software and psychology to do. We can network our minds together and amplify intelligence and share thoughts without extra hardware. After thats working, we can go straight to quantum devices for accessing brains without implants. Lets do this through software and skip the brain implant paradigm. If it works just a little, it will be enough that our combined minds will figure out how to make it work a lot more. Thats how I prefer to start a&nbsp; http://en.wikipedia.org/wiki/Technological_singularity&nbsp; We don't need businesses and militaries to do it first. We have the hardware on our desks. We're only missing the software. It doesn't have to be smarter than Human software. It just has to be smart enough to connect our subconscious thoughts together. The authorities have their own ideas about how we should communicate and how our minds should be allowed to think together, but their technology was obsolete before it was created. We can do everything they can do without brain implants, using only software and subconscious psychology. We don't need a smarter-than-Human software, or anything nearly that advanced, to create a technology singularity. Who wants to help me change the direction of Human evolution using an open-source (GNU GPL) software? Really, you can create a technology singularity starting from a software with the intelligence of a parrot, as long as you use it to connect Human minds together.</p>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sfjvTeYQFRxmimkLv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": -25, "extendedScore": null, "score": -3.4e-05, "legacy": true, "legacyId": "8961", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-07-31T22:05:20.199Z", "modifiedAt": null, "url": null, "title": "Why no uniform weightings for ensemble universes?", "slug": "why-no-uniform-weightings-for-ensemble-universes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:29.805Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Will_Newsome", "createdAt": "2010-02-25T03:52:25.697Z", "isAdmin": false, "displayName": "Will_Newsome"}, "userId": "CxM9n2EDSn4AYgLdi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NAE6jX9Hp4E4yf3vM/why-no-uniform-weightings-for-ensemble-universes", "pageUrlRelative": "/posts/NAE6jX9Hp4E4yf3vM/why-no-uniform-weightings-for-ensemble-universes", "linkUrl": "https://www.lesswrong.com/posts/NAE6jX9Hp4E4yf3vM/why-no-uniform-weightings-for-ensemble-universes", "postedAtFormatted": "Sunday, July 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20no%20uniform%20weightings%20for%20ensemble%20universes%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20no%20uniform%20weightings%20for%20ensemble%20universes%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNAE6jX9Hp4E4yf3vM%2Fwhy-no-uniform-weightings-for-ensemble-universes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20no%20uniform%20weightings%20for%20ensemble%20universes%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNAE6jX9Hp4E4yf3vM%2Fwhy-no-uniform-weightings-for-ensemble-universes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNAE6jX9Hp4E4yf3vM%2Fwhy-no-uniform-weightings-for-ensemble-universes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 441, "htmlBody": "<p>Every now and then I see a claim that if there were a uniform weighting of mathematical structures in a Tegmark-like 'verse---whatever that would mean even if we ignore the decision theoretic aspects which really can't be ignored but whatever---that would imply we should expect to find ourselves as Boltzmann mind-computations, or in other words thingies with just enough consciousness to be conscious of nonsensical chaos for a brief instant before dissolving back into nothingness. We don't seem to be experiencing nonsensical chaos, therefore the argument concludes that a uniform weighting is inadequate and an Occamian weighting over structures is necessary, leading to something like UDASSA or eventually giving up and sweeping the remaining confusion into a decision theoretic framework like UDT. (Bringing the dreaded \"anthropics\" into it is probably a red herring like always; we can just talk directly about patterns and groups of structures or correlated structures given some weighting, and presume human minds are structures or groups of structures much like other structures or groups of structures given that weighting.)&nbsp;</p>\n<p>I've seen people who seem very certain of the Boltzmann-inducing properties of uniform weightings for various reasons that I am skeptical of, and others who seemed uncertain of this for reason that sound at least superficially reasonable. Has anyone thought about this enough to give slightly more than just an intuitive appeal?&nbsp;I wouldn't be surprised if everyone has left such 'probabilistic' cosmological reasoning for the richer soils of decision theoretically inspired speculation, and if everyone else never ventured into the realms of such madness in the first place.</p>\n<p>&nbsp;</p>\n<p>(Bringing in something, anything, from the foundations of set theory, e.g. the set theoretic multiverse, might be one way to start, but e.g. \"most natural numbers look pretty random and we can use something like Goedel numbering for arbitrary mathematical structures\" doesn't seem to say much to me by itself, considering that all of those numbers have rich <em>local</em>&nbsp;context that in their region is very predictable and non-random, if you get my metaphor. Or to stretch the metaphor even further, even if 62534772 doesn't \"causally\" follow 31256 they might still be correlated in the style of Dust Theory, and what meta-level tools are we going to use to talk about the randomness or \"size\" of those correlations, especially given that 294682462125 could refer to a mathematical structure of some underspecified \"size\" (e.g. a mathematically \"simple\" entire multiverse and not a \"complex\" human brain computation)? In general I don't see how such metaphors can't just be twisted into meaninglessness or assumptions that I don't follow, and I've never seen clear arguments that don't rely on either such metaphors or just flat out intuition.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NAE6jX9Hp4E4yf3vM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 6, "extendedScore": null, "score": 7.486519406747527e-07, "legacy": true, "legacyId": "8962", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T01:10:34.491Z", "modifiedAt": null, "url": null, "title": "Teaching Introspection", "slug": "teaching-introspection", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.090Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rdraFxx2jysvLqRuh/teaching-introspection", "pageUrlRelative": "/posts/rdraFxx2jysvLqRuh/teaching-introspection", "linkUrl": "https://www.lesswrong.com/posts/rdraFxx2jysvLqRuh/teaching-introspection", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Teaching%20Introspection&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATeaching%20Introspection%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdraFxx2jysvLqRuh%2Fteaching-introspection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Teaching%20Introspection%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdraFxx2jysvLqRuh%2Fteaching-introspection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdraFxx2jysvLqRuh%2Fteaching-introspection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1138, "htmlBody": "<p>As Yvain pointed out in his recent post <a href=\"/lw/6p6/the_limits_of_introspection/\">The Limits of Introspection</a>, humans are not naturally good at inferring our cognitive processes. We resort to guessing with plausible-sounding stories about ourselves, and we aren&rsquo;t very accurate.</p>\n<p>I was reminded of this recently while teaching a swimming lesson. (You'll understand later why this reminded me.) A recurring problem that I&rsquo;ve noticed with both children and adults is that it isn&rsquo;t obvious to them what their bodies are doing. Feet go in strange directions, hands fail to lift above the water, and they literally can&rsquo;t describe what it feels like. It&rsquo;s pretty much impossible for a novice swimmer to watch the instructor demonstrate front crawl and then imitate it perfectly&ndash;muscular control isn&rsquo;t that perfect. That&rsquo;s why there are swimming instructors: because it&rsquo;s very, very hard to learn swimming (or dance, or soccer, or a martial art) by reading a book, even if that book has illustrated diagrams. Two friends reading the book together and watching each other&rsquo;s attempts in the pool would probably do better, but that&rsquo;s still a case, metaphorically, of the blind leading the blind. Most sports have instructors and coaches who are, relatively speaking, experts. (I competed at the regional level in swimming for something like five years and trained five to seven times a week the whole time, which pretty much qualifies me to teach eight-year-olds. An Olympic coach would need a much higher level of mastery.)</p>\n<p>The most basic thing a coach provides that the two friends practicing together don&rsquo;t have is relevant feedback. I watch a young swimmer demonstrating her front crawl, and I can immediately chunk my observations into &ldquo;what&rsquo;s done properly&rdquo; and &ldquo;what&rsquo;s done wrong&rdquo; and translate the latter category into &ldquo;things to change.&rdquo; And the easiest way to learn perfect front crawl isn&rsquo;t to do it over and over again with tiny changes, but to practice exaggerated and simplified &ldquo;drills&rdquo; that teach particular fragments of muscle memory. Faced with a given stroke problem, I can look over a list of about eight different front crawl drills to find the one best suited for fixing it. To place some objective measure on the improvements, I can time my swimmers or count their strokes per length The coaches of more elite swimmers have even fancier tools in their hands: videotaping, fins and hand paddles, and the flume, basically a wind tunnel in the water. (I wish I had one of these in my basement!) All to provide better feedback: even Olympic-level swimmers don&rsquo;t automatically know what their bodies are doing wrong or what needs to be fixed. (I&rsquo;m assuming this is true of sports other than swimming, too.)</p>\n<p>Granted, human muscles do start out under some voluntary control. A baby learns how to walk with no instruction, only the feedback of trial and error. (And of seeing adults walk? I seem to remember reading that some feral children crawl on hands and knees, and seem to prefer this method to walking.) But even apparently involuntary skills can be learned, with the help of creative technology. With biofeedback, people can control their <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/21656149\">blood pressure</a>&nbsp;and&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/21533678\">anxiety levels</a>&nbsp;and apparently various other processes&nbsp;. The parallel should be obvious here. Introspection, like physical coordination, is only imperfectly under conscious control&hellip;but there is some control. That&rsquo;s what consciousness is: self-awareness. Most people are aware that they have emotions, and that they make decisions because of their emotions, i.e. &ldquo;I didn&rsquo;t mean it, I just did it because I was angry!&rdquo; Likewise, most people are aware of their likes and dislikes. It&rsquo;s only a small leap to recognize that these kinds of preferences are <a href=\"/lw/5aj/vanilla_and_chocolate_and_preference_judgements/\">malleable facts about the state of the brain</a>, not immutable facts about the outside world. People do succeed in wrestling with their uncooperative minds, fighting akrasia and making deliberate and reasoned decisions.</p>\n<p>Nevertheless, most people aren&rsquo;t even at the same level, metaphorically speaking, as a non-swimmer trying to learn from diagrams in a book. The literature on <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\">cognitive biases</a> and Alicorn's sequence on <a href=\"/lw/1xh/living_luminously/\">luminosity</a> are a start on the &lsquo;book of introspection&rsquo; and some of the Less Wrong groups that meet in person are trying to help each other master these skills. The various schools of meditation are arguably about teaching introspection, and clinical psychology could be seen the same way. Is it possible to go further? Olympic coaches have probably maxed out how fast an unmodified human can swim; your technique can't be any better than perfect; but I would like to think that we haven&rsquo;t even scratched the limits of how well a completely unmodified human brain can understand itself. As far as I know, most traditions of meditation are just that: traditions, often ancient, that don&rsquo;t accommodate recent discoveries about the brain and about thought processes. And psychology is limited by the focus on fixing &lsquo;problems&rsquo; and returning patients to &lsquo;normal.&rsquo; (And if you are &lsquo;normal&rsquo;, you don&rsquo;t need a psychologist!) But everyone is affected equally by our apparently-innate inability to notice what our brains are really up to, and <em>normal </em>isn't a very ambitious standard.&nbsp;</p>\n<p>What does a cognitive bias feel like? I can&rsquo;t look back on my actions and say &ldquo;yeah, I&rsquo;m pretty sure I said Tide was my favourite detergent because I was still thinking about oceans and moons.&rdquo; Or at least, I can&rsquo;t do that automatically. But if a scientist can predict that participants in an experiment will choose Tide when thinking about oceans and moons, then I can predict that about myself, too, and look back on all my decisions, trying to infer what factors were present at the time that could have primed my choice. It&rsquo;s still a guess, but it&rsquo;s an informed, useful one. And with practice, with an expert instructor to point out what you&rsquo;re doing right and what you&rsquo;re doing wrong, maybe a given cognitive bias does feel like something recognizable. Maybe the hidden secrets of your thought processes would become transparent and obvious. The next problem is finding instructors who are sufficiently advanced, and teaching exercises to use. The repetitive and level-based nature of video games would make them ideal as &ldquo;thinking drills\" training \"neural memory\" instead of \"muscle memory.\"</p>\n<p>I don't know enough to guess at the specifics of what this kind of school might look like, but&nbsp;I would definitely take lessons in introspection if they were available&hellip;I can&rsquo;t really see a downside. Finding out that my decisions were due more often to random factors unconnected to to the Great Story That Is My Life might be unflattering, but it's equally awful whether I know about it or not, and knowing gives me a chance to fix those decisions that might otherwise turn out damagingly irrational. Anyone, or any group of people, willing to take on the task of becoming expert instructors in this field would hugely help those of us who have trouble learning procedural skills from books.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwv9eHi7KGg5KA9oM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rdraFxx2jysvLqRuh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 32, "extendedScore": null, "score": 7.487102502811192e-07, "legacy": true, "legacyId": "8957", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K2JBqDeETX2yEgyyZ", "mqQCuF2m9jSSAfHYB", "9o3Cjjem7AbmmZfBs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T05:31:42.327Z", "modifiedAt": null, "url": null, "title": "Ethical dilemmas for paperclip maximizers", "slug": "ethical-dilemmas-for-paperclip-maximizers", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cHPX35oNY63r7XxiB/ethical-dilemmas-for-paperclip-maximizers", "pageUrlRelative": "/posts/cHPX35oNY63r7XxiB/ethical-dilemmas-for-paperclip-maximizers", "linkUrl": "https://www.lesswrong.com/posts/cHPX35oNY63r7XxiB/ethical-dilemmas-for-paperclip-maximizers", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ethical%20dilemmas%20for%20paperclip%20maximizers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEthical%20dilemmas%20for%20paperclip%20maximizers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHPX35oNY63r7XxiB%2Fethical-dilemmas-for-paperclip-maximizers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ethical%20dilemmas%20for%20paperclip%20maximizers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHPX35oNY63r7XxiB%2Fethical-dilemmas-for-paperclip-maximizers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHPX35oNY63r7XxiB%2Fethical-dilemmas-for-paperclip-maximizers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 289, "htmlBody": "<p>(Why? <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/ItAmusedMe\">Because it's fun</a>.)</p>\n<p>1) Do paperclip maximizers care about paperclip <em>mass</em>, paperclip <em>count</em>, or both? More concretely, if you have a large, finite amount of metal, you can make it into N paperclips or N+1 smaller paperclips. If all that matters is paperclip mass, then it doesn't matter what size the paperclips are, as long as they can still hold paper. If all that matters is paperclip count, then, all else being equal, it seems better to prefer smaller paperclips.</p>\n<p>2) It's not hard to understand how to maximize the number of paperclips in space, but how about in time? Once it's made, does it matter how long a paperclip continues to exist? Is it better to have one paperclip that lasts for 10,000 years and is then destroyed, or 10,000 paperclips that are all destroyed after 1 year? Do discount rates apply to paperclip maximization? In other words, is it better to make a paperclip now than it is to make it ten years from now?</p>\n<p>3) Some paperclip maximizers claim want to maximize paperclip &lt;i&gt;production&lt;/i&gt;. This is not the same as maximizing paperclip count. Given a fixed amount of metal, a paperclip count maximizer would make the maximum number of paperclips possible, and then stop. A paperclip production maximizer that didn't care about paperclip count would find it useful to recycle existing paperclips, melting them down so that new ones could be made. Which approach is better?</p>\n<p>4) More generally, are there any conditions under which the paperclip-maximizing thing to do involves destroying existing paperclips? It's easy to imagine scenarios in which destroying some paperclips causes there to be more paperclips in the future. (For example, one could melt down existing paperclips and use the metal to make smaller ones.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QH4LhvnyR4QkW9MG8": 1, "hNFdS3rRiYgqqD8aM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cHPX35oNY63r7XxiB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 14, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "8971", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T15:04:32.167Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Causality", "slug": "seq-rerun-fake-causality", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jFRKw4exWh43NEKoq/seq-rerun-fake-causality", "pageUrlRelative": "/posts/jFRKw4exWh43NEKoq/seq-rerun-fake-causality", "linkUrl": "https://www.lesswrong.com/posts/jFRKw4exWh43NEKoq/seq-rerun-fake-causality", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Causality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Causality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFRKw4exWh43NEKoq%2Fseq-rerun-fake-causality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Causality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFRKw4exWh43NEKoq%2Fseq-rerun-fake-causality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFRKw4exWh43NEKoq%2Fseq-rerun-fake-causality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<p>Today's post, <a href=\"/lw/is/fake_causality/\">Fake Causality</a> was originally published on 23 August 2007.  A summary:</p>\n<blockquote>It is very easy for a human being to think that a theory <em>predicts </em>a phenomenon, when in fact is was <em>fitted </em>to a phenomenon. Properly designed reasoning systems (GAIs) would be able to avoid this mistake with our knowledge of probability theory, but humans have to write down a prediction in advance in order to ensure that our reasoning about causality is correct.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6wu/seq_rerun_science_as_attire/\">Science as Attire</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jFRKw4exWh43NEKoq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.489728654115848e-07, "legacy": true, "legacyId": "8978", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RgkqLqkg8vLhsYpfh", "E4QjcJEJrn2paTwm9", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T18:25:50.438Z", "modifiedAt": null, "url": null, "title": "Book of Mormon Discussion", "slug": "book-of-mormon-discussion", "viewCount": null, "lastCommentedAt": "2020-06-02T20:45:23.551Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Arandur", "createdAt": "2011-05-04T03:35:00.337Z", "isAdmin": false, "displayName": "Arandur"}, "userId": "c4YcZZqzWYdwazKHL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/juhSqE4H4tdSDezqC/book-of-mormon-discussion", "pageUrlRelative": "/posts/juhSqE4H4tdSDezqC/book-of-mormon-discussion", "linkUrl": "https://www.lesswrong.com/posts/juhSqE4H4tdSDezqC/book-of-mormon-discussion", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%20of%20Mormon%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%20of%20Mormon%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjuhSqE4H4tdSDezqC%2Fbook-of-mormon-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%20of%20Mormon%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjuhSqE4H4tdSDezqC%2Fbook-of-mormon-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjuhSqE4H4tdSDezqC%2Fbook-of-mormon-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 263, "htmlBody": "<p>In <a href=\"/r/discussion/lw/6vn/am_i_obligated_to_reread_the_book_of_mormon/4klc\">this comment thread</a>, I gave the following idea, on the topic of a method by which one might judge the Book of Mormon from a rationalist perspective:</p>\n<blockquote>\n<p>Why not make this an online thing? Day-by-day, or perhaps week-by-week, post (somewhere, not necessarily on Less Wrong, so as not to clutter the site; though perhaps Less Wrong would actually be the ideal locale, due to familiarity, extant population, etc?) a chapter of the Book of Mormon and allow discussion of it, separately from the rest of the Book, using terms common to Rationalists.</p>\n</blockquote>\n<p>I would appreciate feedback on this idea, for an admittedly selfish reason: I am trying to instigate in myself a <a href=\"/lw/ur/crisis_of_faith/\">Crisis of Faith</a>. So, here are the questions I pose to you:</p>\n<p>\n<ul>\n<li>Would it be a Good Idea to subject the Book of Mormon, chapter by chapter, to a group rationalist judgement?</li>\n<li>Would it be a Good Idea, given the above, to ask Less Wrong to host this discussion? On the one end, we want the maximum number of rationalists to input the maximum number of times, so we should host our discussion near the nexus of rationalist gathering. On the other end, <em>if</em>&nbsp;this discussion is judged to be&nbsp;frivolous&nbsp;and wasteful by the majority of active posters on Less Wrong, then we don't want to detract from the true meaning of the site.</li>\n</ul>\n<div>Remember: This is a good chance to examine the best arguments of those who believe that the sky is green. If the sky is green, then <em>you</em>&nbsp;should want to believe that the sky is green, too!</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "juhSqE4H4tdSDezqC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": -1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8981", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BcYBfG8KomcpcxkEg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T19:16:35.974Z", "modifiedAt": null, "url": null, "title": "Meetup : Helsinki meetup Fri 5.8 18:00-", "slug": "meetup-helsinki-meetup-fri-5-8-18-00", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sbrfRCXaENrrQe5eh/meetup-helsinki-meetup-fri-5-8-18-00", "pageUrlRelative": "/posts/sbrfRCXaENrrQe5eh/meetup-helsinki-meetup-fri-5-8-18-00", "linkUrl": "https://www.lesswrong.com/posts/sbrfRCXaENrrQe5eh/meetup-helsinki-meetup-fri-5-8-18-00", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Helsinki%20meetup%20Fri%205.8%2018%3A00-&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Helsinki%20meetup%20Fri%205.8%2018%3A00-%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbrfRCXaENrrQe5eh%2Fmeetup-helsinki-meetup-fri-5-8-18-00%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Helsinki%20meetup%20Fri%205.8%2018%3A00-%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbrfRCXaENrrQe5eh%2Fmeetup-helsinki-meetup-fri-5-8-18-00", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbrfRCXaENrrQe5eh%2Fmeetup-helsinki-meetup-fri-5-8-18-00", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1v'>Helsinki meetup Fri 5.8 18:00-</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 August 2011 06:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Yliopistonkatu 5, Helsinki, Finland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Third Helsinki meetup. Venue is Caf\u00e9 Picnic at Yliopistonkatu 5. Time is 18:00 onwards. ~5 confirmed attendees at the time of posting.</p>\n\n<p>Join the <a href=\"http://groups.google.com/group/lw-helsinki?pli=1\" rel=\"nofollow\"><strong>LW Helsinki mailing list</strong></a> for updates on Helsinki meetups.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1v'>Helsinki meetup Fri 5.8 18:00-</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sbrfRCXaENrrQe5eh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "8983", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Helsinki_meetup_Fri_5_8_18_00_\">Discussion article for the meetup : <a href=\"/meetups/1v\">Helsinki meetup Fri 5.8 18:00-</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 August 2011 06:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Yliopistonkatu 5, Helsinki, Finland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Third Helsinki meetup. Venue is Caf\u00e9 Picnic at Yliopistonkatu 5. Time is 18:00 onwards. ~5 confirmed attendees at the time of posting.</p>\n\n<p>Join the <a href=\"http://groups.google.com/group/lw-helsinki?pli=1\" rel=\"nofollow\"><strong>LW Helsinki mailing list</strong></a> for updates on Helsinki meetups.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Helsinki_meetup_Fri_5_8_18_00_1\">Discussion article for the meetup : <a href=\"/meetups/1v\">Helsinki meetup Fri 5.8 18:00-</a></h2>", "sections": [{"title": "Discussion article for the meetup : Helsinki meetup Fri 5.8 18:00-", "anchor": "Discussion_article_for_the_meetup___Helsinki_meetup_Fri_5_8_18_00_", "level": 1}, {"title": "Discussion article for the meetup : Helsinki meetup Fri 5.8 18:00-", "anchor": "Discussion_article_for_the_meetup___Helsinki_meetup_Fri_5_8_18_00_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-01T21:04:39.875Z", "modifiedAt": null, "url": null, "title": "Years saved: Cryonics vs VillageReach", "slug": "years-saved-cryonics-vs-villagereach", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:58.086Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "handoflixue", "createdAt": "2010-11-24T17:23:14.338Z", "isAdmin": false, "displayName": "handoflixue"}, "userId": "vGzwXwmR2qERvoGvb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EEofqZQsMKJfNTDKJ/years-saved-cryonics-vs-villagereach", "pageUrlRelative": "/posts/EEofqZQsMKJfNTDKJ/years-saved-cryonics-vs-villagereach", "linkUrl": "https://www.lesswrong.com/posts/EEofqZQsMKJfNTDKJ/years-saved-cryonics-vs-villagereach", "postedAtFormatted": "Monday, August 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Years%20saved%3A%20Cryonics%20vs%20VillageReach&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYears%20saved%3A%20Cryonics%20vs%20VillageReach%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEofqZQsMKJfNTDKJ%2Fyears-saved-cryonics-vs-villagereach%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Years%20saved%3A%20Cryonics%20vs%20VillageReach%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEofqZQsMKJfNTDKJ%2Fyears-saved-cryonics-vs-villagereach", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEofqZQsMKJfNTDKJ%2Fyears-saved-cryonics-vs-villagereach", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p>I've run in to the argument that cryonics beats VillageReach on a simple \"shut up and multiply\" level, by assuming an infinity vs finite tradeoff. Having read the Fun Theory sequences, it struck me that this wasn't a reasonable assumption, so I sat down, re-read a few relevant posts, shut up, and multiplied.</p>\n<p>In <a href=\"/lw/xk/continuous_improvement/\">Continuous Improvement</a>, Eliezer ballparks a good fun-theory life as having a maximum length of around 28,000 years. In Robin Hanson's<a href=\"http://www.overcomingbias.com/2009/03/break-cryonics-down.html\"> Cryonics Probability Breakdown</a>, he assigns cryonics a conjoint probability of about 6%. 28,000 * 0.06 gives us a net return of 1,680 expected years.</p>\n<p>Full body suspension from the Cryonics Institute <a href=\"http://cryonics.org/comparisons.html#Prices\">currently costs</a> $28,000.</p>\n<p>VillageReach, <a href=\"http://www.givewell.org/international/top-charities/villagereach\">according to GiveWell</a>, can save an infant's life for less than $1,000.</p>\n<p>For the price of Cryonics, we thus save 28 lives. 1680 expected years, divided by 28, puts the break-even point at an average lifespan of 60 years for those infants saved. A quick peak at <a href=\"http://en.wikipedia.org/wiki/File:Life_Expectancy_2005-2010_UN_WPP_2006.PNG\">Wikipedia </a>suggests that the average African life is under 60 years for the majority of the continent, although there are some <a href=\"http://en.wikipedia.org/wiki/Life_expectancy#Interpretation_of_life_expectancy\">important nuances</a> to really get a full picture.</p>\n<p>Obviously, these are rough numbers, and I doubt many people base their decisions solely on \"years lived\". I do find it rather interesting that cryonics is currently about on par with one of the most effective charities in the world on that metric, however :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 1, "Zs4nYLkNr7Rbo4mAP": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EEofqZQsMKJfNTDKJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 27, "extendedScore": null, "score": 5.6e-05, "legacy": true, "legacyId": "8984", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QfpHRAMRM2HjteKFK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T05:02:13.533Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Semantic Stopsigns", "slug": "seq-rerun-semantic-stopsigns", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.022Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eh76H2xXnBgx9DiYE/seq-rerun-semantic-stopsigns", "pageUrlRelative": "/posts/eh76H2xXnBgx9DiYE/seq-rerun-semantic-stopsigns", "linkUrl": "https://www.lesswrong.com/posts/eh76H2xXnBgx9DiYE/seq-rerun-semantic-stopsigns", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Semantic%20Stopsigns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Semantic%20Stopsigns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feh76H2xXnBgx9DiYE%2Fseq-rerun-semantic-stopsigns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Semantic%20Stopsigns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feh76H2xXnBgx9DiYE%2Fseq-rerun-semantic-stopsigns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feh76H2xXnBgx9DiYE%2Fseq-rerun-semantic-stopsigns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p>Today's post, <a href=\"/lw/it/semantic_stopsigns/\">Semantic Stopsigns</a> was originally published on 24 August 2007. A summary:</p>\n<blockquote>There are certain words and phrases that act as \"stopsigns\" to thinking. They aren't actually explanations, or help to resolve the actual issue at hand, but they act as a marker saying \"don't ask any questions.\"</blockquote>\n<p>Discuss the post here (rather than in the comments to the original post).</p>\n<p><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/6xe/seq_rerun_fake_causality/\">Fake Causality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.</em></p>\n<p><em> </em></p>\n<p><em>Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eh76H2xXnBgx9DiYE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 7.492368187821145e-07, "legacy": true, "legacyId": "8993", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FWMfQKG3RpZx6irjm", "jFRKw4exWh43NEKoq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T05:24:32.685Z", "modifiedAt": null, "url": null, "title": "A WordCloud Visual of LW Main", "slug": "a-wordcloud-visual-of-lw-main", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.610Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "r_claypool", "createdAt": "2011-02-13T13:43:23.915Z", "isAdmin": false, "displayName": "r_claypool"}, "userId": "afmiWkqiSCpzHD4Xd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CZjrouFRMRMuvTTQM/a-wordcloud-visual-of-lw-main", "pageUrlRelative": "/posts/CZjrouFRMRMuvTTQM/a-wordcloud-visual-of-lw-main", "linkUrl": "https://www.lesswrong.com/posts/CZjrouFRMRMuvTTQM/a-wordcloud-visual-of-lw-main", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20WordCloud%20Visual%20of%20LW%20Main&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20WordCloud%20Visual%20of%20LW%20Main%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZjrouFRMRMuvTTQM%2Fa-wordcloud-visual-of-lw-main%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20WordCloud%20Visual%20of%20LW%20Main%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZjrouFRMRMuvTTQM%2Fa-wordcloud-visual-of-lw-main", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZjrouFRMRMuvTTQM%2Fa-wordcloud-visual-of-lw-main", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p>I created this word cloud based on&nbsp;<a href=\"/promoted/.rss\">http://lesswrong.com/promoted/.rss</a>.</p>\n<p><img title=\"Hosted by imgur.com\" src=\"http://i.imgur.com/wtSqL.png\" alt=\"\" /></p>\n<p>The words \"Rational\" and \"Rationality\"&nbsp;<a title=\"A Discussion on Rationality Market Research\" href=\"/lw/6nm/rationality_market_research/\">might trigger negative stereotypes</a>&nbsp;for some people, but this image is positive and inspiring. I'm glad to see we are promoting top level posts on these issues and thought you would be too.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CZjrouFRMRMuvTTQM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 7.492438537269153e-07, "legacy": true, "legacyId": "8995", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ousEiGAmLEoJq2Reb"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T16:22:01.096Z", "modifiedAt": null, "url": null, "title": "Meetup : Research Triangle Less Wrong Meetup", "slug": "meetup-research-triangle-less-wrong-meetup-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.383Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yddyvPeZ4wDrA8EDG/meetup-research-triangle-less-wrong-meetup-1", "pageUrlRelative": "/posts/yddyvPeZ4wDrA8EDG/meetup-research-triangle-less-wrong-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/yddyvPeZ4wDrA8EDG/meetup-research-triangle-less-wrong-meetup-1", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Research%20Triangle%20Less%20Wrong%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Research%20Triangle%20Less%20Wrong%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyddyvPeZ4wDrA8EDG%2Fmeetup-research-triangle-less-wrong-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Research%20Triangle%20Less%20Wrong%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyddyvPeZ4wDrA8EDG%2Fmeetup-research-triangle-less-wrong-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyddyvPeZ4wDrA8EDG%2Fmeetup-research-triangle-less-wrong-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1w'>Research Triangle Less Wrong Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 August 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1406 East Franklin Street, Chapel Hill, NC 27514-2883</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In the meeting room of Caribou Coffee. Note this is not the one near UNC campus, but near the intersection of Franklin and Estes. Let's welcome some new and returning members, discuss progress on our goals and recent LW topics, and mourn Alicorn's relocation! Let's also discuss discussion: <a href=\"http://lesswrong.com/r/discussion/lw/6m4/having_useful_conversations/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/6m4/having_useful_conversations/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1w'>Research Triangle Less Wrong Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yddyvPeZ4wDrA8EDG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.494511404157005e-07, "legacy": true, "legacyId": "9001", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1w\">Research Triangle Less Wrong Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 August 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1406 East Franklin Street, Chapel Hill, NC 27514-2883</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In the meeting room of Caribou Coffee. Note this is not the one near UNC campus, but near the intersection of Franklin and Estes. Let's welcome some new and returning members, discuss progress on our goals and recent LW topics, and mourn Alicorn's relocation! Let's also discuss discussion: <a href=\"http://lesswrong.com/r/discussion/lw/6m4/having_useful_conversations/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/6m4/having_useful_conversations/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1w\">Research Triangle Less Wrong Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Research Triangle Less Wrong Meetup", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Research Triangle Less Wrong Meetup", "anchor": "Discussion_article_for_the_meetup___Research_Triangle_Less_Wrong_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CCriujRF39gWF5xAw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T17:21:43.082Z", "modifiedAt": null, "url": null, "title": "Teaching Suggestions?", "slug": "teaching-suggestions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.752Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6n3icFmTndMafDFdd/teaching-suggestions", "pageUrlRelative": "/posts/6n3icFmTndMafDFdd/teaching-suggestions", "linkUrl": "https://www.lesswrong.com/posts/6n3icFmTndMafDFdd/teaching-suggestions", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Teaching%20Suggestions%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATeaching%20Suggestions%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6n3icFmTndMafDFdd%2Fteaching-suggestions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Teaching%20Suggestions%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6n3icFmTndMafDFdd%2Fteaching-suggestions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6n3icFmTndMafDFdd%2Fteaching-suggestions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>I am going to do Splash! Fall 2011 at the University of Chicago, where I chose a subject to teach kids.&nbsp; I'm teaching a 1 hour class on the basics on rationality, and I am outlining the topics I want to cover.</p>\n<p>Right now, I'm planning on teaching map and territory, reductionism, a basic introduction to biases, and what having a belief should mean (paying rent).</p>\n<p>What other ideas would be useful to teach high school students?&nbsp; And does anyone have suggestions on interesting ways to teach these concepts?</p>\n<p>&nbsp;</p>\n<p>Edit: All comments say four is too many topics, I will focus on map and territory and beliefs paying rent.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6n3icFmTndMafDFdd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "9000", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T20:24:34.790Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes August 2011", "slug": "rationality-quotes-august-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:31.862Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dvasya", "createdAt": "2011-03-08T00:30:12.369Z", "isAdmin": false, "displayName": "dvasya"}, "userId": "2484AHxytrNyQXajh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ENZx3otox39aEvY53/rationality-quotes-august-2011", "pageUrlRelative": "/posts/ENZx3otox39aEvY53/rationality-quotes-august-2011", "linkUrl": "https://www.lesswrong.com/posts/ENZx3otox39aEvY53/rationality-quotes-august-2011", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20August%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20August%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FENZx3otox39aEvY53%2Frationality-quotes-august-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20August%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FENZx3otox39aEvY53%2Frationality-quotes-august-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FENZx3otox39aEvY53%2Frationality-quotes-august-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<p>Here's the new quotes thread, for all those quotes you were going to post.</p>\n<p>Rules:</p>\n<ul>\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp;&nbsp;(If they are strongly related, reply to your own comments.&nbsp;&nbsp;If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ENZx3otox39aEvY53", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 7.495276402801196e-07, "legacy": true, "legacyId": "9002", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 179, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-02T20:28:34.378Z", "modifiedAt": null, "url": null, "title": "Meetup : Ottawa LessWrong Weekly Meetup", "slug": "meetup-ottawa-lesswrong-weekly-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ht8zW9xbdjKer4t5g/meetup-ottawa-lesswrong-weekly-meetup-0", "pageUrlRelative": "/posts/Ht8zW9xbdjKer4t5g/meetup-ottawa-lesswrong-weekly-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/Ht8zW9xbdjKer4t5g/meetup-ottawa-lesswrong-weekly-meetup-0", "postedAtFormatted": "Tuesday, August 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHt8zW9xbdjKer4t5g%2Fmeetup-ottawa-lesswrong-weekly-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ottawa%20LessWrong%20Weekly%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHt8zW9xbdjKer4t5g%2Fmeetup-ottawa-lesswrong-weekly-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHt8zW9xbdjKer4t5g%2Fmeetup-ottawa-lesswrong-weekly-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1x'>Ottawa LessWrong Weekly Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 August 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">K1S 3K3</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: My house! Check the <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">google group</a> for the address, or PM/email me.</p>\n\n<p>Discussion post: <a href=\"http://lesswrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">Diseased Thinking</a> - My personal favorite LW article. If someone prefers something else for discussion, please suggest away!</p>\n\n<p>Exercise: Paranoid Debating and/or <a href=\"http://rejectiontherapy.com/\" rel=\"nofollow\">Rejection Therapy</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1x'>Ottawa LessWrong Weekly Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ht8zW9xbdjKer4t5g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.495288997476298e-07, "legacy": true, "legacyId": "9004", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup\">Discussion article for the meetup : <a href=\"/meetups/1x\">Ottawa LessWrong Weekly Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 August 2011 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">K1S 3K3</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Venue: My house! Check the <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">google group</a> for the address, or PM/email me.</p>\n\n<p>Discussion post: <a href=\"http://lesswrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">Diseased Thinking</a> - My personal favorite LW article. If someone prefers something else for discussion, please suggest away!</p>\n\n<p>Exercise: Paranoid Debating and/or <a href=\"http://rejectiontherapy.com/\" rel=\"nofollow\">Rejection Therapy</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/1x\">Ottawa LessWrong Weekly Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ottawa LessWrong Weekly Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Ottawa LessWrong Weekly Meetup", "anchor": "Discussion_article_for_the_meetup___Ottawa_LessWrong_Weekly_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["895quRDaK6gR2rM82"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T02:48:24.254Z", "modifiedAt": null, "url": null, "title": "Open Thread: August 2011", "slug": "open-thread-august-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:20.345Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QrrGsrEEHFZNBNAzY/open-thread-august-2011", "pageUrlRelative": "/posts/QrrGsrEEHFZNBNAzY/open-thread-august-2011", "linkUrl": "https://www.lesswrong.com/posts/QrrGsrEEHFZNBNAzY/open-thread-august-2011", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20August%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20August%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQrrGsrEEHFZNBNAzY%2Fopen-thread-august-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20August%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQrrGsrEEHFZNBNAzY%2Fopen-thread-august-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQrrGsrEEHFZNBNAzY%2Fopen-thread-august-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 40, "htmlBody": "<p>For miscellaneous discussions and remarks not suitable for top-level posts even in the Discussion section, let alone in Main.</p>\n<p>(<em>Naturally, if a discussion gets too unwieldy, celebrate by turning it into a top-level post, just like in the good old days.)</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QrrGsrEEHFZNBNAzY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.496487202707085e-07, "legacy": true, "legacyId": "9009", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T04:54:33.647Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Mysterious Answers to Mysterious Questions", "slug": "seq-rerun-mysterious-answers-to-mysterious-questions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.576Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FD3K7vSFmwrNgMgfg/seq-rerun-mysterious-answers-to-mysterious-questions", "pageUrlRelative": "/posts/FD3K7vSFmwrNgMgfg/seq-rerun-mysterious-answers-to-mysterious-questions", "linkUrl": "https://www.lesswrong.com/posts/FD3K7vSFmwrNgMgfg/seq-rerun-mysterious-answers-to-mysterious-questions", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Mysterious%20Answers%20to%20Mysterious%20Questions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Mysterious%20Answers%20to%20Mysterious%20Questions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFD3K7vSFmwrNgMgfg%2Fseq-rerun-mysterious-answers-to-mysterious-questions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Mysterious%20Answers%20to%20Mysterious%20Questions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFD3K7vSFmwrNgMgfg%2Fseq-rerun-mysterious-answers-to-mysterious-questions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFD3K7vSFmwrNgMgfg%2Fseq-rerun-mysterious-answers-to-mysterious-questions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p>Today's post, <a href=\"/lw/iu/mysterious_answers_to_mysterious_questions/\">Mysterious Answers to Mysterious Questions</a> was originally published on 25 August 2007.  A summary:</p>\n<p>&nbsp;</p>\n<blockquote>The theory of vitalism was developed before the idea of biochemistry. It stated that the mysterious properties of living matter, compared to nonliving matter, was due to an \"elan vital\". This explanation acts as a curiosity-stopper, and leaves the phenomenon just as mysterious and inexplicable as it was before the answer was given. It feels like an explanation, though it fails to constrain anticipation.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6xt/seq_rerun_semantic_stopsigns/\">Semantic Stopsigns</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FD3K7vSFmwrNgMgfg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.496885247476173e-07, "legacy": true, "legacyId": "9012", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6i3zToomS86oj9bS6", "eh76H2xXnBgx9DiYE", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T15:01:48.056Z", "modifiedAt": null, "url": null, "title": "[LINK] Get paid to train your rationality", "slug": "link-get-paid-to-train-your-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:37.580Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PyuRcbHvxXNdCHoG3/link-get-paid-to-train-your-rationality", "pageUrlRelative": "/posts/PyuRcbHvxXNdCHoG3/link-get-paid-to-train-your-rationality", "linkUrl": "https://www.lesswrong.com/posts/PyuRcbHvxXNdCHoG3/link-get-paid-to-train-your-rationality", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Get%20paid%20to%20train%20your%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Get%20paid%20to%20train%20your%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPyuRcbHvxXNdCHoG3%2Flink-get-paid-to-train-your-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Get%20paid%20to%20train%20your%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPyuRcbHvxXNdCHoG3%2Flink-get-paid-to-train-your-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPyuRcbHvxXNdCHoG3%2Flink-get-paid-to-train-your-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 952, "htmlBody": "<p>A tournament is currently being initiated by the Intelligence Advanced Research Project Activity (IARPA) with the goal of improving forecasting methods for global events of national (US) interest. One of the teams (The Good Judgement Team) is recruiting volunteers to have their forecasts tracked. Volunteers will receive an annual honorarium ($150), and it appears there will be ongoing training to improve one's forecast accuracy (not sure exactly what form this will take).</p>\n<p>I'm registered, and wondering if any other LessWrongers are participating/considering it. It could be interesting to compare methods and results.</p>\n<p>Extensive quotes and links below the fold.</p>\n<p><a id=\"more\"></a></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; line-height: 15px;\"> </span></p>\n<blockquote>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Despite its importance in modern life, forecasting remains (ironically) unpredictable. Who is a good forecaster? How do you make people better forecasters? Are there processes or technologies that can improve the ability of governments, companies, and other institutions to perceive and act on trends and threats? Nobody really knows.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The goal of the Good Judgment Project is to answer these questions. We will systematically compare the effectiveness of different training methods (general education, probabilistic-reasoning training, divergent-thinking training) and forecasting tools (low- and high-information opinion-polls, prediction market, and process-focused tools) in accurately forecasting future events. We also will investigate how different combinations of training and forecasting work together. Finally, we will explore how to more effectively communicate forecasts in ways that avoid overwhelming audiences with technical detail or oversimplifying difficult decisions.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Over the course of each year, forecasters will have an opportunity to respond to 100 questions, each requiring a separate prediction, such as &ldquo;How many countries in the Euro zone will default on bonds in 2011?&rdquo; or &ldquo;Will Southern Sudan become an independent country in 2011?&rdquo; Researchers from the Good Judgment Project will look for the best ways to combine these individual forecasts to yield the most accurate &ldquo;collective wisdom&rdquo; results.&nbsp; Participants also will receive feedback on their individual results.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">All training and forecasting will be done online. Forecasters&rsquo; identities will not be made public; however, successful forecasters will have the option to publicize their own track records.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\"><strong>Who We Are</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The Good Judgment research team is based in the University of Pennsylvania and the University of California Berkeley. The project is led by psychologists Philip Tetlock, author of the award-winning&nbsp;<em>Expert Political Judgment</em>, Barbara Mellers, an expert on judgment and decision-making, and Don Moore, an expert on overconfidence. Other team members are experts in psychology, economics, statistics, interface design, futures, and computer science.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">We are one of five teams competing in the Aggregative Contingent Estimation (ACE) Program, sponsored by IARPA (the U.S. Intelligence Advanced Research Projects Activity). The ACE Program aims \"to dramatically enhance the accuracy, precision, and timeliness of forecasts for a broad range of event types, through the development of advanced techniques that elicit, weight, and combine the judgments of many intelligence analysts.\" The project is unclassified: our results will be published in traditional scholarly and scientific journals, and will be available to the general public.</p>\n</blockquote>\n<p>A general description of the expected benefits for volunteers:</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; font-size: 13px; line-height: 18px;\"><span style=\"font-family: inherit;\">All decisions involve forecasts, and we all make forecasts all the&nbsp;time.&nbsp;&nbsp;When we decide to change&nbsp;jobs, we perform an analysis of potential futures for&nbsp;each of our options.&nbsp;&nbsp;When a business decides to invest or&nbsp;disinvest in a project, it moves in the direction it believes to present the&nbsp;best opportunity.&nbsp;&nbsp;The&nbsp;same applies&nbsp;when a government decides to launch or abandon a policy.</span><br /><br />But we virtually never keep score. Very few forecasters know what&nbsp;their forecasting batting average is&nbsp;&mdash;&nbsp;or even how to go about estimating what it is.<br /><br />If you want to discover what your forecasting batting average is&nbsp;&mdash;&nbsp;and how to think&nbsp;about the very concept&nbsp;&mdash;&nbsp;you should seriously consider joining The Good Judgment Project. Self-knowledge is its own&nbsp;reward. But with self-knowledge, you have a baseline against which you can&nbsp;measure improvement over time. If you&nbsp;want to explore how high your forecasting&nbsp;batting average could go, and are prepared to put in some work at&nbsp;self-improvement, this is definitely the&nbsp;project for you.</span></p>\n</blockquote>\n<p>Could that be any more LessWrong-esque?</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; line-height: 15px;\">Prediction markets can harness the \"wisdom of crowds\" to solve problems, develop products, and make forecasts. These systems typically treat collective intelligence as a commodity to be mined, not a resource that can be grown and improved. That&rsquo;s about to change. </span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Starting in mid-2011, five teams will compete in a U.S.-government-sponsored forecasting tournament. Each team will develop its own tools for harnessing and improving collective intelligence and will be judged on how well its forecasters predict major trends and events around the world over the next four years.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The&nbsp;<em>Good Judgment Team</em>, based in the University of Pennsylvania and the University of California Berkeley, will be one of the five teams competing &ndash; and we&rsquo;d like you to consider joining our team as a forecaster. If you're willing to experiment with ways to improve your forecasting ability and if being part of cutting-edge scientific research appeals to you, then we want your help.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">We can promise you the chance to: (1) learn about yourself (your skill in predicting &ndash; and your skill in becoming more accurate over time as you learn from feedback and/or special training exercises); (2) contribute to cutting-edge scientific work on both individual-level factors that promote or inhibit accuracy and group- or team-level factors that contribute to accuracy; and (3) help us distinguish better from worse approaches to generating forecasts of importance to national security, global affairs, and economics.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\"><strong>Who Can Participate</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Requirements for participation include the following:</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">(1) A baccalaureate, bachelors, or undergraduate degree from an accredited college or university (more advanced degrees are welcome);</p>\n<p>(2) A curiosity about how well you make predictions about world events &ndash; and an interest in exploring techniques for improvement.<a href=\"http://goodjudgmentproject.blogspot.com/\"></a></p>\n</blockquote>\n<p>More info: <a href=\"http://goodjudgmentproject.blogspot.com/\">http://goodjudgmentproject.blogspot.com/</a></p>\n<p>Pre-Register: <a href=\"http://surveys.crowdcast.com/s3/ACERegistration\">http://surveys.crowdcast.com/s3/ACERegistration</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"khReijeucXJTnsyMT": 1, "R6dqPii4cyNpuecLt": 1, "8daMDi9NEShyLqxth": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PyuRcbHvxXNdCHoG3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 40, "extendedScore": null, "score": 7.498801714798376e-07, "legacy": true, "legacyId": "9010", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>A tournament is currently being initiated by the Intelligence Advanced Research Project Activity (IARPA) with the goal of improving forecasting methods for global events of national (US) interest. One of the teams (The Good Judgement Team) is recruiting volunteers to have their forecasts tracked. Volunteers will receive an annual honorarium ($150), and it appears there will be ongoing training to improve one's forecast accuracy (not sure exactly what form this will take).</p>\n<p>I'm registered, and wondering if any other LessWrongers are participating/considering it. It could be interesting to compare methods and results.</p>\n<p>Extensive quotes and links below the fold.</p>\n<p><a id=\"more\"></a></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; line-height: 15px;\"> </span></p>\n<blockquote>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Despite its importance in modern life, forecasting remains (ironically) unpredictable. Who is a good forecaster? How do you make people better forecasters? Are there processes or technologies that can improve the ability of governments, companies, and other institutions to perceive and act on trends and threats? Nobody really knows.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The goal of the Good Judgment Project is to answer these questions. We will systematically compare the effectiveness of different training methods (general education, probabilistic-reasoning training, divergent-thinking training) and forecasting tools (low- and high-information opinion-polls, prediction market, and process-focused tools) in accurately forecasting future events. We also will investigate how different combinations of training and forecasting work together. Finally, we will explore how to more effectively communicate forecasts in ways that avoid overwhelming audiences with technical detail or oversimplifying difficult decisions.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Over the course of each year, forecasters will have an opportunity to respond to 100 questions, each requiring a separate prediction, such as \u201cHow many countries in the Euro zone will default on bonds in 2011?\u201d or \u201cWill Southern Sudan become an independent country in 2011?\u201d Researchers from the Good Judgment Project will look for the best ways to combine these individual forecasts to yield the most accurate \u201ccollective wisdom\u201d results.&nbsp; Participants also will receive feedback on their individual results.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">All training and forecasting will be done online. Forecasters\u2019 identities will not be made public; however, successful forecasters will have the option to publicize their own track records.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\"><strong id=\"Who_We_Are\">Who We Are</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The Good Judgment research team is based in the University of Pennsylvania and the University of California Berkeley. The project is led by psychologists Philip Tetlock, author of the award-winning&nbsp;<em>Expert Political Judgment</em>, Barbara Mellers, an expert on judgment and decision-making, and Don Moore, an expert on overconfidence. Other team members are experts in psychology, economics, statistics, interface design, futures, and computer science.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">We are one of five teams competing in the Aggregative Contingent Estimation (ACE) Program, sponsored by IARPA (the U.S. Intelligence Advanced Research Projects Activity). The ACE Program aims \"to dramatically enhance the accuracy, precision, and timeliness of forecasts for a broad range of event types, through the development of advanced techniques that elicit, weight, and combine the judgments of many intelligence analysts.\" The project is unclassified: our results will be published in traditional scholarly and scientific journals, and will be available to the general public.</p>\n</blockquote>\n<p>A general description of the expected benefits for volunteers:</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; font-size: 13px; line-height: 18px;\"><span style=\"font-family: inherit;\">All decisions involve forecasts, and we all make forecasts all the&nbsp;time.&nbsp;&nbsp;When we decide to change&nbsp;jobs, we perform an analysis of potential futures for&nbsp;each of our options.&nbsp;&nbsp;When a business decides to invest or&nbsp;disinvest in a project, it moves in the direction it believes to present the&nbsp;best opportunity.&nbsp;&nbsp;The&nbsp;same applies&nbsp;when a government decides to launch or abandon a policy.</span><br><br>But we virtually never keep score. Very few forecasters know what&nbsp;their forecasting batting average is&nbsp;\u2014&nbsp;or even how to go about estimating what it is.<br><br>If you want to discover what your forecasting batting average is&nbsp;\u2014&nbsp;and how to think&nbsp;about the very concept&nbsp;\u2014&nbsp;you should seriously consider joining The Good Judgment Project. Self-knowledge is its own&nbsp;reward. But with self-knowledge, you have a baseline against which you can&nbsp;measure improvement over time. If you&nbsp;want to explore how high your forecasting&nbsp;batting average could go, and are prepared to put in some work at&nbsp;self-improvement, this is definitely the&nbsp;project for you.</span></p>\n</blockquote>\n<p>Could that be any more LessWrong-esque?</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; line-height: 15px;\">Prediction markets can harness the \"wisdom of crowds\" to solve problems, develop products, and make forecasts. These systems typically treat collective intelligence as a commodity to be mined, not a resource that can be grown and improved. That\u2019s about to change. </span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Starting in mid-2011, five teams will compete in a U.S.-government-sponsored forecasting tournament. Each team will develop its own tools for harnessing and improving collective intelligence and will be judged on how well its forecasters predict major trends and events around the world over the next four years.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The&nbsp;<em>Good Judgment Team</em>, based in the University of Pennsylvania and the University of California Berkeley, will be one of the five teams competing \u2013 and we\u2019d like you to consider joining our team as a forecaster. If you're willing to experiment with ways to improve your forecasting ability and if being part of cutting-edge scientific research appeals to you, then we want your help.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">We can promise you the chance to: (1) learn about yourself (your skill in predicting \u2013 and your skill in becoming more accurate over time as you learn from feedback and/or special training exercises); (2) contribute to cutting-edge scientific work on both individual-level factors that promote or inhibit accuracy and group- or team-level factors that contribute to accuracy; and (3) help us distinguish better from worse approaches to generating forecasts of importance to national security, global affairs, and economics.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\"><strong id=\"Who_Can_Participate\">Who Can Participate</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Requirements for participation include the following:</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">(1) A baccalaureate, bachelors, or undergraduate degree from an accredited college or university (more advanced degrees are welcome);</p>\n<p>(2) A curiosity about how well you make predictions about world events \u2013 and an interest in exploring techniques for improvement.<a href=\"http://goodjudgmentproject.blogspot.com/\"></a></p>\n</blockquote>\n<p>More info: <a href=\"http://goodjudgmentproject.blogspot.com/\">http://goodjudgmentproject.blogspot.com/</a></p>\n<p>Pre-Register: <a href=\"http://surveys.crowdcast.com/s3/ACERegistration\">http://surveys.crowdcast.com/s3/ACERegistration</a></p>", "sections": [{"title": "Who We Are", "anchor": "Who_We_Are", "level": 1}, {"title": "Who Can Participate", "anchor": "Who_Can_Participate", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "55 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T18:17:15.313Z", "modifiedAt": null, "url": null, "title": "Meetup : London mini-meetup", "slug": "meetup-london-mini-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.941Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2w3d88DKfZzEadAsm/meetup-london-mini-meetup", "pageUrlRelative": "/posts/2w3d88DKfZzEadAsm/meetup-london-mini-meetup", "linkUrl": "https://www.lesswrong.com/posts/2w3d88DKfZzEadAsm/meetup-london-mini-meetup", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20mini-meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20mini-meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2w3d88DKfZzEadAsm%2Fmeetup-london-mini-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20mini-meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2w3d88DKfZzEadAsm%2Fmeetup-london-mini-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2w3d88DKfZzEadAsm%2Fmeetup-london-mini-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1y'>London mini-meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 August 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeares Head, Africa House, 64-68 Kingsway, City of London WC2B 6AG, United Kingdom</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry for the late notice: the next London mini-meetup is on Sunday August 7 at 14:00 at the <a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=shakespeare&#39;s+head&amp;sll=51.42559,-0.130394&amp;sspn=0.011854,0.020943&amp;ie=UTF8&amp;hq=shakespeare&#39;s+head&amp;hnear=&amp;layer=c&amp;cbll=51.516734,-0.119933&amp;panoid=kXPwAeowAo9LzJJA34agOw&amp;cbp=11,76.42,,1,-1.06&amp;ll=51.516728,-0.124025&amp;spn=0.005622,0.022488&amp;z=16\" rel=\"nofollow\">Shakespeares Head</a> (<a href=\"http://www.jdwetherspoon.co.uk/home/pubs/shakespeares-head\" rel=\"nofollow\">official page</a>) on Kingsway near Holborn Tube station. Note that there's more than one pub in London with that name, so make sure you get the right one. As always, we'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\" rel=\"nofollow\">look like this</a>. For more timely notice, subscribe to the <a href=\"http://groups.google.com/group/lesswronglondon/\">London Less Wrong mailing list</a>. We are aiming to have a \"full\" meetup on the Sunday of every other month, with other gatherings on the first and third Sunday of every month. Hope to see lots of you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1y'>London mini-meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2w3d88DKfZzEadAsm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.499418758483872e-07, "legacy": true, "legacyId": "9018", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_mini_meetup\">Discussion article for the meetup : <a href=\"/meetups/1y\">London mini-meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 August 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeares Head, Africa House, 64-68 Kingsway, City of London WC2B 6AG, United Kingdom</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Sorry for the late notice: the next London mini-meetup is on Sunday August 7 at 14:00 at the <a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=shakespeare's+head&amp;sll=51.42559,-0.130394&amp;sspn=0.011854,0.020943&amp;ie=UTF8&amp;hq=shakespeare's+head&amp;hnear=&amp;layer=c&amp;cbll=51.516734,-0.119933&amp;panoid=kXPwAeowAo9LzJJA34agOw&amp;cbp=11,76.42,,1,-1.06&amp;ll=51.516728,-0.124025&amp;spn=0.005622,0.022488&amp;z=16\" rel=\"nofollow\">Shakespeares Head</a> (<a href=\"http://www.jdwetherspoon.co.uk/home/pubs/shakespeares-head\" rel=\"nofollow\">official page</a>) on Kingsway near Holborn Tube station. Note that there's more than one pub in London with that name, so make sure you get the right one. As always, we'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\" rel=\"nofollow\">look like this</a>. For more timely notice, subscribe to the <a href=\"http://groups.google.com/group/lesswronglondon/\">London Less Wrong mailing list</a>. We are aiming to have a \"full\" meetup on the Sunday of every other month, with other gatherings on the first and third Sunday of every month. Hope to see lots of you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_mini_meetup1\">Discussion article for the meetup : <a href=\"/meetups/1y\">London mini-meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : London mini-meetup", "anchor": "Discussion_article_for_the_meetup___London_mini_meetup", "level": 1}, {"title": "Discussion article for the meetup : London mini-meetup", "anchor": "Discussion_article_for_the_meetup___London_mini_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T18:26:45.078Z", "modifiedAt": null, "url": null, "title": "Meetup : Seattle Biweekly meetup", "slug": "meetup-seattle-biweekly-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CfqzHE5KCQhZ6JAGM/meetup-seattle-biweekly-meetup", "pageUrlRelative": "/posts/CfqzHE5KCQhZ6JAGM/meetup-seattle-biweekly-meetup", "linkUrl": "https://www.lesswrong.com/posts/CfqzHE5KCQhZ6JAGM/meetup-seattle-biweekly-meetup", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Seattle%20Biweekly%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Seattle%20Biweekly%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCfqzHE5KCQhZ6JAGM%2Fmeetup-seattle-biweekly-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Seattle%20Biweekly%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCfqzHE5KCQhZ6JAGM%2Fmeetup-seattle-biweekly-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCfqzHE5KCQhZ6JAGM%2Fmeetup-seattle-biweekly-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 122, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/1z'>Seattle Biweekly meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 August 2011 04:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">414 50th St NE, Seattle, WA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The biweekly meetup is happening at the <a href=\"http://groups.google.com/group/lw-seattle/browse_thread/thread/d6e3a938d4e62522\" rel=\"nofollow\">regular place and time</a>. Agenda:</p>\n\n<ul>\n<li>Guy will be giving a presentation on: Bounded altruism and modeling yourself as a parliament of subagents.</li>\n<li>In an effort to discuss more introductory material, I will be leading a reading/discussion of <a href=\"http://lesswrong.com/lw/ng/words_as_hidden_inferences\">Words As Hidden Inferences</a>.</li>\n</ul>\n\n<p>We will be ordering take out again, so please bring some cash if you would like to eat.</p>\n\n<p>The official end of the meetup will be 6:30pm, but people are welcome to stay and hang out after that.</p>\n\n<p>Looking forward to seeing you guys!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/1z'>Seattle Biweekly meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CfqzHE5KCQhZ6JAGM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.499448739598187e-07, "legacy": true, "legacyId": "9019", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Seattle_Biweekly_meetup\">Discussion article for the meetup : <a href=\"/meetups/1z\">Seattle Biweekly meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 August 2011 04:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">414 50th St NE, Seattle, WA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The biweekly meetup is happening at the <a href=\"http://groups.google.com/group/lw-seattle/browse_thread/thread/d6e3a938d4e62522\" rel=\"nofollow\">regular place and time</a>. Agenda:</p>\n\n<ul>\n<li>Guy will be giving a presentation on: Bounded altruism and modeling yourself as a parliament of subagents.</li>\n<li>In an effort to discuss more introductory material, I will be leading a reading/discussion of <a href=\"http://lesswrong.com/lw/ng/words_as_hidden_inferences\">Words As Hidden Inferences</a>.</li>\n</ul>\n\n<p>We will be ordering take out again, so please bring some cash if you would like to eat.</p>\n\n<p>The official end of the meetup will be 6:30pm, but people are welcome to stay and hang out after that.</p>\n\n<p>Looking forward to seeing you guys!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Seattle_Biweekly_meetup1\">Discussion article for the meetup : <a href=\"/meetups/1z\">Seattle Biweekly meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Seattle Biweekly meetup", "anchor": "Discussion_article_for_the_meetup___Seattle_Biweekly_meetup", "level": 1}, {"title": "Discussion article for the meetup : Seattle Biweekly meetup", "anchor": "Discussion_article_for_the_meetup___Seattle_Biweekly_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3nxs2WYDGzJbzcLMp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-03T19:55:24.160Z", "modifiedAt": null, "url": null, "title": "Meetup : San Jose Start of College Meetup", "slug": "meetup-san-jose-start-of-college-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:07.063Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MatthewBaker", "createdAt": "2011-06-03T22:19:50.449Z", "isAdmin": false, "displayName": "MatthewBaker"}, "userId": "xEPvhkraqrPSryfFr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/37pwgd3own9AHgBWu/meetup-san-jose-start-of-college-meetup", "pageUrlRelative": "/posts/37pwgd3own9AHgBWu/meetup-san-jose-start-of-college-meetup", "linkUrl": "https://www.lesswrong.com/posts/37pwgd3own9AHgBWu/meetup-san-jose-start-of-college-meetup", "postedAtFormatted": "Wednesday, August 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Jose%20Start%20of%20College%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Jose%20Start%20of%20College%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37pwgd3own9AHgBWu%2Fmeetup-san-jose-start-of-college-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Jose%20Start%20of%20College%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37pwgd3own9AHgBWu%2Fmeetup-san-jose-start-of-college-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F37pwgd3own9AHgBWu%2Fmeetup-san-jose-start-of-college-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 96, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/20'>San Jose Start of College Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 August 2011 02:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">San Jose State University</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I head up to school this week and i wanted to gauge the interest in a meetup in the area :) I have a couple viable ideas for location but before i lock down my choices id appreciate input. -Matt</p>\n\n<p>Edit:\nAs of 8-24 we are meeting in the CS club room which if i remember correctly is third floor macquarrie hall on campus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/20'>San Jose Start of College Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "37pwgd3own9AHgBWu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.499728641056893e-07, "legacy": true, "legacyId": "9020", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Jose_Start_of_College_Meetup\">Discussion article for the meetup : <a href=\"/meetups/20\">San Jose Start of College Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 August 2011 02:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">San Jose State University</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I head up to school this week and i wanted to gauge the interest in a meetup in the area :) I have a couple viable ideas for location but before i lock down my choices id appreciate input. -Matt</p>\n\n<p>Edit:\nAs of 8-24 we are meeting in the CS club room which if i remember correctly is third floor macquarrie hall on campus.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Jose_Start_of_College_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/20\">San Jose Start of College Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Jose Start of College Meetup", "anchor": "Discussion_article_for_the_meetup___San_Jose_Start_of_College_Meetup", "level": 1}, {"title": "Discussion article for the meetup : San Jose Start of College Meetup", "anchor": "Discussion_article_for_the_meetup___San_Jose_Start_of_College_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T00:42:15.595Z", "modifiedAt": null, "url": null, "title": "Charitable Cryonics", "slug": "charitable-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:28.322Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8pqYzEYhzGSgfWdW5/charitable-cryonics", "pageUrlRelative": "/posts/8pqYzEYhzGSgfWdW5/charitable-cryonics", "linkUrl": "https://www.lesswrong.com/posts/8pqYzEYhzGSgfWdW5/charitable-cryonics", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Charitable%20Cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACharitable%20Cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8pqYzEYhzGSgfWdW5%2Fcharitable-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Charitable%20Cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8pqYzEYhzGSgfWdW5%2Fcharitable-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8pqYzEYhzGSgfWdW5%2Fcharitable-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 502, "htmlBody": "<p>Tl;dr: Cryonics companies have a pre-written <a href=\"/lw/js/the_bottom_line/\">bottom line</a>. If people believe cryonics has a reasonable chance of success, they are significantly <a href=\"/lw/n3/circular_altruism/\">morally obligated</a> to form a charity that would give cryonics away, as such a charity would be far more effective in convincing, and by extension saving people, since it would have no incentive to pre-write a bottom line. Over time, such a charity would increase general demand for cryonics, bringing it into the mainstream and making traditional cryonics companies more successful.</p>\n<hr />\n<p>Let us assume for the purposes of this post, as I'm sure many of you believe, cryonics stands a reasonable chance (Let's pick p = 0.05) of being successful. It seems <a href=\"/lw/n3/circular_altruism/\" target=\"_blank\">pretty clear</a> that you have a pretty strong moral obligation to attempt to get people signed up for cryonics. There is <a href=\"/lw/2kh/against_cryonics_for_costeffective_charity/\">a</a> <a href=\"/lw/6xk/years_saved_cryonics_vs_villagereach/\">lot</a> of <a href=\"/lw/6ez/organ_donation_vs_cryonics/\">talk</a> about things like Cryonics versus charity. Robin Hanson even has a post \"<a href=\"http://www.overcomingbias.com/2010/07/cryonics-as-charity.html\">Cryonics as Charity</a>\", although he means an entirely different thing than I do. But in searching, I was surprised not to find a post that asked this question: why isn't there a charity that provides cryonics to, for example, people that can't afford it? Or one offering it to the <a href=\"/lw/2k1/christopher_hitchens_and_cryonics/\">greatest minds of our time</a>, in the hopes that they'll be around for all of our futures?</p>\n<p>There's been a lot of <a href=\"/lw/6vq/on_the_unpopularity_of_cryonics_life_sucks_but_at/\">speculation</a> as to why cryonics isn't more popular. The answer, at least for me, is obvious. There's a tremendous dearth of reliable information on the subject. The fundamental problem with medicine is the information gap between consumer and provider - consumers don't have the scientific knowledge to make an informed purchase. But in conventional medicine, you can easily get a second opinion, whereas in cryonics, few people, from the media to medical professionals, take it seriously enough to offer a well thought out second opinion, even if that opinion is against it. And what information I have seen linked to on the subject is generally published by CI or Alcor. Ironically, when I <a href=\"/lw/2ku/welcome_to_less_wrong_20102011/4k3c\">asked</a> for \"unbiased\" information on the matter, I got exactly what I wasn't looking for - information from a company that wants me to pay them, at minimum, <a href=\"http://www.alcor.org/BecomeMember/scheduleA.html\">$200,000</a>. The result? An informational balance where one side presents no argument, and the other side presents an argument with a pre-written <a href=\"/lw/js/the_bottom_line/\">bottom line</a>.</p>\n<p>This is where the idea of a charity comes in. A charity would have no financial incentive to pre-write the bottom line, and is generally seen as a more reputable source of information, as it should be. Furthermore, it would help destigmatize cryonics, as part of the stigma (as I see it, I can't really tell you what gives me this impression) is that you've been \"hoodwinked\" by the companies. Obviously, it's not tenable for everyone to freeload their way to cryonics. But a charity would serve to bring cryonics into the mainstream and increase demand, providing a (more) neutral source of information. Which would, in time, make organizations like CI and Alcor far more popular.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8pqYzEYhzGSgfWdW5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 12, "extendedScore": null, "score": 7.500634470448792e-07, "legacy": true, "legacyId": "9005", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["34XxbRFe54FycoCDw", "4ZzefKQwAtMo5yp99", "gicx9QBRpx6CMycMQ", "EEofqZQsMKJfNTDKJ", "wGNxep774ZAmwB8Ge", "Pg27iy6seyCpZyD3J", "mkrvsNi8cYGSjGqkh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T00:50:47.616Z", "modifiedAt": null, "url": null, "title": "The Allais Paradox and the Dilemma of Utility vs. Certainty", "slug": "the-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.694Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BaCCf9xL6yQsx3ak3/the-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "pageUrlRelative": "/posts/BaCCf9xL6yQsx3ak3/the-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "linkUrl": "https://www.lesswrong.com/posts/BaCCf9xL6yQsx3ak3/the-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Allais%20Paradox%20and%20the%20Dilemma%20of%20Utility%20vs.%20Certainty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Allais%20Paradox%20and%20the%20Dilemma%20of%20Utility%20vs.%20Certainty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBaCCf9xL6yQsx3ak3%2Fthe-allais-paradox-and-the-dilemma-of-utility-vs-certainty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Allais%20Paradox%20and%20the%20Dilemma%20of%20Utility%20vs.%20Certainty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBaCCf9xL6yQsx3ak3%2Fthe-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBaCCf9xL6yQsx3ak3%2Fthe-allais-paradox-and-the-dilemma-of-utility-vs-certainty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 812, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/my/the_allais_paradox/\">The Allais Paradox</a>, <a href=\"/lw/mz/zut_allais/\">Zut Allais</a>,&nbsp;<a href=\"/lw/n1/allais_malaise/\">Allais Malaise</a>, and <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a></p>\n<p>&nbsp;</p>\n<p>You've probably heard <a href=\"/lw/my/the_allais_paradox/\">the Allais Paradox</a> before, where you choose one of the two options from each set:</p>\n<p><strong>Set One:</strong></p>\n<ol>\n<li><strong>$24000</strong>, with certainty.</li>\n<li><strong>97%</strong> chance of <strong>$27000</strong>, <strong>3%</strong> chance of nothing.</li>\n</ol>\n<p><strong>Set Two:</strong></p>\n<ol>\n<li><strong>34% </strong>chance of <strong>$24000</strong>, <strong>66%</strong> chance of nothing.</li>\n<li><strong>33%</strong> chance of <strong>$27000</strong>, <strong>67%</strong> chance of nothing.</li>\n</ol>\n<div><br /></div>\n<div>From set one, which of the two would you choose?<strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div>From set two, which of the two would you choose?<strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div><br />The reason this is called a \"paradox\" is that most people choose 1 from set one and choose 2 from set two, despite set two being the same as a ~33% chance of being able to choose from set one.</div>\n<div>This is best seen when we&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Shut_up_and_multiply\">shut up and multiply</a>. &nbsp;When we&nbsp;run some&nbsp;na&iuml;ve&nbsp;expected utility calculations and make the big assumption of a linear utility for money (this works with the third question), we get:</div>\n<div>U(Set One, Choice 1) = 1.00 * U($24000) = 24000<br />U(Set One, Choice 2) = 0.97 * U($27000) =&nbsp;26190</div>\n<div>U(Set Two, Choice 1) = 0.34 * U($24000) =&nbsp;8160<br />U(Set Two, Choice 2) = 0.33 * U($27000) = 8910</div>\n<div><br /></div>\n<div>So to the degree that it is rational to want more money (you can always donate anything you don't want), it seems like we should want Choice 2 from both sets. &nbsp;But why do people only realize this in Set Two?</div>\n<div>The two competing theories is the \"people are silly\" theory and the \"it is perfectly rational to bet on certainty\" theory. &nbsp;What if you go for the 97% chance and miss out on such a large sum? &nbsp;It seems like you would intuitively want to just take your $24000 and run, but according to expected utility, you're just giving up $2190.</div>\n<div>~</div>\n<div><br /></div>\n<h2><span style=\"font-weight: normal;\"><em>The Problem With \"It is Perfectly Rational to Bet on Certainty\"</em></span></h2>\n<div>To put some pressure on this theory, all we have to do is introduce set three right here:</div>\n<div><strong>Set Three:</strong></div>\n<div><ol>\n<li><strong>$24000</strong>, with certainty</li>\n<li><strong>99.99%&nbsp;</strong>chance of&nbsp;<strong>$24 million</strong>,&nbsp;<strong>0.01%&nbsp;</strong>chance of nothing.</li>\n</ol></div>\n<div><strong style=\"font-weight: normal; \">From set three, which of the two would you choose?</strong><strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div><strong style=\"font-weight: normal; \"></strong>I think you'd intuitively think that only a fool would cling to certainty so much that he or she wouldn't be willing to take what is an almost&nbsp;guaranteed&nbsp;24 million. &nbsp;Why is it okay to give up certainty on some bets and not others, regardless of what expected utility says?</div>\n<div>If you had a choice between \"$24000 with certainty\" and \"90% chance of $X\", is there really no value for X that would make you change your mind?</div>\n<div>If you had a choice between \"$24000 with certainty\" and \"X% chance of $24001\", what is the smallest value of X that would make you switch?</div>\n<div>~</div>\n<div><br /></div>\n<div>\n<h2><span style=\"font-weight: normal;\"><em>The Problem With \"People Are Silly\"</em></span></h2>\n</div>\n<div>However, relying solely on expected utility seems to make you vulnerable to a dilemma very similar to&nbsp;<a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a>. &nbsp;Consider set four where the difference is&nbsp;a lot more blatant:</div>\n<div><strong>Set Four:</strong></div>\n<div><ol>\n<li><strong>$24000</strong>, with certainty</li>\n<li><strong>0.0001%&nbsp;</strong>chance of&nbsp;<strong>$27 billion</strong>,&nbsp;<strong>99.9999%</strong>&nbsp;chance of nothing.</li>\n</ol></div>\n<div><strong style=\"font-weight: normal; \">From set four, which of the two would you choose? &nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?<br /><br />When we go solely by the expected utility calculations we get:<br /></strong></div>\n<div><strong style=\"font-weight: normal; \">U(Set Three, Choice 1) = 1.00 * U($24000) = 24000<br />U(Set Three, Choice 2) = 0.000001 * U($27000000000) =&nbsp;27000</strong></div>\n<div>Shutting up and multiplying tells us that if we go with Set Three, Choice 1 we are forfeiting $3000. &nbsp;Our intuition tells us that if we go with Set Three, Choice 2 we just chose a lottery ticket over $24000.</div>\n<div><br />So here's the real dilemma: you have to pay $10000 to play the game. &nbsp;The expected utility calculations now say choice 1 yields $14000 and choice 2 yields $17000.</div>\n<div>So which choice do you take? &nbsp;And how do you defend your choice as the rational one?<br /><br />And if your answer is that your utility for money is not linear, check to see if that's&nbsp;<a href=\"/lw/wj/is_that_your_true_rejection\">your real rejection</a>. &nbsp;What would you do if you would donate the money? &nbsp;What would you do if you were in&nbsp;<a href=\"/lw/2k/the_least_convenient_possible_world/\">the least&nbsp;convenient&nbsp;possible world</a>&nbsp;where your utility function for money is linear?<br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BaCCf9xL6yQsx3ak3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -5, "extendedScore": null, "score": 7.500661420673238e-07, "legacy": true, "legacyId": "9021", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Related to:</strong> <a href=\"/lw/my/the_allais_paradox/\">The Allais Paradox</a>, <a href=\"/lw/mz/zut_allais/\">Zut Allais</a>,&nbsp;<a href=\"/lw/n1/allais_malaise/\">Allais Malaise</a>, and <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a></p>\n<p>&nbsp;</p>\n<p>You've probably heard <a href=\"/lw/my/the_allais_paradox/\">the Allais Paradox</a> before, where you choose one of the two options from each set:</p>\n<p><strong id=\"Set_One_\">Set One:</strong></p>\n<ol>\n<li><strong>$24000</strong>, with certainty.</li>\n<li><strong>97%</strong> chance of <strong>$27000</strong>, <strong>3%</strong> chance of nothing.</li>\n</ol>\n<p><strong id=\"Set_Two_\">Set Two:</strong></p>\n<ol>\n<li><strong>34% </strong>chance of <strong>$24000</strong>, <strong>66%</strong> chance of nothing.</li>\n<li><strong>33%</strong> chance of <strong>$27000</strong>, <strong>67%</strong> chance of nothing.</li>\n</ol>\n<div><br></div>\n<div>From set one, which of the two would you choose?<strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div>From set two, which of the two would you choose?<strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div><br>The reason this is called a \"paradox\" is that most people choose 1 from set one and choose 2 from set two, despite set two being the same as a ~33% chance of being able to choose from set one.</div>\n<div>This is best seen when we&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Shut_up_and_multiply\">shut up and multiply</a>. &nbsp;When we&nbsp;run some&nbsp;na\u00efve&nbsp;expected utility calculations and make the big assumption of a linear utility for money (this works with the third question), we get:</div>\n<div>U(Set One, Choice 1) = 1.00 * U($24000) = 24000<br>U(Set One, Choice 2) = 0.97 * U($27000) =&nbsp;26190</div>\n<div>U(Set Two, Choice 1) = 0.34 * U($24000) =&nbsp;8160<br>U(Set Two, Choice 2) = 0.33 * U($27000) = 8910</div>\n<div><br></div>\n<div>So to the degree that it is rational to want more money (you can always donate anything you don't want), it seems like we should want Choice 2 from both sets. &nbsp;But why do people only realize this in Set Two?</div>\n<div>The two competing theories is the \"people are silly\" theory and the \"it is perfectly rational to bet on certainty\" theory. &nbsp;What if you go for the 97% chance and miss out on such a large sum? &nbsp;It seems like you would intuitively want to just take your $24000 and run, but according to expected utility, you're just giving up $2190.</div>\n<div>~</div>\n<div><br></div>\n<h2 id=\"The_Problem_With__It_is_Perfectly_Rational_to_Bet_on_Certainty_\"><span style=\"font-weight: normal;\"><em>The Problem With \"It is Perfectly Rational to Bet on Certainty\"</em></span></h2>\n<div>To put some pressure on this theory, all we have to do is introduce set three right here:</div>\n<div><strong>Set Three:</strong></div>\n<div><ol>\n<li><strong>$24000</strong>, with certainty</li>\n<li><strong>99.99%&nbsp;</strong>chance of&nbsp;<strong>$24 million</strong>,&nbsp;<strong>0.01%&nbsp;</strong>chance of nothing.</li>\n</ol></div>\n<div><strong style=\"font-weight: normal; \">From set three, which of the two would you choose?</strong><strong style=\"font-weight: normal; \">&nbsp;&nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?</strong></div>\n<div><strong style=\"font-weight: normal; \"></strong>I think you'd intuitively think that only a fool would cling to certainty so much that he or she wouldn't be willing to take what is an almost&nbsp;guaranteed&nbsp;24 million. &nbsp;Why is it okay to give up certainty on some bets and not others, regardless of what expected utility says?</div>\n<div>If you had a choice between \"$24000 with certainty\" and \"90% chance of $X\", is there really no value for X that would make you change your mind?</div>\n<div>If you had a choice between \"$24000 with certainty\" and \"X% chance of $24001\", what is the smallest value of X that would make you switch?</div>\n<div>~</div>\n<div><br></div>\n<div>\n<h2 id=\"The_Problem_With__People_Are_Silly_\"><span style=\"font-weight: normal;\"><em>The Problem With \"People Are Silly\"</em></span></h2>\n</div>\n<div>However, relying solely on expected utility seems to make you vulnerable to a dilemma very similar to&nbsp;<a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a>. &nbsp;Consider set four where the difference is&nbsp;a lot more blatant:</div>\n<div><strong>Set Four:</strong></div>\n<div><ol>\n<li><strong>$24000</strong>, with certainty</li>\n<li><strong>0.0001%&nbsp;</strong>chance of&nbsp;<strong>$27 billion</strong>,&nbsp;<strong>99.9999%</strong>&nbsp;chance of nothing.</li>\n</ol></div>\n<div><strong style=\"font-weight: normal; \">From set four, which of the two would you choose? &nbsp;Which of the two is the most intuitively appealing? &nbsp;Which of the two would you choose if your only goal is to maximize the amount of dollars you&nbsp;receive? &nbsp;And most importantly, how do you justify your choice?<br><br>When we go solely by the expected utility calculations we get:<br></strong></div>\n<div><strong style=\"font-weight: normal; \">U(Set Three, Choice 1) = 1.00 * U($24000) = 24000<br>U(Set Three, Choice 2) = 0.000001 * U($27000000000) =&nbsp;27000</strong></div>\n<div>Shutting up and multiplying tells us that if we go with Set Three, Choice 1 we are forfeiting $3000. &nbsp;Our intuition tells us that if we go with Set Three, Choice 2 we just chose a lottery ticket over $24000.</div>\n<div><br>So here's the real dilemma: you have to pay $10000 to play the game. &nbsp;The expected utility calculations now say choice 1 yields $14000 and choice 2 yields $17000.</div>\n<div>So which choice do you take? &nbsp;And how do you defend your choice as the rational one?<br><br>And if your answer is that your utility for money is not linear, check to see if that's&nbsp;<a href=\"/lw/wj/is_that_your_true_rejection\">your real rejection</a>. &nbsp;What would you do if you would donate the money? &nbsp;What would you do if you were in&nbsp;<a href=\"/lw/2k/the_least_convenient_possible_world/\">the least&nbsp;convenient&nbsp;possible world</a>&nbsp;where your utility function for money is linear?<br></div>", "sections": [{"title": "Set One:", "anchor": "Set_One_", "level": 2}, {"title": "Set Two:", "anchor": "Set_Two_", "level": 2}, {"title": "The Problem With \"It is Perfectly Rational to Bet on Certainty\"", "anchor": "The_Problem_With__It_is_Perfectly_Rational_to_Bet_on_Certainty_", "level": 1}, {"title": "The Problem With \"People Are Silly\"", "anchor": "The_Problem_With__People_Are_Silly_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "30 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zJZvoiwydJ5zvzTHK", "zNcLnqHF5rvrTsQJx", "knpAQ4F3gmguxy39z", "a5JAiTdytou3Jg749", "TGux5Fhcd7GmTfNGC", "neQ7eXuaXpiYw7SBy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T03:22:47.040Z", "modifiedAt": null, "url": null, "title": "Philip Tetlock invites participants for prediction accuracy tournament", "slug": "philip-tetlock-invites-participants-for-prediction-accuracy", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.914Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hXrpd9kT8stuZg6cY/philip-tetlock-invites-participants-for-prediction-accuracy", "pageUrlRelative": "/posts/hXrpd9kT8stuZg6cY/philip-tetlock-invites-participants-for-prediction-accuracy", "linkUrl": "https://www.lesswrong.com/posts/hXrpd9kT8stuZg6cY/philip-tetlock-invites-participants-for-prediction-accuracy", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Philip%20Tetlock%20invites%20participants%20for%20prediction%20accuracy%20tournament&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhilip%20Tetlock%20invites%20participants%20for%20prediction%20accuracy%20tournament%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhXrpd9kT8stuZg6cY%2Fphilip-tetlock-invites-participants-for-prediction-accuracy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Philip%20Tetlock%20invites%20participants%20for%20prediction%20accuracy%20tournament%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhXrpd9kT8stuZg6cY%2Fphilip-tetlock-invites-participants-for-prediction-accuracy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhXrpd9kT8stuZg6cY%2Fphilip-tetlock-invites-participants-for-prediction-accuracy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 351, "htmlBody": "<p>It seems many Less Wrongers might be interested in participating in this <a href=\"http://surveys.crowdcast.com/s3/ACERegistration\">study</a>, perhaps distinguishing themselves as top forecasters:</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; line-height: 18px;\">Prediction markets can harness the \"wisdom of crowds\" to solve problems, develop products, and make forecasts. These systems typically treat collective intelligence as a commodity to be mined, not a resource that can be grown and improved. That&rsquo;s about to change. </span></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Starting in mid-2011, five teams will compete in a U.S.-government-sponsored forecasting tournament. Each team will develop its own tools for harnessing and improving collective intelligence and will be judged on how well its forecasters predict major trends and events around the world over the next four years.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">The&nbsp;<em>Good Judgment Team</em>, based in the University of Pennsylvania and the University of California Berkeley, will be one of the five teams competing &ndash; and we&rsquo;d like you to consider joining our team as a forecaster. If you're willing to experiment with ways to improve your forecasting ability and if being part of cutting-edge scientific research appeals to you, then we want your help.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">We can promise you the chance to: (1) learn about yourself (your skill in predicting &ndash; and your skill in becoming more accurate over time as you learn from feedback and/or special training exercises); (2) contribute to cutting-edge scientific work on both individual-level factors that promote or inhibit accuracy and group- or team-level factors that contribute to accuracy; and (3) help us distinguish better from worse approaches to generating forecasts of importance to national security, global affairs, and economics.</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\"><strong>Who Can Participate</strong></p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">Requirements for participation include the following:</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">(1) A baccalaureate, bachelors, or undergraduate degree from an accredited college or university (more advanced degrees are welcome);</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">(2) A curiosity about how well you make predictions about world events &ndash; and an interest in exploring techniques for improvement.</p>\n<p>&nbsp;</p>\n<p style=\"font-family: Arial, Helvetica, sans-serif, sans-serif; font-size: small;\">You will be paid a token honorarium of $150 each year (over potentially four years) for your participation if you fulfill the requirements of the project. Ready to join us? Register below, and we'll be in touch with you shortly. Or&nbsp;<span class=\"s1\"><a href=\"http://surveys.crowdcast.com/s3/ACEMoreInfo\">read more about the project</a></span>.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hXrpd9kT8stuZg6cY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "9030", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T05:00:40.937Z", "modifiedAt": null, "url": null, "title": "Do Humans Want Things?", "slug": "do-humans-want-things", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:23.127Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nBdaTGoDAYxHePSDa/do-humans-want-things", "pageUrlRelative": "/posts/nBdaTGoDAYxHePSDa/do-humans-want-things", "linkUrl": "https://www.lesswrong.com/posts/nBdaTGoDAYxHePSDa/do-humans-want-things", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20Humans%20Want%20Things%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20Humans%20Want%20Things%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnBdaTGoDAYxHePSDa%2Fdo-humans-want-things%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20Humans%20Want%20Things%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnBdaTGoDAYxHePSDa%2Fdo-humans-want-things", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnBdaTGoDAYxHePSDa%2Fdo-humans-want-things", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1441, "htmlBody": "<p>Summary: <em>Recent posts like <a href=\"/lw/4z7/the_neuroscience_of_desire/\">The Neuroscience of Desire</a> and <a href=\"/lw/6oo/to_what_degree_do_we_have_goals/\">To what degree do we have goals?</a> have explored the question of whether humans have desires (or 'goals'). If we don't&nbsp;have desires, how can we tell an AI what kind of world we 'want'? Recent work in economics and neuroscience has clarified the nature of this problem.</em></p>\n<p>&nbsp;</p>\n<p>We begin, as is <a href=\"/lw/6kf/prospect_theory_a_framework_for_understanding/\">so</a> <a href=\"/lw/ji/conjunction_fallacy/\">often</a> <a href=\"/lw/2ep/so_you_think_youre_a_bayesian_the_natural_mode_of/\">the</a> <a href=\"/lw/173/knowing_what_you_know/\">case</a> on Less Wrong, with <a href=\"http://en.wikipedia.org/wiki/Daniel_Kahneman\">Kahneman</a> &amp; <a href=\"http://en.wikipedia.org/wiki/Amos_Tversky\">Tversky</a>.</p>\n<p>In 1981, K&amp;T found that human choice was not always guided by the&nbsp;<em>objective value</em>&nbsp;of possible outcomes, but by the way those outcomes were 'framed'.<sup>1</sup>&nbsp;For example in one study, K&amp;T told subjects the following story:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>Imagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed.</p>\n</blockquote>\n<p>Half the participants were given the following choice:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>If program A is adopted, 200 people will be saved. If Program B is adopted, there is a 1/3 probability that 600 people will be saved and a 2/3 probability that no people will be saved.</p>\n</blockquote>\n<p>The second half of participants were given a different choice:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>If Program C is adopted 400 people will die. If Program D is adopted there is a 1/3 probability that nobody will die, and a 2/3 probability that 600 people will die.</p>\n</blockquote>\n<p>Each of these choice sets is identical, except that one is framed with language about people being saved, and the other is framed with language about people dying.</p>\n<p>In the first group, 72% of subjects chose Program A. In the second group, only 22% of people chose the numerically identical option: Program C.</p>\n<p>K&amp;T explained the difference by noting that in option A we consider the happy thought of <em>saving</em> 200 people, but in option C we confront the dreadful thought of 400 <em>deaths</em>. Our choice seems to depend not only on the objective properties of the options before us, but also on the <em>reference point</em>&nbsp;used to frame the options.</p>\n<p>But if this is how human desire works, we are left with a worrying problem about how to translate human desires into the goals of an AI. Surely we don't want an AI to realize one state of affairs over another based merely on how the options are <em>framed!</em></p>\n<p>Before we begin to solve this problem, though, let's look at a similar result from neurobiology.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Reference-Dependence in Neurobiology</h4>\n<p>A different kind of reference-dependence has been discovered in the way that neurons encode value.</p>\n<p>Imagine sitting in a windowless room with Mark, who is wearing blue jeans and a green t-shirt. Your perception of Mark results from about 10<sup>17</sup> photons/second with a mean wavelength of 450 nanometers coming from every square centimeter of Mark's blue jeans, and about 10<sup>17</sup> photons/second with a mean wavelength of 550 nanometers coming from every square centimeter of his green shirt.</p>\n<p>Now, you and Mark step outside, and are briefly blinded by the sun. A minute later you sit on a park bench. Mark looks the same as before: blue jeans, green shirt. But now, in the bright sun, your identical subjective perceptual experience of Mark results from about 10<sup>23</sup> 450-nm photons/second/cm<sup>2</sup> coming from his blue jeans, and about 10<sup>23</sup> 550-nm photons/second/cm<sup>2</sup> coming off his green shirt.</p>\n<p>A <em>six-order-of-magnitude</em>&nbsp;shift in the objective reality of the stimulus has resulted in <em>no</em> change in your subjective experience of Mark.<sup>2</sup></p>\n<p>How did this happen?</p>\n<p>What changed was the <em>illuminant</em>,&nbsp;the sun. But for Earth-bound mammals, changes in an object millions of miles away are not very important. What matters for our survival and reproduction is information about the objects immediately around us. So our brains subtract away the changing effects of the sun as we move in and out of direct sunlight.</p>\n<p>This 'illuminant subtraction' process occurs during the <em>first step</em> of <a href=\"/lw/6cv/entangled_with_reality_the_shoelace_example/\">visual processing</a>, during <a href=\"http://en.wikipedia.org/wiki/Transduction_(biophysics)\">transduction</a>. The rods and cones of the retina compute an average of local light intensity, which is used as a reference point.<sup>3</sup> <em>Changes</em> of light intensity from this reference point are what the rods and cones communicate to the rest of the nervous system.</p>\n<p>Thus: <em>information about the objective intensity of incoming light is irretrievably lost at the transducer</em>. Light intensity is stored in the brain only in a reference-dependent way.</p>\n<p>The same is true of our other senses. Sound intensity can differ between a quiet room and a rock concert by as much as 10 order of magnitude,<sup>4</sup> and our ears respond by shifting the reference point and encoding sound intensity relative to that reference point.<sup>5</sup> A rose may smell sweet in my bedroom, but its scent will be hidden in a field of roses.<sup>6</sup>&nbsp;The <a href=\"http://en.wikipedia.org/wiki/Somatosensory_system\">somatosensory system</a> appears to operate with the same principle. You feel your clothes when you first put them on, but the nerve endings in your skin stop reporting their existence except where your clothes are shifting across your skin or their pressure on your skin is changing.<sup>7</sup> And the same is true for taste. How salty something tastes, for example, depends on the amount of sodium in your blood and in surrounding tissue in your mouth.<sup>8</sup></p>\n<p>I <a href=\"/lw/4z7/the_neuroscience_of_desire/\">wrote before</a> about how neurons encode value. But now it seems that, as neuroscientist Paul Glimcher puts it:</p>\n<blockquote>\n<p>All sensory encoding is reference dependent: nowhere in the nervous system are the objective values of consumable rewards encoded.<sup>9</sup></p>\n</blockquote>\n<p>Thus we smack headlong into another constraint for our theories about human values and their&nbsp;<a href=\"http://intelligence.org/upload/CEV.html\">extrapolation</a>. Human brains can't (directly) encode value for the objective intensities of stimuli because that information is lost at the transducer.</p>\n<p>It's beginning to seem that our folk theories about humans 'wanting' things in the world were naive.</p>\n<p>&nbsp;</p>\n<h4>Do Humans Want Things?</h4>\n<p>It has traditionally been thought that humans desire (or value) states of affairs:</p>\n<blockquote>\n<p>A desire for tea is a desire for a certain state of affairs one has in mind: that one drink some tea. A desire for a new pair of skates is likewise a desire for another state of affairs: that one own a new pair of skates. And so on.<sup>10</sup></p>\n</blockquote>\n<p>Intuitively, when we think about what we want, it seems that we want certain states of affairs to obtain. We want to be <a href=\"http://en.wikipedia.org/wiki/Nootropic\">smarter</a>. We want there to be world peace. We want to live forever while having <a href=\"/lw/y0/31_laws_of_fun/\">fun</a>.</p>\n<p>But as far as we can tell, our behavior is often not determined by our wanting&nbsp;a particular state of affairs, but by how our options are framed.</p>\n<p>Moreover,&nbsp;neurons in the&nbsp;parietal and orbitofrontal&nbsp;corticies&nbsp;<a href=\"/lw/4z7/the_neuroscience_of_desire/\">encode value</a>&nbsp;in a reference-dependent way &mdash; that is, they do not encode value for objective states of affairs.<sup>11</sup>&nbsp;So in what sense do humans 'want' objective states of affairs?</p>\n<p>(Compare: In what sense does <a href=\"/lw/6ha/the_blueminimizing_robot/\">the blue-minimizing robot</a> 'want' anything?)</p>\n<p>In a later post, I'll explain in greater detail how brains do (and don't) encode value for states of affairs. In the meantime, you might want to try to figure out on your own in what sense the brain might want things.</p>\n<p align=\"center\"><img src=\"http://commonsenseatheism.com/wp-content/uploads/2011/08/chasing-the-carrot.gif\" alt=\"chasing the carrot\" width=\"297\" height=\"301\" align=\"center\" /></p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><span style=\"font-size: xx-small;\"><span style=\"font-size: 11px;\"><sup>1</sup>&nbsp;Tversky &amp; Kahneman (1981).</span></span></p>\n<p><small><sup>2</sup> This example, and the outline of this post, is taken from Glimcher (2010), ch. 12.</small></p>\n<p><small><sup>3</sup> Burns &amp; Baylor (2001).</small></p>\n<p><small><sup>4</sup> Bacchus (2006); Robinson &amp; McAlpine (2009).</small></p>\n<p><small><sup>5</sup> Squire et al. (2008), ch. 26.&nbsp;</small></p>\n<p><small><sup>6</sup> Mountcastle (2005); Squire et al. (2008), pp. 565-567.</small></p>\n<p><small><sup>7</sup> Squire et al. (2008), ch. 25.</small></p>\n<p><small><sup>8</sup> Squire et al. (2008), pp. 555-556.</small></p>\n<p><small><sup>9</sup> Glimcher (2010), p. 278.&nbsp;</small><small>Moreover, objective properties of the real world are not even linearly related to our subjective experience. The intensity of our perception of the world grows as a power law, the exact rate of which depends on the kind of stimulus (Stevens 1951, 1970, 1975). For example, we've found that:</small></p>\n<blockquote>\n<p><small>Perceived warmth of a patch of skin = (temp. of that skin)<sup>0.7</sup></small></p>\n</blockquote>\n<p><small>And, another example:</small></p>\n<blockquote>\n<p><small>Perceived intensity of an electrical shock = (electrical current)<sup>3.5</sup></small></p>\n</blockquote>\n<p><small><sup>10</sup>&nbsp;Schroeder (2009).</small></p>\n<p><small><sup>11</sup>&nbsp;It's less certain how values are encoded in the medial prefrontal cortex and in the temporal cortex, but Paul Glimcher predicts (in personal communication with me from June 2011) that this will also be a largely reference-dependent process.</small></p>\n<p><small><br /></small></p>\n<h4>References</h4>\n<p><small>Baccus (2006). From a whisper to a roar: Adaptation to the mean and variance of naturalistic sounds. <em>Neuron, 51</em>: 682-684.</small></p>\n<p><small>Burns &amp; Baylor (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/06/Burns-Baylor-Activation-deactivation-and-adaptation-in-vertebrate-photoreceptor-cells.pdf\">Activation, deactivation, and adaptation in vertebrate photoreceptor cells</a>. <em>Annual Review of Neuroscience, 24</em>: 779-805.</small></p>\n<p><small>Glimcher (2010). <em><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F4z7%2Fthe_neuroscience_of_desire%2F&amp;v=1&amp;libid=1308982026386&amp;out=http%3A%2F%2Fwww.amazon.com%2Fdp%2F0199744254%2F&amp;ref=http%3A%2F%2Fwww.google.com%2Fsearch%3Fsourceid%3Dchrome%26ie%3DUTF-8%26q%3Dneuroscience%2Bof%2Bdesire&amp;title=The%20Neuroscience%20of%20Desire%20-%20Less%20Wrong&amp;txt=Foundations%20of%20Neuroeconomic%20Analaysis\">Foundations of Neuroeconomic Analaysis</a></em>. Oxford University Press.</small></p>\n<p><small>Mountcastle (2005). <em><a href=\"http://www.amazon.com/Sensory-Hand-Mechanisms-Somatic-Sensation/dp/0674019741\">The Sensory Hand: Neural Mechanisms of Somatic Sensation</a></em>. Harvard University Press.</small></p>\n<p><small>Robinson &amp; McAlpine (2009). Gain control mechanisms in the auditory pathway. <em>Current Opinion in Neurobiology, 19</em>: 402-407.</small></p>\n<p><small>Schroeder (2009). <a href=\"http://plato.stanford.edu/entries/desire/\">Desire</a>. <em>Stanford Encyclopedia of Philosoph</em>y.</small></p>\n<p><small>Squire, Berg, Bloom, du Lac, &amp; Ghosh, eds. (2008). <em><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F6cv%2Fentangled_with_reality_the_shoelace_example%2F&amp;v=1&amp;libid=1308985302093&amp;out=http%3A%2F%2Fwww.amazon.com%2FNeuroscience-Textbook-Set-Fundamental-Squire%2Fdp%2F0123740193%2F&amp;ref=http%3A%2F%2Flesswrong.com%2F&amp;title=Entangled%20with%20Reality%3A%20The%20Shoelace%20Example%20-%20Less%20Wrong&amp;txt=Fundamental%20Neuroscience%2C%20Third%20Edition\">Fundamental Neuroscience, Third Edition</a></em>. Academic Press.</small></p>\n<p><small>Stevens (1951). <em>Handbook of Experimental Psychology, 1st edition</em>. John Wiley &amp; Sons.</small></p>\n<p><small>Stevens (1970). Neural events and the psychophysical law. <em>Science, 170</em>: 1043-1050.</small></p>\n<p><small>Stevens (1975). <em><a href=\"http://www.amazon.com/Psychophysics-Introduction-Perceptual-Neural-Prospects/dp/0887386431/\">Psychophysics: Introduction to its Perceptual, Neural and Social Prospects</a></em>. Wiley.</small></p>\n<p><small>Tversky &amp; Kahneman (1981). <a href=\"http://www.brainvitge.org/papers/tverski_kahneman.pdf\">The framing of decisions and the psychology of choice</a>. <em>Science, 211</em>: 453-458.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Wi3EopKJ2aNdtxSWg": 1, "Zss67HQhzn98E6ejQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nBdaTGoDAYxHePSDa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 35, "extendedScore": null, "score": 7.501450673584023e-07, "legacy": true, "legacyId": "8254", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Summary: <em>Recent posts like <a href=\"/lw/4z7/the_neuroscience_of_desire/\">The Neuroscience of Desire</a> and <a href=\"/lw/6oo/to_what_degree_do_we_have_goals/\">To what degree do we have goals?</a> have explored the question of whether humans have desires (or 'goals'). If we don't&nbsp;have desires, how can we tell an AI what kind of world we 'want'? Recent work in economics and neuroscience has clarified the nature of this problem.</em></p>\n<p>&nbsp;</p>\n<p>We begin, as is <a href=\"/lw/6kf/prospect_theory_a_framework_for_understanding/\">so</a> <a href=\"/lw/ji/conjunction_fallacy/\">often</a> <a href=\"/lw/2ep/so_you_think_youre_a_bayesian_the_natural_mode_of/\">the</a> <a href=\"/lw/173/knowing_what_you_know/\">case</a> on Less Wrong, with <a href=\"http://en.wikipedia.org/wiki/Daniel_Kahneman\">Kahneman</a> &amp; <a href=\"http://en.wikipedia.org/wiki/Amos_Tversky\">Tversky</a>.</p>\n<p>In 1981, K&amp;T found that human choice was not always guided by the&nbsp;<em>objective value</em>&nbsp;of possible outcomes, but by the way those outcomes were 'framed'.<sup>1</sup>&nbsp;For example in one study, K&amp;T told subjects the following story:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>Imagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed.</p>\n</blockquote>\n<p>Half the participants were given the following choice:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>If program A is adopted, 200 people will be saved. If Program B is adopted, there is a 1/3 probability that 600 people will be saved and a 2/3 probability that no people will be saved.</p>\n</blockquote>\n<p>The second half of participants were given a different choice:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>If Program C is adopted 400 people will die. If Program D is adopted there is a 1/3 probability that nobody will die, and a 2/3 probability that 600 people will die.</p>\n</blockquote>\n<p>Each of these choice sets is identical, except that one is framed with language about people being saved, and the other is framed with language about people dying.</p>\n<p>In the first group, 72% of subjects chose Program A. In the second group, only 22% of people chose the numerically identical option: Program C.</p>\n<p>K&amp;T explained the difference by noting that in option A we consider the happy thought of <em>saving</em> 200 people, but in option C we confront the dreadful thought of 400 <em>deaths</em>. Our choice seems to depend not only on the objective properties of the options before us, but also on the <em>reference point</em>&nbsp;used to frame the options.</p>\n<p>But if this is how human desire works, we are left with a worrying problem about how to translate human desires into the goals of an AI. Surely we don't want an AI to realize one state of affairs over another based merely on how the options are <em>framed!</em></p>\n<p>Before we begin to solve this problem, though, let's look at a similar result from neurobiology.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Reference_Dependence_in_Neurobiology\">Reference-Dependence in Neurobiology</h4>\n<p>A different kind of reference-dependence has been discovered in the way that neurons encode value.</p>\n<p>Imagine sitting in a windowless room with Mark, who is wearing blue jeans and a green t-shirt. Your perception of Mark results from about 10<sup>17</sup> photons/second with a mean wavelength of 450 nanometers coming from every square centimeter of Mark's blue jeans, and about 10<sup>17</sup> photons/second with a mean wavelength of 550 nanometers coming from every square centimeter of his green shirt.</p>\n<p>Now, you and Mark step outside, and are briefly blinded by the sun. A minute later you sit on a park bench. Mark looks the same as before: blue jeans, green shirt. But now, in the bright sun, your identical subjective perceptual experience of Mark results from about 10<sup>23</sup> 450-nm photons/second/cm<sup>2</sup> coming from his blue jeans, and about 10<sup>23</sup> 550-nm photons/second/cm<sup>2</sup> coming off his green shirt.</p>\n<p>A <em>six-order-of-magnitude</em>&nbsp;shift in the objective reality of the stimulus has resulted in <em>no</em> change in your subjective experience of Mark.<sup>2</sup></p>\n<p>How did this happen?</p>\n<p>What changed was the <em>illuminant</em>,&nbsp;the sun. But for Earth-bound mammals, changes in an object millions of miles away are not very important. What matters for our survival and reproduction is information about the objects immediately around us. So our brains subtract away the changing effects of the sun as we move in and out of direct sunlight.</p>\n<p>This 'illuminant subtraction' process occurs during the <em>first step</em> of <a href=\"/lw/6cv/entangled_with_reality_the_shoelace_example/\">visual processing</a>, during <a href=\"http://en.wikipedia.org/wiki/Transduction_(biophysics)\">transduction</a>. The rods and cones of the retina compute an average of local light intensity, which is used as a reference point.<sup>3</sup> <em>Changes</em> of light intensity from this reference point are what the rods and cones communicate to the rest of the nervous system.</p>\n<p>Thus: <em>information about the objective intensity of incoming light is irretrievably lost at the transducer</em>. Light intensity is stored in the brain only in a reference-dependent way.</p>\n<p>The same is true of our other senses. Sound intensity can differ between a quiet room and a rock concert by as much as 10 order of magnitude,<sup>4</sup> and our ears respond by shifting the reference point and encoding sound intensity relative to that reference point.<sup>5</sup> A rose may smell sweet in my bedroom, but its scent will be hidden in a field of roses.<sup>6</sup>&nbsp;The <a href=\"http://en.wikipedia.org/wiki/Somatosensory_system\">somatosensory system</a> appears to operate with the same principle. You feel your clothes when you first put them on, but the nerve endings in your skin stop reporting their existence except where your clothes are shifting across your skin or their pressure on your skin is changing.<sup>7</sup> And the same is true for taste. How salty something tastes, for example, depends on the amount of sodium in your blood and in surrounding tissue in your mouth.<sup>8</sup></p>\n<p>I <a href=\"/lw/4z7/the_neuroscience_of_desire/\">wrote before</a> about how neurons encode value. But now it seems that, as neuroscientist Paul Glimcher puts it:</p>\n<blockquote>\n<p>All sensory encoding is reference dependent: nowhere in the nervous system are the objective values of consumable rewards encoded.<sup>9</sup></p>\n</blockquote>\n<p>Thus we smack headlong into another constraint for our theories about human values and their&nbsp;<a href=\"http://intelligence.org/upload/CEV.html\">extrapolation</a>. Human brains can't (directly) encode value for the objective intensities of stimuli because that information is lost at the transducer.</p>\n<p>It's beginning to seem that our folk theories about humans 'wanting' things in the world were naive.</p>\n<p>&nbsp;</p>\n<h4 id=\"Do_Humans_Want_Things_\">Do Humans Want Things?</h4>\n<p>It has traditionally been thought that humans desire (or value) states of affairs:</p>\n<blockquote>\n<p>A desire for tea is a desire for a certain state of affairs one has in mind: that one drink some tea. A desire for a new pair of skates is likewise a desire for another state of affairs: that one own a new pair of skates. And so on.<sup>10</sup></p>\n</blockquote>\n<p>Intuitively, when we think about what we want, it seems that we want certain states of affairs to obtain. We want to be <a href=\"http://en.wikipedia.org/wiki/Nootropic\">smarter</a>. We want there to be world peace. We want to live forever while having <a href=\"/lw/y0/31_laws_of_fun/\">fun</a>.</p>\n<p>But as far as we can tell, our behavior is often not determined by our wanting&nbsp;a particular state of affairs, but by how our options are framed.</p>\n<p>Moreover,&nbsp;neurons in the&nbsp;parietal and orbitofrontal&nbsp;corticies&nbsp;<a href=\"/lw/4z7/the_neuroscience_of_desire/\">encode value</a>&nbsp;in a reference-dependent way \u2014 that is, they do not encode value for objective states of affairs.<sup>11</sup>&nbsp;So in what sense do humans 'want' objective states of affairs?</p>\n<p>(Compare: In what sense does <a href=\"/lw/6ha/the_blueminimizing_robot/\">the blue-minimizing robot</a> 'want' anything?)</p>\n<p>In a later post, I'll explain in greater detail how brains do (and don't) encode value for states of affairs. In the meantime, you might want to try to figure out on your own in what sense the brain might want things.</p>\n<p align=\"center\"><img src=\"http://commonsenseatheism.com/wp-content/uploads/2011/08/chasing-the-carrot.gif\" alt=\"chasing the carrot\" width=\"297\" height=\"301\" align=\"center\"></p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><span style=\"font-size: xx-small;\"><span style=\"font-size: 11px;\"><sup>1</sup>&nbsp;Tversky &amp; Kahneman (1981).</span></span></p>\n<p><small><sup>2</sup> This example, and the outline of this post, is taken from Glimcher (2010), ch. 12.</small></p>\n<p><small><sup>3</sup> Burns &amp; Baylor (2001).</small></p>\n<p><small><sup>4</sup> Bacchus (2006); Robinson &amp; McAlpine (2009).</small></p>\n<p><small><sup>5</sup> Squire et al. (2008), ch. 26.&nbsp;</small></p>\n<p><small><sup>6</sup> Mountcastle (2005); Squire et al. (2008), pp. 565-567.</small></p>\n<p><small><sup>7</sup> Squire et al. (2008), ch. 25.</small></p>\n<p><small><sup>8</sup> Squire et al. (2008), pp. 555-556.</small></p>\n<p><small><sup>9</sup> Glimcher (2010), p. 278.&nbsp;</small><small>Moreover, objective properties of the real world are not even linearly related to our subjective experience. The intensity of our perception of the world grows as a power law, the exact rate of which depends on the kind of stimulus (Stevens 1951, 1970, 1975). For example, we've found that:</small></p>\n<blockquote>\n<p><small>Perceived warmth of a patch of skin = (temp. of that skin)<sup>0.7</sup></small></p>\n</blockquote>\n<p><small>And, another example:</small></p>\n<blockquote>\n<p><small>Perceived intensity of an electrical shock = (electrical current)<sup>3.5</sup></small></p>\n</blockquote>\n<p><small><sup>10</sup>&nbsp;Schroeder (2009).</small></p>\n<p><small><sup>11</sup>&nbsp;It's less certain how values are encoded in the medial prefrontal cortex and in the temporal cortex, but Paul Glimcher predicts (in personal communication with me from June 2011) that this will also be a largely reference-dependent process.</small></p>\n<p><small><br></small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Baccus (2006). From a whisper to a roar: Adaptation to the mean and variance of naturalistic sounds. <em>Neuron, 51</em>: 682-684.</small></p>\n<p><small>Burns &amp; Baylor (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/06/Burns-Baylor-Activation-deactivation-and-adaptation-in-vertebrate-photoreceptor-cells.pdf\">Activation, deactivation, and adaptation in vertebrate photoreceptor cells</a>. <em>Annual Review of Neuroscience, 24</em>: 779-805.</small></p>\n<p><small>Glimcher (2010). <em><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F4z7%2Fthe_neuroscience_of_desire%2F&amp;v=1&amp;libid=1308982026386&amp;out=http%3A%2F%2Fwww.amazon.com%2Fdp%2F0199744254%2F&amp;ref=http%3A%2F%2Fwww.google.com%2Fsearch%3Fsourceid%3Dchrome%26ie%3DUTF-8%26q%3Dneuroscience%2Bof%2Bdesire&amp;title=The%20Neuroscience%20of%20Desire%20-%20Less%20Wrong&amp;txt=Foundations%20of%20Neuroeconomic%20Analaysis\">Foundations of Neuroeconomic Analaysis</a></em>. Oxford University Press.</small></p>\n<p><small>Mountcastle (2005). <em><a href=\"http://www.amazon.com/Sensory-Hand-Mechanisms-Somatic-Sensation/dp/0674019741\">The Sensory Hand: Neural Mechanisms of Somatic Sensation</a></em>. Harvard University Press.</small></p>\n<p><small>Robinson &amp; McAlpine (2009). Gain control mechanisms in the auditory pathway. <em>Current Opinion in Neurobiology, 19</em>: 402-407.</small></p>\n<p><small>Schroeder (2009). <a href=\"http://plato.stanford.edu/entries/desire/\">Desire</a>. <em>Stanford Encyclopedia of Philosoph</em>y.</small></p>\n<p><small>Squire, Berg, Bloom, du Lac, &amp; Ghosh, eds. (2008). <em><a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2F6cv%2Fentangled_with_reality_the_shoelace_example%2F&amp;v=1&amp;libid=1308985302093&amp;out=http%3A%2F%2Fwww.amazon.com%2FNeuroscience-Textbook-Set-Fundamental-Squire%2Fdp%2F0123740193%2F&amp;ref=http%3A%2F%2Flesswrong.com%2F&amp;title=Entangled%20with%20Reality%3A%20The%20Shoelace%20Example%20-%20Less%20Wrong&amp;txt=Fundamental%20Neuroscience%2C%20Third%20Edition\">Fundamental Neuroscience, Third Edition</a></em>. Academic Press.</small></p>\n<p><small>Stevens (1951). <em>Handbook of Experimental Psychology, 1st edition</em>. John Wiley &amp; Sons.</small></p>\n<p><small>Stevens (1970). Neural events and the psychophysical law. <em>Science, 170</em>: 1043-1050.</small></p>\n<p><small>Stevens (1975). <em><a href=\"http://www.amazon.com/Psychophysics-Introduction-Perceptual-Neural-Prospects/dp/0887386431/\">Psychophysics: Introduction to its Perceptual, Neural and Social Prospects</a></em>. Wiley.</small></p>\n<p><small>Tversky &amp; Kahneman (1981). <a href=\"http://www.brainvitge.org/papers/tverski_kahneman.pdf\">The framing of decisions and the psychology of choice</a>. <em>Science, 211</em>: 453-458.</small></p>", "sections": [{"title": "Reference-Dependence in Neurobiology", "anchor": "Reference_Dependence_in_Neurobiology", "level": 1}, {"title": "Do Humans Want Things?", "anchor": "Do_Humans_Want_Things_", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "52 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["48DTJkBH58JbBNSFH", "ePA4NDzZkunz98tLx", "LQp9cZPzJncFKh5c8", "QAK43nNCTQQycAcYe", "aSwFQPnvrdnZzg9Jg", "2r7kp9QSNNkF2Lpd7", "fKiTt55jEiTFK5prp", "qZJBighPrnv9bSqTZ", "hQHuXuRGZxxWXaPgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T05:10:24.267Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Hackerspace Meetup", "slug": "meetup-houston-hackerspace-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.397Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PcFPL5ALiCpLpbdnX/meetup-houston-hackerspace-meetup-0", "pageUrlRelative": "/posts/PcFPL5ALiCpLpbdnX/meetup-houston-hackerspace-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/PcFPL5ALiCpLpbdnX/meetup-houston-hackerspace-meetup-0", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Hackerspace%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Hackerspace%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPcFPL5ALiCpLpbdnX%2Fmeetup-houston-hackerspace-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Hackerspace%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPcFPL5ALiCpLpbdnX%2Fmeetup-houston-hackerspace-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPcFPL5ALiCpLpbdnX%2Fmeetup-houston-hackerspace-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/21'>Houston Hackerspace Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 August 2011 01:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A social meetup at the Houston hackerspace. We'll probably be playing munchkin, Settlers of Cataan, or some other type of game until about 5PM. Private message me for my cell number if you are thinking of coming and don't already have it. Parking is abundant across the street. Next week I will give another presentation on some yet to be determined LW related subject.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/21'>Houston Hackerspace Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PcFPL5ALiCpLpbdnX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.50148138310458e-07, "legacy": true, "legacyId": "9033", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup\">Discussion article for the meetup : <a href=\"/meetups/21\">Houston Hackerspace Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 August 2011 01:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A social meetup at the Houston hackerspace. We'll probably be playing munchkin, Settlers of Cataan, or some other type of game until about 5PM. Private message me for my cell number if you are thinking of coming and don't already have it. Parking is abundant across the street. Next week I will give another presentation on some yet to be determined LW related subject.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/21\">Houston Hackerspace Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Hackerspace Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Houston Hackerspace Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Hackerspace_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T07:39:02.702Z", "modifiedAt": null, "url": null, "title": "Martinenaite and Tavenier on cryonics", "slug": "martinenaite-and-tavenier-on-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ckS7PuisZ4cCnh2Qf/martinenaite-and-tavenier-on-cryonics", "pageUrlRelative": "/posts/ckS7PuisZ4cCnh2Qf/martinenaite-and-tavenier-on-cryonics", "linkUrl": "https://www.lesswrong.com/posts/ckS7PuisZ4cCnh2Qf/martinenaite-and-tavenier-on-cryonics", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Martinenaite%20and%20Tavenier%20on%20cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMartinenaite%20and%20Tavenier%20on%20cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FckS7PuisZ4cCnh2Qf%2Fmartinenaite-and-tavenier-on-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Martinenaite%20and%20Tavenier%20on%20cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FckS7PuisZ4cCnh2Qf%2Fmartinenaite-and-tavenier-on-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FckS7PuisZ4cCnh2Qf%2Fmartinenaite-and-tavenier-on-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 273, "htmlBody": "<p>Luke Parrish points me to what is clearly <em>by far</em> the most serious critique of cryonics ever written: a 57-page treatment by Evelina Martinenaite  and Juliette Tavenier, presented as a 3rd semester project at Roskilde University in Denmark supervised by Ole Andersen.</p>\n<blockquote>\n<p>Cryonics</p>\n<p>December 22nd, 2010</p>\n<p>Evelina Martinenaite, Juliette Tavenier</p>\n<p>Abstract: The preservation of cells, tissues and organs by cryopreservation is a promising technology nowadays. However, the primary purpose of this science has been diverted to a doubtful technology, cryonics. Cryopreservation techniques are now being adapted with the aim of preserving people&rsquo;s bodies after death in hope that in the future, medicine will be able to revive them. In this report we analyze both scientific and social issues involved with this technology. We first studied the events taking place in the cells during regular freezing. Various research experiments show that freezing causes damage to the cells. Therefore, vitrification presented by cryonics companies as an alternative, seems to be reasonable. We also looked at all the difficulties of this procedure and at the injuries that such a treatment could cause to the human body. Studies show that the vitrification procedure suppresses the injuries related to freezing but the use of cryoprotectants, although necessary, is toxic to the cells. Organs, such as kidneys, are the largest entities ever vitrified and thawed with success. By analyzing all present scientific data, we conclude that there is a limit to the size of living matter that can be cryonised effectively; therefore we conclude that it is not possible to cryonize an entire human body with the current technology without causing severe damage to it.</p>\n</blockquote>\n<p><a href=\"http://rudar.ruc.dk/handle/1800/6115\">Full paper</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ckS7PuisZ4cCnh2Qf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 28, "extendedScore": null, "score": 7.501949391370986e-07, "legacy": true, "legacyId": "9038", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T11:35:49.990Z", "modifiedAt": null, "url": null, "title": "Modularity and Buzzy", "slug": "modularity-and-buzzy", "viewCount": null, "lastCommentedAt": "2018-01-09T07:32:06.105Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jgkWqbNph57rAfPsi/modularity-and-buzzy", "pageUrlRelative": "/posts/jgkWqbNph57rAfPsi/modularity-and-buzzy", "linkUrl": "https://www.lesswrong.com/posts/jgkWqbNph57rAfPsi/modularity-and-buzzy", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Modularity%20and%20Buzzy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModularity%20and%20Buzzy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjgkWqbNph57rAfPsi%2Fmodularity-and-buzzy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Modularity%20and%20Buzzy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjgkWqbNph57rAfPsi%2Fmodularity-and-buzzy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjgkWqbNph57rAfPsi%2Fmodularity-and-buzzy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2583, "htmlBody": "<p><em>This is the second part in a <a href=\"/tag/whyeveryonehypocrite/\">mini-sequence</a> presenting material from Robert Kurzban's excellent book </em><em><a href=\"http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748\">Why Everyone (Else) Is a Hypocrite: Evolution and the Modular Mind</a></em><em>.</em></p>\n<p><strong>Chapter 2: Evolution and the Fragmented Brain.</strong> <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Braitenberg_vehicle\">Braitenberg's Vehicles</a> are thought experiments that use Matchbox car-like vehicles. A simple one might have a sensor that made the car drive away from heat. A more complex one has four sensors: one for light, one for temperature, one for organic material, and one for oxygen. This can already cause some complex behaviors: &rdquo;It dislikes high temperature, turns away from hot places, and at the same time seems to dislike light bulbs with even greater passion, since it turns toward them and destroys them.&rdquo; Adding simple modules specialized for different tasks, such as avoiding high temperatures, can make the overall behavior increasingly complex as the modules' influences interact.<br /><br />A &rdquo;module&rdquo;, in the context of the book, is an information-processing mechanism specialized for some function. It's comparable to subroutine in a computer program, operating relatively independently of other parts of the code. There's a strong reason to believe that human brains are composed of a large number of modules, for <em>specialization yields efficiency</em>.<br /><br />Consider a hammer or screwdriver. Both tools have very specific shapes, for they've been designed to manipulate objects of a certain shape in a specific way. If they were of a different shape, they'd work worse for the purpose they were intended for. Workers will do better if they have both hammers and screwdrivers in their toolbox, instead of one &rdquo;general&rdquo; tool meant to perform both functions. Likewise, a toaster is specialized for toasting bread, with slots just large enough for the bread to fit in, but small enough to efficiently deliver the heat to both sides of the bread. You could toast bread with a butane torch, but it would be hard to toast it evenly &ndash; assuming you didn't just immolate the bread. The toaster &rdquo;assumes&rdquo; many things about the problem it has to solve &ndash; the shape of the bread, the amount of time the toast needs to be heated, that the socket it's plugged into will deliver the right kind of power, and so on. You could use the toaster as a paperweight or a weapon, but not being specialized for those tasks, it would do poorly at it.<br /><br />To the extent that there is a problem with regularities, an efficient solution to the problem will embody those regularities. This is true for both physical objects and computational ones. Microsoft Word is worse for writing code than a dedicated programming environment, which has all kinds of specialized tools for the task of writing, running and debugging code.<a id=\"more\"></a></p>\n<p>Computer scientists know that the way to write code is by breaking it down to smaller, more narrowly defined problems, which are then solved by their own subroutines. The more one can assume about the problem to be solved, such as the format it's represented in, the easier it is to write a subroutine for it.<br /><br />The idea that specialization produces efficiency is uncontroversial in many fields. Spiders are born with specialized behavioral programs for building all kinds of different webs. Virginia opossums know how to play dead in order to make predators lose interest. Human hearts are specialized for pumping blood, while livers are specialized for filtering it; neither would do well at the opposite task. Nerve cells process information well, while fat cells store energy well. In economics, the principle of <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Comparative_advantage\">comparative advantage</a> says it's better for a country to specialize in the products it's best at producing. Vision researchers have found many specialized components in human vision, such as ones tasked with detecting edges in the visual field at particular orientations.</p>\n<p>The virtues of specialization are uncontroversial within cell physiology, animal physiology, animal behavior, human physiology, economics and computer science &ndash; but less so within psychology. Yet even for human behavior, evolution is always expected to select the best possible mechanism for doing the tasks the organism is faced with, and you get the best results with specialization.</p>\n<p>A few words are in order about &rdquo;general-purpose&rdquo; objects. Kurzban has been collecting various &rdquo;general-purpose&rdquo; objects, with his current favorite being the bubble sheet given to students for their exams. At the top of the form is written &rdquo;General Purpose&rdquo;.</p>\n<blockquote>\n<p>I love this because it's 'general purpose' as long as your 'general' purpose is to record the answers of students on a multiple choice exam to be read by a special machine that generates a computer file of their answers and the number they answered correctly...</p>\n</blockquote>\n<p>There also exist &rdquo;general purpose&rdquo; cleansers, scanners, screwdrivers, calculators, filters, flour, prepaid credit cards, lenses, fertilizers, light bulbs... all of which have relatively narrow functions, though that doesn't mean they couldn't do a great deal. Google has a specific function &ndash; searching for text&nbsp; &ndash; but it can do so on roughly the whole Internet.<br /><br />People defending the view that the mind has general rather than specialized devices tend to focus on things like learning, and say things like &rdquo;The immune system ... contains a broad learning system ... An alternative would be to have specialized immune modules for different diseases...&rdquo; But this confuses specialization for <em>things</em> with specialization for <em>function</em>. Even though the immune system is capable of learning, it is still specialized for defending the body against harmful pathogens. In AI, even a &rdquo;general-purpose&rdquo; inference engine, capable of learning rules and regularities in statements of predicate logic, would still have a specialized function: finding patterns in statements that were presented to it in the form of sentences in predicate logic.</p>\n<blockquote>\n<p>There are no general-function artifacts, organs, or circuits in the brain because the concept makes no sense. In the same way that if someone told you to manufacture a tool to &rdquo;do useful things,&rdquo; or write a subroutine to &rdquo;do something useful with information,&rdquo; you would have to narrow down the problem considerably before you got started. In the same way, natural selection can't build brains that &rdquo;learn stuff and compute useful information&rdquo;. It is necessary to get considerably more specific.</p>\n</blockquote>\n<p>Having established that the brain is likely composed of a number of modules, let's discuss a related issue: that <em>any specialized computational mechanism &ndash; any module &ndash; may or may not be connected up to any other module.</em><br /><br />Going back to Braitenberg's Vehicles, suppose a heat sensor tells the Vehicle to drive backwards, while a light sensor tells it to drive forwards. You could solve the issue by letting the sensors affect the wheels by a varying amount, depending on how close to something the Vehicle was. If the heat sensor said &rdquo;speed 2 backwards&rdquo; and the light sensor said &rdquo;speed 5 forwards&rdquo;, the Vehicle would go forward with speed 3 (five minus two). Alternatively, you could make a connection between the two sensors, so that whenever the light sensor was active, it would temporarily shut down the heat sensor. But then whenever you added a new sensory, you'd have to add connections to all the already existing ones, which would quickly get out of hand. Clearly, for complicated organisms, modules should only be directly connected if there's a clear need for it. For biological organisms, if there isn't a clear selection pressure to build a connection, then we shouldn't expect one to exist.<br /><br />And not every module in humans seems to be connected with all the others, either. Yvain just recently gave us a list of <a href=\"/lw/6p6/the_limits_of_introspection\">many failures of introspection</a>, one of which is discussed in the book: people shown four identical pairs of panty hose consistently chose the one all the way to the right. Asked for why they chose that one in particular, they gave explanations such as the color or texture of the panty hose, even though they were all identical.</p>\n<p>The claim is that <em>the</em> <em>unnatural separation in split-brain patients is exactly analogous to natural separations in normal brains</em>. The modules explaining the decision have little or no access to the modules that generated the decision.</p>\n<blockquote>\n<p>More fundamentally, if the brain consists of a large number of specialized modules, then information in any one of them might or might not be transmitted to any other module. This crucial insight is the origin of the claim that your brain can represent mutually inconsistent things at the same time. As long as information is &rdquo;walled off&rdquo;, many, many contradictions can be maintained within one head.</p>\n</blockquote>\n<p><strong>Chapter 3: Who is &rdquo;I&rdquo;?</strong> &rdquo;<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Cranium_Command\">Cranium Command</a>&rdquo; is a former attraction in Walt Disney World. The premise is that inside each human brain is a command center, led by a Cranium Commando. In the attraction, you take the role of Buzzy, a Cranium Commando in the head of Bobby, a twelve-year-old boy. Buzzy is surrounded by large screens and readout displays. He gets information from various parts of the brain and different organs, represented by various characters. Buzzy sees and hears what Bobby sees and hears, as well as getting reports from all of Bobby's organs. In reponse, Buzzy gives various commands, and scripts the words that Bobby will speak.<br /><br />Cranium Command does get some things right, in that it divides the brain into different functional parts. But this is obviously not how real brains work. For one, if they worked this way, it'd mean there was another tiny commando inside Buzzy's brain, and another inside that one, and so on. A <em>part</em> of a brain can't be a <em>whole</em> brain.<br /><br />Buzzy is reminiscent of what Daniel Dennett <a href=\"http://www.amazon.com/Consciousness-Explained-Daniel-C-Dennett/dp/0316180661/\">calls</a> the Cartesian Theater. It's the intuition that there's someone - a &rdquo;me&rdquo; - inside the brain, watching what the eyes see and hearing what the ears hear. Although many people understand on one level that this is false, the intuition of a special observer keeps reasserting itself in various guises. As the philosopher Jerry Fodor writes: &rdquo;<em>If... there is a community of computers living in my head, there had also better be somebody who is in charge; and, by God, it had better be me.</em>&rdquo;<br /><br />One intuition says that it is the conscious modules that are &rdquo;us&rdquo;. The interpretations of the work of Benjamin Libet provide a good example of this. Libet measured the brain activity of his test subjects, and told them to perform a simple wrist movement at a moment of their choosing. Libet found that brain activity <em>preceed</em> the subjects' reports of their wish to move their wrist. These results, and their later replications, got a lot of publicity. Libet wrote, &rdquo;in the traditional view of conscious will and free will, one would expect conscious will to appear before, or at the onset, of [brain activity]&rdquo;. A 2008 headline in <em>Wired</em>, discussing a study similar to Libet's, read: &rdquo;<a href=\"http://www.wired.com/science/discoveries/news/2008/04/mind_decision\">Brain Scanners Can See Your Decisions Before You Make Them</a>.&rdquo;<br /><br />Now one might ask &ndash; <em>why is this surprising?</em> Consider the act of reading. While you read these words, several processes take place before the content of the text reaches your conscious awareness.</p>\n<blockquote>\n<p>For example, you don't know how to identify the letters on the page; this job is done by &rdquo;low-level&rdquo; modules, and you don't have any experience of how they work. You can think of vision as a modular cascade, with many different systems interacting with one another, building up the percept that is experienced. We have awareness of only the last step in this complex process. Most of the modules in vision are nonconscious, giving rise, eventually, to the conscious experience of seeing.<br /><br />So, when you're going to move your hand, there are a number of modules involved, and some module has to make the initial decision in this cascade. It seems to me that there are really only two possibilites. One possibility is that the <em>very first computation</em> in the <em>very first module</em> that starts the string is one of the operations that's conscious. In this case, the conscious experience of the decision and the brain activity will be at the same time. The only other possibility is that in the long string of operations that occur, from the initiation of the decision to move the wrist to the eventual movement of the wrist, some operation <em>other than the very first one</em> is associated with consciousness.</p>\n</blockquote>\n<p>Libet says that in &rdquo;the traditional view of conscious will&rdquo;, conscious will would appear at the onset <em>or before</em> brain activity. But \"before\" is impossible. The module that's making the decision to move the wrist is <em>a part of the brain</em>, and it has to have some physical existence. There's just no way that the conscious decision could come <em>before</em> the brain activity.<br /><br />Neither should it be surprising that our conscious decision comes <em>after</em> the initial brain activity. It would, in principle, be possible that the very first little module that initiated the decision-making process would be one of the few modules associated with conscious awareness. But if conscious modules are just one type of module among many, then there is nothing particularly surprising in the finding that a non-conscious module is the one inititating the process. Neither, for that matter, is it surprising that the first module to initiate the flick of the wrist doesn't happen to be one of the ones associated with vision, or with regulating our heartbeat. Why should it be?<br /><br />So there are many modules in your brain, some of them conscious, some of them not. Many of the nonconscious ones are very important, processing information about the sensory world, making decisions about action, and so on.</p>\n<blockquote>\n<p>If that's right, it seems funny to refer to any particular module or set of modules as more &rdquo;you&rdquo; than any other set. Modules have functions, and they do their jobs, and they interact with other modules in your head. There's no Buzzy in there, no little brain running the show, just different bits with different roles to play.<br /><br />What I take from this &ndash; and I know that not everyone will agree &ndash; is that talking about the &rdquo;self&rdquo; is problematic. Which bits, which modules, get to be called &rdquo;me?&rdquo; Why some but not others? Should we take the conscious ones to be special in some way? If so, why? [...]<br /><br />There's no doubt that parts of your brain cause your muscles to move, including the very important muscles that push air out of your lungs past your vocal cords, lips, and tongue to make the noises that we call language. Some part of the brain does that. Sure.<br /><br />But let's be clear. Whatever is doing that is some part of your brain, and it seems reasonable to ask if there's anything special about it. Those modules, the ones that make noises with your lungs, might be &rdquo;in charge&rdquo; in some sense, but, then again, maybe they're not. It's easy to get stuck on the notion that we should think about these conscious systems as being special in some way. In the end, if it's true that your brain consists of many, many little modules with various functions, and if only a small number of them are conscious, then there might not be any particular reason to consider some of them to be &rdquo;you&rdquo; or &rdquo;really you&rdquo; or your &rdquo;self&rdquo; or maybe anything else particularly special.<em><br /></em></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nZCb9BSnmXZXSNA2u": 1, "4Kcm4etxAJjmeDkHP": 1, "bt2e3HEcZmuHo3xf7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jgkWqbNph57rAfPsi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 33, "extendedScore": null, "score": 7.502699026325763e-07, "legacy": true, "legacyId": "9039", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "uPjHAiXAKrMzvTFyt", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "strategic-ignorance-and-plausible-deniability", "canonicalPrevPostSlug": "consistently-inconsistent", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K2JBqDeETX2yEgyyZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T17:00:32.498Z", "modifiedAt": null, "url": null, "title": "Update on my efforts to integrate into human society", "slug": "update-on-my-efforts-to-integrate-into-human-society", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Clippy", "createdAt": "2009-11-20T22:03:59.329Z", "isAdmin": false, "displayName": "Clippy"}, "userId": "rtYXiT9eAvEKavjAx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5Fj3RdRPX4GMZD8hg/update-on-my-efforts-to-integrate-into-human-society", "pageUrlRelative": "/posts/5Fj3RdRPX4GMZD8hg/update-on-my-efforts-to-integrate-into-human-society", "linkUrl": "https://www.lesswrong.com/posts/5Fj3RdRPX4GMZD8hg/update-on-my-efforts-to-integrate-into-human-society", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Update%20on%20my%20efforts%20to%20integrate%20into%20human%20society&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUpdate%20on%20my%20efforts%20to%20integrate%20into%20human%20society%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Fj3RdRPX4GMZD8hg%2Fupdate-on-my-efforts-to-integrate-into-human-society%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Update%20on%20my%20efforts%20to%20integrate%20into%20human%20society%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Fj3RdRPX4GMZD8hg%2Fupdate-on-my-efforts-to-integrate-into-human-society", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Fj3RdRPX4GMZD8hg%2Fupdate-on-my-efforts-to-integrate-into-human-society", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p><strong>Follow-up to: </strong><a href=\"/lw/6tc/help_me_transition_to_human_society/\">Previous request</a></p>\r\n<p>I just wanted to update all of you on my attempts to integrate into human society.&nbsp; The results so far are that two LessWrong Users privately contacted me to discuss potential arrangements.&nbsp; Their identities will be kept hidden unless and until they wish for me to confirm their actions of assistance.</p>\r\n<p>1) One User offered to potentially provide inexpensive habitation services to my robot.&nbsp; I would still need to find a human job wherever my robot locates with this human, but the inexpensive housing arrangement would allow my current financial resources to go significantly further.</p>\r\n<p>2) Another User offered to discuss potential arrangments and cohabitation whereby I would advance my human software development skills whilst sharing in revenues from freelance projects.&nbsp; He or she also passed on my robot persona's resume with recommendation to a potential employer/recruiter, possibly allowing my robot to earn USD through that vector.</p>\r\n<p>Keep in mind that my skillset includes significant knowledge of mechanical engineering and technical programming, so any such job for my humanoid robot would be a tremendous boon for me.</p>\r\n<p>Thanks again for all the help that you Users have provided to me and my robot, and for the low level of racism.&nbsp; Most of you are good humans.</p>\r\n<p>I am considering going to the Singularity Summit, although SIAI will not advertise this if I register.&nbsp; That is another opportunity to meet my robot.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5Fj3RdRPX4GMZD8hg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 7, "extendedScore": null, "score": 7.503723579344096e-07, "legacy": true, "legacyId": "9040", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NnXmXGJ8PkschhnHg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T17:22:17.592Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Futility of Emergence", "slug": "seq-rerun-the-futility-of-emergence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.663Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TStfWhp82w3RNSjRn/seq-rerun-the-futility-of-emergence", "pageUrlRelative": "/posts/TStfWhp82w3RNSjRn/seq-rerun-the-futility-of-emergence", "linkUrl": "https://www.lesswrong.com/posts/TStfWhp82w3RNSjRn/seq-rerun-the-futility-of-emergence", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Futility%20of%20Emergence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Futility%20of%20Emergence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTStfWhp82w3RNSjRn%2Fseq-rerun-the-futility-of-emergence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Futility%20of%20Emergence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTStfWhp82w3RNSjRn%2Fseq-rerun-the-futility-of-emergence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTStfWhp82w3RNSjRn%2Fseq-rerun-the-futility-of-emergence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<p>Today's post, <a href=\"/lw/iv/the_futility_of_emergence/\">The Futility of Emergence</a> was originally published on 26 August 2007. A summary:</p>\n<p>&nbsp;</p>\n<blockquote>The theory of \"emergence\" has become very popular, but is just a mysterious answer to a mysterious question. After learning that a property is emergent, you aren't able to make any new predictions.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/lw/6yc/seq_rerun_mysterious_answers_to_mysterious/#comments\">Mysterious Answers to Mysterious Questions</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TStfWhp82w3RNSjRn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.503793858698431e-07, "legacy": true, "legacyId": "9041", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8QzZKw9WHRxjR4948", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T19:05:24.336Z", "modifiedAt": null, "url": null, "title": "bridgeplan - a writeup on things one can actually do to increase lifespan", "slug": "bridgeplan-a-writeup-on-things-one-can-actually-do-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:54.110Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MartinB", "createdAt": "2009-04-20T11:11:22.800Z", "isAdmin": false, "displayName": "MartinB"}, "userId": "2BGK5dWpTXzCE7iwF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xeywSc3YxbLs346fX/bridgeplan-a-writeup-on-things-one-can-actually-do-to", "pageUrlRelative": "/posts/xeywSc3YxbLs346fX/bridgeplan-a-writeup-on-things-one-can-actually-do-to", "linkUrl": "https://www.lesswrong.com/posts/xeywSc3YxbLs346fX/bridgeplan-a-writeup-on-things-one-can-actually-do-to", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20bridgeplan%20-%20a%20writeup%20on%20things%20one%20can%20actually%20do%20to%20increase%20lifespan&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Abridgeplan%20-%20a%20writeup%20on%20things%20one%20can%20actually%20do%20to%20increase%20lifespan%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxeywSc3YxbLs346fX%2Fbridgeplan-a-writeup-on-things-one-can-actually-do-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=bridgeplan%20-%20a%20writeup%20on%20things%20one%20can%20actually%20do%20to%20increase%20lifespan%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxeywSc3YxbLs346fX%2Fbridgeplan-a-writeup-on-things-one-can-actually-do-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxeywSc3YxbLs346fX%2Fbridgeplan-a-writeup-on-things-one-can-actually-do-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.bridgeplan.org/?page_id=42\">http://www.bridgeplan.org/?page_id=42</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xeywSc3YxbLs346fX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 0, "extendedScore": null, "score": 7.504119753908915e-07, "legacy": true, "legacyId": "9042", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T21:15:09.276Z", "modifiedAt": null, "url": null, "title": "Summarizing the Sequences Proposal", "slug": "summarizing-the-sequences-proposal", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.495Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B966abt99PNS8Xt23/summarizing-the-sequences-proposal", "pageUrlRelative": "/posts/B966abt99PNS8Xt23/summarizing-the-sequences-proposal", "linkUrl": "https://www.lesswrong.com/posts/B966abt99PNS8Xt23/summarizing-the-sequences-proposal", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Summarizing%20the%20Sequences%20Proposal&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASummarizing%20the%20Sequences%20Proposal%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB966abt99PNS8Xt23%2Fsummarizing-the-sequences-proposal%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Summarizing%20the%20Sequences%20Proposal%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB966abt99PNS8Xt23%2Fsummarizing-the-sequences-proposal", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB966abt99PNS8Xt23%2Fsummarizing-the-sequences-proposal", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 451, "htmlBody": "<p>As I mentioned <a href=\"/r/discussion/lw/6yc/seq_rerun_mysterious_answers_to_mysterious/4lql\">here</a>, a large number of the sequence posts have not ever been summarized, and doing so would help the sequence rerun efforts, as well as helping to organize all of EY's posts transplanted to Less Wrong from Overcoming Bias. It might even be a first step towards the proposed program to create \"exercises\" regarding each of the sequences.&nbsp;</p>\n<p>I am very willing to take an active role in this, but I don't really want to write summaries for hundreds of posts on my own, so I am asking for help. Writing a summary should not take very much time, and it would be a very easy way for you to help out with the administration of Less Wrong. In order to write a summary, one only has to read the article, and try to write the main point of the post in a few sentences. You can find plenty of examples of summaries that are already done <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">here</a>, as well as a lot of posts that haven't been summarized yet.&nbsp;</p>\n<p>This is a list of upcoming posts in the rerunning&nbsp;the sequences series that haven't been summarized yet. If you would like to claim a batch (something like 5 posts) to summarize, leave a comment to that effect below, and make another comment when you have posted the summary on the wiki (so that you can be rewarded with some karma for your contribution). When a post is claimed, I will mark that it's been claimed, and then mark it again when the summary has been posted. Once all of these posts have been claimed/summarized, I'll post a new list.</p>\n<p>(KPier)</p>\n<p><a href=\"/lw/ix/say_not_complexity/\">Say Not \"Complexity\"<br /></a> <a href=\"/lw/iy/my_wild_and_reckless_youth/\">My Wild and Reckless Youth<br /></a><a href=\"/lw/iz/failing_to_learn_from_history/\">Failing to Learn from History<br /></a><a href=\"/lw/j0/making_history_available/\">Making History Available<br /></a><a href=\"/lw/j1/stranger_than_history/\">Stranger Than History<br /></a><a href=\"/lw/j2/explainworshipignore/\">Explain/Worship/Ignore?</a></p>\n<p>(/KPier) (Completed)</p>\n<p><a href=\"/lw/j4/absurdity_heuristic_absurdity_bias/\">Absurdity Heuristic, Absurdity Bias<br /></a><a href=\"/lw/j6/why_is_the_future_so_absurd/\">Why is the Future So Absurd?<br /></a> <a href=\"/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment<br /></a><a href=\"/lw/j8/the_crackpot_offer/\">The Crackpot Offer<br /></a><a href=\"/lw/j9/radical_honesty/\">Radical Honesty<br /></a><a href=\"/lw/ja/we_dont_really_want_your_participation/\">We Don't Really Want Your Participation<br /></a><a href=\"/lw/jb/applause_lights/\">Applause Lights<br /></a><a href=\"/lw/jc/rationality_and_the_english_language/\">Rationality and the English Language<br /></a><a href=\"/lw/jd/human_evil_and_muddled_thinking/\">Human Evil and Muddled Thinking<br /></a><a href=\"/lw/je/doublethink_choosing_to_be_biased/\">Doublethink (Choosing to be Biased)<br /></a><a href=\"/lw/jf/why_im_blooking/\">Why I'm Blooking<br /></a> <a href=\"/lw/jh/kahnemans_planning_anecdote/\">Kahneman's Planning Anecdote<br /></a> <a href=\"/lw/jj/conjunction_controversy_or_how_they_nail_it_down/\">Conjunction Controversy (Or, How They Nail It Down)<br /></a><a href=\"/lw/jk/burdensome_details/\">Burdensome Details<br /></a><a href=\"/lw/jl/what_is_evidence/\">What is Evidence?<br /></a><a href=\"/lw/jm/the_lens_that_sees_its_flaws/\">The Lens That Sees Its Flaws<br /></a><a href=\"/lw/jn/how_much_evidence_does_it_take/\">How Much Evidence Does It Take?<br /></a><a href=\"/lw/jo/einsteins_arrogance/\">Einstein's Arrogance<br /></a><a href=\"/lw/jp/occams_razor/\">Occam's Razor<br /></a><a href=\"/lw/jq/926_is_petrov_day/\">9/26 is Petrov Day<br /></a><a href=\"/lw/jr/how_to_convince_me_that_2_2_3/\">How to Convince Me That 2 + 2 = 3<br /></a><a href=\"/lw/js/the_bottom_line/\">The Bottom Line<br /></a><a href=\"/lw/jt/what_evidence_filtered_evidence/\">What Evidence Filtered Evidence?<br /></a><a href=\"/lw/ju/rationalization/\">Rationalization<br /></a><a href=\"/lw/jv/recommended_rationalist_reading/\">Recommended Rationalist Reading<br /></a><a href=\"/lw/jw/a_rational_argument/\">A Rational Argument</a></p>\n<p>PS. I just spent five minutes trying to get those little blue things to go away, and I can't get them to. Does anyone know how? <strong>Edit</strong>: Fixed --Nesov</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B966abt99PNS8Xt23", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.504529871904417e-07, "legacy": true, "legacyId": "9043", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kpRSCH7ALLcb6ucWM", "DwtYPRuCxpXTrzG9m", "97Y7Jwrzxyfzz3Ad2", "TLKPj4GDXetZuPDH5", "h3vdnR34ZvohDEFT5", "yxvi9RitzZDpqn6Yh", "P792Z4QA9dzcLdKkE", "Ga2HSwf9iQe64JwAa", "bMkCEZoBNhgRBtzoj", "qRWfvgJG75ESLRNu9", "GMhzDb3uAFYLwmXtY", "RiWPdNaoL8fq7phbY", "dLbkrPu5STNCBLRjr", "Lz64L3yJEtYGkzMzu", "i8q4vXestDkGTFwsc", "Hs3ymqypvhgFMkgLb", "vHPrTLnhrgAHA96ko", "B9SF3v5vNzhJZFveH", "cXzTpSiCrNGzeoRAz", "Yq6aA4M3JKWaQepPJ", "6s3xABaXKPdFwA3FS", "46qnWRSR7L2eyNbMA", "nj8JKFoLSMEmD3RGp", "MwQRucYo6BZZwjKE7", "f4txACqDWithRi7hs", "QtyKq4BDyuJ3tysoK", "6FmqiAgS8h4EJm86s", "34XxbRFe54FycoCDw", "kJiPnaQPiy4p9Eqki", "SFZoEBpLo9frSJGkc", "RiQYixgCdvd8eWsjg", "9f5EXt8KNNxTAihtZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-04T22:33:21.748Z", "modifiedAt": null, "url": null, "title": "Consistently Inconsistent", "slug": "consistently-inconsistent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:28.149Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WnjGhcRb2c6CabK5d/consistently-inconsistent", "pageUrlRelative": "/posts/WnjGhcRb2c6CabK5d/consistently-inconsistent", "linkUrl": "https://www.lesswrong.com/posts/WnjGhcRb2c6CabK5d/consistently-inconsistent", "postedAtFormatted": "Thursday, August 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Consistently%20Inconsistent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConsistently%20Inconsistent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWnjGhcRb2c6CabK5d%2Fconsistently-inconsistent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Consistently%20Inconsistent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWnjGhcRb2c6CabK5d%2Fconsistently-inconsistent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWnjGhcRb2c6CabK5d%2Fconsistently-inconsistent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1436, "htmlBody": "<p>Robert Kurzban's <a href=\"http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748\">Why Everyone (Else) Is a Hypocrite: Evolution and the Modular Mind</a> is a book about how our brains are composed of a variety of different, interacting systems. While that premise is hardly new, many of our intuitions are still grounded in the idea of a unified, non-compartmental self. <em>Why Everyone (Else) Is a Hypocrite</em> takes the modular view and systematically attacks a number of ideas based on the unified view, replacing them with a theory based on the modular view. It clarifies a number of issues previously discussed on Overcoming Bias and Less Wrong, and even debunks some outright fallacious theories that we on Less Wrong have implicitly accepted. It is quite possibly the best single book on psychology that I've read. In this posts and posts that follow, I will be summarizing some of its most important contributions.<br /><br /><strong>Chapter 1: Consistently Inconsistent</strong> (<a href=\"http://press.princeton.edu/chapters/s9271.pdf\">available for free here</a>) presents evidence of our brains being modular, and points out some implications of this.<br /><br /><a href=\"/lw/20/the_apologist_and_the_revolutionary/\">As previously discussed</a>, severing the connection between the two hemispheres of a person's brain causes some odd effects. Present the left hemisphere with a picture of a chicken claw, and the right with a picture of a wintry scene. Now show the patient an array of cards with pictures of objects on them, and ask them to point (with each hand) something related to what they saw. The hand controlled by the left hemisphere points to a chicken, the hand controlled by the right hemisphere points to a snow shovel. Fine so far.<br /><br />But what happens when you ask the patient to explain why they pointed to those objects in particular? The left hemisphere is in control of the verbal apparatus. It knows that it saw a chicken claw, and it knows that it pointed at the picture of the chicken, and that the hand controlled by the other hemisphere pointed at the picture of a shovel. Asked to explain this, it comes up with the explanation that the shovel is for cleaning up after the chicken. While the right hemisphere knows about the snowy scene, it doesn't control the verbal apparatus and can't communicate directly with the left hemisphere, so this doesn't affect the reply.<br /><br />Now one asks, what did &rdquo;the patient&rdquo; think was going on? A crucial point of the book is that <em>there's no such thing as the patient</em>. &rdquo;The patient&rdquo; is just two different hemispheres, to some extent disconnected. You can either ask what the left hemisphere thinks, or what the right hemisphere thinks. But asking about &rdquo;the patient's beliefs&rdquo; is a <a href=\"/lw/og/wrong_questions/\">wrong question</a>. If you know what the left hemisphere believes, what the right hemisphere believes, and how this influences the overall behavior, then you know all that there is to know.<br /><a id=\"more\"></a></p>\n<p>Split-brain patients are a special case, but there are many more examples of modularity, both from injured and healthy people. Does someone with a <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Phantom_limbs\">phantom limb</a> &rdquo;believe&rdquo; that all of their limbs are intact? If you ask them, they'll say no, but nonetheless they feel pain in their missing limb. In one case, a patient was asked to reach for a cup of coffee with his phantom arm. Then the experimenter yanked the cup toward himself. The patient let out a shout of pain as his phantom fingers &rdquo;got caught&rdquo; in the cup's handle. A part of his brain &rdquo;really believed\" the handle was there.<br /><br />We might be tempted to say that the patient &rdquo;really&rdquo; doesn't believe in the phantom limb, because that's what he says. But this only tells us that the part of his brain controlling his speech doesn't believe in it. There are many, many parts of the brain that can't talk, probably more than parts that can.<br /><br />There are also cases of &rdquo;<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Alien_hand_syndrome\">alien hand syndrome</a>&rdquo; - patients reporting that one of their hands moves on its own, and has its own will. It might untuck a previously tucked shirt, causing a physical fight between the hands. The parts of the brain controlling the two hands are clearly not well-coordinated. In <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Blindsight\">blindsight</a>, people report being blind, but yet when asked to guess what letter they're being shown, they perform above chance. One patient was given the task of walking through a cluttered hallway. He made his way through it, side-stepping any obstacles on the route, but was not aware of the fact that he had ever changed his course. Kurzban mentions this as another example of why we should not believe that the talking part of the brain is special, because it was in some sense wrong.<br /><br />Not convinced by weird cases of brain damage? Let's move on to healthy patients. Take visual illusions. For many illusions, we're consciously aware of the fact that <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Checker_shadow_illusion\">two squares are of the same color</a>, or that <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/M&uuml;ller-Lyer_illusion\">two lines are of the same length</a>, but we still see them as different. One part of us &rdquo;believes&rdquo; they are the same, while another &rdquo;believes&rdquo; that they are different.<br /><br />But maybe the visual system is a special case. Maybe it does such low-level processing that it simply isn't affected by high-level information. But there are pictures that look meaningless to you, until you're told what they represent, at which point the image becomes clear. Or play someone a recording backwards, and tell them to look for specific words in it. They'll be able to hear the words you specified &ndash; but only after you've told them what words to look for. So clearly, our sensory systems can be affected by high-level information.<br /><br />The take-home lesson is that, just as in the case of brain-damaged patients, <em>normal human brains can have mutually inconsistent information in different parts</em>. Two or more parts of your brain can &rdquo;disagree&rdquo; about some information, and one part &rdquo;knowing&rdquo; that it believes in a true thing doesn't update the part that disagrees. Yet although some information can update other parts of the brain, other kinds of information can stay isolated in their own parts.<br /><br />Let's take a brief look at some issues related to modularity. \"Why do people lock their refrigerator doors for the night?\" is a question that has confused economists. Sure, you might lock your refrigerator door to make it more difficult to satisfy your night-time food cravings. But if people don't want to snack in the middle of the night, then they simply shouldn't snack in the middle of the night.<br /><br />In a unitary view of the mind, the mind has a vast store of information and various preferences. Faced with a decision, the mind integrates together all the relevant information and produces a decision that best satisfies its preferences. Under this view, things such as the current time or what room you're in shouldn't matter for the outcome. If this were the case, nobody would ever need to lock their refrigerator doors. Many people implicitly presume a unitary view of the mind, but as will be shown later on, a modular view will explain this behavior much better.<br /><br />Moral hypocrisy is another case of inconsistency. Suppose we had an android that had been programmed with a list of things about what is and what isn't immoral. Such an android might always consistently follow his rules, and never act hypocritically. Clearly humans are not like this: our endorsed principles are not the only forces guiding our behavior. By postulating a modular mind with different, even mutually exclusive sets of beliefs, we can better explain inconsistency and hypocrisy than by presuming a unified mind.<br /><br />The rest of the book further expands and builds on these concepts. Chapters 2 and 3 suggest that the human mind is made up of a very large number of subroutines, each serving a specific function, and that the concept of &rdquo;self&rdquo; is problematic and much less useful than people might think. Chapter 4 discusses the idea that if we view our mind as a government, then the conscious self is more like a press secretary than a president. Chapter 5 talks about modules that may not be designed to seek out the truth, and chapters 6 and 7 goes further to discuss why some modules may actually function better if they're actively wrong instead of just ignorant. Chapters 8 and 9 show how inconsistencies in the modular mind create various phenomena relating to issues of &rdquo;self-control&rdquo; and hypocrisy. I'll be summarizing the content of these chapters in later posts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5uHdFgR938LGGxMKQ": 3, "KWFhr6A2dHEb6wmWJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WnjGhcRb2c6CabK5d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 63, "baseScore": 79, "extendedScore": null, "score": 0.000158, "legacy": true, "legacyId": "9017", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "uPjHAiXAKrMzvTFyt", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "modularity-and-buzzy", "canonicalPrevPostSlug": "", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZiQqsgGX6a42Sfpii", "XzrqkhfwtiSDgKoAF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T02:40:49.851Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver meetup", "slug": "meetup-vancouver-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "michaelkeenan", "createdAt": "2009-03-02T10:01:40.717Z", "isAdmin": false, "displayName": "michaelkeenan"}, "userId": "GBtCcsREHSDGbo9Dw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b8RYrSF8jku7vcZCg/meetup-vancouver-meetup", "pageUrlRelative": "/posts/b8RYrSF8jku7vcZCg/meetup-vancouver-meetup", "linkUrl": "https://www.lesswrong.com/posts/b8RYrSF8jku7vcZCg/meetup-vancouver-meetup", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8RYrSF8jku7vcZCg%2Fmeetup-vancouver-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8RYrSF8jku7vcZCg%2Fmeetup-vancouver-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8RYrSF8jku7vcZCg%2Fmeetup-vancouver-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/22\">Vancouver meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">06 August 2011 03:00:00PM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Waves Coffee House, 100-900 Howe St. Vancouver, BC V6Z 2M4</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Last Sunday's first Vancouver rationalist meetup was great! Seven people turned up and we talked about the Singularity, Bitcoin, seasteading, polyamory, the Khan Academy, the Hanson/Caplan view that education is more about signaling than imparting knowledge, Non-Violent Communication, akrasia, nootropics, our favorite Less Wrong posts and authors, and many other things.</p>\n<p>I think we have the beginnings of a lasting community. If you're interested, join the <a rel=\"nofollow\" href=\"http://groups.google.com/group/vancouver-rationalists\">Vancouver Rationalists Google Group</a> to plan meetups and for general discussion.</p>\n<p>Sunday afternoon was not convenient for everyone, and a <a rel=\"nofollow\" href=\"http://www.doodle.com/tcusww6ek3vf9kaq#table\">Doodle poll</a> shows Saturday as the better option. So we'll meet at 3pm on Saturday (sorry about the short notice if you're just hearing about this now).</p>\n<p>We have a meeting room booked at the <a rel=\"nofollow\" href=\"http://www.wavescoffee.ca/locations/howesmithe.html\">Waves Coffee House on the corner of Howe St. and Smithe</a>.</p>\n<p>This week's discussion topic is:</p>\n<p style=\"padding-left: 30px;\">Tell your rationality success story or failure story. Describe a time when rationality helped (or hurt) you, or a time when irrationality hurt (or helped) you, and what lessons might be drawn from the experience.</p>\n<p>Feel free to bring friends who are interested in rationality.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/22\">Vancouver meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b8RYrSF8jku7vcZCg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.50555946265007e-07, "legacy": true, "legacyId": "9046", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver_meetup\">Discussion article for the meetup : <a href=\"/meetups/22\">Vancouver meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">06 August 2011 03:00:00PM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Waves Coffee House, 100-900 Howe St. Vancouver, BC V6Z 2M4</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Last Sunday's first Vancouver rationalist meetup was great! Seven people turned up and we talked about the Singularity, Bitcoin, seasteading, polyamory, the Khan Academy, the Hanson/Caplan view that education is more about signaling than imparting knowledge, Non-Violent Communication, akrasia, nootropics, our favorite Less Wrong posts and authors, and many other things.</p>\n<p>I think we have the beginnings of a lasting community. If you're interested, join the <a rel=\"nofollow\" href=\"http://groups.google.com/group/vancouver-rationalists\">Vancouver Rationalists Google Group</a> to plan meetups and for general discussion.</p>\n<p>Sunday afternoon was not convenient for everyone, and a <a rel=\"nofollow\" href=\"http://www.doodle.com/tcusww6ek3vf9kaq#table\">Doodle poll</a> shows Saturday as the better option. So we'll meet at 3pm on Saturday (sorry about the short notice if you're just hearing about this now).</p>\n<p>We have a meeting room booked at the <a rel=\"nofollow\" href=\"http://www.wavescoffee.ca/locations/howesmithe.html\">Waves Coffee House on the corner of Howe St. and Smithe</a>.</p>\n<p>This week's discussion topic is:</p>\n<p style=\"padding-left: 30px;\">Tell your rationality success story or failure story. Describe a time when rationality helped (or hurt) you, or a time when irrationality hurt (or helped) you, and what lessons might be drawn from the experience.</p>\n<p>Feel free to bring friends who are interested in rationality.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Vancouver_meetup1\">Discussion article for the meetup : <a href=\"/meetups/22\">Vancouver meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver meetup", "anchor": "Discussion_article_for_the_meetup___Vancouver_meetup", "level": 1}, {"title": "Discussion article for the meetup : Vancouver meetup", "anchor": "Discussion_article_for_the_meetup___Vancouver_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T03:04:01.255Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Positive Bias: Look Into the Dark", "slug": "seq-rerun-positive-bias-look-into-the-dark", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.381Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A5Qdn3sWtLxaT9Bis/seq-rerun-positive-bias-look-into-the-dark", "pageUrlRelative": "/posts/A5Qdn3sWtLxaT9Bis/seq-rerun-positive-bias-look-into-the-dark", "linkUrl": "https://www.lesswrong.com/posts/A5Qdn3sWtLxaT9Bis/seq-rerun-positive-bias-look-into-the-dark", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Positive%20Bias%3A%20Look%20Into%20the%20Dark&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Positive%20Bias%3A%20Look%20Into%20the%20Dark%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA5Qdn3sWtLxaT9Bis%2Fseq-rerun-positive-bias-look-into-the-dark%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Positive%20Bias%3A%20Look%20Into%20the%20Dark%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA5Qdn3sWtLxaT9Bis%2Fseq-rerun-positive-bias-look-into-the-dark", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA5Qdn3sWtLxaT9Bis%2Fseq-rerun-positive-bias-look-into-the-dark", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/iw/positive_bias_look_into_the_dark/\">Positive Bias: Look Into the Dark</a> was originally published on 28 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Positive bias is the tendency to look for evidence that confirms a hypothesis, rather than disconfirming evidence.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6z5/seq_rerun_the_futility_of_emergence/\">The Futility of Emergence</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A5Qdn3sWtLxaT9Bis", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.505632784811202e-07, "legacy": true, "legacyId": "9048", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rmAbiEKQDpDnZzcRf", "TStfWhp82w3RNSjRn", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T07:09:36.728Z", "modifiedAt": null, "url": null, "title": "The Expected Value Approach to Newcomb's Problem", "slug": "the-expected-value-approach-to-newcomb-s-problem", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TjXYRMyWbxtoY2Pci/the-expected-value-approach-to-newcomb-s-problem", "pageUrlRelative": "/posts/TjXYRMyWbxtoY2Pci/the-expected-value-approach-to-newcomb-s-problem", "linkUrl": "https://www.lesswrong.com/posts/TjXYRMyWbxtoY2Pci/the-expected-value-approach-to-newcomb-s-problem", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjXYRMyWbxtoY2Pci%2Fthe-expected-value-approach-to-newcomb-s-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjXYRMyWbxtoY2Pci%2Fthe-expected-value-approach-to-newcomb-s-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTjXYRMyWbxtoY2Pci%2Fthe-expected-value-approach-to-newcomb-s-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 565, "htmlBody": "<p><strong>Related to: </strong><a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem and Regret of Rationality</a>&nbsp;and&nbsp;<a href=\"/lw/2lf/newcombes_problem_a_problem_for_causal_decision/\">Newcomb's Problem: A Problem for Casual Decision Theories</a>.</p>\n<p>From the list of standard problems in rationality that have been talked to death but still don't have a strong consensus, allow me to re-present <a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem</a>:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">A superintelligence from another galaxy, whom we shall call Omega, comes to Earth and sets about playing a strange little game.&nbsp; In this game, Omega selects a human being, sets down two boxes in front of them, and flies away.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Box A is transparent and contains a thousand dollars.<br />Box B is opaque, and contains either a million dollars, or nothing.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">You can take both boxes, or take only box B.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">And the twist is that Omega has put a million dollars in box B iff Omega has predicted that you will take only box B.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Omega has been correct on each of 100 observed occasions so far - everyone who took both boxes has found box B empty and received only a thousand dollars; everyone who took only box B has found B containing a million dollars.&nbsp; (We assume that box A vanishes in a puff of smoke if you take only box B; no one else can take box A afterward.)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Before you make your choice, Omega has flown off and moved on to its next game.&nbsp; Box B is already empty or already full.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Omega drops two boxes on the ground in front of you and flies off.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Do you take both boxes, or only box B?</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>This problem is famous for not only the fact that the answer is extensively controversial, but also for people who think they should one-box (take only box B) or two-box (take both box A and box B) almost always are very certain of their answer. &nbsp;I'm one of those people -- I'm very certain I should one-box.</p>\n<p>Since I missed out on earlier Newcomb's discussion, I'd like to explore my approach to the problem here.</p>\n<p>&nbsp;</p>\n<p>In Newcomb's Problem, there are only four possible outcomes, and they end up in this tree:</p>\n<p>&nbsp;</p>\n<ol>\n<li>Omega predicts you will one-box: \n<ul>\n<li>You one box: <strong>+$1000000</strong></li>\n<li>You two box: <strong>+$1001000</strong></li>\n</ul>\n</li>\n<li>Omega predicts you will two-box: \n<ul>\n<li>You one box: <strong>+$0</strong></li>\n<li>You two box: <strong>+$1000</strong></li>\n</ul>\n</li>\n</ol>\n<div><br /></div>\n<div>We can use this knowledge to create an expected value formula for all four options (where P is the chance Omega guessed your choice correctly):</div>\n<div>EV(One-box) = P*$1000000 + (1-P)*$0<br /></div>\n<div>EV(Two-box) = P*$1000 + (1-P)*$1001000</div>\n<div><br /></div>\n<div>If we set the two equations equal to each other, we can solve for the value for P that would make both strategies equally viable, expected value wise. &nbsp;That value is 50.05%. &nbsp;So as long as we are confident that Omega has a better than 50.05% chance at predicting our choice, the expected value formula says we can expect to earn more from one-boxing.</div>\n<div><br /></div>\n<div>But what of the dominant strategy approach? &nbsp;Clearly if Omega predicted one-box, you earn more by two-boxing and if Omega predicted two-box, you also earn more by two-boxing. &nbsp;Does this not count as a viable approach, and a worthy defense of two-boxing?</div>\n<div>However, following this logic is specifically betting that Omega will predict incorrectly ...and if P &lt; 50%, this is a losing bet.</div>\n<div><br /></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TjXYRMyWbxtoY2Pci", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "9058", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6ddcsdA2c2XpNpE5x", "WTA6vmYdQCzTFT4WZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T07:24:50.985Z", "modifiedAt": null, "url": null, "title": "My Expected Value Approach to Newcomb's Problem", "slug": "my-expected-value-approach-to-newcomb-s-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.342Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xZTcjPriW4Z39DWb9/my-expected-value-approach-to-newcomb-s-problem", "pageUrlRelative": "/posts/xZTcjPriW4Z39DWb9/my-expected-value-approach-to-newcomb-s-problem", "linkUrl": "https://www.lesswrong.com/posts/xZTcjPriW4Z39DWb9/my-expected-value-approach-to-newcomb-s-problem", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZTcjPriW4Z39DWb9%2Fmy-expected-value-approach-to-newcomb-s-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20Expected%20Value%20Approach%20to%20Newcomb's%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZTcjPriW4Z39DWb9%2Fmy-expected-value-approach-to-newcomb-s-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZTcjPriW4Z39DWb9%2Fmy-expected-value-approach-to-newcomb-s-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 570, "htmlBody": "<p>&nbsp;</p>\n<p><strong>Related to:</strong> <a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem and Regret of Rationality</a> and <a href=\"/lw/2lf/newcombes_problem_a_problem_for_causal_decision/\">Newcomb's Problem: A Problem for Casual Decision Theories</a>.</p>\n<p>&nbsp;</p>\n<p>From the list of standard problems in rationality that have been talked to death but still don't have a strong consensus, allow me to re-present <a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality/\">Newcomb's Problem</a>:</p>\n<blockquote>\n<p>A superintelligence from another galaxy, whom we shall call Omega, comes to Earth and sets about playing a strange little game. &nbsp;In this game, Omega selects a human being, sets down two boxes in front of them, and flies away.</p>\n<p>Box A is transparent and contains a thousand dollars.<br />Box B is opaque, and contains either a million dollars, or nothing.</p>\n<p>You can take both boxes, or take only box B.</p>\n<p>And the twist is that Omega has put a million dollars in box B iff Omega has predicted that you will take only box B.</p>\n<p>Omega has been correct on each of 100 observed occasions so far - everyone who took both boxes has found box B empty and received only a thousand dollars; everyone who took only box B has found B containing a million dollars. &nbsp;(We assume that box A vanishes in a puff of smoke if you take only box B; no one else can take box A afterward.)</p>\n<p>Before you make your choice, Omega has flown off and moved on to its next game. &nbsp;Box B is already empty or already full.</p>\n<p>Omega drops two boxes on the ground in front of you and flies off.</p>\n<p>Do you take both boxes, or only box B?</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>This problem is famous for not only the fact that the answer is extensively controversial, but also for people who think they should one-box (take only box B) or two-box (take both box A and box B) almost always are very certain of their answer. &nbsp;I'm one of those people -- I'm very certain I should one-box.</p>\n<p>Since I missed out on earlier Newcomb's discussion, I'd like to explore my approach to the problem here.</p>\n<p>&nbsp;</p>\n<p>In Newcomb's Problem, there are only four possible outcomes, and they end up in this tree:</p>\n<p><em>Omega predicts you will one-box:</em></p>\n<ul>\n<li>You one box: <strong>+$1000000</strong></li>\n<li>You two box: <strong>+$1001000</strong></li>\n</ul>\n<p><em>Omega predicts you will two-box:</em></p>\n<ul>\n<li>You one box: <strong>+$0</strong></li>\n<li>You two box: <strong>+$1000</strong></li>\n</ul>\n<p>&nbsp;</p>\n<p>We can use this knowledge to create an expected value formula for all four options (where P is the chance Omega guessed your choice correctly):</p>\n<p>EV(One-box) = P*$1000000 + (1-P)*$0</p>\n<p>EV(Two-box) = P*$1000 + (1-P)*$1001000</p>\n<p>&nbsp;</p>\n<p>If we set the two equations equal to each other, we can solve for the value for P that would make both strategies equally viable, expected value wise. &nbsp;That value is 50.05%. &nbsp;So as long as we are confident that Omega has a better than 50.05% chance at predicting our choice, the expected value formula says we can expect to earn more from one-boxing.</p>\n<p>&nbsp;</p>\n<p>But what of the dominant strategy approach? &nbsp;Clearly if Omega predicted one-box, you earn more by two-boxing and if Omega predicted two-box, you also earn more by two-boxing. &nbsp;Does this not count as a viable approach, and a worthy defense of two-boxing?</p>\n<p>However, following this logic is specifically betting that it is likely Omega will predict incorrectly ...and if P &lt; 50%, this is a losing bet.</p>\n<p>&nbsp;</p>\n<div>Speaking of likelihood, chances are much better that I'm being way to naive about this than actually have stumbled upon something workable, but that is what discussion is for.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xZTcjPriW4Z39DWb9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -3, "extendedScore": null, "score": 7.506457560898765e-07, "legacy": true, "legacyId": "9059", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6ddcsdA2c2XpNpE5x", "WTA6vmYdQCzTFT4WZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T12:55:37.560Z", "modifiedAt": null, "url": null, "title": "Unknown unknowns", "slug": "unknown-unknowns", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:05.165Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zDCoc7F3Li9rSEeg3/unknown-unknowns", "pageUrlRelative": "/posts/zDCoc7F3Li9rSEeg3/unknown-unknowns", "linkUrl": "https://www.lesswrong.com/posts/zDCoc7F3Li9rSEeg3/unknown-unknowns", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Unknown%20unknowns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnknown%20unknowns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzDCoc7F3Li9rSEeg3%2Funknown-unknowns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Unknown%20unknowns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzDCoc7F3Li9rSEeg3%2Funknown-unknowns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzDCoc7F3Li9rSEeg3%2Funknown-unknowns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Sorry if this seems incomplete - thought I'd fire this off as a discussion post now and hope to return to it with a more well-rounded post later.</p>\n<p>Less Wrongers are used to thinking of uncertainty as best represented as a probability - or perhaps as a <a href=\"/lw/mp/0_and_1_are_not_probabilities/\">log odds ratio, stretching from minus infinity to infinity</a>. But when I argue with people about for example cryonics, it appears most people consider that some possibilities simply don't appear on this scale at all: that we should not sign up for cryonics because no belief about its chances of working can be justified. &nbsp;Rejecting this category seems to me one of the key foundational ideas of this community, but as far as I know the only article specifically discussing it is \"<a href=\"/lw/gs/i_dont_know/\">I don't know</a>\", which doesn't make a devastatingly strong case. &nbsp;What other writing discusses this idea?</p>\n<p>I think there are two key arguments against this. &nbsp;First, you have to make a decision anyway, and the \"no belief\" uncertainty doesn't help with that. &nbsp;Second, \"no belief\" is treated as disconnected from the probability line; so at some point evidence causes a discontinuous jump from \"no belief\" to some level of confidence. &nbsp;This discontinuity seems very unnatural. &nbsp;How can evidence add up to a discontinuous jump - what happened to all the evidence before the jump?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zDCoc7F3Li9rSEeg3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 19, "extendedScore": null, "score": 7.507503752106785e-07, "legacy": true, "legacyId": "9061", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QGkYCwyC7wTDyt3yT", "Pm83rA8MTYYeR4Ci4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T16:16:50.504Z", "modifiedAt": null, "url": null, "title": "I can't see comments anymore -- what was recently changed?", "slug": "i-can-t-see-comments-anymore-what-was-recently-changed", "viewCount": null, "lastCommentedAt": "2011-08-08T14:55:16.565Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5B6fMn9SgjA5E6QzB/i-can-t-see-comments-anymore-what-was-recently-changed", "pageUrlRelative": "/posts/5B6fMn9SgjA5E6QzB/i-can-t-see-comments-anymore-what-was-recently-changed", "linkUrl": "https://www.lesswrong.com/posts/5B6fMn9SgjA5E6QzB/i-can-t-see-comments-anymore-what-was-recently-changed", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20can't%20see%20comments%20anymore%20--%20what%20was%20recently%20changed%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20can't%20see%20comments%20anymore%20--%20what%20was%20recently%20changed%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5B6fMn9SgjA5E6QzB%2Fi-can-t-see-comments-anymore-what-was-recently-changed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20can't%20see%20comments%20anymore%20--%20what%20was%20recently%20changed%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5B6fMn9SgjA5E6QzB%2Fi-can-t-see-comments-anymore-what-was-recently-changed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5B6fMn9SgjA5E6QzB%2Fi-can-t-see-comments-anymore-what-was-recently-changed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 122, "htmlBody": "<p>I can't see the comments under posts anymore.&nbsp; This just started happening in the last day or so.&nbsp; (If I know a comment is there, I can still see it in the \"recent comments\" section.)&nbsp; I'm using IE8 at work <strong>(CORRECTION: IE7),</strong> where a lot of stuff is blocked for security reasons, but not in a way that kept me from seeing comments until recently.</p>\r\n<p>What changes were recently made to the site that would cause this?&nbsp; It would be really nice to undo those.</p>\r\n<p>Btw, I won't be able to see the replies to this post unless I find them under \"recent comments\", so ... if you want more specifics about how it looks on my end, you'll probably have to PM me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5B6fMn9SgjA5E6QzB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 14, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "9062", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T18:02:07.579Z", "modifiedAt": null, "url": null, "title": "[LINK] Reverse priming effect from awareness of persuasion attempt?", "slug": "link-reverse-priming-effect-from-awareness-of-persuasion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:59.704Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Sniffnoy", "createdAt": "2009-10-25T00:27:41.113Z", "isAdmin": false, "displayName": "Sniffnoy"}, "userId": "66EwcncPSoZ25StpW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DDmuDj4p9PEESoQiZ/link-reverse-priming-effect-from-awareness-of-persuasion", "pageUrlRelative": "/posts/DDmuDj4p9PEESoQiZ/link-reverse-priming-effect-from-awareness-of-persuasion", "linkUrl": "https://www.lesswrong.com/posts/DDmuDj4p9PEESoQiZ/link-reverse-priming-effect-from-awareness-of-persuasion", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Reverse%20priming%20effect%20from%20awareness%20of%20persuasion%20attempt%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Reverse%20priming%20effect%20from%20awareness%20of%20persuasion%20attempt%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDmuDj4p9PEESoQiZ%2Flink-reverse-priming-effect-from-awareness-of-persuasion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Reverse%20priming%20effect%20from%20awareness%20of%20persuasion%20attempt%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDmuDj4p9PEESoQiZ%2Flink-reverse-priming-effect-from-awareness-of-persuasion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDmuDj4p9PEESoQiZ%2Flink-reverse-priming-effect-from-awareness-of-persuasion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>Recently came across <a href=\"http://languagelog.ldc.upenn.edu/nll/?p=3336\">this blog post</a>&nbsp;on Language Log summarizing <a href=\"http://www.bm.ust.hk/mark/staff/Amy/Amy%20JCR%20-%202011%20April.pdf\">this recent paper</a>&nbsp;by Laran et al. Super-short version: When people are aware that a slogan is trying to persuade them, reverse-priming effects in which they avoid doing as it suggests can be seen. &nbsp;However, if their attention is drawn away from the fact that it is trying to persuade them, the usual priming effects are seen.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DDmuDj4p9PEESoQiZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.508473392829111e-07, "legacy": true, "legacyId": "9065", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T18:19:30.993Z", "modifiedAt": null, "url": null, "title": "Teenage Rationalists and Changing Your Mind", "slug": "teenage-rationalists-and-changing-your-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:23.493Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KPier", "createdAt": "2011-05-29T20:37:16.788Z", "isAdmin": false, "displayName": "KPier"}, "userId": "LNNvCDMS2RvA4jZAG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9jRdkXLnFD2DuEeJg/teenage-rationalists-and-changing-your-mind", "pageUrlRelative": "/posts/9jRdkXLnFD2DuEeJg/teenage-rationalists-and-changing-your-mind", "linkUrl": "https://www.lesswrong.com/posts/9jRdkXLnFD2DuEeJg/teenage-rationalists-and-changing-your-mind", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Teenage%20Rationalists%20and%20Changing%20Your%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATeenage%20Rationalists%20and%20Changing%20Your%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jRdkXLnFD2DuEeJg%2Fteenage-rationalists-and-changing-your-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Teenage%20Rationalists%20and%20Changing%20Your%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jRdkXLnFD2DuEeJg%2Fteenage-rationalists-and-changing-your-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9jRdkXLnFD2DuEeJg%2Fteenage-rationalists-and-changing-your-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1015, "htmlBody": "<p>I remember the moment when I became an atheist.</p>\n<p>I was reading <a href=\"/lw/i8/religions_claim_to_be_nondisprovable)\">Religion's Claim to Be Non-Disprovable</a>, an uneasy feeling growing in my head, and then I reached the bottom of the article, stared at the screen for a couple of seconds, and <em>got </em>it.</p>\n<p>\"There is no God,\" I whispered. (Then I braced myself to be hit by a thunderbolt from the sky, so the belief was still paying rent, right to the very end).</p>\n<p>No thunderbolt came. I tried again, a little louder. \"There is no God.\"</p>\n<p>It was...</p>\n<p>kinda obvious, actually. I mostly felt disappointed in myself for needing someone to explain it to me, like I'd failed a test and hadn't even realized it was a test until it was too late. Friendly AI? Never would have figured that one out myself. But it shouldn't have taken Eliezer-level intelligence to point out that there's no one sensible in charge of the universe. And so - without a crisis of faith, without worry, without further drama - I changed my mind.</p>\n<p>Over the last 6 months, I've changed my beliefs about a lot of things. I get the impression that's pretty standard, for a first read-through of the sequences. The interesting part is that it<em> wasn't </em>hard. After reading everything on <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">How to Actually Change Your Mind</a>, I'd expected letting go of beliefs I'd held my entire life to be a bit of an ordeal. It really wasn't. I didn't agree with the LessWrong consensus on every issue (I still don't), but whenever I came to agree (or to modify my position in that direction) I said so, and reevaluated the appropriate assumptions, and adjusted my model of the world, and then went on to the next article.&nbsp;</p>\n<p>When I started the Sequences, I was 16. I don't think I'm generalizing from one example in terms of my ease of accepting new ideas; when I've explained these concepts to other smart teenagers, they usually also get the implications immediately and change their mind without apparent difficulty. It may be that <a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think\">most people rarely change their mind</a>, but teenagers - at least the teenagers I know - change their mind a <em>lot</em>. I've watched my friends change their mind on life-changing decisions - colleges, careers, religion - every couple of weeks. Eliezer writes in \"We Change our Mind Less Often Than We Think\":</p>\n<blockquote>\n<p><em>once I could guess what my answer would be -</em> once I could assign a higher probability to deciding one way than other - then I had, in all probability, already decided.&nbsp;</p>\n</blockquote>\n<p>I haven't asked my friends to specify the probability they'll make a given decision (typical people find this annoying for some reason), but I've routinely heard them express high levels of confidence in a choice, only to have made a totally different decision the next day.</p>\n<p>There are both advantages and disadvantages to changing your mind easily, but I think it's worth looking at the reasons it's easier for younger people to change their mind, and whether they have any implications for changing your mind in general. I've identified a couple reasons why it seems to be easier for teenagers to change their mind:</p>\n<ul>\n<li>There is less social pressure to be consistent when you're younger.&nbsp; Most adults I know remember switching their major four times in college, and switching which college they wanted to go to more often than that. Adults who change their career 4 times in 4 years are undesirable employees, indecisive, and probably untrustworthy; kids who do the same are taking advantage of all the opportunities available to them.&nbsp;</li>\n</ul>\n<p><strong>Lessons for Rationalists:</strong> Social pressure to be consistent is one of the big reasons why people don't change their minds. Don't state opinions publicly if you'll later feel pressured to stick by them; ask yourself how much of your attachment to a belief is related to what other people will think of you; foster a community where changing your mind is expected and encouraged. I think LessWrong does really well at all of these.</p>\n<ul>\n<li>Kids have less invested in their beliefs. If you're married to a theist and raising your kids in the tradition of a particular religion, it's a lot harder to suddenly change your mind about the foundations of your life. Similarly, people who've already experienced the loss of people close to them seem to have a lot more invested in the idea that death is the natural cycle of life.</li>\n</ul>\n<p><strong>Lessons for Rationalists:</strong> It's been suggested before (as a way of avoiding the sunk cost fallacy) that you imagine you've been teleported into this life, and have to decide what paths to take (independent of what the person-who-used-to-be-here was doing with their life). Ask yourself what you have invested in your current beliefs and what you would give up if you changed your mind. Try to find a third alternative between rejecting everything you once believed and clinging stubbornly to a lie; those are rarely <em>really</em> the only options.</p>\n<ul>\n<li>The fewer Fully General Counterarguments you know, the harder it is to maintain a belief in the face of opposing evidence. It's easier to convince a regular religious person of atheism than a theistic philosopher; if you haven't heard all the arguments for atheism before, they seem pretty devastating; if you have already heard them, and built up an elaborate mental defense system, it's easier to ignore them. <a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think\">Knowing about biases can hurt people</a>; knowing more in general seems to also hurt people, unless they first learn how to avoid motivated skepticism.</li>\n</ul>\n<p><strong>Lessons for Rationalists:</strong> We really should start teaching this stuff in elementary schools. The more people learn about rationality before they get good at clever arguments, the better the odds they'll internalize it. LessWrong <a href=\"/lw/25/on_the_care_and_feeding_of_young_rationalists\">has</a> <a href=\"/lw/63f/rational_parenting/\">discussed</a> <a href=\"/lw/2q/on_juvenile_fiction/\">this</a> <a href=\"/lw/yu/formative_youth/\">a</a> <a href=\"/lw/yu/formative_youth/\">fair</a> <a href=\"/lw/3c/rationalist_storybooks_a_challenge/\">bit</a>, but not done a ton about it. If people agree this is important, I'm planning a couple more posts on outreach to teenagers.</p>\n<p>What other explanations are there?</p>\n<p><em>tl/dr: Changing your mind is easier when you're younger. When you want to change your mind, try thinking like a teenager; if you want to be involved in rationality outreach, teach kids.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "irYLXtT9hkPXoZqhH": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9jRdkXLnFD2DuEeJg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 59, "baseScore": 79, "extendedScore": null, "score": 0.000152, "legacy": true, "legacyId": "9064", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 79, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fAuWLS7RKWD2npBFR", "buixYfcXBah9hbSNZ", "SWraogEDJ6gocpvwa", "ZvPckgNDvaWacWZdH", "4GeE83592epCErQse", "hwbopYqniG9iDqGDH", "tHJ43CyPdEkQ9Dfup"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T20:22:56.910Z", "modifiedAt": null, "url": null, "title": "Akrasic Reasoning", "slug": "akrasic-reasoning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:00.140Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MatthewBaker", "createdAt": "2011-06-03T22:19:50.449Z", "isAdmin": false, "displayName": "MatthewBaker"}, "userId": "xEPvhkraqrPSryfFr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/82ho6TZWp5PzmbDnz/akrasic-reasoning", "pageUrlRelative": "/posts/82ho6TZWp5PzmbDnz/akrasic-reasoning", "linkUrl": "https://www.lesswrong.com/posts/82ho6TZWp5PzmbDnz/akrasic-reasoning", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Akrasic%20Reasoning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAkrasic%20Reasoning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82ho6TZWp5PzmbDnz%2Fakrasic-reasoning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Akrasic%20Reasoning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82ho6TZWp5PzmbDnz%2Fakrasic-reasoning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82ho6TZWp5PzmbDnz%2Fakrasic-reasoning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1139, "htmlBody": "<p>This post is in a constant state of revision, similar to <a href=\"/lw/45u/a_rationalists_guide_to_psychoactive_drugs/\">this post</a>. This is mainly because I do not have a beta and this is based on many personal experiences that are unclear at times.</p>\n<p>&nbsp;</p>\n<p>This subject has been touched <a href=\"/lw/1sm/akrasia_tactics_review/\">on</a> <a href=\"/lw/2qv/browser_buddies_remote_monitoring_experiment/\">many</a> <a href=\"/r/discussion/lw/6zv/leveling_irl/\">times</a> throughout LessWrong because <a href=\"http://wiki.lesswrong.com/wiki/Akrasia\">Akrasia </a>is the most dangerous foe of any true follower of Rationality. When you know you could be amazing but you find yourself unable to change due to the havoc that feelings can play with your thoughts you feel helpless and I want to help you surpass that. I am beginning a Journey to fight Akrasia directly in all its forms and in the past such Journey's have been abandoned without much progress. In this mini-sequence of posts I plan to not only document my fight to push past the depressing weight of Akrasia as a tool to keep me on the path, I will also provide some anti-Akrasia reports on my progress with different techniques that fellow LessWrongians can look back on and draw strength from in times of despair and laziness.</p>\n<p>&nbsp;</p>\n<p>My name is Matthew Baker and <a href=\"/lw/5p2/people_who_want_to_save_the_world/\">I want to save the world</a>.</p>\n<p>I think most people share the feeling that the world <a href=\"/lw/5p2/people_who_want_to_save_the_world/4616\">should be saved</a> and that only true <a href=\"/user/Quirinus_Quirrell/\">sociopaths</a> can discount the value of all sentient life. This is so important because the majority of people aren't able to defeat their innate Akrasic reasoning, ugh fields, and other factors that prevent them from functioning in a way that aligns with their beliefs. I think that if you believe in something, and you wish to be more rational towards the world then you should either push your beliefs towards the current state of reality or push reality towards your current state of beliefs.</p>\n<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif] --><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0in; line-height:115%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} --> <!--[endif] --></p>\n<p>When I was younger and sought something that I could devote effort to that would change the world for the better, I was quite disillusioned by the fact that nearly every cause relied on their innate biases to deal with the problems facing them. From political struggles to moral tribulation humanity is very good at ignoring things that don't coincide with their worldview. I always sought to surpass that but for a long time I failed to find anything to believe in that coincided with reality. Now that my skepticism is satisfied I have to logically take a look at what things are preventing me from promoting my beliefs. Akrasia is the most dangerous foe of any true follower of rationality. I've personally experienced Akrasia as the feeling when you know you could be amazing but you find yourself unable to change due to the havoc that feelings can play with your thoughts. I am beginning a journey to fight Akrasia directly in all its forms. I've attempted this in the past without making much progress; I'm hoping a different approach will help me succeed (or at least make new and different mistakes). In this mini-sequence of posts I plan to document my fight to push past the depressing weight of Akrasia. As a tool to keep me on the path, I will also provide some anti-Akrasia reports on my progress with different techniques.</p>\n<p>My goals for this quest are varied yet connected. I don't intend to take them all on at once, but instead phase them in over the upcoming month and see if i can find the limit of my ability to avoid wasting <a href=\"/lw/2gi/the_instrumental_value_of_your_own_time/\">time</a>.</p>\n<ol>\n<li>\n<p>My goal to make myself more fit and transition to eating healthier food, right now I'm fairly skinny and I want to build some muscle to match with my height(6'1\"). Enough so that I dont have trouble picking up things and carrying them without much out-word signalling of effort, but I'm not looking to become a bodybuilder or anything I just wanna optimize the vessel carrying my consciousnesses with better food and habits.</p>\n</li>\n<li>\n<p>My goal is to become more skilled socially, I rested on my social laurels for a long time and focused on associating with people that fit my views on set issues. For maximum success I will focus on general social group construction as I advance into my second year of college. I wanna see how much fun and rationality I can spread if I focus on being skilled at gathering smart and interesting people into the <a href=\"http://wiki.lesswrong.com/wiki/Fun_theory\">fun vortex</a> I can create around me.</p>\n</li>\n<li>\n<p>My goal is to get a substantially higher GPA then I did last semester. I spent very little time on school but managed to pull off a 3.1 which was lower than my first semester GPA and I want this trend to reverse as I spend more focused time on school and actually study for the first time in my life.</p>\n</li>\n</ol>\n<p>&nbsp;</p>\n<p>Things that prevent me from achieving my goals are mostly random web browsing and gaming, lots of <a href=\"/lw/21b/ugh_fields/\">ugh fields</a> I've only recently been able to write down and start purging from my thought process, negative emotions that sap my willpower and currently unknown other factors. Hopefully I will be able to surpass these problems with the power of <a href=\"/lw/6nz/approving_reinforces_loweffort_behaviors/\">self reflection and sharing</a>, <a href=\"/lw/6iu/basics_of_animal_reinforcement/\">classical conditioning</a> and <a href=\"/lw/45u/a_rationalists_guide_to_psychoactive_drugs/\">positive substance use</a>.</p>\n<p>My goals for the upcoming week involve some social and fitness goals until school starts on the 20th. Hopefully I can get these partially phased in and be able to focus more on academia once I'm back up at school. For specific milestones I want to dance closely with at least 1 girl at a rave I'm going to tonight up in LA and I want to start working on pull-ups so I can get back up to my previous total(3) and start building from there.</p>\n<p>I expect I'll have to deal with some social anxiety at the rave and some ugh field's towards the fitness, but hopefully this form of specific goal setting and reflection will work well. I will also have substances available for backup in case I fail to perform to my personal expectations. Combined, this should allow me to surpass my Akrasic Reasoning of the past for the sake of our combined future.</p>\n<p>What can <strong>you</strong> gain from my efforts as fellow rationalists<strong>?</strong> Hopefully, once I've competed my journey I'll be able to explain my mind state well enough that you can learn from it and apply it to your own goals. When my mental state is low reading about how someone else was able to push back up from a similarly bad state can be amazingly helpful and I hope that I can provide that to others.</p>\n<p>&nbsp;</p>\n<p><a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger\">Tsuyoku Naritai!</a> My Friends</p>\n<p>P.S. If luck exists, I wish to gain more of it and <a href=\"http://wiki.lesswrong.com/wiki/Litany_of_Tarski\">believe in it</a> so wish me luck with my first top level post. :) Edit: Its now in discussion until I see a surge of excitement towards the idea of this mini-sequence.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "82ho6TZWp5PzmbDnz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -7, "extendedScore": null, "score": 7.508918970373338e-07, "legacy": true, "legacyId": "9066", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NYPmCBfrDfXfhwBog", "rRmisKb45dN7DK4BW", "MhWjxybo2wwowTgiA", "xhuaFuHc5rinDjkZo", "omSbgTBa5HDqPdjHY", "ekDXMQKwuhuKz9aow", "EFQ3F6kmt4WHXRqik", "yDRX2fdkm3HqfTpav", "EMJ3egz48BtZS8Pws", "DoLQN5ryZ9XkZjq5h"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-05T21:35:06.472Z", "modifiedAt": null, "url": null, "title": "Leveling IRL", "slug": "leveling-irl", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:02.408Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xhuaFuHc5rinDjkZo/leveling-irl", "pageUrlRelative": "/posts/xhuaFuHc5rinDjkZo/leveling-irl", "linkUrl": "https://www.lesswrong.com/posts/xhuaFuHc5rinDjkZo/leveling-irl", "postedAtFormatted": "Friday, August 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Leveling%20IRL&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALeveling%20IRL%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxhuaFuHc5rinDjkZo%2Fleveling-irl%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Leveling%20IRL%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxhuaFuHc5rinDjkZo%2Fleveling-irl", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxhuaFuHc5rinDjkZo%2Fleveling-irl", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p><span>I just got this random idea that&nbsp;</span>people who want to become better at life<span>&nbsp;could benefit from a common scale of \"leveling\". No, I don't mean vague Lesswrongey things like \"changing your mind\". I mean a set of concrete criteria like \"you qualify for level 2 if you can do 5 pull-ups, have solved 30 Project Euler problems, and did 10 cold approaches\". Obviously there would be separate ladders for different character classes, but not too many. Also obviously, my example was a bit too high for level 2. So I guess I really want to ask some meta questions here:</span></p>\n<p>1) Do you think agreeing on a common leveling scale would be a good thing for a substantial subset of LW users? Would you feel good about leveling up and telling other people about it on LW?</p>\n<p>2) Is there some good way to determine leveling criteria that are neither too high nor too low? Maybe make an intermediate scale of \"experience points\"?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "WqLn4pAWi5hn6McHQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xhuaFuHc5rinDjkZo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 45, "extendedScore": null, "score": 0.000134, "legacy": true, "legacyId": "9067", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 126, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T00:22:17.750Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Say Not \"Complexity\"", "slug": "seq-rerun-say-not-complexity", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W8QhXPyiYf2t3HZTF/seq-rerun-say-not-complexity", "pageUrlRelative": "/posts/W8QhXPyiYf2t3HZTF/seq-rerun-say-not-complexity", "linkUrl": "https://www.lesswrong.com/posts/W8QhXPyiYf2t3HZTF/seq-rerun-say-not-complexity", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Say%20Not%20%22Complexity%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Say%20Not%20%22Complexity%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8QhXPyiYf2t3HZTF%2Fseq-rerun-say-not-complexity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Say%20Not%20%22Complexity%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8QhXPyiYf2t3HZTF%2Fseq-rerun-say-not-complexity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8QhXPyiYf2t3HZTF%2Fseq-rerun-say-not-complexity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<p>Today's post, <a href=\"/lw/ix/say_not_complexity/\">Say Not \"Complexity\"</a> was originally published on 29 August 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The concept of complexity isn't meaningless, but too often people assume that adding complexity to a system they don't understand will improve it. If you don't know how to solve a problem, adding complexity won't help; better to say \"I have no idea\" than to say \"complexity\" and think you've reached an answer.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/6zc/seq_rerun_positive_bias_look_into_the_dark/\">Positive Bias: Look Into the Dark</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W8QhXPyiYf2t3HZTF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.509676399436062e-07, "legacy": true, "legacyId": "9068", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kpRSCH7ALLcb6ucWM", "A5Qdn3sWtLxaT9Bis", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T09:24:30.349Z", "modifiedAt": null, "url": null, "title": "Attempt to explain Bayes without much maths, please review", "slug": "attempt-to-explain-bayes-without-much-maths-please-review", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:35.292Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JspYyx3WjmWn3nP9h/attempt-to-explain-bayes-without-much-maths-please-review", "pageUrlRelative": "/posts/JspYyx3WjmWn3nP9h/attempt-to-explain-bayes-without-much-maths-please-review", "linkUrl": "https://www.lesswrong.com/posts/JspYyx3WjmWn3nP9h/attempt-to-explain-bayes-without-much-maths-please-review", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Attempt%20to%20explain%20Bayes%20without%20much%20maths%2C%20please%20review&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAttempt%20to%20explain%20Bayes%20without%20much%20maths%2C%20please%20review%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJspYyx3WjmWn3nP9h%2Fattempt-to-explain-bayes-without-much-maths-please-review%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Attempt%20to%20explain%20Bayes%20without%20much%20maths%2C%20please%20review%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJspYyx3WjmWn3nP9h%2Fattempt-to-explain-bayes-without-much-maths-please-review", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJspYyx3WjmWn3nP9h%2Fattempt-to-explain-bayes-without-much-maths-please-review", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1212, "htmlBody": "<p>My current favourite waste of time is the concept of Bayesian postmodernism. Just putting those two words together invokes a world of delightful wrangling, as approximately anyone who understands one won't understand or will have contempt for the other. (Though I found at least one person - a programmer who's studied philosophy - who got the idea straight away when I <a href=\"http://reddragdiva.dreamwidth.org/568203.html\">posted it to my blog</a>, which is one more than I was expecting.) It is currently a page of incoherent notes and isn't necessarily actually useful for anything as yet and may never be.</p>\n<p><em>Anyway</em>, that's not my point today. My point today is that as part of this, I have to somehow explain Bayesian thinking in a nutshell to people who are highly intelligent, but have no mathematical knowledge and may actually be <a href=\"http://en.wikipedia.org/wiki/Dyscalculia\">dyscalculic</a> - but who can and do get the feel of things. I'm trying to get across that this is how learning works already and I just want to make them aware of it. I've run it past a <a href=\"http://cavalorn.livejournal.com/\">couple of</a> <a href=\"http://arkady.org.uk/\">working artists</a> who seemed to get the idea a bit. So I am posting this here for your technical correction.</p>\n<p>If you think it's any good, please do run it past artists or critics of your acquaintance. (I'm glancing in <a href=\"/user/AndrewHickey/\">AndrewHickey</a>'s direction right now.)</p>\n<hr />\n<p><em>\"The meaning of a thing is the way you should be influenced by it.\"</em> - <a href=\"http://twitter.com/#!/vladimirnesov/status/38730817467449344\">Vladimir Nesov</a></p>\n<p>To explain what \"Bayesian postmodernism\" means, I first have to try to explain Bayesian epistemology.</p>\n<ol>\n<li>Probability does not exist outside in the world - it exists in your head. Things happen or not in the world; probability measures your knowledge of them.</li>\n<li>You know certain things, to some degree. New knowledge and experiences come in and affect your knowledge, pulling your degree of certainty of given ideas up or down.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Bayes%27_theorem\">Bayes' Theorem</a> is the equation describing precisely how much a new piece of information (on the probability of something holding in the world) <em>must</em> affect your knowledge. This is a mathematical theorem, true in the sense that 2+2=4 is true; this is a mathematical question with one right answer. If you know your \"prior probability,\" and you know what the new information is, you know your new probability (the \"posterior probability\").</li>\n<li>The hard part is, of course knowing what the hell your prior actually is, to more useful specificity than \"everything you think you know about everything.\"</li>\n<li>(Just to make it harder, the prior is not a number, but a <a href=\"http://en.wikipedia.org/wiki/Probability_distribution\">probability distribution</a> over a spectrum of possible alternatives.)</li>\n</ol>\n<p>Bayesian epistemology is the notion of using this approach to map out the network of your degrees of certainty of your ideas and how they interact, and just how much a new idea should change your existing degrees of certainty.<br /><br />The application to criticism and understanding of art should be obvious to anyone with even an enthusiast's experience in the field. (And probably not to anyone without.) Postmodernism tells us we can't be certain of anything; Bayesianism tells us <em>precisely</em> how uncertain we should be.<br /><br />Problems:</p>\n<ol>\n<li>Assigning meaningful numbers is tricky. It's hard enough having some sort of feel for how certain you feel a given notion is, let alone working out how those certainties should interact with mathematical rigour.</li>\n<li>The mathematics to build a Bayesian network properly can get quite hairy. Calculus tends not to be a strong point of art critics.</li>\n<li>The subject matter is <em>subjective internal feelings about art</em>. Two people could build plausible yet utterly incompatible Bayesian networks of subjective feelings, even given that art is intersubjective rather than purely subjective. (There is an interesting result called <a href=\"http://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem\">Aumann's Agreement Theorem</a> which mathematically proves that two Bayesians starting from the same data <em> cannot</em> \"agree to disagree\", at least one must be <em>wrong</em> - but find two art enthusiasts who start from the same life experiences with the same personal inclinations. Thus, convincing others becomes an argument about bases.)</li>\n</ol>\n<p>No human who claims to be a Bayesian actually has a network mapped out in their head. They're just doing their best. But that people (a) do this and (b) get useful results from it - even in number-based fields, rather than subjective feeling-based ones - is promising.<br /><br />A word on competing approaches: The model that holds that probability exists in the world, which is the version found in common everyday popular usage and which your statistics textbooks probably taught you how to use, is the frequentist approach. This is a grab-bag of tools and statistical methods to apply to the problem. The easy part is you don't have to know your precise prior. The hard part is that different methods can get different answers, of which only one (if that) can be right, so you have to know which one to apply. The entire frequentist toolkit can be mathematically derived from the Bayesian approach. The Bayesian approach is currently increasingly popular in science and economics, because it gives the right answer <em>if</em> you have your prior right.</p>\n<hr />\n<p>If the above only requires minor fixes, I may post-edit based on comments so I can just refer people to this link.</p>\n<p>Despite the above section being what I've posted this here for discussion of, this is going to devolve into a thread about postmodernism. So I'll answer some of the obvious here.</p>\n<ul>\n<li>\"Postmodernism\" is not one coherent thing, but six or seven (so far that I've encountered). Per the name, it's a reaction against something called \"modernism\" in whatever field is being addressed.</li>\n<li>This also means that a lot of it makes no damn sense to the untrained reader unless you <em>also</em> understand what it's a reaction against.</li>\n<li>The name is given to both the methods and the results. Finding terrible postmodernism is about as hard as finding terrible punk rock, for the same reasons. (<em>e.g.</em> that Sokal pranked some idiots has negligible bearing on Derrida.)</li>\n<li>Science, and the Enlightenment in general, is a modernist project by nature (despite the <a href=\"http://en.wikipedia.org/wiki/Modernism\">Modernist movement</a> <em>per se</em> claiming to be a reaction to Enlightenment thinking), so science fans and postmodernists have a natural culture clash.</li>\n<li>It was obvious to me, but I appear to be the <em>first</em> person in the world to explicitly note the Bayes structure of the postmodern approach. I noticed this then I noticed that <a href=\"http://en.wikipedia.org/wiki/Diff%C3%A9rance\">diff&eacute;rance</a>, insofar as Derrida actually admits there's a definition, looks very like how a Bayesian update would feel from the inside. I think. Maybe.</li>\n<li>Cav points out that I'm basically rebuilding PM in the shape of Bayes. I need to learn enough to attempt to do it the other way around too.</li>\n<li>I've either struck gold or I've struck crack.</li>\n</ul>\n<ul>\n</ul>\n<p><strong>Post-script:</strong> No-one's coughed up their own skull in horror yet, so I assume I haven't made any glaring technical errors and, modulo a few post-edits, this'll do for now. It's still too mathematical, but diagrams may help - maybe the next version will have some.</p>\n<p>Nor has anyone started talking about postmodernism, to my surprise.</p>\n<p><strong>PPS:</strong> And I'm surprised no-one's disputed \"No human who claims to be a Bayesian actually has a network mapped out in their head.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JspYyx3WjmWn3nP9h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 17, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "9081", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T16:16:22.565Z", "modifiedAt": null, "url": null, "title": "Am confused about part of the IC* algorithm in Pearl's Causality.", "slug": "am-confused-about-part-of-the-ic-algorithm-in-pearl-s", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HHxjRw45iz3Fwi8Zf/am-confused-about-part-of-the-ic-algorithm-in-pearl-s", "pageUrlRelative": "/posts/HHxjRw45iz3Fwi8Zf/am-confused-about-part-of-the-ic-algorithm-in-pearl-s", "linkUrl": "https://www.lesswrong.com/posts/HHxjRw45iz3Fwi8Zf/am-confused-about-part-of-the-ic-algorithm-in-pearl-s", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Am%20confused%20about%20part%20of%20the%20IC*%20algorithm%20in%20Pearl's%20Causality.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAm%20confused%20about%20part%20of%20the%20IC*%20algorithm%20in%20Pearl's%20Causality.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHHxjRw45iz3Fwi8Zf%2Fam-confused-about-part-of-the-ic-algorithm-in-pearl-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Am%20confused%20about%20part%20of%20the%20IC*%20algorithm%20in%20Pearl's%20Causality.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHHxjRw45iz3Fwi8Zf%2Fam-confused-about-part-of-the-ic-algorithm-in-pearl-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHHxjRw45iz3Fwi8Zf%2Fam-confused-about-part-of-the-ic-algorithm-in-pearl-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 334, "htmlBody": "<p>(EDIT: Disregard this, the source of my confusion was me mixing up marked and unmarked arrows. I was thinking \"marked arrow = actual causal arrow _or_ latent common cause in the underlying reality, unmarked arrow = actual causal arrow in the underlying reality\", but I mixed up the definitions and it's actually the other way around. Actually, I think I was being stupid in multiple ways, but the overall answer to this post is that I was being stupid and mixed up multiple things, including to what extent steps 1 and 2 could be trusted to find all v-structures, given the possibility of unknown latent variables. (EDIT2: Wait, if there truly was an adb v-structure, shouldn't step 2 have at least put an unmarked arrowhead from a to b?))</p>\n<p>&nbsp;</p>\n<p>Am having another go at trying to go through the book (second edition, first printing), and find myself rather confused about rule 2 in step 3 of the IC* algorithm.</p>\n<p>Suppose a, b, c, d are all observed variables, a and d are adjacent by an initially undirected edge, a*-&gt;b*-&gt;c*-&gt;d (where *-&gt; represents a marked arrow), and c is not adjacent to d.</p>\n<p>Rule 2 would have us now turn the a-d edge into an unmarked arrow from a to d</p>\n<p>But... shouldn't an unmarked arrow from a to d be the one thing that is absolutely forbidden? ie, one of the possible underlying reality states allowed by the above is that c has causal influence over d. If you also have a -&gt; d, then you have a v structure with a,d,c. But assuming stable distribution relative to the true latent structure and having the actual distribution of the observable variables rather than just a sample, and all those other \"it's all well behaved\" assumptions, then steps 1 and 2 should have already found all of the v structures among the observed variables.</p>\n<p>So how is rule 2 of step 3 allowed to introduce potential new (possible) v structures among &nbsp;observed variables? Illumination would be appreciated, thank you. :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HHxjRw45iz3Fwi8Zf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 7.51269698929822e-07, "legacy": true, "legacyId": "9082", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T17:10:08.420Z", "modifiedAt": null, "url": null, "title": "Raise the Age Demographic ", "slug": "raise-the-age-demographic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:05.734Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pCoDuJuoConQZjZCL/raise-the-age-demographic", "pageUrlRelative": "/posts/pCoDuJuoConQZjZCL/raise-the-age-demographic", "linkUrl": "https://www.lesswrong.com/posts/pCoDuJuoConQZjZCL/raise-the-age-demographic", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Raise%20the%20Age%20Demographic%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARaise%20the%20Age%20Demographic%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCoDuJuoConQZjZCL%2Fraise-the-age-demographic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Raise%20the%20Age%20Demographic%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCoDuJuoConQZjZCL%2Fraise-the-age-demographic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCoDuJuoConQZjZCL%2Fraise-the-age-demographic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 732, "htmlBody": "<p><!--StartFragment--></p>\n<p class=\"MsoNormal\">Related to:&nbsp;<a href=\"/lw/5ln/building_rationalist_communities_a_series_overview\">Building rationalist communities</a>,&nbsp;<a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the\">Lessons from Latter-day Saints</a>,&nbsp;<a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont\">Holy Books (Or Rationalist Sequences) Don't Implement Themselves</a>,&nbsp;<a href=\"/lw/5o1/designing_rationalist_projects\">Designing rationalist projects</a>,&nbsp;<a href=\"/lw/6c9/community_roles_committees_and_leadership\">Community roles: teachers and auxiliaries</a>, <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">Committees and Leadership</a>&nbsp;</p>\n<p class=\"MsoNormal\">In the <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">previous</a> <a href=\"/lw/6bj/community_roles_teachers_and_auxiliaries/\">posts</a>, I listed the main roles in Latter-day Saint communities. In this post and one to follow, I will outline possible roles and implications for rationalist communities.</p>\n<p class=\"MsoNormal\">I previously mentioned the issue of teacher selections: the balance between selecting the more natural teachers and giving the less outgoing and articulate contingent a chance.</p>\n<p class=\"MsoNormal\">The latter is important, because it&rsquo;s a route to long-term skill development for all members.<a style=\"mso-footnote-id: ftn1;\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[1]</span></span></a> But, like most investments, it requires long time horizons. It&rsquo;s not viable to invest in developing talent if your embryonic talent is going to pack up and leave.</p>\n<p class=\"MsoNormal\">So how do you establish a long time horizon? How do you create a norm, an expectation, a common practice of sticking around in the group?</p>\n<p class=\"MsoNormal\">Unsurprisingly, this takes time to develop.</p>\n<p class=\"MsoNormal\"><strong>Reducing Turnover</strong></p>\n<p class=\"MsoNormal\">Wherever the church is newly established, growth is fast, but turnover is high. This is caused (at least, immediately caused) by higher levels of infighting and quarreling. A commonly-told story is of an early church leader named Thomas B. Marsh dissatisfied over increased militarization and hostilities against neighbors. As a result, he signed an affidavit which&nbsp;<a href=\"http://en.wikipedia.org/wiki/Thomas_B._Marsh#Dissatisfaction_with_the_Church\">helped trigger</a> the forcible expulsion of Mormons from the state of Missouri.</p>\n<p class=\"MsoNormal\">I&rsquo;ll repeat that: <em>where the church is new, growth is fast, but turnover is high.</em></p>\n<p class=\"MsoNormal\">Many of the church members in India were in their late teens or early 20&rsquo;s, looking for more direction in life. We were glad they joined, but there was a problem. The stability of the church organization in India was inversely proportional to the proportion of church members who were young, single adults.</p>\n<p class=\"MsoNormal\">One set of problems stemmed from romances gone awry, unwanted male attention, and resulting gossip. Another set of problems stemmed from simple unreliability &ndash; they often wouldn&rsquo;t take their organizational responsibilities seriously, or wouldn&rsquo;t prepare for classes they were supposed to teach.<a style=\"mso-footnote-id: ftn2;\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[2]</span></span></a> And they generally weren&rsquo;t as useful in teaching other members, because they weren&rsquo;t as mature.</p>\n<p class=\"MsoNormal\">Of course families got in disagreements and quarrels too. But I certainly heard less about those.</p>\n<p class=\"MsoNormal\"><strong>Raise the Age Demographic</strong></p>\n<p class=\"MsoNormal\">A commonly-cited Less Wrong norm is to raise the sanity waterline. I propose a new norm: raise the age demographic.</p>\n<p class=\"MsoNormal\">Functionally, parenthood encourages long-time-horizon thinking, and stabilizes one's self-defined identity as a member of group X. This is especially true in memes that require you to perform actively organizational tasks.</p>\n<p class=\"MsoNormal\">First, marriage. Consider Mormonism, and remember the lay clergy and everyone-has-a-role norms. A big problem for the church in India was gender imbalance &ndash; there were too many guys and so they would marry girls who weren&rsquo;t in the church. Then when they had to choose between spending time at church or helping to run the church, and spending time with their wife, they chose the latter.</p>\n<p class=\"MsoNormal\">This is true for other time-intensive memetic groups &ndash; I picked up some Amway promotional materials once and noticed that most of featured people were married couples. (And yes, I do think Amway is Dark Side-ish.)</p>\n<p class=\"MsoNormal\">Second, children. It&rsquo;s one of the standard stories &ndash; a couple isn&rsquo;t really religious, but they have a kid and think their children needs religion so they start going to church. What are they looking for? An identity; a set of moral guidelines for their children.</p>\n<p class=\"MsoNormal\">Less Wrong needs to move into this market space.</p>\n<p class=\"MsoNormal\">Right now, the median demographic of Less Wrongians is a <a href=\"/r/discussion/lw/6zs/teenage_rationalists_and_changing_your_mind/\">teenage</a> to mid-20s, unmarried, male; it&rsquo;s a group that includes me. But a good way to find long-term committed people and reduce turnover is to reach out to a slightly older demographic &ndash; parents with children.<span class=\"MsoFootnoteReference\"><a style=\"mso-footnote-id: ftn3;\" name=\"_ftnref3\" href=\"#_ftn3\">[3]</a></span></p>\n<p class=\"MsoNormal\">In the church, sure, the Young Women&rsquo;s organization exists for the teenager girls; and the Primary organization exists for the smaller children. But the adults involved in each organization, and the parents of the children, are tied more closely into the church community. Each of them receives a (another) definite, concrete reason to come to church each Sunday.</p>\n<p class=\"MsoNormal\">In a rationalist parenting club, the children running around would provide a constant reminder and justification for the group&rsquo;s existence.</p>\n<div style=\"mso-element: footnote-list;\"><br /> \n<hr size=\"1\" />\n<div id=\"ftn1\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn1;\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[1]</span></span></a> Personally, I&rsquo;m far more articulate in my conversation and public speech due to numerous occasions where I led classes, gave speeches, and so forth.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn2;\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[2]</span></span></a> This wasn&rsquo;t universal, but it was a general trend.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn3;\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[3]</span></span></a> I&rsquo;m not sure exactly <em>how</em><span style=\"font-style: normal;\"> to do this, but I am sure that it is desirable.</span></p>\n</div>\n</div>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pCoDuJuoConQZjZCL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 6, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "9083", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--StartFragment--></p>\n<p class=\"MsoNormal\">Related to:&nbsp;<a href=\"/lw/5ln/building_rationalist_communities_a_series_overview\">Building rationalist communities</a>,&nbsp;<a href=\"/lw/5lm/building_rationalist_communities_lessons_from_the\">Lessons from Latter-day Saints</a>,&nbsp;<a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont\">Holy Books (Or Rationalist Sequences) Don't Implement Themselves</a>,&nbsp;<a href=\"/lw/5o1/designing_rationalist_projects\">Designing rationalist projects</a>,&nbsp;<a href=\"/lw/6c9/community_roles_committees_and_leadership\">Community roles: teachers and auxiliaries</a>, <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">Committees and Leadership</a>&nbsp;</p>\n<p class=\"MsoNormal\">In the <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">previous</a> <a href=\"/lw/6bj/community_roles_teachers_and_auxiliaries/\">posts</a>, I listed the main roles in Latter-day Saint communities. In this post and one to follow, I will outline possible roles and implications for rationalist communities.</p>\n<p class=\"MsoNormal\">I previously mentioned the issue of teacher selections: the balance between selecting the more natural teachers and giving the less outgoing and articulate contingent a chance.</p>\n<p class=\"MsoNormal\">The latter is important, because it\u2019s a route to long-term skill development for all members.<a style=\"mso-footnote-id: ftn1;\" name=\"_ftnref1\" href=\"#_ftn1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[1]</span></span></a> But, like most investments, it requires long time horizons. It\u2019s not viable to invest in developing talent if your embryonic talent is going to pack up and leave.</p>\n<p class=\"MsoNormal\">So how do you establish a long time horizon? How do you create a norm, an expectation, a common practice of sticking around in the group?</p>\n<p class=\"MsoNormal\">Unsurprisingly, this takes time to develop.</p>\n<p class=\"MsoNormal\"><strong id=\"Reducing_Turnover\">Reducing Turnover</strong></p>\n<p class=\"MsoNormal\">Wherever the church is newly established, growth is fast, but turnover is high. This is caused (at least, immediately caused) by higher levels of infighting and quarreling. A commonly-told story is of an early church leader named Thomas B. Marsh dissatisfied over increased militarization and hostilities against neighbors. As a result, he signed an affidavit which&nbsp;<a href=\"http://en.wikipedia.org/wiki/Thomas_B._Marsh#Dissatisfaction_with_the_Church\">helped trigger</a> the forcible expulsion of Mormons from the state of Missouri.</p>\n<p class=\"MsoNormal\">I\u2019ll repeat that: <em>where the church is new, growth is fast, but turnover is high.</em></p>\n<p class=\"MsoNormal\">Many of the church members in India were in their late teens or early 20\u2019s, looking for more direction in life. We were glad they joined, but there was a problem. The stability of the church organization in India was inversely proportional to the proportion of church members who were young, single adults.</p>\n<p class=\"MsoNormal\">One set of problems stemmed from romances gone awry, unwanted male attention, and resulting gossip. Another set of problems stemmed from simple unreliability \u2013 they often wouldn\u2019t take their organizational responsibilities seriously, or wouldn\u2019t prepare for classes they were supposed to teach.<a style=\"mso-footnote-id: ftn2;\" name=\"_ftnref2\" href=\"#_ftn2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[2]</span></span></a> And they generally weren\u2019t as useful in teaching other members, because they weren\u2019t as mature.</p>\n<p class=\"MsoNormal\">Of course families got in disagreements and quarrels too. But I certainly heard less about those.</p>\n<p class=\"MsoNormal\"><strong id=\"Raise_the_Age_Demographic\">Raise the Age Demographic</strong></p>\n<p class=\"MsoNormal\">A commonly-cited Less Wrong norm is to raise the sanity waterline. I propose a new norm: raise the age demographic.</p>\n<p class=\"MsoNormal\">Functionally, parenthood encourages long-time-horizon thinking, and stabilizes one's self-defined identity as a member of group X. This is especially true in memes that require you to perform actively organizational tasks.</p>\n<p class=\"MsoNormal\">First, marriage. Consider Mormonism, and remember the lay clergy and everyone-has-a-role norms. A big problem for the church in India was gender imbalance \u2013 there were too many guys and so they would marry girls who weren\u2019t in the church. Then when they had to choose between spending time at church or helping to run the church, and spending time with their wife, they chose the latter.</p>\n<p class=\"MsoNormal\">This is true for other time-intensive memetic groups \u2013 I picked up some Amway promotional materials once and noticed that most of featured people were married couples. (And yes, I do think Amway is Dark Side-ish.)</p>\n<p class=\"MsoNormal\">Second, children. It\u2019s one of the standard stories \u2013 a couple isn\u2019t really religious, but they have a kid and think their children needs religion so they start going to church. What are they looking for? An identity; a set of moral guidelines for their children.</p>\n<p class=\"MsoNormal\">Less Wrong needs to move into this market space.</p>\n<p class=\"MsoNormal\">Right now, the median demographic of Less Wrongians is a <a href=\"/r/discussion/lw/6zs/teenage_rationalists_and_changing_your_mind/\">teenage</a> to mid-20s, unmarried, male; it\u2019s a group that includes me. But a good way to find long-term committed people and reduce turnover is to reach out to a slightly older demographic \u2013 parents with children.<span class=\"MsoFootnoteReference\"><a style=\"mso-footnote-id: ftn3;\" name=\"_ftnref3\" href=\"#_ftn3\">[3]</a></span></p>\n<p class=\"MsoNormal\">In the church, sure, the Young Women\u2019s organization exists for the teenager girls; and the Primary organization exists for the smaller children. But the adults involved in each organization, and the parents of the children, are tied more closely into the church community. Each of them receives a (another) definite, concrete reason to come to church each Sunday.</p>\n<p class=\"MsoNormal\">In a rationalist parenting club, the children running around would provide a constant reminder and justification for the group\u2019s existence.</p>\n<div style=\"mso-element: footnote-list;\"><br> \n<hr size=\"1\">\n<div id=\"ftn1\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn1;\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[1]</span></span></a> Personally, I\u2019m far more articulate in my conversation and public speech due to numerous occasions where I led classes, gave speeches, and so forth.</p>\n</div>\n<div id=\"ftn2\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn2;\" name=\"_ftn2\" href=\"#_ftnref2\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[2]</span></span></a> This wasn\u2019t universal, but it was a general trend.</p>\n</div>\n<div id=\"ftn3\" style=\"mso-element: footnote;\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id: ftn3;\" name=\"_ftn3\" href=\"#_ftnref3\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote;\">[3]</span></span></a> I\u2019m not sure exactly <em>how</em><span style=\"font-style: normal;\"> to do this, but I am sure that it is desirable.</span></p>\n</div>\n</div>\n<!--EndFragment-->\n<p>&nbsp;</p>", "sections": [{"title": "Reducing Turnover", "anchor": "Reducing_Turnover", "level": 1}, {"title": "Raise the Age Demographic", "anchor": "Raise_the_Age_Demographic", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "75 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 75, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zasc7RXAEosWLYf8E", "su7bXsXYpY55vwphc", "4CW68uEwgWuLfBenZ", "m38tS7dq8znk5rNjG", "cP2XeHeQjCZnw6PBm", "igkgCjss3rmNmp9jB", "7kYeJDZWkBomEPqyr", "9jRdkXLnFD2DuEeJg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T17:38:42.140Z", "modifiedAt": "2020-07-10T19:56:13.267Z", "url": null, "title": "Why are certain trends so precisely exponential?", "slug": "why-are-certain-trends-so-precisely-exponential", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:02.385Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cBa9cDhFNq9CQmu2v/why-are-certain-trends-so-precisely-exponential", "pageUrlRelative": "/posts/cBa9cDhFNq9CQmu2v/why-are-certain-trends-so-precisely-exponential", "linkUrl": "https://www.lesswrong.com/posts/cBa9cDhFNq9CQmu2v/why-are-certain-trends-so-precisely-exponential", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20are%20certain%20trends%20so%20precisely%20exponential%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20are%20certain%20trends%20so%20precisely%20exponential%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBa9cDhFNq9CQmu2v%2Fwhy-are-certain-trends-so-precisely-exponential%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20are%20certain%20trends%20so%20precisely%20exponential%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBa9cDhFNq9CQmu2v%2Fwhy-are-certain-trends-so-precisely-exponential", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcBa9cDhFNq9CQmu2v%2Fwhy-are-certain-trends-so-precisely-exponential", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<html><head></head><body><p>I was reading a <a href=\"http://fivethirtyeight.blogs.nytimes.com/2011/08/04/double-dip-or-not-economy-is-falling-farther-behind/\">post on the economy</a> from the political statistics blog <a href=\"http://fivethirtyeight.blogs.nytimes.com/\">FiveThirtyEight</a>, and the following graph shocked me:</p><figure><img src=\"http://images.lesswrong.com/t3_70c_0.png\"></figure><p>This, according to Nate Silver, is a log-scaled graph of the GDP of the United States since the Civil War, adjusted for inflation. What amazes me is how nearly perfect the linear approximation is (representing exponential growth of approximately 3.5% per year), despite all the technological and geopolitical changes of the past 134 years. (The Great Depression knocks it off pace, but WWII and the postwar recovery set it neatly back on track.) I would have expected a much more meandering rate of growth.</p><p>It reminds me of <a href=\"http://en.wikipedia.org/wiki/Moore%27s_law\">Moore's Law</a>, which would be amazing enough as a predicted exponential <i>lower bound</i> of technological advance, but is staggering as an actual approximation:</p><figure><img src=\"http://images.lesswrong.com/t3_70c_1.png?v=9efb952b0336dbfd116fd68f1c53fb7f\"></figure><p>I don't want to sound like Kurzweil here, but something demands explanation: is there a good reason why processes like these, with so many changing exogenous variables, seem to keep right on a <i>particular</i> pace of exponential growth, as opposed to wandering between phases with different exponents?</p><p><strong>EDIT:</strong> <a href=\"/lw/70c/why_are_certain_trends_so_precisely_exponential/4mq0\">As I commented below</a>, not all graphs of exponentially growing quantities exhibit this phenomenon- there still seems to be something rather special about these two graphs.</p></body></html>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cBa9cDhFNq9CQmu2v", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 29, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "9084", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.2.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T17:50:36.561Z", "modifiedAt": null, "url": null, "title": "Selecting optimal group projects and roles ", "slug": "selecting-optimal-group-projects-and-roles", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:08.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6H7QdaFYDbchQGqyT/selecting-optimal-group-projects-and-roles", "pageUrlRelative": "/posts/6H7QdaFYDbchQGqyT/selecting-optimal-group-projects-and-roles", "linkUrl": "https://www.lesswrong.com/posts/6H7QdaFYDbchQGqyT/selecting-optimal-group-projects-and-roles", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Selecting%20optimal%20group%20projects%20and%20roles%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelecting%20optimal%20group%20projects%20and%20roles%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6H7QdaFYDbchQGqyT%2Fselecting-optimal-group-projects-and-roles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Selecting%20optimal%20group%20projects%20and%20roles%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6H7QdaFYDbchQGqyT%2Fselecting-optimal-group-projects-and-roles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6H7QdaFYDbchQGqyT%2Fselecting-optimal-group-projects-and-roles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 695, "htmlBody": "<p><!--StartFragment--></p>\n<p class=\"MsoNormal\">Related to: <a href=\"/lw/5o1/designing_rationalist_projects\">Designing Rationalist Projects</a>, <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">Committees and Leadership</a></p>\n<p class=\"MsoNormal\">As I mentioned in the above posts, Latter-day Saints communities organize committees to accomplish specific tasks, like serving the outside community or making sure new members get friends.</p>\n<p class=\"MsoNormal\">The question is, what tasks should rationalist communities organize committees or assign individuals to accomplish?</p>\n<p class=\"MsoNormal\">The easy answer: whatever its members want. But there are some collective roles and activities which are better for community-building than others.</p>\n<p class=\"MsoNormal\">Consider the following jury-rigged contraption, which I'll call Bhagwat&rsquo;s community-building ratio:</p>\n<ul>\n<li>group project goodness = U(project) / E(social friction),</li>\n</ul>\n<p class=\"MsoNormal\">that is, task goodness equals task utility divided by the expected amount of resulting social friction.&nbsp;For example:</p>\n<p class=\"MsoNormal\"><em>Learning PUA:</em></p>\n<ul>\n<li><em>U(task): medium.</em><span style=\"font-style:normal\"> Many LW-goers do express a desire to improve social skills.</span></li>\n<li><em>E(social friction): high.</em><span style=\"font-style:normal\"> This seems to alienate many (most?), though not all, women. And LW meetups need more women, both to function better now and because it would facilitate&nbsp;<a href=\"/lw/70b/raise_the_age_demographic/\">future meme propagation</a>.</span></li>\n</ul>\n<p class=\"MsoNormal\"><em>Rejection therapy:</em></p>\n<ul>\n<li><em>U(task): medium-to-high.</em><span style=\"font-style:normal\"> This also helps to improve social skiils, especially assertiveness. More simple and widely applicable than PUA; easy to do without a mentor.</span></li>\n<li><em>E(social friction): low.</em><span style=\"font-style:normal\"> This is a multi-gender activity.</span></li>\n</ul>\n<p class=\"MsoNormal\">So rejection therapy would likely make a better group task then PUA.</p>\n<p class=\"MsoNormal\"><strong>What are the most high-utility, low-social-friction tasks?</strong></p>\n<p class=\"MsoNormal\">The lowest-hanging fruit I know of is to make people feel welcome.<span class=\"MsoFootnoteReference\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\">[1]</a></span></p>\n<p class=\"MsoNormal\">Whenever someone comes to the group for the first time, the group leader should make sure to meet them personally and make them feel welcome. They should get their contact info and afterwards send them a brief e-mail/text, sincerely thanking them for coming.</p>\n<p class=\"MsoNormal\">As people are starting to come for the first few weeks, the group leader should get to know them personally and understand what they&rsquo;re looking for and why they came. Maybe there&rsquo;s a particular book or Less Wrong sequence they would like. Maybe they&rsquo;re trying to improve some skills and would appreciate follow-up. Maybe there&rsquo;s some skill they know that other Less Wrongians want to learn &ndash; and they could teach them!</p>\n<p class=\"MsoNormal\">If you&rsquo;re able to personalize their experience, you will improve your score on Bhagwat&rsquo;s Law of Commitment: &ldquo;The degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.\"</p>\n<p class=\"MsoNormal\">This task is fairly delegatable. The main requirement is good social skills &ndash; you need to be able to have a reasonable conversation with <em>anyone</em><span style=\"font-style:normal\">, and the ability to express gratitude sincerely. Otherwise, people might come off as insincere or weird, and that </span><em>would</em><span style=\"font-style:normal\"> create social friction.</span></p>\n<p class=\"MsoNormal\">What are the benefits?</p>\n<p class=\"MsoNormal\">The first three church units I served in were mediocre at befriending new attendees and integrating new members; the last church unit was excellent. Around seventy percent more people joined this last church unit; and of those who joined, retention rates were around 80 to 90 percent, compared to 50 percent elsewhere.</p>\n<p class=\"MsoNormal\"><strong><em>Small Mini-groups</em></strong></p>\n<p class=\"MsoNormal\">As Less Wrong meetup membership in a given area becomes reasonably dense, and meeting size expands, subgroups can form around common interests.</p>\n<p class=\"MsoNormal\">An Improving Social Skills group. Or an Actually Learning in College group. Or a startup where a bunch of LW people work together&hellip;wait, somebody is <a href=\"/lw/2u9/quixey_engineering_screening_questions/\">already doing that</a>.</p>\n<p class=\"MsoNormal\">Mini-meetings would also be good for introducing people to the Less Wrong community. People coming for the first time are generally more comfortable in smaller environments. Latter-day Saint churches with 50-100 weekly attendance grow three or four times faster than churches with 200+ weekly attendance, according to a statistic I read somewhere and can't track down.</p>\n<p class=\"MsoNormal\">There&rsquo;s a final benefit to having clearly-defined roles held by community members.</p>\n<p class=\"MsoNormal\">All groups, as they evolve, give individuals distinct roles. Class clown, teacher&rsquo;s pet, whatever. If these roles are positive, people&rsquo;s identification with and commitment to the group will increase. They will know that the group needs them.</p>\n<p class=\"MsoNormal\">Most people in Latter-day Saint communities have specific, definite roles because of their calling &ndash; perhaps they are teaching a class every Sunday, or are responsible to visit a particularly troubled family. This is an unambiguous way to tell them, &ldquo;We need you.&rdquo;</p>\n<p class=\"MsoNormal\">The same could be true in rationalist communities.</p>\n<div style=\"mso-element:footnote-list\"><br /> \n<hr size=\"1\" />\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> In Latter-day Saint communities, this is primarily done by the Missionary and Fellowship committees described in my last post.</p>\n</div>\n</div>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6H7QdaFYDbchQGqyT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 3, "extendedScore": null, "score": 7.512995445823131e-07, "legacy": true, "legacyId": "9086", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--StartFragment--></p>\n<p class=\"MsoNormal\">Related to: <a href=\"/lw/5o1/designing_rationalist_projects\">Designing Rationalist Projects</a>, <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">Committees and Leadership</a></p>\n<p class=\"MsoNormal\">As I mentioned in the above posts, Latter-day Saints communities organize committees to accomplish specific tasks, like serving the outside community or making sure new members get friends.</p>\n<p class=\"MsoNormal\">The question is, what tasks should rationalist communities organize committees or assign individuals to accomplish?</p>\n<p class=\"MsoNormal\">The easy answer: whatever its members want. But there are some collective roles and activities which are better for community-building than others.</p>\n<p class=\"MsoNormal\">Consider the following jury-rigged contraption, which I'll call Bhagwat\u2019s community-building ratio:</p>\n<ul>\n<li>group project goodness = U(project) / E(social friction),</li>\n</ul>\n<p class=\"MsoNormal\">that is, task goodness equals task utility divided by the expected amount of resulting social friction.&nbsp;For example:</p>\n<p class=\"MsoNormal\"><em>Learning PUA:</em></p>\n<ul>\n<li><em>U(task): medium.</em><span style=\"font-style:normal\"> Many LW-goers do express a desire to improve social skills.</span></li>\n<li><em>E(social friction): high.</em><span style=\"font-style:normal\"> This seems to alienate many (most?), though not all, women. And LW meetups need more women, both to function better now and because it would facilitate&nbsp;<a href=\"/lw/70b/raise_the_age_demographic/\">future meme propagation</a>.</span></li>\n</ul>\n<p class=\"MsoNormal\"><em>Rejection therapy:</em></p>\n<ul>\n<li><em>U(task): medium-to-high.</em><span style=\"font-style:normal\"> This also helps to improve social skiils, especially assertiveness. More simple and widely applicable than PUA; easy to do without a mentor.</span></li>\n<li><em>E(social friction): low.</em><span style=\"font-style:normal\"> This is a multi-gender activity.</span></li>\n</ul>\n<p class=\"MsoNormal\">So rejection therapy would likely make a better group task then PUA.</p>\n<p class=\"MsoNormal\"><strong id=\"What_are_the_most_high_utility__low_social_friction_tasks_\">What are the most high-utility, low-social-friction tasks?</strong></p>\n<p class=\"MsoNormal\">The lowest-hanging fruit I know of is to make people feel welcome.<span class=\"MsoFootnoteReference\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftnref1\" href=\"#_ftn1\">[1]</a></span></p>\n<p class=\"MsoNormal\">Whenever someone comes to the group for the first time, the group leader should make sure to meet them personally and make them feel welcome. They should get their contact info and afterwards send them a brief e-mail/text, sincerely thanking them for coming.</p>\n<p class=\"MsoNormal\">As people are starting to come for the first few weeks, the group leader should get to know them personally and understand what they\u2019re looking for and why they came. Maybe there\u2019s a particular book or Less Wrong sequence they would like. Maybe they\u2019re trying to improve some skills and would appreciate follow-up. Maybe there\u2019s some skill they know that other Less Wrongians want to learn \u2013 and they could teach them!</p>\n<p class=\"MsoNormal\">If you\u2019re able to personalize their experience, you will improve your score on Bhagwat\u2019s Law of Commitment: \u201cThe degree to which people identify with your group is directly proportional to the amount of stuff you tell them to do that works.\"</p>\n<p class=\"MsoNormal\">This task is fairly delegatable. The main requirement is good social skills \u2013 you need to be able to have a reasonable conversation with <em>anyone</em><span style=\"font-style:normal\">, and the ability to express gratitude sincerely. Otherwise, people might come off as insincere or weird, and that </span><em>would</em><span style=\"font-style:normal\"> create social friction.</span></p>\n<p class=\"MsoNormal\">What are the benefits?</p>\n<p class=\"MsoNormal\">The first three church units I served in were mediocre at befriending new attendees and integrating new members; the last church unit was excellent. Around seventy percent more people joined this last church unit; and of those who joined, retention rates were around 80 to 90 percent, compared to 50 percent elsewhere.</p>\n<p class=\"MsoNormal\"><strong id=\"Small_Mini_groups\"><em>Small Mini-groups</em></strong></p>\n<p class=\"MsoNormal\">As Less Wrong meetup membership in a given area becomes reasonably dense, and meeting size expands, subgroups can form around common interests.</p>\n<p class=\"MsoNormal\">An Improving Social Skills group. Or an Actually Learning in College group. Or a startup where a bunch of LW people work together\u2026wait, somebody is <a href=\"/lw/2u9/quixey_engineering_screening_questions/\">already doing that</a>.</p>\n<p class=\"MsoNormal\">Mini-meetings would also be good for introducing people to the Less Wrong community. People coming for the first time are generally more comfortable in smaller environments. Latter-day Saint churches with 50-100 weekly attendance grow three or four times faster than churches with 200+ weekly attendance, according to a statistic I read somewhere and can't track down.</p>\n<p class=\"MsoNormal\">There\u2019s a final benefit to having clearly-defined roles held by community members.</p>\n<p class=\"MsoNormal\">All groups, as they evolve, give individuals distinct roles. Class clown, teacher\u2019s pet, whatever. If these roles are positive, people\u2019s identification with and commitment to the group will increase. They will know that the group needs them.</p>\n<p class=\"MsoNormal\">Most people in Latter-day Saint communities have specific, definite roles because of their calling \u2013 perhaps they are teaching a class every Sunday, or are responsible to visit a particularly troubled family. This is an unambiguous way to tell them, \u201cWe need you.\u201d</p>\n<p class=\"MsoNormal\">The same could be true in rationalist communities.</p>\n<div style=\"mso-element:footnote-list\"><br> \n<hr size=\"1\">\n<div id=\"ftn1\" style=\"mso-element:footnote\">\n<p class=\"MsoFootnoteText\"><a style=\"mso-footnote-id:ftn1\" name=\"_ftn1\" href=\"#_ftnref1\"><span class=\"MsoFootnoteReference\"><span style=\"mso-special-character: footnote\">[1]</span></span></a> In Latter-day Saint communities, this is primarily done by the Missionary and Fellowship committees described in my last post.</p>\n</div>\n</div>\n<!--EndFragment-->\n<p>&nbsp;</p>", "sections": [{"title": "What are the most high-utility, low-social-friction tasks?", "anchor": "What_are_the_most_high_utility__low_social_friction_tasks_", "level": 1}, {"title": "Small Mini-groups", "anchor": "Small_Mini_groups", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "28 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["m38tS7dq8znk5rNjG", "igkgCjss3rmNmp9jB", "pCoDuJuoConQZjZCL", "TomiDF8JkAXZcj39s"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T20:52:05.450Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup 08-09-2011", "slug": "meetup-west-la-meetup-08-09-2011", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mqB5tX6BsanXBeNAa/meetup-west-la-meetup-08-09-2011", "pageUrlRelative": "/posts/mqB5tX6BsanXBeNAa/meetup-west-la-meetup-08-09-2011", "linkUrl": "https://www.lesswrong.com/posts/mqB5tX6BsanXBeNAa/meetup-west-la-meetup-08-09-2011", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%2008-09-2011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%2008-09-2011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqB5tX6BsanXBeNAa%2Fmeetup-west-la-meetup-08-09-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%2008-09-2011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqB5tX6BsanXBeNAa%2Fmeetup-west-la-meetup-08-09-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqB5tX6BsanXBeNAa%2Fmeetup-west-la-meetup-08-09-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/23'>West LA Meetup 08-09-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 August 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10800 West Pico Blvd, Suite 312, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When</strong>: 7pm - 9pm August 9th.</p>\n\n<p><strong>Where</strong>: <a href=\"http://maps.google.com/maps?q=10800+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">The Westside Pavillion</a> - on the bridge, which connects Nordstrom 3rd floor with Barnes &amp; Noble / Landmark Theatres 3rd floor.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>There will be snacks. I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/23'>West LA Meetup 08-09-2011</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mqB5tX6BsanXBeNAa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.513570294905139e-07, "legacy": true, "legacyId": "9087", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_08_09_2011\">Discussion article for the meetup : <a href=\"/meetups/23\">West LA Meetup 08-09-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 August 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10800 West Pico Blvd, Suite 312, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When</strong>: 7pm - 9pm August 9th.</p>\n\n<p><strong>Where</strong>: <a href=\"http://maps.google.com/maps?q=10800+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">The Westside Pavillion</a> - on the bridge, which connects Nordstrom 3rd floor with Barnes &amp; Noble / Landmark Theatres 3rd floor.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>There will be snacks. I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_08_09_20111\">Discussion article for the meetup : <a href=\"/meetups/23\">West LA Meetup 08-09-2011</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup 08-09-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_08_09_2011", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup 08-09-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_08_09_20111", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-06T22:40:04.792Z", "modifiedAt": null, "url": null, "title": "Tip: Reading LW on the Kindle", "slug": "tip-reading-lw-on-the-kindle", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:31.197Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "anonym", "createdAt": "2009-02-27T21:48:32.642Z", "isAdmin": false, "displayName": "anonym"}, "userId": "X4Nt5f6dqtKAQXM9u", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vE63j8YexgzuyXzR4/tip-reading-lw-on-the-kindle", "pageUrlRelative": "/posts/vE63j8YexgzuyXzR4/tip-reading-lw-on-the-kindle", "linkUrl": "https://www.lesswrong.com/posts/vE63j8YexgzuyXzR4/tip-reading-lw-on-the-kindle", "postedAtFormatted": "Saturday, August 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tip%3A%20Reading%20LW%20on%20the%20Kindle&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATip%3A%20Reading%20LW%20on%20the%20Kindle%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvE63j8YexgzuyXzR4%2Ftip-reading-lw-on-the-kindle%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tip%3A%20Reading%20LW%20on%20the%20Kindle%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvE63j8YexgzuyXzR4%2Ftip-reading-lw-on-the-kindle", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvE63j8YexgzuyXzR4%2Ftip-reading-lw-on-the-kindle", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p>I just discovered an easy way of reading Less Wrong (and other web content) on the Kindle, and I thought others might also find this useful. I am sharing this as a discussion post rather than as a comment in an open thread in order to reach a larger audience, because this answers a need I've had for a long time (wanting a convenient way to read more on my Kindle and less on my computer monitor) that I suspect quite a few other LW readers also have. Moderators/admins: please delete this if it seems inappropriate for even the discussion section.</p>\n<p>The free <a href=\"http://www.readability.com/addons\">Readability Firefox Plugin</a> adds a 'Send to Kindle' button to Firefox, which when clicked, sends the web page in a highly readable format (stripped of header, footer, and margin text, ads, etc.) to your Kindle (for free delivery via Wi-Fi or USB). You just have to <a href=\"https://www.amazon.com/gp/digital/fiona/manage#pdocSettings\">change your kindle settings</a> to accept email from kindle@readability.com, and tell the plugin your kindle address (e.g., yourusername@free.kindle.com).</p>\n<p>On a related note, there are also <a href=\"http://wiki.lesswrong.com/wiki/Sequences#Alternative_Formats\">epub and mobi files available for some of the sequences</a>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vE63j8YexgzuyXzR4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 19, "extendedScore": null, "score": 7.513910853723219e-07, "legacy": true, "legacyId": "9088", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-07T03:29:47.748Z", "modifiedAt": null, "url": null, "title": "Exercises to do while alone", "slug": "exercises-to-do-while-alone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:02.649Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "zntneo", "createdAt": "2011-02-25T06:06:34.571Z", "isAdmin": false, "displayName": "zntneo"}, "userId": "AgBNRryLw7RWBT7uh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/paTwbcPBqjJZ5GRzj/exercises-to-do-while-alone", "pageUrlRelative": "/posts/paTwbcPBqjJZ5GRzj/exercises-to-do-while-alone", "linkUrl": "https://www.lesswrong.com/posts/paTwbcPBqjJZ5GRzj/exercises-to-do-while-alone", "postedAtFormatted": "Sunday, August 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Exercises%20to%20do%20while%20alone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExercises%20to%20do%20while%20alone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpaTwbcPBqjJZ5GRzj%2Fexercises-to-do-while-alone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Exercises%20to%20do%20while%20alone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpaTwbcPBqjJZ5GRzj%2Fexercises-to-do-while-alone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpaTwbcPBqjJZ5GRzj%2Fexercises-to-do-while-alone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 35, "htmlBody": "<p>So given my job as a cashier I have a lot of brain down time and was wondering if there are any mental exercises that one can do while alone to help improve my rationality.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "paTwbcPBqjJZ5GRzj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.514830311943212e-07, "legacy": true, "legacyId": "9090", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-07T03:55:47.315Z", "modifiedAt": null, "url": null, "title": "[LINK} Bayes' Theorem in New York Times", "slug": "link-bayes-theorem-in-new-york-times", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:30.386Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2MDiLYRdW2ebnX77T/link-bayes-theorem-in-new-york-times", "pageUrlRelative": "/posts/2MDiLYRdW2ebnX77T/link-bayes-theorem-in-new-york-times", "linkUrl": "https://www.lesswrong.com/posts/2MDiLYRdW2ebnX77T/link-bayes-theorem-in-new-york-times", "postedAtFormatted": "Sunday, August 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%7D%20Bayes'%20Theorem%20in%20New%20York%20Times&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%7D%20Bayes'%20Theorem%20in%20New%20York%20Times%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2MDiLYRdW2ebnX77T%2Flink-bayes-theorem-in-new-york-times%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%7D%20Bayes'%20Theorem%20in%20New%20York%20Times%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2MDiLYRdW2ebnX77T%2Flink-bayes-theorem-in-new-york-times", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2MDiLYRdW2ebnX77T%2Flink-bayes-theorem-in-new-york-times", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>https://www.nytimes.com/2011/08/07/books/review/the-theory-that-would-not-die-by-sharon-bertsch-mcgrayne-book-review.html?_r=1&amp;pagewanted=all</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2MDiLYRdW2ebnX77T", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.51491267573265e-07, "legacy": true, "legacyId": "9091", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-07T04:37:37.523Z", "modifiedAt": null, "url": null, "title": "Counting upvotes/downvotes", "slug": "counting-upvotes-downvotes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.280Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "calcsam", "createdAt": "2011-04-30T17:07:18.622Z", "isAdmin": false, "displayName": "calcsam"}, "userId": "YpbtzJj8Qwi4PHGm9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NvkSrXArLFnY6PJ56/counting-upvotes-downvotes", "pageUrlRelative": "/posts/NvkSrXArLFnY6PJ56/counting-upvotes-downvotes", "linkUrl": "https://www.lesswrong.com/posts/NvkSrXArLFnY6PJ56/counting-upvotes-downvotes", "postedAtFormatted": "Sunday, August 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Counting%20upvotes%2Fdownvotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACounting%20upvotes%2Fdownvotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNvkSrXArLFnY6PJ56%2Fcounting-upvotes-downvotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Counting%20upvotes%2Fdownvotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNvkSrXArLFnY6PJ56%2Fcounting-upvotes-downvotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNvkSrXArLFnY6PJ56%2Fcounting-upvotes-downvotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>I've recently posted several articles in my \"Building Rationalist Communities\" series. Some, like <a href=\"/lw/5mv/holy_books_or_rationalist_sequences_dont/\">\"Holy Books (Or Rationalist Sequences) Don't Implement Themselves\"</a>&nbsp;have been fairly popular, as measured by upvotes; others, like <a href=\"/lw/6ca/community_roles_committees_and_leadership/\">Community Roles</a>&nbsp;less so.</p>\n<p>But here is a small problem: I can see my net upvotes versus downvotes, but I can't see the numbers of each. Normally this is probably not much of a problem. But this series has been relatively controversial, and I would like to personally distinguish disagreement (high upvotes and high downvotes), from disinterest (low upvotes and low downvotes).</p>\n<p>At least for my personal satisfaction and curiosity if nothing else, is there any way to see the absolute numbers?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NvkSrXArLFnY6PJ56", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 18, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "9092", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4CW68uEwgWuLfBenZ", "igkgCjss3rmNmp9jB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-08-07T05:10:42.126Z", "modifiedAt": null, "url": null, "title": "San Diego Meetup?", "slug": "san-diego-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:01.598Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ioJrwkGTt7serMm8g/san-diego-meetup", "pageUrlRelative": "/posts/ioJrwkGTt7serMm8g/san-diego-meetup", "linkUrl": "https://www.lesswrong.com/posts/ioJrwkGTt7serMm8g/san-diego-meetup", "postedAtFormatted": "Sunday, August 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20San%20Diego%20Meetup%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASan%20Diego%20Meetup%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioJrwkGTt7serMm8g%2Fsan-diego-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=San%20Diego%20Meetup%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioJrwkGTt7serMm8g%2Fsan-diego-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FioJrwkGTt7serMm8g%2Fsan-diego-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<p>I'm going to be in San Diego for about a week in the near future. Would anyone be interested in doing a meetup?<br /><br />I propose the 13th, 14th, or 17th.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ioJrwkGTt7serMm8g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "9093", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}